# data-base-career-experimental-security-and-information-thesis-
data base career 
•	Access Control and Identity Management, 3rd Ed. by Mike Chapple. Publisher: Jones and Bartlett Learning. (Sep, 2020).
________________________________________
•	Building an Information Security Awareness Program, 1st Ed. by Bill Gardner and Valerie Thomas. Publisher: Syngress. (Aug, 2014).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Cybersecurity Risk Management by Cynthia Brumfield, Brian Haugli. Publisher: Wiley. (Dec, 2021).
________________________________________
•	Digital Forensics and Incident Response, 2nd Ed. by Gerard Johansen. Publisher: Packt Publishing. (Jan, 2020).
________________________________________
•	Disaster Recovery, Crisis Response, and Business Continuity: A Management Desk Reference by Jamie Watters, Janet Watters. Publisher: Apress. (Dec, 2013).
________________________________________
•	Distributed Denial of Service (DDoS) by Eric Chou, Rich Groves. Publisher: O’Reilly Media, Inc. (Apr, 2018).
________________________________________
•	Foundations of Information Security: A Straightforward Introduction by Jason Andress. Publisher: William Pollock. (Oct, 2019).
________________________________________
•	Fundamentals of Information Systems Security, 4th Ed. by David Kim, Michael G. Solomon. Publisher: Jones & Bartlett Publishers. (Nov, 2021).
________________________________________
•	Information Assurance Handbook: Effective Computer Security and Risk Management Strategies, 1st Ed. by Corey Schou and Steven Hernandez. Publisher: McGraw-Hill Education. (Sep, 2014).
________________________________________
•	Information Security Policies, Procedures, and Standards: A Practitioner’s Reference by Dogulas J. Landoll. Publisher: Auerbach Publications. (Mar, 2017).
________________________________________
•	ISC2 Code of Ethics by ISC2. (Dec, 2023).
________________________________________
•	Mastering Windows Security and Hardening by Mark Dunkerley, Matt Tumbarello. Publisher: Packt Publishing. (Aug, 2022).
________________________________________
•	Modern Cryptography for Security Professionals, 1st Ed. by Lisa Bock. Publisher: Packt Publishing. (Jun, 2021).
________________________________________
•	Network Security, Firewalls, and VPNs, 3rd Edition by J. Michael Stewart, Denise Kinsey. Publisher: Jones & Bartlett Learning. (Oct, 2020).
________________________________________
•	Networking Fundamentals, 1st Ed. by Gordon Davies. Publisher: Packt Publishing. (Dec, 2019).
________________________________________
•	Network Security Strategies by Aditya Mukherjee. Publisher: Packt Publishing. (Nov, 2020).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-61, Rev. 2, Computer Security Incident Handling Guide by Paul Cichonski, Tom Millar, Tim Grance, Karen Scarfone. (Aug, 2012).
________________________________________
•	Security Policies and Implementation Issues, 3rd Ed. by Robert Johnson and Chuck Easttom. Publisher: Bartlett Learning. (Oct, 2020).
________________________________________
•	The Complete Guide to Physical Security by Paul R. Baker and Daniel J. Benny. Publisher: Auerbach Publications. (Apr, 2016).
•	A Practical Guide to TPM 2.0: Using the New Trusted Platform Module in the New Age of Security by Will Arthur, David Challener. Publisher: Apress. (Jan, 2015).
________________________________________
•	Access Control and Identity Management, 3rd Ed. by Mike Chapple. Publisher: Jones and Bartlett Learning. (Sep, 2020).
________________________________________
•	A Technical Guide to IPSec Virtual Private Networks by James S. Tiller. Publisher: Auerbach Publications. (Jul, 2017).
________________________________________
•	Applied Cryptography: Protocols, Algorithms and Source Code in C, 20th Anniversary Ed. by Bruce Schneier. Publisher: Wiley. (Mar, 2015).
________________________________________
•	Building an Information Security Awareness Program, 1st Ed. by Bill Gardner and Valerie Thomas. Publisher: Syngress. (Aug, 2014).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Cryptography and Network Security Principles and Practice, 6th Ed. by William Stallings. Publisher: Pearson. (Mar, 2013).
________________________________________
•	Cybersecurity Incident Response: How to Contain, Eradicate, and Recover from Incidents by Eric C. Thompson. Publisher: Apress. (Sep, 2018).
________________________________________
•	Digital Forensics and Incident Response, 2nd Ed. by Gerard Johansen. Publisher: Packt Publishing. (Jan, 2020).
________________________________________
•	Foundations of Information Security: A Straightforward Introduction by Jason Andress. Publisher: William Pollock. (Oct, 2019).
________________________________________
•	Fundamentals of Information Systems Security, 4th Ed. by David Kim, Michael G. Solomon. Publisher: Jones & Bartlett Publishers. (Nov, 2021).
________________________________________
•	Identity Attack Vectors: Implementing an Effective Identity and Access Management Solution by Darran Rolls, Morey J. Haber. Publisher: Apress. (Dec, 2019).
________________________________________
•	Identity and Access Management: Business Performance Through Connected Intelligence, 1st Ed. by Ertem Osmanoglu. Publisher: Syngress. (Nov, 2013).
________________________________________
•	Information Risk Management: A Practitioner's Guide by David Sutton. Publisher: BCS, The Chartered Institute for IT. (Nov, 2014).
________________________________________
•	Introduction to Computer Networks and Cybersecurity, 1st Ed. by J. Chwan-Hwa Wu, David Irwin. Publisher: CRC Press. (Apr, 2016).
________________________________________
•	ISC2 Code of Ethics by ISC2. (Dec, 2023).
________________________________________
•	Logging and Log Management by A. Chuvakin, K. Schmidt. Publisher: Syngress. (Dec, 2012).
________________________________________
•	Network Security, Firewalls, and VPNs, 3rd Edition by J. Michael Stewart, Denise Kinsey. Publisher: Jones & Bartlett Learning. (Oct, 2020).
________________________________________
•	Networking Fundamentals, 1st Ed. by Gordon Davies. Publisher: Packt Publishing. (Dec, 2019).
________________________________________
•	NIST SP 800-61, Rev. 2, Computer Security Incident Handling Guide by Paul Cichonski, Tom Millar, Tim Grance, Karen Scarfone. (Aug, 2012).
________________________________________
•	Official (ISC)² SSCP CBK Reference, 5th Ed. by Mike Wills. Publisher: Sybex. (Dec, 2019).
________________________________________
•	Practical Cloud Security: A Guide for Secure Design and Deployment by Chris Dotson. Publisher: O'Reilly Media. (Mar, 2019).
•	A Practical Guide to TPM 2.0: Using the New Trusted Platform Module in the New Age of Security by Will Arthur, David Challener. Publisher: Apress. (Jan, 2015).
________________________________________
•	Access Control, Authentication, and Public Key Infrastructure (Information Systems Security & Assurance), 1st Ed. by Bill Ballad, Tricia Ballad, Erin Banks. Publisher: Jones & Bartlett Learning. (Oct, 2010).
________________________________________
•	Agile Application Security by Laura Bell, Rich Smith, Michael Brunton-Spall, Jim Bird. Publisher: O’Reilly Media, Inc. (Jun, 2017).
________________________________________
•	Architecting the Cloud: Design Decisions for Cloud Computing Service Models (SaaS, PaaS, and IaaS) by Michael Kavis. Publisher: Wiley. (Jan, 2014).
________________________________________
•	Asset Attack Vectors: Building Effective Vulnerability Management Strategies to Protect Organizations by Morey J. Haber, Brad Hibbert. Publisher: Apress. (Jun, 2018).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Computer and Information Security Handbook, 3rd Ed. by John Vacca. Publisher: Morgan Kaufmann. (May, 2017).
________________________________________
•	Computer Security: Art and Science, 2nd Ed. by Matt Bishop. Publisher: Addison-Wesley Professional. (Nov, 2018).
________________________________________
•	Core Software Security: Security at the Source by Anmol Misra, James F. Ransome. Publisher: Auerbach Publications. (Oct, 2018).
________________________________________
•	Data Center Handbook, 2nd Ed. by Hwaiyu Geng. Publisher: Wiley. (May, 2021).
________________________________________
•	Developing Cybersecurity Programs and Policies, 3rd Ed. by Omar Santos, Sari Greene. Publisher: Pearson IT Certification. (Aug, 2018).
________________________________________
•	Disaster Recovery, Crisis Response, and Business Continuity: A Management Desk Reference by Jamie Watters, Janet Watters. Publisher: Apress. (Dec, 2013).
________________________________________
•	Distributed Denial of Service (DDoS) by Eric Chou, Rich Groves. Publisher: O’Reilly Media, Inc. (Apr, 2018).
________________________________________
•	DomainKeys Identified Mail (DKIM) Signature by Murray Kucherawy, Dave Crocker, Tony Hansen. Publisher: IETF. (Sep, 2011).
________________________________________
•	Ethical Hacking and Penetration Testing Guide by Rafay Baloch. Publisher: Auerbach Publications. (Sep, 2017).
________________________________________
•	Federated Identity Primer, 1st Ed. by Derrick Rountree. Publisher: Syngress. (Dec, 2012).
________________________________________
•	Foundations of Information Security: A Straightforward Introduction by Jason Andress. Publisher: William Pollock. (Oct, 2019).
________________________________________
•	Fundamental Practices for Secure Software Development: Essential Elements of a Secure Development Lifecycle Program, 3rd Ed. by Toni Rice. Publisher: SAFECode. (Mar, 2018).
________________________________________
•	Fundamentals of Information Systems Security, 4th Ed. by David Kim, Michael G. Solomon. Publisher: Jones & Bartlett Publishers. (Nov, 2021).
________________________________________
•	EU General Data Protection Regulation (GDPR) by European Parliament. Publisher: European Parliament and Council of the European Union. (May, 2016).
________________________________________
•	Identity and Access Management: Business Performance Through Connected Intelligence, 1st Ed. by Ertem Osmanoglu. Publisher: Syngress. (Nov, 2013).
________________________________________
•	Identity Attack Vectors: Implementing an Effective Identity and Access Management Solution by Darran Rolls, Morey J. Haber. Publisher: Apress. (Dec, 2019).
________________________________________
•	Information Assurance Handbook: Effective Computer Security and Risk Management Strategies, 1st Ed. by Corey Schou and Steven Hernandez. Publisher: McGraw-Hill Education. (Sep, 2014).
________________________________________
•	Information Security Handbook by Darren Death. Publisher: Packt Publishing. (Dec, 2017).
________________________________________
•	Information Security Policies, Procedures, and Standards: A Practitioner’s Reference by Dogulas J. Landoll. Publisher: Auerbach Publications. (Mar, 2017).
________________________________________
•	Introduction to Computer Networks and Cybersecurity, 1st Ed. by J. Chwan-Hwa Wu, David Irwin. Publisher: CRC Press. (Apr, 2016).
________________________________________
•	ISC2 Code of Ethics by ISC2. (Dec, 2023).
________________________________________
•	IT Auditing Using Controls to Protect Information Assets, 3rd Edition by Mike Kegerreis, Mike Schiller, Chris Davis. Publisher: McGraw-Hill Education. (Oct, 2019).
________________________________________
•	Network Security, Firewalls, and VPNs, 3rd Edition by J. Michael Stewart, Denise Kinsey. Publisher: Jones & Bartlett Learning. (Oct, 2020).
________________________________________
•	Network Vulnerability Assessment: Identify Security Loopholes in Your Network's Infrastructure by Sagar Rahalkar. Publisher: Packt Publishing. (Aug, 2018).
________________________________________
•	Networking Fundamentals, 3rd Ed. by Chuck Easttom, Richard M. Roberts. Publisher: Goodheart-Willcox. (Sep, 2018).
________________________________________
•	NIST SP 800-30, Rev. 1, Guide for Conducting Risk Assessments by Joint Task Force Transformation Initiative. (Sep, 2012).
________________________________________
•	NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems by Marianne Swanson, Pauline Bowen, Amy Wohl Phillips, Dean Gallup, David Lynes. (May, 2010).
________________________________________
•	NIST SP 800-41, Revision 1, Guidelines on Firewalls and Firewall Policy by Karen Scarfone, Paul Hoffman. (Sep, 2009).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-63-3, Digital Identity Guidelines: Enrollment and Identity Proofing by Paul A. Grassi, James L. Fenton, Naomi B. Lefkovitz, Jamie M. Danker, Yee-Yin Choong, Kristen K. Greene, Mary F. Theofanos. (Jun, 2017).
________________________________________
•	NIST SP 800-77, Revision 1, Guide to IPsec VPNs by Elaine Barker, Quynh Dang, Sheila Frankel, Karen Scarfone, Paul Wouters. Publisher: NIST. (Jun, 2020).
________________________________________
•	NIST SP 800-88, Guidelines for Media Sanitization by Richard Kissel, Andrew Regenscheid, Matthew Scholl, Kevin Stine. (Dec, 2014).
________________________________________
•	NIST SP 800-95, Guide to Secure Web Services by Anoop Singhal, Theodore Winograd, Karen Scarfone. (Aug, 2007).
________________________________________
•	NIST SP 800-115, Technical Guide to Information Security Testing and Assessment by Karen Scarfone, Murugiah Souppaya, Amanda Cody, Angela Orebaugh. (Sep, 2008).
________________________________________
•	NIST SP 800-122, Guide to Protecting the Confidentiality of Personally Identifiable Information (PII) by Erika McCallister, Tim Grance, Karen Scarfone. (Apr, 2010).
________________________________________
•	NIST SP 800-128, Guide for Security-Focused Configuration Management of Information Systems by Arnold Johnson, Kelley Dempsey, Ron Ross, Sarbari Gupta, Dennis Bailey. (Aug, 2011).
________________________________________
•	NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for Federal Information Systems and Organizations by Kelley Dempsey, Nirali Shah Chawla, Arnold Johnson, Ronald Johnston, Alicia Clay Jones, Angela Orebaugh, Matthew Scholl, Kevin Stine. (Sep, 2011).
________________________________________
•	NIST SP 800-160, Vol. 1, Systems Security Engineering: Considerations for a Multidisciplinary Approach in the Engineering of Trustworthy Secure Systems by Ron Ross, Michael McEvilley, Janet Carrier Oren. (Mar, 2018).
________________________________________
•	Official (ISC)² Guide to the CISSP CBK, 5th Ed. by John Warsinske, Mark Graff, Kevin Henry, Christopher Hoover, Ben Malisow, Sean Murphy, C. Paul Oakes, George Pajari, Jeff T. Parker, David Seidl and Mike Vasquez. Publisher: Wiley. (May, 2019).
________________________________________
•	OWASP Testing Guide, Release 4.0 by Matteo Meucci, Andrew Muller. Publisher: OWASP. (Dec, 2014).
________________________________________
•	Physical Security and Safety by Jeffrey Dingle, Bobby E. Ricks, Truett A, Ricks. Publisher: CRC Press. (Oct, 2014).
________________________________________
•	Practical Cloud Security: A Guide for Secure Design and Deployment by Chris Dotson. Publisher: O'Reilly Media. (Mar, 2019).
________________________________________
•	Practical Internet of Things Security, 2nd Ed. by Brian Russel, Drew Van Duren. Publisher: Packt Publisher. (Nov, 2018).
________________________________________
•	Securing Open Source Libraries by Guy Podjarny. Publisher: O’Reilly Media, Inc. (Nov, 2017).
________________________________________
•	Securing VoIP, 1st Ed. by Regis Bates. Publisher: Syngress. (Nov, 2014).
________________________________________
•	Security Policies and Implementation Issues, 3rd Ed. by Robert Johnson and Chuck Easttom. Publisher: Bartlett Learning. (Oct, 2020).
________________________________________
•	Security Risk Assessment: Managing Physical and Operational Security by John M. White. Publisher: Butterworth-Heinemann. (Jul, 2014).
________________________________________
•	Solving Identity Management in Modern Applications: Demystifying OAuth 2.0, OpenID Connect, and SAML 2.0 by Abhishek Hingnikar, Yvonne Wilson. Publisher: Apress. (Nov, 2022).
________________________________________
•	The Complete Guide to Physical Security by Paul R. Baker and Daniel J. Benny. Publisher: Auerbach Publications. (Apr, 2016).
________________________________________
•	The Disaster Recovery Handbook, 3rd Ed. by Michael Wallace, Lawrence Webber. Publisher: AMACOM. (Dec, 2017).
________________________________________
•	Threat Modeling: Designing for Security, 1st Ed. by Adam Shostack. Publisher: Wiley. (Feb, 2014).
________________________________________
•	Web Application Security: Exploitation and Countermeasures for Modern Web Applications by Andrew Hoffman. Publisher: O’Reilly Media, Inc. (Mar, 2020).
________________________________________
•	Zero Trust Networks: Building Secure Systems in Untrusted Networks by Evan Gilman, Doug Barth. Publisher: O'Reilly. (Jul, 2017).
•	Architecting Cloud Computing Solutions by Kevin L. Jackson and Scott Goessling. Publisher: Packt Publishing. (May, 2018).
________________________________________
•	Architecting the Cloud: Design Decisions for Cloud Computing Service Models (SaaS, PaaS, and IaaS) by Michael Kavis. Publisher: Wiley. (Jan, 2014).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Cloud Computing Design Patterns by Thomas Erl, Robert Cope, Amin Naserpour. Publisher: Prentice Hall. (Mar, 2017).
________________________________________
•	Cloud Security Handbook by Eyal Estrin. Publisher: Packt Publishing. (Apr, 2022).
________________________________________
•	Data Governance: The Definitive Guide by Evren Eryurek, Uri Gilad, Valliappa Lakshmanan, Anita Kibunguchy-Grant, Jessi Ashdown. Publisher: O'Reilly Media, Inc. (Mar, 2021).
________________________________________
•	EU General Data Protection Regulation (GDPR) by European Parliament. Publisher: European Parliament and Council of the European Union. (May, 2016).
________________________________________
•	Fundamental Practices for Secure Software Development. Publisher: SAFECode. (Mar, 2018).
________________________________________
•	Guide to Privacy and Security of Electronic Health Information. Publisher: HealthIT.gov. (Apr, 2015).
________________________________________
•	Incident Response in the Age of Cloud: Techniques and best practices to effectively respond to cybersecurity incidents by Erdal Ozkaya. Publisher: Packt Publishing. (Feb, 2021).
________________________________________
•	Information Security Handbook by Darren Death. Publisher: Packt Publishing. (Dec, 2017).
________________________________________
•	NIST SP 800-125, Guide to Security for Full Virtualization Technologies by Karen Scarfone, Murugiah Souppaya, Paul Hoffman. (Jan, 2011).
________________________________________
•	Official (ISC)² Guide to the CCSP CBK, 3rd Ed. by Leslie Fife, Aaron Kraus, Bryan Lewis. Publisher: Sybex. (July, 2021).
________________________________________
•	Practical Cloud Security: A Guide for Secure Design and Deployment by Chris Dotson. Publisher: O'Reilly Media. (Mar, 2019).
________________________________________
•	Security Guidance for Critical Areas of Focus in Cloud Computing v4.0 by Rich Mogull, James Arlen, Adrian Lane, Gunnar Peterson, Mike Rothman, David Mortman. Publisher: Cloud Security Alliance. (Jul, 2017).
________________________________________
•	Security, Privacy, and Digital Forensics in the Cloud by Lei Chen, Hassan Takabi, Nhien-An Le-Khac. Publisher: Wiley. (Apr, 2019).
•	Information Security Risk Management for ISO 27001/ISO 27002, 3rd Ed. by Alan Calder, Steve Watkins. Publisher: IT Governance Publishing. (Aug, 2019).
________________________________________
•	ISO 27001/ISO 27002, A Pocket Guide, 2nd Ed. By Alan Calder. Publisher: IT Governance Publishing. (Oct, 2013).
________________________________________
•	NIST FIPS-199, Standards for Security Categorization of Federal Information and Information Systems by U.S. Dept. of Commerce. (Feb, 2004).
________________________________________
•	NIST SP 800-18, Rev. 1, Guide for Developing Security Plans for Federal Information Systems by Marianne Swanson, Joan Hash, Pauline Bowen. (Feb, 2006).
________________________________________
•	NIST SP 800-30, Rev. 1, Guide for Conducting Risk Assessments by Joint Task Force Transformation Initiative. (Sep, 2012).
________________________________________
•	NIST SP 800-37, Rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy by Joint Task Force Transformation Initiative. (Dec, 2018).
________________________________________
•	NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and Information System View by Joint Task Force Transformation Initiative. (Mar, 2011).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-53A, Rev. 5, Assessing Security and Privacy Controls in Information Systems and Organizations by Joint Task Force Transformation Initiative. (Jan, 2022).
________________________________________
•	NIST SP 800-53B, Control Baselines for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-60, Vol. 1, Rev. 1, Guide for Mapping Types of Information and Information Systems to Security Categories by Kevin Stine, Rich Kissel, William C. Barker, Jim Fahlsing, Jessica Gulick. (Aug, 2008).
________________________________________
•	NIST SP 800-70, Rev. 4, National Checklist Program for IT Products: Guidelines for Checklist Users and Developers by Stephen D. Quinn, Murugiah Souppaya, Melanie Cook, Karen Scarfone. (Feb, 2018).
________________________________________
•	NIST SP 800-88, Guidelines for Media Sanitization by Richard Kissel, Andrew Regenscheid, Matthew Scholl, Kevin Stine. (Dec, 2014).
________________________________________
•	NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for Federal Information Systems and Organizations by Kelley Dempsey, Nirali Shah Chawla, Arnold Johnson, Ronald Johnston, Alicia Clay Jones, Angela Orebaugh, Matthew Scholl, Kevin Stine. (Sep, 2011).
•	A Guide to Building Secure Web Applications and Web Services 2.0 Black Hat Ed. by Abraham Kang, Adrian Wiesmann, et al. Publisher: OWASP. (Jul, 2005).
________________________________________
•	A Practical Guide to TPM 2.0: Using the New Trusted Platform Module in the New Age of Security by Will Arthur, David Challener. Publisher: Apress. (Jan, 2015).
________________________________________
•	Access Control, Authentication, and Public Key Infrastructure, 2nd Ed. by Mike Chapple, Bill Ballad, Tricia Ballad, Erin Banks. Publisher: Jones & Bartlett Learning. (Jul, 2013).
________________________________________
•	Agile Application Security by Laura Bell, Rich Smith, Michael Brunton-Spall, Jim Bird. Publisher: O’Reilly Media, Inc. (Jun, 2017).
________________________________________
•	Applied Cryptography: Protocols, Algorithms and Source Code in C, 20th Anniversary Ed. by Bruce Schneier. Publisher: Wiley. (Mar, 2015).
________________________________________
•	CMMI for Development: Implementation Guide by Mukund Chaudhary, Abhishek Chopra. Publisher: Apress. (Dec, 2016).
________________________________________
•	Computer Security: Art and Science, 2nd Ed. by Matt Bishop. Publisher: Addison-Wesley Professional. (Nov, 2018).
________________________________________
•	Core Software Security: Security at the Source by Anmol Misra, James F. Ransome. Publisher: Auerbach Publications. (Oct, 2018).
________________________________________
•	Cybersecurity - Attack and Defense Strategies, 2nd Ed. by Erdal Ozkaya and Yuri Diogenes. Publisher: Packt Publishing. (Dec, 2019).
________________________________________
•	Enterprise Software Security: A Confluence of Disciplines by Kenneth R. van Wyk, Mark G. Graff, Dan S. Peters, Diana L. Burley. Publisher: Addison-Wesley Professional. (Dec, 2014).
________________________________________
•	Hacker Techniques, Tools, and Incident Handling, 2nd Ed. by Sean-Philip Oriyano. Publisher: Jones & Bartlett Learning. (Aug, 2013).
________________________________________
•	Hands-On Security in DevOps by Tony Hsu. Publisher: Packt Publishing. (Jul, 2018).
________________________________________
•	Improper Error Handling by Jeremy Ferragamo, Wichers, Jim Bird. Publisher: OWASP. (Dec, 2021).
________________________________________
•	Information Security: Principles and Practices, 2nd Ed. by Mark S. Merkow, Jim Breithaupt. Publisher: Pearson IT Certification. (Jun, 2014).
________________________________________
•	IT Release Management: A Hands-on Guide by Dave Howard. Publisher: CRC Press. (Apr, 2016).
________________________________________
•	IT Security Risk Control Management: An Audit Preparation Plan by Raymond Pompon. Publisher: Apress. (Sep, 2016).
________________________________________
•	Lessons Learned in Software Testing: A Context-Driven Approach by Bret Pettichord, Cem Kaner, James Marcus Bach. Publisher: Wiley. (Dec, 2001).
________________________________________
•	Logging and Log Management by A. Chuvakin, K. Schmidt. Publisher: Syngress. (Dec, 2012).
________________________________________
•	Mastering the Requirements Process: Getting Requirements Right v3.0 by S. Robertson, J. Robertson. Publisher: Addison-Wesley Professional. (Aug, 2012).
________________________________________
•	NIST SP 800-37, Rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy by Joint Task Force Transformation Initiative. (Dec, 2018).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-60, Vol. 1, Rev. 1, Guide for Mapping Types of Information and Information Systems to Security Categories by Kevin Stine, Rich Kissel, William C. Barker, Jim Fahlsing, Jessica Gulick. (Aug, 2008).
________________________________________
•	NIST SP 800-88, Guidelines for Media Sanitization by Richard Kissel, Andrew Regenscheid, Matthew Scholl, Kevin Stine. (Dec, 2014).
________________________________________
•	NIST IR 7622, Notional Supply Chain Risk Management Practices for Federal Information Systems by Jon Boyens, Celia Paulsen, Nadya Bartol, Stephany A. Shankles, Rama Moorthy. (Oct, 2012).
________________________________________
•	Official (ISC)² Guide to the CSSLP, 2nd Ed. by Mano Paul. Publisher: Auerbach Publications. (Aug, 2013).
________________________________________
•	OWASP Testing Guide, Release 4.0 by Matteo Meucci, Andrew Muller. Publisher: OWASP. (Dec, 2014).
________________________________________
•	Penetration Testing: A Survival Guide by W. Halton, B. Weaver, J. Ansari, S. Kotipalli, M. Imran. Publisher: Packt Publishing. (Jan, 2017).
________________________________________
•	Security Risk Management by Evan Wheeler. Publisher: Syngress. (Apr, 2011).
________________________________________
•	Software Testing Foundations: A Study Guide for the Certified Tester Exam, 4th Ed. by Andreas Spillner. Publisher: Rocky Nook. (Feb, 2014).
________________________________________
•	Web Application Firewalls by Chad Russell. Publisher: O’Reilly Media, Inc. (Apr, 2018).
•	Agile Application Lifecycle Management: Using DevOps to Drive Process Improvement, 1st Ed. by Bob Aiello, Leslie Sachs. Publisher: Addison-Wesley Professional. (Jun, 2016).
________________________________________
•	Agile Application Security by Laura Bell, Rich Smith, Michael Brunton-Spall, Jim Bird. Publisher: O'Reilly Media, Inc. (Jun, 2017).
________________________________________
•	Architecting Secure Software Systems, 1st Ed. by Asoke Talukder, Manish Chaitanya. Publisher: Auerbach Publications. (Sep, 2019).
________________________________________
•	Applied Cryptography: Protocols, Algorithms and Source Code in C, 20th Anniversary Ed. by Bruce Schneier. Publisher: Wiley. (Mar, 2015).
________________________________________
•	Beginning Database Design Solutions by Rod Stephens. Publisher: Jossey-Bass. (Nov, 2008).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Cloud Storage Security: A Practical Guide by Aaron Wheeler, Michael Winburn. Publisher: Elsevier. (Jul, 2015).
________________________________________
•	Common Criteria for Information Technology Security Evaluation, Version 3.1 Rev. 5 by Mead, N. Publisher: Carnegie. (Apr, 2017).
________________________________________
•	Data Center Handbook, 2nd Ed. by Hwaiyu Geng. Publisher: Wiley. (May, 2021).
________________________________________
•	Disaster Recovery and Business Continuity, 3rd Ed. by B.S. Thejandra. Publisher: IT Governance Publishing. (Jan, 2014).
________________________________________
•	Enterprise Security Architecture: A Business-Driven Approach, 1st Ed. by John Sherwood. Publisher: CRC Press. (Nov, 2015).
________________________________________
•	Identity and Access Management: Business Performance Through Connected Intelligence, 1st Ed. by Ertem Osmanoglu. Publisher: Syngress. (Nov, 2013).
________________________________________
•	Information Security Management Handbook, Vol. 6, 6th Ed. by Harold F. Tipton and Micki Krause Nozaki. Publisher: Auerbach Publications. (Apr, 2016).
________________________________________
•	Information Security Management Handbook, Vol. 7, 6th Ed. by Richard O'Hanley, James Tiller. Publisher: Auerbach Publications. (Aug, 2013).
________________________________________
•	NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems by Marianne Swanson, Pauline Bowen, Amy Wohl Phillips, Dean Gallup, David Lynes. (May, 2010).
________________________________________
•	NIST SP 800-57, Rev. 5, Recommendation for Key Management: Part 1 – General by Elaine Barker. Publisher: NIST. (May, 2020) .
________________________________________
•	NIST SP 800-61, Rev. 2, Computer Security Incident Handling Guide by Paul Cichonski, Tom Millar, Tim Grance, Karen Scarfone. (Aug, 2012).
________________________________________
•	NIST SP 800-63-3, Digital Identity Guidelines: Enrollment and Identity Proofing by Paul A. Grassi, James L. Fenton, Naomi B. Lefkovitz, Jamie M. Danker, Yee-Yin Choong, Kristen K. Greene, Mary F. Theofanos. (Jun, 2017).
________________________________________
•	NIST SP 800-115, Technical Guide to Information Security Testing and Assessment by Karen Scarfone, Murugiah Souppaya, Amanda Cody, Angela Orebaugh. (Sep, 2008).
________________________________________
•	]NIST SP 800-125, Guide to Security for Full Virtualization Technologies by Karen Scarfone, Murugiah Souppaya, Paul Hoffman. (Jan, 2011).
________________________________________
•	NIST SP 800-162, Guide to Attribute Based Access Control (ABAC) Definition and Considerations by Vincent Hu, David Ferraiolo, Rick Kuhn, Adam Schnitzer, Kenneth Sandlin, Robert Miller, Karen Scarfone. (Jan, 2014).
________________________________________
•	Official (ISC)² Guide to the ISSAP CBK, 2nd Ed. by Adam Gordon. Publisher: Auerbach Publications. (Jan, 2017).
________________________________________
•	Payment Card Industry Data Security Standards, Requirements and Security Assessment Procedures, Version 3.2.1 by PCI Security Standards Council. Publisher: PCI Security Standards Council, LLC. (May, 2018).
________________________________________
•	Practical Internet of Things Security, 2nd Ed. by Brian Russel, Drew Van Duren. Publisher: Packt Publisher. (Nov, 2018).
________________________________________
•	SABSA Executive Summary by SABSA. Publisher: The SABSA Institute. (Dec, 2021).
________________________________________
•	Secure Coding in C and C++, 2nd Ed. by Robert Seacord. Publisher: Addison-Wesley Professional. (Apr, 2013).
________________________________________
•	Security Patterns in Practice: Designing Secure Architectures Using Software Patterns by Eduardo Fernandez-Buglioni. Publisher: Wiley. (May, 2013).
________________________________________
•	Security Guidance for Critical Areas of Focus in Cloud Computing v4.0 by Rich Mogull, James Arlen, Adrian Lane, Gunnar Peterson, Mike Rothman, David Mortman. Publisher: Cloud Security Alliance. (Jul, 2017).
•	A Guide to the Project Management Body of Knowledge (PMBOK Guide), 7th Ed. by Project Management Institute. Publisher: Project Management Institute. (Aug, 2021).
________________________________________
•	INCOSE Systems Engineering Handbook by Walden. Publisher: Wiley. (Jul, 2015).
________________________________________
•	Information Assurance Technical Framework 3.1 by National Security Agency Information Assurance Solutions Technical Directors. (Sep, 2002).
________________________________________
•	ISO/IEC 15408 Common Criteria for Information Technology Security Evaluation by ISO/IEC. Publisher: National Information Assurance Partnership. (Dec, 2017).
________________________________________
•	NIST SP 800-30, Rev. 1, Guide for Conducting Risk Assessments by Joint Task Force Transformation Initiative. (Sep, 2012).
________________________________________
•	NIST SP 800-37, Rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy by Joint Task Force Transformation Initiative. (Dec, 2018).
________________________________________
•	NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and Information System View by Joint Task Force Transformation Initiative. (Mar, 2011).
________________________________________
•	NIST SP 800-40, Rev. 3, Guide to Enterprise Patch Management Technologies Murugiah Souppaya, Karen Scarfone. (Jul, 2013).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-88, Guidelines for Media Sanitization by Richard Kissel, Andrew Regenscheid, Matthew Scholl, Kevin Stine. (Dec, 2014).
________________________________________
•	NIST SP 800-115, Technical Guide to Information Security Testing and Assessment by Karen Scarfone, Murugiah Souppaya, Amanda Cody, Angela Orebaugh. (Sep, 2008).
________________________________________
•	NIST SP 800-160, Vol. 1, Systems Security Engineering: Considerations for a Multidisciplinary Approach in the Engineering of Trustworthy Secure Systems by Ron Ross, Michael McEvilley, Janet Carrier Oren. (Mar, 2018).
________________________________________
•	NIST SP 800-161, Supply Chain Risk Management Practices for Federal Information System and Organizations by Jon Boyens, Celia Paulsen, Rama Moorthy, Nadya Bartol. (Apr, 2015).
•	A Guide to the Project Management Body of Knowledge (PMBOK Guide), 7th Ed. by Project Management Institute. Publisher: Project Management Institute. (Aug, 2021).
________________________________________
•	Auditing IT Infrastructures for Compliance, 2nd Ed. by Martin Weiss. Publisher: Jones & Bartlett Publishers. (Jul, 2015).
________________________________________
•	Business Continuity and Disaster Recovery Planning for IT Professionals, 2nd Ed. by Susan Snedaker. Publisher: Syngress. (Sep, 2013).
________________________________________
•	Digital Forensics and Incident Response, 2nd Ed. by Gerard Johansen. Publisher: Packt Publishing. (Jan, 2020).
________________________________________
•	Disaster Recovery, Crisis Response, and Business Continuity: A Management Desk Reference by Jamie Watters, Janet Watters. Publisher: Apress. (Dec, 2013).
________________________________________
•	Disaster Recovery Planning: For Computers and Communication Resources by Jon Toigo. Publisher: Wiley. (Jan, 1996).
________________________________________
•	Information Security Management Handbook, Vol. 6, 6th Ed. by Harold F. Tipton and Micki Krause Nozaki. Publisher: Auerbach Publications. (Apr, 2016).
________________________________________
•	ISC2 Code of Ethics by ISC2. (Dec, 2023).
________________________________________
•	Incident Response & Computer Forensics, 3rd Ed. by Jason Luttgens, Matthew Pepe, Kevin Mandia. Publisher: McGraw-Hill Osborne Media. (Aug, 2014).
________________________________________
•	IT Auditing Using Controls to Protect Information Assets, 3rd Edition by Mike Kegerreis, Mike Schiller, Chris Davis. Publisher: McGraw-Hill Education. (Oct, 2019).
________________________________________
•	NIST SP 800-30, Rev. 1, Guide for Conducting Risk Assessments by Joint Task Force Transformation Initiative. (Sep, 2012).
________________________________________
•	NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems by Marianne Swanson, Pauline Bowen, Amy Wohl Phillips, Dean Gallup, David Lynes. (May, 2010).
________________________________________
•	NIST SP 800-37, Rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy by Joint Task Force Transformation Initiative. (Dec, 2018).
________________________________________
•	NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and Information System View by Joint Task Force Transformation Initiative. (Mar, 2011).
________________________________________
•	NIST SP 800-53, Rev. 5, Security and Privacy Controls for Information Systems and Organizations by Joint Task Force Transformation Initiative. (Sep, 2020).
________________________________________
•	NIST SP 800-55, Rev. 1, Performance Measurement Guide for Information Security by Elizabeth Chew, Marianne Swanson, Kevin Stine, Nadya Bartol, Anthony Brown, Will Robinson. (Jul, 2008).
________________________________________
•	NIST SP 800-61, Rev. 2, Computer Security Incident Handling Guide by Paul Cichonski, Tom Millar, Tim Grance, Karen Scarfone. (Aug, 2012).
________________________________________
•	NIST SP 800-128, Guide for Security-Focused Configuration Management of Information Systems by Arnold Johnson, Kelley Dempsey, Ron Ross, Sarbari Gupta, Dennis Bailey. (Aug, 2011).
________________________________________
•	NIST SP 800-160, Vol. 1, Systems Security Engineering: Considerations for a Multidisciplinary Approach in the Engineering of Trustworthy Secure Systems by Ron Ross, Michael McEvilley, Janet Carrier Oren. (Mar, 2018).
________________________________________
•	Official (ISC)² Guide to the ISSMP CBK by Joseph Steinberg and Harold F. Tipton. Publisher: Auerbach Publications. (Apr, 2016).
________________________________________
•	Security Operations Center: Building, Operating, and Maintaining your SOC by Gary McIntyre, Joseph Muniz, Nadhem AlFardan. Publisher: Cisco Press. (Nov, 2015).
________________________________________
•	The Disaster Recovery Handbook, 3rd Ed. by Michael Wallace, Lawrence Webber. Publisher: AMACOM. (Dec, 2017).
________________________________________
•	Threat Modeling: Designing for Security, 1st Ed. by Adam Shostack. Publisher: Wiley. (Feb, 2014).
 
nline Training
Official ISC2 Certified in Cybersecurity (CC) eTextbook 
eTextbook Description
< Return to Listing
 
The Official ISC2 Certified in Cybersecurity (CC) eTextbook is your go-to learning resource as you prepare for the CC exam. It provides a comprehensive review of the topics covered in the Official ISC2 Training Course and will help you navigate key cybersecurity concepts as you build confidence for exam day. 
Price: $24.95
Language:
English
Japanese
Who Should Purchase:
IT professionals, career-changers, college students, recent graduates and executives seeking foundational knowledge in cybersecurity. ISC2 is offering free Certified in Cybersecurity (CC) Online Self-Paced Training and an exam to 1 million people as part of our pledge to help close the cybersecurity workforce gap and diversify those working in the field. To meet every learner’s needs, we’re also offering two CC Training Bundles with special extras. Learn more.
What to Expect:
A comprehensive review of the Official ISC2 Training Course content related to the ISC2 Certified in Cybersecurity exam. Learning supports include:
•  Chapter overviews, objectives and summaries 
•  Informative graphics 
•  Key terms and definitions 
•  Chapter quizzes and answer keys 
CPE Credits
None
Access Period:
365 days from inital access
This eTextbook covers the following:
Chapter 1: Security Principles
•	• 1: Understand the Security Concepts of Information Assurance
•	• 2: Understand the Risk Management Process
•	• 3: Understand Security Controls
•	• 4: Understand Governance Elements and Processes
•	• 5: Understand ISC2 Code of Ethics 
Chapter 2: Incident Response, Business Continuity and Disaster Recovery Concepts
•	• 1: Understand Incident Response
•	• 2: Understand Business Continuity 
•	• 3: Understand Disaster Recovery
Chapter 3: Access Controls Concepts
•	• 1: Understand Access Control Concepts
•	• 2: Understand Physical Access Controls
•	• 3: Understand Logical Access Controls
Chapter 4: Network Security
•	• 1: Understand Computer Networking
•	• 2: Understand Network (Cyber) Threats and Attacks
•	• 3: Understand Network Security Infrastructure
Chapter 5: Security Operations
•	• 1: Understand Data Security
•	• 2: Understand System Hardening
•	• 3: Understand Best Practice Security Policies
•	• 4: Understand Security Awareness Training
Technology Requirements:
The CC eTextbook uses VitalSource eReader, which will allow you to view materials on multiple devices and platforms, online and offline.
The following may be among system requirements to access your eTextbook. 
•	A stable and continuous internet connection.
Hardware Specifications
•	• Processor 2 GHz +
•	• RAM 4 GB +
•	• Monitor minimum resolution (1024 x 768)
•	• Video Card
•	• Keyboard and Mouse or other assistive technology
Supported Operating Systems
•	• Macintosh OS X 10.10 to present
•	• Windows 10 to present
Supported Browsers
•	• Google Chrome
•	• Microsoft Edge
•	• Mozilla Firefox
Application Software
•	VitalSource eReader
•	Certification Exam Outline 
•	Effective Date: November 15, 20222 
•	ISSMP Certification Exam Outline 
•	About CISSP-ISSMP 
•	The Information Systems Security Management Professional (ISSMP) is a CISSP who specializes in establishing, 
•	presenting and governing information security programs and demonstrates management and leadership 
•	skills. CISSP-ISSMPs direct the alignment of security programs with the organization’s mission, goals and 
•	strategies in order to meet enterprise financial and operational requirements in support of its desired risk 
•	position. 
•	The broad spectrum of topics included in the CISSP-ISSMP Common Body of Knowledge (CBK®) ensure its 
•	relevancy across all disciplines in the field of information security management. Successful candidates are 
•	competent in the following six domains: 
•	• Leadership and Business Management 
•	• Systems Lifecycle Management 
•	• Risk Management 
•	• Threat Intelligence and Incident Management 
•	• Contingency Management 
•	• Law, Ethics and Security Compliance Management 
•	Experience Requirements 
•	Candidates must be a CISSP in good standing and have two years cumulative paid work experience 
•	in one or more of the six domains of the CISSP-ISSMP CBK. You can learn more about CISSP-ISSMP 
•	experience requirements and how to account for part-time work and internships at 
•	www.isc2.org/Certifications/CISSP-Concentrations#steps-to-certification. 
•	Accreditation 
•	CISSP-ISSMP is in compliance with the stringent requirements of ANSI/ISO/IEC Standard 17024. 
•	Job Task Analysis (JTA) 
•	(ISC)² has an obligation to its membership to maintain the relevancy of the CISSP-ISSMP. Conducted at 
•	regular intervals, the Job Task Analysis (JTA) is a methodical and critical process of determining the tasks that 
•	are performed by security professionals who are engaged in the profession defined by the CISSP-ISSMP. The 
•	results of the JTA are used to update the examination. This process ensures that candidates are tested on the 
•	topic areas relevant to the roles and responsibilities of today’s practicing information security professionals.3 
•	ISSMP Certification Exam Outline 
•	CISSP-ISSMP Examination Information 
•	CISSP-ISSMP Examination Weights 
•	Length of exam 
•	Number of items 
•	Item format 
•	Passing grade 
•	Exam availability 
•	Testing center 
•	3 hours 
•	125 
•	Multiple choice 
•	700 out of 1000 points 
•	English 
•	Pearson VUE Testing Center 
•	Domains 
•	Weight 
•	1. Leadership and Business Management 
•	20% 
•	2. Systems Lifecycle Management 
•	18% 
•	3. Risk Management 
•	19% 
•	4. Threat Intelligence and Incident Management 
•	17% 
•	5. Contingency Management 
•	15% 
•	6. Law, Ethics and Security Compliance Management 
•	11% 
•	Total: 100%4 
•	ISSMP Certification Exam Outline 
•	Domain 1: 
•	Leadership and Business Management 
•	1.1 Establish security’s role in organizational culture, vision and mission 
•	» Define information security program vision and mission 
•	» Align security with organizational goals, objectives and values 
•	» Define security’s relationship to the overall business processes 
•	» Define the relationship between organizational culture and security 
•	1.2 Align security program with organizational governance 
•	» Identify and navigate organizational governance structure 
•	» Validate roles of key stakeholders 
•	» Validate sources and boundaries of authorization 
•	» Advocate and obtain organizational support for security initiatives 
•	1.3 Define and implement information security strategies 
•	» Identify security requirements from business initiatives 
•	» Evaluate capacity and capability to implement security strategies 
•	» Manage implementation of security strategies 
•	» Review and maintain security strategies 
•	» Prescribe security architecture and engineering theories, concepts and methods 
•	1.4 Define and maintain security policy framework Determine applicable external standards 
•	» Determine applicable external standards 
•	» Determine data classification and protection requirements 
•	» Establish internal policies 
•	» Advocate and obtain organizational support for policies 
•	» Develop procedures, standards, guidelines and baselines 
•	» Ensure periodic review of security policy framework5 
•	ISSMP Certification Exam Outline 
•	» Define roles and responsibilities 
•	» Determine and manage team accountability 
•	» Build cross-functional relationships 
•	» Resolve conflicts between security and 
•	other stakeholders 
•	» Identify communication bottlenecks 
•	and barriers 
•	» Integrate security controls into human 
•	resources processes 
•	» Evaluate service management agreements 
•	(e.g., risk, financial) 
•	» Govern managed services 
•	(e.g., infrastructure, cloud services) 
•	» Manage impact of organizational change (e.g., 
•	mergers and acquisitions, outsourcing) 
•	» Ensure that appropriate regulatory compliance 
•	statements and requirements are included in 
•	contractual agreements 
•	» Monitor and enforce compliance with 
•	contractual agreements 
•	1.5 Manage security requirements in contracts and agreements 
•	1.6 Manage security awareness and training programs 
•	» Promote security programs to key stakeholders 
•	» Identify needs and implement training programs by target segment 
•	» Monitor and report on effectiveness of security awareness and training programs 
•	1.7 Define, measure and report security metrics 
•	» Identify Key Performance Indicators (KPI) 
•	» Associate Key Performance Indicators (KPI) to the risk posture of the organization 
•	» Use metrics to drive security program development and operations 
•	1.8 Prepare, obtain and administer security budget 
•	» Prepare and secure annual budget 
•	» Adjust budget based on evolving risks and threat landscape 
•	» Manage and report financial responsibilities 
•	1.9 Manage security programs 
•	1.10 Apply product development and project management principles 
•	» Incorporate security into project lifecycle 
•	» Identify and apply appropriate project management methodology 
•	» Analyze project time, scope and cost relationship6 
•	ISSMP Certification Exam Outline 
•	2.1 Manage integration of security into Systems Development Life Cycle (SDLC) 
•	» Integrate information security gates (decision points) and requirements into lifecycle 
•	» Implement security controls into system lifecycle 
•	» Oversee security configuration management (CM) processes 
•	2.2 Integrate new business initiatives and emerging technologies into the 
•	security architecture 
•	» Integrate security into new business initiatives and emerging technologies 
•	» Address impact of new business initiatives on security posture 
•	2.3 Define and oversee comprehensive vulnerability management programs 
•	(e.g., vulnerability scanning, penetration testing, threat analysis) 
•	» Identify, classify and prioritize assets, systems and services based on criticality to business 
•	» Prioritize threats and vulnerabilities 
•	» Manage security testing 
•	» Manage mitigation and/or remediation of vulnerabilities based on risk 
•	2.4 Manage security aspects of change control 
•	» Integrate security requirements with change control process 
•	» Identify and coordinate with the stakeholders 
•	» Manage documentation and tracking 
•	» Ensure policy compliance (e.g., continuous monitoring) 
•	Domain 2: 
•	Systems Lifecycle Management 7 
•	ISSMP Certification Exam Outline 
•	Domain 3: 
•	Risk Management 
•	3.1 Develop and manage a risk management program 
•	» Identify risk management program objectives 
•	» Communicate and agree on risk management objectives with risk owners and other stakeholders 
•	» Determine scope of organizational risk program 
•	» Identify organizational security risk tolerance/appetite 
•	» Obtain and verify organizational asset inventory 
•	» Analyze organizational risks 
•	» Determine countermeasures, compensating and mitigating controls 
•	» Perform cost-benefit analysis (CBA) of risk treatment options 
•	3.2 Conduct risk assessments 
•	» Identify risk factors 
•	3.3 Manage security risks within the supply chain (e.g., supplier, vendor, third-party risk) 
•	» Identify supply chain security risk requirements 
•	» Integrate supply chain security risks into organizational risk management 
•	» Validate security risk control within the supply chain 
•	» Monitor and review the supply chain security risks8 
•	ISSMP Certification Exam Outline 
•	4.1 Establish and maintain threat intelligence program 
•	» Aggregate threat data from multiple threat intelligence sources 
•	» Conduct baseline analysis of network traffic, data and user behavior 
•	» Detect and analyze anomalous behavior patterns for potential concerns 
•	» Conduct threat modeling 
•	» Identify and categorize an attack 
•	» Correlate related security event and threat data 
•	» Create actionable alerting to appropriate resources 
•	4.2 Establish and maintain incident handling and investigation program 
•	» Develop program documentation 
•	» Establish incident response case management process 
•	» Establish incident response team 
•	» Apply incident management methodologies 
•	» Establish and maintain incident handling process 
•	» Establish and maintain investigation process 
•	» Quantify and report financial and operational impact of incidents and investigations to stakeholders 
•	» Conduct root cause analysis (RCA) 
•	Domain 4: 
•	Threat Intelligence and Incident 
•	Management 9 
•	ISSMP Certification Exam Outline 
•	5.1 Facilitate development of contingency plans 
•	» Identify and analyze factors related to the Continuity of Operations Plan (COOP) 
•	» Identify and analyze factors related to the business continuity plan (BCP) (e.g., time, resources, verification) 
•	» Identify and analyze factors related to the disaster recovery plan (DRP) (e.g., time, resources, verification) 
•	» Coordinate contingency management plans with key stakeholders 
•	» Define internal and external crisis communications plans 
•	» Define and communicate contingency roles and responsibilities 
•	» Identify and analyze contingency impact on business processes and priorities 
•	» Manage third-party contingency dependencies 
•	» Prepare security management succession plan 
•	5.2 Develop recovery strategies 
•	» Identify and analyze alternatives 
•	» Recommend and coordinate recovery strategies 
•	» Assign recovery roles and responsibilities 
•	5.3 Maintain contingency plan, Continuity of Operations Plan (COOP), business continuity 
•	plan (BCP) and disaster recovery plan (DRP) 
•	» Plan testing, evaluation and modification 
•	» Determine survivability and resiliency capabilities 
•	» Manage plan update process 
•	5.4 Manage disaster response and recovery process 
•	» Declare disaster 
•	» Implement plan 
•	» Restore normal operations 
•	» Gather lessons learned 
•	» Update plan based on lessons learned 
•	Domain 5: 
•	Contingency Management 10 
•	ISSMP Certification Exam Outline 
•	10 
•	6.1 Identify the impact of laws and regulations that relate to information security 
•	6.2 Adhere to the (ISC)
•	2 
•	Code of Ethics as related to management issues 
•	6.3 Validate compliance in accordance with applicable laws, regulations and industry 
•	best practices 
•	6.4 Coordinate with auditors and regulators in support of the internal and external 
•	audit processes 
•	6.5 Document and manage compliance exceptions 
•	» Identify and document compensating controls and workarounds 
•	» Report and obtain authorized approval of risk waiver 
•	Domain 6: 
•	Law, Ethics and Security Compliance 
•	Management 
•	» Identify applicable privacy laws 
•	» Identify legal jurisdictions the organization and 
•	users operate within (e.g., trans-border data flow) 
•	» Identify export laws 
•	» Identify intellectual property (IP) laws 
•	» Identify applicable industry regulations 
•	» Identify and advise on non-compliance risks 
•	» Inform and advise senior management 
•	» Evaluate and select compliance framework(s) 
•	» Implement the compliance framework(s) 
•	» Define and monitor compliance metrics 
•	» Plan 
•	» Schedule 
•	» Coordinate audit activities 
•	» Evaluate and validate findings 
•	» Formulate response 
•	» Validate implemented mitigation and 
•	remediation actions11 
•	ISSMP Certification Exam Outline 
•	Additional Examination Information 
•	Supplementary References 
•	Candidates are encouraged to supplement their education and experience by reviewing 
•	relevant resources that pertain to the CBK and identifying areas of study that may need 
•	additional attention. 
•	View the full list of supplementary references at www.isc2.org/certifications/References. 
•	Examination Policies and Procedures 
•	(ISC)2 recommends that CISSP-ISSMP candidates review exam policies and procedures 
•	prior to registering for the examination. Read the comprehensive breakdown of this 
•	important information at www.isc2.org/Exams/Before-Your-Exam. 
•	Legal Info 
•	For any questions related to (ISC)
•	2 
•	’s legal policies, please contact the (ISC)2 Legal 
•	Department at legal@isc2.org. 
•	Any Questions? 
•	(ISC)2 Americas 
•	Tel: +1.866.331.ISC2 (4722) 
•	Email: info@isc2.org 
•	(ISC)2 Asia-Pacific 
•	Tel: +(852) 28506951 
•	Email: isc2asia@isc2.org 
•	(ISC)2 EMEA 
•	Tel: +44 (0)203 300 1625 
•	Email: info-emea@isc2.org 
•	11 
v222Register for exam
 
Effective Date: August 29, 2022
Certified in Cybersecurity Certification Exam Outline
View and download the latest PDF version of the Certified in Cybersecurity Exam Outline in the following languages:
CC - English  |  CC - Chinese  |  CC - Japanese  |  CC - German  |  CC - Spanish 
About Certified in Cybersecurity
ISC2 developed the Certified in Cybersecurity (CC) credential for newcomers to the field, to recognize the growing trend of people entering the cybersecurity workforce without direct IT experience. Getting Certified in Cybersecurity provides employers with the confidence that you have a solid grasp of the right technical concepts, and a demonstrated aptitude to learn on the job. As an ISC2 certification, those who hold the CC are backed by the world’s largest network of certified cybersecurity professionals helping them continue their professional development and earn new achievements and qualifications throughout their career.
The topics on the CC exam include:
•	Security Principles
•	Incident Response, Business Continuity (BC) and Disaster Recovery (DR) Concepts
•	Access Controls Concepts
•	Network Security
•	Security Operations
Certified in Cybersecurity Examination Information
Length of exam	2 hours
Number of items	100
Item format	Multiple choice
Passing grade	700 out of 1000 points
Exam language availability	English, Chinese, Japanese, German, Spanish
Testing center	Pearson VUE Testing Center

Certified in Cybersecurity Examination Weights
Domains	Average Weight
1. Security Principles	26%
2. Business Continuity (BC), Disaster Recovery (DR) & Incident Response Concepts	10%
3. Access Controls Concepts	22%
4. Network Security	24%
5. Security Operations	18%
Total	100%

Boost your chances of passing the exam with the CC eTextbook
Build your fundamental cybersecurity knowledge and prepare for the exam.
Get eTextbook

Domains
1.1 - Understand the security concepts of information assurance
•	Confidentiality
•	Integrity
•	Availability
•	Authentication (e.g., methods of authentication, multi-factor authentication (MFA))
•	Non-repudiation
•	Privacy
1.2 - Understand the risk management process
•	Risk management (e.g., risk priorities, risk tolerance)
•	Risk identification, assessment and treatment
1.3 - Understand security controls
•	Technical controls
•	Administrative controls
•	Physical controls
1.4 - Understand ISC2 Code of Ethics
•	Professional code of conduct
1.5 - Understand governance processes
•	Policies
•	Procedures
•	Standards
•	Regulations and laws
2.1 - Understand business continuity (BC)
•	Purpose
•	Importance
•	Components
2.2 - Understand disaster recovery (DR)
•	Purpose
•	Importance
•	Components
2.3 - Understand incident response
•	Purpose
•	Importance
•	Components
3.1 - Understand physical access controls
•	Physical security controls (e.g., badge systems, gate entry, environmental design)
•	Monitoring (e.g., security guards, closed-circuit television (CCTV), alarm systems, logs)
•	Authorized versus unauthorized personnel
3.2 - Understand logical access controls
•	Principle of least privilege 
•	Segregation of duties
•	Discretionary access control (DAC)
•	Mandatory access control (MAC)
•	Role-based access control (RBAC)
4.1 - Understand computer networking 
•	Networks (e.g., Open Systems Interconnection (OSI) model, Transmission Control Protocol/Internet Protocol (TCP/IP) model, Internet Protocol version 4 (IPv4), Internet Protocol version 6 (IPv6), WiFi)
•	Ports
•	Applications
4.2 - Understand network threats and attacks
•	Types of threats (e.g., distributed denial-of-service (DDoS), virus, worm, Trojan, man-in-the-middle (MITM), side-channel)
•	Identification (e.g., intrusion detection system (IDS), host-based intrusion detection system (HIDS), network intrusion detection system (NIDS))
•	Prevention (e.g., antivirus, scans, firewalls, intrusion prevention system (IPS))
4.3 - Understand network security infrastructure
•	On-premises (e.g., power, data center/closets, Heating, Ventilation, and Air Conditioning (HVAC), environmental, fire suppression, redundancy, memorandum of understanding (MOU)/memorandum of agreement (MOA))
•	Design (e.g., network segmentation (demilitarized zone (DMZ), virtual local area network (VLAN), virtual private network (VPN), micro-segmentation), defense in depth, Network Access Control (NAC) (segmentation for embedded systems, Internet of Things (IoT))
•	Cloud (e.g., service-level agreement (SLA), managed service provider (MSP), Software as a Service (SaaS), Infrastructure as a Service (IaaS), Platform as a Service (PaaS), hybrid)
5.1 - Understand data security
•	Encryption (e.g., symmetric, asymmetric, hashing)
•	Data handling (e.g., destruction, retention, classification, labeling)
•	Logging and monitoring security events
5.2 - Understand system hardening
•	Configuration management (e.g., baselines, updates, patches)
5.3 - Understand best practice security policies
•	Data handling policy 
•	Password policy
•	Acceptable Use Policy (AUP)
•	Bring your own device (BYOD) policy
•	Change management policy (e.g., documentation, approval, rollback)
•	Privacy policy
5.4 - Understand security awareness training
•	Purpose/concepts (e.g., social engineering, password protection)
•	Importance
 
A safe and secure cyber world
The Center for Cyber Safety & EducationISC2 CareersCommunityBlog
Frequently Asked QuestionsContact UsPolicies and Procedures
ISC2 Authorized China AgencyISC2 Japan
© Copyright 1996-2025. ISC2, Inc. All Rights Reserved.

All contents of this site constitute the property of ISC2, Inc. and may not be copied, reproduced or distributed without prior written permission. ISC2, CISSP, SSCP, CCSP, CGRC, CSSLP, HCISPP, ISSAP, ISSEP, ISSMP, CC, and CBK are registered marks of ISC2, Inc.

Sitemap
     
Certified in Cybersecurity Exam Outline
Access Period:
365 days from inital access
This eTextbook covers the following:
Chapter 1: Security Principles
•	• 1: Understand the Security Concepts of Information Assurance
•	• 2: Understand the Risk Management Process
•	• 3: Understand Security Controls
•	• 4: Understand Governance Elements and Processes
•	• 5: Understand ISC2 Code of Ethics 
Chapter 2: Incident Response, Business Continuity and Disaster Recovery Concepts
•	• 1: Understand Incident Response
•	• 2: Understand Business Continuity 
•	• 3: Understand Disaster Recovery
Chapter 3: Access Controls Concepts
•	• 1: Understand Access Control Concepts
•	• 2: Understand Physical Access Controls
•	• 3: Understand Logical Access Controls
Chapter 4: Network Security
•	• 1: Understand Computer Networking
•	• 2: Understand Network (Cyber) Threats and Attacks
•	• 3: Understand Network Security Infrastructure
Chapter 5: Security Operations
•	• 1: Understand Data Security
•	• 2: Understand System Hardening
•	• 3: Understand Best Practice Security Policies
•	• 4: Understand Security Awareness Training
Technology Requirements:
The CC eTextbook uses VitalSource eReader, which will allow you to view materials on multiple devices and platforms, online and offline.
The following may be among system requirements to access your eTextbook. 
•	A stable and continuous internet connection.
Hardware Specifications
•	• Processor 2 GHz +
•	• RAM 4 GB +
•	• Monitor minimum resolution (1024 x 768)
•	• Video Card
•	• Keyboard and Mouse or other assistive technology
Supported Operating Systems
•	• Macintosh OS X 10.10 to present
•	• Windows 10 to present
Supported Browsers
•	• Google Chrome
•	• Microsoft Edge
•	• Mozilla Firefox
Application Software
•	VitalSource eReader
Online Training
Continuing education
Stay relevant and on top of the latest trends. Leverage our online courses to gain interactive, engaging and timely learning experiences throughout your career. Each course is designed with input from leading industry experts and based on proven learning techniques to maximize your time and content retention.
The self-paced learning format delivers modular content combined with interactive activities involving videos, labs, case studies, quizzes, etc. Learn at your own pace on your own time and earn valuable Continuing Professionals Education (CPE) credits towards your ISC2; certifications. (Note: Credits may be eligible for continuing education credits for non-ISC2 certifications. Please review the requirements established by the credentialing organization for eligibility.)
ISC2; Members and Associates have free unlimited access to courses that are denoted as ‘Free for Members’ by logging in above and clicking the ‘My Courses’ menu item.
For individual course purchases learners will have access to the course content for 180 days from the time of purchase. Please note, we do not offer time extensions for you to complete this training course.
For All Access and Express Learning Bundle purchases learners will have access to the course content for 365 day from the time of purchase. Please see course description for pricing and CPEs.
1 2 3 > >| 
 	Certification	
	Defining the Boundaries of Zero Trust 
This learning experience invites you to review the set of guiding principles for workflow, system design, and operations that create a zero trust architecture. (2.0 CPE) 	



	Software Inventory and SBOM 
This course invites you to expand your knowledge of how Software Bill of Materials (SBOM) can help cybersecurity professionals effectively mitigate vulnerabilities and ensure compliance. 	



	Software Inventory and SBOM 
This course invites you to expand your knowledge of how Software Bill of Materials (SBOM) can help cybersecurity professionals effectively mitigate vulnerabilities and ensure compliance. 	



	Working in the Cloud 
This course invites you to learn about the range of challenges security professionals face as they work to utilize, optimize and secure critical assets in the cloud. 	



	Working in the Cloud 
This course invites you to learn about the range of challenges security professionals face as they work to utilize, optimize and secure critical assets in the cloud. 	



	Moving to the Cloud 
This course invites you to learn about the strategic and security considerations necessary to transition an organization to cloud computing in alignment with business needs. 	



	Moving to the Cloud 
This course invites you to learn about the strategic and security considerations necessary to transition an organization to cloud computing in alignment with business needs. 	



	Cloud Basics 
This course invites you to learn about essential cloud concepts and principles, including key drivers for use, essential characteristics, and service and deployment models within cloud architectures. 	



	Cloud Basics 
This course invites you to learn about essential cloud concepts and principles, including key drivers for use, essential characteristics, and service and deployment models within cloud architectures. 	



	Building Your Personal Brand and Digital Presence 
This course invites you to review the essentials of building a personal brand and digital presence that reflects your core values, unique strengths and professional aspirations. 	



	Resume/CV/Portfolio Building and Management 
This course invites you to review the critical components of documents such as resumes, CVs and portfolios that showcase your unique strengths and value to potential employers. 	



	Identifying and Building Your Network 
This course invites you to review the critical role networking plays in professional development by unlocking new opportunities, facilitating knowledge sharing and supporting long-term career success. 	



	Identifying Your Cyber Path and Industry 
This course invites you to explore a wide range of opportunities in cybersecurity and plan a skill development path toward a successful career. 	



	Nailing the Interview Process 
This course invites you to review actionable strategies and skills to excel in any interview scenario and stand out from the competition. 	



	Managing the Offer and Negotiation Process 
This course invites you to review the essential knowledge and skills to navigate job offers, negotiate confidently and transition smoothly into new roles. 	



	Managing the Offer and Negotiation Process 
This course invites you to review the essential knowledge and skills to navigate job offers, negotiate confidently and transition smoothly into new roles. 	



	Nailing the Interview Process 
This course invites you to review actionable strategies and skills to excel in any interview scenario and stand out from the competition. 	



	Identifying Your Cyber Path and Industry 
This course invites you to explore a wide range of opportunities in cybersecurity and plan a skill development path toward a successful career. 	



	Identifying and Building Your Network 
This course invites you to review the critical role networking plays in professional development by unlocking new opportunities, facilitating knowledge sharing and supporting long-term career success. 	



	Resume/CV/Portfolio Building and Management 
This course invites you to review the critical components of documents such as resumes, CVs and portfolios that showcase your unique strengths and value to potential employers. 	



1 2 3 > >| 
Go to the main content 
Privacy and Cookies This website stores cookies on your computer which help us make the website work better for you.
 
Collapsed, toggle side navigation to expand 
Edit my profile  Tshingombe Tshingombe Tshitadi  
ISC2 ID: 1907033 
•	Dashboard 
•	My Profile 
•	
•	
•	Sign out 
Find an exam
Find an Exam:  


CC	Certified in Cybersecurity (CC)

CCSP	Certified Cloud Security Professional (CCSP)

CGRC	Certified in Governance Risk and Compliance

CISSP	Certified Information Systems Security Professional

CSSLP	Certified Secure Software Lifecycle Professional

ISSAP	Information Systems Security Architecture Professional

ISSEP	Information Systems Security Engineering Professional

ISSMP	Information Systems Security Management Professional

SSCP	Systems Security Certified Practitioner

•	Terms
•	Privacy
•	Contact

Copyright 1996-2025 Pearson Education Inc. or its affiliate(s). All rights reserved. 
 

•	








Certification is Just the Beginning

Achieving your certification isn’t the end of your journey. ISC2 members and associates are part of a global community of cybersecurity professionals with access to a long list of benefits that include continuing professional education, peer-to-peer networking and exclusive discounts. 
 
Stay focused on your goal and make the most of what’s ahead. 
Preview Your Benefits



________________________________________









            
ISC2 625 N Washington Street, Suite 400, Alexandria, VA 22314, United States • www.isc2.org 
© 1996–2024. ISC2, Inc. All rights reserved. 

You're receiving this email because you've expressed interest in Certifications, Education Resources and Offers. Click to unsubscribe, or update your subscription preferences on the Member Website. 










 	




























Register for exam
 
Effective Date: September 2024
SSCP Certification Exam Outline
View and download the latest PDF version of the SSCP Certification Exam Outline in the following languages:
SSCP - English  |  SSCP - Japanese  |  SSCP - Spanish
About SSCP
The Systems Security Certified Practitioner (SSCP) is the ideal certification for those with proven technical skills and practical, hands-on security knowledge in operational IT roles. It provides confirmation of a practitioner’s ability to implement, monitor and administer IT infrastructure in accordance with information security policies and procedures that ensure data confidentiality, integrity and availability.
The broad spectrum of topics included in the SSCP Common Body of Knowledge (CBK) ensure its relevancy across all disciplines in the field of information security. Successful candidates are competent in the following domains:
•	Security Concepts and Practices
•	Access Controls
•	Risk Identification, Monitoring, and Analysis
•	Incident Response and Recovery
•	Cryptography
•	Network and Communications Security
•	Systems and Application Security
Experience Requirements
Candidates must have a minimum of one year cumulative work experience in one or more of the domains of the SSCP CBK. A one year prerequisite pathway will be granted for candidates who received a degree (bachelors or masters) in a cybersecurity program.
A candidate that doesn’t have the required experience to become an SSCP may become an Associate of ISC2 by successfully passing the SSCP examination. The Associate of ISC2 will then have two years to earn the one year required experience. You can learn more about SSCP experience requirements and how to account for part-time work and internships at www.isc2.org/Certifications/SSCP/SSCP-Experience-Requirements.
Accreditation
SSCP is in compliance with the stringent requirements of ANSI/ISO/IEC Standard 17024.
Job Task Analysis (JTA)
ISC2 has an obligation to its membership to maintain the relevancy of the SSCP. Conducted at regular intervals, the Job Task Analysis (JTA) is a methodical and critical process of determining the tasks that are performed by security professionals who are engaged in the profession defined by the SSCP. The results of the JTA are used to update the examination. This process ensures that candidates are tested on the topic areas relevant to the roles and responsibilities of today’s practicing information security professionals.
SSCP Examination Information
Length of exam	3 hours
Number of items	125
Item format	Multiple choice
Passing grade	700 out of 1000 points
Language availability	English, Japanese and Spanish
Testing center	Pearson VUE Testing Center

SSCP Examination Weights
Domains	Average Weight
1. Security Concepts and Practices	16%
2. Access Controls	15%
3. Risk Identification, Monitoring and Analysis	15%
4. Incident Response and Recovery	14%
5. Cryptography	9%
6. Network and Communications Security	16%
7. Systems and Application Security	15%
Total	100%
Domains
1.1 - Comply with codes of ethics
•	ISC2 Code of Ethics
•	Organizational code of ethics
1.2 - Understand security concepts
•	Confidentiality
•	Integrity
•	Availability
•	Accountability
•	Non-repudiation
•	Least privilege
•	Segregation of duties (SoD)
1.3 - Identify and implement security controls
•	Technical controls (e.g., firewalls, intrusion detection systems (IDS), access control list (ACL)
•	Physical controls (e.g., mantraps, cameras, locks)
•	Administrative controls (e.g., security policies, standards, procedures, baselines)
•	Assessing compliance requirements
•	Periodic audit and review
1.4 - Document and maintain functional security controls
•	Deterrent controls
•	Preventative controls
•	Detective controls
•	Corrective controls
•	Compensating controls
1.5 - Support and implement asset management lifecycle (i.e., hardware, software, and data)
•	Process, planning, design and initiation
•	Development /Acquisition (e.g., DevSecOps, testing)
•	Inventory and licensing (e.g., open source, closed-source)
•	Implementation/Assessment
•	Operation/Maintenance/End of Life (EOL)
•	Archival and retention requirements
•	Disposal and destruction
1.6 - Support and/or implement change management lifecycle
•	Change management (e.g., roles, responsibilities, processes, communications, audit)
•	Security impact analysis
•	Configuration management (CM)
1.7 - Support and/or implement security awareness and training (e.g., social engineering/phishing/tabletop exercises/awareness communications)
1.8 - Collaborate with physical security operations (e.g., data center/facility assessment, badging and visitor management, personal device restrictions)
2.1 - Implement and maintain authentication methods
•	Single/Multi-factor authentication (MFA)
•	Single sign-on (SSO) (e.g., Active Directory Federation Services (ADFS), OpenID Connect)
•	Device authentication (e.g., certificate, Media Access Control (MAC) address, Trusted Platform Module (TPM))
•	Federated access (e.g., Open Authorization 2 (OAuth2), Security Assertion Markup Language (SAML))
2.2 - Understand and support internetwork trust architectures
•	Trust relationships (e.g., 1-way, 2-way, transitive, zero)
•	Internet, intranet, extranet, and demilitarized zone (DMZ)
•	Third-party connections (e.g., application programming interface (API), app extensions, middleware)
2.3 - Support and/or implement the identity management lifecycle
•	Authorization
•	Proofing
•	Provisioning/De-provisioning
•	Monitoring, Reporting, and Maintenance (e.g., role changes, new security standards)
•	Entitlement (e.g., inherited rights, resources)
•	Identity and access management (IAM) systems
2.4 - Understand and administer access controls
•	Mandatory
•	Discretionary
•	Role-based (e.g., subject-based, object-based, Privileged Access Management (PAM))
•	Rule-based
•	Attribute-based
3.1 - Understand risk management
•	Risk visibility and reporting (e.g., risk register, sharing threat intelligence, indicators of Compromise (IOC), Common Vulnerability Scoring System (CVSS), socialization, MITRE/ATT&CK model)
•	Risk management concepts (e.g., impact assessments, threat modeling, scope)
•	Risk management frameworks
•	Risk tolerance (e.g., appetite, risk quantification)
•	Risk treatment (e.g., accept, transfer, mitigate, avoid)
3.2 - Understand legal and regulatory concerns (e.g., jurisdiction, limitations, privacy)
3.3 - Perform security assessments and vulnerability management activities
•	Risk management frameworks implementation
•	Security testing
•	Risk review (e.g., internal, supplier, architecture)
•	Vulnerability management lifecycle (e.g., scanning, reporting, analysis, remediation)
3.4 - Operate and monitor security platforms (e.g., continuous monitoring)
•	Source systems (e.g., applications, security appliances, network devices, hosts)
•	Events of interest (e.g., errors, omissions, anomalies, unauthorized changes, compliance violations, policy failures)
•	Log management (e.g., policy, integrity, preservation, architectures, configuration, aggregation, tuning)
•	Security information and event management (SIEM) (e.g., real-time monitoring, analysis, tracking, audit)
3.5 - Analyze monitoring results
•	Security baselines and anomalies (e.g., correlation, noise reduction)
•	Visualizations, metrics, and trends (e.g., notifications, dashboards, timelines)
•	Event data analysis
•	Document and communicate findings (e.g., escalation)
4.1 - Understand and support incident response lifecycle (e.g., National Institute of Standards and Technology (NIST), International Organization for Standardization (ISO))
•	Preparation (e.g., defining roles, training programs)
•	Detection, analysis, and escalation (e.g., incident communication, public relations)
•	Containment
•	Eradication
•	Recovery (e.g., incident documentation)
•	Post incident activities (e.g., lessons learned, new countermeasures, continuous improvement)
4.2 - Understand and support forensic investigations
•	Legal (e.g., civil, criminal, administrative) and ethical principles
•	Evidence handling (e.g., first responder, triage, chain of custody, preservation of scene)
•	Reporting of analysis
•	Organization Security Policy Compliance
4.3 - Understand and support business continuity plan (BCP) and disaster recovery plan (DRP)
•	Emergency response plans and procedures (e.g., information system contingency, pandemic, natural disaster, crisis management)
•	Interim or alternate processing strategies
•	Restoration planning (e.g., Restore Time Objective (RTO), Restore Point Objectives (RPO), Maximum Tolerable Downtime (MTD))
•	Backup and redundancy implementation
•	Testing and drills (e.g., playbook, tabletop, disaster recovery exercises, scheduling)
5.1 - Understand reasons and requirements for cryptography
•	Confidentiality
•	Integrity and authenticity
•	Data sensitivity (e.g., personally identifiable information (PII), intellectual property (IP), protected health information (PHI))
•	Regulatory and industry best practice (e.g., Payment Card Industry Data Security Standards (PCI-DSS), International Organization for Standardization (ISO))
•	Cryptography entropy (e.g., quantum cryptography, quantum key distribution)
5.2 - Apply cryptography concepts
•	Hashing
•	Salting
•	Symmetric/Asymmetric encryption/Elliptic curve cryptography (ECC)
•	Non-repudiation (e.g., digital signatures/certificates, Hash-based Message Authentication Code (HMAC), audit trails)
•	Strength of encryption algorithms and keys (e.g., Advanced Encryption Standards (AES), Rivest-Shamir-Adleman (RSA)
•	Cryptographic attacks and cryptanalysis
5.3 - Understand and implement secure protocols
•	Services and protocols
•	Common use cases (e.g., credit card processing, file transfer, web client, virtual private network (VPN), transmission of PII data)
•	Limitations and vulnerabilities
5.4 - Understand public key infrastructure (PKI)
•	Fundamental key management concepts (e.g., storage, rotation, composition, generation, destruction, exchange, revocation, escrow)
•	Web of Trust (WOT) (e.g., Pretty Good Privacy (PGP), GNU Privacy Guard (GPG), blockchain)
6.1 - Understand and apply fundamental concepts of networking
•	Open Systems Interconnection (OSI) and Transmission Control Protocol/Internet Protocol (TCP/IP) models
•	Network topologies 
•	Network relationships (e.g., peer-to-peer (P2P), client server)
•	Transmission media types (e.g., wired, wireless)
•	Software-defined networking (SDN) (e.g., Software-Defined Wide Area Network (SD-WAN), network virtualization, automation)
•	Commonly used ports and protocols
6.2 - Understand network attacks (e.g., distributed denial of service (DDoS), man-in-the-middle (MITM), Domain Name System (DNS) cache poisoning)
•	Countermeasures (e.g., content delivery networks (CDN), firewalls, network access controls, intrusion detection and prevention systems (IDPS))
6.3 - Manage network access controls
•	Network access controls, standards and protocols (e.g., Institute of Electrical and Electronics Engineers (IEEE) 802.1X, Remote Authentication Dial-In User Service (RADIUS), Terminal Access Controller Access-Control System Plus (TACACS+))
•	Remote access operation and configuration (e.g., thin client, virtual private network (VPN), virtual desktop infrastructure)
6.4 - Manage network security
•	Logical and physical placement of network devices (e.g., inline, passive, virtual)
•	Segmentation (e.g., physical/logical, data/control plane, virtual local area network (VLAN), access control list (ACL), firewall zones, micro-segmentation)
•	Secure device management
6.5 - Operate and configure network-based security appliances and services
•	Firewalls and proxies (e.g., filtering methods, web application firewall (WAF), cloud access security broker (CASB))
•	Network intrusion detection/prevention systems
•	Routers and switches
•	Traffic-shaping devices (e.g., wide area network (WAN) optimization, load balancing)
•	Network Access Control (NAC)
•	Data Loss Prevention (DLP)
•	Unified Threat Management (UTM)
6.6 - Secure wireless communications
•	Technologies (e.g., cellular network, Wi-Fi, Bluetooth, Near-Field Communication (NFC))
•	Authentication and encryption protocols (e.g., Wi-Fi Protected Access (WPA), Extensible Authentication Protocol (EAP), Wi-Fi Protected Access 2 (WPA2), Wi-Fi Protected Access 3 (WPA3))
6.7 Secure and monitor Internet of Things (IoT) (e.g., configuration, network isolation, firmware updates, End of Life (EOL) management)
7.1 - Identify and analyze malicious code and activity
•	Malware (e.g., rootkits, spyware, scareware, ransomware, trojans, virus, worms, trapdoors, backdoors, fileless, app/code/operatin3 system (OS)/mobile code vulnerabilities)
•	Malware countermeasures (e.g., scanners, anti-malware, containment and remediation, software security)
•	Types of malicious activity (e.g., insider threat, data theft, distributed denial of service (DDoS), botnet, zero-day exploits, web-based attacks, advanced persistent threat (APT))
•	Malicious activity countermeasures (e.g., user awareness/training, system hardening, patching, isolation, data loss prevention (DLP))
•	Social engineering methods (e.g., SPAM email, phishing/smishing/vishing, impersonation, scarcity, whaling)
•	Behavior analytics (e.g., machine learning, Artificial Intelligence (AI), data analytics) 
7.2 - Implement and operate endpoint device security
•	Host-based intrusion prevention system (HIPS)
•	Host-based intrusion detection system (HIDS)
•	Host-based firewalls
•	Application white listing
•	Endpoint encryption (e.g., full disk encryption)
•	Trusted Platform Module (TPM) (e.g., hardware security module management)
•	Secure browsing (e.g., digital certificates)
•	Endpoint detection and response (EDR)
7.3 - Administer and manage mobile devices
•	Provisioning techniques (e.g., corporate owned, personally enabled (COPE), Bring Your Own Device (BYOD), Mobile Device Management (MDM))
•	Containerization
•	Encryption
•	Mobile application management
7.4 - Understand and configure cloud security
•	Deployment models (e.g., public, private, hybrid, community)
•	Service models (e.g., Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS))
•	Virtualization (e.g., hypervisor, Virtual Private Cloud (VPC))
•	Legal and regulatory concerns (e.g., privacy, surveillance, data ownership, jurisdiction, eDiscovery, shadow information technology (IT))
•	Data storage, processing, and transmission (e.g., archiving, backup, recovery, resilience) 
•	Third-party/Outsourcing requirements (e.g., service-level agreement (SLA), data portability/ privacy/destruction/auditing) 
•	Shared responsibility model
7.5 - Operate and maintain secure virtual environments
•	Hypervisor (i.e., Type 1 (e.g., bare metal), Type 2 (e.g., software))
•	Virtual appliances
•	Containers
•	Continuity and resilience
•	Storage management (e.g., data domain)
•	Threats, attacks, and countermeasures (e.g., brute-force attack, virtual machine escape, threat hunting)
Additional Examination Information
Supplementary References
Candidates are encouraged to supplement their education and experience by reviewing relevant resources that pertain to the CBK and identifying areas of study that may need additional attention.
View the full list of supplementary references at www.isc2.org/certifications/References.
Examination Policies and Procedures
ISC2 recommends that SSCP candidates review exam policies and procedures prior to registering for the examination. Read the comprehensive breakdown of this important information at www.isc2.org/Register-for-Exam.
 
A safe and secure cyber world
The Center for Cyber Safety & EducationISC2 CareersCommunityBlog
Frequently Asked QuestionsContact UsPolicies and Procedures
ISC2 Authorized China AgencyISC2 Japan
© Copyright 1996-2025. ISC2, Inc. All Rights Reserved.

All contents of this site constitute the property of ISC2, Inc. and may not be copied, reproduced or distributed without prior written permission. ISC2, CISSP, SSCP, CCSP, CGRC, CSSLP, HCISPP, ISSAP, ISSEP, ISSMP, CC, and CBK are registered marks of ISC2, Inc.

Sitemap
     
SSCP Exam Outline
Agree to ISC2 policies 
back to previous step 
CC: Certified in Cybersecurity (CC) 
ISC2 policies 
Admission Policy 
Plan to arrive at your test center at least 30 minutes before your exam start time. To check in for your appointment the following is required:
•	Show two (2) valid, unexpired forms of personal ID (examples include: government issued ids, passports, etc.). Both must have your name (exactly as it appears in your exam registration) and signature, and one of the two must have your photo. For more information about acceptable IDs please visit: https://www.isc2.org/Exams/Exam-Day and look under What You Need to Bring to the Test Center tab for more information.
o	Unacceptable form of ID: Digital IDs (A digital ID is an electronic representation of personally identifying information that may be used to verify the identity of a person) 
For additional information regarding the Aadhaar ID, please visit Aadhaar ID Policy for Pearson VUE.
•	Minors under 18 – Minor must be accompanied by a parent or guardian on the day of exam. 
o	Please refer for ID requirements for minors, https://www.isc2.org/exams/exam-day 
•	Provide your signature.
•	Submit to a palm vein scan (unless expressly prohibited by law).
•	Have your photo taken. Hats, scarves, and coats may not be worn for your photo. Additionally, you may not wear these items in the test room.
•	Leave your personal belongings outside the testing room. You will have access to secure storage. As storage space is limited, please plan appropriately. Pearson VUE test centers do not assume responsibility for your personal belongings.
•	Receive a short orientation from the Test Administrator (TA). After the orientation, the TA will escort you to a testing station.
•	Sign and agree to the Non-Disclosure Agreement that will be presented at the beginning of your exam. Please take a moment to review the agreement now so that you are familiar with it when you sit for your exam.
Where selected by your Test Sponsor, you agree that Pearson VUE will collect your palm vein pattern at the test center on the day of your exam and retain that information, to the extent permitted by law. Your palm vein scan will be used for the purposes of identification verification on the day of your test and on your future test days, detecting and preventing any fraud, and maintaining the security and integrity of the testing program. For more information on Pearson VUE‘s policy for use and retention of personal data including biometric data like palm vein scans, please see our Privacy and Cookies Policy. Your agreement to these Testing policies includes agreement to the Privacy and Cookies Policy.
Reschedule Policy 
•	If you wish to reschedule your exam appointment, you must contact Pearson VUE.
•	There is no fee for rescheduling the Certified in Cybersecurity (CC) exam. For all other certifications, there is a US$50 fee for exam appointment rescheduled.
•	If you choose to go online to reschedule your appointment, you must do so at least 48 hours prior to your appointment.
•	If you choose to call the Pearson customer support team to reschedule, you must do so at least 24 hours prior to your appointment.
•	If you do not reschedule your exam appointment without proper advanced notice, as outlined above, it will result in a no-show, and you will forfeit your exam fee. If you used the ISC2 Candidate promo code, as part of the One Million Certified in Cybersecurity initiative, you will not be able to register again with that code.
•	Once scheduled you have up to 365 days to sit for your exam. Failure to sit for your examination within 365 days will result in a no-show and forfeiture of all exam and rescheduling fees.
Cancellation Policy 
•	If you wish to cancel your exam appointment, you must contact Pearson VUE.
•	There is no fee for canceling the Certified in Cybersecurity (CC) exam. For all other certifications, there is a US$100 fee for exam appointment cancelations.
•	If you choose to go online to cancel your appointment, you must do so at least 48 hours prior to your appointment.
•	If you choose to call the Pearson customer support team to cancel, you must do so at least 24 hours prior to your appointment.
•	If you do not cancel your exam appointment without proper advanced notice, as outlined above, it will result in a no-show, and will forfeit your exam fee. If you used the ISC2 Candidate promo code, as part of the One Million Certified in Cybersecurity initiative, you will not be able to register again with that code.
Additional Information 
ISC2 Terms and Conditions
•	ISC2 requires that all candidates for certification read and accept the terms and conditions set forth here: https://www.isc2.org/uploadedFiles/Certification_Programs/CBT-Examination-Agreement.pdf. Candidates that do not agree to the terms and conditions will not be permitted to sit for any ISC2 examination.
Non-Disclosure Agreement (NDA)
•	Failure to read or accept the ISC2 NDA agreement within the allotted five minutes will result in exam termination and forfeiture of exam appointment. Forfeiture of exam appointment also includes forfeiture of all exam fees. To take the examination at a later date you will be required to re-register for the exam and pay all applicable registration fees.
Important Information on ISC2 Exams
•	One of the benefits to candidates taking an examination via Computer-Based Testing is that most candidates receive their scores immediately upon completing their examination. In some cases, ISC2 must conduct periodic psychometric analyses prior to releasing exam results. For the small number of candidates affected by this process, it is expected that candidates will receive their results within 6 -8 weeks following the exam.
•	ISC2 offers two types of computer-based exams – linear and adaptive – however neither exam type allows for candidates to skip an item, nor can items be returned to later during administration. Once an answer is confirmed it cannot be changed, reviewed, or revisited.
•	Frequently asked questions (FAQs) and answers for common inquiries that can be found here: https://www.isc2.org/Frequently-Asked-Questions.

Accommodations Policy
ISC2 provides reasonable and appropriate accommodations for people who have a documented need for exam accommodations. Accommodations must be requested and approved by ISC2 prior to scheduling your examination. If you wish to request an accommodation, please visit https://www.isc2.org/Register-for-Exam and look under the Requesting Special Accommodations tab for information and instructions on how to request an accommodation. Test accommodations are individualized and considered on a case-by-case basis. Once an accommodation is approved, ISC2 will inform the Pearson VUE Accommodations team. Please allow up to three business days for Pearson VUE to receive this information. Then, contact 
Cart
Collapsed, toggle side navigation to expand 
Edit my profile  Tshingombe Tshingombe Tshitadi  
ISC2 ID: 1907033 
•	Dashboard 
•	My Profile 
•	
•	
•	Sign out 
Almost there... 
back to previous step 
Confirm Order Details
Description 	Details 	Price
Exam
CC: Certified in Cybersecurity (CC)
Language: English 
Length: 120 minutes 	Appointment 
Friday, March 14, 2025 
Start time: 8:00 AM Africa/Johannesburg - SAST 
Location
Pearson Professional Centers-Johannesburg 
Pearson VUE
6th Floor Sandton City Office Tower
Sandton City Shopping Centre
158 5th Street, SANDTON
Johannesburg
2146
South Africa 	199.00 
Payment Details
Exams for
Name:
Tshingombe Tshingombe Tshitadi 
ISC2 ID:
1907033
Order Total
Subtotal: 	199.00 
Tax: 	0.00 
TOTAL DUE: 	USD 199.00 
	USD 199.00 



Pearson VUE, so you can schedule your exam, contact information can be found at www.pearsonvue.com/isc2/contact.
Accommodations are not a guarantee of improved performance or exam completion. Once an initial exam appointment is scheduled, there may be a US$50 fee to reschedule an exam with an approved accommodation.
Agree to ISC2 policies 
back to previous step 
CCSP: Certified Cloud Security Professional (CCSP) 
CGRC: Certified in Governance Risk and Compliance 
CISSP: Certified Information Systems Security Professional 
CSSLP: Certified Secure Software Lifecycle Professional 
ISSAP: Information Systems Security Architecture Professional 
ISSMP: Information Systems Security Management Professional 
SSCP: Systems Security Certified Practitioner
Certification Exam Outline 
Effective Date: November 15, 20222 
ISSMP Certification Exam Outline 
About CISSP-ISSMP 
The Information Systems Security Management Professional (ISSMP) is a CISSP who specializes in establishing, 
presenting and governing information security programs and demonstrates management and leadership 
skills. CISSP-ISSMPs direct the alignment of security programs with the organization’s mission, goals and 
strategies in order to meet enterprise financial and operational requirements in support of its desired risk 
position. 
The broad spectrum of topics included in the CISSP-ISSMP Common Body of Knowledge (CBK®) ensure its 
relevancy across all disciplines in the field of information security management. Successful candidates are 
competent in the following six domains: 
• Leadership and Business Management 
• Systems Lifecycle Management 
• Risk Management 
• Threat Intelligence and Incident Management 
• Contingency Management 
• Law, Ethics and Security Compliance Management 
Experience Requirements 
Candidates must be a CISSP in good standing and have two years cumulative paid work experience 
in one or more of the six domains of the CISSP-ISSMP CBK. You can learn more about CISSP-ISSMP 
experience requirements and how to account for part-time work and internships at 
www.isc2.org/Certifications/CISSP-Concentrations#steps-to-certification. 
Accreditation 
CISSP-ISSMP is in compliance with the stringent requirements of ANSI/ISO/IEC Standard 17024. 
Job Task Analysis (JTA) 
(ISC)² has an obligation to its membership to maintain the relevancy of the CISSP-ISSMP. Conducted at 
regular intervals, the Job Task Analysis (JTA) is a methodical and critical process of determining the tasks that 
are performed by security professionals who are engaged in the profession defined by the CISSP-ISSMP. The 
results of the JTA are used to update the examination. This process ensures that candidates are tested on the 
topic areas relevant to the roles and responsibilities of today’s practicing information security professionals.3 
ISSMP Certification Exam Outline 
CISSP-ISSMP Examination Information 
CISSP-ISSMP Examination Weights 
Length of exam 
Number of items 
Item format 
Passing grade 
Exam availability 
Testing center 
3 hours 
125 
Multiple choice 
700 out of 1000 points 
English 
Pearson VUE Testing Center 
Domains 
Weight 
1. Leadership and Business Management 
20% 
2. Systems Lifecycle Management 
18% 
3. Risk Management 
19% 
4. Threat Intelligence and Incident Management 
17% 
5. Contingency Management 
15% 
6. Law, Ethics and Security Compliance Management 
11% 
Total: 100%4 
ISSMP Certification Exam Outline 
Domain 1: 
Leadership and Business Management 
1.1 Establish security’s role in organizational culture, vision and mission 
» Define information security program vision and mission 
» Align security with organizational goals, objectives and values 
» Define security’s relationship to the overall business processes 
» Define the relationship between organizational culture and security 
1.2 Align security program with organizational governance 
» Identify and navigate organizational governance structure 
» Validate roles of key stakeholders 
» Validate sources and boundaries of authorization 
» Advocate and obtain organizational support for security initiatives 
1.3 Define and implement information security strategies 
» Identify security requirements from business initiatives 
» Evaluate capacity and capability to implement security strategies 
» Manage implementation of security strategies 
» Review and maintain security strategies 
» Prescribe security architecture and engineering theories, concepts and methods 
1.4 Define and maintain security policy framework Determine applicable external standards 
» Determine applicable external standards 
» Determine data classification and protection requirements 
» Establish internal policies 
» Advocate and obtain organizational support for policies 
» Develop procedures, standards, guidelines and baselines 
» Ensure periodic review of security policy framework5 
ISSMP Certification Exam Outline 
» Define roles and responsibilities 
» Determine and manage team accountability 
» Build cross-functional relationships 
» Resolve conflicts between security and 
other stakeholders 
» Identify communication bottlenecks 
and barriers 
» Integrate security controls into human 
resources processes 
» Evaluate service management agreements 
(e.g., risk, financial) 
» Govern managed services 
(e.g., infrastructure, cloud services) 
» Manage impact of organizational change (e.g., 
mergers and acquisitions, outsourcing) 
» Ensure that appropriate regulatory compliance 
statements and requirements are included in 
contractual agreements 
» Monitor and enforce compliance with 
contractual agreements 
1.5 Manage security requirements in contracts and agreements 
1.6 Manage security awareness and training programs 
» Promote security programs to key stakeholders 
» Identify needs and implement training programs by target segment 
» Monitor and report on effectiveness of security awareness and training programs 
1.7 Define, measure and report security metrics 
» Identify Key Performance Indicators (KPI) 
» Associate Key Performance Indicators (KPI) to the risk posture of the organization 
» Use metrics to drive security program development and operations 
1.8 Prepare, obtain and administer security budget 
» Prepare and secure annual budget 
» Adjust budget based on evolving risks and threat landscape 
» Manage and report financial responsibilities 
1.9 Manage security programs 
1.10 Apply product development and project management principles 
» Incorporate security into project lifecycle 
» Identify and apply appropriate project management methodology 
» Analyze project time, scope and cost relationship6 
ISSMP Certification Exam Outline 
2.1 Manage integration of security into Systems Development Life Cycle (SDLC) 
» Integrate information security gates (decision points) and requirements into lifecycle 
» Implement security controls into system lifecycle 
» Oversee security configuration management (CM) processes 
2.2 Integrate new business initiatives and emerging technologies into the 
security architecture 
» Integrate security into new business initiatives and emerging technologies 
» Address impact of new business initiatives on security posture 
2.3 Define and oversee comprehensive vulnerability management programs 
(e.g., vulnerability scanning, penetration testing, threat analysis) 
» Identify, classify and prioritize assets, systems and services based on criticality to business 
» Prioritize threats and vulnerabilities 
» Manage security testing 
» Manage mitigation and/or remediation of vulnerabilities based on risk 
2.4 Manage security aspects of change control 
» Integrate security requirements with change control process 
» Identify and coordinate with the stakeholders 
» Manage documentation and tracking 
» Ensure policy compliance (e.g., continuous monitoring) 
Domain 2: 
Systems Lifecycle Management 7 
ISSMP Certification Exam Outline 
Domain 3: 
Risk Management 
3.1 Develop and manage a risk management program 
» Identify risk management program objectives 
» Communicate and agree on risk management objectives with risk owners and other stakeholders 
» Determine scope of organizational risk program 
» Identify organizational security risk tolerance/appetite 
» Obtain and verify organizational asset inventory 
» Analyze organizational risks 
» Determine countermeasures, compensating and mitigating controls 
» Perform cost-benefit analysis (CBA) of risk treatment options 
3.2 Conduct risk assessments 
» Identify risk factors 
3.3 Manage security risks within the supply chain (e.g., supplier, vendor, third-party risk) 
» Identify supply chain security risk requirements 
» Integrate supply chain security risks into organizational risk management 
» Validate security risk control within the supply chain 
» Monitor and review the supply chain security risks8 
ISSMP Certification Exam Outline 
4.1 Establish and maintain threat intelligence program 
» Aggregate threat data from multiple threat intelligence sources 
» Conduct baseline analysis of network traffic, data and user behavior 
» Detect and analyze anomalous behavior patterns for potential concerns 
» Conduct threat modeling 
» Identify and categorize an attack 
» Correlate related security event and threat data 
» Create actionable alerting to appropriate resources 
4.2 Establish and maintain incident handling and investigation program 
» Develop program documentation 
» Establish incident response case management process 
» Establish incident response team 
» Apply incident management methodologies 
» Establish and maintain incident handling process 
» Establish and maintain investigation process 
» Quantify and report financial and operational impact of incidents and investigations to stakeholders 
» Conduct root cause analysis (RCA) 
Domain 4: 
Threat Intelligence and Incident 
Management 9 
ISSMP Certification Exam Outline 
5.1 Facilitate development of contingency plans 
» Identify and analyze factors related to the Continuity of Operations Plan (COOP) 
» Identify and analyze factors related to the business continuity plan (BCP) (e.g., time, resources, verification) 
» Identify and analyze factors related to the disaster recovery plan (DRP) (e.g., time, resources, verification) 
» Coordinate contingency management plans with key stakeholders 
» Define internal and external crisis communications plans 
» Define and communicate contingency roles and responsibilities 
» Identify and analyze contingency impact on business processes and priorities 
» Manage third-party contingency dependencies 
» Prepare security management succession plan 
5.2 Develop recovery strategies 
» Identify and analyze alternatives 
» Recommend and coordinate recovery strategies 
» Assign recovery roles and responsibilities 
5.3 Maintain contingency plan, Continuity of Operations Plan (COOP), business continuity 
plan (BCP) and disaster recovery plan (DRP) 
» Plan testing, evaluation and modification 
» Determine survivability and resiliency capabilities 
» Manage plan update process 
5.4 Manage disaster response and recovery process 
» Declare disaster 
» Implement plan 
» Restore normal operations 
» Gather lessons learned 
» Update plan based on lessons learned 
Domain 5: 
Contingency Management 10 
ISSMP Certification Exam Outline 
10 
6.1 Identify the impact of laws and regulations that relate to information security 
6.2 Adhere to the (ISC)
2 
Code of Ethics as related to management issues 
6.3 Validate compliance in accordance with applicable laws, regulations and industry 
best practices 
6.4 Coordinate with auditors and regulators in support of the internal and external 
audit processes 
6.5 Document and manage compliance exceptions 
» Identify and document compensating controls and workarounds 
» Report and obtain authorized approval of risk waiver 
Domain 6: 
Law, Ethics and Security Compliance 
Management 
» Identify applicable privacy laws 
» Identify legal jurisdictions the organization and 
users operate within (e.g., trans-border data flow) 
» Identify export laws 
» Identify intellectual property (IP) laws 
» Identify applicable industry regulations 
» Identify and advise on non-compliance risks 
» Inform and advise senior management 
» Evaluate and select compliance framework(s) 
» Implement the compliance framework(s) 
» Define and monitor compliance metrics 
» Plan 
» Schedule 
» Coordinate audit activities 
» Evaluate and validate findings 
» Formulate response 
» Validate implemented mitigation and 
remediation actions11 
ISSMP Certification Exam Outline 
Additional Examination Information 
Supplementary References 
Candidates are encouraged to supplement their education and experience by reviewing 
relevant resources that pertain to the CBK and identifying areas of study that may need 
additional attention. 
View the full list of supplementary references at www.isc2.org/certifications/References. 
Examination Policies and Procedures 
(ISC)2 recommends that CISSP-ISSMP candidates review exam policies and procedures 
prior to registering for the examination. Read the comprehensive breakdown of this 
important information at www.isc2.org/Exams/Before-Your-Exam. 
Legal Info 
For any questions related to (ISC)
2 
’s legal policies, please contact the (ISC)2 Legal 
Department at legal@isc2.org. 
Any Questions? 
(ISC)2 Americas 
Tel: +1.866.331.ISC2 (4722) 
Email: info@isc2.org 
(ISC)2 Asia-Pacific 
Tel: +(852) 28506951 
Email: isc2asia@isc2.org 
(ISC)2 EMEA 
Tel: +44 (0)203 300 1625 
Email: info-emea@isc2.org 
11 
v222Certification Exam Outline 
Effective Date: November 13, 20202 
ISSEP Certification Exam Outline 
About CISSP-ISSEP 
The Information Systems Security Engineering Professional (ISSEP) is a CISSP who specializes in the practical 
application of systems engineering principles and processes to develop secure systems. An ISSEP analyzes 
organizational needs, defines security requirements, designs security architectures, develops secure designs, 
implements system security, and supports system security assessment and authorization for government and 
industry. 
The broad spectrum of topics included in the ISSEP Common Body of Knowledge (CBK®) ensure its relevancy 
across all disciplines in the field of security engineering. Successful candidates are competent in the following 
five domains: 
• Systems Security Engineering Foundations 
• Risk Management 
• Security Planning and Design 
• Systems Implementation, Verification and Validation 
• Secure Operations, Change Management and Disposal 
Experience Requirements 
Candidates must be a CISSP in good standing and have two years cumulative paid work experience 
in one or more of the five domains of the CISSP-ISSEP CBK. You can learn more about CISSP-ISSEP 
experience requirements and how to account for part-time work and internships at 
www.isc2.org/Certifications/CISSP-ISSEP/experience-requirements. 
Accreditation 
CISSP-ISSEP is in compliance with the stringent requirements of ANSI/ISO/IEC Standard 17024. 
Job Task Analysis (JTA) 
(ISC)² has an obligation to its membership to maintain the relevancy of the ISSEP. Conducted at regular 
intervals, the Job Task Analysis (JTA) is a methodical and critical process of determining the tasks that are 
performed by security professionals who are engaged in the profession defined by the ISSEP. The results of 
the JTA are used to update the examination. This process ensures that candidates are tested on the topic 
areas relevant to the roles and responsibilities of today’s practicing information security professionals.3 
ISSEP Certification Exam Outline 
CISSP-ISSEP Examination Information 
CISSP-ISSEP Examination Weights 
Length of exam 
Number of items 
Item format 
Passing grade 
Exam availability 
Testing center 
3 hours 
125 
Multiple choice 
700 out of 1000 points 
English 
Pearson VUE Testing Center 
Domains 
Weight 
1. Systems Security Engineering Foundations 
25% 
2. Risk Management 
14% 
3. Security Planning and Design 
30% 
4. Systems Implementation, Verification and Validation 
14% 
5. Secure Operations, Change Management 
and Disposal 
17% 
Total: 100%4 
ISSEP Certification Exam Outline 
Domain 1: 
Systems Security Engineering Foundations 
1.1 Apply systems security engineering fundamentals 
1.2 Execute systems security engineering processes 
1.3 Integrate with applicable system development methodology 
1.4 Perform technical management 
1.5 Participate in the acquisition process 
1.6 Design Trusted Systems and Networks (TSN) 
» Understand systems security engineering trust 
concepts and hierarchies 
» Identify the relationships between systems and 
security engineering processes 
» Apply structural security design principles 
» Integrate security tasks and activities 
» Verify security requirements throughout 
the process 
» Integrate software assurance methods 
» Perform project planning processes 
» Perform project assessment and control 
processes 
» Perform decision management processes 
» Perform risk management processes 
» Perform configuration management processes 
» Perform information management processes 
» Perform measurement processes 
» Perform Quality Assurance (QA) processes 
» Identify opportunities for security process 
automation 
» Identify organizational security authority 
» Identify system security policy elements 
» Integrate design concepts 
(e.g., open, proprietary, modular) 
» Prepare security requirements for acquisitions 
» Participate in selection process 
» Participate in Supply Chain Risk Management 
(SCRM) 
» Participate in the development and review of 
contractual documentation5 
ISSEP Certification Exam Outline 
Domain 2: 
Risk Management 
2.1 Apply security risk management principles 
2.2 Address risk to system 
2.3 Manage risk to operations 
» Establish risk context 
» Identify system security risks 
» Perform risk analysis 
» Perform risk evaluation 
» Recommend risk treatment options 
» Document risk findings and decisions 
» Determine stakeholder risk tolerance 
» Identify remediation needs and other system changes 
» Determine risk treatment options 
» Assess proposed risk treatment options 
» Recommend risk treatment options 
» Align security risk management with Enterprise Risk Management (ERM) 
» Integrate risk management throughout the lifecycle6 
ISSEP Certification Exam Outline 
3.1 Analyze organizational and operational environment 
3.2 Apply system security principles 
3.3 Develop system requirements 
3.4 Create system security architecture and design 
Domain 3: 
Security Planning and Design 
» Capture stakeholder requirements 
» Identify relevant constraints and assumptions 
» Assess and document threats 
» Determine system protection needs 
» Develop Security Test Plans (STP) 
» Incorporate resiliency methods to address threats 
» Apply defense-in-depth concepts 
» Identify fail-safe defaults 
» Reduce Single Points of Failure (SPOF) 
» Incorporate least privilege concept 
» Understand economy of mechanism 
» Understand Separation of Duties (SoD) concept 
» Develop system security context 
» Identify functions within the system and security 
Concept of Operations (CONOPS) 
» Document system security requirements baseline 
» Analyze system security requirements 
» Develop functional analysis and allocation 
» Maintain traceability between specified design 
and system requirements 
» Develop system security design components 
» Perform trade-off studies 
» Assess protection effectiveness7 
ISSEP Certification Exam Outline 
Domain 4: 
Systems Implementation, Verification 
and Validation 
4.1 Implement, integrate and deploy security solutions 
4.2 Verify and validate security solutions 
» Perform system security implementation and integration 
» Perform system security deployment activities 
» Perform system security verification 
» Perform security validation to demonstrate security controls meet stakeholder security requirements8 
ISSEP Certification Exam Outline 
Domain 5: 
Secure Operations, Change Management 
and Disposal 
5.1 Develop secure operations strategy 
5.2 Participate in secure operations 
5.3 Participate in change management 
5.4 Participate in the disposal process 
» Specify requirements for personnel conducting operations 
» Contribute to the continuous communication with stakeholders for security relevant aspects of the system 
» Develop continuous monitoring solutions and processes 
» Support the Incident Response (IR) process 
» Develop secure maintenance strategy 
» Participate in change reviews 
» Determine change impact 
» Perform verification and validation of changes 
» Update risk assessment documentation 
» Identify disposal security requirements 
» Develop secure disposal strategy 
» Develop decommissioning and disposal procedures 
» Audit results of the decommissioning and disposal process9 
ISSEP Certification Exam Outline 
Additional Examination Information 
Supplementary References 
Candidates are encouraged to supplement their education and experience by reviewing 
relevant resources that pertain to the CBK and identifying areas of study that may need 
additional attention. 
View the full list of supplementary references at www.isc2.org/certifications/References. 
Examination Policies and Procedures 
(ISC)² recommends that ISSEP candidates review exam policies and procedures prior to 
registering for the examination. Read the comprehensive breakdown of this important 
information at www.isc2.org/Register-for-Exam. 
Legal Info 
For any questions related to (ISC)²’s legal policies, please contact the (ISC)2 Legal 
Department at legal@isc2.org. 
Any Questions? 
(ISC)² Americas 
Tel: +1-866-331-ISC2(4722) 
Email: membersupport@isc2.org 
(ISC)² Asia Pacific 
Tel: +852-2850-6951 
Email: membersupportapac@isc2.org 
(ISC)² EMEA 
Tel: +44-203-960-7800 
Email: membersupportemea@isc2.org 
9 
  
Attachments
Rate this
Details
Lenovo and Intel are Driving AI Innovation at the Edge
Flynn Maloy, Chief Marketing Officer of Lenovo ISG
Jan 23 2025| 0 mins
Lenovo and Intel’s long-standing partnership is transforming industries by bringing cutting-edge AI solutions to the edge and beyond. From PCs to data centers, our collaboration has consistently pushed technological boundaries. The strength of Lenovo’s ThinkEdge portfolio is enabling AI-driven applications in manufacturing sites, retail stores, schools, and more. Join @Flynn Maloy, Chief Marketing Officer of Lenovo ISG, as he details how Lenovo and Intel® are leading the way in AI innovation: - Comprehensive solutions for diverse industries: From computer vision in manufacturing to advanced AI in education and retail, Lenovo and Intel’s joint solutions empower a variety of applications. - Next-gen AI with CPUs: Not every AI workload requires massive GPUs. Intel’s CPUs are driving the next wave of edge AI, particularly in inferencing and delivering efficient and accessible AI solutions. - Scalable and powerful edge portfolio: Lenovo’s edge clients and servers, powered by Intel, are designed to meet the demands of modern businesses, offering flexibility and performance across workloads. - A partnership that drives innovation: With a shared vision for the future of AI, Lenovo and Intel continue to push the boundaries of what’s possible for our customers. Together, Lenovo and Intel are leading the charge in making AI more accessible, scalable, and impactful for businesses worldwide.
State of Cloud 2025: Navigating EMEA’s Cloud Revolution
John Bradshaw, Director of Cloud Computing Technology and Strategy, EMEA, Akamai & Bryan Glick, Editor in Chief, Computer Weekly
Feb 27 2025| 18 mins
Boris Cipot, Senior Security Engineer
Sep 05 2024| 30 mins
Python is a fast, platform-agnostic, and easy-to-learn programming language that is suited for beginners and experienced developers alike. Ever since its first release in 1991, Python has had a constant presence in the computer world and has become a go-to language thanks to its easy-to-understand code and versatility. Today, Python can boast a wide array of libraries and frameworks, and they are the cornerstone of fast and easy Python programming—the so-called Pythonic way of development. But like all programming languages, Python is not immune to security threats. Secure coding best practices must be adopted to avoid risks from attackers. In this webinar, we’ll explore Python security best practices that should employed when building secure application. One-Stop DevOps: Simplifying Toolchains with GitLab and Google Cloud
Nate Avery, Outbound Product Manager - Google | Jackie Porter, Director of Product - Gitlab | Torsten Volk, Principal Analyst - ESG
Dec 04 2024| 28 mins
Seamless Edge Deployment and Management with Lenovo and Intel
Blake Kerrigan, Senior Director, ThinkEdge Business Group
Jan 23 2025| 1 mins

topics
Inbox

tshingombe fiston <tshingombefiston@gmail.com> 
	11:34 AM (51 minutes ago)
	
	
to me 


Feedback on Security Service Provider Application and Complaint Process
Application for Exemption Terms of Section 23(6)
Key Points:
Applicant Information: 
oFull Name: Tshingombe Fiston
oDate: January 18, 2025, 6:36 PM
oContact: Not provided
Application Details: 
oTerms of Section 23(6) of the Private Security Industry Regulation Act 56 of 2001.
oDespite Section 23(1) and (2), the authority may register any applicant as a security service provider on good cause shown.
oRequirements include applicant's age, training, and clearance of any criminal offenses in the last ten years.
Particulars of Appellant:
Full Name: Tshingombe Fiston
Contact Address: Not provided
Refusal Reasons: 
oRefusal to grant application for registration.
oRefusal to renew registration.
oCancellation or suspension of registration.
oConviction of improper conduct.
Complaints Management Process:
Statutory Mandate: Derived from the Private Security Regulation Act 56 of 2001.
Complaint Definition: Dissatisfaction reported to PSIRA regarding the quality of service rendered by a private security service provider.
Complaint Handling: Complaints are processed, referred, or dealt with by PSIRA in accordance with the code of conduct and statutory mandate.
Security Equipment Definition:
Types of Equipment: 
oAlarm systems, safes, satellite tracking devices.
oIntrusion detection, access control, bomb detection, and fire detection devices.
oSecurity containers, X-ray, and communication devices.
Improper Conduct:
Examples: 
oOperating without registration.
oDeploying unregistered security officers.
oFailure to meet training and uniform standards.
oNon-payment of prescribed wages and allowances.
Complaint Resolution:
Time Frame: Standard period to finalize any complaint is 30 to 90 days.
Common Complaints: Include wage disputes, improper conduct, and training deficiencies.
Digital Records:
Last Updated: 12-05-2022
Batch Numbers: 
oBatch 383731: Pending since June 28, 2024.
oBatch 383732: Termination pending since June 29, 2024.
Job Career Information:
Current Status: Application for registration as a security officer in progress.
Job Requirements: 
oBasic salary, education qualifications, and employment history.
oAbility to work under pressure and interpret legislation.
oHigh administrative skills and problem-solving abilities.
Investigation and Complaints:
Details of Complaints: 
oComplainant Name: Tshingombe Fiston
oIncident Date: July 14, 2023
oNature of Complaint: Dismissal from job, irregularities in exam processes, and issues with certification.
Legal and Administrative Actions:
Court Cases: 
oLabour court cases and appeals.
oComplaints lodged with various authorities including the Office of the Chief Justice.
Outcomes: 
oPending decisions and unresolved issues.
oRequests for reviews and rescission rulings.
Training and Development:
Police Community Support Officer (PCSO) Training: 
oDuration: One month initial training.
oKey Areas: Radio procedures, evidence gathering, crime scene management, human rights, and diversity awareness.
Student Placement Programs:
Areas of Placement: 
oFinancial crime investigation.
oEstate and asset management.
oConstruction and building engineering.
Essential Skills: 
oPlanning, organization, communication, technical skills, and teamwork.
Expression of Interest and Withdrawals:
Record of Interest: Successfully withdrawn from certain roles.
Feedback: Encouraged to explore other opportunities within the organization.
Freedom of Information Requests:
Recent Requests: 
oRequest for validation and information under the Freedom of Information Act.
oRequirements for resubmission and personal data verification.
Integrity and Defense:
Research Focus: 
oIssues related to justice, education, and low development.
oEmphasis on technological support and criminal investigations.
Summary:
Feedback: Comprehensive review of the application, complaint process, and training details provided. Emphasis on proper documentation, clear communication, and adherence to statutory mandates.


	Virus-free.www.avast.com

tshingombe fiston <tshingombefiston@gmail.com> 
	11:36 AM (48 minutes ago)

	
	
to me 


Feedback on Various Topics and Processes
NQF Monitoring and Irregularities
Key Points:
Monitoring Issues: Umalusi monitoring in terms of policy and sections 17 and 18 of the General and Further Education and Training Quality Assurance Act 2001 (Act No. 58 of 2091).
Student Records: Integrated information system to provide proof of qualifications for part-time students.
Remuneration and Employment: Governed by the Future Educator Act 2006.
Irregularities:
National Certificate: SAQA includes part-time qualifications.
Portfolio: Collection of evidence for students.
Judgement and Assessment
Key Points:
Judgement Need: Describing evidence learning view group lecture approach to assessment.
Policing Learner Overview: 
oIntroduction to crime information management system.
oCrime prevention principles and applied communication in policing.
oInvestigative principles and professionalism in policing.
Community Policing:
Framework: Community policing involves a proactive, problem-oriented approach with interrelated roles of law enforcement officials.
Creative Law Response: Policing strategies and tactics are introduced to address underlying causes of crime.
Assessor Training and Work-based Assessment
Key Points:
Purpose: Guide to learning material and assessment protocols.
Work-based Holistic Assessment Model: Includes planning, activity forms, and witness testimony.
Assessment Standards: Emphasize validity, authenticity, reliability, and standardization.
Portfolio Assessment:
Components: Collection of evidence, assessor comments, and learner reporting.
Technical Competency: Shown through project reports and presentations.
Research and Methodology Assessment
Key Points:
Overview: Research design and methodology for CAPS, NCV, trade, UCPD, SETA, and SASSETA.
Participants: Teachers and HODs' responses to research findings.
Recommendations: To the Department of Education (DBE) and DHET.
Ethical Considerations:
Research Design: Includes literature review, data collection, and analysis.
Teacher Roles: Attitudes towards integrating technical subjects in civil technology.
Library Research and Grant Proposals
Key Points:
Grant Proposal: Submission details for non-profit and research proposals.
Request for Proposal Template: For qualifications and award certificates.
Project Overview: National system examination and qualifications framework.
Case Studies:
Electro Energetical Stability: Reports on rural sector safety and resource management.
Training Support: For learners in electro energetical systems.
Project Goals:
Workplace Training: Regulation and irregularity in attendance and outcome criteria.
Resource Allocation: Value breakdown and retrospective cost projections.
Summary
Feedback:
Comprehensive Review: Covering various topics including NQF monitoring, judgement and assessment, assessor training, research methodology, library research, and grant proposals.
Documentation: Emphasis on proper documentation, clear communication, and adherence to statutory mandates and assessment standards.
Recommendations: To improve processes and address irregularities in the education and training systems.


	Virus-free.www.avast.com


tshingombe fiston <tshingombefiston@gmail.com> 
	11:39 AM (45 minutes ago)

	
	
to me 


ISC2 Security Congress 2025 Proposal
Submission Details
Submission Type: Call for Papers Proposals
Presentation Proposal Status: Complete
Presentation Proposal ID: 2070815
Presentation Proposal Title: Thesis Master Engineering Thesis Master Doctoral Engineering Electrical Subject Curriculum Framework Qualification Education Technology
Speaker Information
Speaker Name: Tshingombe Tshi Tshitadi
Role: Facilitator
Pronouns: He/him/his
Presentation Proposal Details
Audience Experience Level
General (Everyone will obtain value)
Early (0-3 years)
Mid (4-9 years)
Senior (10+ years)
Audience Career Track
All
Engineering/Architecture
Management/Executive
Operational/Tactical
Preferred Presentation Type
Breakout Session
Bright Ideas Roundtable
Full Description
Proposal of Thesis Content / Final Project
Content:
1.Name of Thesis
2.Index
3.Introduction
4.Description
5.General Analyzing
Key Differentiator / Originality:
Description: At the heart of solutions to framework qualification and national trade implementation sub-sector training. Trainer experimental workplace industrial, more students and institutes, college trade years external internal work value increase price macro.
Content Area:
Governance, Risk, and Compliance (GRC)
Additional Details/Supporting Information
Recommendation/Endorsement:
3.4 Synopsis of Content: The stability design, projection system trade marketing board, information system electrokinematic dynamic physical state engineering science introduction, used to trade theory electrical, manufacture process inventory low stamp system low stable loadshedding week manufacture.
What prompted you to submit a proposal?
Email
Have you presented this session or content at any other conferences, webinars, or events?
Yes
If Yes, what other conference(s) or event(s) was this content presented at?
3.4 Synopsis of Content: The stability design projection system trade marketing board, information system electrokinematic dynamic physical state engineering science introduction, used to trade theory electrical, manufacture process inventory low stamp system low stable loadshedding week manufacture.
Prior Speaking Engagements/Experience:
Engineering
Webcasts, Podcasts, & Videos:
3.4 Synopsis of Content: The stability design projection system trade marketing board, information system electrokinematic dynamic physical state engineering science introduction, used to trade theory electrical, manufacture process inventory low stamp system low stable loadshedding week manufacture.
Books, Papers, Etc.:
3.4 Synopsis of Content: The stability design projection system trade marketing board, information system electrokinematic dynamic physical state engineering science introduction, used to trade theory electrical, manufacture process inventory low stamp system low stable loadshedding week manufacture.
Would you like to be contacted about additional opportunities to contribute as a speaker or writer for other ISC2 programs?
Speaking on Webcasts
Speaking at other Virtual Events
Speaking at Future Security Congress
Speaking at In-Person Events
Speaking at ISC2 Chapter Events
Authoring Content for Magazine Articles/Newsletter/Blogs
Authoring and/or Reviewing Content for Professional Development
Would you like to be part of a speaker database, made available to ISC2 Chapters?
Yes
Additional Demographics Collection Questions
ISC2 is committed to ensuring the cybersecurity profession is as diverse, equitable, and inclusive as the world we serve.
Age: 45-54
Nationality: Congolese (DRC)
Gender: Man
Pronouns: He/his
Ethnicity/Race (US): American Indian or Alaska Native
US: If you selected "Other ethnic group", please list it below: Black
Ethnicity/Race (UK): Mixed or Multiple Ethnic Groups (White and Black Caribbean, White and Black African, White and Asian, Any other Mixed or Multiple ethnic background)
UK: If you selected "Other ethnic group", please list it below: UK
Highest level of education (US): High school graduate, diploma or the equivalent (for example: GED)
Highest level of education (UK): College or university
Preferred spoken/written language: English
Do you identify as a member of any of the following groups? Veteran or Prior Armed Forces Service
Deadline
All submissions must be received no later than 11:59 p.m. ET on Feb. 28, 2025. Deadline subject to change per the discretion of ISC2. 

	Virus-free.www.avast.com


tshingombe fiston <tshingombefiston@gmail.com> 
	11:43 AM (42 minutes ago)

	
	
to me 


ISC2 Security Congress 2025: Call for Presentations
Your Feedback
Submission Details
Date Submitted: Dec 27, 2024, 9:10 AM
Feedback ID: [Not provided]
Submission Type: Call for Papers Proposals
Presentation Proposal Status
Status: Complete
Presentation Proposal ID: 2070815
Title: Thesis Master Engineering Thesis Master Doctoral Engineering Electrical Subject Curriculum Framework Qualification Education Technology
Speaker Information
Speaker Name: Tshingombe Tshitadi
Role: Facilitator
Pronouns: He/him/his
Feedback Content
Overview of Topics Submitted
Locksmith / Safe Technician
Management Skills: General management skills applied to the role of locksmith and safe technician.
Health and Safety: Emphasis on applying health and safety standards in the workplace.
Traffic Management
Vehicle Identification: Accurate identification of vehicle types and configurations.
Operational Procedures: Data captured and assessed according to standard operational procedures and legislation.
Road Traffic Management: Includes traffic signal design, installation, and maintenance.
Electrical and Electronic Engineering
Professional Skills: Usage of digital electronics, advanced telecommunications, and data transmission systems.
Maintenance and Repair: Installation, maintenance, and repair of electrical and electronic systems.
Traffic Signal Installation
Planning and Design: In-depth planning and design by skilled professionals.
Operational Supervision: Effective supervision and control during installation to ensure compliance with specifications.
Security Practice in Education
Security Concepts: Introduction to basic security concepts and administrative procedures.
Criminal Investigation: Overview of criminal investigation techniques and the role of technology in security.
Labour Relations and Mediation
Pension Funds Act: Application of the Pension Funds Act to the administration of retirement funds.
Labour Conciliation: Conducting conciliation processes and understanding labour relations legislation.
Skill Development in Legislation and Training
Sector Training Authorities: Emphasis on skills development and adherence to safety standards.
Workshop Tools: Proper use and maintenance of workshop tools in various engineering tasks.
Additional Comments
Diversity and Inclusion: Emphasis on ensuring the cybersecurity profession is diverse, equitable, and inclusive.
Demographic Information: Collection of demographic data to assess representation and improve processes.
Recommendations
Continued Education: Importance of continuing education and skill transfer in various fields.
Practical Training: Emphasis on practical training and on-the-job experience to ensure comprehensive skill development.
Feedback: Detailed and constructive feedback provided to improve future submissions and ensure alignment with ISC2 standards.
Conclusion
Thank you for submitting feedback to ISC2 Security Congress 2025. Your detailed insights and recommendations are highly valued and will contribute to the ongoing improvement of our processes and programs. We look forward to your continued participation and engagement in ISC2 events. 

	Virus-free.www.avast.com


tshingombe fiston		11:46 AM (38 minutes ago)

Virus-free.www.avast.com


tshingombe fiston <tshingombefiston@gmail.com> 
	11:50 AM (34 minutes ago)

	
	
to me 


ISC2 Security Congress 2025: Call for Presentations
Your Feedback
Submission Details
Date Submitted: Jan 18, 2025
Submission Type: Call for Papers Proposals
Presentation Proposal Status
Status: Complete
Presentation Proposal ID: [Not provided]
Speaker Information
Speaker Name: Tshingombe Fiston
Role: Project Lead
Pronouns: [Not provided]
Feedback Content
Overview of Topics Submitted
Application for Exemption Terms of Section 23(6)
Private Security Industry Regulation Act 56 of 2001: Despite provisions of sections 23(1) and (2), the authority may register any applicant as a security service provider on good cause shown.
Applicant Requirements: Includes age, training, and clearance of any criminal offenses in the last ten years.
Complaints Management Process
Statutory Mandate: Derived from the Private Security Regulation Act 56 of 2001.
Complaint Definition: Dissatisfaction reported to PSIRA regarding the quality of service rendered by a private security service provider.
Complaint Handling: Complaints are processed, referred, or dealt with by PSIRA in accordance with the code of conduct and statutory mandate.
Security Equipment Definition
Types of Equipment: 
oAlarm systems, safes, satellite tracking devices.
oIntrusion detection, access control, bomb detection, and fire detection devices.
oSecurity containers, X-ray, and communication devices.
Improper Conduct
Examples: 
oOperating without registration.
oDeploying unregistered security officers.
oFailure to meet training and uniform standards.
oNon-payment of prescribed wages and allowances.
Recommendations
Continued Education: Importance of continuing education and skill transfer in various fields.
Practical Training: Emphasis on practical training and on-the-job experience to ensure comprehensive skill development.
Feedback: Detailed and constructive feedback provided to improve future submissions and ensure alignment with ISC2 standards.
Conclusion
Thank you for submitting feedback to ISC2 Security Congress 2025. Your detailed insights and recommendations are highly valued and will contribute to the ongoing improvement of our processes and programs. We look forward to your continued participation and engagement in ISC2 events. 


























Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
1 of 18

Cookies
We use some essential cookies to make our website work. We’d like to set additional cookies so we can remember your preferences and understand how you use our site.
You can manage your preferences and cookie settings at any time by clicking on “Customise Cookies” below. For more information on how we use cookies, please see our Cookies notice.
Title
Ms
Accept cookies
Close
Progress
Review
Review
Back
Review
Review
Surname
tshitadi
Your details
Your details
First name
tshingombe
Company name
Email address
Phone number
0725298946
Your request
Your details
Your request
Review
Change
tshingombefiston@gmail.com
Change
Reject cookies
Sorry, there was a technical problem. Please try again.
Request an intellectual property (IP) licence
tshingombe enging/st peace college
Customise cookies
Your cookie preferences have been saved. You can update your cookie settings at any time on the cookies page.
Your cookie preferences have been saved. You can update your cookie settings at any time on the cookies page.
Request an intellectual property (IP) licence
To understand how your data is collected and handled read our privacy notice.
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
2 of 18

Your request
Select the option that most applies to you
Request an intellectual property (IP) licence to use a trademark belonging to the Met or Mayor's Office for Policing and Crime (MOPAC) for any purpose
Details of your enquiry
Letter experimental job experience: theoretical practical n diploma, employees learner n diplomat ,basic advance filing ,posted minim cadet junior senior principle trademarks Workbased - Microsoft certification close Pearson instituts Graduate institute high Education. -Department : DHET high act No,101 of 1997 ,as private.reg high Education reg Certificate No:2004/HE7/004 -accreditation qualities (HEQC),(CHE. continuing and training,act No16 of 2006 amendment,NQF ,act No 67 of 2008 ,as amended , determination phase N1-N3 term ,sect 42(1)(a) training dhet ,N1-N3 juanert ,2024 , dr zimande trade test ,trade occupation revise.. Record transcription academic , ------------------------------------------------------------ -bakc log ,Sita -Ref saqa . -pearson instituts/St peace college instituts, Africa police instituts , Intec institute, saqa foreigners instituts ---------------------------------------------------------------- -Qualification|minimum admin req----------------------------------------------------------------- - foundation| national NSC certificate ----------------------------------------------------------------- Programme| diploma ordegre - bachelor. | International school. Degree |living certificate,accompani | Saqa certificate | national senior NSC NQF | Exemption certificate usaf ----------------------------------------------------------------- Honours. | A recognised under grad Degree | degree module level ----------------------------------------------------------------- Point institute Pearson NSC%. |90-100%|80-89%|70-79%|60-69% |50-59%||40-49|30-39|------------------------------------------------------------- Ncv%. | Nated%| Ucpd%| -------------------------------------------------------------- Faculty humanities :/ Bachelor of arts , Saqa I'd : 62761|NQF level: career opportunities child care communication humanity resource management marketing research , public relations research teaching writing -nated : educare : subject record transcription, personal training facilitator assessor saqa Ncv abet NC's matric technical record : Lecture - ---------------------------------------------------------------- -bachelor of arty in graphics design saqa ,ID : 99332 ,NQF level : career opportunities advertising branding design ,3 D modelling animation broadcasting copy writing desktop publishing layour and illustrations entrepreneurship web design. -Nated : drawing engineering,PC business record -------------------------------------------------------------- Bachelor of arts in journalism saqa I'd : 488832 NQF : level 7 : career opportunities communication editorial work for magazine communication editorial work and news papers journalism , - presenting television social media research . Education actually technologie Nated : media record prensted rwiten---------------------------------------------------------- -faculty of applied sciences. - bachelor's of science in computer science saqa : is 74131 NQF,6 level 7 career database administration IT management net work admnistration programming software developer system analyse project administrator specialist enterprise architecture and open system : - Bachelor of science saqa ,ID 62754,NQF level : Career opportunities business analysis database administrator IT management project management specialist position.it system analyst .. -bachelor science in internet communications saqa ,ID : 6274 NQF : level ,: Career journalism networks administration technical liason technical writing web editing . - bachelor's of science in biomedical,saw I'd : 6275 NQF , Level: career scientifice communication technical position in laboratory project management academic research. Management science communication technical , - bachelor of science honour information technology , .ID saqa : 84566 ,NQF level 8 . Career opportunities: academic it manages programming project administrator specialise Technical position position in data mining and entrepreneurship architecture system analyse ----------------------------------------------- Faculty of commerce and low ,saqa 48858 NQF level , admnistration:career opportunities business business consultant economist entrepreneurs.- bachelor of commerce in accounting: Career auditing budget financial management ,tax consultant account charted financial cost . - bachelor's commerce hr manager consulting personnel consultants recruitment training and development employment relations manager and count. - bachelor's of commerce low business administration entrepreneurs politics . - saqa I'd commerce in marketing manager I'd 488822 advertising sales manager marketing Anat media ,to - tourism management is eco, tourism planning event strategies, market research bachelor's of commerce in business management,saqa ID 84326 NQF level 8 counseling entrepreneurs management. ----------- Faculty engineering: Bachelor Nated saqa I'd lecture learner Bachelor nated trade engineering trade Distance :level 7, degree I'd: instituts engineering council engineering electrical instituts engineering Bachelor: Faculty, police police instituts Saqa instituts: level 7, degrees Bachelor:---------------------------------------------------------------------trade sector training trainer bachelor's Serta ,seta career opportunities guide schools leavers , university of technology,and university leaver,and college leavers . Career ICT : information communication , technology ICT: technical skills research design development testing installation commissioning maintained product software prodt modem via media land wireless.. - computer. |NQF|4|5|6|7|8| total req networking|lev3|. | | Occupation code 263101: developm program 261302 ICT business analyst 261303 ICT customer support officer 313104 computer system technical 263193 system ,test engineering ICT : securite special ICT : project manager ICT : sales represent - systeme representative system analysis project , database admnistration telecommunication,web development network ____________________________ ICT Microsoft office Occupation | recommend It| recommend -13510-projec| language,c#,have,ado,asi,nsd Management| Database ,Oracle,htk,sap java,net .. - 31314 , systeme techniciens| hardware at, ICT support engineering PC network and Eng - description of the top ICT occupation: Project plan organise direct control co-ordinate qualifition account day to day operations of resourcing schedule priority. Task : skill analizing need. - software engineer design modified documents test implementation installation software support with . -ict : assurance ,create maintence manage quality assurance functionalite performance of PC audit ensuring compliance accreditation scheduled qualifications inspection analysed review system data docut, identified potential risk area in security non compliance with stolen detect. - network ,systt plan deployment test optimisation taking responsibility analizing interpretation data model in developm research monitoring assessing improve network , provided network performance. - ICT securite special established organisat ICT securite procedures ensure prevention recovery strategy internal exterior , ensure prevet recovery strat . - customer support Offit provide support Education developm maintence infrastructure resolution technical problem issue may work. - determined hardware response program to meet usase installation appropriate soft , implementation PC network,repairs performance. -business selling compagny using director ,quotat price record order ,monitor client competition active maintenat submitted record business. - continuing and training,act No16 of 2006 amendment,NQF ,act No 67 of 2008 ,as amended , determination phase N1-N3 term ,sect 42(1)(a) training dhet ,N1-N3 juanert ,2024 , dr zimande trade test ,trade occupation revise..--------------------------------------------------------------- -testability checklist at the schematic level. - testability checklist at the PCB layout level , - revising design. Win existing ICT creating a test point report manufacture.,PC designer PCB relay project status information,PLC. - PLC wiring ,main breaker switch busbar circuit breaker SMP digital input output analif input terminal. -reaning PLC wiring diagram, profit bus communication PLC , digital input card diagram ,PLC digital -1. requirement: .letter experimental work based log activities theoretical practical school institutes employees learner , orientation practical school disciplinary didactic work based, -1.1 explanation assessment :trade claim inventory low Triggered: gitlab,/ GitHub /azure Issue test .. -Triggered electronic elektor technologies -Circuit microcontroller ,, -Gitlab ,fail running Issue kananga ,, Engineering tshingombe Project ,committed contributing ,code source ... 36..Explanation: gitlab ,GitHub azure data ,work Running -projects , pinned , issues,merge , request, contributors analytic , - repository analyse: Manage,plan ,code , building, secure, deployed, operate , monitoring. - measured in byte code exclude generated . - percentage , ,- coverage static for main mars 26-jun 24.. September Bi Weet code covered. Commit statict for main may 09-june 24.-august -total 4 commit , average per day , authoritie. Drag up date kananga5 .. overview commit pipeline., assignment, review milestone,time participate: Issues... Project code source , Marketing ------------------------------------------ Azure :,work item ,epic printed Pipe line , ,test pipe -measure in byte: project existing Engineering tshingombe __________________________________ -github : tshingombe Issue contribution, Repository: run project code data source Pipeline: Repository: -Dhet St peace college running projection: Contribution GitHub collectivity; __------------------------------------------------------------ -38. pratical school: instituts research and development learner lecture vocational - isita project back log dhet and DBE umalusi : pratical school trade experiemental workbased Teaching learning student assessor , student educator technical trade student trainer training student learner facilitator technical ,student : engineering businesses study, Isita project subject engineering electrical : national examination learner topics examin: Time table examination ,n3to n6 orientation industrial , plant operations, electrotechnology ,electric trade theory conduct assessment - project isita project total grand : experiemental theoretical and practical,engineering ,orientation industrial trade theory ,orientation industrial plant operations, orientation industrial electrotechnology -Project low examin rules ,in dhet in high school orientation assessment teaching workplace workshop technologie electrical , technologie construction,technologie ,grade 1to grade 12 technologie, Educational technologie circulum,grade 1,6teach pratical skill trade ,,9-12 teaching orientation technologie electrotechnology, organisation supervisor planing manager supervisor Phase circulum,module conductor, insulation,matter ,AC ,DC current ,AC machine ,DC machine instrument, transmission rectified -Teaching orientation industrial class: grade period basic workshop Orientation . -workplace experiemental relate: explanation , isita in dhet in DBE teaching workshop work class engineering vocational career Guidence -Framework work qualification saqa: Undertake material engineering , Teaching qualify n3subject isita project Council trade, orientation industrial trade occupation trade isita workplace manufacture city power power: technology trade electrotechnology letter topics CVS ,, in DBE teaching technical DBE orientation industrial Eskom ..city power -organisation supervisor duty Eskom city Power Under printed learner assessment self assessment peer in dhet project. ,in dbe teaching grade circulum, orientation industrial Eskom expo science : teaching teach grade electrotechnology orientation, electrotech industrial ,social project computer Back log project skill fund .. ,- orientation industrial CDs ..close tendered-lesson social worker practice Marksheet student orientation industrial time table ,student organisations planing supervisor time table , student educare time time table , student Education,student Engineering studies time table, : student policing traffic , business, pratical office school student marksheet workplace experiemental learner close bid : close material trade theories in dhet in DBE isita ..umalusi - DBE subject workshop grade to working CVS circulum study in trading isita _______________________________ - teaching and lecture Irregularite Pratical material candidate processing learn Regulation back log after Assessment center -non attandance subject appear letter application letter workplace in dhet conduct learner project in dhet Afric instituts training shalom traing ,out mark term Non attandance: subject non registered Irregularite material: subject engineering science , mathematics,electrotechnical , industrial electronicien dhet in DBE ,ucpd Record academic years . -Total subject ,to back log project Management system information learn , policy in DBE trade theory subject registration second additional subject Rwiten subject : extra circular in dhet in DBE pratical regulation . - practice police , orientation life teaching , literature mathematics ncv teach vocational guidance in DBE level 4 certificate pratical skilled panel control wiring electrical DBE workshop development: teaching workplace to trade in DBE panel ,,teach ucpd irregularity project back log printed ... Introduction technologie,workshop electrotechnology , electrotechnic, electromechanical manufacture process 1.3purpose: -planta d shop layout , -insustrial safety , -ferrous materials , -non ferrous materials. -meeting furnaces -properties and testing of metals -heat treatment carpentery . -patter. and core making -foundry tools and equipment -mold and core making . -casting -forgi g . -hot working of metals . - cold working , Sheet metal work,lathe machine drilling plane and sloping -powder metalling . - inspection quality 2.explanation :Manufacturing Engineering: process planing , Claim 2.1 process planing , 2 process sheets, 3 route sheet ,tooling , 5 cutting tools machine tools , traditional,numerical jogs and fixture ,7 jigs and mould ,manufacturing information generation , CNC port program ,10 robor programmers ,11 flexible manufacturing systems ,FM's group , integrated manufacturing cm. -3. Explanation:Production process : process planing. Manufacture process , classification of manufacture row , -primary shopping process size casting melting . -secondary machining process job understanding operational hot working processing forging rolling hot sprinning extrusion hot drawing. 4.explanation cold working process : Cold forging cold rolling heading cold drawing wire stretch forming ,sheet metal working Piercy punching lancing notche. ,coming sequence ,deep drawing. -5.explanatiin join process: reffiling assembly, welding platisc or fusion , -soldering reverting screwing welding plastic,press fitting sinter , bonding shrinking fitting ,explosive welding diffusion welding key and cotter ,coupling and nut and bolt joint .- surface finishing process. -6 explanation:honing lPpi g supper finishing belt grinding, polishing tumbling spraying ,pouring inorganic coatic analizing ,sherodizing parkerzi g galvanizing plastic ,metallic . -7 product simplification and standardization: policy a counting procedure personal policies performance evaluation control of expenditure safety aspect security procedure regulation,design manufacture material and part supplies ,methods of testing drafting method abbreviations -inspection and quality control ,size shape other dimensions involved measure. -mechanization and autonomy Control device increased productivity reduced cost of labour and dependence on labour short improve quality reduce in process inventory reduce dependence on operator in tease safety reduce risk humans fixed automation programmables automation flexible automation . -fixed automation cam . -Product system , manufacturing system . Detailed design prototype development test simulation design manufacture. - computer manufactt..- - factory level production management planing , production management material Requirements planing . - bill of materials capacity planning , inventory - CIM technologt compl networks system design and analysis distribution process , modelling and simulation expert system quality engineering. - CAD :soliD modelling variation computer .-meeits of a good plant layout , reduce machine how workflow process inventory is , manufacture time relatively less floor area is required , material handling is less. - explain types of layout ,fixed or position -men tools component yes , workplace yes ,finished product to store -explanation S.No| line or product layout | process or function Industrial safety ,safety precautions while working different
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
3 of 18

hand tools . Approved : screw drives wrenches ,hammers files chisel,saw tap -engi seeing material yes = metallic material yes or no. Metallic yes , Metal yes ,feroos or non ferouse , steel plain carbon ,allot , Cast ion grey while react metalloid ductile, - non ferrous , aluminium copperwood papperleather ,mineral cement class graphic, - -iron ore heanotite Fe304 colore red ,iron 70%, -magneite (Fe203, colore blanc 72% -lemo ite ,colore brown. 62% siderite ,brow,48% _______________________________________ _-explanation market forms of steel structure shapes : laball _free cutting ,c=0,13max,MN=0,7-0,12,,S=0.16 -steel quality ,carbon tools steel Anees ,plain carbons , - Properties: application % tensile strength kg/mm.sq -Typical blast furnace: -Blow yes ,yes stove yes ,blast furnace yes ,slag ,oxygen yes ,mixer , .-basic oxygen produce yes carbon yes Stell ,bessirer convert bessure ,, Basic open heart basic operation , acide open heart ,, electric furnace yes acid , pudding process wraug iron , acide crucible ,steel ,iron ,mealable ,steel , , ________________________________________ Tools Plastic plaster ,5wax - factor effecting selection of pattern material,-number of casting to produce metal pattern are prefu required large in number ,type of mould process methods ,of molding hand or machine ,6 degree of dimensions accuracy surface finishing requirements minimum thickness requirements shapes complexity piece cost of pattern chances repeat order . -types ofpatter : -properties of moulding sand refactoring permeable cohesive green ,found sound casting test moisture content test clay chemical composition of sonde ground shape and surface texture of sound grand size distribution sans specific water absorption capacity permeability shatter index ---_____________________________________ Explanation: welding process ozyfuel gaz ,air acetylene welding oxyacet, oxyaceten ,oxy - hydrogen welding pressure ,-arc welding process car on arc welding ,sheelded metal arc ,welding , submerged arc welding ,gas tungsten arc welding , resistance welding ,solids state ,welding process theemique radiant energy welding -explanation: claim low machine used in sheet metal shearing machine,bending machine, grooving machines peini g machine ,beading machine ,swaging , machine ,blurring machine,double seaming machine. -types of press -method of operations an born press .methods of power source Manuel press mechanical power hydraulic press , -fitting : explain introduction device equipment tools marking tools , measure device measure instruments, supporting tools holding tools striking tools , cutting tools ,tightening tools .. -explain : inspection and quality control: checking components or product with requirements specification ,tolere Ce on port , interchangeable dimensions. Size numerical value lengthimjte size : .-uppee deviations algebraic difference between the two maximum limited of any size ,low deviations,mean fundamental deviations ,tolerance -fits allowance fit difference hole size and shaft size allowance. Fits yes clearence fit yes sliding fit yes or running fit yes ,,, Interference fit yes or forcefit yes or strink yes press fit .. -control chart : used quality industrial yes maintenance yes continuous yes evaluation yes , manufacture yes, -statistical control yes ,device cast yes , -surface finish yes ,routines primary yes ,waviness profile ,lay,flow -----_____________________________________ 4.1requirement installation electrical guide ,, scheneider electric-explanation : characteristics of particular source and load . - photovoltaic installation , -residential premise and other special location . -WMC guidelines measure. -General rules of electrical installation statutory regulation ,0V to 1000V ,AC ,,0V to 1500, ln public network , compliance with national regulation ,IEC 603643, -installes power load : characteristics values of cos . I=IA.cos$/cos$.. power factor before compensation and cos alpha factor after compensation being the original. - heating factor of 0,8 recommender number consumer ,5 story's apartment building with 25 consumer ,each having 6 kva installed . - the total installed load the building is 36+24+30+36+24=150kva, -thw apparent power supply required for building ,150×0,46=69Kv, - magnitude of current in different sections of the main feeder supplying vertical rising ground ,level cross section area conventionally spece , 3 floor current entering the rising main at ground level , -159×0,46×1000÷400×√3=100A -(36+24)×0,63×1000÷400×√3=55A. -Possibivilty of improving power factor ,extension to the installation installation constraint. -In=Pa×1000÷U×√3, Pa=KVa ,rating the transformer. I=phase -to phase voltage at no load in volts ( 237V or 410V) in ampers , In =Pa×1000÷V=, V= voltage between LV terminal, Simplified equation for 400v(3phaae load ,) In = kva×1,4 ( IEC 60000 power , -explain choice and use MV equipment ,MV / Lv transfo for use of MV , equipment choice of MV /LV ventit in MV substation, - substation including generator and parallel operator of transformer. Generator alone operation not working in parallel with the supply network. Generator in parallel utility supply parallel operation of transformer , - type and constitution MV/diatrt,-differenr type of substation,indoor substation ,outdoor substation. I'd=Uo÷ZS,,0,8.Uo÷ZC.. I'd=fault current , Uo=nomminal phase . ZS=earth fault current , ZC=fault . __________________________________. 5.Scotland qualifications Explanation -basic software engineering concept to solving electrical and electronics engineering problem. -writing and testing and documenting I/O. - Program using the basic structure -deaign using flow charts or program design language. -Write test and documents linear programming using I/O statement. - Write test and documents I/O Programmation incorporating subroutines . -table Boolean expression for logic gate knowledge skil . -hexadecimal number system. -conversion , between hexadecimal and binary gate symbols. -teith table associated Boolean,and /or/not ,exor/and and nor . -combibation logic , expression in sum of products.produxt minimise logic ,draw minimised digital, -sequencw logic . -bloc diagram of sequential machine need for memory in sequential machine need memory in sequential logic latch ,JJ and D bistable elements. -asynchronous and synchronisation operation counter and shift register circuit using bistable . -lofic family device characteristics. Circuit . Build and test counter and shift register circuit - evidence requirements should -single line schematic for 33/11kv substation, -liar standard fault level for local Sister voltage (250MVA at 11KV ,100MVA at 33 KV, -pee unit calcul : concept of infinite busbar by grid system working with ,3phaae short circuit by grid system working with 3 phase short circuit worst case scenario calculate fault level for a fault on an ,11kv feeder fault level , fault 11kv feeder from a busbar it is expected that the circuit used will smillar to infinite system feeding 33 KV line with inductive reactance and transform per line excepted one generator should be connected to the ,11kv ,, .S1=250MVA,,U1=11kv,,Z=√R.R.+z(w).. V÷I=11÷39,3=0,279,,ohm ,,, =100÷5,24=19,083 ohm .. S,=V.I.√3.. I2=250÷11×3=22,72KA,,,,39,3KA I1=100÷33×√3=3,039==5,24KA.. -explain next generation higher national electrical engineering : utilisation electrical power transmission lines and complex waves, -Porformence calculation to determine each Zo ,V ,B .. - Voltage current and power for one fill ZL>Zo,,,ZL> -ID conditions then action ifco dition gold's . -ID conditions then action if condition holds -else Action if condition does hold. -End if Case condition of Case 1:action for case 1 Case 2:action 3 for case2 Case n : action for case 2 n End case Condition based input portion use of build process such - write . -test condition documents I/O prog using iterative loop statement. -repetition For variable ,from start to finish in steps of value . Do. -sections to be repeatlt perform End for . -fundamental of control system and transducer . -high level Engineering software. -soffward engineering process creating file editing files process constant and variable. -operatoe and -statement :input output documents. - evidence requirements , satisfactory write one linear prog. - input and output statement different type of variables arithmetic operator . - knowledge skill test and documents. Relation operator =,|=>logical operators -vooleen express. -branxh statement ,if then if ,. Then,,else,,case,,of,,port configuration readings. -outcome 3 : Flowchart pseudo code : for ,do,repeat, until,while,loop. -statement:for do repeat , until while . -looo to manipulable data array -out put array , data array read port data into . -testing of iterative loops ,test plan and actual . - if then ,else If of either while do or repeat until for next to - Advanced unit specifications: engineering mathematics 1, qualifications Scotland,level6 -outcome outcome provide evidence following skills skill time . -solved 2 problem on degree radian . -A.sin(nx+-a)=, or ACOs (nx+a)=b -blow , logarithmic -log+logy=logx.y ---logx-logy=logx÷y p.logx =logxP. y=A×lnx y=A×log x..base10 Convert rad =Teta ÷180×π - A×sin(nx+a)=+-B - A ×cos (nx+alpha=+-B -y=a.expx - explain ,,x =log .base a inverrse function .y =a.exp x y=10 .exp x y=e.exo x ,,x = log . y=e.expx and ..x.exo =log..e y - solve exponential ( 5 .exp , = 95 ,,,x exo 3.5 =0,1.. log .base 10 (x+2)+log .base (x+4)=0,5 .. -Apply mathematics technique to vector and complex numbers ,2 d d=√(x2-x1)(x2-x1)+(y2-y1)(y2-y1) -D:,,d=√(x2-x1)(x2-x1)(x2-x1)+(y2-y1)(y2-y2)(y1-y2)+(z1-z1) -scalar ,,ab = b.a ,,,a(b+c)=a.b+AC -b.b-4a.c< - cos(x+B) Sin.a ×sina+cos.cos alpha =1 -sin2a=2sin alpha.xos alpha-cos 2 alpha = cos .cos alpha -sin - driver , differential , hyperbolic a.x exo ( ax+b).exo n ,,,ln ( ax+b),,,e..expon (ax+b) -sin (180 degree +Teta ) = sin .Teta Sin Teta + cos = 1 , sin 2 a alpha 1-2 sin .sin a ,,,cos 2 a ,alpha = cos .cos a - sin 2.alph -_________ Hyperbolic identify e.exox = cos hx + sin .h.z e. - x = cos h x - sin h x Cos h.x 2x-sin x =1.. - sin h ( x+-y ) = sin hx .cos by +- coshx sin y -cish ( x+-y)=cosh.z coshy+- sin h x sin h.y -sin 2x = 2sin h.x .cos hx -cish 2x = cosh.x+ sin h .sinh x. ___________ Integral .u (dv/dx).dx=uv-.. integral.v(du/dx).dx Equation: Integral .x.x.e.e. dx Integral 3 limited ,x dx .. Integral ..b..a √1+(Dy)(Dy)÷dx()...dx __________ Introducing ,j in term ...j.j =-1,,j=√-1 Introduction Euler relation e..exo j Teta = cos .Teta+j.sin Teta ..and Z=r(cos.teta -jsin.teta ) r .e.-j.teta For ,-10,(-2+j5),(1-j)(1+3j)..that Z1 ,Z1=6,e .j π/6,,and z2=9e..-jπ/3.. -Det,Z1.Z2..and Z1/Z2.. -introduced moivre theorem ( cos .Teta +j sin Teta) .n = cos Teta..Z.exo = r .. -solved involve express (√2+j)5.... -solved ,Z..... ---________________ -diffentiatiin technic to solve engineering problem. a.x .exo ,(ax+b).exo..n -dy/dx=Dy/du,xdu/dx -apply chain module to function.. (3.x.exp4+7).exo,,sin(t.t.t+1),,5 ___________________ Use differentiation technique to solve . y(x)=u(x).v(x)...state product quotation.. Dy/dx=V×du/dx+u.dv/dx..or y'=v.u'+uv' y(x)=u.(x)÷v(x)-dy÷dx=v×du/dx-u×dv/dx÷v.v.. -Vu'-uv'/v.c -solved ..x.x,,sin (4x+9).e.-3x,, t.t-1/t.t+1,,.. Solve differential x.x+3(y)(y)+4x-5y=, linear factor quadrature improper. .-solved infinite integration .. Integration. (5x+2).exp6 dx,, Integral (x)√1-x.z..dx.. -solved second order constant linear differential. a×d.d.y/d.x.x+Dy/dx+cy=f(x).. Use partial differential f(x,y)...z=f(x,y) , explain that double integration involve integration,f(x,y) Integration.integration .r..f(x,y)dy.dx.. Region integration x-y,, -solved differential equations Laplace transform introduction la place transfo ,f(t) F(s)=integration ,e St ..f(t)DT.. ,,ergent value vector solve linear , |[A-lambda],, matrices ,,,x of eq Ax =lambda x.. -problem manipulation of matrices ,sq, identified transpose argument.. - solve problem use of Serie representative Taylor Serie . f(x)=f(xo)+(x-xo)f'(xo)+(x-xo)exp2,f'(xo)/2+(x-xo)exp n,f(n).(Xo)/n| introduce mac Laurence . f(x)=f(0)+xf'(0)+x.x.f"(0)/2|+...(x.n.f(n).0/n.. ,eg ..e.x ln (1+x),,,e.x tanx.. Deviations a linear approximation,polynoy.. -solved first differential equations.. Dy/dx=f(x)g(y).. -y=Vx,,or y=ax+by+c Dy/dx+P!x).y=q(x).. -voltage flow A 1=RF/R1,,Av2=RF/R2,,AVN = Rd.. Vo=(Av1.V1)+(Av2.v2)+... Vo=RF(V1/R1+V2/R2+.... Amplifier AV=Vo/(V2-V1),,AV=RF/R1,,Vo=RF/RI(V2-V1) --id V1...I.. ________ 6.Engineering science. Structure : Stress =£=F/A,,,,strain €=∆L/L Young module ,E=¢/€,, Factor of safety = ultimate load / safety working load.. --------------: Pneumatic: pressure force area ,P=F/A,,area circle ,A=π.r.r ,,,A=π.d.d/4,,=. π=3,14,, -mecanisme : Velocity rotation, VR=spped of input /speed of output,, Torque ,T=F.r Circular of circle ,C=π.d Moment of force ,M=f×l Prince moment ,sum =0,, condition.. -7. explanation engineering science Explanation: :variable temperature soldering iron is shown the soldering iron use a two state control system to turn heating element on and off,and to monitor it output to maintain the desired temperature. - completed the control diagram for the soldering. -desited temperature>>>, control unite ,>>, temperature sensor,>>>soldering iron temperature, -viewi g platform.. -explanation: A beam used in the construction of the viewing platform. Calculate the magnitude of the reaction at B , calculate magnitude and direction of the reaction, - calculate the magnitude of reaction at B ,, Labalked , (24000×1.10m)-(3500×0,30) (F1×L)+(F2×L2)= 264000+10500=35000×L 265050÷35000=75,70m/n ------------------------------------------------------------- 8.Explanation: A lifting system to allow worker on construction to carry out essential maintenance is being . A warning system that will ,sound an alarm when the platform in motion is two button used to control the upward and downward motion .. -input /output. | Operation-alarm sound | A=0 -Maximum load. | B=1 -bouton c Pressed, Bouton depressed| C=1,,,D=1.. .-propose design has the following specifications condition must be met the alarm z ,will not sound unless the gate (A) is closed will not sound when weight on platform will sound when either button ,c or complete the Boolean equation for the alarm .. --------------------------------------- Explanation: calculate a suitable value for RF: Vi=RF/R1(V2-V1),,, Vin =(Vin+Vin+Vin, O,31+0,53+0,47=1,32 RT=1/33000+1/3099+1/30000=o,ooooo90960 RF=,,RF=Vo×R1/V2-V1=, 1,2×0,09999096/1,32=0,0099910 ---------------------------------------- Explanation mechanical engineering must design a pneumatic circuit meet the flow,when push button VA and VB not pressed ,or when. Not pressed lever ,VC state double acting cycling must, outstrok {A`.B.`+C -a short time after cylinder outstrok must instroke automatically an initial design the circuit...----------------------------------------------------- The program to control the cylinder must follow criteria oustroke =A`.B`+C the cylinder must remain oustroke 15000 milrsecond ,209 milrsecond after the command to instroke the system start monitoring. -------------------------------------------------- Explanation -An alternative motor with moseft driver in also consider the mosef has a resistance of 2,3ohm fully Saturated and the motor is rated as 0,49 w at 6.0 I=0,40÷6,0=0,07 I=V/R=6,9/2,6=2,60,, E=V-IR 6-0,182=5,818V ------------------------------------------------- As part of the car control window are to be open and automatically the following control produced ,by - explain with ref to the circuit above the impact switching out 7 high then output 6 high then output 6 high has on the motor----------------------------------------------------- Program below in Pbasic ardwno code is know to have fault.. - main if pin 3=I then jump If pin 2=I then main If pin 1=0then man Jump:high 7 Pause 15000 High 6 Pause200 Low6 Goto jump -void loop (){if digital read (3)== high {jump();} else if (digital read 2, ==High ){loop ();} else if ( digital read (1)==Low ){ loop();} Void jump (){ Digital write (7,H,G, Delay (15000) Digital write (6,high delay (2000); digital write} - -------------------------------------------------- The camera is placed on the outside car and a talk of clear plastic is place ... ------------------ Ligth sensor is used to identify when the plastic is dirty when it sense a value of less than 219 lux a motor spins to move clean plastic In front of the camera the control , - calculate the value of aR1 required to saturated the op - Amp positive 219 lux , R1=Rcc-R ,,,Vo=(1+RF/R1).v -motir requirements ,55mA of current ti operate the op - amp saturated to 78% of the supply voltage vbe is ,0,70V saturated transistor RF =,,,explan 9,0055A÷0,70÷0,000795÷6÷9,, R1=Rf÷vo÷v2-v1, = 0,01119... ------------------------------------- Truck ligth system ,completed logic A,B,C,D,E,F, --------------------------------------------+ Batteries power portable flood light are to be installed the construction site to allow work to be completed in lower ligth ,the battery is rated at 15V,13A,kB hour useful energy is 2,32 MJ Completed the energy audit diagram for the portable floodlight batteries slowing the input and output energy .. ------------------------------ The diagram below show part of the design for the framework that supports the floodlight. .-calculating using nodal analysis at node A,and B the natural force in ,AB,AE,BD,and BC Member | magnitude. | Natural AB. |. |tie AE. |. | Strut BD. | BC . explanation= L=355×cos 30=321,73nm AE=455×sin39=227,5Nm BE=455×cos 30=227,5 DA=(455×30 sin ×30 sin )+(350,sin 39 =321,73+227,=549,29 ---------------------------------------------------------- The force w represent the weight exhibition and is acting ,1,4 m from point B ,the distance from A to B is 3,46m Draw a free body diagram of the force acting on the exhibition calculate the force , 650×sin 120° 776×sub 120°-force acting on the connecting ring Q=(530×cos65°)=223,97 P=650×cos 37°=447,2 T=776×cos48=539,054 F1+f2+f3= -------------------------------------------- d) replacement exhibition is to suspend from ceiling some positions two cable support the new exhibit hanging from the connecting ring are replaced Hallow aluminium.. The 2.7 long tube has a diameter of 72 mm an walk thickness ,,2,5 mm it support a load of 32,7 N calcul the charge in length tube it is load new exhibith . A= π.d.d÷4= 3,14×72÷4... €°2,6-2,5÷2,7=1,92.. £=F/A=32,7÷56,62=0,62.. ----------------------------- Engineering civil
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
4 of 18

compact , calcul the total torque produce by motor , - described an advantage : described the purpose of. -funal design structure used to support the weight the boring . Completed using nodal analyse table of the missing force their nature of the missing force their nature . Member .| AB | AC| BC| BD| CD Force |. |. | 583kn|566kn| Nature | tie | strut | strut | AB=(550×61)+(550×61(---------++------ Calcul the force that player strikes the ball product a torque of 295 NM (0,34×295)+(0,84×295) Force extension graph ropes Calcul the strain energy in the rope when it experience tensile tension 159 .. --------------------------------------__----_ An electronic engineering design digital logic circuit for Boolean equation , Z=(A`.B`)+(C.D) - draw the digital circuit for the .. Design for an operation amplitude op circuit is Calcul gain for circuit when V input voltage is ,9,11V ,,∆V=7,59÷0,11=69.. Determine appropriate resistor value for E 1,and RF : AV - R1/E1=59-1/R.. Integrator §vout =1/RC.integrator .Vin St ... f=1/2πRc.. 555,timer stable .. Marj = T1=0,7(R1+R2) T2=9,7 R2.c Freq° 1.44/R1+2R2c.. -------------- Calculate t output voltage of the difference amplifier amplifier when the ligth ,calculate the minimum output voltage requirements from Amol to cause three , d) described effect adjusting variable resistor will have light level .. - the LEDs ,are at their most offence when current of 52 mA ,flow each they also found 2,3 y occurrence , Calculate the required resistance for protection resistor ensure maximum efficiency ,VCC for the comparator is set to 8.0 v the comparator saturate at 75% .I'd = 52 mA ,,vs = 23v ,,, ID,= 9,0952÷8=0,93,, 23/0,04=575 ohm ------------------- Future solution involving used of microcontroller is also tested an output pin on the microcontroller activate bank of LEDs .. From sensor input ,microcontrol yes ,,pin 6 ,, 1/R1-RD )+(1/R2+rd2)+(1/R3+Rd3)+(1/R4+Rd4.. ------------------- Explain with ref ,to code circut the effect on the LEDs ,when the reading from the analogue sensor rises from,5 to 200 -------- The logic circuit show below control valve that provides water for the plants .. ------------ Explanation pneumatic circuit need to feed wast into incidence part of a system to produce electricity safety reasons ,be bar material is pushed in the system cylinder outstrokes allows . . càlcul the minimum base current in requirements to switch on the relay ,,,, In =0,7/1,5=0,4667A.. .- calculate the voltage requirements across the resistor assuming vbe is ,07 v ,,calculate the current through the variable resistor , V=6.0.1,5/2,5 --------------------- - by using pulse width modulation the LEDs can be mode appear bright or dim Code for the test is below in Pbasic and ardruuno Main: into sensor =A9 redax Pino,Bo. Int led bank =7 If Bo<50 then level 1. Void set up (){ If Bo<100 then level pin mode led bank output If Bo 49 value 99 et value design concepts --->computer>>>display.. Use , existing design,use existing formula,modify , generator - Vmean at 0°=√2/2π×VRM×(1+cos alpha ) √2/2π×240(1+cos 1)=108,038v Meant at 90°=√2/2π×VRM×(1+cos alpha ) =√2/2π+240(1+cos90)=54,019v -Vmax=√2×Vrm =√2×240=339,411V IRMs=√2/2×irmax = 10,60.. ----------------------- P2=√P1.P2 =√104x×800 V1=Vr1/N=0,4×60/550=0,0436mm. m=P1.P2= 104×0,04364=0,05416kg V2=m.R.T2=0,05416×0,287×292=0,01574m P2,288,44 Vs =v2=π(D2)/4.D=0,01574=π(D2)./4 P=2.n/n-1.P1.V1.[(P2/P1).exp .n-1/n -1] =95,69kw - prerequisite= pact /n = 95,69/0,88=108,74kw -at ,44,8°c ,,h1=188kj/kg at 93,5°c, H2=392kj/kg At 1500kpa , 350 °,, H4=3148kh /kg .. h plant = ms (h4-h1)/mf×hv. ×100/1 =5400(3148-188)/600×3200×100/1=83,25% EE=ms (h4-h1)/mf×2257 =5400(3148-188)/600×2257=11,803kg,steam /kg fuel Qecon = ms ( h2-h1)/mf 5400(392-188)/600=1836kj/kg At,1500 kpa ,hf = 846kj/kg and ,hfg = 1946kj/kg = 2595,5kj/kg Q,super = ms ( h4-h3)/mf 5400(3148-2595,5)/600=4972,5kg/ Q,flag=m×.cp.×∆t (15+1)x,1,045(210-24)=3109,92kj/KJ _______________________________________ Qin (KJ/kg) |. out KJ /kg |. %-------------------------------------------------------------- Qfuel=. | Qecon=1836. |5,74 32000. |Q Eva=19831,55. |61,97 |Super. = 4972,5. | 15,54 |Qflugas. =3109,9| 9,72 | Unaccount= 255 |7,03-------------------------------------------------------------- 320. | 3200. |100 ---------------------------------------------------- ~=C.p/CV=1/0,712=1,4 T2=T1(V1/V2). exp ,alpha -1 = 28(13/1) ,exp ,1,4-1 = 806,26k T2=P1(V1/V2)=10,325(13/1),exp = 3674,83kpa. T3=T2.P3/P2=806,26×5000/3674,83=1097k. Q2-3=2/3.QT Q3-4=1/3QT. (2/3).m.c.v(T3-T2)=(1/3).m.c.p(t4-t3) 3×0,712(1097-806,26)=1(t4-1097) T4=1511,01 V4=T4.V3/T1=1,3774m T5=T4(V4/V5).alpha -1 ASR=1-Ts-T1/(T3-T2)+aplh(T4-T3)×100%=62,47% - explanation cpd, continue professional development , Scotland outcom qualifications,UK qualifications: -13. research on papper libry text book Bibliotech: Reference:resource -uk magazine for electronics technology and computer projects . EPE , everyday pratical electronics Order book ,8$ ,,10$ ,,3euro ,200rans -Projects and circuit,series features, regular and services -Topics : Scotland magazine second voice recorded module: record two ,four eigth different message clean and clutch free line level audio output can feed an amplifier or PA system ,8 bit recording quality user selected bandwidth.. - Scotland:Applied skill engineering electric , Engineering electronic engineering science , mathematics engineering -Topics : scottland outcom PIR - triggered mains switch ,use a domestic pie system to switch any mains -power device ratesup to 10A..-topics : multti function , intelligent remote , controlles dinner the ultimate dimmer project using a standard handheldsr remote .. -topics teach in 2011 part :logic circuits - our to be missed introduction to gates and flip flops.. Microchips microsti k development board.. -10.constructional project: Design concepts: Hk828 module record 40,60 -getting the messat : module jump random sequence. - how it works: function heart module architecture -labelle the block diagram of the hk828 voice recorder chip while the recording process relies on audio sampling the audio is not stored digital but used and analoguw sample and hold system the analogue sample stored sample .. -samplung rate : capacity array means that HK store total ,8000samplw per second total ,262,144/8000,,42000 sample ,4200 total ,262,@44/42000, recording bandwidth fidelity propertionaj sample ,2khz , samples ,just 4khz.. -circuit details , 4,7 if ,,and 220kohn ,19pin preamp and AGC,, circuit vis couple 29,,5,8hz,,47kohn , switch logic signaj teeminaj . -parts list multi message voice : 1,PC board code 797 available Epe pcb service 110mm×57mm. 1).electre microphone insert . 3) ,3 way terminal blocks PC mounting 1), 2way terminal block PC mounting 3), 2 2- pin section of Sik header strip. 3 jumper shunt 1 ,)28-pin Dik ,ic socket :15,24mm spacing. 1)8-pin Dik ic socket ,7,62mm spacing 1)2.5mm concentric DC power plug ,PC mounty socket ,PC mounting _semiconductors :.1 HK828 voice recorder IC (ic1) 1)LM358 dual op amps (IC2) 1)78L05. +5regulator ,reg1 1) PN2099,PnP transistor Q1. 1) 5mm green led (led1) 1)5mm res Les (led2) 1)1 N4004,1A diode ,D1 -capacitors : 1) 2200uf , 16V, radial wlectr. 1)220uf, 16V radial elect 1)22uf,16 v radial electric 1)10uf,16v 1)4,7 if tag tantalum 1)220nf ,100v MKT metallised polyester. 1)100 nf ,multiyar ,monolithic ceramic , -resistor : 0,24w,1% 1) 470,kohm, 2)100,kohm 9)22k ohm 1)100 k ohm .. 1) 220k ohm 8) 47 k ohm 2) ,10 John 2) 680.ohm 1) 47 ,ohm --------------------------------------- 12) constructional project : IR remote control ligth dimmer module,the circuit is based on a PIC 18 F ,1329-U/SI microcontroller ,a triac and and IE detector ( IRD1)the two RGB ,LED. give user feedback in the operation and setting. -power supply: micro synchronisation waveform connecting neutaj ,,derived from the mains via a 1kohm ,5w , resistor and a 470 nf (X2) capacitor and resistor act as current limiting impedance for association ,5,6v zener diode ZD1,the supply works as follows,for positive half cycle of the 230v,AC current flow via zD@,the ,470nf ,, capacitor Nd 1k.ohm ,5w resistor same time , electrolyte capacitor capacitor is charged ,up then for negative half cycle of the mains current flow ,via D1,the 479nf capacitor and the 1 k.ohm resistor ,the results is that the 470,if capacitor is charge to ,5,6v-0,6=5V..DC Impedance of 470 nf ,series 1 kohm ,,micro,,5v supllie,up 23ma ,IRD1,, supply bcircuit two RGB LED are connected six cathode connected to a different I/O pin the common anode two RGB LED connected together 5v,single 1 kohm .. IR remote are amplified filter decoder received module IRD1,,the 1000 ohm ,resistor capacitor are module to decoupled it 5v supplies the data output at pin 1 of IRD#,is connected to pin 10 of ic# and configured.. -construction : intelligent dimmer is built on a single &sider PC board code ,799, measure 76mm×50mm .. _____________________________________ Part list intelligence dimer , 1.PC board code 799,acat from Epe service ,size 76mm×50mm 1. Ip65 sealed ABS plast case Witt clear lid ,size ,,125mm×85mm×55mm(jaycar HB-6246) 1.flush mount ,3 pin main socket ,jaycar ,PS 4094 similar .1. IEC make chassis connect with mounting holes jaycar ,PP-4005 1.)10 MHz crystt(x1) 1)47uf, 5a inductor (jatcar lf-1274 1)4-way Dinklage screw terminals plug ,jaycar ,HM-3124 1(10A,ISC main cord -semiconductors : 1 .pic 1 1.ie receiver 1. -capacitors: 1470 ,16v electrolyte -resistor ,: o,25w - miscellaneous: 3M3×25mm nylon screws (to secure PC board. 2M3×15mm,nylon screw ,for IEC connector 3 M3 x12 mm nylon space , 10 M3,nuts -1)1 ok mm of ,0,7 mm dia times copper wire for links ,, 1)200 length ,3-core mains flex (250v,,10A ratt, 1) 4,8 mm res spade conductor,fully insulated , 14,7m yellow spade connector duly ,5 )100 cables tie Add,part requirements testing 1)12 AC ,500mA,or 1A plugpacj, 1)12v,,300mA,ligth bulb (jaycard ,SL 2656) -construction project:PIR -triggered main switch: Futer detector ,20m away ,two pair telephone cable , switch unit also provide 12v power PIR detector cable switch main rates relay to switch the power twin 239 AC ,outlet ,relay contact rated 20A, switch. , 10A limited,10 different ,, switch power load any time regardless ,switch units fits ,UB2,size plastt box ,, switch itself battery operated and switch low device if about ,80mA,12v .. :how it wot:block regulated 12 volte power , internal circuit plus unregulated,17C ,DC power virtual contact ,which are normal close ,open when detector Sens movemt. Contact unit also connected ,12 line detector contact open R1,and it's output switch low ,this action issued set reset ,flip -floo ,normalt resting .. Switches intu set state Q high used a transistor driver circuit energy relay ,power switch 239 AC outlet and loads, at same ,sR flip flop switch to A Output multi stage remove reset counting pulse from simple clock oscillator ,which run 0,9374 the reason odd frequently clear , the binary counter has 14 stage but make only from internal flip flop 4 to 10 (04-19)and 12 to 14 (012-014) we rotary switch S2 to select one 10 output ,si rotor of S2 kept until the selected counter output switch This happens a soon counter has received the appropriate number of clock pulses,eigth in case 04,16for O5for32,for0664,for 07 switch high after 8192 pulse been counter ,selected counter switch low situation coupled via capacity c1, resistor R# inverses I..-main connector ,three connector ,iex green wire , yellow main wire ,T1 longer ,same wire 160mm , outlet socket .. - insulating shield ,two outlet socket insulation material pvx , -final assembly: step the two plug into socket make noctch , completed box ,, -Pir : testing or adjust.. In used .. -parts list trigger main switch, PC board code available service size 147mm×69mm 1)ub2-size plastt box ,197mm×113mm×63mm 1)PIR sensor 2)heatsink ,19mm,square t o-220 type , 1pushbutton switch spst (S1) 1 rotary switch,1-pole ,12 position (S2) Point knob with removable pointer insert . ,1)6- pin Rj12 socket ,PC board MTG (con1)or ,3way PC board mounting termi block 1) 14- pin Dik ic socket ,for I 1 16 pin Dik ic socket for , 1) power transformer ,12,6v/2va,2851 type 1)29A mains rated relay ,chassis MTG (RLy1) 1)IEC main plug , panel mounting 2(mains sicker flush mounted 4 main socket ,flusg ,15 mm long ,M3 tapped,. nylon M3 machine screw ,10mm long csk head ,N3 machine ,6mn,long pan ,solder lug ,,nylon cable tie 100m ,25 mm length ,6 mm diamt heatsgrink tubing , -semiconductors: quad scmit band ic1,4093B,,4069 binaicounyer,12 regulatory,PnP transit,led green silicon ,, - capacitor, : resist -capacityi -explanation: Project a plethora of , together with the pic programming , -PIC training course. , training development course enhanced ,pic programme module,-bool expirmenting . Experimenting with PIC microcontroller,this book introduces pic programming , jumping straight in with four easy knowledge 8 binary. Explanation logic - digital logic , circuit basic building digital circuit and system . -possible , switch and lamp logic , -lofic gate with inverted output ,, Y=A+B Y=A.B Inverter ,,y=/X.. And gate ,,or gate ,,and gate ,,nor gate. ,exclusive ,incluve gate.-Bistables ..D type bistable , D-typpe bistable,,j-k bistable .. -pratical logic circuit.. -build the circuit wizard way : opening to gates , gate number Intruder alarm: real life application of simple logic intruder alarm push to break , advance... - ripple counter.. -investigate : a block schematic diagram logic syst ,the system is designed to alert the flight crew visible and audio warning ,door switch logic signal respective door logic 0,when closed warning indicator active low requirements logic 0,to produce a visible audio ,study the circuit carefully and then see if you .. 1.what logic level appears at point of door closed ,wath logic level appears x,y,z ,,wath level appears point x,y nose door open other closed .. - circuit surgery : collector feedback theory /bias ,, A=So/Sai,, feed factor,,loop gain ,,Sf°BSo Sai=Sin-beta So -So+beta So=ASin .. AcL=So/Sin=A/(1+beta+A 14. Files system. Record academic and certificate diploma, 1.Pocket number. Implementation work Data right,met investigation: Project : drawing : Career project : theory circuit Schematic Experimental : workshop workplace school class pratical career guidance National trade examination :theoretical and practical ,n diploma 18month Memo tech , Project drawing: interpretation -Mathematics graphic draw :project Line point -Electrical trade theory draw labell: Circuit component make: Resistor cell,baterrie ,AC DC circuit current,lighting washing machine , transmission generation AC inspection -insustrial electronics draw labell Circuit component make: -engineering science Graphic and circuit .. - grade total career ,staff theory learn Pratical exam test trade assessment Engineering electrical. -fault find diagram schematical . Relay -installes rules ,circuit diagram, -lofic system -control system : -15 .experimental,.projects pratical trade framework qualifications marks : certificate diploma 6 month semmester trade.. Trade theory -pratice frame work Component frame ,electrical and electronics Drawing : make circuit tools process make circuit framework Trade pratical engineering:level5,6,7 Process Design Designation unity| ,component| ,tool trade| -male tool pincil draw Make, resistor ,condensator charger circuit tools make drawing . -makee installation lighting way switch : -makee transmission ,generation ,drawing ..design. 3.experimental :project drawing City power Eskom advanced career Drawing workshop and workplace , Library on line project On line. Power engineering,advanced Scheneider,Eaton breaker design -drawing diagrams city : Metering circuit: design Installation city transmission generat drawing schematic: Installation: -drawing interpretation: discovery electronics Drawing make: installation security alarm ,police alarm design intelligence robot circuit timer 555.. Computer electr -4. implementation integration system . Guidelines guidence pratical school Microsoft project azure ..GitHub ,visual studio gith lab Work item : epic item project repository project issue project run project code source readme licence,IP drawing circuit 15.1 Trademarks T Blaser tableaux Met career police tpm , counter terrism , Engineering systems:met block mark TMP circuit maintenance meeting break Data right .. Cell phone: IP licence book rwiten integration : met career detective ,counter flip flop ,electronics ,CCTV circuit right , cameras phographic right lens zoom circuit , repaired center cellphone city vs transmission Telecomm office vs Microsoft office vs circuit power vs installation electrique compagny police data certificate copy license copy private police ,,policy city power Eskom policy claim drawing design power cost economic load ,outage circuit . Total ,pratical , policy claim vs claim alarm maintenance total career , Security safety claim nated counter terro record irregularity phase circuit complain circuit implementation: -total framework policy vs police record LDR framew not meeting vs Terri counter irregularity vs Total grand :grand council department energy Eskom policy ,city power policy terro counter emet. Irregularity mining company trade mark , telecommunication claim vs customer trade marks compone maint Tom . -total grand met tblazer Salesforce energy claud metering energy co circuit incidence force sale policy -data right energy metery claim. Vs alarm relay delay dimer switch. Microsoft project azure blue defender Regulatory factor ,limited Freq , energy cost. Bill cost energy Intergration circuit switch. Record total Physical meeting .. script inspection 16..Experience pratical: www elektor .con, Test book Order booking :200rand ,,4eu - microcontrol analogue audio , digital,test measurement. -Pratical: quick to implement reusable multi plat form , fts. -sub long term weather logger . - ATM,18 compass. -j2B universal MMI module using ,arms cortex .. - FT232 ,USB Serie bridges/BOB Chip kit first Arduino compatible ,23 bit microller development platform,design manufacture. -Parallax : li - ion power pack charger -reflow mate : Supply voltage: 230V/50HZ only Power : 3500w Weight: approx ,29kg Dimensions: 620×245×520mm (w×H×D) Heating method: combined IR radiation and hot air .
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
5 of 18

Operation: directly using menu buttons and LCD remotely using PC software and USB connection. -menu language : -temlerature range ;25 to 300°C - Maximum PCB size :400×285mm -temperature sensor : 2 internal , Optimal temperature distribution thank to IR lamps - Drawer opens automatically et end of soldering , - Glass open automatically at end soldering process - interactive commander for data transfer Command | action h =help. | Print available command _______________________________________ -Current drawn by entire system at ,3,3 V CPU frequency| sleep mode | current drawn 8Mhz. |Non. | 5.8mA ________________________________________ Fuse settings ATmega 88 Fuse | Ext| OxF9| 8MHZ intern oscill (divided hence cpu clock is 1Mhz-$______________________________________ -weathet logger operates supply voltage of nomminal 3,3v power over USB ,is available 17 ,VCC of BOB ,FT232R serial -to-usb converter module for stand alone operation unit power via BT ,, supply voltage between ,3,5v and 30,V regulator ic3 diode detector again accidental reverse polarity connection important employees reduced measure to maximise battery life in stand ,alone operation microcontrol is responsible cincentre measure effort circuit ,3,3 V under various conditions is shown , alkalt or NIMH ,AA cell , 4,5 v or 3,6 v nominal capacity of between ,2Ah and 3Ah ..record data for least 1000hours instead of three AA cell free the employee single ,Li - ion Lipo cell supplies ,3,6 or 3,7 ,, on power saving measure is to carry , 100second ,, measure system draws extra about ,2,5 mA ,,120 ms ,when taking reading in between ,10ms corresponding to the 1hz interrupt the device is from ,power save mode 59 second ,I/o clock micro controller order need to be count the pulse in order , CPU.. Result disping result Test measurement: HH10D humidity sensor module feature . Re Swegethttps://GitHub .com/milkmist)mist rewmaster tools / filter m. Bios serial received firmware download request from the device. Flyerm uploading Kerbal (83475 bytes Upload completed (9,5kb/s. Booting the device Done Hello - the pattern obtained after numerous iteration of the command pixel [I]=y*y* x>>5.. Testing in development board ,,use serial port to upload application ,,serve a console for displaying the message sent to print f +) the Boras fitted with a ,3,3 serial port ,located between the ethernet and VGA connector ,pin marked ,board received the data marke tx is used by the board for transmission the GND is obviously ground ,3V3 is a 3.3 V power rail serial long use 3.3 level ( not 5v or RS -232) or the combined devdlop - organisation display of the measurements results .. -CMOS compass module: board .kmz 51 chip ,the resistance variation in resistance cause voltage variation which is amplified,LMC 6036 ,sensor electronics magnetic heading us calculated micontroller bus ,corrected module positions ,pin 7 ,AC power grid in him parameter story EEPROJ - orienteering ,4 load firmware power manufacture ,want to recover the module function bearing send following by modulating.. Wiring block - digital communications with the robot electronics cmps module Graphical representation of the compass point -circuit diagram the construction file eagle files component list software Keypad : consist 12switcges ,4 to the left of the display ,4 right , rotary encoder switch encode build push button three encoder space ,9 encoder build in button 27 button ,a5×6 Matrix need connect key I/o scane 4 key free way , function available some function make ,use diode avoided problem phantom key several press ,a situation turning the diodes package .. Different variations on the 2×@6 LCD ,key swiy offset .main function resistor R38,to R 44 board turned using button S1,s8,s12 key fitting , resistor provide. ,turn key circuit by battery function asymmetric matrix line have limiting resistor (15-R25) is final circuit .. - display: board offers possibility of fitting ,2 line by 16 character (2×16) display ,4 line by 29 (4×29) ,,by 16 character connection ,5v power ..R ,36 ,R 41 is necessary T relay ,R1 ,120package . -Powering : the board main rail ( V+) is 5v microcontrol itself ,3.3 derive,3 ,, are directly connecting the display available on transistor (piooo,6,,Pio 2,8. Etc pad k1 and k2 ..signal -construction: - implementation : board - twitter message local area network LAN wireless configt.dialog - communication on the dso board. Detec signal the ratio signal generator DSP ,101dv,and this ,n level of ,94 db application peak to peak with sinuskidaj ,0,53 to 0,59 time supply average Test measurement: Component list Resistor :.R1=220kohm To R5 -capacitors : C1=4,7uf ,63 radial to C7=470nf. - semiconductor: D1,D2=BAT42, T1=BS170. IC1= Ic2=ATMEG,, Miscellaneous:.S1,S2,S3=6mm switch ,PCB mount S4= single -pole switch X1=32,768khz quartz crystal LCD 1=DOG @62w.. Mod 1=BoB .. Mod2= humidity sensor HH10D K1=6-pin(2×3) pibheader option iso interface -20-way socket strips SIL for LCD1 ,, 18 -way(2×9) socket for mod @.ic socket for Ic1(8-eay and ic2 (28 -eay ,PCB hi Settings and function button S1 to S3 Print circuit board. Humidy sensitive used transducer elements frequency 6khz to 7khz measured AT mega ,value with calibration par ameyer again stored series module frequently counting the output pulses module over second ,the 16 -bit counter timer , capacity 64 kbyte,,stored,record .. -soffward : firmware for the microcontroller is written in C complied using .. Program in weather station,LCD to control display .... - construction: double site circuit board diagrams components mounted in board ,socket solder components,fused iso connector ,k1, programmation job ,program used sensor module serial to USB module , switch ,S4 position to select external power ,3,3 - operationel ,: treer button ( S1,S2,and S3:,S1 cycle variouse Setting ----________________ C28=C26/(4Q.Q×(1+Ao)),. R24=2Q/2(wo×C26) R25=(1+So)×R24, R23=(2+So)×R24/So If ,A=0,7071 and So=,these formulas sin plify to , C28=C26/4 R24=1,4142/wo.c26) R23=R25=2×R25.... ____________________________ Basemodu ---- Lab testing ..prototype audio convert implementation: Component list -Resistor= R1=330 ohm R2=680 ohm R3= 470 ohm Capacitor C1=100nf Inductor: tri ,home -semiconductors Led = standard led yellow - miscellaneous, cinch so let ,solder pins ,USB audio - circuit : circuitry design ,signal pin @, coupled resistor impedat former signal (0,5vand 75ohm ) coupling transformer provide galvanized cover upper frequently transfo limited couplings toroidaj core material suitable signaj ,50Mhz .. Construction: PCB ------------------------------------------------------------ - schemat diagram of the flasher - Circuit the time integration module Base e two operational amplifier ,A1 and A2 ,- ,non + input and output,varyyng voltage V1(t) is applied A2 driver integrato ,R c and A2 ,Rc stage ,add resist ------------------------------------------------------------- Light sensor : With twilight detect: sensiu circuit 9vdc. to .15 VDC..ligth room circuit generate ,lm257 ,R1 and R2,,voltage dived ,,R3 and R 1 circuit , Ooamp ic1 wired buffer voltage LDR suitable R2,voltage pin IC,,,IC1,,, ic2,0 other ,,22kohn R,10two comparators ,ic2and ic 2b compare income p1and p2,0thar output R 90,be ause ,, determine dark ,ic2. and I 2.. -explanation teach ,in A broad based introduction to electronics: digital to analogue and to digital conversion: electronics studies school college UK ,include byec level 2 award electronics diploma in engineering level 2 experienc - e read ,teach teach learn experience test electronics circuit Learn : - beam break flash trigger ,build necessary time delay photo flash response IE -Parts list active loop antenna : - @ PC board code 813 ( ant loop ) 31mm × 94,mm - @ PC board code 814 (rad loop) 58mm×48mm -@weatherproof plastic box ,eg 130×54×83mm plastics box -@8-pin IC socket - semiconductor: 1BA4560 dual op amp (IC@ 1 k8L08 or 78K10 voltage regulator. 2KDV ,149 varicao diode (D1,D2) -capacitors -3 )100uf ,16v electrolyte 5,) 15 nf disc ceramic. -Resistor (0,#5w, 5%) ..micelanot _________________________________________ Beam - break flash trigger.: the infrared beam is generated by led1 to led3 and picked up by phodetector diode ,PD2,,op amp ic@ b function as current ti voltage ,while I 1 is wired as non inverting amplifier the latter derives transistor A mosef briefly sait h trigger outbut when the or is interrut . -circuit details: Power isderiver battery in detector unit IRv beam from source unity OD ,3,5 mm jack plug con@ mate ,, detector unit IRv source unit ,IR pgotodetector diode ,is connector diode ground and the inventing input ,out site,,+1,7 v ,and +4,0v ,IR ligth is falling on OD@ dark , basically ,#2kohm ,,2,7kohn ,,220uf ,, Qrin writing amplifier ,, s -Switching the triggers output: Q1 switched when IR beam falls on PD1 collector voltage is normally,beam interrupted ,mosef .. -parts list : IR source unit : *1 PC board code 808 ,57×26mm 1)UBS size box ,8#mm×53mm×31mm 46mm long untapped spacer ,4 M3,×13mm screw ,counter sink head nylon cable tie ,75mm long 12m length ,8cable 23,5 mm ,monk jack plug cable type , - 35mm IR ,led ( led @ to led 3 ,1)820 ohm -detctor unit : 1) PC board ,code ,size ,,122mm×58mm 2UB3-size box ,129mm,×68mm×44 mm 1)SPDT mini toggle switch ,s@ @)PC mounty ,,3,5 mm stereo jack,socket ,, - PC mount ,15 mm tapped spaced ,8 M3 ,6 mm machine screws pan head - 21 mm PC board terminal pin,, 19v ,,battery clip lead 1)8-pin Dik ,,IC socket .. 1)30mmm length of ,13 mm to ,,15 mm length of ,12 mm to ,15 mm diameter black pvx conduit or brass tubing .. -1 piece of ,IRv- transparent red film ,approx snap connector or , 1×4- way ,AA cell holder . 1×2 way ,AA cell holder - semiconductors: dual op amp ( ic1) 1Bc33,nob transistor ,Q1,IR pgotodetector, - capacitor : - detector board final assembly n: construction v -cinverting scanners for ,VHF/UHF discrimination tap socket ,the basic setup for received ,159 MHz signsk ,,.. - PC board is secured to black the lid M3 ×25 mm tapped keypads pluggi into machine socket .. -precision resistor: -Lcd module: remaining components installer .. --------------------------------------------------------------- - digital insulation meter : 1) PC board ,code ( main /dis)109mm×84mm 1)PC board code 859 (dc-dc con),70mm×51mm Ub1- size plastic box ,157mm×95mm,53mm 1)LCD modut,2 line ,16 character with back ligthning. 1 ferrite pot core pair ,26 diameter enameled copper wire , 1) 100mm ,lengtt ,o,7 mm diameter enameled copper 1)8m length of ,0,7mm diameter enameled copper wire 1)100 mm length of ,0,7mm diameter tinned copper 1)10×AA battery holder. 0,7 mm diameter pinned copt 1)2- pole rotart switch ,PC board mounting ,wit 16 mm,S1 1)SPDT mini toggle switch panel mounting (S3,S3) @ Min Dil relay ,spt switch p with 5v ,2) binding post ,Bana jack (1 red ,1 black . 24 mm solder lug.. 1) ,16 -pin lengi of Sik socket strips 1) 18 pin IC , socket ,4( 25 mm ,m$ tapped metal spacers Block diagram of the ,16 ,bit digital potential the desired out voltage is entered via keypad and microcontrol IC 2 the correct binary number to drive the ,16 relays in the ,R/R ladder networks - arena loop , Experience trade mark , engineering science career ,motoring vehicle,power machine , engineering,trader Compagny,Transnet motoring career , ford career Engineering system and Toyota , nated ,, Magazine collection motoring reviews -rwiten oral relate : Specifications : - 1.engine: -cylinder : four ,in line transverse - fuel supply : electronics multi point ,injector -bore /stroke : 81,0/96,3mm to 87cm -cubic capacity : 1799 cm cube -compressiin ratio : 10,5 to 1 -valce gear : s-o-h-c ,valve per cylinder , variable valve timing -ignition :five -2Engine output: -Max power iso(kW)103 -power peak (r/Min)6300 3transmission: Forward speed -low gear: ,3 ,142 to 1. -2end gear :1,869to 1 -3rd gear : 1,235to 1 4th gear : 0,948 to # Top gear : 0,727 to 2 - reverse gears :3,307 to 1 - final drive : 4,294 to # Drive wheels. : front -wheels and type - road wheels : 16×6,5j alloy Tyre make brigestonr turazan , Tyre size : 205/55,R 26 92v Type pressure front : 220 kpa Type pressure rear : 220 kpa - spare : full ,size disc 5.brakes: Front : 262 ventilated disc Rear : 262 solid disc Hydraulic : ABS , with end and bas. - street : Type : rack and pinion hydraulic ,speed sensitive power assist -lock to lock : 2,7 turns - turning circle : 11,6 metres -suspensiin : Front mac person strut ,lower wisthbor e gas filled dampers anti ,roll bar multi coil gas rear - capacities : Seating: 4/5 Fuel tank : 50litres Boot space. : 304 dm 3: Utily space :928 .DM cube - warranty and service intervals :. 3 years /1000.000 km warranty. 5 years /100.000km service plan Service every 15000km: Honda civic 1,8 Vxi; Volkswagen Jetta ,1,6 Comfortline ,ford focused ,2,0 trend ,, Toyota corrola ,180i Test claim t 203km/h top ,speed and acceleration to 100km/h in ,,9,44 second Honda tops at 202 km/h achieve the benchmark sprint in ,9,39 second performance - test data : .Amarok bitid ,4 motion Engine : -Cylinder / capacity : 4/1968 -bore and stroke : 81×91,5mm -compressiin ratio : 26,5 to 2 Fuel supply:common rail Injection - fuel diesel . -max torque : 400nm@1500rpm -max power :120 ke@4000 rpm -transmission: Shift type: 6 - speed manual - first gear : 4810 -second gear :2540 Third gear : 1.590 Fourth gear : 1000 Fifth gear :0,760 Sixth gear : 0,630 Final drive : 4100.reverse : 4.370 Loe-range : 2729 Control 4 WD selection type electron button Wheels : alloys Full-size spare - 2.measurements (mm) -height :1834 -length : 5254 -width : 1944 Wheelbase :3095-fuel consumption: 120 km/h ,,:8,61/km Urban : 9,8/km - calculate range : 688km - performance: 0-100km/h : 20,8 second 100-129 km/h : 4,86 second rpm @ 120km/h : 2100 -recovery point : Front ,,RHS Rear - underbody protect: Transfer case non Fuel tank : plastic guard Rea diff non - odometer 6,248km -load and towing capabilities (kg) Tare : 1848 GVM : 2829 CVM: 4668 Towing capacity ,unbraked : 750 Towing capacity ( braked) - brakes : Front. Ventilated disc Rear. : drums ABS ,yes - load capacity ( litre ) Load box : 2520 - warranties maintenance and service: Warranty : 3year/ 100000km Corrosion ; 6 years Service plan : 3 years / 90000 km Service intervals: 15000 - guard motor ,police maintance Record Guard gold platinum ion Eligibility car _____________________________________ 17. Specifications:volswat golf Pricing : Test pricing Standard equipment; controle aluminium - general data : Kerb weight:1541 kg -length:4212 mm-width,excl mirror :1779mm -wheelbase :2578mm -weigth distribution front ,n/a - ground clearance : 132 mm - boot space : 275 litre,.. -utility space : 1305 litre - coefficient drag CD : 0,34 Seating capacity : 5 Headroom front : 987 mm Headroom rear : 979 mm Hatch lift height : 2017 mm - safety -warenty : 3 - years : 120000km -maintenance service : 5 ,years : 900000km -2Engine: Type layout : 4 cyl transverse turbocharge . - valvetraun : DOHC ,16 ,valve -displacement :1984 cc - bore ,x stroke mm : 82,5×92,8 - compression ratio ,:92,8 -power kW : 188kw,,6000rpm -torque; NM : 350Nm ,,25000,,500rpm - power ,to weigh ratio : 121,8 kW/ tonne - fuel injection : direct petrol inject -recommended fuel : 95 unleaded.. - drivetrain : Transmission : six speed - gear : ration 1st : 2,92 2 end : 1,96 3 Rd : 1,4 4 the :1,03 4th: 1,08 6th : Body frame with .. Brake from : 345mm disc - break rear : 310 mm disc - wheels : alloy :tyre : - steerit : servitronjc - steert ratio : 14,96 - turn lock : e Suspt front : 10,9 m - susoenst front : Subjectivjy base averaged weights out Driver ,gearbox ,steering ,vraj ride handling ,exterior styling ,interior styling sear , ergonomic control ,luggage space , percentage ,price value - Performance: Accelerated: Speed / time 0-60kph / 3,17 sec. 0-80 kph/4,55 sec 0-100kph , :6,27 sec 0-120kph - quarter mil , soeedo calibration ,120 kph ,error ,,116 kph / -3,3% Overtake 60-109kph. / 3,31 sex 80-129/4,24 sex Braking : Average speed to zero 100-0kph / time / distance : 2,77 second /39m. -fuel economy: Real world test route : 72,3km - fyej used : 6,3 litre -our consumption:8,7 litre / 100km urban cycle claimed : 11,2 litre / 100km Co 2 emissions 195 g/ km Fuel tank size : 55 litre - estimated crying Test conditions: test car odinetr : 5396kn Reading-temperature:21deg ,c Wind Locay ,test note : ------------------------------------ Car note Hon payment calculator based ,19 percentage deposit: 18.explanation: comparative test : Subaru. Specifications:-2Engine: Cylinder : four horizontally ,opposed Fuel supply: electronics multi - point injections -bore stroke : 99,5/79,0mm -cubic capacity : 2457 cm cube - compression ratio : 10,0 to 1 Valvagear : s-o-h-c bank four valve 2 : engine output ; -max power iso kW. 123 -power peak (r/Min)5600 Red line ( r/Min). 6450 Max torque ( N.m ) 329 -torque peak (r/Min) 4000 3.transmission : Type cvt Low gear : 3,525to # 2end gear. 2,238 to 2 3rd gear. : #,641to 2 4th gear. : 1,194 to 1 5th gear. : 0,850 to 1 Top gear. : 0,850 to 1 -reversr gear. : 2,358 to 2 -final drive : 3,700to 2 -drive wheel : permanent ASD. 4.WHEEls and tyre: - road wheels. : 18×7,5j -types make : Bridgestone -tyre size : 225/45,, R2891 w. -Spare ,tyre and location ,spacy 5: brakes: Front : 294 mm ventilated disc Rear. : 286 m ,solid Hydraulic ,ABS. Breaker assist 6.suspension : Front : mac person struts Rear . Capacities: seating:4/5 Fuel tank : 65 litre Boot /utility space :348 DM.cube - warranty and service intervals: 4 years /100000 km,warranty ,3 years / 63000km maintenance. Test results: Maximum speed (km/h) -true speed. :210 -speedo calibration:60,,80,100,120 -true speed : 54,74,,93,,113 -odometer error :0,9 percent over. *Accelerated,second 0-60. ,5,2# -0-80. , 7,50 0-100. ,14/95 0-120 , 20,74 0-140. , .1km sprint , 32,15 Terminal speed : 264,4km/h -overtaking acceleration: second 40-60. ,/ 2,53 60-80/. 3,01 80-100/. 3,65 100-129/. 4,41 - fuel index : Manufacture fig : 9,2 litre /100km Car fuel index :/1 0,92 litre /1000 Estimated tank range : 595 km Taxable CO,2 rating : 214 g/km -braking test : 10 stops from 100km/h measure in second at ,30 second interval on good bitumeise -beat / worst stop : 2,70/2,89 Average of 10 stops rating ,2,79 excell - geardsd speeds ,km/h low gear ; 52 , 60 2
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
6 of 18

Nd gear : 82 ;94 3 Rd. gear. : 11; 128 4th gear : 253 ; 176 5 the gear. ; 299 ; 344. - calculated at engin power , 5600 r/ Min and red line ,6400 r/ Min - performance factor : Power / mass ( w/kg) 80 Power / litre ( kW/ litre ) 50 Power / litre ( ks/litre). 93 Torque/ litre ( n.m / litre Engine ,,: 1124 Engine rev/ km - mass tested ( kg ) - test conditions : Altitude : at see level Ambiy temp / barometric press ,22° c / 2020 hPa Test car odometer : 1765 km -150000km warenty and five t ,100000km service Comparative: Test summary class Hyunay test scores,25/29 Mercedes Benz blue efficiency,75/100 Opel Corsa collour - hummer H3 adventure Design and development the TBM ,,700 is singles turboprop engined low wing monoplane aluminium and steel construction the TBN product PT 6 A ,rates at 850 sho (634) ,,522 kW take off and landing cruise flight engin power,859 ,,634 the extra ,,2529 neutical miles (2829) -General characteristics: Crew : 1 or 2 pilots Capacity: 4 to 6 inclus on passenger .cockpit Length : 10,65 m (34 ft 11 in ) Wingspan : 12,68 m (42 ft 7 in ) Height: 4,36 m (14 ft 3 in Wing area : 18 .m.n (193.7 ft Empty weight : 2132 kg (4699 lb ) Max take off weight : 3354 kg (7394 lb ) Max playload : 385 kg ( 849) - performance: Maximum speed : 593 km/h (320 knot ,368 mph) Cruise speed : 467km/h ( 252 KTS ,290 mph) Range : 2813 km ( 1519 NM,,1784 miles Service ceiling : 9450 m ( 31000 ft ) Rate of climb : 12,09 m/s ( 2380 ft / Min Time to climb to 26000ft ---------------------------------------------- Based . Price : | POA Number of seats and luggage : 2 seat ,34 kg - engine type : Lycoming -fuel burn : 23-30 litre per hour - tank capacity: 136 litre - range and endurance : 2384 km - propeller type and oper: sensenjc -undercarriage: - lead time orders: depend -standard avionics: vrf Panels - Speed |. Size |weigth Cruise:147 KTS| length 6,2m|MTow:794k Stall:38 KTS. | Wing:85 m| empty :460 kg Vine:171kts| height :1,8m| useful: 334 kg -pulk out plan Explanation VIP. Paint protection that actually works approved by major Manufacturing in South vehicle shield .. -bonnet guard , Headlight,front guard,side guard ,,repaired scratches ,stones Chios ,damage ,film removed ,film warranted 5years peeling ,bubbling and cracking -_____________________________________ Journey|price|engine|power|torque| 27sxt. | Maintenance plan: three years /100000km -fuel tank:78 litre -averagr sales per month -service plan 17..Explanation engine calculation How to calculate bore ,stroke displacement -volymetric efficiency VE=3456×cfm÷CID× RPM,, -Cubic inch displacement=NOC=Noc×SV - head gasket volume: HGV=HGCT×0,785×BORE: PVD=0,7854×Bore×DPD)+)+(VPD-VPB)= piston deck volume - compression ratio CR=1+0,7854×30RE×strokr÷ccv+HGV+PDV. +ISH=HP/16 : fuel system injector size per horse power.. VE: volume office, Cfm: engine air flow rate cubic feet per mine. Cid : engine displacement ,size volume cubic -RPM= engine speed revolution per minute . - NOC: number of cylinder -bore =length -stroke = length -HGV= head gasket volume Hgct : head gasket compressed thickness. PDV:piston deck volume DPV: piston distance Or .. SV= sweet volume . CR= compression ration Ccv: combustion chamber volume Ish = injector size per horse . HP: horse power--________________________ 18.Explanation: engineering science ,stress,unity stress,type stress,unit for strain , elasticity ,hook low, straight, ductile material,young module elasticity.. -explanation : applied thermal engineering engine testing: structure .explain performance measurement:. -basic parameters: -measuremsnt of speed . - fuel consumption measure -measuremsnt of air consumer -measure of exhaust make -measuremsnt emissions. - measure of brake power : -measuremsnt of friction horse power. - performance of si engin -porformence Calculate speed in evaluation performance development : charge load -bp=2πNT÷60, break,,2πnt/60,, AL ,,N.K/60 -specific output: Specific . Volumetric efficiency n=mass of charge actually scke in÷mass of charge corresponding to the cylinder pond conditions. -relative power air : FR=actual fuel - air motion÷stochiometric fuel -air (bsfc).. - thermal efficiency heat balance .. Brake thermal efficiency:= bo÷ m.f×c -performen e: Heat equivalent break work rejeter to cooling . - heat career for engin .. Heat balance sheet. Input | kW| %| output | kW | % _____________________________ -explanation: construction techniques:. Petition: record -structure ,model aeriplane. section :;. Side : Model assembly details: Covering and finishing. Refinement. -------- -construction note Letter : ..... Materials:-------------------------------------------------------------- -letter,|number|name|size. |Masse A. 1. Gear 1/4 , ------------------------------------------------------------------ Seat,frame,back,fender,back,Fook, healings,front,front axle,wheel,gasttank,rivo.. ------------------------------------------------------------------ three wheel motorcycle: motor driven car ,, - simplified concrete mensonery planning ,mortar ,concrete = A.P/s - ----------__________________________________ - explanation study material and fire arm ,ballatisc Gun Typical muzzle energy of fire arm: _______________________________________ -fire arm ( except |calibre |muzzle energy -air gun .Ek=1/2×v×v(2ft.LBf/7000gr×32163.f.t.t/s.s E=(m×v.v)+ K=450,95(2×32,1930,700)--------------------------------------- -spefication -Calibration:9mm ,para ,40s , -ovarall length : 2184 mm. -barrel length :5 - high : 240mm -weigth:0,81k Construction slide Magazine : 24 round sign front ,GPS -test firing results : -Ammunition : group - factor : -41mm. - hand load :51 mm..note accuracy average.group..fired ,25 mm... --------------------- -artillerie ,AM×30F@ Characteristics service -types : canon automoteur,utilisation Conflicts. -characteristic equipment : 4 home piece piloted longer left : 10,23 mm Larger weight:13;10mm Hight : 3,17 m Mass in combat : 43,5 tonnes blindage ,size ,case lunch.. ------------------------------------------------- -report installer: - mounting battery replacement step remote: - connection to the fence -connection , configuration -pc board replacement - service condity -Pc board ,F1,Fu ,18 vac fuse.. -Lcd display,18 LCD ,7,2 output in 500ogm Energy out put .500 ohm ,joule -9000v ,zone monitot,1/2 control display,2 max gate - gate and panic button input time gate ,yes - alarm output ,siren output .. -power consumpt under normt operational conditions ,18VA -battery time charge ,24h - solar power operational,60 Ah -wire in a Serie : galvanized : @,2 mm : 5 m optimal.. High voltage ,set point :10,00 volt ,set ------------------------------------------------ Balance rate installation: item..design draw element ,security access plan. --------- Card access reader mount type technologie. -biometric access reader mount type be specific. -keypad device. -keypad,kepead securt. -card reader with key.. - horn siren - weather proof him - horn ,strong - strobe. - car reader with turn attandance, Tensile,revolving door -traffic arm. -vehicle ,exit device , -smoke detector, -heat detector. -gaz detector, carbon monoxide,electro lock, push button ,camerarwite,camera ,with intercom, - security window scret ,heat detect, -window contact,vibrasic,glass,floor,car drivers,overload,dual tech ,contact saity,wall motion,floor motion, -beam fence distribution, - 19. Explanation : pratical school Disciplinary hearing school . trainings system orientation school career guidence : Experience trade explain: career skill -explanation: safe road usage teacher manual secondary: -explanation the foundation for road : Meaningful maturity,human dignity mordaly depending decisions,making responsible action , identification of criteria, phylosophie of life ,inclucating road safety , various level human , existing in frame of reference,co existing temporary,relation , - explant:the origin of technology and it's implications Forman ,technology and responsibilities ,Sens of responsibility and Education,the task of the school, requirements of the school,road safety and involved in accident, accident according degree ,type of road user accordt to racial group involved , statistics cost alcok poor vision . - explain: traffic training secondai ,content of traffic , traffic situation,those involved,road safety , certain criteria for ,traffic training ,certain requirements , content method for ,youth levels ,abuse among , legislation and low enforcement ,vehicle ,trafft ,element , traffic hours . Trainer methods conversation,self , training, Education orientation, -expt differential teacher road safety education ,basis off teaching from road ,child involved , inequality child different safety Education ,road Education for school undertaking parent school local ,,locak - explanation different road safety education and the secondary: Education concept ,secondary school ,diffet road safety , Education central ,road safety ,road safety situation, road safety orientation,road saft Education road attitude , secondary child personal,goal diffential road safety,road safety matury, psychopedagogie persscpectuve, fundamental pedagogic perspectt ,social pedagogic , didactic , orthopaedic ,irthopedidact, realisation , opportunity and road safety education, The school , secondary child basic ,, - explanation:the methodology of road safety,goal of traffic Education , traffic lesson objective,the learning objectives, problem settings and problem solving , - lesson structure and form.. -explan group course lesson , actually preknowled, actually , unlocked of new , evaluation, group discussion,class arrangements,quality teacher ,skill the teacher and group,how to handle group ,group cohessiob ,criteria for judging the success of .. General methodology guidelines. -chao teaching aid road safety education : Teaching lessons modalities teaching didactic , a schematic presentation of Education , teachings software . Teaching wath look like ,teaching wath , teaching broad ,blackboard ,conograpguc teaching aid ,poster brochure model.. -thw sons box training ground the overhead projector , - the overhead projector film projector . -selecting teaching a lesson ,nature , didactic consideration, -road: safety ,nayv,point of contact in road safety ,few partie , department transformer provincial authority vlocal , evaluation .. -calcul situation traffic possible, criteria,test total traffic situation,different large ,self orientation up him self regards world self discovery evaluation accepted road,lesson telling lesson subject road ,time 35 minute ,lesson objecy explain pedestrian ,setting problem pupil ,stopping ,self realisation , instruction control .. Topics :Lesson objective to explain ,learn objective pupils must knowledge the application legislation and must able to mention aspects which ensures safe , pedestrian. - explain the problem: LinkedIn up knowledge pupi will be led to the realisation that injuries pedestrian behaviour is not only annoying to other dangerouse during lesson phase new content is gradually unlocked , - scheme consider energetic behaviour on pavement keep try to walk next another , stepping pavement intersection trafficking ligth buses getting out of vehicles. - the course of , actually preknowled the pupils citoyeb Saturday morning ask Unlocked behaviour pointed outcome traffic legislation is explained content , mentioned in problem solving is unlocked b, - explanation : functionalism : practising of acquired insight by mean model or diagram on the black board may explain how the will intersection as an assignment pupils observations and make annoying and effective behaviour of pedestrian.. -explanation defensive driving; road sign ,warning sign ,guidence , regulation sign , traffic bsign ,hand signals ,flag signal ,overhead lane flashing signals, road marking, - explanation: rules of road vehicles : control theory test driving.mirror blind spot ,signsk clutch ,speed control breaking ,gear change ,motorcyy ,board inspection , inspection staring , Explain manouvring test moving running left speed control changing ,incline ,turning speed judgement emergency . - the driving test : light motor vehicle, heavy motor ,the years ,staring procedure ,moving off , inclined ,alley docking ,reversing ,making a left turn ,hand signal , parallel parking ,the road test ligth heaving , light and heady . - changing lanes ,stopping in traffic , stopping parking , turning at intersections, proceedings ,stop traffic sign ,entering a traffic circle, leaving a traffic ,block pedestrian ,level crossing , overtake,entering ,leaving freeway ,overtaking ,on a freeway passing , freeway on Ramp.. - explain test checklist record , faillure manoeuvre point ,exceed time limited 29/18 penalty , roadworthy, violation traffic low , uncontrolled action , dangerous action , collision, 20..Explanation: Management system information: pratical Science motor policy guard -statement of insurt; statement of the administration,vehicle eligibility, important servit,policy commence date, replacement of components,claim procedures,cover provided this policy , components Covered, beneft: classic,bronze silver ,gold, titanium, polyester ,ceramii , additional silucd , transfers it,exclusion form cover ,limit Silver,gold titanium ,limi of indemnity,wear and tear restrictions, consequences damage,cancellatt,jusdiction currency and dispute,fraude ,quality control,insurer rigth after , service history intarion , statutory notice , resolution. - explanation : road warranty all passenger commercial maximi carrying capacity 200kg , cover the cost service maintenance accident ,petrol engt service relevat as . -displacement interval .petrol diesels electric maximum service run over if 1000km or 30dats occure RMI repair claim , - policy vehiclt schedule still subject to Manufacturing warenty plan motor guard plan. - faillure occuring 39 days . - replace claim process in event of mecanique construction fail occury. - Owen ,policy number , current kilometre ready,partict of clay ,item cause quotation,address vehicle inspected service record invoice submitted with 45 days , benefits ,5 years ,120000km ,18 years ,160009km - description of good stolen property must descrt very accurate bear it in mind invest official searching good , -makee or manufacture ,modej not years ,years of products, serial number ,registration ,engine and chassis ,size ,colour ,completed ,state midst iteb ,charge that change , _______________________________________ - 22. explanation: industrial administration management - explain : general framey historical background complexity of management - general princy and groi of management thought. -growth of management the pioneers - outline of managet theory : definition - business orgat: organisation the diviy of managet, -growth of organisations stage growt ,orgabiy chart , organisation rekatu, - organisation problem : corpsratt planint traditional and modern organit theory future reauit , - production marketing and admnistration. - organisat and the manufacturing fynctt stage in production manufacti,organisation of production the manufacturer functions: -:Products the ancillat functions b; maintent production planning and control store keeping purchasit handlit of material. - products the advisory functy : work studye time ,method -production the advisory functions : work study time study methods work study , ergonomic , operational research inspect. -marketing : marketing's organisat: admnistration area ,personek management wage. - growth of industrial relat: trade union unions emply associt collective bargaining and joint negotiation: - personal managent : motivation of management content of a personal policy achievement of harmony of objectiy: - the person's department staff recruitment, the manager . - personnel functionalite organisation if personnel department staff recruitment sciencetif selecti - job evaluation and : wage structure determining the wage structure merited rating personnel problem induction training wage and salaries: - personnel problems: disciplinaire promotion safety labour turnover management by participation personnel statistics ., part four financial management and statisciak .. - financiere management : scope of accounting provist affinaire source of finance. -outline of financial and cost account definition the purpose account , fundamental accounting transit from financial to cost accrost , classification. - of cost controlling cost absorbing factor .cost miscellaneous overhead absorpty , overhead facially .. -cost account system : process casting batch costing hybrids costing ststt organisation for labour orgat for material cost organisat for overhead .. - method of casting and control : marginal costing decision . - profit and efficiently and loss measure capital expendy decision . - statistical method : Chart and graph statistics quality control . Designation experimt time Serie published statisic.. - part ,five the industrial environments: The middlege to eight center the industrial revolution from development of large .. - principal development in some ,major : coak iron and steel engineering textile chemical and artift fibre ,scienty research.. - the economic ent:.demands and supply cost of production types of compety resale price maintenat the general economic situation. - general principles of financial and visit low banking and finance trade credibly commerce the merchant bank and issuing house hire finance industi and commercial Indy corporation for industrial negoy instrument. -government and industry: introt devet of govert organisation of control . - necessity for government control : - element of legaj system : the low modern communities source of low common low system Englanders and Wales legal person the idea and property. - general princiy : of contract princt of contract and commercial law ,contract ,tart liability for dangerous premise agent sale good , miscellaneous commercial low matter, - elements of industrial low apprenticeship contract of employment factories act Offit premise ,act social insurance industrial arbitration industrial relations general managent division function .. - explain award bid clause ,price industrial minimum salair ,flow manufacture process lighting tube. Design process: Order ,item price : product case 24. Explain: pratical school regulation and irregularity Vocational guidance theory and practice: -1 vocational guidance , -2 explanation: psychological explanation of occupational trait and factor personality
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
7 of 18

development , social learning ,decision making autonomy, -3 explain sociological explanation of occupational ,choice class gender ethnicity group , opportunity structure an interdisciplinary framework. 4- explain , the interview: philosophy, structure questions talking silence , listening ,non verbal communication information and advice. - 5 , explain traite factor client centred , psychodynamic, behaviours problem silvt , fantasy,the place of counseling in vocational guidance. -6 Career Education: explain objective: structure and occupational information the curriculum evaluation. -7. Test interested questionnaire,self help instrument computer based guide special program - re written career guidence ,total faculty subject total grad time table Admi total grand reason career .-explanation: study of occupational ,self study of occupational. -qualification obtained your present position how college. - how to choose career,: knowledge of occupational finding about occupation , know yourself. -how to apply find employment,way find . -how to apply for work . -how work relationship, introduction, different kind ,your concept relationship .. - communication ,danger --explain , psychological test : instrument , mechanical and technical aptitude. -qualification| work do to choose career - occupation | social conduct , relation social . Psychometric -Personality and aptitude profile confitial psychology Name : Interest ,| attitude | verbal reasoning , vocabulary ready completed| factor | personality - test results reported | survey councillors . - profile / v(y) ,, Batteries , ________________________________________ -explanation tpm is profitable,direction in production achievement zero breakdown the parko factory. -RPM challenge limits from four devet stage , definition and distinctive features Tom striving for overall equipment effectiveness tomb,defect prevention system ,between , Tero technology and -explain: maximizing equipment effectiveness , equipment used at half effective. - breaks motor stoppages imped automation stop acceleration the deteriore of equipment. - explain preventive maintenance alone cannot eliminate breakdown five counter measure for zero breakdown. - unlicensed operational of automated equipment errors equipment investment, five tpm development. - organising for tpm implementation the twelve step . -step ,announce top management decisions to introduce tpm ,step 2 : launch Education companies. Step 3 : establit create organization's promotion. - established basic Tom police and coak . -formulate master plan for tpm .. Tom , implementation,and stabilzat. Step 6: hold Tom Step 7: improve equipment effectiveness. Step 8 : estabt autonomous , maintence prograyfor operational. -step 8 set up schedule maintenance program for maintenat. Step conduct improve operation and may skills ,step initial development equipment management. Small group. - integration small ,small group goal coincii with goal , - evaluating the maturity of small group acty the functionalite of top many in small group . 25.Total maintenance product,,meeting police ::------------------------------------------------------------- -explanation: director social worker practice theory and skill, - explain social work,an overview. Direct practice domain phylosophie and roles . - overview of the helping process. -explain operationalizing cardinal social work. - relationship building skill community with emphasis and authentic. Verbal following exploring and focusing skill,eliminating counter productive communict patterd multidimenst assessment, - assessing intraperst and environmental system . - assessing family function , forming and assessing therapeutic group,enhancing motivation,with involuntary and ambivat client,negot goal and formulating contract . - change oriented phase ,planing and implementation change oriented strategies. - enhanced client problem solving skills assertiveness. - modifying envit developing resource and planing ,.additive emphasis interpolation confrontation ,managing individual famili and organizat barrier change. -the termination and evaluation phase , Explain : final phase termination and evaluation of code ethics,timing and intensity ,of self disclosure. -A paradigm for respond authentic stimulation client message. -Fuel for authentication response.initiated by practionner. - positive feedback form of authenticity response . - relating assertivei to client saying no and setting limit, - exercise in responding authentication and ,client statement model resnse ,in surface underlying feeling , answer to exercise to discriminate level of emphasize response. - explain: verbal following exploring and focusing skill , maintaining psychopedagogie contact with clients exploring problem. Verbal following furthering response ,paraphrasing response,open and closed end , responding,client statement,seeking concreteness ,modeled response , summarise response analizing verak following skil , - focussing ,a complex skill selecting topics ,exploring topics depth blending open ended ,empgic response maintained focuy.- evaluation used of focussing , response ..to exercise,answer to exercise identify in close and ended response .. -explanation : eliminated counter productive communication patterns: impacts of counter productive communication patterns : eliminating non verbal effecty communicay culture nuance of non verbal ,other inventory of non verbal patter of responding -communication barrier eliminate verbal to effectively,gauging effective response the challenge of learning new skills. - multidimensional assessment, critical role of assessment , -assessment an ongoing process , assessment as product,include strength in assessing,sources of information verbal report.direct observations of non verbal behavt observations interatclient monitoring collateral source of infot. -psychologi test , -computer assisted personal experience based on direct interat. - the importance of self awareness. The multimensionaliry of assessment. -the problem identify the clarity ecological factory assessing devetneed stress association. -key factor to be addressed. Manifestation of the problem, participate -explanation: source of information verbal report.direct observations of non verbal behaviour, observations interactive.client self monitoring,collateral source of information. - psychological test., computer assisted asssessor personalite expression based on direct interaction. -the importance of self awareness. - the multimensionaliry,of assessment,the problem identify the clarifying , ecological factory assessing development, participants and system implicated in the problem how participate. , development stage and life transitions. - severity of the problem meaning client to problem. - site of problematic behaviour the temporary context of problematic. - frequency of problematic, possible alcohol, substance. - child maltreatment.and spouse abuse . - client emotional coping effort skill strength and skill of client . - cultural and social class factor questions to be answered assessment other factors . - assessing interpersonal and environmental. -the interaction of multimensionaliry humans the introper system , biophysical characteristics presentation. -physical health cult factor in social support , assessing use and abuse of , alcohol and drug , effect of abuse alcohol dual diagnosis in , biophysical social , using interview skill to asses possible , alcohol ,using instrument and procedures assessment . -assessing abuse ,use of instrument and procedures ,conveying assessment finaling client.genetic factor psychiatry. -cognitive , perceptual , intellectual judgement , reality testing, cognitive flexible ,value misconceptions, concept, interaction between cognition emotional and behavioural, - emotional functionalite, emotional controls ,range of emotional, appropriate of affect ,assessing effects disorder ,bipolar effective, bipolarity ,assessing social,.- : motivation: precipating event and motivation,in volunteering client ,culture norm , different, determined pattern degree of acculturation , bicultural and mental health .. - fluency with language problem solving , achieved credible, providing immediately benefit attitude ward , environment health and safety factor environment resource universal need identify relevant social , system social support system . - negative social support system assessing reciprocal interactive between individuals , instrument to , environmental need of disabled. - assessing family function the evolution of family system. - system framework for assessing . - family functioning , family home , content process of interaction.. - sequence of interaction employment circulum explanation , assessing problem. - outer boundary internal boundaries and family subsystem family power structure , family decision making , family and range feeling ,gosk , family myth cognitive communication styles of member , - forming and assessing therapeutic group ,classication of group formation of therapeutic,group established group purpose,Agence and practitioners perspective. - established specifications individual group goal.. - conducting preliminary interview. - group composition. -open versus closed group ,size frequently and duration meeting. - voluntary versus involving .. -assesin group process, assessing patterned idify group alliance , group norm value , -enhacing motivation with involved , applying concept from social, initial contracts structure of initial interview.. - using confrontation facilities. - negotiation a problem search bargaining with clients getting mandate off your back .. - exploring self defeat consequences,resolving ambivalence in family creating incentive culture hope , highlights strengths modifying cognitive self . -negatiatinf goal and formulating an rational contract ,purpose of goal ,type of gosk , guidelines for selecting ,process of mutually selecting .. -------------------------------------------------------------- -26. labour relations in education . - termination for labour in education - act and bills for labour low in education . - explain: an historical, clarification of concept the development of labour ..- the of exploitation racial discrimination, Explanation: era of advertisement ,the era code termination and cooperation. - development of Education labour relations. -sources of labour , labour relations and the constitution. -the common low and labour legislation for Education. -the rules of natural justice., -the contractor of employment,labour relations act and related labour low. - labour legislation for Education - individual employees relation . -defining employees and employers in education. - employees right of employment in education, - employees right of employment in education , - fundamental right . - duties of educator as employee .-dumie of employees Skill development and Education ,national skills authority ,seta for Education, - learnership in education , - collective labour ,freedom association, organisation right of trade union ,. -collective bargaining in education,collective agreement,managing industrial action strike and lockout. -responsibilty of manager , - procedure during strike ,duties of manager , established and implementation..- fairness in workplace disciplinaire: - substantive and procedural fairness,fair unfair dismissal , progressive disciplinaire , - workplace disciplinaire Education: - incapacity ,poor work performance,defining poor work, procedure incapacity, health injury , definitely health ... 29. Explanation : - Principle of commercial low : Large credit ,agree small intermediary, - explain: size of agret, regulation, concellation of registration of credits b, - registration of definitely counselor credit . - consumer credit policy. - source of the low , statutory low or legislation. - the constitution . -the customer low,judgt of the court ,old authority , foreigners low , case discussion. - the court in republt t constiy court , - the constitution court . The supreme court appeal ,high court officer of superior court duty -officer the supieur court duty process master . - magistrate court . - doctrine of store decision ,Cree case create judg . -application of the doctrine : - interpretation status : the relationship bet the star decision rules the general principles, - court judgement : ration decides . -:the term : low rules ,meaning low rigth, legal subject legal objt, intellectual,private low , protection , servitude bself defense provocation . ,- term of the contract : essential natural and incidentally,condition ,penalty - contract of sole: the our,chosen is entitled to be protected by seller again b,for content , - indemnity insurance. - determinat of the amount payable non indemnity insurance ,value house ,. - relation diffusion form intellectual, - franchising : mediation, arbitration,award Statutory arbitration,source of the low of arbitration ,matter excluded form arbitt ,national cause ,matter relating to ,criminal case ,validity of arbitration agree ,the arbitration agree ,the power of court in relation to arbitration agreement,stay of legal proceeding where there is an arbitration agreement appointment of arbitration,power of power of partie , appointment of arbitration ,power of partie to appoint arbitration to fill , termination of an arbitration , - notice of proceedings partie , summing of witness and recording , evidence manner of arbitration award the act ,time manner and publicat of award refused to sign must does not invalidate order specifications,setting a side of award ,cashing of cheque,the relationship between card ,issue and card hold traveller ,the low of trust basic feature a ,trust transfer control ,, right consequences of windings the effect of windings, liquidation meeting land proof ...- the low of administration of estate ,the executor ,appoint , furnished of security removal and dischat ,master , preliminary work ,death notice , letter accept ,band security ,making over in space ,completed sell , redistribution agreement payment to creditor on brief 30. Explain: practice school management -management characteristics of management styles the main components of . - planning: explain planing cycle different level of planned the need for planning policy general guidelines for effective plan - explaun : step decision making ,routine and innovative. -explain : time management the importt plannit way in which time is wasted making effective . -explan time table drawing time variouse , drawing up time various types of time table .. - the annual programme , purpose of the annual progrt consii drawing, - plannt preparation and record and keeping. - culture activity in the debat society youth activities religious movements , competition. -explanation sport actuy ,the aim of school ,sport police, - basic requirements for successful organisation and control , organisation of sport various.- the education value wells organised . - Education execurssion - officii applit for sport. - officit applit plannit and organisations, number of excussioner ,prior asssssmt ,follow up teach. - follot up after .- teacher and human relations ship ,teacher and authority ,teacher and the princit, teacher and principles,teacher and colleagues,teacher Nd pupils teacher parents .. - class organisation and routine . Definition of class room management.the relation between teaching class manager , - the important of classroom management. -element if classroom management. Organising the classrt to create atmosphere for learning developing an effect classroit routine. - furnit arrangements changii classing storage and stirat facities.. - laboratory organisation pratical work . Grouping and teaching. - the structure Education department,head office advisory council for Education and training, regional control , circuit area office board of control ,board of many ,school committee hostel board ,parent teacher . - type of schot secondary school ,special school the . - explain correspondence and filing system: -the prescribed filing system ,subfiles , Directive regard mail ,register The school journal ,the visitor Matter arising from incoming corresponding. -explain : in service training: in service training for staff development aims the in servit training. -the task the principal: substance a travelling allowance Decentralized in service training role of head office in service . - delagating : What Delagaty means ,who delegates , in the school , difference bet ,the of delagatiib . - - co ordination : co ordinating teacher work ,subject meeting , coordination pupils , - performance: perfot appraisal performance appru , performance effective common value ,reviewing and analyse career development.- staring equipment,storeroom ,stick keeping teacher in charge ,papper order book kept number item , - safe check labo rules maint conductivity head office directorate ...- responsible post school ,power durie . - didactt oriet instruction and learning , Didactic principt condition ,the currit ,aim of the currit ,the selection and oral,( arraignment of learning .. - dudacting method and each ,lesson presentation evaluation .. - defining didact science pedagt ,.- didact and other relating teach ,didacic . - the didactic activit ,the didactic situat,general peadagogic andragific . Didactic environment. -tsxhook as didactic nature and structure ,task of the ,teach learning ,tertiary education institutions non firmaj cybernetics ,system theory . -------___________________________________ explain: activity guidance, -explain : self knowledge psychopedagogie , decision making stage , - choosing partion,examinat,tertair Education ,social conductor ,human relationships,the work. -need that can fulfied through work ,the career attitude towards. - testing: questions such follot may be set nocturak pedestrian shi preferably. -a grupe discussed: stlabutthem courtesy and road usage -the educational objet:to orientate the pupit in the relationship between coutsey and responsibilities. -the learning objectives:to identify the character of courteous road usage determine level . - to accept a losit attit award the requirements. - explain : solving problem : during the unlaxjinf of new mean of discussion teacher must si that follotbasic fact concerning courteous road usage trafficking. - pupils Alfred have knowledge: steering : it is difficulties to determine the main character the relation courtesy and is not clear jointly lesson problem is formulated .. - good maneee : unlocki new content pupils asked traffic low pupils matter how disret further points , - dunctt: characteristics of courtesy can applier motorcycle .. evaluation pupils completed self questions,@= alway, 2 = often ,seldom -
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
8 of 18

traffic ,control - questions: wath is functt if a lesson objective ,his is lease object ,why is formulated of a learning objectives important in term minimt an skill level of achit. - why is lesson problem import give 4 reason..-what us primary with demonstrate lesson .. - wath is importy. - during introductory phase of lesson them . - which important prerequisite applies to group ...-----_________________________________ 31. Life training religious,Cristian culture, art buchellor : Explant: administration Guide master form - explain spread gospel pratical & Admnistrat Guide master form , - questt after asked about . - introduction letter church member... -suggested sheet adver,suggested 1st years scheduled (33 weeks , - application form admnistration, -student address planer, -recors of tests marks and exams ,paymet of fees register, -attandance register , assignment register. - order for code cost and note ,record of orders, -certificate warding sample in cover ,-bible school survey compus registraty. -please take book apart except the last two sheet important documents read, certificate sample , certificate merited , certt Christian service ,diplome in Christ lead ,certt in word minister,licenciate in Christian ministries .. -----------------.... -32.explanation: marketing reseat the research process and problem . - structural eqt models ,neural networks,social net,- analysis ,factor analyse ,cluster analysis. -cass part , winscon power,stormt equt,canopy of core ,canopy production, food ,transitional housing ,picty word megabyt of ...- equipment,fabut -research report ,fundamt criteria if form of report the oral grapt presentation. - students guidence to office autimat : . Office start four kinds of infot infirmat processt operational office ,procedure office system office, - example of an office system designing and office ,system the impact of office automation on job. -office automation hard , - computer and office how computer work disk drive,work disk driver input output ,device networks other office automation hardware. -the electronics desktop,system siftt ,operating system task operating syst command . - operating envy. -recors keeping : record keet concept ,record keet task ,record keeping application type of record keeping . - software . - choosing a package. -spreadsheets: - spread sheet and database packau ,spread sheet package other spread sheet facitie and graphs spreadshtappli a.. Item loyal customer te - 32 explain: Educational the Mrs in time perspective. Explain peadagogic and perspective history of Education development .- orientation : Greek idea sophist concepts ,Socratic idea of knowledge the platonic concept ,Aristotelian idea on the infrastructure of Education ,the stoic Telos formula , - Roman idea , earthing Christianity ,media volbidea ,humanistt ide ,pedagy becomes ,pioneer of peadagogic founder of pedagt become science of historical original and development . - methodology of the history of Education.: orientation field of reast nature of problem of research ,general methodict,post minded futt ,factuality individual b,open mind , Conte temporality , setting the regret methodology unrestrained complexity present and future ,nomothecity .. +Professional competence personal enrichment.comparaison ,method approach,basic science method of investigation,them design field ,invesy of contemporary them , hypothesis formulation, investigation ,collecting data making , established information Education ,interprefinger data writing, approach for research, problem historical problem historical anthropology approach Mets bletic , history. - explain : development of higher education in general.comment , concept higher education a time instituts history functioning ,modern ..-explain college university criticism , justice. - established ,some .. - English education system ,control Education used ,aim content , - note ,the act preamble to the act ..some stipulation----------------------------------------------------- Aspect of the provincial Education system : - Education control , religious instruction,teaching medium . - a natit Education dispensation coordination uniform in education matter , preliminary work for new Education dispensation .. - policy keep with policy principles : change in some important Education matter , preliminary Education primary and secondary , division to schools course , the grouping of school , provincial Education , ---------------------------------------------------------- - 35 .explanation :General psychology low - the identification of psychopedagogie two , -method of psychopedagogie test nationalism the experiemental testing the experiemental method the clinak methods, naturalism observations testing ,the functy of theory test verification , modification form of modern theory . - explanation of behaviour reductions, explanation pattern , psychopedagogie influenced school of psychopedagogie present phylosophie - motivation , : explain motivation questions acquired classifying working . - biological energy recurring need measure activai stimulus transaction - discrimination conditions: other classically conditions response , instrumental learning and operant conditioning..- - reward and principal of reinforcement three learnings situation narration rewards non continouse extinction, stimulus generation learner reward negotivr reinforcement and motivation. .-learning : selective discrimination learning ,trial and error multimensionaliry learning.. - motor skills learnings motor skills task distribution of , transfer of training feedbay knowledge. - verbal learning : general procedure verbal rate presentation vfactor some interpretation in verbal learning transfer of learning concept.. -cognition memory: Measurements of two factor of retention,short term memory information processing memory control language, development, hereditary some genetic principle . - maturation: patterns of development maturation and experience. - some devely topics : perceptual development language development of intelligence development of socisk . - sociality interiors change communication society .. -consumer psychology: attention getting methods effective of advy other aspects of , structure,purpose Personal patter animal socisk manipulation social acquisition. -motion : emotional in history analyse Lyman emotion physiology functionalite, facial expressions. - acquisition emotional: limitations emotional conditions, learning developing and maturation of emotional,theory.. -psychologicsl stress: selyes ,systt stress psychological stress psychomat. Perception : receptor function:vision audition ,faction and skin sense kinds, - psychophysic : detectsbily low sublimation perceptions scaling ,.- - organization's : reception audition faction the skin equilibrium. - origin perception: development perception at distance visual depth movement perception,sound locaty colour perception colour their... - subjective color after effect illusion. - attention : matter orientation Tracy passive stimulation select. -attentiin analyse : neurological attention negotivr didactt listening institute , attention brief stability. - conditioning : the learning concept classical conditioning ,temporal relation extincty recovered higer order classical response .. motivation .. _________&&_&& - learning and memory at school in Learning psychopedagogie persscpectuve perspectt components of the learning memory. - model , - the affective level of the learning memory process sensory memory. -the cognitive level of t learning memory process Short term memory -the normative level in the memory process long term memory Long term memory epis and semantic memory why do pupils forget learnings . -learning subject content school -ainm ,learning model for subject content planning phase , planning and preparing subject content effective learn ,planing execution phase.. - step in the learnerinf process with reference to learning pattern level of drilling reinforcement and competency , -product phase ,level of proficiency,level of structure complex , monitoring the prodtphase. - communication the teacher as the exponey Education in transition teacher communicayteach ,communicat process ,general process. Communicator style noise , - Educationak medit for effective teaching media practice subject : teach computer in education class PC Education use for teaching - learning purpose :.computer aide instruction single PC managed available and placement of teacher : - social aspect of classroom practice Communication classroom , emotional aspect authority flexibility. - acknowledge of father people motional encounter ,transfer of value personal aspect distance. -function of teacher task directed functionalite of the teacher the social emoy group . - life orit: explanation competency life skill ,type of skill life orientation study research in respect.- -role : of the the church in realisation the role society . - the role of occupy life in the realisation of wath do emplot exception terrait planing for life skill trait. - explain definition terrain delimitation,the desit of programmtfor skill training a primary or secondary,CVS develot ,life skill modej ,religit Education theory and lrat. Agraindinf of the subjey ...- - handling of pupils of : Motional assisted.. - benefits the individual , orthopaedic they _______________________________________ Explanation: teacing the practice of nursing a text nursing didactic th. - nursing educst the phylosophie of nursing ,nursing educst . -the scope of practice of a registered nurse . - the scope of the role nurse. - the scope of pratice of enrollment nurse . - the independent and dependent of nurse ..the independent functy of nurse . Phylosophie of nurse ...- the historical of nursing education outline ,:introduy , nights syst, amercain system ,conbtini. - purpose : and object nursing education.: selected of Education object in nursing ,decide what student ,plan implementation plan , evaluation. - authoritie responsible for providing education . -regulatiin affecting nursi Education: Regulation country council ,RSA ,training registration and enrollment ,types course a Aila le registration, --_------------------- Safety health aid tools hand ,,,. Education safety health occupation,security. ,, ... Explain: what is pedagy importance of pedagogy in teaching and learning process , - what is pedagogy, - what is the pedagy in teaching, - difference between a pedagogical approach pedagogical technical. - type of peadagogic, - role of pedagogie, - pedagogie is method of teaching in theory pratical understanding student. - pedagogie in teaching in refer educator student lead ,LMS , construction. - teaching quality of teaching, encourage cooperation learn , eliminate mono learning. - pedagical technique ,a pedagogical technique. : defines a set of action performance by the teacher in the classe for teaching include flipped learn learning computational thing and stepped learning it is more granular Thant . - technological pedagical content knowledge understand of how teaching learning can participate framework an education. - technologiCal pedagogical content knowledge framework integrating knowledge record. __________________________________ - Engineering pedagogie educating ,focus if view of engineering pedagy is the development teaching concept creation for the preparation of further Engineering leadership roles changing . - explain problem base learning TVET engineering electrical, ________________________________ - explain ,educare qualifications has been designed for people love work with children be able growth development child phrase .. ______________________________ -explanation psychotechnique ,: system of actor training preparatory Deve theatre practical test measurement large verbal numerique ,test permis, suspension, permit v. QI. = Quotient intellectual ,age mental /age chronological . recruitment test suit logic. Is used to determine the degree of extrave Ce emotional stability professionalism ,as employment,is concerned accord board dimensions psychopedagogie. -______________________________________ Psychometric test : the main goal of an aptitude test is to ensure that a candidate passes the amount of skill and cognitive ability to perform the duties of job role the common skill set measure test numerical verbal and non verbal rea ... 39.Explain: pratical school , orientation industrial trade Pratical nated , - promote standardisation in trade and industry is one the objective of council ,CSIR -orientation industrial in electrotechnology.standard industrial draw and label gate by EIC system gate output,,explain neer . orientation industrial : in electrical trade theory ,domestic appliances: type machine washer , ,,- maintenance out replace element tasg ,replace ,stei pannej ,, - orientation industrial in plant operations theory ,chemestrt and chemical processing ,cellulose fibre material ,manonr,readrvcombustion fuel and thermal insuy,,transfer heat pump, mechanism , convection. - orientation industrial advantage close cooperation compagny ,industry ,, Functionalite supervisor control responsibility,the aspect to prevent is to teach workers not tact :teach work Teach worker. Discuss different between Education and training .. government instituts. - a supervisor realise account organisation position direction tools ,, - importance diRectiob stragie ,operationel ,, - supervisor selection worker job tools need , employees training performance - operator is need mechanical workshop machine operator for stocking material - industrial orientation in trade electrical Operator stock material orientation, By protection ,heart, illumination. Application , equation AC ,DC -___________________________________,_ -In dbe to isita project to teach workers In dbe teaching worker training direction practice workshop dbe ..compagny corporation City power Eskom : exam national DBE ... Explanation , orientation industrial vs manage supervisor,vs management system information vs manage system information in education key challenge n Career posting time table counseling: trademarks industrial compagny trade theory license and trade pratical license. Orientation industrial Teach sork disciplinaire work communication skill team study team operational discipline teach counselor assessment and facilitate team value Journal classwork average score Counselor statement ,by psychometric goal work counselor conduct misconduct coursework engineering Counselor engineering studies creation Portofolio assessment,and planing by ruling courtesy low common . In dhet ,,in DBE workshop technologie Counseling project by orientation checking low outcome workers project isita umalusi electrotech EIC commissioner in job experience -Minister creation secret arrested ministerial letter appeal step. Minister dhet and DST building infrastructure government system careers creation authoritie building creation, counselor conductor, complain compliance duty Orientation industrial guidelines project workplace disciplinaire, questions number of task number job project marktrad licensed , -appeal release result irregularity,non accreditation school instituts research trade training to minister ucpd , development isita creating DST ,supplier profile , regulation,minister irregularity creating diploma technologie system DBE and recreating system backlog ista Teach appeal low Education processing learn ,by abscent Clauseoffice ucpd record learner orientation ministers teaching students practice counseling orientation industrial and marking process presentation ucpd and DBE system was learn job in trainer training . - explain: isita project orientation industrial counseling experiemental - pratical experiemental irregularity assessment. back log ,,time table n4 ,,and time table n3 trade theory examination .. Irregularite suspension 12month ,n4 rwiten final n6 ,n5 final examination,final soon n4 examin irregularity final Examination assessment years academic final , -Level 5,6 framework qualifition letter no qualifications isita back log . Irregularite: 12 additional information pratical process learner completed: Management system information Level 1,2,3,4,5 vocational principle police theory ,applied resolved Orientation: principle . information management system: Pratical 12month ,18 month pratical subject pratical exam school . Topics test n 6 .. -in high Education subject assessment moderation project: In dbe subject it orientation vocational guidance: outmark DBE filing pratical Poe s Isita project student make computer Learning lecturer computer subject , orientation skill training computer system - information system , :computer - quest operating system ,display option control panel gives , - system tool data computer . Option , change display ,system defragmentation display.. - uninstall program system programs feature ,, physical formatting Calle relative , ram room cache memory ,folder created. - Process of converting or data into prevention b, software , fraudulent vpratice email personal information ,infects . - format pictures style drop ,use ,,spread is opened ,insert formulae .- appropriate spread sheet v. - appropriate functy determinat the price contract router .. - computerised systeme Create a news set of name select file compagny , - compagny parameter , business - word processing : create services invoice ,use Arial 12 pt , all .. - leave two line space , key ,, - unit and replace word megabity ,save file A,,fibre .. - irregularity,isita project back log record complain subject .. Assessment mathematics: -Orientation industrial and trade mathematics :teach workers ,trainer workers supervisor ,standard measure -Management supervisor, :mathematics Computer system management -geometrical, algebraic ,limited , dervide function Prove ,radius area high calculate approximate change in volume: V= π.r.r.h -use partial fraction to calculate b.. -determind particular solutions integration. - sketch the graphs of , the area bounded . determine the length of curve , equation, - calculate surface the curve , x ,y is rotated---------------------------------------------- Engineering ,orientation industrial: engineering physics T# compression : Heat heeded to bring heater , Heat gained ,heat lost - electrostatics: Power = w/t the amount of energy . - heat gained ,atom , frequently ,the energy of each ,,thermionic ,optical -------------------------------- - electrotechnical : DC : excitat motor control obtat adjust, Alternates - power
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
9 of 18

developed,rotor output ,, Power input = rotor output rotor . Energy Industrial electronics ,transient ,calcul value resistance to allow oscillation , Transducers : standard current ,step .. - ultrasonic x -rays and radii activt: the energy can transmitted the energy genert high , - electronics safety device and electronics ,regulator system. -thyristor device and scr speed . -,programmable logic controller.. Pratical industrial in dhet high irregularity regulation material project ,, Outmark .. - Counseling: project In dbe project workshop counseling Management supervisor workshop engineering,isita record academic ucpd Create diploma: certificate Counseling industrial electronic electrotechnique mathematics ,in trade theory electrical ,material irregularity DBE disciplinaire 11month suspension marking progress .appeal minister Pratical, action take occured irregularity and complain address ,, qualifications subject: 18 month technology guidence vocational module. Explanation : career vocational science ,, explanation low Portofilio. The police introduction - section Career orientation profile, -selection process ; choose career answers. -question reward live leave , professional answers occupation. -student guidance counseling police opportunity,, career understand job sleep skill , duty correlation, - peace officer preami,duty assignment case involy policing ,salary career allowance, duties securite function compagny invesy,older private police no longer existed replacement ,in function ,police minim case senior college orientation profile,psychometric , polytropic test college Deb employ , task physical , deduction probation life insurance, professional, listening ,career ,profey a matter an amateur career ,Unifor report ,court syst , division Pre trial paralegal ,, - police officer entrance exam police measure the basic skill ,exN read word duty -what is community oriented in policing range , innovation organisation police improve skill project build communy , procedure,practice , activities residents ... Explanation: irregularity Error test used for diffece between two independent sample satisfactory distributor performance: -service ranking ×1 overall,raking difference ,d1=y1-y2.(Bid sum .d.d = s data analyse invest assot agreement irregularity and back log project trademarks nated in job ,step process respond , provisional tax payer and penalty , understand and late submission,file Portofilio education trade , ,maturity date Poe s social award student , coupon rate 14%, internet,tendered bid or submitting 12%, tendered assumed accepted ,(1009),I R 709 interested,pay + c / 100×d, 3609,c = rate interested order ,d= number of day , 60 day proceed,R,1000=(1000×17,49,, denomination acceptance capital emploie, capital reserve resent taxation total assets liabilities balance sheet,manufacture -pat total retrenct , provided tax liability,salary and interest tax sum tax norm tax tax free portion award , provisional tax ,income salary overtime , allowance award irregularity plug ,equal renumeration leave,less acceptance of quotation irregularity and back log . __________________________________ 40..Management administration industrial , - products maintence tpm - H: rate of Quality products 98% ,ideal cycle time=0,8minute, f: actual processing time + j×g=0,8×400 t availability= s/c×100=400/600×100=87% -( m: operating speed rde= I / jx 100+0,5×0,8×100=6,25%,, - net operating rate = f/e ×100=(0,8×400)400×199+80%> I: performance efficiency ,+ m×n .100 +×100=(0,8×4000+80% -net operating rate = file + actual processing / operationek -process amount × actual cycle to operating+ 400 item× 0,8 % availability, Avat + operation time / loadshedding time day academic record and Pratical -net ... -time loading,400 Mon × 109+ workplace record accuracy,process running,planned down ,lost process ,time c- d ,, processing time ,, j×g operating time finished , external total, quantity processed ,total including losses memory , attander ,cycle , actually processing time - time × idee cycle actual appears= 400 item × 0,8 Min /400,, -ovarall ,, - job schedule job , production planning and control schedule date issued , relaxation total,credit 0-4 Min work earned ,1080 per× 0,4+43 Min work Min available work of 100 performance ,432 Min ,, 432/432 days of work = 90 out ,100 performance,Orla ,% is over all relaxation allowance mode rate .. ------------------------------------- B. Planned down time per day ,down time accounted for inhere proceed,--------------------------------------------------- a.manning meeting +29 minute loading time per day. A-B + 460 minute ,D ,stoppage loss per day ,break down,20 minute stop, 30 minute, adjustment -20 minute= 60 minute ,operating time per day -C-D= 400 minute ,G : output per day + 400 item file 42-Duty industrial trade college and industrial , - explanation ista project back log computer student make . -document wallet project office , appointment documents access post , -docuy wallet registration form appointment office , register documents emplomy, information recruitment documents Wallpaper wallet information,database stationery documents wallet ,arch office ,office size mass . - docuy wallet bank account ATM printer ,record book customer revie ,record registry I'd number system , documents wallet Portofilio job career , - database emploie system entry exhib , - emploie record trait job qualifications graduation training post advertised, - I'd register for customer entry databy job post sale reward , programme logic control custy logiy system I'd programmation language database .. - print I'd frame work student ,print I'd student information ,print I'd ,job duty post ,print task rosta ,price over time print labour .. -explanation: to -electronics digital analogic circuit: input a,b gate yes = a.B -storage : potentiometer coefficient resulted and reducing voltage integration by factor (6/12( initial ,x= 6/12 chart capacitor input , output and gate Inverter integral circuit dx/St,,6/4 ,13,, Sum,integer,summat,difference,RLC L.di/DT(R,,+2/c , integral.. -construction PC architecture design development: input unit yes mouse optical keyboard yes , card red,control unity memory RAM ,ROM yes output ,CRT didn't,CPU yes ,room ,yes I/o,year vertical ,8 bit 69 but ,64×#=655336, -memkry systt. -sequencw +3 yes ,0,25 yes ,a+b ,A,B rim , - row yes data ,yes gate output gate , transistor bibpolaire logic diagram ,static RAM ,select ,supplies logic , - booleen algorithm program read ,yes memory register , printer charge plate ,electrosty digital input ,character ,source ,Lazer mirror ,module ,ribbon tape supply. - data memory time yes, -128 sector memoire ,564 bit sector, input output devices microcomputer converter serial data , parallel decoding microspacev,ram 16×16 bineray yes -disc label plastic with write ed inde hold, - sectaire track ,2,255 but logic process read digital step motor, -ns ram yes ,ram yes ,ROM yes ,CPU semie conductor yes ,hard dic driver yes ,external yes flopy disc ,data 150 km to 12m,typical machine -3 bit /5bit/ secret,000A,/AAA@/ load AC ,oo#B/BBB - 00/ load output /001,001/ ---------------------------------------------------------------- -pc specifications format : Intel core 7 , external 975@,3,3ghz ,Intel ,DX58SO motherboard ,6GB,g skill trident DDR-200 channel gaineard ,GTx580 sponsored by vertex ,wD 320 GB ,data iu hard drive ,Intel core ,i7870 ,Gigabyte ,P55-UD6 ,LG flatro ,a essential up grade components AMD,procedure,chip choice the starting dusk x 2550BEb, CPU ,,X4 , 646 upward faster closely processor direct conflict shoe improvement load processor specific benchmark 3 d tendered video encoder x 264 ,, - graphic upgrade ,new little graphic card up date gaming phenomenon power × 2550 choice graphic card filled card up grade ,sub R1,500 udger choice HD 5770bigger to jumping performance Dx ,10 gaming word in conflict , - platform up grade ,CPU u grade path for LGA ,775 socket mother PC 3Ghz,core ,3500 CPU ,4 GB of DDR,ram direct ,x9 tessellation performance heaven ,,2,5 / frame per second higher better ,base systeme with sapphire,HD 550/#7 - upgrade to HD 6959 -ditect ,x 9 gaming perfot.. -one the card edge graphic tracker #gb , sapphire 5850 Xtreme ,retailing R2000 ,price complain 6 pin power connector which PSU hard physical driver installed benchmark away result disappointed ,3 marks improvement word conflict did manage ,lost planet frame wallet being ,R2000 ligth completed reliable, - battery ,g ram ,slot ,#gb,systy memory sticks R150 ,ram benchmark -upgrading memory and processor GB ,test window ,CPU the HD , -weigth components for the perfect budgy building , perfect machine Mother board F#A75-M-R1.100, processor A8-3859-R1,300,, -ram ,corsair ,4 GB,,:1600mhz-R1000 -graphic ,xFx random:HD6670-R1000, -storage : 750 GB - R 619, opacity ,re R200,PSU corsair ,430w ,R470, chassis : cm elite 343/, total :R5,369 ------- Build test installation CPU Vital - compot case layer CPU guard lockdown,add cooler and fan fixing bracket underneath ,screw holes fitting connect mbod,fit the ram : open the catch snai lock. Motheboymemory Chanel ,# and 3 operator, Hook connect ,2+4 pin connector to mobo ,the 8 pin EPs cable whichever,. - test the company power that sucker uonturning , screwdriver,striking the balance corsair ,4 GB ,,1,600 MHz ,DDR3 ,liani ram share system,CPU gaming rate ,2,34 MHz ,and 1,600mhz case , - Pre the case bit ,atz mounting screws install the PSU ,bottoy cable module drop in mother remove CPU from mobo CPU - test it still works connect cable case fab ,tech analysis: 2560×1600 screen Gami surplus frame ,R14,09 flashi ,CPU rendering performance. - cindbonh ,R#1, Test ... 44.Explanation:Technologie compagny: Teasing compagny , requirements market technologie solutions customer product security surveillance network point , - mission : provide technology added value business provide quality products , - valeur accountability ,,. - LCD monitor screen size ,22,5" , 6 viewable image size : 546,86 mm display area : 476.H,,,268,2,v).. mm brightness , typical : 300 CD/mm, contrast ,ratio ( typical ) 600000:1(DCR) response time ( typically ) 5 ms , viewing angles 170/169,max ,, - resolution : 2920×1080@ ,60hz -HDCP compatible ,yes ,input signal : analogy ,RGB ,,and user control menu entry image ration source up ,consumption power ,on < 49 standard < ,wall mounted ,visa 100 mm , mechanical function tilt ,5-29 - special features : touch key USB , - type Gori - 335 case type ,ATx Min ,case motherboard : micro ATX , external up ( up to 13"×9,7),(p4ready) - power supply: 400w Culp ,P/s with 22cm fan ( 20+4 pin socket ,775 ready,.,,5,25" drive bays : ,3,3,5" drive hidden , expansion slots: 7,I/O interfy USB × 3 mic ,1 spk ×2 cooling fans front ,80mm,×2,rear 80 mm×1, dimensions,( D×w×H): 410×182×425mm,M/t(cuft):1,73. - print mount USB audio high green LCD fan external ,= 4,5,25" and ,3×3,5" internal driver bays ,4× 3,5" HD ,system board ATX form facty ,13"×20,5 expansion slots standard ATX material steel , - dimensions: 52,25×20×45 cm - raid max modular cabling system durable , titanium mirror grade block wraps mesh cable to mention ,20 toal power connector for computer ,type ,ATX ,12 EPs ,22v maximum ,power ,fan ,135 m blue led ,PFC ,main connector , - rails PCI e connector ,2×6 pin ,,1×6+12 ,pin modular cabling support yes , energy efficiency ,up to 80 % ,over voltage , - network cable . 5 cabling : 500m,solid , 24 AWG,,0,5 mm ,pair ,grey ,305 m flex or solids ,to ,24 AWG,,05mm ,pair ,,cat 6 cable ,305 flex or solids uti,24 AWG ,0,57 mm ,4 pair Gray .. - cable tester digital tester ,cat 5. - toolkit ,j-059 long nose pliers (159,mm) by micro cutting pliers ,by ,339 cable blade trividr hyp ,5022 wire stripper , by 567 telephonic plier ,8 p8 ,/-45 punch down tape,2,mm knife , 539 soldering iron ,39 w cable tester tweezers ,125 mm ,crysty, tester , tweezers 225 mm , crystal, screwdriver,+- module plug RJ ,- 45 / 7 PC , PC plastt box ,315× 255×55mm ,crimping ,tool ,Rachel type dual crimping ,punch down tools ,walls boxry cat singltpart,45 key Stine jack , surface ,car 5 double ,RJ 45 jack ,carb , - connector ,boot sleever ,RJ45 cat micron connector , standard cable make female ,15 pin VGA,extenst available ,in 2,0 m ,,3.0,,m,5 / male 25 pin,, -1000VA/2000VA,rack mount ups, - patch panel 24 port it cat ,5 a panel ,w,t back ,bar ,48 port cat ,5 panel ,, - battery voltage ,24 VDC recharge ,8 hours to ,90% charger input voltage ,2# vac ,, - or 220VA,, output,wave from pseudo,wave protection outshort city overload protection with current limiting protection ,659 VA line interactive ups ,auto restart recover , provide ovrlot protection size ligth,b microprost control ,proviy modem phone ,line surge protector optit , equipment input ,voltage , building DC start functionalite enable ups ,input commercial power range ,145 vac ,280vac,avr range ,265 vac , frequency ,59 ,z #0% ,, output commercial power, sine shared frequence AVR voltage , 229vac ,auto sensing transfered ,b gross weight ,6,2 ,size mm,D×w×H,,,, 260×96×135.. - data manufacture data security , securite technologie PC , undertaking ,self finger printing , maximum b,test winner , antivirus program,,engine ,anti spyware,antipising, systeme tuning, firewall,internet ,award technologie,double scan outbreak shield , integration block,file archive ,formal ,heurisy detectt of virus ,client security , manager server ,agent notbooj server memory ,, - - Serie projector ,3 projection sysy ,3,LCD ,panel,2 lense projects , system ,resoloi was resolution.. _____________________________& ,- adabase ,storage data, association, emploie..file edit mask array , more, systeme, session systeme, system data. Area program ,nucleus ,buffer pool / ,I/o General,file control block field data space command is added , database, Empl modification,leave ,,name ,title ,edit----------------------------------------------------------- -Triggered: gitlab,/ GitHub /azure Issue test .. -Triggered electronic elektor technologie -Circuit microcontrol ,, -Gitlab ,fail running Issue kananga ,, Engineering tshingombe Project ,commited contributing ,code source ... tshingombe fiston Sep 16, 2024, 9:29 PM (5 days ago) to tshigombekb, me Explanation: asssessment task management system information Back log isita : orientation police career Pratical Platform software engineer,policy data right met career ,detective career electronics engineering,detective met Tableaux design analyse investigation research police forensic digital print report , intelligence felonies vector design source analyse report evidence - ID submission: 22255 Your :tableau blue print assessment results thank ,completing blue print assessment:: Find everything building action plan get started tableau kit collection resource whitin organisation ,creating data culture happen by flipping a switch professional: - agility deployment monitor maintence typically,it led effort understand board technical requirements. - capabilities agility ,low high . - recommendations to building your agility capabilities,recommattiin to building server , understand hardware, network, database , application is first step in planning server installation. Review tableaux deployment section , completed the enterprise architecture in the the tableaux blueprt planner . - leverage installation can tableaux server implementation to deploy authenty and details, configuration. - manage tableau licensed: license be manage accordt softt license process allocating ,use changing tableaux analyi skill in trade , reclaiming available tableau licensed . - reviy tableaux license level for the company. - deployed client software desktop prep builders,if virtual desktop determine want to manage license. - monitor tableau server process status server process monitoring back group job runseever ,job include extra data slots admnise process fail so corrective action can be taken ,, - configuration critical information platform outage take immediate. 2 - configuy notification system alert and faillure process state drive space constraints instat. - define a process how admnistration will response alerge triggered issue ,, - reviews performance thresholds Claude understand systeme proactive admnistration view. -monitor license utilisation administration monitor usage answer using if you need , - review admnistration view for monitoring. - completed loadtrst capacity planning load testing understand data work load usage capacity planning , - performance database maintence free space review database maintence.. Installation add extension on tableaux. ------------------------------------------------------- -tshingombe Tshitadi - Dev Engineering south africa traiblazet profile : communauty .sale force : Rank 115 badge | 22,125 point |7trails - earn ,6,875 more point reach maintence - career mode , certificate - network security planning, application ,security basic , network care ,security ,cyber security threat and three -------------- Work book : tshingombe , executive, summary Pipe : value , discovery , negotiation,prose , qualifition,, - topics learn objective take stock of your building energy use stationnnary assets data for key field ,few calculation . -refrigerant emissions factor : global warming ( GwO) Coolin create record . Auto calculated , emissions in CO2 ,scope corresponding ,entered , -:sum explored key information energy record for a stationary asset emissions ,Miami stationnnary asset envirt,fuel const details NTO headquarters Miami , monthly electricity bill ,electricity 1000kwh ,NTO diesel 1000 litre NTO headquarters ,W1 refresh bilk ,10kg ,calculation of electricity related emissions,the unite state ,us .. C02o emisst rate for location based emissions factor = 396,78 g/kWh Location - based coal -miz percentage ,20% Location based gas mix, 47% Location based nuclear. , 11% .. - scope ,2 location - base emissions ( tc02)= electricity consumption ( in kW) - emissions factor ( g/kW ) ,/ 10^6(tC02, convection factor ,100*396 .78 / 100000000= 0,3968t ,c02 _____________________ - information is calculate ,base grid mix - location based electricity from coal ( kWh) 29% of 100kwh= 200kwh. - location based gaz 47%,10000=470kwh - grid mix stationary càlcul,12% of 10000kwh = 11000 - Simi core reference fuel factor record warning potential GwO of CH4:28,GEO of N2I=265,,CH4 emissions factor ,co 2 emissions factor ,C02
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
10 of 18

emissions factor ,N2I.. - diesel : 15 kWh ,, 12,45 tones / MWh,, Consumption of diesel ( 1000litre is first converted to is kWh , calorific value ,15 kW/ K,, - total fuel consumption = 1500kwh ( 1000×15) = 12,45 × 15000/1000)=186,5 Calculate refrigerant emissions are calculate fuel type is refrigeration sulfure Hexa fluoride ( sf6)- IPCC ,,AR ,2007 refrigerator emissions factor record specific global warming. - scope , emissions ( tc2e)= GwO)=Gwp×fuel . Green house gas emissions result on stationery asset enert. - Salesforce helo create a stationed asset environmental source record. - Map, stationnnary asset environmental record type . - create an electricity emissions factor record - create an electricity efactor record ,other emissions factor set record .. - Grid mix information : comparison data Quality metrics ,, - eisten case case predictive intellence Consol , Zero claud calculate ,daily energy consumption ,F gaos -------------------------------------------------------- Action user tableau cloud . Wath is action specify user taking this site user name ,wath action user taking , Line x coordination -2 to 150;,, Access interactive action ,,0,50,1000 - published download action ,, subscription b.. - item name ,action :. opportunity tshingombe pipe ,use data source . -home ,,access view -engineering tsht : ----publish workbook Executive ,summary ---- access view - pipeline analyse ,access view - login ,access view , published workbook published data source ,user data -------------------------------------- - metropolitan: met request intellectuel property ,IP license ,date 03 July ,2024,time ,this form has been sent to metropolice police via online home report service<MIP-332-24-0100&00 Detailed ,title ,, --------------------- Indicator ,saps Protection VIP ,detective manager syst Infor ,,. ph ,base ,acide ,, concentration solutions ------------------------------------------------------- Microsoft form : (HTTPS form office .com page N diplomat award certificate national framework :--------------- Response overview ,active : Response ,average score,average time time. - response submitted choice , questions,number ,option ,option 2, Level system ,1,6 5,0 average rating.. -diploma award certificate national framework qualifition design engineering studies ,dhet labour ,. - skill development learn --http// form.con / page/ design page ,v2 ,ASPx,origin = neo portal ,,30 PG Claim your free Microsoft Certification exam from the Microsoft Learn AI Skills Challenge Inbox Microsoft Thu, Apr 25, 11:30 PM to me View in browser Congratulations! You can now claim the free Microsoft Certification exam you earned from successfully completing your Microsoft Learn AI Skills Challenge. Use the voucher you earned and schedule your Microsoft Certification exam before it expires. Voucher code: MSPR97002022 Expiration date: 6/24/2024 12:00:00 AM Schedule your exam now You can only claim one offer per person, regardless of the number of challenges you complete. This exam offer is exam-specific and only redeemable for select Microsoft exams. Once your exam is scheduled, keep preparing by checking out certification resources and additional content related to your journey. Have questions? See the official rules for more details and find answers in the challenge FAQs. Privacy Statement Microsoft Corporation, One Microsoft Way, Redmond, WA 98052 USA Challenge Collection AI Skills Challenge: Build next generation apps with Azure OpenAI In this challenge, you will learn how to build Azure AI solutions, rich search experiences, and generative AI apps that combine large language models with enterprise data. You will work with AI Search and AI Document Intelligence to bring these solutions to life within Copilot Studio. • 19 hr 39 min • 27 Modules Official collection by Microsoft Created by 47% Completed, Get started with Azure OpenAI Service, Build natural language solutions with Azure OpenAI Service, Apply prompt engineering with Azure OpenAI Service Generate code with Azure OpenAI Service, Generate images with Azure OpenAI Service Implement Retrieval Augmented Generation (RAG) with Azure OpenAI Service Fundamentals of Responsible Generative AI Create an Azure AI Search solution Create a custom skill for Azure AI Search Create a knowledge store with Azure AI Search Enrich your data with Azure AI Language Implement advanced search features in Azure AI Search Build an Azure Machine Learning custom skill for Azure AI Search Search data outside the Azure platform in Azure AI Search using Azure Data Factory., Maintain an Azure AI Search solution, Perform search re-ranking with semantic ranking in Azure AI Search Perform vector search and retrieval in Azure AI Search, Plan an Azure AI Document Intelligence solution Use prebuilt Form Recognizer models Prepare for the renewal assessment o in • Module Build a Form Recognizer custom skill for Azure Cognitive Search Get started with Microsoft Copilot Studio Manage topics in Microsoft Copilot Studio Work with entities and variables in Microsoft Copilot Studio Enhance Microsoft Copilot Studio copilots dev.azure.com/tshingombefiston0091 is now ready! Azure DevOps Sat, Oct 12, 9:00 PM (15 hours ago) to me Azure DevOps Welcome to Azure DevOps dev.azure.com/tshingombefiston0091 is all yours. Azure DevOps gives teams access to a wide set of developer services we think you'll love. Plan smarter, collaborate better, and ship faster with a set of modern dev services. Start your project Invite your team Invite fellow developers to your team or project to drive improved collaboration on your code, or create backlog items and bugs for tracking status. Stakeholders can check on a project's status and give feedback for free. Add users Details Your organization URL https://dev.azure.com/tshingombefiston0091 Your preferred email tshingombefiston@gmail.com Review your details See your personal page Need help? Check out support options Keep in touch Sign up to receive periodic emails giving you resources, tips, and information on using Azure DevOps. You can unsubscribe at any time. Subscribe This message from Microsoft is an important part of a program, service, or product that you or your company purchased or participate in. Microsoft respects your privacy. Review our Online Services Privacy Statement. One Microsoft Way, Redmond, WA, USA 98052. Sent from Azure DevOps VSS, engineering data portal - TrackingID#2403110060003192 Inbox Marek P Thu, Mar 28, 1:51 PM to me Support Dear Tshingombe, I am contacting you concerning the support case 2403110060003192. I would like to inform you that it has been 2 business days since I asked for your confirmation if your issue was resolved. As I have not received the confirmation, I will close the ticket for the time being, however, you may always contact us again. In case you need any future assistance, please go to https://my.visualstudio.com, use the Get Help tab and click on “Create a new support case” choosing the most suitable Category, Subject and Issue. You will find additional self-help resources, troubleshooting steps and possibility to submit a support request. You can also directly follow this link: https://my.visualstudio.com/GetHelp/AssistedSupport Due to the fact that the above-mentioned ticket will be closed, after this interaction, you will receive a separate closure email with an opportunity to tell us about your support experience. Your feedback is important to us. Thank you for taking the time to share your valued opinion. Kind Regards, Mark Visual Studio Subscriptions Team Europe, Middle East and Africa For our contact details please visit: https://www.visualstudio.com/subscriptions/support/ Web: https://www.visualstudio.com/ Subscriber Downloads: https://my.visualstudio.com To protect your PC against viruses, click here: https://www.microsoft.com/security About Microsoft Ireland: www.microsoft.com/ireland Microsoft Ireland Operations Limited. A company incorporated and registered in Ireland number 256796. Registered office 70 Sir John Rogerson’s Quay, Dublin 2, Irel d Emerituys college research compagny component desig, work experimental basework institu private organisation and university work base experimental univesal faculty memorendum # Starter pipeline # Start with a minimal pipeline that you can customize to build and deploy your code. # Add steps that build, run tests, deploy, and more: # https://aka.ms/yaml trigger: - main pool: vmImage: ubuntu-latest steps: - script: echo Hello, world! displayName: 'Run a one-line script' - script: | echo Add other tasks to build, test, and deploy your project. echo See https://aka.ms/yaml displayName: 'Run a multi-line script' #20241013.1 • Set up CI with Azure Pipelines Claim your free Microsoft Certification exam from the Microsoft SummaryCode Coverage Triggered by Tshingombe TshitadiView 2 changes Repository and version Claim your free Microsoft Certification exam from the Microsoft main83bb7532 Time started and elapsed Just now - Related 0 work items0 artifacts Tests and coverage Get started Jobs to me Workbased On Tue, 15 Oct 2024, 21:02 tshingombe fiston, wrote: Job Microsoft :career recruitment and training path .record transcription - senior software engineer up to 100% work from home , -digital experiemental management,principal engineering,manager,,senior business planned analizing, senior security technical ,applier security technical ,,applied scienti,web security, research ,student . Hard work engineering,mechanical engineering,electrical engineering Firm engineering Data : posted ,,job. Number ,job site ,travel 0-25 . Overview: artifice : intelligence Microsoft project build a platform based language ,llms copilot clean web technologies trend ,. requirements, bachelor's degree computer science ,java script Luton technician experience database azure Google , responsibility work the delivery high quality service power Al search stability reliability participate in design review development of clean well documented team member plan and execute .. On Wed, 09 Oct 2024, 20:07 tshingombe fiston, wrote: - Microsoft certification close Pearson instituts Graduate institute high Education. -Department : DHET high act No,101 of 1997 ,as private.reg high Education reg Certificate No:2004/HE7/004 -accreditation qualities (HEQC),(CHE. Record transcription academic , ------------------------------------------------------------ -bakc log ,Sita -Ref saqa . -pearson instituts/St peace college instituts, Africa police instituts , Intec institute, saqa foreigners instituts ---------------------------------------------------------------- -Qualification|minimum admin req----------------------------------------------------------------- - foundation| national NSC certificate ----------------------------------------------------------------- Programme| diploma ordegre - bachelor. | International school. Degree |living certificate,accompani | Saqa certificate | national senior NSC NQF | Exemption certificate usaf ----------------------------------------------------------------- Honours. | A recognised under grad Degree | degree module level ----------------------------------------------------------------- Point institute Pearson NSC%. |90-100%|80-89%|70-79%|60-69% |50-59%||40-49|30-39|------------------------------------------------------------- Ncv%. | Nated%| Ucpd%| -------------------------------------------------------------- Faculty humanities :/ Bachelor of arts , Saqa I'd : 62761|NQF level: career opportunities child care communication humanity resource management marketing research , public relations research teaching writing -nated : educare : subject record transcription, personal training facilitator assessor saqa Ncv abet NC's matric technical record : Lecture - ---------------------------------------------------------------- -bachelor of arty in graphics design saqa ,ID : 99332 ,NQF level : career opportunities advertising branding design ,3 D modelling animation broadcasting copy writing desktop publishing layour and illustrations entrepreneurship web design. -Nated : drawing engineering,PC business record -------------------------------------------------------------- Bachelor of arts in journalism saqa I'd : 488832 NQF : level 7 : career opportunities communication editorial work for magazine communication editorial work and news papers journalism , - presenting television social media research . Education actually technologie Nated : media record prensted rwiten---------------------------------------------------------- TSHINGOMBEKB TSHITADI Fri, Oct 18, 8:34 PM (2 days ago) to me On Wed, 09 Oct 2024, 21:12 tshingombe fiston, wrote: -faculty of applied sciences. -bachelor's of science in computer science saqa : is 74131 NQF,6 level 7 career database administration IT management net work admnistration programming software developer system analyse project administrator specialist enterprise architecture and open system : - Bachelor of science saqa ,ID 62754,NQF level : Career opportunities business analysis database administrator IT management project management specialist position.it system analyst .. -bachelor science in internet communications saqa ,ID : 6274 NQF : level ,: Career journalism networks administration technical liason technical writing web editing . - bachelor's of science in biomedical,saw I'd : 6275 NQF , Level: career scientifice communication technical position in laboratory project management academic research. Management science communication technical , - bachelor of science honour information technology , .ID saqa : 84566 ,NQF level 8 . Career opportunities: academic it manages programming project administrator specialise Technical position position in data mining and entrepreneurship architecture system analyse ----------------------------------------------- Faculty of commerce and low ,saqa 48858 NQF level , admnistration:career opportunities business business consultant economist entrepreneurs. - bachelor of commerce in accounting: Career auditing budget financial management ,tax consultant account charted financial cost . - bachelor's commerce hr manager consulting personnel consultants recruitment training and development employment relations manager and count. - bachelor's of commerce low business administration entrepreneurs politics . - saqa I'd commerce in marketing manager I'd 488822 advertising sales manager marketing Anat media ,to -tourism management is eco, tourism planning event strategies, market research bachelor's of commerce in business management,saqa ID 84326 NQF level 8 counseling entrepreneurs management.----------- Faculty engineering: Bachelor Nated saqa I'd lecture learner Bachelor nated trade engineering trade Distance :level 7, degree I'd: instituts engineering council engineering electrical instituts engineering Bachelor: Faculty, police police instituts Saqa instituts: level 7, degrees Bachelor: ---------------------------------------------------------------------trade sector training trainer bachelor's Serta ,seta career opportunities guide schools leavers , university of technology,and university leaver,and college leavers . Career ICT : information communication , technology ICT: technical skills research design development testing installation commissioning maintained product software prodt modem via media land wireless.. - computer. |NQF|4|5|6|7|8| total req networking|lev3|. | | Occupation code 263101: developm program 261302 ICT business analyst 261303 ICT customer support officer 313104 computer system technical 263193 system ,test engineering ICT : securite special ICT : project manager ICT : sales represent - systeme representative system analysis project , database admnistration telecommunication,web development network ____________________________ ICT Microsoft office Occupation | recommend It| recommend -13510-projec| language,c#,have,ado,asi,nsd Management| Database ,Oracle,htk,sap java,net .. - 31314 , systeme techniciens| hardware at, ICT support engineering PC network and Eng - description of the top ICT occupation: Project plan organise direct control co-ordinate qualifition account day to day operations of resourcing schedule priority. Task : skill analizing need. - software engineer design modified documents test implementation installation software support with . -ict : assurance ,create maintence manage quality assurance functionalite performance of PC audit ensuring compliance accreditation scheduled qualifications inspection analysed review system data docut, identified potential risk area in security non compliance with stolen detect. - network ,systt plan deployment test optimisation taking responsibility analizing interpretation data model in developm research monitoring assessing improve network , provided network performance. - ICT securite special established organisat ICT securite procedures ensure prevention recovery strategy internal exterior , ensure prevet recovery strat . - customer support Offit provide support Education developm maintence infrastructure resolution technical problem issue may work. - determined hardware response program to meet usase installation appropriate soft , implementation PC network,repairs performance. - business selling compagny using director ,quotat price record order ,monitor client competition active maintenat submitted record business. -forecasts sale force : / HTTPS:// momentum 6463 ligthning force . - tshingombe Tshitadi:. Forcecast |quota|closed only|commit|be Month |® |R13900|R258500|R258 July - opportunity for July 2021 open pipeline R2645000 -opportunity name | account|amount |clo 1.globalR 19500•2024|negotiation|90% 2.acre 225|R4500. | Qualifi|10% 3.sales force |R10000| ________________________________________ Home | Microsoft 365 Free : 18,3MB used ,5GB% ______________________________________ - HTTPS : GitHub .com / kananga 5 ,tab = repository. -overview | repositories| project | packag - engineering database help memory trainer trainer framework base - Engineering - tshingombe theory pratical base framework assessment.,met tableaux trailhead , workforce badge. Boost software license .2.0 - engineering tshingombe.theory practice base framework assess met ,Scottish sqa . - digital ,private security career labour
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
11 of 18

bargaining career met metropolice train . - Engineering theoretical pratical framework tshingombe mi- engineering letter experience theoretical pratical . -engineer tshingombe letter experience theory assessment wallet . - java selenium sample . - assess tshingombe lab libraie technical documentation. - Autodesk edge engineering. -job engineering integrity career GitHub azure result. - skill development labour and conciliation security. - memotexh engineering dhet saqa back certificate. - eny libraries technical documentation - GitHub . - engineering tshingombe council. - engineering career attatic - career student ass exp science engineering - tshingombe engineering scie bono work integrity - tshingombe enginering data science, sciebono - engineering scie power hand book city power Eskom Education technology education technology career saqa . - engineering electrical Saqa complain. - tshingombe challenge Microsoft building word cup project - Education technologie Sawa results - tshingombe data excell VB reg . - library arch excell VB master _______________________________________ - tshingombe Tshitadi resume/ trailblazer career | http :// trailhead.saleforce .com career - career mode , preview - open to remote work , open to relocation Career mode off . - o yrs ,sale force experiemental ,0 certificate ,0 super badge,. - career path , prite ,/899 points , earn ,2,200 point. - work education,project 6;badge ,data analyse fundamental, - artificial intelligence for ,certi Pre ,sales force AI association. - artificial intelligence fundamental. -prospect tracking with sake lead quickly look. - module Project Trailhead ________________________________________ -certificate for previous papoer exam nated. Certificate Previous papers ,| secti RSA | user trust | Validation| certificatio | Secure service _______________________________________.subject name: Common name ________________________________________issuer name | Country | State provic|greater Manchester Locality. |Salford Organization's|sectiga Common| sectogi RSA domains validate ________________________________________ Validity | sun,05 Feb 2023,,00:00:00 GMT Not before| this : o7 March ,2024 ,23 -________________________________________ Subject act Names : DNS name : previous papers .co.za DNS name : www.previouse . ________________________________________ Public : key info . algorithm: RSA Key size : 2048. Exponent : 65537 Modulus : B5:13:9A:7F:9F:E5:A8:79:9F:57:28:C4:4C:94:C4:A6:3C:A6:3C:3C:1B:27 ________________________________________ Miscellaneous: Serial number: 73:D1:F1:19:36:A5:05:4B:69:cF:45:48:52:6- signature algorithm : SHA- 256 with RSA encryption. - version:3 - download ,PEM ( cert) PEm _____________________________________ Finger print - SHA-266: 2C : CB : 79:67:8D:A2:DF: B3:4B:EE:39:9D:08:EF:45:D0:49:3E:36:07:06 SHA: 24 :C3:79:BA:F4:D5:BF:62:58:39:55:4A:C5:C5:B6:56:B7:92. ____________________________________ Basic constraint certificate authority No _______________________________________.extebd key usage - purpose : digital signature key server authentication Subject ID : Key ID : 4C: AD : A7:D3:43:67:46:AD:DD:55:37:49:B4,.key ID------------------------------- Authority : info ( AIA( Location: http:/) CRT.ssctigo.com /sectigi.rsa.dimaib validation securite Method : CA issuer Location : htr//ocsp .sectogi.com Method online certificate start protocol,ocsp ------------------------ Certificate police -policy : statement identifier ,( 2.3.6.14) Value : 1.3.6.1.4.16.4.2.2.2.7 Qualified: http:// sectigo .com/cps Policy : certificate.type (2.23.148.1.2.1---------------__________________________ Embedded acts Log ID:76:FF:88:3F:0A:B6:FB95:52:C2:61:CC:F5:87:BA:34:B4:44:CD:BB:29: Signature algorithm:sHS - 256ECDsa Version - Time stamp :sun,o5 Feb ,2002: p7:50:55 Log ID: EE:CD:D0:64:D5:DB:1A;2A:CE:C5:C5:5C:B7:B4:CD:13:32:87:46:76;BC:EC. - signature : algorithm ,SHA - 256 , version Time stamp sun ,05feb , 2023:07:59: ___________________________________ Request on intellectual property IP license __________________________________________diploma award certificate examination national : HTTPS :// form .office .com/ pages/design page.V3.ASpx ?origin= Nei portal ------_____________________________ C,:>user>library tree app data >code user profi\e 1{ 2} 3 name : build , code quality 4 name build ,code quality 4. 5 job 6 build 7 8 9 run - on Ubuntu - latest 11 12 step: 13 uses : action ) checkout @v1 - name : set up .JD 1.8 - uses : action / setup - with app name : Wze ba ) sample token: ${{ secret.APO _ center_ Group Tate File aoo build outmname upload artefac to app center with File aoo / build ) outbut ) aoj - start- contribution Module Zejdu / aoo center - gthub action Report abuse Aoo center distributee update note is not certifie by GitHub On Thu, 10 Oct 2024, 20:25 tshingombe fiston, wrote: - continuing and training,act No16 of 2006 amendment,NQF ,act No 67 of 2008 ,as amended , determination phase N1-N3 term ,sect 42(1)(a) training dhet ,N1-N3 juanert ,2024 , dr zimande trade test ,trade occupation revise.. ----------------------------------------------------------------testability checklist at the schematic level. - testability checklist at the PCB layout level , - revising design. Win existing ICT creating a test point report manufacture.,PC designer PCB relay project status information,PLC. - PLC wiring ,main breaker switch busbar circuit breaker SMP digital input output analif input terminal. -reaning PLC wiring diagram, profit bus communication PLC , digital input card diagram ,PLC digital Re: for multiple positions Inbox TSHINGOMBEKB TSHITADI Fri, Sep 20, 2:47 PM (20 hours ago) to Thandiwe, me On Thu, 19 Sep 2024, 17:15 Thandiwe at Jobrapido, wrote: Unsubscribe You've been a little distant lately. Have a look at all the jobs you've let slide Engineering Electrical / Engineering - 15km Apply Now Engineering Electrical Apply Now Remember to keep your searches simple, updated and fully completed EDIT YOUR SEARCHES Help Center | Unsubscribe Jobrapido S.r.l. via Paleocapa, 7 - 20121 Milan - Italy- Tax code and VAT number: IT11876271005 You are receiving this email because you subscribed to the Job Alert service, accepting Jobrapido's Terms of Service and Privacy Policy . Re: FW: SABS- Online enquiry Inbox info@sabs.co.za Thu, Oct 12, 2023, 11:06 AM to me Good day, Tshingombe Thank you for your e-mail enquiry. According to the information below, your enquiry has been identify as complaint. Pleaser elaborate more on your subject. Regards, MamtshaliMefane Customer Services T: 0861 27 7227 | T: +27 12 428 7911 | F: +27 12 344 1568 | www.sabs.co.za >-----Original Message----- > From: INFO@sabs.co.za > Sent: Monday, October 9, 2023 6:31 PM > To: > Subject: SABS - Online enquiry > > Online Enquiry > Subject: Complaint > Name: Tshingombe > Surname: tshingombe > Phone: 0725298946 > EMail: tshingombefiston@gmail.com > Company: Tshingombe assessment engineering electrical > Address: Percy Street 20, Rockview 103 yehovill jhb SABS Client: No Products / Certification: Trade engineering electrical research city power , Education Engineering electrical > Industry: Other > Comments: Education Engineering electrical subjects nated > DISCLAIMER:This electronic communication is sent from the SABS Group of Companies and complies with the communication requirements of the Companies ACT. For further information please visit http://www.sabs.co.za/Terms/index.asp Your SABS EMC Department order confirmation Inbox SABS EMC Department Sales Sat, Sep 14, 5:48 PM (7 days ago) to me tshingombe fiston, Thank you for your order from SABS EMC Department. You can check the status of your order by logging into your account. If you have questions about your order, you can email us at emc@sabs.co.za or call us at 012 428 6700. Your Order #4000000618 Placed on Sep 14, 2024, 5:47:42 PM Billing Info tshingombe fiston rockview 103 / yeohvill ,jhb percy street 20 jhb, Gauteng, 1030 South Africa T: 0725298946 Payment Method Bank Transfer / Wire Transfer Direct payments to be paid into: SABS Commercial SOC Ltd, ABSA Brooklyn 40-5322-5013 Branch No: 632-005 Items Qty Price ALABFULLTERM SKU: ALABFULLTERM A-Lab Application ID 14 1 R120,000.00 Subtotal R120,000.00 Grand Total (Excl.Tax) R120,000.00 VAT (@15%) R0.00 Grand Total (Incl.Tax) R120,000.00 Thank you, SABS EMC Department! DISCLAIMER:This electronic communication is sent from the SABS Group of Companies and complies with the communication requirements of the Companies ACT. For further information please visit http://www.sabs.co.za/Terms/index.asp Disclaimer The information contained in this communication from the sender is confidential. It is intended solely for use by the recipient and others authorized to receive it. If you are not the recipient, you are hereby notified that any disclosure, copying, distribution or taking action in relation of the contents of this information is strictly prohibited and may be unlawful. This email has been scanned for viruses and malware, and may have been automatically archived by Mimecast Ltd, an in IEC Special offer with IEC 62368-1:2023 Academy Masterclass. QUO-004536 Inbox IEC Sales Department Fri, Sep 20, 1:07 PM (21 hours ago) to me Dear Sir, Thank you for your quotation request. Following your registration to the IEC 62368-1:2023 Academy Masterclass, you will find attached our special offer for the purchase of IEC 62368-1:2023 RLV. Quote Nr. QUO-004536 totalling Swiss Francs CHF 578.40. This quote remains valid for three months only, after which it will automatically be deleted. Please note that prices in EUR and USD are given for information purposes only and as per today's exchange rate. You may proceed to the payment online through the following payment link. We remain available shall you have any questions. Best regards, IEC Sales Department T +41 22 919 0211 IEC – International Electrotechnical Commission 3 rue de Varembé, PO Box 131 CH-1211 Geneva 20, Switzerland www.iec.ch Re: Ticket #ZPQDJ: PC format saling magazine Inbox TSHINGOMBEKB TSHITADI Fri, Sep 20, 2:47 PM (20 hours ago) to 6236161+ZPQDJ, me On Mon, 26 Sep 2022, 14:23 , wrote: Your ticket is now solved! PC format saling magazine Tom Mon, 09/26/22 2:23 pm Hi Fiston, Greetings from Magzter! Please share your query in detail so we could assist you better. Thank you. fiston tshingombe Sun, 09/25/22 5:58 pm Message: PC format electronics Re: Magnum enquiry Inbox TSHINGOMBEKB TSHITADI Fri, Sep 20, 2:47 PM (20 hours ago) to Gail, me On Mon, 26 Sep 2022, 08:17 Gail Osborne, wrote: Hi Tshingombe, Thank you for communicating with Magnum Magazine. Please clarify what cost you are looking for so that I can provide you with a quote: 1. A subscription to Magnum Magazine - let me know your street address so I can find out if you can receive hand delivery 2. A back issue of Magnum Magazine - let me know which edition/s you need so I can check on stock 3. A copy of the book "The Lighter Side of Hunting & Shooting" - let me know the name of your nearest Postnet branch 4. A copy of the "Magnum Tactical Guide" - let me know the name of your nearest Postnet branch Thank you. Kind regards, Gail Osborne Senior Sub-Editor Magnum Magazine PO Box 35204, Northway, 4065, KwaZulu-Natal, South Africa Cell 084-432-1306 Fax 086-520-3711 www.manmagnum.com Your opinion matters: Please complete the evaluation for the course: Maximize Profitability and Operations Efficiency 2/3 Inbox noreply-MyLearningLink@learning.se.com Fri, Sep 20, 3:15 PM (19 hours ago) to me NB: If you have already completed the evaluation or rated this course, please disregard this email Dear Tshingombe, Congratulations on completing the training Maximize Profitability and Operations Efficiency 2/3! Continue your development journey by putting into action what you learnt: did you know that you will have forgotten 80% of what you learned if you do not apply it in the following day? • Think about how you can practice what you just learned • Take actions to ensure you succeed: reminders in your calendar, meeting with peers, manager... • Share your learning on Yammer or in the relevant community using #whatdidyoulearntoday Please also tell us what you thought of the training: your opinion matters! • If the Training has an evaluation, click on the below link to complete the survey: • Review the training using the star ratings For any questions about this training, please open a ticket in support@Schneider Keep on being curious and open to new challenges! #LearnEveryDay Thank you! Your Learning Team #whatdidyoulearntoday Any Questions? Visit My LearningLink Help or contact your helpdesk CSRe: TopGear Mag | Subscription Form Inbox TSHINGOMBEKB TSHITADI Fri, Sep 20, 2:47 PM (20 hours ago) to mlungisi, me On Wed, 28 Sep 2022, 12:27 Mlungisi Ngwenya | TopGear South Africa, wrote: Good day Thanks for your interest to subscribe to TopGear Magazine, would you please furnish us with your billing details that we may be able to begin the on-boarding process and send you an invoice. Best regards Mlungisi Ngwenya Re: Sale .buyer trade.. library bibliotech Amazon booking order ticket money market account refund statement conciliation Inbox TSHINGOMBEKB TSHITADI Thu, May 30, 2:26 PM to comments, me, TSHINGOMBEKB, tshingombetshitadi On Fri, 16 Sep 2022, 07:36 TSHINGOMBEKB TSHITADI, wrote: Hello dear saler tax invoice Ce claim..reclaim sta Application.mr tshingombe tshitadi TSHINGOMBEKB TSHITADI Sun, Aug 25, 1:04 PM On Fri, 16 Sep 2022, 07:36 TSHINGOMBEKB TSHITADI, wrote: Hello dear saler tax invoice Ce claim..reclaim staApplication.mr tshingombe ts TSHINGOMBEKB TSHITADI Fri, Sep 20, 2:47 PM (20 hours ago) to comments, me Your Internet Archive item has been reviewed Inbox The Internet Archive Thu, Jun 27, 12:22 PM to me Dear Archive Patron: A review was recently written for your item, https://archive.org/details/2-ltter-tshingombe-self-asseme-incident-logged-on-2024 at the Internet Archive. We thought you might appreciate knowing this and might want to read it by clicking on the link above. -The Internet Archive team. metropolis@abacusemedia.com Sun, Sep 25, 2022, 5:01 PM to me Welcome to Motor Trader Magazine Thank you for registering your details with Motor Trader magazine. You can also choose from: Daily Newsletter Jobs Newsletter You can change the emails you wish to receive anytime by clicking here I hope that Motor Trader Magazine will keep you informed and entertained and that you will take advantage of the free email services on offer. OD SYSTEM ID: 517377239 On Sun, 23 Oct 2022, 11:45 TSHINGOMBEKB TSHITADI, wrote: Money market extra savings Inbox TSHINGOMBEKB TSHITADI Mon, Oct 17, 8:23 PM (6 days ago) to help Hello claim extra savings money. 9710085084520751 Amount deposited money for gift receipt cash back magazine resend comments checkers MMA Support via freshdesk.com Tue, Oct 18, 11:15 AM (5 days ago) to me Hi TSHINGOMBEKB TSHITADI, Please note the amount showing on your slip is to show how much you have saved on goods. This amount cannot be used to buy anything. It is just to show that you have been saving on your groceries. Best, Thelma , TSHINGOMBEKB TSHITADI wrote: Disclaimer: https://www.shopriteholdings.co.za/email-disclaimer.html 1331500:961486 TSHINGOMBEKB TSHITADI Tue, Oct 18, 1:25 PM (5 days ago) Thank you for the clarification. TSHINGOMBEKB TSHITADI Tue, Oct 18, 1:33 PM (5 days ago) to MMA I m asking if can have letter of statement for that account number card confirm saling for that saving account to confirm that balance the saling that grocery or it will be give tendered statement cashback for saling or pay back returned savings account for the accounts . MMA Support via freshdesk.com Tue, Oct 18, 1:54 PM (5 days ago) to me Hi TSHINGOMBEKB TSHITADI, We cannot provide a statement for Xtra Savings card on our end. Please contact Xtra Sabvings Support on the below number. • Xtra Savings Support: 0800 33 33 85 Best, Thelma 1331500:961486 TSHINGOMBEKB TSHITADI Tue, Oct 18, 5:20 PM (5 days ago) to MMA Yes, I confirm. On Tue, 18 Oct at 1:34 PM , TSHINGOMBEKB TSHITADI wrote: I m asking if can have letter of statement for that account number card confirm saling for that saving account to confirm that balance the saling that grocery or it will be give tendered statement cashback for saling or pay back returned savings account for the accounts . On Tue, 18 Oct 2022, 13:25 TSHINGOMBEKB TSHITADI, wrote: Thank you for the clarification. On Tue, 18 Oct 2022, 11:15 MMA Support, wrote: Hi TSHINGOMBEKB TSHITADI, Please note the amount showing on your slip is to show how much you have saved on goods. This amount cannot be used to buy anything. It is just to show that you have been saving on your groceries. Best, Thelma On Mon, 17 Oct at 8:24 PM , TSHINGOMBEKB TSHITADI wrote: Hello claim extra savings money. 9710085084520751 Amount deposited money for gift receipt cash back magazine resend comments checkers Disclaimer: https://www.shopriteholdings.co.za/email-disclaimer.html Disclaimer: https://www.shopriteholdings.co.za/email-disclaimer.html Corporate Gift Cards | Website Enquiry Inbox TSHINGOMBEKB TSHITADI Oct 18, 2022, 1:58 PM (5 days ago) to giftcards Hi there, I’d like to enquire about your corporate gift cards. Below is my personal information: Name and surname: tshingombe Tshitadi Contact number:0725298946# Email address Amount of gift cards required: @100000rand to 1000rand Mart Marie Van Antwerpen Oct 18, 2022, 2:52 PM (5 days ago) to me Good day I hope you are doing well Please find attached the policies and procedures which should explain the bulk gift card process. This document also indicates the discount rates. If you are
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
12 of 18

interested in placing an order, please fill in your details below so we can create your profile for an accurate invoice: Name and surname of delivery contact :tshingombe Email address of delivery contact :tshingombekb@gmail.vom Telephone number of delivery contact :072529846 Cell number of delivery contact :0725298946 Company Name :tshingombe trade Delivery address (please include postal code) :103 Company address :rockview yeohvill jhb Postal Code : Company VAT number : Not Compulsory/ Denomination Quantity Type Total R x1200 X4 Gift Cards R x12000 12000 0 5 Gift Cards 12000 TOTAL 120000 Please ensure that the delivery contact is available to answer their phone and receive the gift cards from the couriers. Please note that we cannot take any responsibility for a delay in delivery when the delivery address or delivery contact details are incorrect. Please do not hesitate to contact me if you have any questions. Thank you Kind regards, Mart-Marié van Antwerpen Money Market Gift Cards 021 980 4727 / 021 980 4665 Request #87322: How would you rate the support you received? Inbox Support Unsubscribe Tue, Sep 17, 9:01 AM (4 days ago) to me Hello tshingombe fiston, We'd love to hear what you think of our customer service. Please take a moment to answer one simple question by clicking either link below: How would you rate the support you received? Good, I'm satisfied Bad, I'm unsatisfied Here's a reminder of what this request was about: Elektor Support Team (Elektor) 16 Sept 2024, 08:44 CEST EN0202272ID Dear Sir, Thank you for your e-mail. What's your question about the newsletter please? Hopefully we have informed you sufficiently, but if you need anything else, please do not hesitate to contact us again. Our customer service team would be glad to assist you. Kind regards, Marleen Brouwer Customer Support Elektor International Media www.elektor.com www.elektor.nl www.elektor.de www.elektor.fr Elektor is the media brand of EIM | learn, design & share electronics tshingombe fiston 14 Sept 2024, 16:47 CEST Become a Member My • • Topics • Magazine • Articles • News • Video • Projects • Newsletter • Submit • Store MyLAB EN0202272ID No bio • • • • • • • • 0 | Follow user View as visitor: My Groups Coming soon My Stats 0 Published projects Views 0 Followers 0 Star(s) on average 0 Comments 0 Comments My Projects • Letter experimental job experience: theoretical practical by EN0202272ID . requirement: .letter experimental work based log activities theoreti... 0 0 Draft • Education technology engineering electrical and trade by EN0202272ID Trade , pratical and theory ,Technologie technical electrotechnic elec... 0 0 Following Not following any project Subscribe to the e-zine Elektor is a great international source of essential electronic engineering information and innovative solutions for engineers, pro makers, startups, and the companies seeking to engage them. We helped launch the first electronics maker movement in the 1960s. Since then, our global electronics design community has expanded to include hundreds of thousands of active members and more than 1,000 contributing experts. We are proud to be growing every day as we inspire new members to design, share, and earn. Become a member • CUSTOMER SERVICE • Privacy Policy • Terms of business • Copyright • Contact us • Advertising info • ELEKTOR WORLD • Elektor MAGAZINE • Elektor LABS • Elektor STORE • Submit Your Content • Social Media • • Safe Payments • • BECOME FREE MEMBER AND RECEIVE OUR EZINE • THE ELEKTOR UNIVERSE ________________________________________ tshingombe fiston 14 Sept 2024, 16:36 CEST engineering hello my question about published Hi there, a warm welcome from our Elektor community! For your records, below is a copy of the information you submitted to us. • Email: tshingombefiston@gmail.com • First Name: fiston • Last Name: tshingombe • Birthday: • Country: South Africa • Phone: • Address: Johannesburg, South Africa • Gender: • Company: Engineering tshingombe • Elektor Store: • Elektor Editorial Newsletter: • Elektor Industry Updates: • Vertical: • Education: • Field of Studies: • Field of industry: • Elektor Editorial Newsletter: Subscribe • Elektor Store: Subscribe • Elektor Industry Updates: Subscribe • Newsletter Subscriptions: Elektor Editorial Newsletter, Elektor Store, Elektor Industry Updates If at any time you wish to stop receiving our emails, you can: unsubscribe here You have questions? Contact us at: service@elektor.com T tshingombe fiston Member since 9/17/2024 ________________________________________ Achievements To start earning badges, sign up to be a Product Expert in our Product Expert Program open_in_new . Activity Oct NovDecJanFebMarAprMayJunJulAugSep21 Community guides Community videos Questions Total replies Recommended User activity chart Post history Reply to Engineering electrical database Google Account•9/17/2024 Education technology engineering electrical and computer science data word excell windows school year vertical rising ground floor current location Engineering electrical database Google Account•9/17/2024 Engineering electrical database management system information, 1 reply Application Update Inbox Met Recruitment Team 9:35 AM (1 hour ago) to me Vacancy: 17878 - Specialist Operations Recovery Driver - Perivale Car Pound Dear tshingombe, Thank you for your application for a new position within the Met. To be eligible to apply for this new position, we have a set of criteria that applicants need to meet. Based on the information you have shared so far; we regret to inform you that you are not eligible to progress with your application. Your individual answers suggest that you do not meet the application criteria. You can read more about our eligibility criteria on our Careers Website or by reviewing information available on MyHR. We understand that this will be disappointing news for you but would like to thank you for your interest in this position and wish you all the best for the future. Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com Met Recruitment Team 9:40 AM (1 hour ago) Vacancy: 17952 - Student Placement - Portfolio Office Assistant - Change -2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 9:45 AM (1 hour ago) Vacancy: 17902 - LMS Administrator Met Recruitment Team 9:50 AM (1 hour ago) Vacancy: 17924 - HR Performance and Reporting Lead Met Recruitment Team 9:55 AM (1 hour ago) Vacancy: 17939 - Student Placement - Analysis & Research Assistant - Data & Analysis - 2025/2026- Counter Terrorism Policing HQ Met Recruitment Team 9:55 AM (1 hour ago) Vacancy: 17957 - Student Placement - Project Support Assistant - Change - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:00 AM (1 hour ago) Vacancy: 17951 - Student Placement - Junior DevOps Engineer - Technology - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:00 AM (1 hour ago) Vacancy: 17956 - Student Placement - Junior Service Designer - Technology - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:10 AM (1 hour ago) Vacancy: 17942- Student Placement - Borders Assistant - Borders Operations Centre - 2025/2026 Counter Terrorism Policing HQ Met Recruitment Team 10:10 AM (1 hour ago) Vacancy: 17955 - Student Placement- Junior Project Manager - Technology - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:10 AM (1 hour ago) Vacancy: 17941 - Student Placement - Project Support Assistant -Strategy, Performance, and Planning - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:15 AM (1 hour ago) Vacancy: 17908 - Business and Policy Support Officer - Data & Analysis - Counter Terrorism Policing HQ Met Recruitment Team 10:15 AM (1 hour ago) Vacancy: 17947 - Student Placement - Assurance and Standards Team Assistant - Change - 2025/2026 -Counter Terrorism Policing HQ Met Recruitment Team 10:20 AM (1 hour ago) Vacancy: 17948 - Student Placement - Associate End User Computing Engineer - Technology - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:20 AM (1 hour ago) Vacancy: 17823 - SQL Server Database Administrator - Counter Terrorism Policing HQ Met Recruitment Team 10:25 AM (1 hour ago) Vacancy: 17937 - Student Placement - Project / Research Assistant - Data & Analysis - 2025/2026 -Counter Terrorism Policing HQ Met Recruitment Team 10:25 AM (1 hour ago) Vacancy: 18030- Senior MetLaw Officer Met Recruitment Team 10:35 AM (50 minutes ago) Vacancy: 17980 - Police prosecutor Met Recruitment Team 10:35 AM (50 minutes ago) Vacancy: 17752 - Student Placement - Media and Communication Administrator 2025/2026 Met Recruitment Team 10:35 AM (50 minutes ago) Vacancy: 16279 - Experienced Intelligence Analyst Met Recruitment Team 10:40 AM (45 minutes ago) Vacancy: 17949 - Student Placement - Business Change Assistant - Change - 2025/2026 - Counter Terrorism Policing HQ Met Recruitment Team 10:40 AM (45 minutes ago) Vacancy: 17680 - Student Placement - Forensic Business Assistant 2025/2026 Met Recruitment Team 10:45 AM (40 minutes ago) to me Vacancy: 17959 - Student Placement - Communications Assistant - 2025/2026 - Communications - Counter Terrorism Policing HQ Met Recruitment Team 10:55 AM (30 minutes ago) Vacancy: 17853 - Enquiry Officer Met Recruitment Team 10:55 AM (31 minutes ago) to me Vacancy: 17830 - Programme Management Office Administrator Met Recruitment Team 10:55 AM (30 minutes ago) to me Vacancy: 16747 - 202402 - MPS Return Scheme Retired Officers Candidate added to Talent Bank Inbox Met Recruitment Team 9:35 AM (1 hour ago) to me Dear tshingombe, Thank you for registering to speak with the Outreach team. A member of the team will contact you shortly by your preferred method. If you no longer wish to speak to a member of the team, please click here to withdraw from our contact list. Many thanks, The Outreach Team Phone: 01633 632500 Email: TalkToUs@met.police.uk Outreach Live chat link: https://uk.meetandengage.com/al2rpqdab Your recent submission Inbox no-reply@service.police.uk 9:15 AM (2 hours ago) to me Thank you for completing the form, your reference is: MIP-482-24-0100-000. --- We understand how distressing being affected by crime or anti-social behaviour can be and we are committed to bringing offenders to justice and ensuring that victims of crime receive the support they need from us and from others. We have lots of crime prevention advice which you may also find useful. Consider our environment - please do not print this email unless absolutely necessary. NOTICE - This email and any attachments may be confidential, subject to copyright and/or legal privilege and are intended solely for the use of the intended recipient. If you have received this email in error, please notify the sender and delete it from your system. To avoid incurring legal liabilities, you must not distribute or copy the information in this email without the permission of the sender. MPS communication systems are monitored to the extent permitted by law. Consequently, any email and/or attachments may be read by monitoring staff. Only specified personnel are authorised to conclude any binding agreement on behalf of the MPS by email. The MPS accepts no responsibility for unauthorised agreements reached with other employees or agents. The security of this email and any attachments cannot be guaranteed. Email messages are routinely scanned but malicious software infection and corruption of content can still occur during transmission over the Internet. Any views or opinions expressed in this communication are solely those of the author and do not necessarily represent those of the Metropolitan Police Service (MPS). Find us at: Facebook: Facebook.com/metpoliceuk Twitter: @metpoliceuk no-reply@service.police.uk 9:22 AM (2 hours ago) to me Thank you for completing the form, your reference is: CNP-53345-24-0100-000. Tell us what you think of our online service Feedback on your experience of using our online services genuinely helps us to make sure they work as well as possible. If you have a couple of minutes, please complete a quick feedback survey. no-reply@service.police.uk 9:28 AM (1 hour ago) to me Thank you for completing the form, your reference is: FOI-22728-24-0100-000. This email confirms we've got your request. We'll reply within 20 working days if we can. If that's not possible we'll let you know. If you've told us we can respond by email then we'll do that unless the type of information you've asked for means we need to give it to you in a different way. If you've told us you'd prefer us to respond in a different way then we'll do our best, but if it isn't possible we'll contact you by email to explain. Application Update Inbox Met Recruitment Team Sat, Sep 21, 5:40 PM (17 hours ago) to me Vacancy: 17879 - Electronics Development Engineer Dear tshingombe, Thank you for your application for a new position within the Met. To be eligible to apply for this new position, we have a set of criteria that applicants need to meet. Based on the information you have shared so far; we regret to inform you that you are not eligible to progress with your application. Your individual answers suggest that you do not meet the application criteria. You can read more about our eligibility criteria on our Careers Website or by reviewing information available on MyHR. We understand that this will be disappointing news for you but would like to thank you for your interest in this position and wish you all the best for the future. Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com Met Recruitment Team Sat, Sep 21, 5:45 PM (17 hours ago) to me Vacancy: 17895 - Head of Visits and Events Met Recruitment Team Sat, Sep 21, 5:50 PM (17 hours ago) Vacancy: 17896 - Senior Media Officer Met Recruitment Team Sat, Sep 21, 5:55 PM (17 hours ago) Vacancy: 17897 - Media Officer Met Recruitment Team Sat, Sep 21, 6:00 PM (17 hours ago) Vacancy: 17912 - Communication Planning Manager Met Recruitment Team Sat, Sep 21, 6:05 PM (17 hours ago) Vacancy: 17918 - Senior Content, Channels and Engagement Officer Met Recruitment Team Sat, Sep 21, 6:05 PM (17 hours ago) Vacancy: 17927 - Head of Data Literacy and Culture Met Recruitment Team Sat, Sep 21, 6:05 PM (17 hours ago) Vacancy: 17874 - Quality Assurance Lead Met Recruitment Team Sat, Sep 21, 6:15 PM (17 hours ago) Vacancy: 17686 - Service Design and Transition Manager - Band C - Technology - Counter Terrorism Policing HQ Met Recruitment Team Sat, Sep 21, 6:15 PM (17 hours ago) Vacancy: 17844 - Senior Project Manager - Change - Counter Terrorism Policing HQ Met Recruitment Team Sat, Sep 21, 6:15 PM (17 hours ago) Vacancy: 16896 - Lead Data Analyst in the Strategic Insight Unit Met Recruitment Team Sat, Sep 21, 6:15 PM (17 hours ago) Vacancy: 17866 - Business Change Manager - Change - Counter Terrorism Policing HQ Met Recruitment Team Sat, Sep 21, 6:20 PM (17 hours ago) Vacancy: 18011 - HOLMES Typist Met Recruitment Team Sat, Sep 21, 6:30 PM (16 hours ago) Vacancy: 17862 - Junior Data Engineer Met Recruitment Team Sat, Sep 21, 6:30 PM (16 hours ago) Vacancy: 17969 - Business Assurance Junior Manager Met Recruitment Team Sat, Sep 21, 6:30 PM (16 hours ago) Vacancy: 17875 - CTSFO Tactical Advisor Met Recruitment Team Sat, Sep 21, 6:30 PM (16 hours ago) Vacancy: 17834 - Operations Manager Met Recruitment Team Sat, Sep 21, 6:35 PM (16 hours ago) Vacancy: 17877 - Infrastructure Engineer Met Recruitment Team Sat, Sep 21, 6:40 PM (16 hours ago) to me Vacancy: 18001 - Lead Dev Ops Engineer (Cloud Platform) - Technology CSC - Police Staff - Counter Terrorism Policing HQ Thank you for your Application! Inbox Microsoft Recruiting 6:44 AM (4 hours ago) to me Hi, Fiston Tshingombe teodor, Thank you for applying to the Software Engineer II (Job number:1755381) position at Microsoft! We're glad you're interested in a career at Microsoft and we're here to help you find a perfect fit. You may not receive feedback from us on your application directly, but please know that it’s being evaluated, and you’ll hear from us as soon as the review process is complete. If you’re selected for an interview, you’ll be notified by someone on the recruiting team. You can view your application status updates through your Action Center. If you see the job moved to an Archived state, that means the position is either no longer open, you withdrew from consideration, or you were not selected for the role. You may notice that we move your application from one role to another. This may happen a few times and is a normal part of our recruiting process. So, if you see the job you applied to in an Archived state, and a new job listed as Active, please know that this is normal and does not negatively impact your candidacy in any way. How’s your profile? A key part of the review process is evaluating your profile in relation to the job requirements, so please make sure your profile is accurate and extensive – it’s our first step in getting to know you! You can build your profile anyway you’d like – you can import it from LinkedIn, manually update it, or import/attach a resume. The most important thing is that your profile tells your story! We encourage you to check back frequently and continue to look for opportunities that match your interests, as new jobs are being posted regularly. Thank you, Microsoft Recruiting This mail is sent from an unmonitored mailbox. Please do not reply. Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. ________________________________________ This message was sent to tshingombefiston@gmail.com. If you don't want to receive
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
13 of 18

these emails from this company in the future, please go to: https://ms.icims.com/icims2/?r=11B617365170&contactId=116124102 © Microsoft Corporation; One Microsoft Way; Redmond, WA 98052; USA Microsoft Recruiting 6:57 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Technology Specialist - Modern Work (Job number:1771873) position at Microsoft! We're glad you're in Microsoft Recruiting 7:02 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Principal Software Engineering Manager (Job number:1766765) position at Microsoft! We're glad you're Microsoft Recruiting 7:06 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Applied Scientist (Job number:1762056) position at Microsoft! We're glad you're interested in Microsoft Recruiting 7:13 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Software Development Engineer (Platform Firmware & Drivers) (Job number:1738100) position at Microsoft Recruiting 7:16 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Director of Network Supply Chain (Job number:1771684) position at Microsoft! We're glad you're inter Microsoft Recruiting 7:18 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Director, Cybersecurity Business Strategy Lead (Job number:1770318) position at Microsoft! We Microsoft Recruiting 7:21 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Principal Product Manager (Job number:1736502) position at Microsoft! We're glad you're interested i Microsoft Recruiting 7:26 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Data Center Technician (Job number:1769625) position at Microsoft! We're glad you're interested in a Microsoft Recruiting 7:28 AM (4 hours ago) Hi, Fiston Tshingombe teodor, Thank you for applying to the Software Engineer-Full Stack- Xbox (Job number:1771329) position at Microsoft! We're glad you're int Microsoft Recruiting 7:30 AM (3 hours ago) to me Hi, Fiston Tshingombe teodor, Thank you for applying to the Software Engineer II (Job number:1770175) position at Microsoft! We're glad you're interested in a career at Microsoft and we're here to help you find a perfect fit. You may not receive feedback from us on your application directly, but please know that it’s being evaluated, and you’ll hear from us as soon as the review process is complete. If you’re selected for an interview, you’ll be notified by someone on the recruiting team. You can view your application status updates through your Action Center. If you see the job moved to an Archived state, that means the position is either no longer open, you withdrew from consideration, or you were not selected for the role. You may notice that we move your application from one role to another. This may happen a few times and is a normal part of our recruiting process. So, if you see the job you applied to in an Archived state, and a new job listed as Active, please know that this is normal and does not negatively impact your candidacy in any way. How’s your profile? A key part of the review process is evaluating your profile in relation to the job requirements, so please make sure your profile is accurate and extensive – it’s our first step in getting to know you! You can build your profile anyway you’d like – you can import it from LinkedIn, manually update it, or import/attach a resume. The most important thing is that your profile tells your story! We encourage you to check back frequently and continue to look for opportunities that match your interests, as new jobs are being posted regularly. Thank you, Microsoft Recruiting This mail is sent from an unmonitored mailbox. Please do not reply. Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. Your recent job application for (631) Business Analysis Competency Centre Lead - BSTD - 631 Inbox SARB Talent Acquisition Sat, Sep 21, 7:51 AM (1 day ago) to me Hello, tshitadi, We received your job application for (631) Business Analysis Competency Centre Lead - BSTD - 631. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (642) SHEQ Analyst-RMCD - 642 Inbox SARB Talent Acquisition Sat, Sep 21, 7:48 AM (1 day ago) to me Hello, tshitadi, We received your job application for (642) SHEQ Analyst-RMCD - 642. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Recruiting Team Your recent job application for (649) Cloud Engineer - BSTD - 649 Inbox SARB Talent Acquisition Sat, Sep 21, 7:45 AM (1 day ago) to me Hello, tshitadi, We received your job application for (649) Cloud Engineer - BSTD - 649. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Your recent job application for (557) End-User Computing Architect - BSTD - 557 Inbox SARB Talent Acquisition Sat, Sep 21, 7:42 AM (1 day ago) to me Hello, tshitadi, We received your job application for (557) End-User Computing Architect - BSTD - 557. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (630) Data Collection Administrator - 630 Inbox SARB Talent Acquisition Thu, Sep 19, 7:08 AM (3 days ago) to me Hello, tshitadi, We received your job application for (630) Data Collection Administrator - 630. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, Your recent job application for (640) Information Governance Specialist - BSTD - 640 Inbox SARB Talent Acquisition Thu, Sep 19, 7:13 AM (3 days ago) to me Hello, tshitadi, We received your job application for (640) Information Governance Specialist - BSTD - 640. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (635) Reporting Systems Inspector -FinSurv - 635 Inbox SARB Talent Acquisition Thu, Sep 19, 7:06 AM (3 days ago) to me Hello, tshitadi, We received your job application for (635) Reporting Systems Inspector -FinSurv - 635. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (639) Senior Economic Policy Analyst-IERP - 639 Inbox SARB Talent Acquisition Thu, Sep 19, 6:52 AM (3 days ago) to me Hello, tshitadi, We received your job application for (639) Senior Economic Policy Analyst-IERP - 639. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (644) Team Leader - Food and Beverages - CSD - 644 Inbox SARB Talent Acquisition Thu, Sep 19, 6:49 AM (3 days ago) to me Hello, tshitadi, We received your job application for (644) Team Leader - Food and Beverages - CSD- 644. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (643) Associate Trade Settlement Officer – Foreign Markets - FMD -643 Inbox SARB Talent Acquisition Thu, Sep 19, 6:11 AM (3 days ago) to me Hello, tshitadi, We received your job application for (643) Associate Trade Settlement Officer – Foreign Markets - FMD -643. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Recruiting Team Your recent job application for (646) Divisional Head: Security Operations -GSMD - 646 Inbox SARB Talent Acquisition Thu, Sep 19, 6:08 AM (3 days ago) to me Hello, tshitadi, We received your job application for (646) Divisional Head: Security Operations - GSMD - 646. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Update on your Job application with SARB Inbox SARB Talent Acquisition Mon, Sep 16, 11:05 AM (6 days ago) to me Dear tshitadi tshingombe, Thank you for your interest in the (616) Contractor-Building Engineer -CTC at the SARB, we regret to inform you that your application was unsuccessful. Regards Thank you for your interest in Microsoft! Inbox Microsoft Recruiting Unsubscribe Thu, Sep 12, 9:26 PM (10 days ago) to me Hi Fiston Tshingombe teodor, Thank you for your interest in a career at Microsoft. Unfortunately, we will not be moving forward with your candidacy for the position of Software Engineer II (Full stack), 1749784 at this time. However, we’d like to encourage you to continue to explore other career opportunities on Microsoft Careers as we continually update openings on a daily basis. We look forward to considering you for other positions at Microsoft! Thank you, Microsoft Recruiting Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. This mail is sent from an unmonitored mailbox. Please do not reply. Eskom Careers: Confirmation of Application Inbox sharepoint@eskom.co.za Sun, Sep 1, 1:27 PM to me Dear Tshingombe Tshitadi , Job Reference: EMTOPPMT06 Position: Technical Official PPM Mechanical X2 (Distribution) EAL Midrand Region: South Africa (Gauteng) Industry: Engineering Closing Date: 2024/09/09 Thank you for your interest in a career at Eskom. Your online application was received and will be duly actioned by the Recruitment Practitioner allocated to the position you applied for. Should you not be contacted within 28 days of the closing date of this advertisement, please accept that your application was unsuccessful Please also note that you only have to register and load your Personal History Profile (PHP) once. You may in future apply for vacancies using the PHP provided. Once the PHP has been completed for a particular vacancy, it can be saved and used for future applications. The PHP may be up-dated, when necessary, for future applications Best wishes with your future Kind Regards Recruitment Manager Shared Services (HR) FINANCE DIVISION Disclaimer NB: This Email and its contents are subject to the Eskom Holdings SOC Ltd EMAIL LEGAL NOTICE which can be viewed at https://www.eskom.co.za/about-eskom/email-legal-spam-disclaimer/ sharepoint@eskom.co.za Sun, Sep 1, 1:29 PM Dear Tshingombe Tshitadi , Job Reference: EIT X2/GX PrimaryE/MC Position: 1 Learning-Programme-Engineer-in-Training-x-2,-Generation,-Megawatt-Park Region: South sharepoint@eskom.co.za Sun, Sep 1, 1:30 PM Dear Tshingombe Tshitadi , Job Reference: GXMATL- EIT/2024 Position: Learning Programme Engineer in Trainng x17 GX Matla Power Station Region: South Africa (Mpu sharepoint@eskom.co.za Sun, Sep 1, 1:31 PM Dear Tshingombe Tshitadi , Job Reference: 50515483LM Position: Manager Site Outage Execution, Generation, Tutuka Power Station Closing Date: 2024/09/13 sharepoint@eskom.co.za Sun, Sep 1, 1:31 PM Dear Tshingombe Tshitadi , Job Reference: 50813227NLee01 Position: Re Advert Snr Technologist Electrical Engineering Substation x2 ( National Transmission Compa sharepoint@eskom.co.za Sun, Sep 1, 1:32 PM Dear Tshingombe Tshitadi , Job Reference: 50813227NLee01 Position: Re Advert Snr Technologist Electrical Engineering Substation x2 ( National Transmission Compa sharepoint@eskom.co.za Sun, Sep 1, 1:32 PM Dear Tshingombe Tshitadi , Job Reference: 50861481SN/GX-Koeberg Position: Senior Technician Chemistry x2 (Technical Support and Oils Micro) (Generation) Koeberg sharepoint@eskom.co.za Sun, Sep 1, 1:33 PM Dear Tshingombe Tshitadi , Job Reference: GXMedOMM04 Position: Officer Safety Health Environment X1 Generation Medupi Power Station Region: South Africa (Limpop sharepoint@eskom.co.za Sun, Sep 1, 1:34 PM Dear Tshingombe Tshitadi , Job Reference: Learners OGE Contracts Management Position: Learning Programme Outages x1 - Graduate in Training , Generation, Megawat sharepoint@eskom.co.za Sun, Sep 1, 1:35 PM Position: Learning Programme -Graduate in Training-Quantity Surveyor, Generation, Megawatt Park sharepoint@eskom.co.za Sun, Sep 1, 1:36 PM Dear Tshingombe Tshitadi , Job Reference: Snr Advisor SDL&IPL Position: Senior Advisor Supplier Development, Localisation and Industrialisation x2, Generation, sharepoint@eskom.co.za Sun, Sep 1, 1:37 PM Dear Tshingombe Tshitadi , Job Reference: DurbanvilleFXGIT2025 Position: Graduate-in-Training (Finance) Industry: Other Closing Date: 2024/09/09 sharepoint@eskom.co.za Sun, Sep 1, 1:38 PM Dear Tshingombe Tshitadi , Job Reference: 50828254NLee01 Position: Re Advert Snr Draughtsperson Draughting Electrical Substation Engineering x3 NTCSA MWP Closin sharepoint@eskom.co.za Sun, Sep 1, 1:39 PM Dear Tshingombe Tshitadi , Job Reference: PeakingTITDrakensberg2025 Position: Technician-in-Training x2 (1xC+I and 1+Mech) Region: South Africa (Kwa-Zulu Natal) sharepoint@eskom.co.za Sun, Sep 1, 1:39 PM Dear Tshingombe Tshitadi , Job Reference: GX49002630WK/TUT Position: Snr. Supervisor Tech Instrument x 2 (Generation) Tutuka Power Station Region: South Africa sharepoint@eskom.co.za Sun, Sep 1, 1:40 PM Dear Tshingombe Tshitadi , Job Reference: PeakingLearnersEIT2025 Position: Engineer-in-Training-Control and Instrumentation AND-Auxiliary and Ancillary-(Peaking sharepoint@eskom.co.za Sun, Sep 1, 1:42 PM Dear Tshingombe Tshitadi , Job Reference: GXMedSTR14.1 Position: Re Advert Senior Technician Configuration X1 (Generation) Medupi Power Station Closing Date: 20 sharepoint@eskom.co.za Sun, Sep 1, 1:43 PM Dear Tshingombe Tshitadi , Job Reference: 50817165NQ Position: Engineer Prof Eng Quality of Supply (National Transmission Company South Africa) Newscastle Indus sharepoint@eskom.co.za Sun, Sep 1, 1:45 PM Dear Tshingombe Tshitadi , Position: Learning Programme - Graduate in Training x1, Generation, Megawatt Park Region: South Africa (Gauteng) sharepoint@eskom.co.za Sun, Sep 1, 1:45 PM Dear Tshingombe Tshitadi , Job Reference: Learners OGE Environmental Management Position: Learning-Programme -Graduate-in-Training-x3,-Generation,-1Megawatt-Par sharepoint@eskom.co.za Sun, Sep 1, 1:46 PM Dear Tshingombe Tshitadi , Job Reference: Learners Gx Procurement Position: Learning Programme-Graduate in Training x 3, Generation, Megawatt Park sharepoint@eskom.co.za Sun, Sep 1, 1:47 PM Dear Tshingombe Tshitadi , Job Reference: Learners OGE Legal Position: Learning Programme-Graduate in Training x 2, Generation, Megawatt Park sharepoint@eskom.co.za Sun, Sep 1, 1:49 PM Dear Tshingombe Tshitadi , Job Reference: 50097836FN Position: Senior Supervisor Technical Projects ( National Transmission Company South Africa )Northwest and sharepoint@eskom.co.za Sun, Sep 1, 1:51 PM Dear Tshingombe Tshitadi , Job Reference: 50861459SCM Position: Snr-Advisor-Applications-Support-(Group-IT-DIVISION)-Megawatt-Park Region: South Africa (Gauteng sharepoint@eskom.co.za Sun, Sep 1, 1:51 PM Dear Tshingombe Tshitadi , Job Reference: 001 EIT Position: Learning Programme - Engineer in Training x3 (Generation) Engineering MWP Region: South Africa (Gaut sharepoint@eskom.co.za Sun, Sep 1, 1:53 PM Dear Tshingombe Tshitadi , Job Reference: GXKRL-04 Position: Secretary Secretarial (Gx Kriel Power Station) Region: South Africa (Mpumalanga) sharepoint@eskom.co.za Sun, Sep 1, 1:55 PM Dear Tshingombe Tshitadi , Job Reference: Graduate in Training- Commercial Position: Graduate in Training (Commercial) x1 (Generation) Industry: Human Resources sharepoint@eskom.co.za Sun, Sep 1, 1:58 PM Dear Tshingombe Tshitadi , Job Reference: Graduate in Training- Finance Position: Graduate in Training (Finance) x1 (Generation) sharepoint@eskom.co.za Sun, Sep 1, 1:58 PM Dear Tshingombe Tshitadi , Job Reference: Engineer-in-Training Nuclear Engineering Position: Engineer in Training (Nuclear Engineering) x9-Generation Koeberg NP sharepoint@eskom.co.za Sun, Sep 1, 2:00 PM Dear Tshingombe Tshitadi , Job Reference: Learners Gx OMO/SM Position: Learning Programme - Engineer in Training x2,
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
14 of 18

Generation, Megawatt Park Region: South Afr sharepoint@eskom.co.za Sun, Sep 1, 2:01 PM Dear Tshingombe Tshitadi , Job Reference: 505571133PM/01 Position: Re Advert Senior Engineer Prof Electrical Engineering (Project Integration) NTCSA MWP Region: sharepoint@eskom.co.za Sun, Sep 1, 2:02 PM Dear Tshingombe Tshitadi , Job Reference: 50840435MIR Position: Officer Security (National Transmission Company South Africa) Bellville sharepoint@eskom.co.za Sun, Sep 1, 2:04 PM Dear Tshingombe Tshitadi , Job Reference: Gx Arn NN 23/08/24 Position: Officer catering (Generation) Arnot Power Station x1 Region: South Africa (Mpumalanga) In sharepoint@eskom.co.za Sun, Sep 1, 2:05 PM to me Dear Tshingombe Tshitadi , Job Reference: 50842085LRR Position: Re-Advert: Assistant Officer Security Operations Centre (FINANCE DIVISION) Megawatt Park Region: South Africa (Gauteng) Industry: Other Closing Date: 2024/09/06 Thank you for your Application! Inbox Microsoft Recruiting Sun, Sep 1, 8:55 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Principal Software Engineer – Teams Platform (Job number:1726871) position at Microsoft! We're glad Microsoft Recruiting Sun, Sep 1, 8:58 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Machine Learning Engineer (Job number:1759775) position at Microsoft! We're glad you're inter Microsoft Recruiting Sun, Sep 1, 9:01 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Security Technical Program Manager (Job number:1762424) position at Microsoft! We're glad you Microsoft Recruiting Sun, Sep 1, 9:05 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Data & AI Technical Sales Specialist (Job number:1762311) position at Microsoft! We're glad you're i Microsoft Recruiting Sun, Sep 1, 9:11 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Software Engineer II (Full stack) (Job number:1749784) position at Microsoft! We're glad you're inte Microsoft Recruiting Sun, Sep 1, 9:13 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Customer Success Account Manager (Job number:1762683) position at Microsoft! We're glad you're inter Microsoft Recruiting Sun, Sep 1, 9:16 AM Hi, Fiston Tshingombe teodor, Thank you for applying to the Principal Technical Program Manager (Job number:1736977) position at Microsoft! We're glad you're in Microsoft Recruiting Sun, Sep 1, 9:19 AM to me Hi, Fiston Tshingombe teodor, Thank you for applying to the Senior Applied AI Engineer (Job number:1762298) position at Microsoft! We're glad you're interested in a career at Microsoft and we're here to help you find a perfect fit. You may not receive feedback from us on your application directly, but please know that it’s being evaluated, and you’ll hear from us as soon as the review process is complete. If you’re selected for an interview, you’ll be notified by someone on the recruiting team. You can view your application status updates through your Action Center. If you see the job moved to an Archived state, that means the position is either no longer open, you withdrew from consideration, or you were not selected for the role. You may notice that we move your application from one role to another. This may happen a few times and is a normal part of our recruiting process. So, if you see the job you applied to in an Archived state, and a new job listed as Active, please know that this is normal and does not negatively impact your candidacy in any way. How’s your profile? A key part of the review process is evaluating your profile in relation to the job requirements, so please make sure your profile is accurate and extensive – it’s our first step in getting to know you! You can build your profile anyway you’d like – you can import it from LinkedIn, manually update it, or import/attach a resume. The most important thing is that your profile tells your story! We encourage you to check back frequently and continue to look for opportunities that match your interests, as new jobs are being posted regularly. Thank you, Microsoft Recruiting This mail is sent from an unmonitored mailbox. Please do not reply. Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. ________________________________________ This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to: https://ms.icims.com/icims2/?r=11B617365170&contactId=113826735 Your recent job application for Software Engineer FMCD - 34622 Inbox Ford Careers Sun, Sep 1, 8:45 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Software Engineer FMCD -34622 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Cyber Security ISP and Data Analyst - 34582 Inbox Ford Careers Sun, Sep 1, 8:40 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Cyber Security ISP and Data Analyst -34582 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Backend Engineer - 34857 Inbox Ford Careers Sun, Sep 1, 8:37 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Backend Engineer - 34857 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Thermal Systems Integration Engineer, HVAC - 34848 Inbox Ford Careers Sun, Sep 1, 8:35 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Thermal Systems Integration Engineer, HVAC - 34848 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for STA Site Engineer - 34645 Inbox Ford Careers Sun, Sep 1, 8:30 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the STA Site Engineer - 34645 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Propulsion Systems Design Release Engineer - 34464 Inbox Ford Careers Sun, Sep 1, 8:28 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Propulsion Systems Design Release Engineer - 34464 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for HV Battery Build & Test Engineer (Thermal Runaway) - 31563 Inbox Ford Careers Sun, Sep 1, 8:25 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the HV Battery Build & Test Engineer (Thermal Runaway) - 31563 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Systems Engineering - 32712 Inbox Ford Careers Sun, Sep 1, 8:23 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Systems Engineering - 32712 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team Your recent job application for Systems Integration, Electrical Architecture - 32709 Inbox Ford Careers Sun, Sep 1, 8:21 AM to me Hello fiston, Thank you for your interest in joining the Ford Motor Company team. You've taken the first steps by completing your application and sharing your qualifications for the Systems Integration, Electrical Architecture - 32709 position. We will contact you if we think you're a good fit for that position. In the meantime, keep checking www.careers.ford.com for additional opportunities – we'd love to help you find your dream job. Sincerely, The Ford Talent Acquisition Team our recent job application for (602) Bank Analyst-FCSD - 602 Inbox SARB Talent Acquisition Sat, Aug 31, 2:01 PM to me Hello, tshitadi, We received your job application for (602) Bank Analyst-FCSD - 602. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Your recent job application for (608) Lead Policy Analyst - 608 Inbox SARB Talent Acquisition Sat, Aug 31, 1:57 PM to me Hello, tshitadi, We received your job application for (608) Lead Policy Analyst -608. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Recruiting Team Application acknowledgement Inbox SARS Human Capital and Development Sat, Aug 31, 8:43 AM to me Dear Tshingombe Tshitadi , Job Application: Business Area Lead: Civil Case Select Strategy Reference code: 9833 Receipt of your application for the advertised post is hereby acknowledged. It may take some time to process your application. Regards, SARS Talent Acquisition Team 31 August 2024 SARS Human Capital and Development Sat, Aug 31, 8:45 AM to me Dear Tshingombe Tshitadi , Job Application: Ops Manager: Facilities Management Reference code: 9832 SARS Human Capital and Development Sat, Aug 31, 8:46 AM to me Dear Tshingombe Tshitadi , Job Application: Specialist Developer: Information Technology (Adabas) Reference code: 9799 SARS Human Capital and Development Sat, Aug 31, 8:47 AM to me Dear Tshingombe Tshitadi , Job Application: Specialist: Systems Engineer (Mainframe) Reference code: 9804 SARS Human Capital and Development Sat, Aug 31, 8:48 AM to me Dear Tshingombe Tshitadi , Job Application: Senior Specialist: Database Administration (Adabas) Reference code: 9796 SARS Human Capital and Development Sat, Aug 31, 8:49 AM to me Dear Tshingombe Tshitadi , Job Application: Junior Specialist: Asset Management (Software) Reference code: 9791 Update Regarding Your Application Inbox Eaton TalentHub Fri, Aug 30, 3:47 PM to me Hi Fiston, Thank you for applying for the position of Senior Field Service Representative – 31188. We appreciate you considering a career at Eaton. After careful review, we have decided to move forward with other candidates who more closely match the current needs for this team and position. We know that messages like this are disappointing, but we really hope you continue to pursue other opportunities at Eaton. Be sure to check out Eaton.com/careers, where you can find all our open jobs and set up a job alert. Thank you for your interest in Eaton and wish you all the best! Eaton Talent Acquisition Team Your recent job application for (605) Financial Stability Department - Finstab - 605 Inbox SARB Talent Acquisition Sat, Aug 31, 1:45 PM to me Hello, tshitadi, We received your job application for (605) Financial Stability Department - Finstab - 605. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Recruiting Team Your recent job application for (606) Associate Macroprudential Specialist - Finstab - 606 Inbox SARB Talent Acquisition Sat, Aug 31, 1:49 PM to me Hello, tshitadi, We received your job application for (606) Associate Macroprudential Specialist -Finstab - 606. If your profile corresponds to our requirements, a member of our Recruiting team will contact you. If you were requested to provide additional info about your job application, or if you want to manage your profile, go to your candidate self service page. Sincerely, South African Reserve Bank Recruiting Team Application Unsuccessful Inbox SARS Human Capital and Development Wed, Aug 28, 2:00 PM to me Dear Tshingombe Tshitadi , Thank you for applying for Specialist: Case Selection (Transfer Pricing). After careful consideration we regret to inform you that your application was not successful. We wish you everything of the best in your future applications. Yours Sincerely, SARS Talent Acquisition Team • About Us • Our Network • Skills for Work and Life • Knowledge Resources TVET Forum - Connect With a Global TVET Community TVET Forum SDG and TVET Virtual Conferences About the TVET Forum Terms of Use Help & FAQ Manage Your Account Unsubscribe Contact TVET Forum User profile tshitadi fiston Member since 2023-10-14 5 Postings UNEVOC Centre #3043 h Contact: tshingombefiston@gmail.com User Messages: 2024-09-23 Re: Models of Institutional Effectiveness in VET () 2024-09-23 engineering qualification framework implentation tvet college , rdc and rsa record system engineering n studie () 2024-09-23 engineering qualification framework implentation tvet college , rdc and rsa record system engineering n studie () 2024-09-23 experimental workbase tvet and institut back log dhet ucpd record st peace college and sita and examination irregularity implentation () 2024-09-23 experimental career tvet college institu assessment police guidence back log sita and irregularity level 4,5,3,6 ucpd engineering studie diploma certificate () RE: CMS 221043 YS Online form submission: CNP-53345-24-0100-000 Inbox TPMailbox-CMSCCC@met.pnn.police.uk Mon, Sep 23, 12:23 PM (21 hours ago) to me Good Morning, Thank you for your online submission into the Crime Management Services. The crime reference number is showing in the system as not in existence. Are you the victim? What is the nature of the crime? Do you have a named Officer assigned to the Case? Would you like us to place an update onto the system? Kindest regards, Yvonne - Crime Management Services Should you require us in an emergency, please dial 999. If you wish to speak to the operator regarding a non-emergency, please dial 101. ***********PLEASE DO NOT REPLY TO THIS EMAIL. OUR MAILBOX CANNOT RECEIVE EMAILS DIRECTLY FROM MEMBERS OF THE PUBLIC. AS SUCH, SHOULD YOU WISH TO RESPOND TO THIS EMAIL, YOU WILL NEED TO VISIT THE FOLLOWING LINK TO RE-SUBMIT THE REPLY*********** https://www.met.police.uk/contact/af/contact-us/ -----Original Message----- From: no-reply@service.police.uk Sent: 22 September 2024 08:24 To: TP MAILBOX - CMS CCC Subject: CMS 221043 YS Online form submission: CNP-53345-24-0100-000 ************************************************************************************************************************ OFFICIAL - SENSITIVE ************************************************************************************************************************ ------------------------------------------------------------------------------------------------------------------------STEP 1 ------------------------------------------------------------------------------------------------------------------------ First name: fiston -------------------------------------------------------------------------------- Surname: tshingombe -------------------------------------------------------------------------------- Date of birth: 10/11/1982 -------------------------------------------------------------------------------- Email address: tshingombefiston@gmail.com -------------------------------------------------------------------------------- Telephone number (for international numbers include the country code): +270725298946-------------------------------------------------------------------------------- Postcode: Percy street 1039, Hendrik Potgieter St Johannesburg 1030 --------------------------------------------------------------------------------Origin: Form -------------------------------------------------------------------------------- Crime reference number: eg 1234567/17 or 01/00000/24: 2345654/24-------------------------------------------------------------------------------- When did the incident happen?: 02/09/2022 -------------------------------------------------------------------------------- What is your involvement in this
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
15 of 18

case?: High court London transaction victim Edith ,Mrs basem attorney chamber affidavit Portofolio evidence low , complain incidence accident transaction money for claim bank work UK from Canada transaction made in RSA , union waster..Asia bank -------------------------------------------------------------------------------- Please provide us with your update: 10/09/2024 NOTICE - This email and any attachments are solely for the intended recipient and may be confidential. If you have received this email in error, please notify the sender and delete it from your system. Do not use, copy or disclose the information contained in this email or in any attachment without the permission of the sender. Metropolitan Police Service (MPS) communication systems are monitored to the extent permitted by law and any email and/or attachments may be read by monitoring staff. Only specified personnel are authorised to conclude binding agreements on behalf of the MPS by email and no responsibility is accepted for unauthorised agreements reached with other personnel. While reasonable precautions have been taken to ensure no viruses are present in this email, its security and that of any attachments cannot be guaranteed. Application Update Inbox TalkToUs@met.police.com.uk via tal.net Mon, Sep 23, 4:15 PM (18 hours ago) to me Dear tshingombe Good Afternoon Thank you for getting in touch with the Metropolitan Police regarding career opportunities. We apologise if there has been a delay in responding to you but this is likely to be because of the large amount of interest that the campaign has generated. If you have seen it “change needs you !” We are here to help you with any enquiries or questions that you have about the job or your application form in the hope that you will complete and submit an application but please do let us know if you are no longer interested. In order to make a start of understanding how we can help you we have a few questions that we would appreciate you answering in reply to this email and if replying on another device the email address to use is TalkToUs@met.police.uk. Are you still interested in a career in the Met? What role are you interested in? What is your highest level of academic achievement? Are you currently working towards a qualification? Do you have a GCSE or equivalent in English? Have you attended or are you interested in attending an Insight Event? Is there anything that we can help with to encourage your application? Look forward to hearing from you soon Kind Regards Met Police Candidate Engagement Team. Automated Response Inbox TalkToUs@met.police.uk Mon, Sep 23, 4:25 PM (17 hours ago) to me Thank you for getting in touch to find out more about becoming a Met Police Constable. Due to the high volume of queries, we aim to contact you within 5 working days. We will do our best to reach out to you within your ideal time slot, if provided. Kindest regards, Talk to Us Team NOTICE - This email and any attachments are solely for the intended recipient and may be confidential. If you have received this email in error, please notify the sender and delete it from your system. Do not use, copy or disclose the information contained in this email or in any attachment without the permission of the sender. Metropolitan Police Service (MPS) communication systems are monitored to the extent permitted by law and any email and/or attachments may be read by monitoring staff. Only specified personnel are authorised to conclude binding agreements on behalf of the MPS by email and no responsibility is accepted for unauthorised agreements reached with other personnel. While reasonable precautions have been taken to ensure no viruses are present in this email, its security and that of any attachments cannot be guaranteed. Application Update Inbox Met Recruitment Team 1:05 AM (9 hours ago) to me tshingombe, You’ve started your application form, but haven’t yet finished it. You haven’t got much left to do in this section, and we’d love it if you had five minutes to finish this off. You’ll need to log back into the system to continue – Application Centre to pick up where you left off. You can review your progress using the navigation menu on the left hand side of the application form screen – a tick means you’re done in each section. If you’re stuck and need help, please give us a call – our telephone details are below. Please don’t worry about asking us for assistance, that’s what we’re here for! If you’re having trouble deciding whether you want to continue or not, please do give us a call – we’ll be able to help by talking this through with you. Have a great day! Yours sincerely, Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com Removing Barriers to Officer Accountability Inbox Google Forms 9:49 AM (4 minutes ago) to me Thanks for filling out Removing Barriers to Officer Accountability Here's what was received. Removing Barriers to Officer Accountability Section 1: Attorney Affirmation is MANDATORY if you wish to receive CLE credit. Section 2: Course Evaluation is ENCOURAGED to inform the state of New York on our program. Email * tshingombefiston@gmail.com Section 1: Attorney Affirmation NY CLE Credit for Webinar To obtain New York CLE credit, please complete and sign this form and then submit it to the Policing Project at NYU Law. Your participation must be verified by the provider. Experienced New York attorneys (attorneys who have been admitted to the New York bar for more than two years) may earn CLE credit through nontraditional formats. Newly admitted attorneys (attorneys who have been admitted to the New York Bar for two years or less) should confirm that the format is permissible for the category of credit. New York attorneys should retain a copy of this affirmation. Email * tshingombefiston@gmail.com Format: Webconference Course Code(s) During each session of the conference you will see and/or hear one or more CLE course codes. Please enter the code(s) in the fields below. If you do not enter the correct code(s), you will not be awarded New York CLE credit. If you did not attend the entire conference, you are able to receive partial credit for the individual sessions you attended in their entirety. List all code(s) for September 24, 2024 * 21-CIP-J / FFPSA & Kinship (Part 1),Date & Time Sep 24, 2024 09:00 PM Johannesburg Webinar ID 912 5168 3181,Tue Sep 24, 2024 9pm – 10pm (SAST) Where https://nyu.zoom.us /w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.DQcAAAAVPwYvbRZjNTdyNEx1S1NaQzljV2s3NlU2SEdRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA& uuid=WN_3jfCNZddR7iCjsRfhRXPag Who Gabby Bayness 30x30 Initiative: Advancing Women in Policing Chicago Neighborhood Policing Initiative Legislation Litigation Regulating Use of Technology in Policing ReImagining Public Safety SAJE Policing Assessment Our Mission: We Partner With Communities And Police To Promote Public Safety Through Transparency, Equity, and Democratic Engagement. Our work focuses on front-end, or democratic, accountability—meaning the public has a voice in setting transparent, ethical, and effective policing policies and practices before the police or government act. The goal is to achieve public safety in a manner that is equitable, non-discriminatory, and respectful of public values. Broadly speaking, our work is centered around three focus areas: Front-End Voice in Policing: We believe that in a democratic society, the public must have a voice in how it is policed. Regulation of Policing Technology: We believe that there must be transparency and public debate around the adoption of new policing technologies. Reimagining Public Safety: We believe it is time for a national conversation about what public safety means, and how it is best achieved. Explore our focus areas to learn more about our work.*, Name of CLE Provider: New York University School of Law - Policing Project Please confirm the following statements by checking the boxes and typing your name in the signature field below * ✓ I acknowledge receipt of the course materials for Removing Barriers to Officer Accountability ✓ I certify that I have listened to and/or viewed Removing Barriers to Officers Accountability in its entirety for the sessions for which I've entered codes. Therefore, I request that I be awarded the applicable number of New York CLE credits for this course. Signature * tshingombefiston@gmailcom Date of completion of CLE course (New York attorneys earn CLE credit as of the date they complete a CLE course): * MM 09 / DD 25 / YYYY 2024 Attorney email address to receive CLE certificate (if different from the address above): tshingombekb@gmail.com Section 2: Course Evaluation Course evaluations are optional, but must be offered to all attorneys who participated in today's course. Program Title Thank you for registering for Removing Barriers to Law Enforcement Officer Accountability. You can find information about this webinar below. Removing Barriers to Law Enforcement Officer Accountability Date MM 09 / DD 25 / YYYY 2024 Speaker(s): Removing Barriers to Law Enforcement Officer Accountability Confirmation Inbox Gabby Bayness AttachmentsSep 24, 2024, 8:15 PM (13 hours ago) to me Sep24Tue Removing Barriers to Law Enforcement … View on Google Calendar When Tue Sep 24, 2024 9pm – 10pm (SAST) Where https://nyu.zoom.us /w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.DQcAAAAVPwYvbRZjNTdyNEx1S1NaQzljV2s3NlU2SEdRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA& uuid=WN_3jfCNZddR7iCjsRfhRXPag Who Gabby Bayness* Agenda Tue Sep 24, 2024 No earlier events 9pm Removing Barriers to Law Enforcement … No later events Hi Tshingombe tshitadi, Thank you for registering for Removing Barriers to Law Enforcement Officer Accountability. You can find information about this webinar below. Removing Barriers to Law Enforcement Officer Accountability Date & Time Sep 24, 2024 09:00 PM Johannesburg Webinar ID 912 5168 3181 Add to: Google Calendar Outlook Calendar(.ICS) Yahoo Calendar To edit or cancel your registration details, click here. You can cancel your registration before Sep 24, 2024 09:00 PM. Please submit any questions to: gib7728@nyu.edu Thank you! WAYS TO JOIN THIS WEBINAR Join from PC, Mac, iPad, or Android Join Webinar If the button above does not work, paste this into your browser: https://nyu.zoom.us/w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.D Please take a few moments to evaluate this course: Excellent Good Fair Poor N/A Program Content ✓ Instructor Quality ✓ Written Materials ✓ Facility ✓ Technology ✓ Relevence to my practice: assessment police engineering st peace college policing conduct , Comments: policing conduct investigate analyse design framework regulatory mendator policing portofolio eveidence low design in order to resolve in good conduct system managemnt low conduct , in court poe s, Create your own Google Form Report Abuse • Our Work • 30x30 Initiative: Advancing Women in Policing • Chicago Neighborhood Policing Initiative • Legislation • Litigation • Regulating Use of Technology in Policing • ReImagining Public Safety • SAJE Policing Assessment Our Mission: We Partner With Communities And Police To Promote Public Safety Through Transparency, Equity, and Democratic Engagement. Our work focuses on front-end, or democratic, accountability—meaning the public has a voice in setting transparent, ethical, and effective policing policies and practices before the police or government act. The goal is to achieve public safety in a manner that is equitable, non-discriminatory, and respectful of public values. Broadly speaking, our work is centered around three focus areas: Front-End Voice in Policing: We believe that in a democratic society, the public must have a voice in how it is policed. Regulation of Policing Technology: We believe that there must be transparency and public debate around the adoption of new policing technologies. Reimagining Public Safety: We believe it is time for a national conversation about what public safety means, and how it is best achieved. Explore our focus areas to learn more about our work. RE: New WFCP Membership Application Inbox WFCP Secretariat 2:15 AM (7 hours ago) to me Hello Tshingombe, Thank you for your interest in joining the WFCP. To confirm, are you applying for institutional membership or association membership? Sincerely, Joanna Andrews Program Officer, WFCP Secretariat World Federation of Colleges and Polytechnics (WFCP) 1 Rideau Street - Suite 701, Ottawa ON K1N 8S7 Email: secretariat@wfcp.org Website: www.wfcp.org Subscribe to our Newsletter From: Tshingombe Tshitadi Sent: Tuesday, September 24, 2024 1:48 AM To: WFCP Secretariat Subject: New WFCP Membership Application About the Applicant Are you a: private institution Type of membership requested Association Membership Are you accredited? not applicable Name of Applicant (individual or institution) Tshingombe engineering/St peace college Number of students enrolled in your institution 20 Name of accrediting body St peace sasseta Please share your reasons for joining WFCP Engineering electrical assessment police officer, Contact Information Contact name Tshingombe Tshitadi Contact email tshingombefiston@gmail.com Contact telephone +270725298946 Website https://tshingombefiston.com Address 20 percy 1030 Rockview 103, Jhb Gauteng South Africa Map It Application Update Inbox Met Recruitment Team Tue, Sep 24, 2:15 PM (19 hours ago) to me Vacancy: 18023 - Intelligence Manager – Public Order & Public Safety Intelligence - Inspector – MO2 Dear tshingombe, Thank you for your application for a new position within the Met. To be eligible to apply for this new position, we have a set of criteria that applicants need to meet. Based on the information you have shared so far; we regret to inform you that you are not eligible to progress with your application. Your individual answers suggest that you do not meet the application criteria. You can read more about our eligibility criteria on our Careers Website or by reviewing information available on MyHR. We understand that this will be disappointing news for you but would like to thank you for your interest in this position and wish you all the best for the future. Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com Met Recruitment Team Tue, Sep 24, 2:20 PM (19 hours ago) Vacancy: 18028 - Intelligence Manager - Public Order & Public Safety Intelligence - Detective Inspector - MO2 Met Recruitment Team Tue, Sep 24, 2:20 PM (19 hours ago) Vacancy: 17954 - PA to DCS Band E Met Recruitment Team Tue, Sep 24, 2:25 PM (19 hours ago) Vacancy: 17991 - Detective Constable - DASO - Professional Standards Met Recruitment Team Tue, Sep 24, 2:25 PM (19 hours ago) Vacancy: 17874 - Quality Assurance Lead Met Recruitment Team Tue, Sep 24, 2:30 PM (19 hours ago) Vacancy: 17915 - Complaint Resolution Unit (CRU) - Complaint handler Met Recruitment Team Tue, Sep 24, 2:30 PM (19 hours ago) Vacancy: 17879 - Electronics Development Engineer Met Recruitment Team Tue, Sep 24, 2:35 PM (19 hours ago) Vacancy: 18014 - Developing Threats Team – PC Met Recruitment Team Tue, Sep 24, 2:35 PM (19 hours ago) Vacancy: 17806 - Licensing Admin Support Officer Met Recruitment Team Tue, Sep 24, 2:40 PM (19 hours ago) Vacancy: 17978 - Professional Standards Unit (MO12/MO4/CRIB) Band D Met Recruitment Team Tue, Sep 24, 2:40 PM (19 hours ago) Vacancy: 18051 - Operations Lead - Superintendent Met Recruitment Team Tue, Sep 24, 2:45 PM (19 hours ago) Vacancy: 17990 - MO2 Met Intel - ANPR Auditor - Innovation Deployment & Compliance Team Met Recruitment Team Tue, Sep 24, 2:45 PM (19 hours ago) Vacancy: 18033 - Police Constable DPS - Professional Standard Unit Met Recruitment Team Tue, Sep 24, 2:55 PM (19 hours ago) Vacancy: 18008 - CSC - Offender Management - Central Orders Team Police Constable Met Recruitment Team Tue, Sep 24, 2:55 PM (19 hours ago) Vacancy: 17775 - PSO - Threat Assessment & Intelligence Unit - Intelligence Officer – Researcher Met Recruitment Team Tue, Sep 24, 2:55 PM (19 hours ago) Vacancy: 18048 - Met Intel PC ANPR Investigations Met Recruitment Team Tue, Sep 24, 3:00 PM (18 hours ago) Vacancy: 18047 - Met Intel DS ANPR Investigations Met Recruitment Team Tue, Sep 24, 3:00 PM (18 hours ago) Vacancy: 17922 - Intelligence Officer -Bomb Data Centre - FMT - SO15 Met Recruitment Team Tue, Sep 24, 3:10 PM (18 hours ago) Vacancy: 17223 - Digital Engagement Officer Met Recruitment Team Tue, Sep 24, 3:10 PM (18 hours ago) Vacancy: 18042 - Covert Admin (COVAD) Deputy Manager Met Recruitment Team Tue, Sep 24, 3:10 PM (18 hours ago) Vacancy: 17823 - SQL Server Database Administrator - Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 3:10 PM (18 hours ago) Vacancy: 18005 - PC - MO6 Public Order Crime Team Met Recruitment Team Tue, Sep 24, 3:15 PM (18 hours ago) Vacancy: 17986 - Driver Assistance Centre Team Leader Met Recruitment Team Tue, Sep 24, 3:15 PM (18 hours ago) Vacancy: 18006 - DS - Public Order Crime Team Met Recruitment Team Tue, Sep 24, 3:30 PM (18 hours ago) Vacancy: 18050 - Resource Management Office Manager Met Recruitment Team Tue, Sep 24, 3:30 PM (18 hours ago) Vacancy: 17925 - Digital Project Officer -
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
16 of 18

NDES Service 3 - SO15 Met Recruitment Team Tue, Sep 24, 3:30 PM (18 hours ago) Vacancy: 18059 - Detective Sergeant - Complex Investigation Team (CIT) Met Recruitment Team Tue, Sep 24, 3:30 PM (18 hours ago) Vacancy: 18078 - National Counter Terrorism Security Office (NaCTSO) – Venues and Public Spaces Unit- Detective Inspector - Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 3:35 PM (18 hours ago) Vacancy: 18015 - Safety Camera Processing Clerk Met Recruitment Team Tue, Sep 24, 3:40 PM (18 hours ago) Vacancy: 18026 - Health & Safety/Accommodation Manager - Band D - Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 3:40 PM (18 hours ago) Vacancy: 18081 - MO19 Specialist Firearms Command – Development, Delivery, Equipment & Finance Sergeant Met Recruitment Team Tue, Sep 24, 3:45 PM (18 hours ago) Vacancy: 18095 - Complaint Handler Met Recruitment Team Tue, Sep 24, 3:50 PM (18 hours ago) Vacancy: 17848 - MBS Reporting Senior Analyst Met Recruitment Team Tue, Sep 24, 3:50 PM (18 hours ago) Vacancy: 18067 - Dev Ops Engineer (Cloud Platform) - Technology CSC - Police Staff - Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 3:55 PM (18 hours ago) Vacancy: 17977 - MetCC Centre Facilities Support Staff Met Recruitment Team Tue, Sep 24, 4:00 PM (17 hours ago) Vacancy: 17872 - BCU Learning and Development Lead Met Recruitment Team Tue, Sep 24, 4:05 PM (17 hours ago) Vacancy: 17923 - Business Analyst – Strategy, Planning and Performance (SPP) Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 4:05 PM (17 hours ago) Vacancy: 17987 - Character Enquiry Centre Team Leader Met Recruitment Team Tue, Sep 24, 4:10 PM (17 hours ago) Vacancy: 18086 - MO7 Taskforce TSG -Police Sergeant Met Recruitment Team Tue, Sep 24, 4:15 PM (17 hours ago) Vacancy: 17229 -Higher Computer Aided Surveyor / 3D Specialist Met Recruitment Team Tue, Sep 24, 4:20 PM (17 hours ago) Vacancy: 18065 - Counter Weapons Threat Team Officer - PC - Counter Terrorism Policing HQ Met Recruitment Team Tue, Sep 24, 4:25 PM (17 hours ago) Vacancy: 18063 - MO19 Specialist Firearms Command - Tactical Firearms Commander Inspector (UNARMED) Met Recruitment Team Tue, Sep 24, 4:40 PM (17 hours ago) Vacancy: 18064 - MO19 Specialist Firearms Command - Tactical Firearms Commander Detective Inspector (UNARMED) Met Recruitment Team Tue, Sep 24, 9:30 PM (12 hours ago) to me Vacancy: 18085 - Royalty and Specialist Protection - RaSP 400 Inspector Met Recruitment Team Tue, Sep 24, 9:35 PM (12 hours ago) to me Vacancy: 18009 - MO7 Taskforce Mounted Branch Inspector Met Recruitment Team Tue, Sep 24, 9:35 PM (12 hours ago) to me Vacancy: 16708 - 202402 - MPS Return Scheme Approaching Retirement Met Recruitment Team Tue, Sep 24, 9:40 PM (12 hours ago) to me Vacancy: 18004 - Digital Forensic Manager Met Recruitment Team Tue, Sep 24, 9:45 PM (12 hours ago) to me Vacancy: 17666 - Motor Vehicle Technician Met Recruitment Team Tue, Sep 24, 9:55 PM (12 hours ago) to me Vacancy: 17392 - Volunteer Police Cadet Leader Google Forms Thu, Sep 26, 9:28 AM (1 day ago) to me Thanks for filling out Removing Barriers to Officer Accountability Here's what was received. Removing Barriers to Officer Accountability Section 1: Attorney Affirmation is MANDATORY if you wish to receive CLE credit. Section 2: Course Evaluation is ENCOURAGED to inform the state of New York on our program. Email * tshingombefiston@gmail.com Section 1: Attorney Affirmation NY CLE Credit for Webinar To obtain New York CLE credit, please complete and sign this form and then submit it to the Policing Project at NYU Law. Your participation must be verified by the provider. Experienced New York attorneys (attorneys who have been admitted to the New York bar for more than two years) may earn CLE credit through nontraditional formats. Newly admitted attorneys (attorneys who have been admitted to the New York Bar for two years or less) should confirm that the format is permissible for the category of credit. New York attorneys should retain a copy of this affirmation. Email * tshingombefiston@gmail.com Format: Webconference Course Code(s) During each session of the conference you will see and/or hear one or more CLE course codes. Please enter the code(s) in the fields below. If you do not enter the correct code(s), you will not be awarded New York CLE credit. If you did not attend the entire conference, you are able to receive partial credit for the individual sessions you attended in their entirety. List all code(s) for September 24, 2024 * Model statute: An Act to Removing Barriers to Accountability and Facilitate Robust Oversight Our model statute gives states guidance on how to remove barriers to law enforcement officer accountability and oversight commonly found in state or local laws, and/or in police collective bargaining agreements. Advocacy Toolkit: Community Oversight of Police Union Contracts This toolkit by the Legal Defense Fund breaks down accountability-impeding provisions in over 100 police union contracts, providing a resource for advocates and community members engaging in police collective bargaining agreement reform efforts. Journal Article: Stephen Rushin, Police Union Contracts, 66 Duke Law Journal 1191-1266 (2017) This article collects and analyzes more than 170 police union contracts, showing how provisions in these agreements serve as barriers to officer accountability. Journal Article: Kevin M. Keenan & Samuel Walker, An Impediment to Police Accountability - An Analysis of Statutory Law Enforcement Officers' Bills of Rights, 14 B.U. PUB. INT. L.J. 185 (2005) This law review article identifies provisions in Law Enforcement Bills of Rights (LEOBORs) from 14 different states that are impediments to holding officers accountable, focusing on five kinds of provisions that are particularly harmfulVictor Dempsey, Community Organizer, Legal Defense Fund Victor Dempsey is a community organizer at the NAACP’s Legal Defense Fund (LDF). Mr. Dempsey has devoted his career to ending police violence through community organizations, eventually founding his own organization to support and advocate for impacted families called Families are the Frontlines. Reneé Hall, former Chief of the Dallas Police Department Reneé Hall is the former Chief of the Dallas Police Department, the first woman to lead the department. Chief Hall has worked to bridge communities with law enforcement through the implementation of a civilian oversight board and has been a champion of accountability by establishing a duty to intervene policy when officers witness excessive force. She graduated with masters degrees from the University of Detroit Mercy (M.S.) and Grambling State University (B.S.). Stephen Rushin, Professor of Law at Loyola University Chicago School of Law Stephen Rushin is the Associate Dean of Faculty Research and the Judge Hubert Louis Will Professor of Law at Loyola University of Chicago School of Law. He has published a series of articles on police unions and the officer internal disciplinary procedures. His research interests include policing, criminal procedure, and criminal sentencing. His work has recently appeared in the Stanford Law Review, the University of Pennsylvania Law Review, the California Law Review, the Cornell Law Review, the Duke Law Journal, the Vanderbilt Law Review, the Texas Law Review, the Iowa Law Review, the Minnesota Law Review, the George Washington Law Review, the Fordham Law Review, the Boston College Law Review, and the Florida Law Review, among other journals. He published the premier article on police union contracts in the Duke Law Journal in 2017. Rushin graduated from Berkeley (J.D. and PhD) and the University of Texas (B.A.). HOST Josh Parker, Deputy Director of Legislative Policy, Policing Project at NYU Law Josh Parker is the Deputy Director of Legislative Policy at the Policing Project. He is a policing policy and legal expert who co-drafted the Removing Barriers to Accountability model statute and has counseled legislators and agency leaders across the country on how to reform their laws to better address police misconduct. Given his expertise, Josh is often sought for legislative testimony, media interviews, and public comment on a number of police misconduct topics. He graduated from the University of Chicago Law School (J.D.), where he served as an Articles Editor of the University of Chicago Law Review, and Duke University (B.A.).21-CIP-J / FFPSA & Kinship (Part 1),Date & Time Sep 24, 2024 09:00 PM Johannesburg Webinar ID 912 5168 3181,Tue Sep 24, 2024 9pm – 10pm (SAST) Where https://nyu.zoom.us /w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.DQcAAAAVPwYvbRZjNTdyNEx1S1NaQzljV2s3NlU2SEdRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA& uuid=WN_3jfCNZddR7iCjsRfhRXPag Who Gabby Bayness 30x30 Initiative: Advancing Women in Policing Chicago Neighborhood Policing Initiative Legislation Litigation Regulating Use of Technology in Policing ReImagining Public Safety SAJE Policing Assessment Our Mission: We Partner With Communities And Police To Promote Public Safety Through Transparency, Equity, and Democratic Engagement. Our work focuses on front-end, or democratic, accountability—meaning the public has a voice in setting transparent, ethical, and effective policing policies and practices before the police or government act. The goal is to achieve public safety in a manner that is equitable, non-discriminatory, and respectful of public values. Broadly speaking, our work is centered around three focus areas: Front-End Voice in Policing: We believe that in a democratic society, the public must have a voice in how it is policed. Regulation of Policing Technology: We believe that there must be transparency and public debate around the adoption of new policing technologies. Reimagining Public Safety: We believe it is time for a national conversation about what public safety means, and how it is best achieved. Explore our focus areas to learn more about our work.*,. Name of CLE Provider: New York University School of Law - Policing Project Please confirm the following statements by checking the boxes and typing your name in the signature field below * ✓ I acknowledge receipt of the course materials for Removing Barriers to Officer Accountability ✓ I certify that I have listened to and/or viewed Removing Barriers to Officers Accountability in its entirety for the sessions for which I've entered codes. Therefore, I request that I be awarded the applicable number of New York CLE credits for this course. Signature * tshingombe tshitadi Date of completion of CLE course (New York attorneys earn CLE credit as of the date they complete a CLE course): * MM 09 / DD 26 / YYYY 2024 Attorney email address to receive CLE certificate (if different from the address above): tshingombekb@gmail.com Section 2: Course Evaluation Course evaluations are optional, but must be offered to all attorneys who participated in today's course. Program Title 21-CIP-J / FFPSA & Kinship (Part 1),Date & Time Sep 24, 2024 09:00 PM Johannesburg Webinar ID 912 5168 3181,Tue Sep 24, 2024 9pm – 10pm (SAST) Where https://nyu.zoom.us /w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.DQcAAAAVPwYvbRZjNTdyNEx1S1NaQzljV2s3NlU2SEdRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA& uuid=WN_3jfCNZddR7iCjsRfhRXPag Who Gabby Bayness 30x30 Initiative: Advancing Women in Policing Chicago Neighborhood Policing Initiative Legislation Litigation Regulating Use of Technology in Policing ReImagining Public Safety SAJE Policing Assessment Our Mission: We Partner With Communities And Police To Promote Public Safety Through Transparency, Equity, and Democratic Engagement. Our work focuses on front-end, or democratic, accountability—meaning the public has a voice in setting transparent, ethical, and effective policing policies and practices before the police or government act. The goal is to achieve public safety in a manner that is equitable, non-discriminatory, and respectful of public values. Broadly speaking, our work is centered around three focus areas: Front-End Voice in Policing: We believe that in a democratic society, the public must have a voice in how it is policed. Regulation of Policing Technology: We believe that there must be transparency and public debate around the adoption of new policing technologies. Reimagining Public Safety: We believe it is time for a national conversation about what public safety means, and how it is best achieved. Explore our focus areas to learn more about our work.*, Date MM 09 / DD 25 / YYYY 2024 Speaker(s): 21-CIP-J / FFPSA & Kinship (Part 1),Date & Time Sep 24, 2024 09:00 PM Johannesburg Webinar ID 912 5168 3181,Tue Sep 24, 2024 9pm – 10pm (SAST) Where https://nyu.zoom.us /w/91251683181?tk=9vyym4gehi0cHxdYwYdOOiYbUw2lCZzZ_lKD0ceCABo.DQcAAAAVPwYvbRZjNTdyNEx1S1NaQzljV2s3NlU2SEdRAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA& uuid=WN_3jfCNZddR7iCjsRfhRXPag Who Gabby Bayness 30x30 Initiative: Advancing Women in Policing Chicago Neighborhood Policing Initiative Legislation Litigation Regulating Use of Technology in Policing ReImagining Public Safety SAJE Policing Assessment Our Mission: We Partner With Communities And Police To Promote Public Safety Through Transparency, Equity, and Democratic Engagement. Our work focuses on front-end, or democratic, accountability—meaning the public has a voice in setting transparent, ethical, and effective policing policies and practices before the police or government act. The goal is to achieve public safety in a manner that is equitable, non-discriminatory, and respectful of public values. Broadly speaking, our work is centered around three focus areas: Front-End Voice in Policing: We believe that in a democratic society, the public must have a voice in how it is policed. Regulation of Policing Technology: We believe that there must be transparency and public debate around the adoption of new policing technologies. Reimagining Public Safety: We believe it is time for a national conversation about what public safety means, and how it is best achieved. Explore our focus areas to learn more about our work.*, Please take a few moments to evaluate this course: Excellent Good Fair Poor N/A Program Content ✓ Instructor Quality ✓ Written Materials ✓ Facility ✓ Technology ✓ Relevence to my practice: engineering project assessment police low enforcement portfolio discipline quality management evidence low in order police design thing resolve order in gov system orientation Comments: god thing on disciplinary conduct code police Job Description Schneider Electric's EcoStruxure™ Automation Expert (EAE) is a software-centric industrial automation system that creates successive improvements throughout your operational lifecycle. The EcoStruxure team supports countries globally in deploying this solution. Your role: Reporting to the EcoStruxure EMEA Manager (Francisco) and as part of a team of 7 Project Managers, you will participate in the deployment of the EAE automation solution in Europe. You will support our clients (internal and external) during pre-sales and project execution phases. Your main missions: • Promote the technical benefits of the EAE solution in Europe with Schneider Electric entities in the relevant countries (joint visits, presentations, demonstrations) • Provide technical support to Schneider's local pre-sales teams • Assist in creating technical documents, technical guides, white papers, knowledge base articles, etc. • Support pilot project execution and execution of key projects for clients (direct and indirect) • Train internal teams in different countries using Schneider's local technical resources • Develop the autonomy of each country in deploying EAE Your profile: • Master's degree in Engineering or equivalent in automation • 3 years of minimum experience in design and automation Your skills: • Understanding of OT (Operational Technology) and IT (Information Technology) convergence to address client sustainability challenges • Understanding of DCS (Distributed Control Systems) concept and implementation • Mastery of secure, open, interoperable, and scalable control systems • Appreciated knowledge of the IEC61499 standard • Aptitude for assembling software components to meet customer requirements • Software integration experience • Commercial aptitude, good communication skills, relationship building, collaboration, and teaching • Curiosity, organizational skills, and autonomy • Fluent in English and French We know that skills manifest in many ways and can be based on your life experience. If you do not necessarily meet all the requirements listed, we still encourage you to apply. We offer you: Our offer includes an attractive remuneration and goes well beyond. If you join Schneider Electric, here's an idea of all that we can offer you to live the best possible experience: • A competitive salary, individual bonus, as well as profit-sharing and participation bonuses rewarding everyone's efforts • A range of social benefits that make life easier: from CSE to rich catalogs, health insurance that meets all needs, generous savings and retirement plans, an advantageous employee share ownership program • Professional development through training, mobility and internal promotion (local and international), skills sharing, etc. • An integration journey from your first day
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
17 of 18

to give you the keys to success at Schneider Electric within a culture that promotes diversity, professional fulfillment, and inclusion • Work-life balance through our telecommuting policy (up to 48% telecommutable time, equipment included), support for parenthood, inter-company childcare facilities, etc." About Our Company Why us? Schneider Electric is leading the digital transformation of energy management and automation. Our technologies enable the world to use energy in a safe, efficient and sustainable manner. We strive to promote a global economy that is both ecologically viable and highly productive ob Description Schneider Electric's purpose is to empower all to make the most of our energy and resources, bridging progress and sustainability - we call this Life Is On. Our mission is to be the digital partner for sustainability and energy efficiency: https://www.youtube.com/watch?v=VbldHPFltQQ Great people make Schneider Electric a great company - and we are currently recruiting for a Budapest-based, Italian speaking Energy Sourcing Analyst to support the sourcing activity in the Italian market. You will be an active member of our energy and sustainability services group, vital to the future success of the business, and you will play a key role in assisting the team facilitate the delivery of our services to clients across Europe. Please note, this is an Entry level role within the team and this will be a Maternity Cover, starting out as a 2-year-long fixed-term contract with the possibility to extend. Purpose of the job: Deliver effective and efficient energy procurement services (for electricity and natural gas) for our Clients. Maintain effective working relationships at an operational level with key Internal (Client Management, Data, Solutions, Risk Management) and External Stakeholders (Energy Suppliers). Drive operational excellence by participating in process and service improvements in response to market developments and business targets. What you will do: • Analyze energy supply contract prices and terms and negotiate with energy suppliers to ensure optimal contracts are secured • Manage client and supplier relationships through excellent formal and informal communication • Work closely with the Client Management and other internal teams to deliver an exceptional level of service to our clients • Develop and maintain a deep understanding of the Italian energy markets and legislation • Maintain regular contact with energy suppliers in order to ensure flawless service delivery to our client • Effectively create/communicate regional market opinions and knowledge to internal/external clients • Manage pre-tender activities through collecting data, invoices, contracts, etc. • Manage the tendering, analysis and subsequent contract award and placement processes relating to complex energy supply contracts • Negotiate and utilise quantitative and qualitative techniques to deliver optimal energy supply contract terms and prices for our clients through regular interaction with the energy suppliers on the related markets • Collaborate with Sourcing leadership to identify, evaluate, and incorporate efficiencies, new services, and innovative ideas/concepts • Participate in budget forecast creation process What we need from you: • Excellent knowledge of MS Excel is a must • University/College degree preferably in Finance/Economics/Maths/Science or Energy related studies or equivalent experience in energy procurement / client or supplier management / contract management / negotiations • Fluency in English AND Italian is a must • Experience of the energy industry gained either at a supplier or an energy consultancy is a big advantage • Experience in multinational environment is an advantage Skills, competencies that can make you the successful candidate: • Strong analytical and logical skills • Be an excellent influencer, negotiator and collaborator, forming effective relationships with demanding stakeholders • Great communication skills, capablility of engaging people of varying levels in seniority and experience • Strong time management and organisational skills • Results focused and self-directed mindset What we offer: • Life, Accident and Health insurance packages (Medicover White Spring) • Cafeteria allowance • Home Office and Utility allowances • Yearly bonus • Global Family Leave • Flexible and hybrid working model • WESOP (World Employee Share Ownership Plan) to become a shareholder in the company • Engagement groups within the company: get a sneak peek to our company life at https://download.schneider-electric.com/files?p_Doc_Ref=Engagement_groups_HU • Working at the company that ranked #1 in TIME Worlds' Most Sustainable Companies in 2024 • International, diverse environment and a company culture that encourages raising questions and ideas - to make an impact • Real future career building opportunities locally & globally • Working directly with international customers dustrial / Manufacturing senior Engineering - 00934K • Manage the process flow and qualification in collaboration with BU and GSC to prepare a successful industrial transfer • Lead the deployment on NPI and capacity increase projects at the facility ensuring consistency between BU & GSC • Work with cross-functional and remote teams to guarantee the deployment of industrial processes • Accountable for decision making and project execution in compliance with project goals, business, industrial y customer requirements • Accountable for projects requirements: resources, product cost fie, planning & schedule, capacity, SPS and other deliverables • Decision making based on priorities and risk assessment • Ensure the capacities adaptation according to the dedicated tools (CAMA, CORIM, Bridge ..), internal or external • Perform regular Queue Simulations, using the waiting queue design tool, in order to optimize Lead Times and assure capacity of the lines. • Define & maintain a referential operating time based on measurement tools adapted (MTM-UAS-timer-video analysis.) • Ensure the profitability of investments adapted to the needs of optimization and development process Guide the choice of designers by providing industrial and logistical requirements • Is the “Time determination & Ergonomics Specialist/Referent” within his perimeter. • Responsible for Productivity action plan in his perimeter (define, implement) • Implement adaptation on the processes and manufacturing workstation for existing products by improving the industrial performance, in manual process, automatic process & PLC (Programmable Logic Control) using SPS techniques and tools. • Involved in the specifications and quotation of new line architectures and industrial scenarios in order to meet Safety/Quality/Lead Times and productivity requirements. • Optimize Lead Times and assure capacity of the lines. • Write operator work instructions for training • Study the feasibility & profitability of investments adapted to the needs. • Qualifies means and processes, in plant but also at suppliers' location. Application Update Inbox Met Recruitment Team Sat, Oct 26, 7:40 PM (16 hours ago) to me Vacancy: 18130 - National Referral Mechanism Coordinator Dear tshingombe, Thank you for your application for a new position within the Met. To be eligible to apply for this new position, we have a set of criteria that applicants need to meet. Based on the information you have shared so far; we regret to inform you that you are not eligible to progress with your application. Your individual answers suggest that you do not meet the application criteria. You can read more about our eligibility criteria on our Careers Website or by reviewing information available on MyHR. We understand that this will be disappointing news for you but would like to thank you for your interest in this position and wish you all the best for the future. Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com Incomplete Application Inbox Met Recruitment Team Thu, Oct 24, 10:15 PM (3 days ago) to me Vacancy: 14783 - 202305- Police Community Support Officer (PCSO) tshingombe, We don’t think you want to continue with your application, and are sorry to see you go. We’ve closed down your application for now, so that we don’t keep bothering you if you’ve decided this isn’t the opportunity for you. If we’ve got this wrong, and you want to carry on, please get in touch and we’ll open your application form back up. Our contact details are below if you want to give us a call. Being a Police Constable isn’t for everybody, so we understand that sometimes applicants change their mind. If you’ve decided this isn’t the role for you, but you’re still interested in joining the Met, please take a look at the other opportunities we’ve currently got available - you can view our careers website here. Have a great day tshitadi! Yours sincerely Shared Services Connected Ltd – Delivering services in partnership with the Metropolitan Police Service Phone: 01633 632500 Email: Enquiries.PoliceJobs@police.sscl.com HCP Open Day with the MPS Inbox Dawn.James@met.police.uk Thu, Oct 24, 3:09 PM (3 days ago) to Dear Healthcare Professional, Thank you for registering your interest to attend our Healthcare Professional Open Day today at Charing Cross Police Station. Unfortunately you didn’t attend, you can however still apply for the role by clicking on the link below, remember to attach a CV and personal statement. Become a custody healthcare practitioner | Metropolitan Police Please do contact me if you have any queries. Kind Regards Dawn Dawn James | Deputy Healthcare Director (Acting) Met Detention (M09) 07917 586675 | dawn.james@met.police.uk Lambeth HQ, 109 Lambeth Road, London, SE1 7LP NOTICE - This email and any attachments are solely for the intended recipient and may be confidential. If you have received this email in error, please notify the sender and delete it from your system. Do not use, copy or disclose the information contained in this email or in any attachment without the permission of the sender. Metropolitan Police Service (MPS) communication systems are monitored to the extent permitted by law and any email and/or attachments may be read by monitoring staff. Only specified personnel are authorised to conclude binding agreements on behalf of the MPS by email and no responsibility is accepted for unauthorised agreements reached with other personnel. While reasonable precautions have been taken to ensure no viruses are present in this email, its security and that of any attachments cannot be guaranteed. to me Dear Fiston, Thank you for applying for the position of Service Centre Helpdesk Coordinator - 33335. We appreciate the opportunity to consider you for employment with Eaton. This communication is to let you know that this job has been filled. We invite you to visit www.eaton.com/careers and apply to other opportunities that match your current career aspirations. Thank you for your continued interest in Eaton. Best regards, Tshingombe, will you answer a question for us? Inbox Schneider Electric Sat, Oct 26, 2:30 PM (21 hours ago) to me Hello Tshingombe, Recently, you applied and were considered for a position with Schneider Electric. While the outcome has not resulted in an offer of employment, we would appreciate your time in answering one final question which will help us understand your lasting impression of Schneider Electric. Our goal is to treat all candidates with fairness and respect and your lasting impression helps us understand if we have achieved our goal. Pulse - One Question Survey Thank you. We look forward to hearing from you! *Please note that all feedback is confidential and is not associated with any application. Any feedback gathered will not impact any potential employment with Schneider Electric. This email is being sent from an unmonitored email address. Schneider Electric can be reached at the following: 800 Federal Street North Andover, MA 01810 https://www.se.com/us/en/ / (978) 975-9600 Survale sends surveys on behalf of Schneider Electric at their request and has no involvement with employment decisions. We can be reached at contactus@survale.com. To unsubscribe click here Powered by Survale In Automatic reply: letter explanation theoretical pratical base work , n diplomat award engineering electrical Inbox CallCentre via dhetgovza.onmicrosoft.com 9:16 AM (8 hours ago) to me Please note that this is an automated response, do not reply to it. Thank you for contacting the Department of Higher Education and Training Call Centre. We appreciate your inquiry. Regarding NN Diploma, Nated, and NCV certificate enquiries: • All applications for new issues, replacements, or combination requests must be submitted directly to the relevant college. • Please note that there is a minimum waiting period of 3-6 months for diploma applications. • The issuance of NN Diploma is currently paused. We have communicated this to all colleges. • In the meantime, students whose diplomas are finalized but awaiting printing can obtain a confirmation letter from their college. We apologize for any inconvenience this may cause and appreciate your understanding. MMA support Inbox MMA Support via freshdesk.com Mon, Oct 21, 8:41 AM (2 days ago) to me Hi Tshingombe Thanks so much for reaching out! We know there’s nothing worse than sending an email and getting no response. So, to make sure that you know that we are aware of your email, we have created this handy auto-reply just to let you know that we have your email and we are assigning it to the best person to help you! We like to be quite speedy on our replies, so you should get a response soon. Your experience is our first priority and our agents are here from Monday to Saturday between 08h00 and 20h00 and on Sundays between 08h00 and 19h00. You can also chat with our agents directly using our live chat on the Shoprite app. In the meantime, if you have general questions about the Money Market Account, check out our website for some handy walk-throughs and answers to some questions you may have. We have also created some useful videos on how to use the Money Market Account, please click here to view them. If you have any additional information that you think will help us to assist you, please feel free to reply to this email. We look forward to chatting soon! Money Market Account Services Team (no subject) Inbox Ahmed Abdelmonem (International Supplier) Tue, Oct 22, 1:52 PM (1 day ago) to me Hi Tshingombe, I trust this email finds you in good health. My name is Ahmed Abdelmonem, and I serve as a Customer Lifecycle Manager for Microsoft. My responsibilities include overseeing the SMB segment in the South African market. Within my role, I manage various Microsoft workloads, including: • Microsoft Azure: Our expansive cloud platform that provides an array of services tailored for the development, deployment, and management of applications. • Microsoft Dynamics: An integrated suite of ERP and CRM software applications designed to streamline business processes. • Modern Workplace: A collection of solutions aimed at enhancing collaboration and productivity within today’s digital-first work environment. • Copilot: Our latest AI-driven platform that assists in code generation and other complex tasks, ensuring efficiency and innovation. I would like to connect with you to discuss your needs and explore the best possible solutions for your organization. Please let me know a convenient time for us to connect. Thank you for your attention, and I look forward to connecting with you soon. Regards, Ahmed Abdelmonem Customer Lifecycle Manager | SMB South Africa | MEA v-ahmabdelmo@microsoft.com Application Unsuccessful Inbox SARS Human Capital and Development Sat, Oct 26, 9:00 AM (1 day ago) to me Dear Tshingombe Tshitadi , Thank you for applying for Specialist Advisor: Direct Tax (Legal and Domestic Tax). After careful consideration and review of your profile against the minimum requirements (qualifications and work experience) of the job, we regret to inform you that your application was not successful. We encourage you to visit our career site and search other available opportunities. Thank you for showing interest and we wish you all the best in your job search. Thank you for applying to Schneider Electric! Inbox Schneider Electric Unsubscribe Sat, Oct 26, 5:22 AM (1 day ago) to me Hi Tshingombe, We appreciate your interest in career opportunities at Schneider Electric! Thank you for taking the time to apply for the Senior Power Electronics Architect position we have posted online. One of our Talent Acquisition Professionals will review your submission and contact you either by phone or email if you are selected to move forward in the process. We will make every attempt to complete this initial review within 10 – 15 business days; however, we ask for your understanding if it takes slightly longer due to high volumes. At Schneider Electric, we desire to provide reasonable transparency throughout the process. During the application process, you created an account in which you can log-in to check the status of your application at any time. You can also use this account to update and strengthen your profile. Thank you, The Schneider Electric Talent Acquisition Team Access My Career Portal Search for Jobs It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting, hiring, training, transferring and promoting all qualified individuals regardless of race, religion, color, gender, disability, national origin, ancestry, age, military status, sexual orientation, marital status, or any other legally protected characteristic or conduct. ________________________________________ This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to: https://se.icims.com/icims2/?r=6EA61614346& contactId=5749653&pid=17 © Schneider Electric Schneider Electric Sat, Oct 26, 5:26 AM (1 day ago) to me Hi Tshingombe, We appreciate your interest in career opportunities at Schneider Electric!
10/27/2024, 12:52 PM
Request an intellectual property (IP) licence | Metropolitan Policehttps://www.met.police.uk/rqo/request/ipl/request-intellectual-property-ip...
18 of 18

Thank you for taking the time to apply for the Digital Power Inside Sales Manager position we have posted online. One of our Talent Acquisition Professionals will review your submission and contact you either by phone or email if you are selected to move forward in the process. We will make every attempt to complete this initial review within 10 – 15 business days; however, we ask for your understanding if it takes slightly longer due to high volumes. At Schneider Electric, we desire to provide reasonable transparency throughout the process. During the application process, you created an account in which you can log-in to check the status of your application at any time. You can also use this account to update and strengthen your profile. Thank you, The Schneider Electric Talent Acquisition Team Access My Career Portal Search for Jobs It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting, hiring, training, transferring and promoting all qualified individuals regardless of race, religion, color, gender, disability, national origin, ancestry, age, military status, sexual orientation, marital status, or any other legally protected characteristic or conduct. ________________________________________ This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to: https://se.icims.com/icims2/?r=6EA61614346&contactId=5749656&pid=17 © Schneider Electric Schneider Electric Sat, Oct 26, 5:27 AM (1 day ago) We appreciate your interest in career opportunities at Schneider Electric! Thank you for taking the time to apply for the EcoStruxure Automation Expert Regional Schneider Electric Sat, Oct 26, 5:29 AM (1 day ago) to me Hi Tshingombe, We appreciate your interest in career opportunities at Schneider Electric! Thank you for taking the time to apply for the Energy Sourcing Analyst (Italian speaking) -Maternity Cover position we have posted online. One of our Talent Acquisition Professionals will review your submission and contact you either by phone or email if you are selected to move forward in the process. We will make every attempt to complete this initial review within 10 – 15 business days; however, we ask for your understanding if it takes slightly longer due to high volumes. At Schneider Electric, we desire to provide reasonable transparency throughout the process. During the application process, you created an account in which you can log-in to check the status of your application at any time. You can also use this account to update and strengthen your profile. Thank you, The Schneider Electric Talent Acquisition Team Tshingombe Tshitadi Dashboard | Log Out My Career Account Options shown include to update your full profile (helps get important information to our recruiting team), current and past application submissions with current status as well as managing subscription preferences to our talent communities. How can I correct my Personal Information? No need to wait for us, you own and are empowered to correct your data at any time. Just click on 'Update My Profile' and correct the information. Options Update My Profile View Current Job Opportunities Manage My Interests My Rights Submissions All times are in Eastern European Standard Time. Each row is an application to a Job. The last column contains buttons for actions such as withdrawing or continuing an application if applicable. ID Title Status Last Update Actions 2023-62576 Energy Sourcing Analyst (Italian speaking) - Maternity Cover Received Submission 10/25/2024 2023-55706 EcoStruxure Automation Expert Regional Consultant Received Submission 10/25/2024 2024-79748 Digital Power Inside Sales Manager Received Submission 10/25/2024 2024-79405 Senior Power Electronics Architect Received Submission 10/25/2024 2024-79092 Power Systems Medium Voltage Intern Not Selected 10/23/2024 Privacy Notice Schneider Electric Community  About Fiston Tshingombe Fiston Company : Tshingombe Engineering engineering electrical st peace college diploma ,  Cadet Online Community Badges View All  2 Posts 0 Likes Received  0 Likes Given 0 Solutions  MY ACTIVITY BOOKMARKS SUBSCRIPTIONS DRAFTS Go to mySchneider  Translate to: Please select  1 Help  Feedback About Fiston - Schneider Electric Community https://community.se.com/t5/user/viewprofilepage/user-id/153387 1 of 3 10/17/2024, 12:05 PM No Content Available My Content Likes Given Latest Contributions Activity Feed 0 0 0 0 0 0 0 2 My Moderated Posts Understanding Our Pre-Moderation Process: Fostering a Positive Community Environment       My Photos Upload An Image  Top Tags english scada SCADA software SCADA tutorial SCADA app Telemetry and SCADA ups apc battery smart-ups PowerChute back-ups turkish power shutdown firmware bug Indonesian modbus spacelynk management network software beeping edc communication homelynk NMC network_management_card problem View All  Feedback About Fiston - Schneider Electric Community https://community.se.com/t5/user/viewprofilepage/user-id/153387 2 of 3 10/17/2024, 12:05 PM Terms & Conditions Privacy Notice Change your cookie settings © 2024 Schneider Electric, Inc  FORUMS  KNOWLEDGE CENTER EVENTS & WEBINARS IDEAS BLOGS GET STARTED  | | Feedback About Fiston - Schneider Electric Community https://community.se.com/t5/user/viewprofilepage/user-id/153387 3 of 3 10/17/2024, 12:05 PM Thank you for your interest in Microsoft! Inbox Microsoft Recruiting Unsubscribe Fri, Oct 25, 5:10 PM (2 days ago) to me Hi Fiston Tshingombe teodor, Thank you for your interest in a career at Microsoft. Unfortunately, we will not be moving forward with your candidacy for the position of Software Engineer II, 1755381 at this time. However, we’d like to encourage you to continue to explore other career opportunities on Microsoft Careers as we continually update openings on a daily basis. We look forward to considering you for other positions at Microsoft! Thank you, Microsoft Recruiting Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. This mail is sent from an unmonitored mailbox. Please do not reply. Your Application to Schneider Electric - Tshingombe Tshitadi Inbox Schneider Electric Unsubscribe 2:17 PM (2 hours ago) to me Hi Tshingombe, Thank you again for your interest in Schneider Electric and the Power Systems Medium Voltage Intern role we have on our team. We wanted to follow-up on the status of your candidacy. Your application was impressive; however, you were not selected to continue forward in the process. Please do not take this decision to mean we have no interest in you as a candidate. We will keep your resume in our system and share opportunities that fit your skills and experience. New positions are posted daily, so we encourage you to continue visiting our career website but also sign-up for our talent pool emails to receive notification of the latest roles that match your profile. We wish you success in your job search and hope we will have the chance to consider you for another role in the future. Best regards, Brock Coffey The Schneider Electric Talent Acquisition Team Access My Career Portal Search for Jobs ________________________________________ This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to: https://se.icims.com/icims2/?r=6EA61614346&contactId=5716766 © Schneider Electric Update on Your Job Application for (644) Team Leader - Food and Beverages - CSD Inbox SARB Talent Acquisition 2:30 PM (2 hours ago) to me Dear tshitadi tshingombe, Thank you for your your application to (644) Team Leader - Food and Beverages - CSD (644). Kindly note that this requisition hiring process currently on hold. Hence selection process will be paused temporarily, we will notify you as soon as we resume this process. Regards, SARB Talent Acquisition Team Update on your Job application with SARB SARB Talent Acquisition 2:35 PM (2 hours ago) Dear tshitadi tshingombe, Thank you for your interest in the (644) Team Leader - Food and Beverages - CSD at the SARB, we regret to inform you that your application was unsuccessful. Thank you for your interest in Microsoft! Inbox Microsoft Recruiting Unsubscribe 9:29 AM (7 hours ago) to me Hi Fiston Tshingombe teodor, Thank you for your interest in a career at Microsoft. Unfortunately, we will not be moving forward with your candidacy for the position of Senior Applied AI Engineer , 1762298 at this time. However, we’d like to encourage you to continue to explore other career opportunities on Microsoft Careers as we continually update openings on a daily basis. We look forward to considering you for other positions at Microsoft! Thank you, Microsoft Recruiting Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice. This mail is sent from an unmonitored mailbox. Please do not reply. 11 of 8,039 Application Unsuccessful Inbox SARS Human Capital and Development 8:30 AM (8 hours ago) to me Dear Tshingombe Tshitadi , Thank you for applying for Researcher: Tariff X2. After careful consideration and review of your profile against the minimum requirements (qualifications and work experience) of the job, we regret to inform you that your application was not successful. We encourage you to visit our career site and search other available opportunities. Thank you for showing interest and we wish you all the best in your job search. Best Regards, SARS Talent Acquisition Team 23 October 2024 SARS Human Capital and Development 10:30 AM (6 hours ago) to me Dear Tshingombe Tshitadi , Thank you for applying for Technical Officer: Tariff Classification. After careful consideration and review of your profile against the minimum requirements (qualifications and work experience) of the job, we regret to inform you that your application was not successful. SARS Human Capital and Development 10:30 AM (6 hours ago) to me Dear Tshingombe Tshitadi , Thank you for applying for Investigator: Digital Fraud. After careful consideration and review of your profile against the minimum requirements (qualifications and work experience) of the job, we regret to inform you that your application was not successful. Update Around Your Application Inbox Eaton TalentHub Tue, Oct 22, 2:43 PM (1 day ago) to me Dear Fiston, Thank you for applying for the position of Commercial Finance Manager - 31056. We appreciate the opportunity to consider you for employment with Eaton. This communication is to let you know that this job has been filled. We invite you to visit www.eaton.com/careers and apply to other opportunities that match your current career aspirations. Thank you for your continued interest in Eaton. Best regards, Eaton TalentHub Tue, Oct 22, 3:47 PM (1 day ago) to me Dear Fiston, Thank you for applying for the position of Service Centre Helpdesk Coordinator - 33335. We appreciate the opportunity to consider you for employment with Eaton. This communication is to let you know that this job has been filled. We invite you to visit www.eaton.com/careers and apply to other opportunities that match your current career aspirations. Thank you for your continued interest in Eaton. Best regards,
Please tell us the name of the officer or member of staff you are working with in relation to this request








 

Become a Member 
My Elektor






Topics 
Magazine 
Articles 
News 
Video 
Projects 
Newsletter 
Submit 
Store 

You are now logged in. 
MyLAB

EN0202272ID
No bio








0 | Follow user
View as visitor: 

My Groups
Coming soon
My Stats
0 Published projects
Views
0 Followers
0 Star(s) on average
0 Comments
0 Comments
My Projects
No projects 
Following
Not following any project 
Subscribe to the e-zine 


Elektor is an international platform for applied electronics, providing engineers, makers, and startups with expert content, practical knowledge, and industry insights. Since the 1960s, we’ve empowered a global community to design, build, and share real-world solutions. Members get exclusive project access, store discounts, and opportunities to collaborate with top innovators. Whether you’re learning, designing, or scaling a business, Elektor helps you connect, create, and grow. 
Become a member 
CUSTOMER SERVICE
Privacy Policy
Terms of business
Copyright
Contact us
Advertising info
ELEKTOR WORLD
About Elektor
Elektor MAGAZINE
Elektor LABS
Elektor STORE
Submit Your Content
Social Media
       

Safe Payments
      
BECOME FREE MEMBER
AND RECEIVE OUR EZINE

THE ELEKTOR UNIVERSE 


Become a Member 
My Elektor






Topics 
Magazine 
Articles 
News 
Video 
Projects 
Newsletter 
Submit 
Store 

Elektor Account 

My Account

My Address Details

My Membership

My PDF's & Courses 

My Projects

My tag alert preferences

My Newsletter preferences

My Loyalty Coupons

Logout

My Account 
Avatar

 
Upload your profile picture here 
JPEG, PNG or GIF file - 5 MB file size limit (please note this picture may be used with your online publications on our websites). 
Gender
First Name

Last Name

Nickname

Date of Birth

My DVD settings
Email address 
tshingombefiston@gmail.com Primary 
Add email address 
Invoice emailaddress

Phone numbers 
Add phone number 
Change password 
Subscribe to the e-zine 


Elektor is an international platform for applied electronics, providing engineers, makers, and startups with expert content, practical knowledge, and industry insights. Since the 1960s, we’ve empowered a global community to design, build, and share real-world solutions. Members get exclusive project access, store discounts, and opportunities to collaborate with top innovators. Whether you’re learning, designing, or scaling a business, Elektor helps you connect, create, and grow. 
Become a member 
CUSTOMER SERVICE
Privacy Policy
Terms of business
Copyright
Contact us
Advertising info
ELEKTOR WORLD
About Elektor
Elektor MAGAZINE
Elektor LABS
Elektor STORE
Submit Your Content
Social Media
       

Safe Payments
      
BECOME FREE MEMBER
AND RECEIVE OUR EZINE

THE ELEKTOR UNIVERSE 

 Mains Power 
Outages Monitor 
Is Your Grid Supply 
Steadily Available? 
8-Bit Companion for 
the Raspberry Pi 
Power Saving Made Easy 
Mercury Rectifiers 
PECULIAR 
Infographics 
Power & Energy 
Speed Control of 
a Brushed DC Motor 
EMF Measurement 
Instead of Tachogenerator 
535B 
JANUARY & FEBRUARY BONUS EDITION 2025 | ELEKTORMAGAZINE.COM 
EDITION 
DIGITAL 
FOCUS ON 
Power & Energy 
1
9
6
1 
100k 
S
I
N
C 
240210-002 
PIC 
GND 
OPI 
EXT 
D7a 
BZX84C2V7-TP 
C13 
100n 
D1a 
BAS21 
R9 
4k7 
R7 
1k 
R8 
EOne partner, 
unlimited 
technology 
solutions. 
fortec-integrated.de 
fortec-power.de 
• Embedded 
• HMI systems 
• Power supplies 
• Displays and TouchCONTENTS 
Elektor January/February 2025 Bonus Edition 
Elektor Magazine is published 8 times a year by 
Elektor International Media b.v. 
PO Box 11, 6114 ZG Susteren, The Netherlands 
Phone: +31 46 4389444 
elektor.com | elektormagazine.com 
For all your questions 
service@elektor.com 
Become a Member 
elektormagazine.com/membership 
Advertising & Sponsoring 
Büsra Kas 
Tel. +49 (0)241 95509178 
busra.kas@elektor.com 
elektormagazine.com/advertising 
Copyright Notice 
© Elektor International Media b.v. 2025 
The circuits described in this magazine are for 
domestic and educational use only. All drawings, 
photographs, printed circuit board layouts, 
programmed integrated circuits, digital data 
carriers, and article texts published in our books and 
magazines (other than third-party advertisements) 
are copyright Elektor International Media b.v. and 
may not be reproduced or transmitted in any form 
or by any means, including photocopying, scanning 
and recording, in whole or in part without prior 
written permission from the Publisher. Such written 
permission must also be obtained before any part 
of this publication is stored in a retrieval system of 
any nature. Patent protection may exist in respect 
of circuits, devices, components etc. described 
in this magazine. The Publisher does not accept 
responsibility for failing to identify such patent(s) 
or other protection. The Publisher disclaims any 
responsibility for the safe and proper function of 
reader-assembled projects based upon or from 
schematics, descriptions or information published in 
or in relation with Elektor magazine. 
International Editor-in-Chief 
Jens Nickel 
Content Director 
C. J. Abate 
Publisher 
Erik Jansen 
C. J. Abate 
Content Director, Elektor 
Bonus Edition 
Power & Energy Solutions 
Looking for more power- and energy-related content? This 
bonus edition of ElektorMag features additional content to 
inspire you to design your own solutions. As usual, we include 
articles on other interesting topics as well. 
Is your grid supply steadily available? The article, “Mains Power 
Outages Monitor,” details a circuit that constantly monitors 
mains power and signals outages. 
Before high-power semiconductor-based recti! ers, converting 
AC to DC in industrial and transportation applications was a 
signi! cant challenge. Devices were bulky, fragile, used polluting 
materials, and demanded frequent maintenance. Check out 
the article, “Mercury Recti! ers,” to learn about mercury arc 
recti! ers and more. 
Brush-type DC motors are often replaced by brushless 
(BLDC) and stepper motors, but their simpler control still has 
advantages. The article, “Speed Control of a Brushed DC Motor,” 
explores maintaining constant speed regardless of torque — 
without a tachometer generator. 
We hope you enjoy these articles and rest of the content in 
the Bonus edition. As you work on your own projects, be 
sure to document your progress on the Elektor Labs platform 
(www.elektormagazine.com/labs)! 
International Editor-in-Chief: Jens Nickel | Content Director: C. J. Abate | International Editorial Sta! : Asma Adhimi, Roberto Armani, Eric Bogers, JanBuiting, 
Rolf Gerstendorf (RG), Ton Giesberts, Saad Imtiaz, Alina Neacsu, Dr. Thomas Scherer, Jean-Francois Simon, Clemens Valens, Brian Tristam Williams | 
Regular Contributors: David Ashton, Stuart Cording, Tam Hanna, Ilse Joostens, Prof. Dr. Martin Ossmann, Alfred Rosenkränzer | Graphic Design & Prepress: 
Harmen Heida, Sylvia Sopamena, Patrick Wielders | Publisher: Erik Jansen | Technical questions: editor@elektor.com 
The Team 
COLOPHON 
EDITORIAL 
The January/ 
February 2025 
edition of ElektorMag 
is available at 
newsstands and in 
the Elektor Store. 
3 Colophon 
4 Speed Control of a Brushed DC Motor 
EMF Measurement Instead of Tachogenerator 
10 8-Bit Companion for the Raspberry Pi 
Power Saving Made Easy 
12 From Life’s Experience 
Micromanagement 
14 Peculiar Parts 
Mercury Rectifiers 
16 Infographics: Power and Energy 
18 Mains Power Outages Monitor 
Is Your Grid Supply Steadily Available? 
January & February 2025 3 
One partner, 
unlimited 
technology 
solutions. 
fortec-integrated.de 
fortec-power.de 
• Embedded 
• HMI systems 
• Power supplies 
• Displays and Touchgenerator unit is larger and more expensive 
than a tacholess version of a motor. 
  
If the motor is operated with a pulsed 
voltage (PWM), however, the speed is 
proportional to the duty cycle. At the same 
time, the motor operates as a generator in 
the off-phase of the PWM voltage so that its 
speed can be measured in this phase. In the 
past, in the analog age, the electronic effort 
for such a control was not insignificant, as 
can be seen from the schematic diagram 
in Figure 5. 
  
A rectangle generator, a voltage-controlled 
pulse width modulator, a sample-and-hold 
circuit to measure the actual speed value, 
and a PI controller were required. In the 
digital world, the principle remains the 
same, but the effort required is consid
erably reduced thanks to the use of a 
microcontroller. 
By Rainer Schuster (Germany) 
Brush-type DC motors 
are increasingly being 
replaced by their brushless 
(BLDC) and stepper motor 
competitors. However, 
their use still makes some 
sense, as the control effort 
is considerably lower. This 
article shows how to keep 
the speed of a DC motor with 
brushes constant regardless 
of the torque – and without a 
tachometer generator. 
  
In the simplest case, a DC motor is connected 
to a variable voltage supply, as shown in 
Figure 1. The speed is (theoretically) propor
tional to the supply voltage VM, but only as 
long as the torque is constant. Unfortu
nately, the equivalent circuit diagram of the 
DC motor looks like Figure 2. The motor 
winding not only has an inductance LM, but 
also an ohmic resistance of the copper wire, 
which is designated by RM. The higher the 
torque, the more voltage drops across RM, 
until finally there is no more voltage across 
the inductance LM and the motor stops 
(Figure 3). 
  
Control with Tachogenerator or 
EMF Measurement 
To compensate for these torque-dependent 
speed fluctuations, the motor was once 
usually coupled to a tachogenerator, which 
in turn supplied a voltage proportional to the 
speed (Figure 4). However, a motor-tacho
Speed Control 
of a Brushed DC Motor 
EMF Measurement Instead of Tachogenerator 
basics 
4 Bonus Edition January & February 2025 www.elektormagazine.comRPM ~ VM 
M 
VM 
Figure 1: In an ideal world, the speed is 
proportional to the motor voltage. 
I ~ N 
V = V – R x I 
RPM ~ V 
L 
RM 
M 
M 
M 
M M M 
M M 
VM 
Figure 2: In practice, the ohmic resistance of the motor winding 
joins its inductance. 
U/min 
I M 
NM 
Figure 3: The higher the torque, the slower 
the motor turns. 
Rev. 
target 
value 
Differential 
amplifier 
Tacho 
generator 
Motor 
Voltage 
regulator 
Power 
supply 
M 
Figure 4: Block diagram of a motor control 
system with tachogenerator. 
PI-Regler 
Drehzahl
Sollwert 
Sample & Hold-Schaltung 
MOSFET-Schalter 
Spannungsgesteuerter 
Pulsbreitenmodulator 
NF-Rechteck
Generator 
Strom
versorgung 
Motor 
M 
Figure 5: Block diagram of a motor control with EMF measurement. 
January & February 2025 5  
Practical Implementation of an 
EMF Control 
As the complete circuit diagram in 
Figure 6 shows, an ATtiny45 microcon
troller from Microchip with 4 kB of flash 
memory is used for control. The controller 
has only eight pins, but is perfectly suited 
for this application. It can be programmed 
“in system” via SV2 using an ISP program
ming device. 
  
The microcontroller is supplied with 5 V by 
the voltage regulator IC2, which is why the 
input voltage (and thus the motor voltage) 
must not exceed 24 V. Q1 and Q2 control 
the motor. Q2 is a PMOS transistor of the 
type IRF4905, which can theoretically 
handle a motor current of 74 A, but only if a 
sufficiently dimensioned heat sink is used. 
Figure 7 shows what happens at the motor 
terminals during the different phases of 
the PWM signal: After the ON phase of the 
PWM signal, a demagnetization period 
follows in the OFF phase; then the motor 
generates an EMF voltage that is propor
tional to the speed. This voltage is fed to 
the ADC2 analog-to-digital converter of 
the microcontroller via the R4/R5 voltage 
divider. R5 should be dimensioned so that 
the voltage at ADC2 does not exceed 5 V. 
VB 
R5 
12 V 
4k7 
24 V 
2k2 
  
The setpoint speed, which is set by the RPM 
potentiometer or an external voltage of 
0…5 V at X6, is sent to ADC1 of the micro
controller. Diode D1 is absolutely neces
sary because when the control voltage is 
switched off, the inductance of the motor 
discharges, which results in a negative 
voltage spike that D1 limits to about 0.7 V. 
Figure 8 shows a suggested printed circuit 
board layout for the motor control with 
EMF measurement; the required compo
nents are listed in the Component List. 
  
Software I 
The software for the ATtiny45 was written in 
BASCOM. The controller is operated inter
nally at 8 MHz. Timer0 is operated as a PWM 
timer in Phase Correct PWM Timer mode. 
Demagnetization 
Switch-o phase 
Switch-on phase 
Figure 7: The speed is measured in the switch-off phase after demagnetization. EMF = actual motor speed 
240486-009 
see 
text 
ISP 
RPM 
+5V 
+5V 
MOSI 
GND 
Reset 
SCK 
MISO 
+5V 
+24V max. 
+24V max. 
X2 
Power 
PB5(RESET/ADC0) 
PB3(ADC3) PB2(SCK-ADC1) 
PB4(ADC2) 
PB1(MISO) 
PB0(MOSI) 
IC1 
ATtiny45 
GND 
VCC 
4 
1 
2 
3 
8 
7 
6 
5 
1 
3 
5 
2 
4 
6 
SV1 
C1 
1n 
X1 
C2 
100n 
C3 
100n 
Motor 
D1 
1N4004 
Q2 
IRF4905 
G 
D 
S 
R1 
R2 
47k 
R3 
1M 
Q1 
G 
S 
D 
BS170 
R4 
R5 
IC2 
78L05 
C4 
100n 
C5 
100µ 
35V 
R6 
10k 
X3 
C6 
10µ 
16V 
R7 
Figure 6: Practical circuit of the EMF motor control. 
6 Bonus Edition January & February 2025 www.elektormagazine.com 
10k 
10k 
10kWith a prescaler of N  =  64, the PWM 
frequency is: 
  
At 8 MHz, this results in a frequency of 
245 Hz. The pulse width is set via register 
PWM0A from 0 to 255. 
  
Depending on the motor type, the prescaler 
may need to be set to 256, for example if 
the induction phase is longer than or the 
same length as the switch-off phase. This 
results in a PWM frequency of approxi
mately 60 Hz. 
  
In the main program loop, the speed 
setpoint is constantly read in at ADC1. The 
actual value is read in at ADC2 during the 
off-phase (Pwm_Pin=0) and summed up. 
When the motor is switched on again, the 
average of the actual value is calculated. 
  
To implement the PI controller, there is 
the constant Ti (integration time), together 
with the time constant of Timer1 and Kp 
(proportional gain), which must be adapted 
to the motor used. The interrupt time of 
Timer1 is set using the TCCR1 register: 
TCCR1 
Timer1 Interrupt 
4 
250 µs 
5 
500 µs 
6 
1 ms 
7 
2 ms 
When Ti has expired (Timer1-Interrupt × Ti ), 
the speed deviation is calculated, added to the 
previous value (taking into account the sign) 
and multiplied by Kp. The result is output 
directly as the new switch-on duration. 
  
Control Using RI Compensation 
Another practical solution can be what is 
known as RI compensation. As mentioned 
at the beginning, the speed fluctuation of a 
DC motor is due to the ohmic resistance of 
its copper winding. If the current through 
the motor is measured, this resistance can 
be compensated. To do this, only the coil 
resistance of the motor needs to be known, 
which can be easily measured. 
  
The circuit in Figure 9 is similar to that in 
Figure 6, except that the motor current is 
measured as a voltage drop across R5. R5 
is to be dimensioned so that a maximum 
of 0.5 V is dropped across R5 at maximum 
motor current. The power dissipation in 
watts must be equal to R5 × motor current 
squared. Figure 10 shows a suggested 
layout for the motor control with RI 
compensation. 
  
1 
6 
C1 
C2 
C3 
C4 
R3 
R4 
R5 
SV1 
C5 
C6 
R1 
R7 
1 n 
1 00n 
1 00n 
1 00n 
1 M 
1 0k 
TINY45 
1 00u/35 
1 0u/1 6 
1 0k 
1 0k 
Figure 8: Proposal for a circuit board layout for 
the EMF control. 
1 
6 
C1 
C2 
C3 
C4 
R1 
R3 
R5 
SV1 
C5 
C6 
R7 
1 n 
1 00n 
1 00n 
1 00n 
1 0k 
1 M 
TINY45 
1 00u/35 
1 0u/1 6 
1 0k 
Figure 10: Proposed circuit board layout for the 
control with RI compensation. 
Figure 9: The motor control with RI 
compensation differs only in one detail. 
240486-009 
see 
text 
ISP 
RPM 
+5V 
+5V 
MOSI 
GND 
Reset 
SCK 
MISO 
+5V 
+24V max. 
+24V max. 
X2 
Power 
PB5(RESET/ADC0) 
PB3(ADC3) PB2(SCK-ADC1) 
PB4(ADC2) 
PB1(MISO) 
PB0(MOSI) 
IC1 
ATtiny45 
GND 
VCC 
4 
1 
2 
3 
8 
7 
6 
5 
1 
3 
5 
2 
4 
6 
SV1 
C1 
1n 
X1 
C2 
100n 
C3 
100n 
Motor 
D1 
1N4004 
Q2 
IRF4905 
G 
D 
S 
R1 
R2 
47k 
R3 
Q1 
G 
S 
D 
BS170 
R4 
R5 
IC2 
78L05 
C4 
100n 
C5 
100µ 35V 
R6 
10k 
X3 
C6 
10µ 
16V 
Software II 
The software for the RI compensation is 
also written in BASCOM. Timer0 is config
ured as a PWM timer with a frequency of 
245 Hz. In contrast to the EMF control, 
the control here is designed as a pure P 
controller. To do this, the coil resistance 
of the motor and the supply voltage must 
be known and specified as constants RM 
and U0 in the program. 
  
The motor current is now measured during 
the switch-on phase of the PWM signal. 
The effective value of the current is calcu
lated from the switch-on duration: 
  
The duty cycle is then increased by the 
corresponding value. 
  
Two Options 
There are several ways to control a DC 
motor without a tachogenerator. Each of 
these options has different advantages and 
disadvantages: 
  
> For the EMF control, a PI controller 
is required, the parameters of which 
January & February 2025 7 
A1 7,5mm 
1 
2 
1 
2 
- 
OI 
1 
2 
3 
D1 
IC2 
Q1 
Q2 
R2 
X1 
X2 
X3 
IC1 
R6 
1 N4004 
78L05 
BS1 70 
IRF4905 
47k 
1 0k 
A1 7,5mm 
1 
2 
1 
2 
- 
OI 
1 
2 
3 
D1 
IC2 
Q1 
Q2 
R2 
X1 
X2 
X3 
IC1 
R4 
1 N4004 
78L05 
BS1 70 
IRF4905 
47k 
1 0k 
10k 
10k 
10kmust be adapted to the motor used 
in order to optimize over- and under
shoot. To do this, voltage fluctu
ations in the supply voltage are 
compensated. 
> With RI compensation, there are 
no overshoots or undershoots, but 
voltage fluctuations in the supply 
voltage are not compensated. 
  
The schematics, layouts, and software for 
both controllers can be downloaded from 
the Elektor Labs project page at [1]. 
Translated by Jörg Starkmuth — 200486-01 
  
About the Author 
Rainer Schuster ’s fascination with 
electronics began at the age of 13, when 
he received the Philips EE1 electronics 
experiment kit from his parents for Christ
mas in 1970. In September 1971, he bought 
his first issue of Elektor magazine and has 
remained loyal to it to this day. After study
ing electrical engineering at the Munich 
University of Applied Sciences, he worked 
for 37 years as an engineer in electronics 
development at Agfa in Munich. He has 
been writing articles for Elektor since 
2009. Now that he is retired, he also has 
his own YouTube channel (www.youtube. 
com/@rainerschuster5722), where he 
posts his projects. 
Questions or Comments? 
Do you have questions or comments 
about this article? Email the author at 
rainerschuster@mnet-mail.de, or contact 
Elektor at editor@elektor.com. 
Related Product 
> 
Motor Control Development 
Bundle 
www.elektor.com/20534 
[1] Elektor Labs page about this project: https://tinyurl.com/200486-01 
[2] YouTube video: https://www.youtube.com/watch?v=6IEVBQyKIF4 
WEB LINKS 
Component List for RI 
Compensation Controller 
Resistors: 
R1, R6, R7 = 10 kΩ 
R2 = 47 kΩ 
R3 = 1 MΩ 
R5 = see text 
  
Capacitors: 
C1 = 1 nF 
C2…C4 = 100 nF 
C5 = 100 µF/35 V 
C6 = 10 µ/16 V 
  
Semiconductors: 
D1 = 1N4004 
Q1 = BS170 
Q2 = IRF4905 
IC1 = ATtiny45 
IC2 = 78L05 
  
Miscellaneous: 
SV1 = 2 × 3-pin header 
X1,X2 = 2-pin PCB terminal, 5 mm pitch 
X3 = 3-pin PCB terminal, 5 mm pitch 
Component List for EMF 
Controller 
Resistors: 
R1, R4, R6, R7 = 10 kΩ 
R2 = 47 kΩ 
R3 = 1 MΩ 
R5 = see text 
  
Capacitors: 
C1 = 1 nF 
C2…C4 = 100 nF 
C5 = 100 µF/35 V 
C6 = 10 µF/16 V 
  
Semiconductors: 
D1 = 1N4004 
Q1 = BS170 
Q2 = IRF4905 
IC1 = ATtiny45 
IC2 = 78L05 
  
Miscellaneous: 
SV1 = 2 × 3-pin header 
X1, X2 = 2-pin PCB terminal, 5 mm pitch 
X3 = 3-pin PCB terminal, 5 mm pitch 
8 Bonus Edition January & February 2025 www.elektormagazine.com 
January & February 2025 9 
LUCKY YOU! 
Not a subscriber yet? Sign up for our free e-zine 
newsletter at elektormagazine.com/ezine-24 
LUCKY YOU! 
An e-zine subscriber never misses 
the monthly ‘reverse project’ 
GET FREE 
DOWNLOADDEVELOPER ZONE 
The MCU obviously requires a separate power supply that 
is independent of the EN input; due to the low-energy 
requirement, a linear regulator is the most economical 
solution here. In general, the concept is completely 
component-agnostic; the author likes to use modern 
PIC16F derivatives from Microchip. 
Figure 2 shows the sub-circuit that informs the PIC when 
the SBC (OPI = Orange Pi) is supplied by the external 
switching regulator (EXT). D1a, R9 and D7a implement 
a more or less “classic” attenuator, which breaks down 
input voltages in the range of up to 20 V to a value that 
is “manageable” for the inputs of process computer and 
microcontroller. 
Splitting the series resistor into the values R7 and R9 is 
necessary because single board computers sometimes 
become a low-impedance load or have a residual voltage 
when they are switched o" — without the resistor, this 
Single-board computers with Unix capability facilitate the 
development of complex control systems. Especially in 
scenarios with high demands on GUI and data process
ing, they are superior to microcontrollers (MCUs). Unfortu
nately, power consumption and real-time capability leave 
some room for improvement. But why not combine the 
best of both worlds? If you want to trim an o" -the-shelf 
single-board computer to be economical, you can achieve 
this with an eight-bitter as a partner. As an example, we 
want to implement a system that adheres to programmed 
downtimes and carries out an “alarm start” in response 
to a specific external event. 
The Circuit Concept 
In principle, the circuit works as shown in the flowchart 
(Figure 1). The voltage regulator acting as the main supply 
for the process computer (usually a switching regulator) is 
controlled by the microcontroller via its Enable input (EN). 
By Tam Hanna (Hungary) 
Raspberry Pis and other SBCs are ideal for 
sophisticated process control, but require 
signi! cantly more power than microcontrollers. Why 
not combine the best of both worlds? Here we show 
you how to get an 8-bit PIC to switch on a Raspberry Pi 
whenever it is needed. 
8-Bit Companion 
for the Raspberry Pi 
Power Saving Made Easy 
 Figure 1: This circuit design significantly reduces energy 
consumption in stand-by mode. 
 
Figure 2: 
The R7 resistor can 
save both costs and 
headaches. 
240210-002 
PIC 
GND 
OPI 
EXT 
D7a 
BZX84C2V7-TP 
C13 
100n 
D1a 
BAS21 
R9 
4k7 
R7 
1k 
R8 
10 Bonus Edition January & February 2025 www.elektormagazine.com 
100kwould cause the power management microcontroller 
(connected via the PIC terminal) to see strange or invalid 
values. 
R7 is an additional protective element — the inputs of the 
process computer are connected to the supply voltage 
and ground via protective diodes. When very high voltage 
levels occur, R7 ensures that the current flowing into 
these diodes is limited and the process computer is 
not damaged — C13 and R8 provide a small additional 
debouncing function. 
It should be noted that the circuit shown here with its EXT 
input was connected “directly” to the vehicle electrical 
system in various school buses. As there are now several 
thousands of such systems on the market without failures, 
it has been proven to work. 
The role of diode D1a as reverse polarity protection is also 
helpful — please believe the author, who also works in 
the logistics sector, that connecting batteries the wrong 
way round is one of the classic “sports” of a mechanic. 
The Software Is the Key 
Communication via I2C is generally unproblematic (but 
don’t forget the necessary pull-ups). The “secret” of this 
system lies in the software. The PIC implements a kind 
of state machine that is based on the states shown in 
Figure 3. 
The implementation of the shutdown process is of partic
ular importance. Unixoid operating systems tend not to 
react very kindly to rough shutdowns. A convenient and 
practical way to solve the problem is to implement a 
countdown timer: The SBC activates this countdown 
and then starts the shutdown of the operating system. 
After the (generously dimensioned) period of time has 
elapsed, the process computer is “inertialized” and can 
be disconnected from the power supply. 
Of course, the PIC can also perform other tasks. In 
addition to storing serial numbers and other informa
tion (in order to make it harder to manipulate), it is also 
possible, for example, to perform basic control tasks on 
the PIC. Of course, more complex implementations are 
also possible: A complex MSR task, for example, would 
make a 32-bit MCU appear reasonable as the second
ary controller. 
Practical Experience 
Trackers based on the circuit concept shown here are 
now being used in tens of thousands by one of the 
author’s customers, demonstrating the practical value 
of the design. Instead of a stand-by power consumption 
of around 200 mA, the system now gets by with just 
a few milliamperes. The author’s AN4121, published by 
Microchip, is available at [1] and provides further infor
mation on the topic. 
Translated by Jörg Starkmuth — 240210-01 
Questions or Comments? 
Do you have questions or comments about this article? 
Email the author at tamhan@tamoggemon.com or 
contact Elektor at editor@elektor.com. 
 
Figure 3: Also helpful in 
the embedded sector: 
the state machine. 
[1] Usha Ganesh and Tam Hanna, “Using PIC16F Microcontrollers for System Power Supply Control,” Microchip Application Note 
AN4121, 2021: https://www.microchip.com/en-us/application-notes/an4121 
WEB LINK 
About the Author 
Ing. Tam Hanna has been working with electronics, computers, and software 
for more than 20 years; he is a freelance developer, book author, and journalist 
(www.instagram.com/tam.hanna). In his spare time, Tam’s interests include 3D 
printing and the distribution of cigars. 
January & February 2025 11DEVELOPER’S ZONE 
installation on the roof or engage in energy 
sharing with the owner of an installation at 
another location. For a communal instal
lation, you need a two-thirds majority of 
the co-owners, good luck with that, I would 
say; as a tenant, you should try to convince 
your landlord eventually. And regarding 
energy sharing, that is hardly appealing 
because it is complex, cumbersome and 
above all expensive. It is possible to have a 
small PV installation in Belgium, but you 
have to follow the same procedures as for 
traditional larger installations. With a "xed 
connection to a separate group in the distri
bution cabinet, the necessary inspections 
and bureaucracy, the costs rise considerably, 
and your pro" ts melt like snow in the sun. 
However, there is light at the end of the 
tunnel and from May 2025, plug-in solar 
panels would — "nally — be allowed in 
Belgium after all. The question, of course, 
is how strict the conditions and modalities 
will be. With a bit of bad luck, you will have 
to be able to present an inspection report 
of your electrical installation, and you run 
the risk of having a “smart” meter shoved 
down your throat. 
Belgians are rather risk-avoiding, and this 
is also re# ected at the policy and regula
tory level. In my opinion, it would be better 
to ban extension cords with a power strip, 
electric bikes, electric scooters and hover
boards. These have been in the news several 
times in the context of house "res and with 
the last two devices, you can have serious 
accidents too. I was reminded of this 
after last summer’s commotion around 
a well-known Belgian DIY store that had 
o$ ered plug-in solar panels with the best 
of intentions but had to remove them from 
its shelves again, to its shame. 
Speed Camera 
While in neighbouring countries “plug-in 
solar panels” have been used trouble-free 
for years (Figure 1), a Belgian user organi
zation and sector federation for renewable 
energy ODE — apart from the fact that it 
is forbidden — seem to be particularly 
disliking of balcony PV installations [3]. 
According to them, these are potentially 
unsafe, which may have a short lifes
pan, and hardly financially interesting. 
They have a clear preference for larger PV 
installations, including for #at dwellers. 
The latter should just install a communal 
By Ilse Joostens (Belgium) 
I have read with interest the Elektor articles from 2021 and 
2024 on balcony PV installations by Dr. Thomas Scherer [1] 
[2], and I am entirely convinced by the idea of covering your 
home’s “quiescent power consumption” with solar energy. In 
Germany, you even get a subsidy for this; but unfortunately, 
I live in Belgium where this kind of installation is strictly 
forbidden by Synergrid technical regulation C10/11 due to — 
alleged — "re and electrocution danger. 
From Life’s 
Experience 
Micromanagement 
Source: Adobe Stock / EtiAmmos. 
developer’s zone 
12 Bonus Edition January & February 2025 www.elektormagazine.com 
Tips & Tricks, Best Practices and 
Other Useful InformationDEVELOPER’S ZONE 
heating systems and which car we drive. 
Similarly, the sale of numerous “hazard
ous” substances to individuals has been 
restricted. Even lead-based solder is becom
ing harder and harder to "nd, and there 
are already suppliers in Europe that no 
longer sell this stu$ to individuals because 
it contains lead. Just imagine working on 
older electronic equipment for the hobby. 
This kind of micromanagement also curtails 
entrepreneurship because many companies 
start small, perhaps as a few students who 
have discovered a gap in the market and are 
working on a product in a garage (Figure 2). 
Even giants like Microsoft, Google [6], HP 
and Amazon once started this way [7]. 
The website “Nanny State Index” [8] charts 
the patronization by various governments 
when it comes to eating, drinking, smoking, 
and vaping and, as far as I am concerned, 
may be expanded to include more criteria. 
I dare to plead for less interference, fewer 
and clearer regulations and, above all, more 
juridical certainty. Nobody can be against 
that. 
Translated by Hans Adams — 240608-01 
Politicians usually have a legal background 
and within that education one appar
ently sees no point in ill-considered ad 
hoc legislation. They just act according to 
the delusion of the day or based on #ash 
politics, resulting in unclear “# ip-# op legis
lation.” Premiums for electric cars have 
already been introduced and abolished 
twice, and because of twists and turns in 
the law, users of electric company cars who 
charge them at home will soon be allowed 
to pay a lot more taxes. Belgium does not 
have a monopoly on absurdities, and in 
the Netherlands I hear rumours about grid 
operators secretly increasing the voltage 
taps on district transformers to limit feed-in 
from solar panels. In Zeeland, an experi
ment has even started where homeowners 
are asked to switch o$ their solar panels 
on sunny days for a fee. It shouldn’t get 
any crazier after years of pushing people 
to install solar panels anyway. 
Patronizing 
The government is increasingly interfer
ing in all aspects of our lives, and unfortu
nately this goes beyond energy, our home, 
That smart meter hasn’t been out of the 
news recently, "rst because of the virtual 
rollback or not for solar panel owners and 
later in the context of the introduction of the 
capacity tari$ . With that tari$ , your smart 
meter becomes more like a speed camera 
that mercilessly charges you every time you 
have a few too many devices powered on at 
once in a moment of inattention. 
And the regulation on the roll-back counter, 
from which owners with solar panels could 
bene" t for another 15 years, was rejected by 
the Constitutional Court in 2021 because 
the Flemish government had gone beyond 
its authority. After "erce protests, the same 
government was obliged to compensate the 
duped owners of solar panels. 
Flipflop 
You will no doubt be familiar with 
mathematician and computer scientist 
Edsger Dijkstra [4] who took issue with the 
excessive use of goto instructions in higher 
programming languages [5]. During my 
training, the ban on goto instructions was 
enforced to avoid an untidy “spaghetti code.” 
[1] Dr. Thomas Scherer, “Balcony Power Plant,” Elektor 9-10/2021: https://www.elektormagazine.com/magazine/elektor-183/59831 
[2] Dr. Thomas Scherer, “Optimizing Balcony Power Plants,” Elektor 1-2/2024: 
https://www.elektormagazine.com/magazine/elektor-324/62631 
[3] VRT nws: Are solar panels on your balcony a good idea?: 
https://www.vrt.be/vrtnws/en/2022/10/18/are-solar-panels-on-your-balcony-a-good-idea/ 
[4] Wikipedia: Edsger Dijkstra: https://en.wikipedia.org/wiki/Edsger_W._Dijkstra 
[5] Mathematics & Computer Science Centre: Edsger Dijkstra: Go To Statement Considered Harmful: 
https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf 
[6] Inside Google’s original garage, 1998-style: https://blog.google/products/maps/inside-googles-original-garage-1998-style/ 
[7] Business Pundit: 11 famous garage startups that now rule the world: 
https://www.businesspundit.com/11-famous-garage-startups-that-rule-the-world/ 
[8] The Nanny State Index: https://nannystateindex.org/ 
WEB LINKS 
Figure 2: Even large companies once started small. Source: Adobe Stock / 
Gorodenko" . 
Figure 1: Balcony PV power plant — banned in one country, subsidized in 
another. Source: Adobe Stock / Ronald Rampsch. 
January & February 2025 13PECULIAR 
THE SERIES 
Rectifiers — those are like diodes, right? Well, yes. But these are not 
the kind of diodes you’d use in your crystal radio. Or even for your 
Raspberry Pi power supply. Or even for that super-duper 200 W per 
channel amplifier you’ve been building. Think electric trains, subway 
systems, broadcast transmitters. BIG stu" . As Crocodile Dundee might 
say, ”That’s not a rectifier, THIS is a rectifier!” 
Liquid Mercury 
Mercury-Arc rectifiers make use of the fact that if a pool of liquid 
mercury with some mercury vapor is used as a cathode, an arc can 
be drawn from a carbon anode above it, but the process does not 
work the other way around. 
Hence, rectification. This is su" iciently electronic to justify their inclu
sion in this column, even though they’re not the kind of component 
that’s ever been used in an Elektor project. 
Mercury-arc rectifiers were invented in 1902 by Peter Cooper Hewitt, 
an American electrical engineer who had invented mercury vapor 
lamps (the forerunners of our fluorescent lamps) in 1901. They were 
developed in the early 1900s and rapidly became the go-to solution 
for high-voltage, high current rectification. The arc voltage is around 
20…30 V, and the simplicity of their construction makes them e" icient 
and reliable. They were used up to the 1970s, when semiconductor 
rectifiers and thyristors that were up to the same job became available. 
Some were used until 2012. A typical 6-phase rectifier operating is 
shown in Figure 1. 
Mercury Recti! ers 
By David Ashton (Australia) 
Before the advent of high-power 
semiconductor-based recti! ers, 
transforming alternating current to 
DC in industrial and transportation 
! elds was no mean task! The devices 
were huge, fragile, contained highly 
polluting materials, and required 
frequent maintenance. 
Figure 1: A 6-phase, high-power mercury-arc rectifying tube at work. 
(Source: Wikimedia Commons, https://commons.wikimedia.org/wiki/ 
File:Quecksilberdampfgleichrichter_in_Betrieb.JPG) 
Ignitor Electrode 
Ignition has to be started by an ignitor electrode, which usually has to 
briefly come into contact with the mercury. This is done by a number 
of means, including electromagnets, bimetallic strips, etc. Once the 
arc has been struck to cause mercury vapor to form, rectification can 
take place. 
Most mercury-arc rectifiers were 3 or 6-phase, but single-phase recti
fiers needed an excitation electrode to keep the process going. The 
whole assembly is built within a large glass bulb, which allows the 
14 Bonus Edition January & February 2025 www.elektormagazine.comFigure 2: Functional schematic of a mercury-arc rectifying tube (Source: 
Wikimedia commons, https://commons.wikimedia.org/w/index. 
php?curid=4577899) 
mercury vapor to condense and flow back to the cathode pool. The 
construction of a typical rectifier is shown in Figure 2. 
A typical 6-phase, 150 A rectifier was around 600 mm tall and about 
300 mm round. Above 500 A steel tanks were used with ceramic insula
tors for the electrodes, and these were rated up to several thousand 
amps. Ratings up to several kV were available, higher with special 
construction techniques, but these required frequent maintenance. 
The mercury arcs emit a lot of ultraviolet light, you could get sunburned 
while working around them. Additionally, the noise from them and the 
associated transformers was considerable. Mercury is highly toxic and 
extensive clean-up work is often needed to remove traces of mercury 
when decommissioning them. 
240624-01 
Questions or Comments? 
If you have technical questions or comments about this article, 
feel free to contact the Elektor editorial team by email at 
editor@elektor.com. 
About the Author 
David Ashton was born in London, grew up in Rhodesia (now 
Zimbabwe), lived and worked in Zimbabwe, and now lives in 
Australia. He has been interested in electronics since he was 
“knee-high to a grasshopper.” Rhodesia was not the center of the 
electronics universe, so adapting, substituting, and scrounging 
components were skills he acquired early (and still prides himself 
on). He has run an electronics lab, but has worked mainly in 
telecommunications. 
They trust us, do you? 
We love electronics and projects, and we do our utmost 
to fulfill the needs of our customers. 
The Elektor Store: ‘Never Expensive, Always Surprising!’ 
Check out more reviews on 
our Trustpilot page: www.elektor.com/TP/en 
Or make up your own mind by 
visiting our Elektor Store, www.elektor.com 
January & February 2025 15 
elektor.comPower and Energy 
Elektor infographic 
Smart Grids: Enabling 
the Energy Transition 
Solar Energy: 
Innovations Shaping 
the Future 
The global solar energy market is on a positive growth trajectory 
as the solar energy industry is in a constant state of evolution. By 
2030, installed renewable electricity generation capacity under 
the IRENA 1.5°C Scenario (see textbox on next page) is expected 
to more than double, with solar PV contributing 49% of the total 
capacity compared to 40% in 2023 [1]. This translates to an 
increase from 4,085 GW in 2023 to 11,173 GW by 2030, driven by 
annual additions averaging 558 GW per year. 
Challenges and Opportunities 
Achieving the 2030 targets will require robust innovation and 
investment. The solar sector’s ability to sustain its current 
momentum hinges on continued advancements in technologies 
like bifacial panels, floating solar farms, and AI-optimized 
energy systems. These innovations will enhance e! iciency and 
integration, ensuring solar’s key role in a clean energy future. 
> Perovskite Solar Cells: These a! ordable and e! icient 
alternatives to silicon cells are transforming solar 
accessibility. Lab e! iciencies of up to 25% suggest 
they could become a cornerstone of future solar 
technologies. 
> Transparent Solar Panels: Integrating photovoltaics 
into windows o! ers a revolutionary way to harvest 
energy without compromising aesthetics. Early-stage 
transparent panels are achieving e! iciencies around 
10%. 
> Floating Solar Farms: By utilizing water surfaces, 
floating solar farms optimize land use while benefiting 
from natural cooling, which enhances panel e! iciency. 
> AI-Optimized Energy Systems: AI is transforming solar 
operations, helping precise energy prediction, smarter 
grid integration, and real-time optimization. 
> Solar Skins: Customizable appearances for solar panels 
allow ideal integration into residential and commercial 
designs, addressing aesthetic concerns [5]. 
Global Solar Market: A Bright Outlook to 2030 
Source: SolarPower Europe (2024), IRENA (2024) 
Source: Bartz/Stockmar (M), CC BY 4.0 
Global Installed Renewable Electricity 
Generation Capacity in the 1.5°C Scenario, 
2023 and 2030 [1]. 
•
Solar PV 
•
Hydro 
• 
Wind 
•
Other RE 
2023 
4,085 GW 
2030 
11,173 GW 
40% 
25% 
4% 
6% 
31% 
13% 
49% 
32% 
Yesterday 
few large power plants 
production 
market 
transmission 
distribution 
consumer 
centralized, mostly national 
based on large power lines 
and pipelines 
top to bottom 
passive, only paying 
Tomorrow 
many small power producers 
decentralized, ignoring 
boundaries 
including small-scale transmission 
and regional supply compensation 
both directions 
active, participating in 
the system 
16 Bonus Edition January & February 2025 www.elektormagazine.com[1] SolarPower Europe, “Global Market Outlook,” June 2024: https://tinyurl.com/solar-outlook-2024 
[2] IRENA, “World Energy Transitions Outlook 2024: 1.5°C Pathway,” November 2024: 
https://www.irena.org/Publications/2024/Nov/World-Energy-Transitions-Outlook-2024 
[3] IRENA, Hydrogen: https://www.irena.org/Energy-Transition/Technology/Hydrogen 
[4] Zurich, “How blue and green hydrogen can help solve the climate crisis,” July 2024: 
https://www.zurich.com/media/magazine/2022/is-hydrogen-the-fuel-that-can-save-our-planet 
[5] Tamesol, “The Future of Solar Energy,” January 2024: https://tamesol.com/future-of-solar-energy/ 
WEB LINKS 
240640-01 
Green hydrogen production, conversion, and end uses. [3] 
Another critical enabler has emerged for 
sectors that are challenging to electrify, 
such as heavy industry and long-haul 
transport, and that one is hydrogen. 
According to IRENA, hydrogen could 
fulfill 12% of global energy demand under 
the 1.5°C Scenario [3], with applications 
spanning transport, power generation, and 
heating. 
However, its production methods vary 
widely in environmental impact, earning 
the labels grey, blue, and green depending 
on the CO2 emissions involved. Currently, 
96% of global hydrogen production 
relies on fossil fuels (grey hydrogen), 
underscoring the need for a rapid 
transition to cleaner methods [4]. The high 
costs of production for green hydrogen, 
and substantial energy losses during 
production, storage, and conversion 
make it less e! icient than alternatives like 
batteries, while increasing blue hydrogen 
depends on costly carbon capture 
technologies. 
Hydrogen: Main Ingredient for Decarbonization 
12% 
of global energy demand 
could be fulfilled by hydrogen 
under the 1.5°C Scenario. 
96% 
of current share of hydrogen 
is produced from fossil fuels 
(grey hydrogen). 
What Is IRENA’s 1.5°C Scenario? 
IRENA stands for the International Renewable Energy Agency, an intergovernmental organization that promotes the adoption 
and sustainable use of renewable energy worldwide. The IRENA 1.5°C Scenario in the World Energy Transitions Outlook 
presents a pathway to achieve the 1.5°C climate target by 2050 [2]. Achieving this target requires substantial investments 
in clean energy technologies, such as solar, wind, and storage, to decarbonize global energy systems. 
PRODUCTION 
TRANSFORMATION 
TRANSPORT 
END USE 
Renewable energy 
Electrolysis 
Shipping 
Trucks 
Pipeline 
Storage 
Sustainable 
CO2 capture 
Synthetic 
Fuels* 
TRANSFORMATION 
NO TRANSFORMATION 
Green 
ammonia 
+ 
H2 
H2 
H2 
INDUSTRY 
H2 
HEATING 
H2 
POWER 
GENERATION 
H2 
CO2 
+ 
H2 
N2 
NH2 
TRANSPORT 
H2 
NH2 
Chemical industry 
Shipping 
Refineries 
Trucks 
Aviation 
Cars 
Rail 
Buses 
Steel industry 
January & February 2025 17This design addresses the need to monitor service interruptions, 
whether caused by technical issues — such as infrastructure mainte
nance — or by malicious intruders tampering with the external meter 
switch to disconnect the power supply. Such an action could deplete 
the alarm system’s backup batteries, leaving the home vulnerable. 
Triggering an alarm as soon as a disconnection is detected enhances 
overall home security. 
To prevent unnecessary activations, a delay (or tolerance) time of a 
few seconds has been implemented. This helps avoid false alarms 
caused by brief interruptions. In addition to the basic version (see 
Table 1), the digital version o" ers enhanced features: it tracks mains 
voltage drop events, allows adjustment of alarm and delay times, and 
automatically deactivates the signal once the preset alarm duration has 
elapsed. Furthermore, by configuring two DIP switches on the PCB, 
you can enable a beep function and a power-restoration notification. 
These additional features will be discussed in detail later. 
Di! erences Between the Analog and Digital 
Versions 
Analog Version 
As can be seen from the diagram in Figure 1, the power supply section 
has no transformer, which we will find in the digital version instead. 
Therefore, greater care must be taken during testing, since the 
whole circuit is connected to the mains voltage, with danger of 
electrocution in case of contact! In the case of the digital version, 
this danger is limited to the small part of the circuit connected to the 
primary of the transformer, which nevertheless requires a high level 
of attention during the testing phases! 
After the AC rectification and 24 V DC limiting section, consisting of 
diodes D1…D4 diodes and Zener diode D5, we note the split of that 
voltage source into two leads. One heads to the D6-C2 series, the other 
goes to the base of Q1. The D6-C2 series network produces a stabilized 
PROJECT 
By Stefano Purchiaroni (Italy) 
In areas where mains power is unstable 
and/or there may be safety issues, it 
may be useful to have a circuit that 
constantly monitors its presence and 
signals the outages in a timely manner 
to an external system. In this article, 
two design solutions are presented: 
one basic analog and a digital, 
microcontroller-based version, to 
monitor the presence of the power grid 
voltage at home and also perform the 
outages count. 
Mains Power 
Outages 
Monitor 
Is Your Grid Supply Steadily Available? 
Table 1: Available Functions in analog and digital Version. 
Function 
Analog 
Digital 
Delay (tolerance time) against short 
interruptions 
× 
× 
Delay time adjustment 
- 
× 
Alarm stop after a preset time 
- 
× 
Alarm time adjustment 
- 
× 
Counting and display of outages number 
- 
× 
Selectable pulse or permanent activation 
× 
× 
Signaling of mains power return 
- 
× 
18 Bonus Edition January & February 2025 www.elektormagazine.comwill have to be implemented downstream of the circuit, or it must be 
part of the siren or other controlled device of choice. 
In addition to permanent signaling, the Pulse Mode of about 2 s can 
be selected through the other position of switch SW1 (closed contacts 
5-2 and 4-3). In the absence of mains voltage, C3 gradually discharges, 
reducing the voltage across the base of Q1 until it is brought into 
conduction. Q1 thus lets current flow from C2 to the relay, passing 
through C4. The relay is energized, activating the alarm. 
After about half a second, C4 is fully charged, reducing the current 
flow on the relay coil until the relay is de-energized, approximately 2 s 
later. The values of the capacitors and resistors are already calculated 
to make sure that the charge of C2 can sustain the whole cycle. When 
the power returns, Q1 will go o" again, the relay will not change its 
state, and C2 will be charged once more and will be able to support 
new cycles. 
Note the important function of diode D6 in this mode, which acts as 
a “check valve” preventing the base of Q1 from remaining high due to 
the accumulated charge in C2, and the relay from staying o" . 
Digital Version 
The digital version’s greater complexity is immediately apparent from 
the schematic in Figure 2. The circuit is supplied through a trans
former with a 6 V output, which feeds two rectifier bridges, BR1 and 
BR2. The latter, followed by the stabilization section — consisting 
of C3, a small, 5 V linear voltage regulator U1 and C4 at the output 
— provides power for microcontroller U2, a versatile PIC16F1827 by 
Microchip. In the event of no mains voltage, 1.5 F supercapacitor C5 
will continue to provide enough power to the PIC for a considerable 
time. Management of the supercapacitor is achieved by blocking 
diodes D2, D3 and D4, which isolate it during ordinary operation but 
ensure its charge. 
23.3 V output, used to activate the relay via path 4-6 (steady mode) of 
the DPDT switch SW1. When the mains voltage fails, the relay returns 
to the o" position, thus closing the COM-NC contact. Please note: In 
the circuit diagram, the relay is drawn in its de-energized state, which 
means the alarm is on. This is valid only when SW1 is in Steady Mode, 
in the position represented on the schematic. In the other position of 
the switch (4-3/5-2/Pulse Mode) the relay gets energized just for 1 to 
2 seconds (which means then the alarm is on). 
When the mains voltage fails in Steady Mode, the alarm is activated 
with about a 3-to-4-second delay, due to the energy stored by the 
large electrolytic capacitor C2 being discharged. When power comes 
back on, the deactivation of the alarm will occur with about a 2 s delay, 
the time it takes C2 to charge and provide a high enough voltage to 
activate the relay again. 
Capacitor C5, initially discharged, allows the relay to be instanta
neously activated at full voltage, but once charged, the current to 
keep it activated is supplied through R5, and reduced slightly, yet 
remaining at a level more than enough to hold the relay contacts in 
the closed position. This technique greatly extends the life of the relay, 
which remains slightly underpowered most of the time. 
The relay should be a DPDT type, with a 24 V coil and an internal resis
tance of 1,600 Ω. Any mains disconnection that lasts less than the delay 
time mentioned earlier will not produce an alarm activation, since C2 
will not have discharged enough to drop the voltage supplied to the 
relay below its Vo" , measured experimentally at around 4 V. This delay 
avoids unnecessary alarms in case short interruptions might occur. 
In this analog version, the delay time is not adjustable. Another down 
side concerns the alarm time: Once C2 is discharged — and still no 
mains voltage is present at the input — the relay goes o" permanently, 
leaving the alarm active indefinitely. Management of a maximum time 
240559-003 
RL1 
24V 
Alarm 
Mains 
0W5 
1W 
4x 1N4007 
0W5 
0W5 
D3 
D2 
D1 
D4 
D5 
24V 
R1 
1M 
R2 
820Ω 
C1 470n 
D6 
1N4007 
C2 
2200µ 
35V 
C3 
100µ 
35V 
C4 
100µ 
35V 
C5 
100µ 
35V 
R3 
R4 
4k7 
R5 
680Ω 
Q1 
BC557 
D7 
5V1 
D8 
1N4148 
J2 
J1 
SW1 
6 
3 
4 
5 
1 
2 
Figure 1: Schematic of 
the mains power outage 
analog version. 
January & February 2025 19 
18kThe interrupts then wake the microcontroller for program execution 
every second, basically to count the seconds elapsed and decide if it 
is time to act on the relay — comparing the second counter with the 
reading of the two resistive trimmers RV1 and RV2. 
A further reduction in power consumption is made possible by connect
ing the hot side of the two trimmers not directly to the supply voltage, 
but to digital output pin RA2, which will be set to logic high level only 
during the reading of the two trimmers, taken via analog inputs AN3 
and AN4 (pin 2 and 3 of U1, RA3, and RA4, respectively). 
Mains voltage drop detection is done by the section starting at 
BR1, which has no high capacitance downstream, but is equipped 
with a circuit that generates 5.1 V when mains power is present. 
Note jumper JP1, provided for removing and reprogramming of the PIC 
without it being powered by the supercapacitor. To avoid excessive 
voltage drops, diodes D2 and D4 were chosen to be Schottky types, 
with a direct threshold voltage VDS as little as 0.2 V. This allows C5 to 
be charged up to 4.8 V, and to get 4.6 V for the backup power supply 
to the PIC, which has a minimum operating voltage of only 2.8 V for 
the chosen model. 
When the supercapacitor supplies the circuit, the reduction of the 
microcontroller’s power consumption is achieved by software-enabling 
the “Nanowatt” mode, introduced by Microchip on most of its micro
controllers. It sends the controller into a low-power state, where only 
the 32,768 Hz oscillator remains on, reactivating the code execution only 
at the interrupts coming from the timer associated with that oscillator. 
X1 = 26+] 
240559-007 
TOL 
ALM 
BKBP 
RESET 
OnOff 
Stat 
+V1 
+V2
6(16(
 
0W5 
Mains 
W04G 
Alarm 
+V1 
3V 
TP1 
+V2
6(16(
 
+V1 
RA5/MCLR 
RA0 
RA1 
RA2 
RA3 
RA4 
RA6 
RA7 
VSS 
VDD 
RB0 
RB1 
RB2 
RB3 
RB4 
RB5 
RB6 
RB7 
17 
18 
15 
16 
14 
10 
11 
12 
13 
1 
2 
3 
4 
5 
6 
7 
8 
9 
U1 
U1 = PIC16F1827 
C6 
100n 
RV1 
22k 
RV2 
22k 
DSW1 
SW1 
C7 
22p 
C8 
22p 
X1 
R5 
D5 
Yellow 
R7 
D7 
Red 
R9 
D9 
Green 
R6 
4k7 
Q1 
BC547 
R8 
4k7 
Q2 
BC547 
RL1 
D8 
1N4148 
J2 
BR2 
W04G 
BR1 
TR1 
J1 
R1 
R2 
1k 
R3 
R4 
22Ω 
C1 
47µ 
16V 
C2 
100n 
C3 
1000µ 
16V 
C4 
47µ 
16V 
C5 
15) 
5V5 
D1 
5V1 
U2 
78L05 
D4 
SB140 
D2 
SB140 
D3 
1N4007 
JP1 
D6 
1N4148 
Figure 2: Schematic of the microcontroller-based, digital design. 
20 Bonus Edition January & February 2025 www.elektormagazine.com
470Ω 
470Ω 
6V, 1VA5 
22k 
10k 
470Ωvoid SetAlm() { 
// Activate the alarm and count the event in EEPROM 
// Activate the alarm 
ALMOFF=0; 
ALMON=1; 
delay_ms(RlyTim); 
ALMON=0; 
curs = 0; // Reset the second counter 
} 
The following interrupt() function constitutes the entry-point of 
the PIC’s interrupt service routine, ISR. It is invoked by the interrupt 
generated by Timer1 when the second expires, even in low-power 
mode. An output is provided on the circuit board on test point TP1 
to verify with a frequency meter or oscilloscope the operation of the 
oscillator. 
TP1’s level toggles every second, producing a 0.5 Hz signal. The ground 
for the measurement is available on the respective GND-labeled 
test point. The main purpose of the interrupt procedure is to count 
the elapsed seconds using the 32-bit variable, curs. The interrupt for 
the next cycle is enabled again downstream of the function: 
void interrupt() { 
// Interrupt Service Routine. 
// It is called every second by Timer1 overflow. 
// --------- TMR1 --------- 
// Manage Timer1 overflow (each 1s) 
// to count seconds 
if (PIR1.TMR1IF == 1) { 
CLKOUT ^= 1; // Provide 0.5 Hz to Pin 1 
// for checks 
curs++; // Update the current 
// second counter 
TMR1H = TMR1H_INI; // Reload counter high byte 
TMR1L = TMR1L_INI; // Reload counter low byte 
PIR1.TMR1IF = 0; // Clear TMR1 Interrupt flag 
} 
} 
After hardware setup and initialization of variables, main() function 
handles events according to the logic of a finite-state automaton. 
The current state of the automaton is set in the Mode variable. First, 
pressing on the SW1 button is verified, to reset the event counter and 
for restarting the microcontroller via the reset assembler instruction. 
At the first power-up with a blank microcontroller, and only then, it 
will be necessary to press the SW1 button to set the alarm count in 
EEPROM to zero. At the execution of setup(), following the button 
press, it will also be forced to turn o" the alarm control relay, in case 
(for any reason) it had remained active. 
In the event of an outage, the SENSE-tagged output voltage drops 
quickly, communicating the event to digital input pin RB1 (AN11), which 
interprets a voltage less than 0.8 V as a binary “0”; with the component 
values in this section, this threshold is reached about half a second 
after the mains voltage drop. By mounting optional resistor R3, this 
delay can be further reduced. 
Based on the high or low level of pin RB1, the management software 
activates the alarm, according to the settings of the two potentiome
ters RV1 and RV2, which allow you to adjust the delay time between 
0…10 s, and the alarm time from 0…2 min. 
As mentioned earlier, second-counting is handled by the PIC’s internal 
low-power oscillator, fitted with the small external 32,768 Hz watch 
crystal, X1. Again, to minimize power consumption, the relay chosen 
is a bistable, 3 V, double-coil DPDT type. The two sets of contacts are 
connected in parallel to increase the current carrying capacity, which, 
however, may not exceed 5 A. 
The two turn-on and turn-o" coils are driven by Q1 and Q2 transistors, 
whose bases head to the PIC’s RA6 and RA7 pins. The microcontroller 
will thus be able to turn the relay on and o" with short positive pulses 
on those pins. This chip is also connected to a dual DIP switch, which 
enables the two optional functions, Beep and Back. 
The former limits the alarm on to about one second, to provide a 
brief but intense warning to those in the house, for example, alert
ing them to the voltage drop without disturbing the neighborhood. 
The Back function provides two short pulses to indicate the return 
of mains voltage. However, this function is limited by the maximum 
energy delivery time provided by supercapacitor C5, which is about 
a couple of hours. 
Finally, we note button SW1 and LED D5. The latter has the task of 
using short flashes to indicate the drop events that have occurred. 
If, for example, a power failure has occurred twice, D5 will cycle two 
flashes, followed by a pause of about 3 s. 
To reset the count, simply press the Reset button SW1. This switch 
also performs a full restart of the PIC, and a forced disable of the 
relay, which is useful in case of problems. The two LEDs, D7 and D9, 
indicate the output of the short command to enable and disable the 
relay, which, if not followed by the clicking sound of the relay, help to 
identify a failure of this electromechanical component. 
Software 
Let us focus on the main functions, SetAlm(), interrupt(), and 
main(). The SetAlm function shown below provides for the activa
tion of the alarm device connected to J2 output terminals by direct 
pulses to the bistable relay. The persistence time of the pulse to the 
relay control coils is defined by the constant RlyTim, currently set to 
200 ms. The coils head to pins RA6 and RA7 of the microcontroller, 
which energizes them through Q1 and Q2 transistors. 
January & February 2025 21 
// the MCU is powered just by supercap! 
curs = 0; // Start seconds count 
STSLED = 0; // Force Ststus Led off 
Mode = Mode_TOL; 
// Enter the Tolerance Mode 
} 
break; 
In the Mode_TOL state handled by the following section, one of two 
possible events is awaited: the return of mains voltage before the delay 
time expires, to return again to the Mode_SBY state, or the overrun of 
that time. 
The condition to be met for the latter case is slightly complicated by 
the management of the optional Beep mode activated via the first of 
the two DIP switches. Depending on the state of this switch, either 
the ttol limit time defined first by the RV1 trimmer reading, or the 
MinTol time set by the initial code definitions, corresponding to 2 s, 
will be selected. Exceeding the limit time brings the automaton into 
the Mode_ALM state. 
The continuation of the code is always bound to the Timer1 interrupt, 
since it continues to operate in low-power mode: 
case Mode_TOL: // Waiting ttol time 
// before activating the alarm 
if (POWER == 1) { // Mains is back 
// before the alarm activation 
Mode = Mode_SBY; // Just go 
// back to Standby Mode 
} else { // Check end 
// of Tolerance time 
if ( ((BeepMode==FALSE)&&(curs>=ttol)) 
||((BeepMode==TRUE)&&(curs>=MinTol)) ) { 
SetAlm(); // Start the 
// alarm, 
IncAlm(); // Increment 
// the alarms counter, 
Mode = Mode_ALM; // Enter in 
// the Alarm Mode 
} 
} 
break; 
This part handles the Mode_ALM state. It waits for the mains voltage 
to return, to reset the alarm and return to Standby by permanently 
exiting the low-power mode. Or one waits for the exhalation of the 
maximum alarm time, chosen from the talm value set by the analog 
reading of the RV2 trimmer, or from the MinAlm value preset to 1 s at 
the beginning of the program. It remains in low power in that case, to 
handle the return of the line voltage to the Mode_BACK state: 
case Mode_ALM: // Wait talm seconds before 
Alarm activation events are counted in the AlmCnt variable. Note that 
— in case the return of mains voltage is very late and the capacity 
to support operations provided by supercapacitor C5 is exceeded — 
in order not to lose the alarm count, the value of AlmCnt is saved in 
EEPROM. The setup() function requires it to be read again when the 
microcontroller is restarted: 
void main() { 
setup(); // Initialization 
while(1) { // Forever Loop 
if (Button(&PORTB,4,1,0)){ 
// Reset button pressed 
STSLED = 1; 
Delay_ms(500); 
STSLED = 0; 
AlmCnt = 0; 
EEPROM_Write(CNTADDR, AlmCnt); 
// Raz the Alarms counter in EEPROM 
curms = 0; 
// Raz the elapsed ms for Blink cycle 
BlkSts = 0; // Reset the Blink automaton 
{asm{reset}}; // Reset the MCU 
// (the program will restart) 
} 
In the following excerpt, the voltages on the analog pins connected to 
the slider of the two resistive trimmers are read; they are dedicated to 
adjusting the delay and alarm times. The reading is made possible by 
activating the hot side of the two trimmers via the digital output pin 
RA2, referred to here as DIVPOW. 
Since the microcontroller has a 10-bit A/D converter, the two readings 
will consist of a value between 0 and 1,023, between limits defined by 
configurable parameters that by default limit the delay time to between 
0…10 seconds, and the alarm time to between 0…2 minutes. 
In default state Mode_SBY, managed by the block that follows, the 
automaton waits for the mains voltage drop event, communicated 
by the SENSE line through pin RB1 (AN11) referred to here using the 
POWER definition. If it goes to logic level 0, then second-counting will 
start, setting the PIC to low-power mode. Please keep in mind that 
from then on, power is provided solely by supercapacitor C5. 
The new state is Mode_TOL: 
// Automaton 
switch (Mode) { 
case Mode_SBY: // Nominal Mode. 
// Wait for a Power Down event 
if (POWER == 0) { // The Main power gone down, 
22 Bonus Edition January & February 2025 www.elektormagazine.com 
if ( ((BeepMode==FALSE)&&(curs>=talm)) 
||((BeepMode==TRUE)&&(curs>=MinAlm)) ) { 
ResetAlm();      // Suspend the alarm 
Mode = Mode_BACK; // Wait for the 
  
// Power Up event 
} 
} 
break; 
  
// to stop the alarm 
if (POWER == 1) { // Mains is back during Alarm 
ResetAlm(); // Stop the alarm 
if (BackMode==TRUE) Signal(); 
// Signal "Mains is back" if requested 
Mode = Mode_SBY; // Manage the Power Up event 
} else {    // Check end of Alarm time 
Listing 1: Main Blink Sequence and Mains Monitoring Routine. 
// On power presence, signal the occurred alarms (one blink per each alarm) 
if ((POWER == 1) && (AlmCnt > 0)) { 
switch (BlkSts) { 
case 0: // Initialize a new Blinks cycle 
n = AlmCnt; 
STSLED=1; 
curms = 0; // Start ms counting 
BlkSts = 1; // Go to "Wait to turn off the LED" 
break; 
case 1: // Wait CNTBLINK ms to turn off the LED 
if (curms >= CNTBLINK) { 
STSLED=0; 
n--; // Decrement residual Blinks counter 
curms = 0; // Start ms counting 
if (n > 0) BlkSts = 2; // Go to "Wait to turn on the LED" 
else BlkSts = 3; // Go to "Wait for next Blinks cycle" 
} 
break; 
case 2: // Wait CNTBLINK ms to turn on the LED 
if (curms >= CNTBLINK) { 
STSLED=1; 
curms = 0; // Start ms counting 
BlkSts = 1; // Go to "Wait to turn off the LED" 
} 
break; 
case 3: // Wait CNTINTERV for next Blinks cycle 
if (curms >= CNTINTERV) { 
curms = 0; // Start ms counting 
BlkSts = 0; // Initialize a new cycle 
} 
break; 
} 
if (BlkSts > 0) curms += TIC; // Increment the elapsed time counter (ms) 
} 
#ifdef LOWPOW 
// If no external power is present, go in Low Power Mode 
if (POWER == 0) {asm{sleep};} // Sleep. Awake on Timer1 interrupt. 
#endif 
Delay_ms(TIC); // Introduce a cycle delay 
January & February 2025 23The 1.5 F supercapacitor is a special component, but nevertheless 
readily available. In this version, the alarm output is provided via a 
three-way terminal, which allows the user to choose NC or NO activa
tion type, depending on the intended use. This is not possible in the 
analog version, due to circuit limitations. 
The digital version thus o" ers greater versatility and ease of use than 
the analog one, thanks to the ability to configure the alarm output 
according to one’s needs. However, the analog version retains a struc
tural simplicity that may be advantageous in some specific applica
tions. The choice between the two versions will therefore depend on 
the user’s needs and the features of the signaling system to which 
the device will be connected. 
240559-01 
Questions or Comments? 
Do you have technical questions or comments about this article? 
You may write to the author at info@purchiaroni.com or to Elektor’s 
editorial team at editor@elektor.com. 
About the Author 
Passionate about electronics and programming, Stefano Purchiaroni 
shares his works by publishing projects, and also o" ers free robotics 
lessons for teens at a popular school. He is currently employed in 
Telespazio and works in a satellite center near the Italian capital. 
Related Product 
> 
OWON XDM1141 Multimeter 
www.elektor.com/20671 
In Mode_BACK, it waits for the mains voltage to return and signals 
the event by triggering the alarm for two short consecutive pulses if 
provided by the Back DIP switch. Until the grid returns, the PIC is left 
in low-power mode: 
case Mode_BACK: // Waiting for the mains power 
// to come back again 
if (POWER == 1) { // Mains 
// is back: exit to Standby mode 
ResetAlm(); // Force 
// alarm off 
if (BackMode==TRUE) Signal(); 
// Signal "Mains is back" if requested 
Mode = Mode_SBY; 
} 
break; 
After the main automaton, a second four-state automaton was imple
mented just to manage D5 connected to RA0. 
This LED is intended to show the current count of voltage drop events 
of duration longer than the delay time. The AlmCnt counter is reset
table by pressing SW1, managed in the first lines of code of the main 
cycle, seen above. The handling of flashes by an automaton is dictated 
by the need to not interrupt the main cycle with simple delays, which 
would block any other actions during their execution. Flashing times 
are defined by the constants CNTBLINK set to 200 ms, and CNTINTERV, 
which defines the pause between two blocks of flashes, set to 3 s 
(Listing 1). 
Printed Circuit Boards 
For both the analog and digital versions, two single-sided, jumperless 
printed circuit boards have been designed. This will undoubtedly facil
itate their creation using the classic methods of photoengraving, or 
hot transfer. You can download the Gerber files needed for DIY from 
the Elektor Labs page for this article [1]. 
Assembly 
In the analog version shown in the assembly plan, the SW1 switch for 
mode selection is wired to a six-way connector on the printed circuit 
board. You can connect a lever switch to it, or any DPDT switch. The 
digital version of the device, which can be seen in the mounting plan, 
involves socket-mounting the microcontroller, two miniature-type 
trimmers, a two-way dip-switch, and a jumper. 
[1] Elektor Labs page for this article: https://elektormagazine.com/labs/mains-power-outages-monitor 
WEB LINK 
24 Bonus Edition January & February 2025 www.elektormagazine.comlektorstore 
www.elektor.com 
www.elektor.com/21074 
FNIRSI GC-02 Nuclear Radiation 
Detector (Geiger Counter) 
M5Stamp Fly Quadcopter 
(with M5StampS3) 
www.elektor.com/21014 
www.elektor.com/21046 
www.elektor.com/21008 
Price: €104.95 
Douk Audio P6 mini 
Tube Preamplifier 
Elevate your audio experience with the Douk 
Audio P6 mini Tube Preamplifier, a perfect blend 
of modern connectivity, HiFi sound quality, and 
vintage charm. Whether you’re an audiophile or 
just starting your journey into high-quality 
audio, this compact yet powerful preamp 
offers everything you need. 
Raspberry Pi 500 (US) 
The Raspberry Pi 500 (based on the Raspberry Pi 5) 
features a quad-core 64-bit Arm processor, RP1 I/O 
controller, 8 GB RAM, wireless networking, dual
display output, 4K video playback, and a 40-pin 
GPIO header. It’s a powerful, compact all-in-one 
computer built into a portable keyboard. 
Price: €74.95 
Special Price: €59.95 
Price: €49.95 
Member Price: €44.96 
Price: €79.95 
Member Price: €71.96 
January & February 2025 25www.elektormagazine.com/member 
Also available 
The Elektor web archive from 1974! 
8x Elektor Magazine (print) 
8x Elektor Magazine (digital) 
10% discount in our web shop and exclusive off ers 
Access to more than 5,000 Gerber fi les 
The Digital 
membership! 
Join the 
Elektor C mmunity 
Take out a 
membership! 
The Elektor web archive from 1974! 
8x Elektor Magazine (digital) 
10% discount in our web shop and 
exclusive off ers 
Access to more than 5,000 Gerber fi les 
10% discount in our web shop and exclusive off ers 
GOLD 
membership 
membership 
GREEN Power Electronics & Energy

Interested in power electronics and energy-related technologies? This page features news, articles, projects, and links from Elektor on topics such as SiC technology, power transistors, measuring devices, solar technology, inductive charging, inverters, electric cars, laboratory and switching power supplies, e-bikes, GAN semiconductors, batteries and charging technology, semiconductor production, and much more. In addition to the latest news from the industry, Elektor's engineers and editors highlight articles on key topics as well as specific circuits and suggestions. We offer links to select Elektor articles that will make it easy for you to browse through our enormous archive. Elektor has been collecting of electronics-related projects, tutorials, and insights for more than 60 years. Use this page to immerse yourself in the world of power electronics! 

ElektorMag Jan/Feb 2025: Power & Energy
In this project-packed edition of ElektorMag, we tackle the following topics and more: learn to build an energy storage solution for a PV solar array; reduce power dissipation with dropping capacitors; test and optimize MPP trackers and inverters; construct a notebook power bank; update the AmpVolt to measure up to 70 V and 100 A. In addition to power-related articles, we also cover subjects such as EMC compatibility, medical robots, and creating applications with the Elektor Audio DSP FX Processor Board. Check out the magazine!
  

Member Download
  

Free Download Bonus Edition
   

Bonus Content
Download the free Power & Energy bonus edition from Elektor! Inside, we cover a mains power outage monitor, speed control of a brushed DC motor, mercury rectifiers, and more. The edition will be available for download on or around January 17, 2025!
  

  
 Categories
 
Solar and Wind Energy
 
Batteries
 
Power Supplies and Inverters
 
Measurement
 
Components and Circuits
 
Latest News 
Solar and Wind Energy
Top


Wind Power: Wise Move or Waste of Time?
The UK Government recently announced the world’s biggest ever expansion in wind energy. So how realistic is this scheme? What are the pitfalls, technical and otherwise, and how viable is it economically? It’s time to look at wind generation in the round.Wind is simply air in motion, with mass and energy. It has been used for centuries, the most obvious example being windmills. In 1850 the American Daniel Halliday developed the ‘multi-bladed’ farm windmill, a relatively simple device that inspired the first attempts to convert wind into a form of energy that could be either stored for future use, or applied elsewhere.

Download article 



Balcony Power Plant: DIY Solar Balcony = Speedy Payback!
You don’t need to cover a whole roof with PV solar panels before the installation becomes both economically and ecologically viable. The idea of a grid-tie PV installation on your balcony is starting to gain traction with so many office workers now working from home, any energy input from sunlight can help offset the additional domestic power usage during daylight hours. These mini power plants are quite cheap and even benefit from subsidies in some European cities. I looked into the regulations governing them, did some research on the equipment and went ahead with the installation.

Download free article 



Solar Power Made Simple: Solar Charging With and Without a Controller
Complicated charge controllers and inverter circuits can be used to squeeze the last drop of energy out of a solar panel. Contrary to popular belief, however, it is also possible simply to connect the battery directly to the panel.

Download article 



Optimizing Balcony Power Plants: Considerations, Interesting Facts, and Calculations
The hype surrounding solar technology in general and balcony power plants in particular has continued unabated since the start of the war in Ukraine (and the resulting uncertainty regarding energy supply in central Europe). Since our last article in 2021, supply and sales in this sector have seen huge growth and prices are lower than ever. The background information in this article will make it easier to get started!

Download article 

Batteries
Top


The Road to Battery Power: The Dawn of the Age of Electric Vehicles
At the beginning of the twentieth century the internal combustion engine started to take over from electrically-powered vehicles. Now, a hundred years later, electric vehicles are slowly but surely making a come-back. Development continues apace and the enormous potential is clear. The key to the success of electric vehicles lies, contrary to early expectations, in lithium-ion cells rather than in fuel cells.

Download article
  



ABC of Rechargeable Batteries: Basics, Pitfalls & Recommendations
The remarkable progress in battery development owes much to the the boom demand for portable gadgets like mobile phones, laptops, camcorders, and MP3 players. To shed light on the batteries powering these devices, let's take a nostalgic stroll through the charging methods and battery technologies of yesteryears, including the trusty nickel-cadmium (NiCd), nickel-metal-hydride (NiMH), and lithium-ion (Li+) chemistries.

Download article 



Safety in Large Lithium Battery Installations
Every manufacturer of mobile phones, tablets and notebook computers looks to lithium-ion technology to provide a lightweight, long-lasting and reliable energy storage capability that can fit easily inside a small enclosure or housing. Crucially, after billions of hours of use worldwide, lithium-ion batteries in these applications have proved to be safe. How come?

Download article 



Solar Cell Battery Charger/Monitor
Solar battery chargers store the energy obtained from the sun in batteries. The author has developed a system that charges the battery according to the manufacturer's specifications and protects against deep discharge. The system displays all important operating parameters on an LC display. According to the manufacturer's specifications, the peak power of the solar module used here is 150 W at 14.5 V. In practice, the current after deducting all losses is a maximum of 7.5 A.

Download article 



Lithium Battery Pack Repair: Save Money + More Power!
It’s a familiar story. After a few years of use, the cordless screwdriver needs charging more often and the cordless vacuum cleaner doesn’t have the energy to collect your crumbs. The simplest and most costly solution is to order a replacement battery pack. But have you considered just replacing the cells in the battery pack? This approach saves money and reduces waste. This isn’t just a repair; it’s an upgrade!

Download article
  


























Skip to main content 
Learn 

            





46307064
tshingombefiston@gmail.com 
Badges 

929

Trophies 

214

Reputation points 

0

Accepted answers 
0
Following 

0

Followers 
0
Level 16 96% 1,463,000/1,481,099 XP 
Activity 
Training 
Plans 
Challenges 
Credentials 
Q&A 
Achievements 
Collections 
Transcript 
Achievements
Have an achievement code? 
1.


    Badge 

Introduction to Azure Load Balancer

Completed on  1/10/2025 
  


    Badge 

Enhance your service availability and data locality by using Azure Traffic Manager

Completed on  1/10/2025 
  


    Badge 

Improve your reliability with modern operations practices: An introduction

Completed on  1/10/2025 
  


    Badge 

Improve your reliability with modern operations practices: Deployment

Completed on  1/10/2025 
  


    Badge 

Utilize an Azure OpenAI model to create an app

Completed on  11/16/2024 
  


    Badge 

Explore the Copilot stack

Completed on  11/16/2024 
  


    Badge 

Build your custom agent for Teams

Completed on  11/16/2024 
  


    Badge 
Explore generative AI with Copilot in Bing
Completed on  11/16/2024 
  


    Badge 

Orchestrate containers on Windows Server using Kubernetes

Completed on  9/24/2024 
  


    Badge 

Run containers on Windows Server

Completed on  9/24/2024 
  


    Badge 

Apply Networking concepts to Windows containers running on Azure Kubernetes Service (AKS) and AKS Hybrid

Completed on  9/24/2024 
  


    Badge 

Apply storage concepts to Windows containers running on Azure Kubernetes Service (AKS) and AKS Hybrid

Completed on  9/24/2024 
  


    Badge 

Deploy a containerized application on Azure Kubernetes Service

Completed on  9/24/2024 
  


    Badge 

Manage Azure Kubernetes Service on Azure Stack HCI

Completed on  9/24/2024 
  


    Badge 

Introduction to Azure Kubernetes Service

Completed on  9/24/2024 
  


    Badge 

Introduction to Kubernetes

Completed on  9/24/2024 
  


    Badge 

Deploy and run a containerized web app with Azure App Service

Completed on  9/24/2024 
  


    Badge 

Run Docker containers with Azure Container Instances

Completed on  9/24/2024 
  


    Badge 

Build and store container images with Azure Container Registry

Completed on  9/24/2024 
  


    Badge 

Build a containerized web application with Docker

Completed on  9/24/2024 
  


    Badge 

Create a Holographic Remoting app to visualize 3D content on HoloLens 2

Completed on  9/24/2024 
  


    Badge 

Integrate Azure Cloud Services to your Unity project on HoloLens 2

Completed on  9/24/2024 
  


    Badge 

Activate spatial audio for your HoloLens 2 application

Completed on  9/24/2024 
  


    Badge 

Add Azure AI services to your mixed reality project

Completed on  9/24/2024 
  


    Badge 

Use Azure Spatial Anchors to anchor objects in the real world

Completed on  9/24/2024 
  


    Badge 

Enable eye tracking and voice commands for objects on the HoloLens 2

Completed on  9/24/2024 
  


    Badge 

Getting started with 3D object interaction

Completed on  9/24/2024 
  


    Badge 

Place a Mars Rover object in the scene and work with grids and intelligent object tracking

Completed on  9/24/2024 
  


    Badge 

Introduction to the Mixed Reality Toolkit-Set Up Your Project and Use Hand Interaction

Completed on  9/24/2024 
  


    Badge 

Challenge project - Building an Augmented Reality app for HoloLens 2

Completed on  9/24/2024 
  


    Badge 

Designing for mixed reality

Completed on  9/24/2024 
  


    Badge 

Introduction to mixed reality

Completed on  9/24/2024 
  


    Badge 

Configure 3D assets for mixed reality in Unity

Completed on  9/24/2024 
  


    Badge 

Build a 3D Scene for mixed reality in Unity

Completed on  9/24/2024 
  


    Badge 

Set up a mixed reality project for Azure Digital Twins in Unity

Completed on  9/24/2024 
  


    Badge 

Connect IoT data to mixed reality with Azure Digital Twins and Unity

Completed on  9/24/2024 
  


    Badge 

Introduction to Polyglot Notebooks

Completed on  9/24/2024 
  


    Badge 

Create a web UI with ASP.NET Core

Completed on  7/20/2024 
  


    Badge 

Learn the basics of web accessibility

Completed on  7/20/2024 
  


    Badge 

Get started with web development using Visual Studio Code

Completed on  7/20/2024 
  


    Badge 

Publish a web app to Azure with Visual Studio

Completed on  7/20/2024 
  


    Badge 

Create a web API with ASP.NET Core controllers

Completed on  7/20/2024 
  


    Badge 

Work with files and directories in a .NET app

Completed on  7/20/2024 
  


    Badge 

Interactively debug .NET apps with the Visual Studio Code debugger

Completed on  7/20/2024 
  


    Badge 

Create a new .NET project and work with dependencies

Completed on  7/20/2024 
  


    Badge 

Introduction to .NET

Completed on  7/20/2024 
  


    Badge 

Deploy and manage Active Directory Domain Services domain controllers

Completed on  7/20/2024 
  


    Badge 

Manage Microsoft Entra identities

Completed on  7/19/2024 
  


    Badge 

Understand Microsoft Entra ID

Completed on  7/19/2024 
  


    Badge 

Evaluate deployment methods

Completed on  7/19/2024 
  


    Badge 

Get tips and tricks for teaching DP-100: Designing and implementing a data science solution on Azure

Completed on  5/13/2024 
  


    Badge 

Learn best practices from Microsoft Technical Trainers

Completed on  5/13/2024 
  


    Badge 

Microsoft Learn for Educators preparing for course delivery

Completed on  5/13/2024 
  


    Badge 

Get tips and tricks for teaching AZ-104 Microsoft Azure Administrator

Completed on  5/13/2024 
  


    Badge 

Learn best practices from Microsoft Technical Trainers

Completed on  5/13/2024 
  


    Badge 

Microsoft Learn for Educators course planning

Completed on  5/13/2024 
  


    Badge 

Microsoft Learn for Educators Course Preparation

Completed on  5/13/2024 
  


    Badge 

Onboard to Microsoft Learn for Educators program

Completed on  5/13/2024 
  


    Badge 

Introduction to Microsoft Learn for Educators program

Completed on  5/13/2024 
  


    Badge 

Microsoft Learn for Educators student certification

Completed on  5/13/2024 
  


    Badge 

Build a Form Recognizer custom skill for Azure Cognitive Search

Completed on  5/3/2024 
  


    Badge 

Create a composed Form Recognizer model

Completed on  5/3/2024 
  


    Badge 

Extract data from forms with Form Recognizer

Completed on  5/3/2024 
  


    Badge 

Use prebuilt Form Recognizer models

Completed on  5/3/2024 
  


    Badge 

Plan an Azure AI Document Intelligence solution

Completed on  5/3/2024 
  


    Badge 

Perform vector search and retrieval in Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Perform search re-ranking with semantic ranking in Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Maintain an Azure AI Search solution

Completed on  5/3/2024 
  


    Badge 

Search data outside the Azure platform in Azure AI Search using Azure Data Factory

Completed on  5/3/2024 
  


    Badge 

Build an Azure Machine Learning custom skill for Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Implement advanced search features in Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Enrich your data with Azure AI Language

Completed on  5/3/2024 
  


    Badge 

Create a knowledge store with Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Create an Azure AI Search solution

Completed on  5/3/2024 
  


    Badge 

Create a custom skill for Azure AI Search

Completed on  5/3/2024 
  


    Badge 

Get started with Data Activator in Microsoft Fabric

Completed on  3/19/2024 
  


    Badge 

Get started with Real-Time Analytics in Microsoft Fabric

Completed on  3/19/2024 
  


    Badge 

Administer Microsoft Fabric

Completed on  3/19/2024 
  


    Badge 

Create and manage a Power BI deployment pipeline

Completed on  3/19/2024 
  


    Badge 

Load data into a Microsoft Fabric data warehouse

Completed on  3/19/2024 
  


    Badge 

Organize a Fabric lakehouse using medallion architecture design

Completed on  3/19/2024 
  


    Badge 

Ingest data with Spark and Microsoft Fabric notebooks

Completed on  3/19/2024 
  


    Badge 

Detect objects in images

Completed on  3/12/2024 
  


    Badge 

Classify images

Completed on  3/12/2024 
  


    Badge 

Analyze video

Completed on  3/12/2024 
  


    Badge 

Read Text in images and documents with the Azure AI Vision Service

Completed on  3/12/2024 
  


    Badge 

Detect, analyze, and recognize faces

Completed on  3/12/2024 
  


    Badge 

Image classification with custom Azure AI Vision models

Completed on  3/12/2024 
  


    Badge 

Enhance teaching and learning with Microsoft Copilot

Completed on  2/14/2024 
  


    Badge 

Equip and support learners with AI tools from Microsoft

Completed on  2/14/2024 
  


    Badge 

Teach cybersecurity concepts with Minecraft Education

Completed on  2/14/2024 
  


    Badge 

Lead forward: Integrate the best strategies from remote, hybrid, and blended learning for school leaders

Completed on  1/16/2024 
  


    Badge 

Build a question answering solution

Completed on  1/16/2024 
  


    Badge 

Analyze text with Azure AI Language

Completed on  1/16/2024 
  


    Badge 

Translate speech with the Azure AI Speech service

Completed on  1/16/2024 
  


    Badge 

Create speech-enabled apps with Azure AI services

Completed on  1/16/2024 
  


    Badge 

Translate text with Azure AI Translator service

Completed on  1/16/2024 
  


    Badge 

Create a custom named entity extraction solution

Completed on  1/16/2024 
  


    Badge 

Create a custom text classification solution

Completed on  1/16/2024 
  


    Badge 

Build a question answering solution

Completed on  1/16/2024 
  


    Badge 

Extract insights from text with the Azure AI Language service

Completed on  1/16/2024 
  


    Badge 

Build a conversational language understanding model

Completed on  1/16/2024 
  


    Badge 

Custom named entity recognition

Completed on  1/16/2024 
  


    Badge 

Get started with the SharePoint Framework

Completed on  12/28/2023 
  


    Badge 

Use Change Notifications and Track Changes with Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Access Files with Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Manage Group Lifecycle with Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Access User Data from Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Optimize network traffic with Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Optimize data usage when using Microsoft Graph with query parameters

Completed on  12/28/2023 
  


    Badge 

Get started with Microsoft Graph Toolkit

Completed on  12/28/2023 
  


    Badge 

Access user photo information by using Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

Configure a JavaScript application to retrieve Microsoft 365 data by using Microsoft Graph

Completed on  12/28/2023 
  


    Badge 

What is Microsoft Graph?

Completed on  12/28/2023 
  


    Badge 

Introduction to Office client customization with add-ins

Completed on  12/28/2023 
  


    Badge 

Introduction to customizing and extending SharePoint

Completed on  12/28/2023 
  


    Badge 

Introduction to building apps for Microsoft Teams

Completed on  12/28/2023 
  


    Badge 

Understand Actionable Messages in Outlook fundamentals

Completed on  12/28/2023 
  


    Badge 

Automate Microsoft Defender for Cloud Apps with Power Automate

Completed on  12/18/2023 
  


    Badge 

Discover additional resources for Microsoft Defender for Cloud Apps

Completed on  12/18/2023 
  


    Badge 

Configure advanced scenarios in Microsoft Defender for Cloud Apps

Completed on  12/18/2023 
  


    Badge 

Microsoft Defender for Cloud Apps SIEM integration

Completed on  12/18/2023 
  


    Badge 

Leading for equity 101—Prepare your school for equity

Completed on  12/18/2023 
  


    Badge 

Explore identity synchronization

Completed on  12/16/2023 
  


    Badge 

Manage secure user access in Microsoft 365

Completed on  12/16/2023 
  


    Badge 

Manage synchronized identities

Completed on  12/16/2023 
  


    Badge 

Implement directory synchronization tools

Completed on  12/16/2023 
  


    Badge 

Prepare for identity synchronization to Microsoft 365

Completed on  12/16/2023 
  


    Badge 

Prevent data loss

Completed on  12/16/2023 
  


    Badge 

Analyze your Microsoft 365 workplace data using Microsoft Viva Insights

Completed on  12/16/2023 
  


    Badge 

Deploy Microsoft 365 Apps for enterprise

Completed on  12/16/2023 
  


    Badge 

Manage tenant health and services in Microsoft 365

Completed on  12/16/2023 
  


    Badge 

Configure administrative roles in Microsoft 365

Completed on  12/16/2023 
  


    Badge 

Capture Web Application Logs with App Service Diagnostics Logging

Completed on  12/15/2023 
  


    Badge 

Improve incident response with alerting on Azure

Completed on  12/15/2023 
  


    Badge 

Analyze your Azure infrastructure by using Azure Monitor logs

Completed on  12/15/2023 
  


    Badge 

Write multi-table queries by using Kusto Query Language

Completed on  12/15/2023 
  


    Badge 

Gain insights from your data by using Kusto Query Language

Completed on  12/15/2023 
  


    Badge 

Write your first query with Kusto Query Language

Completed on  12/15/2023 
  


    Badge 

Explore the fundamentals of data analysis using Kusto Query Language (KQL)

Completed on  12/15/2023 
  


    Badge 

Generate batch predictions using a deployed model in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Train and track machine learning models with MLflow in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Preprocess data with Data Wrangler in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Explore data for data science with notebooks in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Get started with data science in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Get started with data warehouses in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Ingest Data with Dataflows Gen2 in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Use Data Factory pipelines in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Work with Delta Lake tables in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Use Apache Spark in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Get started with lakehouses in Microsoft Fabric

Completed on  12/15/2023 
  


    Badge 

Introduction to end-to-end analytics using Microsoft Fabric

Completed on  12/4/2023 
  


    Badge 

Manage leads with Dynamics 365 Sales

Completed on  11/21/2023 
  


    Badge 

Set up and configure Dynamics 365 Sales

Completed on  11/21/2023 
  


    Badge 

Get started with Dynamics 365 Sales

Completed on  11/21/2023 
  


    Badge 

Analyze images

Completed on  11/21/2023 
  


    Badge 

Automate Power BI solution management

Completed on  11/21/2023 
  


    Badge 

Enforce data permissions for Power BI embedded analytics

Completed on  11/21/2023 
  


    Badge 

Integrate content with Power BI client APIs

Completed on  11/21/2023 
  


    Badge 

Embed Power BI content

Completed on  11/21/2023 
  


    Badge 

Set up permissions to embed Power BI content

Completed on  11/21/2023 
  


    Badge 

Select a Power BI embedded analytics product

Completed on  11/21/2023 
  


    Badge 

Introduction to Power BI embedded analytics

Completed on  11/21/2023 
  


    Badge 
Assess and convert SQL Server databases using the Data Migration Assistant (DMA)
Completed on  11/20/2023 
  


    Badge 
SQL Server Discovery using the Microsoft Assessment and Planning (MAP) toolkit
Completed on  11/20/2023 
  


    Badge 
Introduction to upgrading SQL Server
Completed on  11/20/2023 
  


    Badge 

Use the SQL Server Query Tuning Assistant

Completed on  11/20/2023 
  


    Badge 
Test and optimize SQL Server databases using the Database Experimentation Assistant (DEA)
Completed on  11/20/2023 
  


    Badge 

Assess SQL Server databases for migration to Azure SQL

Completed on  11/20/2023 
  


    Badge 

Design a SQL Server migration strategy

Completed on  11/20/2023 
  


    Badge 

Migrate SQL workloads to Azure Managed Instances

Completed on  11/20/2023 
  


    Badge 

Migrate SQL Server workloads to Azure SQL Database

Completed on  11/20/2023 
  


    Badge 

Migrate on-premises workloads to Azure

Completed on  11/20/2023 
  


    Badge 

Prepare on-premises workloads for migration to Azure

Completed on  11/20/2023 
  


    Badge 

Design your migration to Azure

Completed on  11/20/2023 
  


    Badge 

Migrate VMware resources on-premises to Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Prepare to migrate VMware resources to Azure by deploying Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Introduction to Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Using Azure NetApp Files with Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Secure outbound internet connectivity for Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Deploy disaster recovery using VMware Site Recovery Manager and Azure VMware Solution

Completed on  11/20/2023 
  


    Badge 

Implement business continuity, disaster recovery, and backup for SAP HANA on Azure (Large Instances)

Completed on  11/20/2023 
  


    Badge 

Monitor and troubleshoot SAP HANA on Azure (Large Instances)

Completed on  11/20/2023 
  


    Badge 

Manage SAP HANA on Azure (Large Instances)

Completed on  11/20/2023 
  


    Badge 

Implement and deploy SAP HANA on Azure (Large Instances)

Completed on  11/20/2023 
  


    Badge 

Examine backup security licensing and support considerations for SAP HANA on Azure (Large Instances)

Completed on  11/20/2023 
  


    Badge 

Plan SAP HANA on Azure (Large Instances) high availability and disaster recovery

Completed on  11/20/2023 
  


    Badge 

Plan SAP HANA on Azure (Large Instances) deployments

Completed on  11/20/2023 
  


    Badge 

Examine SAP HANA on Azure (Large Instances) sample architecture

Completed on  11/20/2023 
  


    Badge 

Identify SAP HANA on Azure (Large Instances) certified offerings

Completed on  11/20/2023 
  


    Badge 

Design data integration

Completed on  11/20/2023 
  


    Badge 

Design a data storage solution for relational data

Completed on  11/20/2023 
  


    Badge 

Design a data storage solution for non-relational data

Completed on  11/20/2023 
  


    Badge 

Scope report design requirements

Completed on  11/20/2023 
  


    Badge 

Manage Power BI assets by using Microsoft Purview

Completed on  11/20/2023 
  


    Badge 

Catalog data artifacts by using Microsoft Purview

Completed on  11/20/2023 
  


    Badge 

Discover trusted data using Microsoft Purview

Completed on  11/20/2023 
  


    Badge 

Introduction to Microsoft Purview

Completed on  11/20/2023 
  


    Badge 

Integrate Microsoft Purview and Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Use Delta Lake in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Transform data with Spark in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Analyze data with Apache Spark in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Challenge project - Create Microsoft Power Platform solutions

Completed on  11/20/2023 
  


    Badge 

Design a semantic model in Power BI

Completed on  11/20/2023 
  


    Badge 

Choose a Power BI model framework

Completed on  11/20/2023 
  


    Badge 

Describe Power BI Desktop models

Completed on  11/20/2023 
  


    Badge 

Optimize a model for performance in Power BI

Completed on  11/20/2023 
  


    Badge 

Add calculated tables and columns to Power BI Desktop models

Completed on  11/20/2023 
  


    Badge 

Add measures to Power BI Desktop models

Completed on  11/20/2023 
  


    Badge 

Write DAX formulas for Power BI Desktop models

Completed on  11/20/2023 
  


    Badge 

Clean, transform, and load data in Power BI

Completed on  11/20/2023 
  


    Badge 

Get data in Power BI

Completed on  11/20/2023 
  


    Badge 

Explore data analytics at scale

Completed on  11/20/2023 
  


    Badge 

Understand concepts of data analytics

Completed on  11/20/2023 
  


    Badge 

Explore Azure data services for modern analytics

Completed on  11/20/2023 
  


    Badge 

Secure data and manage users in Azure Synapse serverless SQL pools

Completed on  11/20/2023 
  


    Badge 

Create a lake database in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Use Azure Synapse serverless SQL pools to transform data in a data lake

Completed on  11/20/2023 
  


    Badge 

Use Azure Synapse serverless SQL pool to query files in a data lake

Completed on  11/20/2023 
  


    Badge 

Load data into a relational data warehouse

Completed on  11/20/2023 
  


    Badge 

Analyze data in a relational data warehouse

Completed on  11/20/2023 
  


    Badge 

Secure a data warehouse in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Manage and monitor data warehouse activities in Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Design a Modern Data Warehouse using Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Explore Azure Synapse Studio

Completed on  11/20/2023 
  


    Badge 

Survey the Components of Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Introduction to Azure Synapse Analytics

Completed on  11/20/2023 
  


    Badge 

Introduction to Azure Data Lake Storage Gen2

Completed on  11/20/2023 
  


    Badge 

Introduction to data engineering on Azure

Completed on  11/20/2023 
  


    Badge 

Build a Power Apps component

Completed on  11/20/2023 
  


    Badge 

Introduction to Dataverse for developers

Completed on  11/20/2023 
  


    Badge 

Extend plug-ins in Power Platform

Completed on  11/20/2023 
  


    Badge 

Apply basic performance optimization in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Build workspaces in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Build reports for finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Create classes in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Build forms and optimize form performance in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Build data models in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Build extended data types and enumerations for finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Develop object-oriented code in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Get started with development using X++ in finance and operations apps

Completed on  11/20/2023 
  


    Badge 

Start developing for finance and operations apps by using Visual Studio

Completed on  11/20/2023 
  


    Badge 
Set up a VHD for finance and operations apps
Completed on  11/20/2023 
  


    Badge 

Configure Azure App Service

Completed on  11/20/2023 
  


    Badge 

Configure Azure App Service plans

Completed on  11/20/2023 
  


    Badge 

Configure virtual machine availability

Completed on  11/20/2023 
  


    Badge 

Configure virtual machines

Completed on  11/20/2023 
  


    Badge 

Host a web application with Azure App Service

Completed on  11/20/2023 
  


    Badge 

Manage virtual machines with the Azure CLI

Completed on  11/20/2023 
  


    Badge 

Configure Azure Container Instances

Completed on  11/20/2023 
  


    Badge 

Enable Containers security

Completed on  11/20/2023 
  


    Badge 

Configure and manage host security

Completed on  11/20/2023 
  


    Badge 

Configure network security

Completed on  11/20/2023 
  


    Badge 

Implement perimeter security

Completed on  11/20/2023 
  


    Badge 

Microsoft Accessibility Features and Tools

Completed on  11/20/2023 
  


    Badge 

Introduction to disability and accessibility

Completed on  11/20/2023 
  


    Badge 

Digital accessibility

Completed on  11/20/2023 
  


    Badge 

Creating accessible content with Microsoft 365

Completed on  11/20/2023 
  


    Badge 
Introduction to Teams Meetings
Completed on  11/20/2023 
  


    Badge 

Bringing it all together for engaging virtual events in Microsoft 365

Completed on  11/20/2023 
  


    Badge 

Design a successful virtual event using Microsoft 365

Completed on  11/20/2023 
  


    Badge 

Introduction to delivering virtual events using Microsoft Teams and Microsoft 365

Completed on  11/20/2023 
  


    Badge 

Introduction to collaborating with Microsoft Teams

Completed on  11/20/2023 
  


    Badge 

Facilitate meetings and events with Microsoft Teams

Completed on  11/20/2023 
  


    Badge 

Collaborate in teams and channels with Microsoft Teams

Completed on  11/20/2023 
  


    Badge 

Create and manage teams and channels with Microsoft Teams

Completed on  11/20/2023 
  


    Badge 

Describe support offerings for Microsoft 365 services

Completed on  11/20/2023 
  


    Badge 

Describe Microsoft 365 pricing, licensing, and billing options

Completed on  11/20/2023 
  


    Badge 

Explore Azure Functions

Completed on  11/20/2023 
  


    Badge 

Develop Azure Functions

Completed on  11/20/2023 
  


    Badge 

Make recommendations with Azure AI Personalizer

Completed on  11/20/2023 
  


    Badge 

Classify and moderate text with Azure Content Moderator

Completed on  11/20/2023 
  


    Badge 

Support reading fluency practice with Reading Progress

Completed on  11/20/2023 
  


    Badge 

Introduction to Azure Logic Apps

Completed on  11/20/2023 
  


    Badge 

Create and deploy an Azure Logic Apps workflow using Azure Resource Manager templates

Completed on  11/20/2023 
  


    Badge 

Call an API from an Azure Logic Apps workflow using a custom connector

Completed on  11/20/2023 
  


    Badge 

Route and process data automatically using Azure Logic Apps

Completed on  11/20/2023 
  


    Badge 

Create serverless logic with Azure Functions

Completed on  11/20/2023 
  


    Badge 

Expose hybrid services securely with Azure Relay

Completed on  11/20/2023 
  


    Badge 

Implement message-based communication workflows with Azure Service Bus

Completed on  11/20/2023 
  


    Badge 

Choose a messaging model in Azure to loosely connect your services

Completed on  11/20/2023 
  


    Badge 

React to state changes in your Azure services by using Event Grid

Completed on  11/20/2023 
  


    Badge 

Enable reliable messaging for Big Data applications using Azure Event Hubs

Completed on  11/20/2023 
  


    Badge 

Communicate between applications with Azure Queue storage

Completed on  11/20/2023 
  


    Badge 

Work with Azure Blob storage

Completed on  11/20/2023 
  


    Badge 

Manage the Azure Blob storage lifecycle

Completed on  11/20/2023 
  


    Badge 

Explore Azure Blob storage

Completed on  11/20/2023 
  


    Badge 

Explore Azure App Service deployment slots

Completed on  11/20/2023 
  


    Badge 

Scale apps in Azure App Service

Completed on  11/20/2023 
  


    Badge 

Configure web app settings

Completed on  11/20/2023 
  


    Badge 

Explore Azure App Service

Completed on  11/20/2023 
  


    Badge 

Design a solution for backup and disaster recovery

Completed on  11/19/2023 
  


    Badge 

Describe high availability and disaster recovery strategies

Completed on  11/19/2023 
  


    Badge 

Implement canary releases and dark launching

Completed on  11/19/2023 
  


    Badge 

Implement blue-green deployment and feature toggles

Completed on  11/19/2023 
  


    Badge 

Introduction to deployment patterns

Completed on  11/19/2023 
  


    Badge 

Manage application configuration data

Completed on  11/19/2023 
  


    Badge 

Integrate with identity management systems

Completed on  11/19/2023 
  


    Badge 

Implement A/B testing and progressive exposure deployment

Completed on  11/19/2023 
  


    Badge 

Manage alerts, blameless retrospectives and a just culture

Completed on  11/19/2023 
  


    Badge 

Design processes to automate application analytics

Completed on  11/19/2023 
  


    Badge 

Share knowledge within teams

Completed on  11/19/2023 
  


    Badge 

Develop monitor and status dashboards

Completed on  11/19/2023 
  


    Badge 

Implement tools to track usage and flow

Completed on  11/19/2023 
  


    Badge 

Manage Git repositories

Completed on  11/19/2023 
  


    Badge 

Plan foster inner source

Completed on  11/19/2023 
  


    Badge 

Explore Git hooks

Completed on  11/19/2023 
  


    Badge 

Identify technical debt

Completed on  11/19/2023 
  


    Badge 

Collaborate with pull requests in Azure Repos

Completed on  11/19/2023 
  


    Badge 

Manage Git branches and workflows

Completed on  11/19/2023 
  


    Badge 

Structure your Git Repo

Completed on  11/19/2023 
  


    Badge 

Introduction to data protection and privacy

Completed on  11/19/2023 
  


    Badge 

Discover the potential of Azure for government

Completed on  11/19/2023 
  


    Badge 

Support data classification with private and hybrid clouds

Completed on  11/19/2023 
  


    Badge 

Safeguard public sector data with Azure

Completed on  11/19/2023 
  


    Badge 

Describe the identity protection and governance capabilities of Microsoft Entra

Completed on  11/19/2023 
  


    Badge 

Describe access management capabilities of Microsoft Entra ID

Completed on  11/19/2023 
  


    Badge 

Describe the authentication capabilities of Microsoft Entra ID

Completed on  11/19/2023 
  


    Badge 

Describe the function and identity types of Microsoft Entra ID

Completed on  11/19/2023 
  


    Badge 

Describe identity concepts

Completed on  11/19/2023 
  


    Badge 

Describe security and compliance concepts

Completed on  11/19/2023 
  


    Badge 

Describe analytics capabilities of Microsoft 365

Completed on  11/19/2023 
  


    Badge 

Describe endpoint modernization, management concepts, and deployment options in Microsoft 365

Completed on  11/19/2023 
  


    Badge 

Describe collaboration solutions of Microsoft 365

Completed on  11/19/2023 
  


    Badge 

Describe productivity solutions of Microsoft 365

Completed on  11/19/2023 
  


    Badge 

What is Microsoft 365?

Completed on  11/19/2023 
  


    Badge 

Use Azure AI Services for Language in a Microsoft Copilot Studio bot

Completed on  11/19/2023 
  


    Badge 

Set up a Microsoft Copilot Studio bot for voice

Completed on  11/19/2023 
  


    Badge 

Manage Power Virtual Agents

Completed on  11/19/2023 
  


    Badge 

Build effective bots with Microsoft Copilot Studio

Completed on  11/19/2023 
  


    Badge 

Enhance Microsoft Copilot Studio bots

Completed on  11/19/2023 
  


    Badge 

Work with entities and variables in Microsoft Copilot Studio

Completed on  11/19/2023 
  


    Badge 

Manage topics in Microsoft Copilot Studio

Completed on  11/19/2023 
  


    Badge 

Get started with Microsoft Copilot Studio bots

Completed on  11/19/2023 
  


    Badge 

Create calculation groups

Completed on  11/19/2023 
  


    Badge 

Use DAX time intelligence functions in Power BI Desktop models

Completed on  11/19/2023 
  


    Badge 

Create Power BI model relationships

Completed on  11/19/2023 
  


    Badge 

Use tools to optimize Power BI performance

Completed on  11/19/2023 
  


    Badge 

Enforce Power BI model security

Completed on  11/19/2023 
  


    Badge 

Publish and share in Power BI

Completed on  11/19/2023 
  


    Badge 

Explore data in Power BI

Completed on  11/19/2023 
  


    Badge 

Use visuals in Power BI

Completed on  11/19/2023 
  


    Badge 

Model data in Power BI

Completed on  11/19/2023 
  


    Badge 

Get started building with Power BI

Completed on  11/19/2023 
  


    Badge 

Discover data analysis

Completed on  11/19/2023 
  


    Badge 

Operate a guide in Dynamics 365 Guides

Completed on  11/19/2023 
  


    Badge 

Author a guide in Dynamics 365 Guides

Completed on  11/19/2023 
  


    Badge 

Dynamics 365 Guides for administrators

Completed on  11/19/2023 
  


    Badge 

Get started with Dynamics 365 Guides

Completed on  11/19/2023 
  


    Badge 

Embed 21st century skills with 21st century learning design

Completed on  11/19/2023 
  


    Badge 

Deepen educational experiences with the 21CLD ICT for learning dimension

Completed on  11/19/2023 
  


    Badge 

Develop learner executive function with the 21CLD self-regulation dimension 

Completed on  11/19/2023 
  


    Badge 

Improve communication skills with the 21CLD skilled communication dimension

Completed on  11/19/2023 
  


    Badge 

Innovate learning with the 21CLD real-world problem solving and innovation dimension 

Completed on  11/19/2023 
  


    Badge 

Practice collaborative skills with the 21CLD collaboration dimension

Completed on  11/19/2023 
  


    Badge 

Develop critical thinking skills with the 21CLD knowledge construction dimension

Completed on  11/19/2023 
  


    Badge 

Transform learning with 21st century learning design

Completed on  11/19/2023 
  


    Badge 

Set up number series and trail codes in Dynamics 365 Business Central

Completed on  11/18/2023 
  


    Badge 

Set up general ledger configuration options in Dynamics 365 Business Central

Completed on  11/18/2023 
  


    Badge 

Set up inventory replenishment in Dynamics 365 Business Central

Completed on  11/18/2023 
  


    Badge 

Plan items in Dynamics 365 Business Central

Completed on  11/18/2023 
  


    Badge 

Set up inventory planning in Dynamics 365 Business Central

Completed on  11/18/2023 
  


    Badge 

Demand Driven Material Requirements Planning in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Use master planning in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Set up Master Planning in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Create bill of materials in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Create products and product masters in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Use inventory reports in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Configure and work with inventory management in Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Get started with Dynamics 365 Supply Chain Management

Completed on  11/18/2023 
  


    Badge 

Introduction to scripting in PowerShell

Completed on  11/18/2023 
  


    Badge 

Write your first PowerShell code

Completed on  11/18/2023 
  


    Badge 

Connect commands into a pipeline

Completed on  11/18/2023 
  


    Badge 

Discover commands in PowerShell

Completed on  11/18/2023 
  


    Badge 

Introduction to PowerShell

Completed on  11/18/2023 
  


    Badge 

Write your first program in C++

Completed on  11/18/2023 
  


    Badge 

Create a Bot with the Bot Framework Composer

Completed on  11/17/2023 
  


    Badge 

Create a bot with the Bot Framework SDK

Completed on  11/17/2023 
  


    Badge 

Deploy Azure AI services in containers

Completed on  11/17/2023 
  


    Badge 

Monitor Azure AI services

Completed on  11/17/2023 
  


    Badge 

Secure Azure AI services

Completed on  11/17/2023 
  


    Badge 

Create and consume Azure AI services

Completed on  11/17/2023 
  


    Badge 

Prepare to develop AI solutions on Azure

Completed on  11/17/2023 
  


    Badge 

Understand the MySQL storage engine

Completed on  11/17/2023 
  


    Badge 

Understand client-server communication in MySQL

Completed on  11/17/2023 
  


    Badge 

Explore MySQL Architecture

Completed on  11/17/2023 
  


    Badge 

Understand concurrency in MySQL

Completed on  11/17/2023 
  


    Badge 

Secure MySQL

Completed on  11/17/2023 
  


    Badge 
Beneath the surface: Device details for IT administrators
Completed on  11/17/2023 
  


    Badge 

Analyze DevOps Continuous Planning and Continuous Integration

Completed on  11/15/2023 
  


    Badge 

Route system feedback to development teams

Completed on  11/15/2023 
  


    Badge 

Explain DevOps Continuous Delivery and Continuous Quality

Completed on  11/15/2023 
  


    Badge 

Characterize DevOps Continuous Collaboration and Continuous Improvement

Completed on  11/15/2023 
  


    Badge 

Introduce the foundation pillars of DevOps: Culture and Lean Product

Completed on  11/15/2023 
  


    Badge 

Assess your existing software development process

Completed on  11/15/2023 
  


    Badge 

Manage Agile software delivery plans across teams

Completed on  11/15/2023 
  


    Badge 

Choose an Agile approach to software development

Completed on  11/15/2023 
  


    Badge 

Introduction to Azure DevOps

Completed on  11/15/2023 
  


    Badge 

Introduction to Git

Completed on  11/15/2023 
  


    Badge 

Edit code through branching and merging in Git

Completed on  11/15/2023 
  


    Badge 

Collaborate with Git

Completed on  11/15/2023 
  


    Badge 

How to create and modify a Git project

Completed on  11/15/2023 
  


    Badge 

Enhance creativity to advance learning with Windows 11 and Microsoft 365 tools

Completed on  11/14/2023 
  


    Badge 

Increase productivity with Office, OneNote, and Edge browser in Windows 11

Completed on  11/14/2023 
  


    Badge 

Build community with Teams and OneNote

Completed on  11/14/2023 
  


    Badge 

Transition to and prepare for fundamentals-level security, compliance, and identity course

Completed on  11/14/2023 
  


    Badge 

Develop search strategies with Search Coach and Search Progress

Completed on  11/14/2023 
  


    Badge 

Perform hyperparameter tuning with Azure Machine Learning

Completed on  11/14/2023 
  


    Badge 

Track model training with MLflow in jobs

Completed on  11/14/2023 
  


    Badge 

Run a training script as a command job in Azure Machine Learning

Completed on  11/14/2023 
  


    Badge 

Deploy a model to a batch endpoint

Completed on  11/14/2023 
  


    Badge 

Deploy a model to a managed online endpoint

Completed on  11/14/2023 
  


    Badge 

Run pipelines in Azure Machine Learning

Completed on  11/14/2023 
  


    Badge 

Find the best classification model with Automated Machine Learning

Completed on  11/14/2023 
  


    Badge 

Make data available in Azure Machine Learning

Completed on  11/14/2023 
  


    Badge 

Build a machine learning model

Completed on  11/14/2023 
  


    Badge 

Data collection and manipulation

Completed on  11/14/2023 
  


    Badge 

Introduction to rocket launches

Completed on  11/14/2023 
  


    Badge 

Digital citizenship: Prepare today’s learners for online success 

Completed on  11/14/2023 
  


    Badge 

Extract invoice data with AI Builder’s prebuilt model

Completed on  11/14/2023 
  


    Badge 

Automate the processing of documents with the AI Builder prepackaged solution

Completed on  11/14/2023 
  


    Badge 

Manage models in AI Builder

Completed on  11/14/2023 
  


    Badge 

Get started with AI Builder

Completed on  11/14/2023 
  


    Badge 

Use text generation in AI Builder

Completed on  11/14/2023 
  


    Badge 

Introduction to expressions in Power Automate

Completed on  11/14/2023 
  


    Badge 

Upload, download, and manage data with Azure Storage Explorer

Completed on  11/13/2023 
  


    Badge 

Control access to Azure Storage with shared access signatures

Completed on  11/13/2023 
  


    Badge 

Configure Azure Storage with tools

Completed on  11/13/2023 
  


    Badge 

Configure Azure Files and Azure File Sync

Completed on  11/13/2023 
  


    Badge 

Configure Azure Storage security

Completed on  11/13/2023 
  


    Badge 

Find commands and Get-Help in Windows PowerShell

Completed on  11/13/2023 
  


    Badge 

Understand the command syntax in Windows PowerShell

Completed on  11/13/2023 
  


    Badge 

Review Windows PowerShell

Completed on  11/13/2023 
  


    Badge 

Manage mail flow rules

Completed on  11/13/2023 
  


    Badge 

Troubleshoot mail flow

Completed on  11/13/2023 
  


    Badge 

Manage mail flow

Completed on  11/13/2023 
  


    Badge 

Troubleshoot audio, video, and client issues

Completed on  11/13/2023 
  


    Badge 

Configure auto attendants and call queues

Completed on  11/13/2023 
  


    Badge 

Configure and manage voice users

Completed on  11/13/2023 
  


    Badge 

Configure and deploy Teams Phone

Completed on  11/13/2023 
  


    Badge 

Plan for Teams Phone

Completed on  11/13/2023 
  


    Badge 

Configure, deploy, and manage Teams devices

Completed on  11/13/2023 
  


    Badge 

Plan for Microsoft Teams Rooms and Surface Hub

Completed on  11/13/2023 
  


    Badge 

Manage meetings and events experiences

Completed on  11/13/2023 
  


    Badge 

Introduction to Teams meetings and calling

Completed on  11/13/2023 
  


    Badge 

Monitor your Microsoft Teams environment

Completed on  11/13/2023 
  


    Badge 

Implement lifecycle management and governance for Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Plan and deploy Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Explore Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Examine Azure Identity Protection

Completed on  11/13/2023 
  


    Badge 

Examine Privileged Identity Management

Completed on  11/13/2023 
  


    Badge 

Examine Microsoft Secure Score

Completed on  11/13/2023 
  


    Badge 

Explore security solutions in Microsoft 365 Defender

Completed on  11/13/2023 
  


    Badge 

Explore the Zero Trust security model

Completed on  11/13/2023 
  


    Badge 

Examine threat vectors and data breaches

Completed on  11/13/2023 
  


    Badge 
Use OneDrive in Microsoft 365
Completed on  11/13/2023 
  


    Badge 

Configure client connectivity to Microsoft 365

Completed on  11/13/2023 
  


    Badge 

Add a custom domain in Microsoft 365

Completed on  11/13/2023 
  


    Badge 

Manage groups in Microsoft 365

Completed on  11/13/2023 
  


    Badge 

Manage users, licenses, and mail contacts in Microsoft 365

Completed on  11/13/2023 
  


    Badge 

Configure your Microsoft 365 experience

Completed on  11/13/2023 
  


    Badge 

Implement compliance for Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Implement security for Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Manage access for external users

Completed on  11/13/2023 
  


    Badge 

Plan and configure network settings for Microsoft Teams

Completed on  11/13/2023 
  


    Badge 

Support social and emotional learning with Microsoft tools

Completed on  11/12/2023 
  


    Badge 

Keep students engaged: Build strong student/teacher connections in a remote learning environment

Completed on  11/12/2023 
  


    Badge 

Stay connected with remote learning through Microsoft Teams and Office 365

Completed on  11/12/2023 
  


    Badge 

Hybrid learning in the primary classroom

Completed on  11/12/2023 
  


    Badge 

Hybrid learning: A new model for the future of learning

Completed on  11/12/2023 
  


    Badge 

Hybrid learning for the adolescent learner

Completed on  11/12/2023 
  


    Badge 

Hybrid learning in the intermediate classroom

Completed on  11/12/2023 
  


    Badge 

Accessibility, special education, and online learning: Supporting equity in a remote learning environment

Completed on  11/12/2023 
  


    Badge 

Differentiation in the classroom using the built-in tools in Office 365 and Windows

Completed on  11/12/2023 
  


    Badge 

Simplify cloud procurement and governance with Azure Marketplace

Completed on  11/12/2023 
  


    Badge 

Design a program launch strategy

Completed on  11/12/2023 
  


    Badge 

Prepare for a program approval event

Completed on  11/12/2023 
  


    Badge 

Design degree program curricula that implement certification

Completed on  11/12/2023 
  


    Badge 

Define academic and industry requirements for implementing certifications in degree programs

Completed on  11/12/2023 
  


    Badge 

Work with data source limits (delegation limits) in a Power Apps canvas app

Completed on  11/11/2023 
  


    Badge 

Work with relational data in a Power Apps canvas app

Completed on  11/11/2023 
  


    Badge 

Use custom connectors in a Power Apps canvas app

Completed on  11/11/2023 
  


    Badge 

Connect to other data in a Power Apps canvas app

Completed on  11/11/2023 
  


    Badge 

Use and understand Controls in a canvas app in Power Apps

Completed on  11/11/2023 
  


    Badge 

Document and test your Power Apps application

Completed on  11/11/2023 
  


    Badge 

Build a mobile-optimized app from Power Apps

Completed on  11/11/2023 
  


    Badge 

Manage apps in Power Apps

Completed on  11/11/2023 
  


    Badge 

Navigation in a canvas app in Power Apps

Completed on  11/11/2023 
  


    Badge 

How to build the UI in a canvas app in Power Apps

Completed on  11/11/2023 
  


    Badge 

Customize a canvas app in Power Apps

Completed on  11/11/2023 
  


    Badge 

Get started with Power Apps canvas apps

Completed on  11/11/2023 
  


    Badge 

How to build your first model-driven app with Dataverse

Completed on  11/11/2023 
  


    Badge 

Configure forms, charts, and dashboards in model-driven apps

Completed on  11/11/2023 
  


    Badge 

Get started with model-driven apps in Power Apps

Completed on  11/11/2023 
  


    Badge 

Create tables in Dataverse

Completed on  11/11/2023 
  


    Badge 

Validation of Teams apps extensible across Microsoft 365

Completed on  11/10/2023 
  


    Badge 

Add significant value to your Teams app

Completed on  11/10/2023 
  


    Badge 

Publish Teams apps in Microsoft Teams store

Completed on  11/10/2023 
  


    Badge 

Azure Health Bot built-in scenarios

Completed on  11/10/2023 
  


    Badge 

Language understanding in Azure Health Bot

Completed on  11/10/2023 
  


    Badge 

Azure Health Bot case studies

Completed on  11/10/2023 
  


    Badge 

Basic Azure Health Bot

Completed on  11/10/2023 
  


    Badge 

Introduction to Azure Health Bot

Completed on  11/10/2023 
  


    Badge 

Channelized Azure Health Bot

Completed on  11/10/2023 
  


    Badge 

Integrate Azure Health Bot with a database

Completed on  11/10/2023 
  


    Badge 

Enhanced Azure Health Bot

Completed on  11/10/2023 
  


    Badge 

Azure Health Bot scenario templates

Completed on  11/10/2023 
  


    Badge 

Deploy a customer service bot

Completed on  11/10/2023 
  


    Badge 

Create a chatbot to help students learn geography

Completed on  11/10/2023 
  


    Badge 

Introduction to responsible bots

Completed on  11/10/2023 
  


    Badge 

Detect objects in images with Azure AI Custom Vision

Completed on  11/10/2023 
  


    Badge 

Translate text and speech with Azure AI services

Completed on  11/10/2023 
  


    Badge 

Classify images with Azure AI Custom Vision

Completed on  11/10/2023 
  


    Badge 

Challenge project - Add image analysis and generation capabilities to your application

Completed on  11/10/2023 
  


    Badge 

Challenge project - Work with variable data in C#

Completed on  11/10/2023 
  


    Badge 

Guided project - Work with variable data in C#

Completed on  11/10/2023 
  


    Badge 

Modify the content of strings using built-in string data type methods in C#

Completed on  11/10/2023 
  


    Badge 

Format alphanumeric data for presentation in C#

Completed on  11/10/2023 
  


    Badge 

Perform operations on arrays using helper methods in C#

Completed on  11/10/2023 
  


    Badge 

Convert data types using casting and conversion techniques in C#

Completed on  11/10/2023 
  


    Badge 

Choose the correct data type in your C# code

Completed on  11/10/2023 
  


    Badge 

Challenge project - Create a mini-game

Completed on  11/10/2023 
  


    Badge 

Guided project - Plan a Petting Zoo Visit

Completed on  11/10/2023 
  


    Badge 

Create C# methods that return values

Completed on  11/10/2023 
  


    Badge 

Create C# methods with parameters

Completed on  11/10/2023 
  


    Badge 

Write your first C# method

Completed on  11/10/2023 
  


    Badge 

Challenge project - Debug a C# console application using Visual Studio Code

Completed on  11/10/2023 
  


    Badge 

Guided project - Debug and handle exceptions in a C# console application using Visual Studio Code

Completed on  11/10/2023 
  


    Badge 

Create and throw exceptions in C# console applications

Completed on  11/10/2023 
  


    Badge 

Implement exception handling in C# console applications

Completed on  11/10/2023 
  


    Badge 

Implement the Visual Studio Code debugging tools for C#

Completed on  11/10/2023 
  


    Badge 

Review the principles of code debugging and exception handling

Completed on  11/10/2023 
  


    Badge 

Evaluate Boolean expressions to make decisions in C#

Completed on  11/10/2023 
  


    Badge 

Challenge project - Develop branching and looping structures in C#

Completed on  11/10/2023 
  


    Badge 

Guided project - Develop conditional branching and looping structures in C#

Completed on  11/10/2023 
  


    Badge 

Add looping logic to your code using the do-while and while statements in C#

Completed on  11/10/2023 
  


    Badge 

Iterate through a code block using for statement in C#

Completed on  11/10/2023 
  


    Badge 

Control variable scope and logic using code blocks in C#

Completed on  11/10/2023 
  


    Badge 

Branch the flow of code using the switch-case construct in C#

Completed on  11/10/2023 
  


    Badge 

Get started with Jupyter notebooks for Python

Completed on  11/9/2023 
  


    Badge 

Python error handling

Completed on  11/9/2023 
  


    Badge 

Python functions

Completed on  11/9/2023 
  


    Badge 

Manage data with Python dictionaries

Completed on  11/9/2023 
  


    Badge 

Use 'while' and 'for' loops in Python

Completed on  11/9/2023 
  


    Badge 

Introduction to lists in Python

Completed on  11/9/2023 
  


    Badge 

Use mathematical operations in Python

Completed on  11/9/2023 
  


    Badge 

Use strings in Python

Completed on  11/9/2023 
  


    Badge 

Use Boolean logic in Python

Completed on  11/9/2023 
  


    Badge 

Create and manage projects in Python

Completed on  11/9/2023 
  


    Badge 

Write your first Python programs

Completed on  11/9/2023 
  


    Badge 

Get started with Python in Visual Studio Code

Completed on  11/9/2023 
  


    Badge 

Using GitHub Copilot with Python

Completed on  11/9/2023 
  


    Badge 

Using GitHub Copilot with JavaScript

Completed on  11/9/2023 
  


    Badge 

Introduction to GitHub Copilot for Business

Completed on  11/9/2023 
  


    Badge 

Introduction to GitHub Copilot

Completed on  11/9/2023 
  


    Badge 

Deploy a model with GitHub Actions

Completed on  11/9/2023 
  


    Badge 

Work with environments in GitHub Actions

Completed on  11/9/2023 
  


    Badge 

Work with linting and unit testing in GitHub Actions

Completed on  11/9/2023 
  


    Badge 

Trigger GitHub Actions with feature-based development

Completed on  11/9/2023 
  


    Badge 

Trigger Azure Machine Learning jobs with GitHub Actions

Completed on  11/9/2023 
  


    Badge 

Use an Azure Machine Learning job for automation

Completed on  11/9/2023 
  


    Badge 

Train and evaluate regression models

Completed on  11/9/2023 
  


    Badge 

Explore and analyze data with Python

Completed on  11/9/2023 
  


    Badge 

Train and evaluate deep learning models

Completed on  11/9/2023 
  


    Badge 

Train and evaluate clustering models

Completed on  11/9/2023 
  


    Badge 

Train and evaluate classification models

Completed on  11/9/2023 
  


    Badge 

Measure and optimize model performance with ROC and AUC

Completed on  11/9/2023 
  


    Badge 

Confusion matrix and data imbalances

Completed on  11/9/2023 
  


    Badge 

Select and customize architectures and hyperparameters using random forest

Completed on  11/9/2023 
  


    Badge 

Create and understand classification models in machine learning

Completed on  11/9/2023 
  


    Badge 

Refine and test machine learning models

Completed on  11/9/2023 
  


    Badge 

Train and understand regression models in machine learning

Completed on  11/9/2023 
  


    Badge 

Introduction to data for machine learning

Completed on  11/9/2023 
  


    Badge 

Build classical machine learning models with supervised learning

Completed on  11/9/2023 
  


    Badge 

Introduction to machine learning

Completed on  11/9/2023 
  


    Badge 

Create a clustering model with Azure Machine Learning designer

Completed on  11/9/2023 
  


    Badge 

Create a classification model with Azure Machine Learning designer

Completed on  11/9/2023 
  


    Badge 

Create a regression model with Azure Machine Learning designer

Completed on  11/9/2023 
  


    Badge 

Use Automated Machine Learning in Azure Machine Learning

Completed on  11/9/2023 
  


    Badge 

Explore developer tools for workspace interaction

Completed on  11/9/2023 
  


    Badge 

Explore Azure Machine Learning workspace resources and assets

Completed on  11/9/2023 
  


    Badge 

Explore Azure Storage for non-relational data

Completed on  11/8/2023 
  


    Badge 

Explore fundamentals of Azure Cosmos DB

Completed on  11/8/2023 
  


    Badge 

Explore relational database services in Azure

Completed on  11/8/2023 
  


    Badge 

Explore fundamental relational data concepts

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Azure AI services

Completed on  11/8/2023 
  


    Badge 

Fundamentals of machine learning

Completed on  11/8/2023 
  


    Badge 

Fundamental AI Concepts

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Knowledge Mining with Azure Cognitive Search

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Azure AI Document Intelligence

Completed on  11/8/2023 
  


    Badge 

Introduction to Computer Vision with PyTorch

Completed on  11/8/2023 
  


    Badge 

Introduction to PyTorch

Completed on  11/8/2023 
  


    Badge 

Introduction to audio classification with PyTorch

Completed on  11/8/2023 
  


    Badge 

Introduction to Natural Language Processing with PyTorch

Completed on  11/8/2023 
  


    Badge 

Transcribe large amounts of audio data with Batch Transcription

Completed on  11/8/2023 
  


    Badge 

Fundamentals of optical character recognition

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Facial Recognition

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Computer Vision

Completed on  11/8/2023 
  


    Badge 

Introduction to Azure Bot Service and Bot Framework Composer

Completed on  11/8/2023 
  


    Badge 

Fundamentals of question answering with the Language Service

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Text Analysis with the Language Service

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Azure AI Speech

Completed on  11/8/2023 
  


    Badge 

Fundamentals of conversational language understanding

Completed on  11/8/2023 
  


    Badge 

Use your own data with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Generate images with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Generate code with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Apply prompt engineering with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Build natural language solutions with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Get started with Azure OpenAI Service

Completed on  11/8/2023 
  


    Badge 

Fundamentals of Responsible Generative AI

Completed on  11/8/2023 
  


    Badge 
Fundamentals of Azure OpenAI Service
Completed on  11/8/2023 
  


    Badge 

Fundamentals of Generative AI

Completed on  11/8/2023 
  


    Badge 

Describe monitoring tools in Azure

Completed on  11/8/2023 
  


    Badge 

Describe features and tools for managing and deploying Azure resources

Completed on  11/8/2023 
  


    Badge 

Describe features and tools in Azure for governance and compliance

Completed on  11/8/2023 
  


    Badge 

Describe cost management in Azure

Completed on  11/8/2023 
  


    Badge 

Align requirements with cloud types and service models in Azure

Completed on  11/8/2023 
  


    Badge 

Move Azure resources to another resource group

Completed on  11/8/2023 
  


    Badge 

Control and organize Azure resources with Azure Resource Manager

Completed on  11/8/2023 
  


    Badge 

Create custom roles for Azure resources with role-based access control (RBAC)

Completed on  11/8/2023 
  


    Badge 

Manage access to an Azure subscription by using Azure role-based access control (Azure RBAC)

Completed on  11/8/2023 
  


    Badge 

Secure your Azure resources with Azure role-based access control (Azure RBAC)

Completed on  11/8/2023 
  


    Badge 

Create Azure users and groups in Microsoft Entra ID

Completed on  11/8/2023 
  


    Badge 

Configure role-based access control

Completed on  11/8/2023 
  


    Badge 

Configure Azure Policy

Completed on  11/8/2023 
  


    Badge 

Configure subscriptions

Completed on  11/8/2023 
  


    Badge 

Configure user and group accounts

Completed on  11/8/2023 
  


    Badge 

Configure Microsoft Entra ID

Completed on  11/8/2023 
  


    Badge 

Allow users to reset their password with Microsoft Entra self-service password reset

Completed on  11/8/2023 
  


    Badge 

Manage device identity with Microsoft Entra join and Enterprise State Roaming

Completed on  11/8/2023 
  


    Badge 

Secure Microsoft Entra users with multifactor authentication

Completed on  11/8/2023 
  


    Badge 

Implement and manage hybrid identity

Completed on  11/8/2023 
  


    Badge 

Implement and manage external identities

Completed on  11/8/2023 
  


    Badge 

Create, configure, and manage identities

Completed on  11/8/2023 
  


    Badge 

Implement initial configuration of Microsoft Entra ID

Completed on  11/8/2023 
  


    Badge 

Investigate threats by using audit features in Microsoft 365 Defender and Microsoft Purview Standard

Completed on  11/8/2023 
  


    Badge 

Manage insider risk in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Respond to data loss prevention alerts using Microsoft 365

Completed on  11/8/2023 
  


    Badge 

Utilize Vulnerability Management in Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Configure for alerts and detections in Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Configure and manage automation using Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Perform evidence and entities investigations using Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Perform actions on a device using Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Perform device investigations in Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Implement Windows security enhancements with Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Deploy the Microsoft Defender for Endpoint environment

Completed on  11/8/2023 
  


    Badge 

Protect against threats with Microsoft Defender for Endpoint

Completed on  11/8/2023 
  


    Badge 

Challenge project - Develop foreach and if-elseif-else structures to process array data in C#

Completed on  11/8/2023 
  


    Badge 

Guided project - Develop foreach and if-elseif-else structures to process array data in C#

Completed on  11/8/2023 
  


    Badge 

Create readable code with conventions, whitespace, and comments in C#

Completed on  11/8/2023 
  


    Badge 

Store and iterate through sequences of data using Arrays and the foreach statement in C#

Completed on  11/8/2023 
  


    Badge 

Add decision logic to your code using `if`, `else`, and `else if` statements in C#

Completed on  11/8/2023 
  


    Badge 

Call methods from the .NET Class Library using C#

Completed on  11/8/2023 
  


    Badge 

Install and configure Visual Studio Code

Completed on  11/8/2023 
  


    Badge 

Perform basic string formatting in C#

Completed on  11/8/2023 
  


    Badge 

Store and retrieve data using literal and variable values in C#

Completed on  11/8/2023 
  


    Badge 

Write your first C# code

Completed on  11/8/2023 
  


    Badge 

Guided project - Calculate final GPA

Completed on  11/8/2023 
  


    Badge 

Guided project - Calculate and print student grades

Completed on  11/8/2023 
  


    Badge 

Perform basic operations on numbers in C#

Completed on  11/8/2023 
  


    Badge 

Explore Windows Editions

Completed on  11/8/2023 
  


    Badge 

Explore the Enterprise Desktop

Completed on  11/8/2023 
  


    Badge 

Examine data security and compliance in Microsoft 365 Copilot

Completed on  11/8/2023 
  


    Badge 

Implement Microsoft 365 Copilot

Completed on  11/8/2023 
  


    Badge 

Examine the Microsoft 365 Copilot design

Completed on  11/8/2023 
  


    Badge 

Manage records in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Manage data retention in Microsoft 365 workloads

Completed on  11/8/2023 
  


    Badge 

Manage the data lifecycle in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Configure DLP policies for Microsoft Defender for Cloud Apps and Power Platform

Completed on  11/8/2023 
  


    Badge 

Prevent data loss in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Manage data loss prevention policies and reports in Microsoft 365

Completed on  11/8/2023 
  


    Badge 

Apply and manage sensitivity labels

Completed on  11/8/2023 
  


    Badge 

Protect information in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Deploy Microsoft Purview Message Encryption

Completed on  11/8/2023 
  


    Badge 

Understand Microsoft 365 encryption

Completed on  11/8/2023 
  


    Badge 

Create and manage sensitive information types

Completed on  11/8/2023 
  


    Badge 

Classify data for protection and governance

Completed on  11/8/2023 
  


    Badge 

Introduction to information protection and data lifecycle management in Microsoft Purview

Completed on  11/8/2023 
  


    Badge 

Design an application architecture

Completed on  11/8/2023 
  


    Badge 

Design an Azure compute solution

Completed on  11/8/2023 
  


    Badge 

Design migrations

Completed on  11/8/2023 
  


    Badge 

Design network solutions

Completed on  11/8/2023 
  


    Badge 

Design a solution to log and monitor Azure resources

Completed on  11/8/2023 
  


    Badge 

Design authentication and authorization solutions

Completed on  11/8/2023 
  


    Badge 

Design governance

Completed on  11/8/2023 
  


    Badge 

Save money with Azure Reserved Instances

Completed on  11/8/2023 
  


    Badge 

Introduction to analyzing costs and creating budgets with Microsoft Cost Management

Completed on  11/8/2023 
  


    Badge 

Microsoft Azure Well-Architected Framework - Cost optimization

Completed on  11/8/2023 
  


    Badge 

Introduction to the Microsoft Azure Well-Architected Framework

Completed on  11/8/2023 
  


    Badge 

Microsoft Cloud Adoption Framework for Azure

Completed on  11/8/2023 
  


    Badge 

Describe Azure identity, access, and security

Completed on  11/8/2023 
  


    Badge 

Describe Azure storage services

Completed on  11/8/2023 
  


    Badge 

Describe Azure compute and networking services

Completed on  11/8/2023 
  


    Badge 

Describe the core architectural components of Azure

Completed on  11/8/2023 
  


    Badge 

Describe cloud service types

Completed on  11/8/2023 
  


    Badge 

Describe the benefits of using cloud services

Completed on  11/8/2023 
  


    Badge 

Describe cloud computing

Completed on  11/8/2023 
  


    Badge 

Publish an API to Azure Static Web Apps

Completed on  11/8/2023 
  


    Badge 

Publish an Angular, React, Svelte, or Vue JavaScript app with Azure Static Web Apps

Completed on  11/8/2023 
  


    Badge 

Create and publish a static web app with Gatsby and Azure Static Web Apps

Completed on  11/8/2023 
  


    Badge 

Publish a Blazor WebAssembly app and .NET API with Azure Static Web Apps

Completed on  11/8/2023 
  


    Badge 

Authenticate users with Azure Static Web Apps

Completed on  11/8/2023 
  


    Badge 

Sign in users with Microsoft Entra ID in a Java web app

Completed on  11/8/2023 
  


    Badge 

Accelerate a Spring Boot application with Azure Cache for Redis

Completed on  11/8/2023 
  


    Badge 

Enable asynchronous messaging in Java apps by using JMS and Azure Service Bus

Completed on  11/8/2023 
  


    Badge 

Build a Java app with cloud-scale NoSQL Cosmos DB

Completed on  11/8/2023 
  


    Badge 

Deploy a Java EE (Jakarta EE) application to Azure

Completed on  11/8/2023 
  


    Badge 

Deploy Spring microservices to Azure

Completed on  11/8/2023 
  


    Badge 

Store application data with Azure Blob Storage

Completed on  11/8/2023 
  


    Badge 

Secure your Azure Storage account

Completed on  11/8/2023 
  


    Badge 

Connect an app to Azure Storage

Completed on  11/8/2023 
  


    Badge 

Create an Azure Storage account

Completed on  11/8/2023 
  


    Badge 

Choose a data storage approach in Azure

Completed on  11/8/2023 
  


    Badge 

Introduction to Docker containers

Completed on  11/8/2023 
  


    Badge 

Secure your identities by using Microsoft Entra ID

Completed on  11/8/2023 
  


    Badge 

Automate Azure tasks using scripts with PowerShell

Completed on  11/8/2023 
  


    Badge 

Control Azure services with the CLI

Completed on  11/8/2023 
  


    Badge 

Fundamentals of network security

Completed on  11/8/2023 
  


    Badge 

Fundamentals of computer networking

Completed on  11/8/2023 
  


    Badge 

Introduction to Azure virtual machines

Completed on  11/8/2023 
  


    Badge 

Create a Windows virtual machine in Azure

Completed on  11/8/2023 
  


    Badge 

Provisioning a Linux virtual machine in Microsoft Azure

Completed on  11/8/2023 
  


    Badge 

Plan your Linux environment in Azure

Completed on  11/8/2023 
  


    Badge 

Introduction to Linux on Azure

Completed on  11/8/2023 
  


    Badge 

Build and run a web application with the MEAN stack on an Azure Linux virtual machine

Completed on  11/8/2023 
  


    Badge 

Optimizing IT operations and management with Azure Automanage

Completed on  11/8/2023 
  


    Badge 

Manage hybrid workloads with Azure Arc

Completed on  11/8/2023 
  


    Badge 

Administer and manage Windows Server IaaS Virtual Machine remotely

Completed on  11/8/2023 
  


    Badge 

Perform Windows Server secure administration

Completed on  11/8/2023 
  


    Badge 

Perform post-installation configuration of Windows Server

Completed on  11/8/2023 
  


    Badge 

Describe Windows Server administration tools

Completed on  11/8/2023 
  


    Badge 

Implement and manage Active Directory Certificate Services

Completed on  11/8/2023 
  


    Badge 

Manage advanced features of AD DS

Completed on  11/8/2023 
  


    Badge 

Implement Group Policy Objects

Completed on  11/8/2023 
  


    Badge 

Manage AD DS domain controllers and FSMO roles

Completed on  11/8/2023 
  


    Badge 

Introduction to AD DS

Completed on  11/8/2023 
  


    Badge 

Deploy and manage Azure IaaS Active Directory domain controllers in Azure

Completed on  11/8/2023 
  


    Badge 

Implement hybrid identity with Windows Server

Completed on  11/8/2023 
  


    Badge 

Implement hybrid network infrastructure

Completed on  11/8/2023 
  


    Badge 

Implement remote access

Completed on  11/8/2023 
  


    Badge 

Implement IP Address Management

Completed on  11/8/2023 
  


    Badge 

Implement Windows Server DNS

Completed on  11/8/2023 
  


    Badge 

Deploy and manage DHCP

Completed on  11/8/2023 
  


    Badge 

Implement DNS for Windows Server IaaS VMs

Completed on  11/8/2023 
  


    Badge 

Implement Windows Server IaaS VM IP addressing and routing

Completed on  11/8/2023 
  


    Badge 

Implement Windows Server IaaS VM network security

Completed on  11/8/2023 
  


    Badge 

Windows Server update management

Completed on  11/8/2023 
  


    Badge 

Hardening Windows Server

Completed on  11/8/2023 
  


    Badge 

Secure Windows Server user accounts

Completed on  11/8/2023 
  


    Badge 

Secure Windows Server DNS

Completed on  11/8/2023 
  


    Badge 

Implement change tracking and file integrity monitoring for Windows IaaS VMs

Completed on  11/8/2023 
  


    Badge 

Configure BitLocker disk encryption for Windows IaaS Virtual Machines

Completed on  11/8/2023 
  


    Badge 

Create and implement application allowlists with adaptive application control

Completed on  11/8/2023 
  


    Badge 

Manage Azure updates

Completed on  11/8/2023 
  


    Badge 

Audit the security of Windows Server IaaS Virtual Machines

Completed on  11/8/2023 
  


    Badge 

Configure and monitor Microsoft Sentinel

Completed on  11/8/2023 
  


    Badge 

Enable and manage Microsoft Defender for Cloud

Completed on  11/8/2023 
  


    Badge 

Configure and manage Azure Monitor

Completed on  11/8/2023 
  


    Badge 

Improve your cloud security posture with Microsoft Defender for Cloud

Completed on  11/8/2023 
  


    Badge 

Secure your cloud apps and services with Microsoft Defender for Cloud Apps

Completed on  11/8/2023 
  


    Badge 

Safeguard your environment with Microsoft Defender for Identity

Completed on  11/8/2023 
  


    Badge 

Remediate risks with Microsoft Defender for Office 365

Completed on  11/8/2023 
  


    Badge 

Protect your identities with Microsoft Entra ID Protection

Completed on  11/8/2023 
  


    Badge 

Mitigate incidents using Microsoft 365 Defender

Completed on  11/8/2023 
  


    Badge 

Introduction to Microsoft 365 threat protection

Completed on  11/8/2023 
  


    Badge 

Configure Azure Load Balancer

Completed on  11/7/2023 
  


    Badge 

Configure network routing and endpoints

Completed on  11/7/2023 
  


    Badge 

Configure Azure Virtual Network peering

Completed on  11/7/2023 
  


    Badge 

Configure Azure DNS

Completed on  11/7/2023 
  


    Badge 

Configure network security groups

Completed on  11/7/2023 
  


    Badge 

Configure virtual networks

Completed on  11/7/2023 
  


    Badge 

Improve application scalability and resiliency by using Azure Load Balancer

Completed on  11/7/2023 
  


    Badge 

Manage and control traffic flow in your Azure deployment with routes

Completed on  11/7/2023 
  


    Badge 

Host your domain on Azure DNS

Completed on  11/7/2023 
  


    Badge 

Distribute your services across Azure virtual networks and integrate them by using virtual network peering

Completed on  11/7/2023 
  


    Badge 

Design an IP addressing schema for your Azure deployment

Completed on  11/7/2023 
  


    Badge 

Configure Azure Application Gateway

Completed on  11/7/2023 
  


    Badge 

Design an enterprise governance strategy

Completed on  11/7/2023 
  


    Badge 

Configure Microsoft Entra Privileged Identity Management

Completed on  11/7/2023 
  


    Badge 

Deploy Microsoft Entra ID Protection

Completed on  11/7/2023 
  


    Badge 

Implement Hybrid identity

Completed on  11/7/2023 
  


    Badge 

Secure Azure solutions with Microsoft Entra ID

Completed on  11/7/2023 
  


    Badge 

Functional Consultant skills

Completed on  11/7/2023 
  


    Badge 

Use knowledge articles to resolve Dynamics 365 Customer Service cases

Completed on  11/7/2023 
  


    Badge 

Search and filter knowledge articles by using Dynamics 365 Customer Service

Completed on  11/7/2023 
  


    Badge 

Create knowledge management solutions in Dynamics 365 Customer Service

Completed on  11/7/2023 
  


    Badge 

Translate Dynamics 365 apps and documentation with Dynamics 365 Translation Service

Completed on  11/7/2023 
  


    Badge 

Challenge project - Architecting solutions for a new product line for customers

Completed on  11/7/2023 
  


    Badge 

Perform fit gap analysis

Completed on  11/7/2023 
  


    Badge 

Work with requirements for Microsoft Power Platform and Dynamics 365

Completed on  11/7/2023 
  


    Badge 

Propose a solution as a Solution Architect for Microsoft Power Platform and Dynamics 365

Completed on  11/7/2023 
  


    Badge 

Discover customer needs as a Solution Architect for Dynamics 365 and Microsoft Power Platform

Completed on  11/7/2023 
  


    Badge 

Becoming a solution architect for Dynamics 365 and Microsoft Power Platform

Completed on  11/7/2023 
  


    Badge 

Integration design for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Review the security model for your Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Create a data migration strategy for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Gap solution design for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Business intelligence and analytics design for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Design data models for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Plan a testing strategy for your Dynamics 365 solution

Completed on  11/7/2023 
  


    Badge 

Create a solution blueprint for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Get started with Success by Design for Dynamics 365

Completed on  11/7/2023 
  


    Badge 

Post go-live strategy for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Cutover strategy for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Implement a performance strategy for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Dual-write implementation for Dynamics 365 solutions

Completed on  11/7/2023 
  


    Badge 

Implement common integration features in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Personalize finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Work with workflows in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Set up batch jobs in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Plan and implement legal entities in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Plan and configure the global address book in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Feature management in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Prepare to go-live with finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Implement role-based security in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Plan and implement security in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Work with performance and monitoring tools in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Updates and upgrades for finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Design and build mobile apps for finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Describe building automation with Microsoft Power Automate

Completed on  11/7/2023 
  


    Badge 

Identify foundational components of Microsoft Power Platform

Completed on  11/7/2023 
  


    Badge 

Describe how to build applications with Microsoft Power Apps

Completed on  11/7/2023 
  


    Badge 

Describe the business value of the Microsoft Power Platform

Completed on  11/7/2023 
  


    Badge 

Work with analytics and reporting in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Data integrations with finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Identify data integration patterns and scenarios in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Consume business events in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Explore extensions and the extension framework in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Implement application lifecycle management in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Prepare data for migration to finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Work with data management in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Perform user acceptance testing in finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Design and plan an implementation of finance and operations apps

Completed on  11/7/2023 
  


    Badge 

Get started with Lifecycle Services for finance and operations apps

Completed on  11/7/2023 
  


    Badge 

FastTrack Customer Success Program for finance and operations

Completed on  11/7/2023 
  


    Badge 

Get started with a finance and operations implementation project

Completed on  11/7/2023 
  


    Badge 

Use approval workflows in Dynamics 365 Business Central

Completed on  11/7/2023 
  


    Badge 

Create workflows in Dynamics 365 Business Central

Completed on  11/7/2023 
  


    Badge 

Migrate on-premises data to Dynamics 365 Business Central

Completed on  11/7/2023 
  


    Badge 

Migrate data to Business Central

Completed on  11/7/2023 
  


    Badge 

Create new companies in Business Central

Completed on  11/7/2023 
  


    Badge 

Administer Dynamics 365 Business Central online

Completed on  11/7/2023 
  


    Badge 

Integrate Business Central with Outlook

Completed on  11/7/2023 
  


    Badge 

Set up email in Dynamics 365 Business Central

Completed on  11/7/2023 
  


    Badge 

Manage users and implement security in Business Central

Completed on  11/7/2023 
  


    Badge 

Administer Microsoft Power Platform subscriptions

Completed on  11/7/2023 
  


    Badge 

Manage Microsoft Power Platform deployments

Completed on  11/7/2023 
  


    Badge 

Use administration options for Dataverse

Completed on  11/7/2023 
  


    Badge 

Get started with security roles in Dataverse

Completed on  11/7/2023 
  


    Badge 

Authentication and user management in Power Pages

Completed on  11/7/2023 
  


    Badge 

Integrate Power Pages with web-based technologies

Completed on  11/7/2023 
  


    Badge 

Power Pages administration

Completed on  11/7/2023 
  


    Badge 

Power Pages maintenance and troubleshooting

Completed on  11/7/2023 
  


    Badge 

Run a Power Automate for desktop flow in unattended mode

Completed on  11/7/2023 
  


    Badge 

Use the Teams connector in Power Automate

Completed on  11/7/2023 
  


    Badge 

Use AI Builder to process invoice forms in Power Automate

Completed on  11/7/2023 
  


    Badge 

Integrate desktop flows with Outlook connector in Power Automate for desktop

Completed on  11/7/2023 
  


    Badge 

Connect a cloud flow to desktop flows in Power Automate for desktop

Completed on  11/7/2023 
  


    Badge 

Define input and output parameters in Power Automate

Completed on  11/7/2023 
  


    Badge 

Build your first Power Automate for desktop flow

Completed on  11/7/2023 
  


    Badge 

Optimize your business process with process advisor

Completed on  11/7/2023 
  


    Badge 

Use AI Builder in Power Automate

Completed on  11/7/2023 
  


    Badge 

Use the Admin center to manage environments and data policies in Power Automate

Completed on  11/7/2023 
  


    Badge 

Power Automate's deep integration across multiple data sources

Completed on  11/7/2023 
  


    Badge 

Build flows to manage user information

Completed on  11/7/2023 
  


    Badge 

Build approval flows with Power Automate

Completed on  11/7/2023 
  


    Badge 

Get started with Power Automate

Completed on  11/7/2023 
  


    Badge 

Get data with Power BI Desktop

Completed on  11/7/2023 
  


    Badge 

Secure, publish, and share data in Power BI

Completed on  11/7/2023 
  


    Badge 

Design interactive data experiences with Power BI Desktop

Completed on  11/7/2023 
  


    Badge 

Transition from Excel to Power BI

Completed on  11/7/2023 
  


    Badge 

Introduction to foundations in data modeling

Completed on  11/7/2023 
  


    Badge 

Automate data cleaning with Power Query

Completed on  11/7/2023 
  


    Badge 

Introduction to modern analytics using Excel and Power BI

Completed on  11/7/2023 
  


    Badge 

Describe the capabilities of Microsoft Power BI

Completed on  11/7/2023 
  


    Badge 

Explore fundamentals of data visualization

Completed on  11/7/2023 
  


    Badge 

Explore fundamentals of real-time analytics

Completed on  11/7/2023 
  


    Badge 

Explore fundamentals of large-scale analytics

Completed on  11/7/2023 
  


    Badge 

Explore data roles and services

Completed on  11/7/2023 
  


    Badge 

Explore core data concepts

Completed on  11/7/2023 
  


    Badge 

Automate multi-container Kubernetes deployments with Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Automate Docker container deployments with Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Automate Azure Functions deployments with Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Manage release cadence in Azure Pipelines by using deployment patterns

Completed on  11/7/2023 
  


    Badge 

Run nonfunctional tests in Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Run functional tests in Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Create a multistage pipeline by using Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Create a release pipeline in Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Host your own build agent in Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Manage build dependencies with Azure Artifacts

Completed on  11/7/2023 
  


    Badge 

Run quality tests in your build pipeline by using Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Create a build pipeline with Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Explore Azure Pipelines

Completed on  11/7/2023 
  


    Badge 

Learn continuous integration with GitHub Actions

Completed on  11/7/2023 
  


    Badge 

Introduction to GitHub Actions

Completed on  11/7/2023 
  


    Badge 

Work with Azure Repos and GitHub

Completed on  11/7/2023 
  


    Badge 

Describe types of source control systems

Completed on  11/7/2023 
  


    Badge 

Introduction to source control

Completed on  11/7/2023 
  


    Badge 

Plan Agile with GitHub Projects and Azure Boards

Completed on  11/7/2023 
  


    Badge 

Choose the DevOps tools

Completed on  11/7/2023 
  


    Badge 

Describe team structures

Completed on  11/7/2023 
  


    Badge 

Choose the right project

Completed on  11/7/2023 
  


    Badge 

Introduction to DevOps

Completed on  11/7/2023 
  


    Badge 

Independent learning with math tools in OneNote

Completed on  11/6/2023 
  


    Badge 

OneNote Class Notebook: A teacher's all-in-one notebook for students

Completed on  11/6/2023 
  


    Badge 

Converse, collaborate, and build community in Teams

Completed on  11/6/2023 
  


    Badge 
Organize content, create assignments, and assess learners’ understanding in Teams
Completed on  11/6/2023 
  


    Badge 

Collaborate with colleagues through live Teams meetings and OneNote

Completed on  11/6/2023 
  


    Badge 

Work collaboratively with Staff and PLC Teams

Completed on  11/6/2023 
  


    Badge 

Assemble learners and staff with Microsoft Teams meetings

Completed on  11/6/2023 
  


    Badge 

Explore the benefits of becoming a Microsoft Educator Trainer

Completed on  11/6/2023 
  


    Badge 

Engage and amplify with Flip

Completed on  11/6/2023 
  


    Badge 

OneNote Staff Notebook: Tools for staff collaboration

Completed on  11/6/2023 
  


    Badge 

Digital storytelling with Microsoft Sway

Completed on  11/6/2023 
  


    Badge 

Create authentic assessments with Microsoft Forms

Completed on  11/6/2023 
  


    Badge 

Engage teachers and students with Windows 11 and Windows 11 SE: Course 201

Completed on  11/6/2023 
  


    Badge 

Empower school leaders and tech-savvy educators with Windows 11 and Windows 11 SE: Course 101

Completed on  11/6/2023 
  


    Badge 

Get started with OneNote

Completed on  11/6/2023 
  


    Badge 

Flipped instruction with PowerPoint Recorder

Completed on  11/6/2023 
  


    Badge 

Structure Teams through channels, tabs, files, and apps

Completed on  11/6/2023 
  


    Badge 

Empower every student with an inclusive classroom

Completed on  11/6/2023 
  


    Badge 

Accessibility: Build the foundation for inclusive learning 

Completed on  11/6/2023 
  


    Badge 

Teach forward: Best strategies for hybrid, remote, and blended learning

Completed on  11/6/2023 
  


924.  
Badge 

Empower educators to explore the potential of artificial intelligence

oCompleted on  11/6/2023 
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025















completed 

Products
Find a product 

  .NET 
    Azure 
    Dynamics 365 
  Excel 
  GitHub 
  HoloLens 
    Industry Solutions 
    Microsoft 365 
    Microsoft Authentication Library 
  Microsoft Copilot 
    Microsoft Defender 
  Microsoft Endpoint Manager 
    Microsoft Entra 
  Microsoft Fabric 
  Microsoft Graph 
  Microsoft Intune 
    Microsoft Power Platform 
  Microsoft Priva 
  Microsoft Purview 
  Microsoft Teams 
    Microsoft Viva 
  Office 365 
  OneDrive 
  OneNote 
  Outlook 
  PowerPoint 
  Quantum Development Kit 
  SQL Server 
  Surface 
  Visual Studio 
  Visual Studio App Center 
  Visual Studio Code 
  
Windows 
Windows Server 
Word 
Roles
Find a role 
Administrator 
AI Edge Engineer 
AI Engineer 
App Maker 
Auditor 
Business Analyst 
Business Owner 
Business User 
Data Analyst 
Data Engineer 
Data Scientist 
Database Administrator 
Developer 
DevOps Engineer 
Functional Consultant 
Higher Education Educator 
Information Protection and Compliance Administrator 
K-12 Educator 
Network Engineer 
Privacy Manager 
Risk Practitioner 
School Leader 
Security Engineer 
Security Operations Analyst 
Service Adoption Specialist 
Solution Architect 
Startup Founder 
Student 
Support Engineer 
Technology Manager 
Levels
Beginner 
Intermediate 
Advanced 
Subjects
Find a subject 

  Application development 
    Artificial intelligence 
    Business applications 
    Data management 
  Security






anscript 
Records may take up to 24 hours to update. 
Transcript 
Legal name:
Tshingombe Tshitadi Fiston 
46307064
Edit display name in settings 
Username: 46307064 Edit user name in settings 
Contact email: tshingombefiston@gmail.com Edit contact email in settings 
Modules completed
924
Training hours completed
738 hr 43 min
Modules completed 
N/A in the module assessment result column means either the module assessment doesn't exist or there's no pass record for it. All modules in this table are complete. 
Module title 	Description 	Completed on 	Duration 	Module Assessment Result 
Introduction to Azure Load Balancer 	This module explains what Azure Load Balancer does, how it works, and when you should choose to use Load Balancer as a solution to meet your organization's needs. 	Jan 10, 2025 	18 min 	N/A 
Enhance your service availability and data locality by using Azure Traffic Manager 	Discover how Azure Traffic Manager provides DNS load balancing for your application to improve the performance and availability of your application. 	Jan 10, 2025 	29 min 	N/A 
Improve your reliability with modern operations practices: An introduction 	Discover a map for navigating reliability challenges and sustainably achieving the appropriate level of reliability in your systems, services, and products. 	Jan 10, 2025 	10 min 	N/A
Expand your AI skills based on your role
Get ready to use Copilot and build AI apps. Discover the transformational experiences you can implement by using Microsoft's AI apps and services. Select a role to explore focused skilling resources.
Developer 
Business or technical leader 
Business user 
IT professional 
Data scientist 
Data professional 
Low-code developer 
Security professional 
Developer
Accelerate app development by using GitHub Copilot
Find out how to use GitHub Copilot to interpret and document code, author new code features more efficiently, and refactor, debug, and test code.
Build AI apps with Azure Services and best practices
Get the details on designing and building a cloud-native AI app, developing a back-end database, and integrating Azure AI services into applications.
Build and extend copilots with Microsoft Copilot Studio
Use Microsoft Copilot Studio to create conversational AI solutions, and learn how to build actions that extend Microsoft 365 Copilot.
Extend Microsoft 365 Copilot (for developers)
Use Copilot Studio actions, and learn about building plugins and connectors for Microsoft 365 Copilot. Discover how to choose the right option for your use case.
Thank you for your interest in Microsoft!
Inbox

Microsoft Recruiting <recruiting@jobs.microsoft.com> 
Unsubscribe
	Thu, Feb 27, 9:00 PM (15 hours ago)
	
	
to me 


 
 
 


Hi Fiston Tshingombe teodor,
Thank you for your interest in a career at Microsoft. Unfortunately, we will not be moving forward with your candidacy for the position of Design Verification Engineer II, 1776092 at this time. However, we’d like to encourage you to continue to explore other career opportunities on Microsoft Careers as we continually update openings on a daily basis. We look forward to considering you for other positions at Microsoft!

Thank you,
Microsoft Recruiting


Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice.
This mail is sent from an unmonitored mailbox. Please do not reply.

			




 
 
 
 
 
 
 


This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to:
https://ms.icims.com/icims2/?r=11B617365170&contactId=129540225 
Thank you for your interest in Microsoft!
Inbox

Microsoft Recruiting <recruiting@jobs.microsoft.com> 
Unsubscribe
	Thu, Feb 27, 9:00 PM (15 hours ago)
	
	
to me 


 
 
 


Hi Fiston Tshingombe teodor,
Thank you for your interest in a career at Microsoft. Unfortunately, we will not be moving forward with your candidacy for the position of Design Verification Engineer II, 1776092 at this time. However, we’d like to encourage you to continue to explore other career opportunities on Microsoft Careers as we continually update openings on a daily basis. We look forward to considering you for other positions at Microsoft!

Thank you,
Microsoft Recruiting


Microsoft respects your privacy. To learn more, please read our Microsoft Data Privacy Notice.
This mail is sent from an unmonitored mailbox. Please do not reply.

			



of libraries and frameworks, and they are the cornerstone of fast and easy Python programming—the so-called Pythonic way of development. But like all programming languages, Python is not immune to security threats. Secure coding best practices must be adopted to avoid risks from attackers. In this webinar, we’ll explore Python security best practices that should employed when building secure application. One-Stop DevOps: Simplifying Toolchains with GitLab and Google Cloud
Nate Avery, Outbound Product Manager - Google | Jackie Porter, Director of Product - Gitlab | Torsten Volk, Principal Analyst - ESG
Dec 04 2024| 28 mins
Seamless Edge Deployment and Management with Lenovo and Intel
Blake Kerrigan, Senior Director, ThinkEdge Business Group
Jan 23 2025| 1 mins




Sort by
Career Opportunity 
Senior Applied Scientist – Copilot Team  
Posted: March 3, 2025 
Location: Beijing, China 
Research Area(s): Artificial intelligence 
We are inviting you to join the Copilot Team, where we are redefining the future of AI-powered experiences. The Copilot Team is at the forefront of innovation, building intelligent solutions that empower users across devices…
Career Opportunity 
Senior Applied AI Engineer – Microsoft Security AI Research team  
Posted: March 3, 2025 
Location: Remote (within US) 
Research Area(s): Artificial intelligence, Security, privacy, and cryptography 
Join the vanguard of cybersecurity innovation with the Microsoft Security AI Research team. We are on the lookout for an Applied Scientist to spearhead the research and development of functional autonomous agents for security scenarios.…
Career Opportunity 
Data Scientist II – Microsoft Security  
Posted: March 1, 2025 
Location: Remote (within US); United States 
Research Area(s): Artificial intelligence, Data platforms and analytics, Human-computer interaction, Security, privacy, and cryptography 
The AI Personalization, Feedback, and Analytics team ensures that Security Copilot, Microsoft’s GenAI platform, delivers adaptive and intelligent experiences by leveraging feedback loops, analytics, and personalization techniques. We are seeking a Data Scientist to help…
Career Opportunity 
Senior Applied Scientist – Power Apps  
Posted: March 1, 2025 
Location: Redmond, WA, US; Remote (within US) 
Research Area(s): Algorithms, Artificial intelligence, Data platforms and analytics 
The Power Apps team at Microsoft is looking to hire a Senior Applied Scientist. As a team, we are very customer focused and driven by curiosity, creativity, teamwork, agility, accountability and desire to learn everyday.…
Career Opportunity 
Applied Scientist II – Power Apps  
Posted: March 1, 2025 
Location: Redmond, WA, US; Remote (within US) 
Research Area(s): Algorithms, Artificial intelligence, Data platforms and analytics, Programming languages and software engineering 
The Power Apps team at Microsoft is looking to hire an Applied Scientist II. As a team, we are very customer focused and driven by curiosity, creativity, team work, agility, accountability and desire to learn everyday. If…
Career Opportunity 
Principal Applied Scientist – Advanced Autonomy and Applied Robotics  
Posted: March 1, 2025 
Location: Redmond, WA, US 
Research Area(s): Artificial intelligence, Hardware and devices, Human-computer interaction, Technology for emerging markets 
Within Microsoft’s Strategic Missions and Technologies (SMT) division, the Advanced Autonomy and Applied Robotics team is seeking a Principal Applied Scientist.The role involves building the future platform for human-robot-agent teaming. This individual will leverage cutting-edge AI and robotics technologies…
Career Opportunity 
Senior Applied Scientist – Advanced Autonomy and Applied Robotics  
Posted: March 1, 2025 
Location: Redmond, WA, US 
Research Area(s): Artificial intelligence, Hardware and devices, Human-computer interaction, Technology for emerging markets 
Within Microsoft’s Strategic Missions and Technologies (SMT) division, the Advanced Autonomy and Applied Robotics team is seeking a Senior Applied Scientist. The role involves building the future platform for human-robot-agent teaming. This individual will leverage…
Career Opportunity 
Principal Researcher – Generative AI – Microsoft Research AI Frontiers  
Posted: March 1, 2025 
Location: New York, NY, US; Redmond, WA, US 
Research Area(s): Artificial intelligence 
We are seeking a Principal Researcher to join our team and lead efforts on the advancement of Generative AI and Large Language Models (LLMs) technologies. As a Principal Researcher, you will play a crucial role in leading,…
Career Opportunity 
Senior Applied Scientist  
Posted: March 1, 2025 
Location: Cairo, Egypt 
Research Area(s): Artificial intelligence 
In shaping the future of monetization for personalized AI assistants and pioneering innovation in the advertiser agentic space, as a Senior Applied Scientist, you will collaborate with engineers, data scientists, and product managers to develop…
Career Opportunity 
Principal Data Scientist – Real-Time Intelligence team  
Posted: February 28, 2025 
Location: Redmond, WA, US 
Research Area(s): Artificial intelligence, Data platforms and analytics, Systems and networking 
Microsoft Fabric’s Real-Time Intelligence team is leading the transformation of real-time analytics in the world of data. We are hiring a Principal Data Scientist to tackle challenges in both open-source and proprietary technologies related to



















































engineering
Inbox
 
tshingombe fiston <tshingombefiston@gmail.com> 
	Mon, Mar 3, 3:19 PM (18 hours ago)
	
	
to me 
 

namics 365 Community / My Profile
 
 
CU03031227-0 
Stats
0 Comments 
0 Posts 
1 Likes 
0 Questions 
My activity 
Achievements
•	
Personal information

•	
Achievements

•	
Notifications

•	
Notification settings

•	
Quick responses

Personal information
Email
tshingombefiston@gmail.com

Confirmation

Registration details
Name
tshingombe tshitadi 
Status
Registered 
Registration ID
102231646 

Quick Links
•	Go to the Microsoft Research Forum Website 
•	Registration support 
•	Cancel registration 
Please note: event emails will be sent to the email address you provided during registration. If you are not receiving event communications, please check your ‘junk’, ‘spam’, or ‘clutter’ folders to confirm your email settings have not redirected the emails. In addition, please add msresearchforum@eventcore.com to your ‘safe sender’ list to ensure you receive future communications for this event. 

Microsoft is committed to your privacy. If you have questions surrounding how your registration is affected by the General Data Protection Regulation (GDPR), then please visit Privacy Management for more information.

Share the news you've registered! 
Compare Microsoft 365 with Office 
Best value for 2 to 6 people 
Microsoft 365 Family 
Subscription
R1 999,00/year
Buy now 
Or buy at R199,00/month 
Try free for 1 month 
Microsoft 365 Personal 
Subscription
R1 599,00/year
Buy now 
Or buy at R159,00/month 
Office Home 2024 
One-time purchase for PC or Mac
R2 299,00
Buy now 
	Microsoft 365 Family 	Microsoft 365 Personal 	Office Home 2024 
Number of users 	1 to 6 people	1 person	One PC or Mac
Number of accounts 	1 to 6	1	One PC or Mac
Cloud storage 	Up to 6 TB (1 TB per person)	1 TB	
Multiple devices and platforms 	Included 	Included 	
Word, Excel, PowerPoint 	Included 	Included 	Included 
OneNote 	Included 	Included 	Included 
Outlook 	Included 	Included 	
Ongoing technical support 	Included 	Included 	
Microsoft Defender 	Included 	Included 	
Microsoft Editor 	Included 	Included 	
Clipchamp 	Included 	Included 	
Microsoft Teams 	Included 	Included 	
Access (PC only) 	Included 	Included 	
Microsoft Forms 	Included 	Included 	
  	•	Learn more 
•	Learn more 
•	Learn more 

Office Home & Business 2024 
•	One-time purchase for one PC or Mac
•	Classic 2024 desktop versions of Word, Excel, PowerPoint, Outlook and OneNote
•	Access to support resources 
Buy now Learn more 
 
Frequently asked questions 
| •  4 is sold as a one-time purchase, which means you pay a single, up-front cost to get Office apps for one computer. One-time purchases are available for both PCs and Macs. However, there are no upgrade options, which means if you plan to upgrade to the next major release, you’ll have to buy it at full price.
Microsoft 365 Personal and Microsoft 365 Family are subscriptions that include powerful productivity apps and creativity tools with AI-powered features. In addition to premium desktop versions of popular Microsoft 365 apps like Word, PowerPoint, Excel and Outlook, you also get spacious cloud storage and cloud-connected features that let you collaborate on files in real time. With a subscription, you’ll always have the latest features, fixes and security updates along with ongoing tech support at no extra cost. You can choose to pay for your subscription on a monthly or yearly basis, and use your apps on multiple PCs, Macs, tablets and phones. Additionally, the Microsoft 365 Family plan lets you share your subscription with up to five more people. Everyone gets their own apps and storage. (AI features only available to subscription owner and cannot be shared; AI usage limits apply; minimum age limits may apply to subscription activation and use of AI features. Learn more.)
•  •  Microsoft 365 is compatible with PC, Mac, Android and iOS. See system requirements for compatible versions of your devices, and for other feature requirements. 
•  •  No. Microsoft 365’s applications are tailored for each platform and each operating system. The applications available for Mac users and the specific features included may be different from those available for PC users. With Microsoft 365, you can be flexible. With your account, you are not limited to exclusively Mac or exclusively PC, so you can transition across devices. 
•  •  Yes. Documents that you have created belong fully to you. You can choose to store them online on OneDrive or locally on your PC or Mac. 
•  •  Internet access is required to install and activate all the latest releases of apps and services included in all Microsoft 365 subscription plans. Note that if you are an existing subscriber, you do not need to reinstall or purchase another subscription.
For Microsoft 365 plans, internet access is also needed to manage your subscription account, for example to install Office apps on other PCs or to change billing options. Internet access is also required to access documents stored on OneDrive, unless you install the OneDrive desktop app.
You should also connect to the internet regularly to keep your version of Microsoft 365 up to date and to benefit from automatic upgrades. If you do not connect to the internet at least every 31 days, your apps will go into reduced functionality mode, which means that you can view or print your documents but cannot edit the documents or create new ones. To reactivate your apps, simply reconnect to the internet.
You do not need to be connected to the internet to use the Office apps, such as Word, Excel and PowerPoint, because the apps are fully installed on your computer.
•  •  Your Microsoft account is the combination of an email address and password that you use to sign in to services like OneDrive, Xbox LIVE and Outlook.com. If you use any of these services, you already have a Microsoft account that you can use, or you can create a new account. Learn more about Microsoft accounts.
As part of signing up for a trial or purchasing Microsoft 365, you will be prompted to sign in with a Microsoft account. You must be signed in with this account to install and manage your Microsoft 365 subscription, or to use some subscription benefits, including cloud storage.
•  •  You can share Microsoft 365 Family with five other people, for a total of six users. Microsoft 365 Personal can be used by one person. 
•  •  If you have an active Microsoft 365 Family subscription, you can share it with up to five other people. Each person you share your subscription with can install Microsoft 365 on all their devices and sign in to five devices at the same time.
To add someone to your subscription, sign in to your Microsoft account and follow the on-screen instructions to add a user. Each person you add will receive an email with the steps they need to follow. Once they have accepted and completed the steps, their information, including the installs they are using, will appear on their My Account page. You can stop sharing your subscription with someone or remove a device they are using by logging into your Microsoft account.
•  •  Visit learn more about free apps. 
•  •  Microsoft Defender is a cross-device security app that helps individuals and families protect their data and devices by continuously scanning the web for threats to your identity and personal data (US only). Defender also helps you stay safer online with malware protection, real-time security notifications and security tips. Download the Microsoft Defender app. 
•  •  Microsoft Defender is a new cross-device app that helps people and families stay safer online. Microsoft Defender adds new features and a simplified user interface. Microsoft Defender also brings valuable device protection to iOS, Android, Windows and Mac, with malware protection, web protection, real-time security notifications and security tips. Microsoft Defender is available in the Apple, Google and Microsoft app stores and requires a Microsoft 365 Personal or Family subscription to use.
Windows Security, formerly known as Windows Defender Security Centre, is built-in security on Windows PCs to protect your device and data. Windows Security is pre-installed and automatically enabled. Windows Security includes Microsoft Defender Antivirus software that protects your Windows device and data against viruses, ransomware, trojans and other malware unless non-Microsoft antivirus software is active.
•  •  A free in-browser video editing platform designed to make video creation accessible for everyone. 
•  •  AI features included in Microsoft 365 Family plans are only available to the subscription owner and cannot be shared with others. 
•  •  To use Copilot in Word, Excel, PowerPoint, OneNote and Outlook, make sure you have the latest version of Microsoft 365 installed. If you're signed in, have the latest updates installed, and still don't see Copilot, please restart your Microsoft 365 apps. Learn more about why I am not seeing Copilot in my apps. 
•  •  Microsoft 365 supports Arabic, Chinese Simplified, Chinese Traditional, Czech, Danish, Dutch, English, Finnish, French, German, Hebrew, Hungarian, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Russian, Spanish, Swedish, Thai and Turkish. Some Designer features, like inline editing capabilities, are available only in English. We plan to add more languages soon. You can also learn more about Copilot supported languages here: Copilot for Microsoft 365 supported languages – Microsoft Support. 
•  •  Visit our Copilot help & learning site to start using Copilot today. 
•  •  Microsoft Designer is a graphic design and image editing app powered by AI. Create eye-catching images with your words, craft next-level designs that pop and even edit photos like an expert. Designer is integrated across your favourite Microsoft apps like Word and PowerPoint to help you create when and where you need it. 
•  •  Beyond the Microsoft Designer web and mobile app, certain Designer features are integrated across some of your favourite Microsoft apps like Word and PowerPoint, helping spark creativity where and when you need it. For Windows users, Designer is also integrated into Microsoft Photos. 
•  •  Usage limits apply to AI-powered features, including Copilot and Designer. Your Microsoft 365 Personal or Family subscription unlocks AI credits to experience and engage with Copilot across Microsoft 365 apps and beyond. Learn more about credits. 
•  Microsoft 365 Business Basic, Business Standard and Business Premium are tailored for businesses, offering professional email with a custom domain, admin controls for managing access and devices and scalability to add additional users as your business grows. They include advanced security features like Exchange Online Protection to guard against phishing and malware, with Business Premium adding Microsoft Defender for Business for ransomware protection and advanced threat management. Plus, you can access professional collaboration tools like Microsoft Teams with meeting recordings, transcription and team workspaces, while business apps such as Microsoft Bookings can simplify meeting and appointment scheduling. Additionally, Microsoft 365 Copilot, an AI-powered assistant for work, is available as an add-on to boost productivity and creativit
 
Course 
Microsoft Azure AI Fundamentals
Course AI-900T00-A: Microsoft Azure AI Fundamentals 
At a glance 
•	Level 
Beginner 
•	Product 
Azure 
•	Role 
AI Engineer 
•	Languages 
English Arabic Chinese (Simplified) Chinese (Traditional) French German Indonesian Italian Japanese Korean Portuguese (Brazil) Russian Spanish 
•	Course Duration 
1 day 
•	Related certifications 
Microsoft Certified: Azure AI Fundamentals 
Overview
This course introduces fundamentals concepts related to artificial intelligence (AI), and the services in Microsoft Azure that can be used to create AI solutions. The course is not designed to teach students to become professional data scientists or software developers, but rather to build awareness of common AI workloads and the ability to identify Azure services to support them. The course is designed as a blended learning experience that combines instructor-led training with online materials on the Microsoft Learn platform (https://azure.com/learn). The hands-on exercises in the course are based on Learn modules, and students are encouraged to use the content on Learn as reference materials to reinforce what they learn in the class and to explore topics in more depth.
Audience Profile
The Azure AI Fundamentals course is designed for anyone interested in learning about the types of solution artificial intelligence (AI) makes possible, and the services on Microsoft Azure that you can use to create them. You don’t need to have any experience of using Microsoft Azure before taking this course, but a basic level of familiarity with computer technology and the Internet is assumed. Some of the concepts covered in the course require a basic understanding of mathematics, such as the ability to interpret charts. The course includes hands-on activities that involve working with data and running code, so a knowledge of fundamental programming principles will be helpful.
Course Syllabus
You can prepare in instructor-led training or self-paced study
•	Learning Path 
Microsoft Azure AI Fundamentals: AI Overview  
o	3 Modules 
o	Beginner
o	AI Engineer
o	Azure AI Bot Service
70% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Computer Vision  
•	3 Modules 
•	Beginner
•	AI Engineer
•	Azure
97% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Natural Language Processing  
•	5 Modules 
•	Beginner
•	AI Engineer
•	Azure Portal
95% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Document Intelligence and Knowledge Mining  
•	2 Modules 
•	Beginner
•	AI Engineer
•	Azure
Completed 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Generative AI  
•	1 of 4 modules completed 
•	Beginner
•	AI Engineer
•	Azure OpenAI Service
20% 
•	
•	
Search for a training provider
 
Course 
Microsoft Azure AI Fundamentals
Course AI-900T00-A: Microsoft Azure AI Fundamentals 
At a glance 
•	Level 
Beginner 
•	Product 
Azure 
•	Role 
AI Engineer 
•	Languages 
English Arabic Chinese (Simplified) Chinese (Traditional) French German Indonesian Italian Japanese Korean Portuguese (Brazil) Russian Spanish 
•	Course Duration 
1 day 
•	Related certifications 
Microsoft Certified: Azure AI Fundamentals 
Overview
This course introduces fundamentals concepts related to artificial intelligence (AI), and the services in Microsoft Azure that can be used to create AI solutions. The course is not designed to teach students to become professional data scientists or software developers, but rather to build awareness of common AI workloads and the ability to identify Azure services to support them. The course is designed as a blended learning experience that combines instructor-led training with online materials on the Microsoft Learn platform (https://azure.com/learn). The hands-on exercises in the course are based on Learn modules, and students are encouraged to use the content on Learn as reference materials to reinforce what they learn in the class and to explore topics in more depth.
Audience Profile
The Azure AI Fundamentals course is designed for anyone interested in learning about the types of solution artificial intelligence (AI) makes possible, and the services on Microsoft Azure that you can use to create them. You don’t need to have any experience of using Microsoft Azure before taking this course, but a basic level of familiarity with computer technology and the Internet is assumed. Some of the concepts covered in the course require a basic understanding of mathematics, such as the ability to interpret charts. The course includes hands-on activities that involve working with data and running code, so a knowledge of fundamental programming principles will be helpful.
Course Syllabus
You can prepare in instructor-led training or self-paced study
•	Learning Path 
Microsoft Azure AI Fundamentals: AI Overview  
o	3 Modules 
o	Beginner
o	AI Engineer
o	Azure AI Bot Service
70% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Computer Vision  
•	3 Modules 
•	Beginner
•	AI Engineer
•	Azure
97% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Natural Language Processing  
•	5 Modules 
•	Beginner
•	AI Engineer
•	Azure Portal
95% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Document Intelligence and Knowledge Mining  
•	2 Modules 
•	Beginner
•	AI Engineer
•	Azure
Completed 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Generative AI  
•	1 of 4 modules completed 
•	Beginner
•	AI Engineer
•	Azure OpenAI Service
20% 
 
Course 
Microsoft Azure AI Fundamentals
Course AI-900T00-A: Microsoft Azure AI Fundamentals 
At a glance 
•	Level 
Beginner 
•	Product 
Azure 
•	Role 
AI Engineer 
•	Languages 
English Arabic Chinese (Simplified) Chinese (Traditional) French German Indonesian Italian Japanese Korean Portuguese (Brazil) Russian Spanish 
•	Course Duration 
1 day 
•	Related certifications 
Microsoft Certified: Azure AI Fundamentals 
Overview
This course introduces fundamentals concepts related to artificial intelligence (AI), and the services in Microsoft Azure that can be used to create AI solutions. The course is not designed to teach students to become professional data scientists or software developers, but rather to build awareness of common AI workloads and the ability to identify Azure services to support them. The course is designed as a blended learning experience that combines instructor-led training with online materials on the Microsoft Learn platform (https://azure.com/learn). The hands-on exercises in the course are based on Learn modules, and students are encouraged to use the content on Learn as reference materials to reinforce what they learn in the class and to explore topics in more depth.
Audience Profile
The Azure AI Fundamentals course is designed for anyone interested in learning about the types of solution artificial intelligence (AI) makes possible, and the services on Microsoft Azure that you can use to create them. You don’t need to have any experience of using Microsoft Azure before taking this course, but a basic level of familiarity with computer technology and the Internet is assumed. Some of the concepts covered in the course require a basic understanding of mathematics, such as the ability to interpret charts. The course includes hands-on activities that involve working with data and running code, so a knowledge of fundamental programming principles will be helpful.
Course Syllabus
You can prepare in instructor-led training or self-paced study
•	Learning Path 
Microsoft Azure AI Fundamentals: AI Overview  
o	3 Modules 
o	Beginner
o	AI Engineer
o	Azure AI Bot Service
70% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Computer Vision  
•	3 Modules 
•	Beginner
•	AI Engineer
•	Azure
97% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Natural Language Processing  
•	5 Modules 
•	Beginner
•	AI Engineer
•	Azure Portal
95% 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Document Intelligence and Knowledge Mining  
•	2 Modules 
•	Beginner
•	AI Engineer
•	Azure
Completed 
•	
•  •  Learning Path 
Microsoft Azure AI Fundamentals: Generative AI  
•	1 of 4 modules completed 
•	Beginner
•	AI Engineer
•	Azure OpenAI Service
20% 
 
1000 XP 
Embrace responsible AI principles and practices
•	51 min
•	Module 
•	9 Units 
Beginner 
Business Owner 
Business User 
Azure 
Dynamics 365 
Microsoft 365 
This module is designed to help you adopt responsible AI practices. It offers an overview of the principles, governance system, and procedures followed at Microsoft, but we encourage you to develop your own AI strategy.
Learning objectives 
In this module, you will:
•	Prepare for the implications of responsible AI
•	Describe principles of responsible AI
•	Establish a system for AI governance
•	Take actions for AI governance
•	Engage across teams and organizations to implement responsible AI principles
•	Take inspiration from ho
Fundamentals of Generative AI
•	9 min remaining
•	Module 
•	11 Units 
Beginner 
AI Engineer 
Developer 
Solution Architect 
Student 
Azure OpenAI Service 
Azure 
In this module, you explore the way in which language models enable AI applications and services to generate original content based on natural language input. You also learn how generative AI enables the creation of agents that can assist humans in creative tasks.
Learning objectives 
By the end of this module, you are able to:
•	Understand generative AI's place in the development of artificial intelligence.
•	Understand language models and their role in intelligent applications.
•	Describe examples of Microsoft Copilot, agents, and good prompts.
Knowledge check
Completed 200 XP 
•	Module assessment
•	3 minutes
1. 
What are Large Language Models?
 
Models that detect additional meaning in paragraphs of text.
 
Lists of words and code that computers use to generate text.
 
Models that use deep learning to process and understand natural language on a massive scale.
2. 
Which Microsoft Copilot should a customer support agent use to research and resolve a support issue?
 
Microsoft Copilot for Microsoft Edge
 
Microsoft Copilot in Dynamics 365 Customer Service
 
Copilot for Security
3. 
Which tool should a professional developer use to build a custom copilot and deploy it as a service endpoint in Azure?
 
Copilot for Azure
 
Microsoft Copilot Studio
 
Microsoft Azure AI Foundry
________________________________________
All units complete:
Having an issue? We can help! 
3.	
 
3900 XP 
Craft effective prompts for Microsoft 365 Copilot
•	2 hr 10 min
•	Learning Path 
•	0 of 4 modules completed
At a glance 
•	Level 
Beginner 
•	Skill 
Create effective prompts for Microsoft Copilot for Microsoft 365 
•	Product 
Microsoft Copilot Microsoft 365 Microsoft 365 Apps Word PowerPoint Excel Outlook Microsoft Teams OneNote 
•	Role 
Business User 
•	Subject 
Business applications Productivity Artificial intelligence 
Discover ways to craft effective and contextual prompts for Microsoft 365 Copilot that create, simplify, transform, and compile content across Microsoft 365 applications. Learn the importance of providing a clear goal, context, source, and expectation in your prompt for the best results. This course covers real world scenarios and examples using Copilot in Microsoft 365 apps like Word, Excel, PowerPoint, Teams, Outlook, OneNote, and Chat.
Note
This content was partially created with the help of AI. An author reviewed and revised the content as needed. Read more.
Prerequisites
Learners should have completed the following content prior to this course:
•	Fundamentals of Generative AI
•	Get started with Microsoft 365 Copilot
Developer
Accelerate app development by using GitHub Copilot
Find out how to use GitHub Copilot to interpret and document code, author new code features more efficiently, and refactor, debug, and test code.
Build AI apps with Azure Services and best practices
Get the details on designing and building a cloud-native AI app, developing a back-end database, and integrating Azure AI services into applications.
Build and extend copilots with Microsoft Copilot Studio
Use Microsoft Copilot Studio to create conversational AI solutions, and learn how to build actions that extend Microsoft 365 Copilot.
Extend Microsoft 365 Copilot (for developers)
Use Copilot Studio actions, and learn about building plugins and connectors for Microsoft 365 Copilot. Discover how to choose the right option for your u
Business or technical leader
Transform your business with Microsoft AI
In this learning path, business leaders will find the knowledge and resources to adopt AI in their organizations. Explore planning, strategizing, and scaling AI projects in a responsible way.
Implement data integration and model grounding with Azure AI Foundry and Microsoft Fabric
Discover how to create advanced AI solutions, ground models in their data, connect and integrate data from various sources, and use OneLake in Microsoft Fabric.
Accelerate gen AI model selection, evaluation, and multimodal integration with Azure AI Foundry
Find out how to benchmark models, apply multimodal models to help enhance customer satisfaction, and complete evaluations to help ensure performance and safety.
Unlocking business potential with AI solutions
Learn how to initiate your organization's AI strategy, assess infrastructure readiness, and understand the business impact of AI
Business user
Design a dream destination using Microsoft Copilot
Bring your personal creativity and passion to dream up a novel destination and create the content to help tell its story. Interact with Microsoft Copilot to learn about the capabilities of generative AI.
Build your Microsoft 365 Copilot skills (for end users)
Find out how to create effective prompts in Microsoft 365 Copilot to help boost your productivity. Explore real-world prompts for specific use case scenarios.
Work smarter with AI
Get more done and unleash your creativity with Microsoft Copilot. In this learning path, you'll explore how to use Microsoft Copilot to help you research, find information, and generate 
Data scientist
Make your data AI ready with Microsoft Fabric
Discover how to implement large-scale data engineering, lakehouse, and warehouse solutions using Microsoft Fabric. Build the skills to use Fabric to effectively manage and analyze data.
Run data analytics solutions with Azure Databricks
Work with Apache Spark and Azure Databricks to run large data engineering workloads in the cloud, and use Azure Databricks for comprehensive data analytics solutions.
IT professional
Get AI-Ready with Microsoft 365 Admin
This content helps admins ensure that Microsoft 365 tenants are set up and configured for AI so that future AI features can be integrated as seamlessly as possible.
Discover Microsoft 365 Copilot (for administrators)
Focus on security and compliance features to configure in your Microsoft 365 tenant to help protect your organizational data before you implement Microsoft 365 Copilot.
Low-code developer
Create Power Platform solutions with AI and Copilot
Learn to use Copilot to set up Dataverse, create Power Apps, and build Automated Processes. Explore what Microsoft Copilot Studio can do to help you build and extend custom copilots.
Accelerate AI development with Low Code
Learn how to develop on Dataverse, Power Apps, and Power Automate. This curated content will also cover creation of custom copilots with Microsoft Copilot Studio.
Extend Microsoft 365 Copilot (for developers)
Use Copilot Studio actions, and learn about building plugins and connectors for Microsoft 365 Copilot. Discover how to choose the right option for your use case.
Build and extend copilots with Microsoft Copilot Studio
Use Microsoft Copilot Studio to create conversational AI solutions, and learn how to build actions that extend Microsoft 365 Copilot.
ecurity professional
Help secure your data in the age of AI
Work with Microsoft Purview, Microsoft Sentinel, and Microsoft Copilot for Security, and learn how to effectively manage, protect, and govern sensitive information in AI-driven environments.
Plan 
Help secure your data in the age of AI 
3 milestones
This Plan is designed to offer you interactive experience working with Microsoft technologies, including Microsoft Purview, Microsoft Sentinel, and Microsoft Copilot for Security, so you can effectively manage, protect, and govern sensitive information in AI-driven environments. Discover how to create a secure and compliant data estate that can easily adapt to AI.• Access Control and Identity Management, 3rd Ed. by Mike Chapple. Publisher: Jones and Bartlett Learning. (Sep, 2020). ________________________________________ • Building an Informati 
•	Published on 3/4/2025 
•	Created by 46307064 
Accelerate app development by using GitHub Copilot 
3 milestones
This Plan is designed to help you enhance your coding efficiency and accuracy. Find out how to use GitHub Copilot to interpret and document code, so you can quickly ramp up on unfamiliar or complex codebases. Learn to author new code features more efficiently by using GitHub Copilot autocompletion and chat features. Additionally, get the details on refactoring, debugging, and testing code with GitHub Copilot. 
•	Published on 3/4/2025 
•	Created by 46307064 
•	Tell us about your PDF experience. 
•	Install C and C++ support in Visual 
•	Studio 
•	Article • 12/09/2021 
•	If you haven't downloaded and installed Visual Studio and the Microsoft C/C++ tools 
•	yet, here's how to get started. 
•	Visual Studio 2022 Installation 
•	Welcome to Visual Studio 2022! In this version, it's easy to choose and install just the 
•	features you need. And because of its reduced minimum footprint, it installs quickly and 
•	with less system impact. 
•	７ Note 
•	This topic applies to installation of Visual Studio on Windows. Visual Studio Code 
•	is a lightweight, cross-platform development environment that runs on Windows, 
•	Mac, and Linux systems. The Microsoft C/C++ for Visual Studio Code extension 
•	supports IntelliSense, debugging, code formatting, auto-completion. Visual Studio 
•	for Mac doesn't support Microsoft C++, but does support .NET languages and 
•	cross-platform development. For installation instructions, see Install Visual Studio 
•	for Mac. 
•	Want to know more about what else is new in this version? See the Visual Studio release 
•	notes. 
•	Ready to install? We'll walk you through it, step-by-step. 
•	Step 1 - Make sure your computer is ready for Visual 
•	Studio 
•	Before you begin installing Visual Studio: 
•	1. Check the system requirements. These requirements help you know whether your 
•	computer supports Visual Studio 2022. 
•	2. Apply the latest Windows updates. These updates ensure that your computer has 
•	both the latest security updates and the required system components for Visual 
•	Studio.3. Reboot. The reboot ensures that any pending installs or updates don't hinder the 
•	Visual Studio install. 
•	4. Free up space. Remove unneeded files and applications from your %SystemDrive% 
•	by, for example, running the Disk Cleanup app. 
•	For questions about running previous versions of Visual Studio side by side with Visual 
•	Studio 2022, see the Visual Studio 2022 Platform Targeting and Compatibility page. 
•	Step 2 - Download Visual Studio 
•	Next, download the Visual Studio bootstrapper file. To do so, choose the following 
•	button to go to the Visual Studio download page. Select the edition of Visual Studio that 
•	you want and choose the Free trial or Free download button. 
•	Download Visual Studio 
•	Step 3 - Install the Visual Studio installer 
•	Run the bootstrapper file you downloaded to install the Visual Studio Installer. This new 
•	lightweight installer includes everything you need to both install and customize Visual 
•	Studio. 
•	1. From your Downloads folder, double-click the bootstrapper that matches or is 
•	similar to one of the following files: 
•	vs_community.exe for Visual Studio Community 
•	vs_professional.exe for Visual Studio Professional 
•	vs_enterprise.exe for Visual Studio Enterprise 
•	If you receive a User Account Control notice, choose Yes to allow the bootstrapper 
•	to run. 
•	2. We'll ask you to acknowledge the Microsoft License Terms and the Microsoft 
•	Privacy Statement . Choose Continue. 
•	Step 4 - Choose workloads 
•	After the installer is installed, you can use it to customize your installation by selecting 
•	the workloads, or feature sets, that you want. Here's how. 
•	1. Find the workload you want in the Installing Visual Studio screen.For core C and C++ support, choose the "Desktop development with C++" 
•	workload. It comes with the default core editor, which includes basic code editing 
•	support for over 20 languages, the ability to open and edit code from any folder 
•	without requiring a project, and integrated source code control. 
•	Additional workloads support other kinds of development. For example, choose 
•	the "Universal Windows Platform development" workload to create apps that use 
•	the Windows Runtime for the Microsoft Store. Choose "Game development with 
•	C++" to create games that use DirectX, Unreal, and Cocos2d. Choose "Linux 
•	development with C++" to target Linux platforms, including IoT development. 
•	The Installation details pane lists the included and optional components installed 
•	by each workload. You can select or deselect optional components in this list. For 
•	example, to support development by using the Visual Studio 2017 or 2015 
•	compiler toolsets, choose the MSVC v141 or MSVC v140 optional components. You 
•	can add support for MFC, the experimental Modules language extension, 
•	IncrediBuild, and more. 
•	2. After you choose the workload(s) and optional components you want, choose 
•	Install. 
•	Next, status screens appear that show the progress of your Visual Studio 
•	installation. 
•	 Tip 
•	At any time after installation, you can install workloads or components that you 
•	didn't install initially. If you have Visual Studio open, go to Tools > Get Tools andFeatures... which opens the Visual Studio Installer. Or, open Visual Studio Installer 
•	from the Start menu. From there, you can choose the workloads or components 
•	that you wish to install. Then, choose Modify. 
•	Step 5 - Choose individual components (Optional) 
•	If you don't want to use the Workloads feature to customize your Visual Studio 
•	installation, or you want to add more components than a workload installs, you can do 
•	so by installing or adding individual components from the Individual components tab. 
•	Choose what you want, and then follow the prompts. 
•	Step 6 - Install language packs (Optional) 
•	By default, the installer program tries to match the language of the operating system 
•	when it runs for the first time. To install Visual Studio in a language of your choosing, 
•	choose the Language packs tab from the Visual Studio Installer, and then follow the 
•	prompts. 
•	Change the installer language from the command line 
•	Another way that you can change the default language is by running the installer from 
•	the command line. For example, you can force the installer to run in English by using the 
•	following command: vs_installer.exe --locale en-US . The installer will remember this 
•	setting when it's run the next time. The installer supports the following language tokens: 
•	zh-cn, zh-tw, cs-cz, en-us, es-es, fr-fr, de-de, it-it, ja-jp, ko-kr, pl-pl, pt-br, ru-ru, and tr-tr.Step 7 - Change the installation location (Optional) 
•	You can reduce the installation footprint of Visual Studio on your system drive. You can 
•	choose to move the download cache, shared components, SDKs, and tools to different 
•	drives, and keep Visual Studio on the drive that runs it the fastest. 
•	） Important 
•	You can select a different drive only when you first install Visual Studio. If you've 
•	already installed it and want to change drives, you must uninstall Visual Studio and 
•	then reinstall it. 
•	Step 8 - Start developing 
•	1. After Visual Studio installation is complete, choose the Launch button to get 
•	started developing with Visual Studio. 
•	2. On the start window, choose Create a new project. 
•	3. In the search box, enter the type of app you want to create to see a list of available 
•	templates. The list of templates depends on the workload(s) that you chose during 
•	installation. To see different templates, choose different workloads. 
•	You can also filter your search for a specific programming language by using the 
•	Language drop-down list. You can filter by using the Platform list and the Project 
•	type list, too. 
•	4. Visual Studio opens your new project, and you're ready to code! 
•	When Visual Studio is running, you're ready to continue to the next step. 
•	Next Steps 
•	Create a C++ projectWhat is Visual Studio? 
•	Article • 06/19/2024 
•	Visual Studio is a powerful developer tool that you can use to complete the entire 
•	development cycle in one place. It's a comprehensive integrated development 
•	environment (IDE) that you can use to write, edit, debug, and build code. Then deploy 
•	your app. Visual Studio includes compilers, code completion tools, source control, 
•	extensions, and many other features to enhance every stage of the software 
•	development process. 
•	With the variety of features and languages support in Visual Studio, you can grow from 
•	writing your first "Hello World" program to developing and deploying apps. For 
•	example, build, debug, and test .NET and C++ apps, edit ASP.NET pages in the web 
•	designer view, develop cross-platform mobile and desktop apps with .NET, or build 
•	responsive Web UIs in C#. 
•	To install Visual Studio, select the following button, and choose the edition of Visual 
•	Studio to download. 
•	Download Visual Studio 
•	Why use Visual Studio? 
•	Visual Studio provides developers a feature rich development environment to develop 
•	high-quality code efficiently and collaboratively. 
•	Workload-based installer - install only what you need 
•	Powerful coding tools and features - everything you need to build your apps in 
•	one placeMultiple language support - code in C++, C#, JavaScript, TypeScript, Python, and 
•	more 
•	Cross-platform development - build apps for any platform 
•	Version control integration - collaborate on code with team mates 
•	AI-assisted development - write code more efficiently with AI assistance 
•	Discover Visual Studio 
•	Visual Studio supports different parts of the software development cycle. 
•	Develop your code 
•	Visual Studio IDE provides many features that make it easier for you to write and 
•	manage your code with confidence. For example, code quickly and accurately with AI 
•	assisted development tools. These tools include GitHub Copilot and IntelliCode. Make 
•	quick improvements to your code using light bulbs that suggest actions, or 
•	expand/collapse blocks of code using outlining. Organize and explore your code with 
•	the Solution Explorer that shows your code organized by files or the Class View that 
•	shows your code organized by classes. 
•	Learn more about all the features in the IDE that help you organize and edit content: 
•	Code editor 
•	Personalize the IDE and the editor 
•	Organize code 
•	Tips and tricks 
•	AI-assisted development 
•	GitHub Copilot, GitHub Copilot Chat, and IntelliCode assist developers in writing code 
•	faster and with greater accuracy, help develop a deeper understanding of the codebase, 
•	and help with other development tasks such as writing unit tests, debugging, and 
•	profiling. 
•	Learn more about AI-assisted development in Visual Studio: 
•	Get started with GitHub Copilot in Visual Studio: 
•	Install and manage GitHub Copilot 
•	Use GitHub Copilot Completions in Visual Studio 
•	Use GitHub Copilot Chat in Visual Studio 
•	Debug with CopilotBuild your app 
•	You can compile and build your applications to create builds immediately and test them 
•	in a debugger. You can run multi-processor builds for C++ and C# projects. Visual 
•	Studio also provides several options that you can configure when you build applications. 
•	You can create a custom build configuration in addition to the built-in configurations, 
•	hide certain warning messages, or increase build output information. 
•	Learn more about how to compile and build in Visual Studio: 
•	Create build configurations for your project 
•	Build an application 
•	Debug your code 
•	Integrated debugging in Visual Studio enables you to debug, profile, and diagnose with 
•	ease. You step through your code and look at the values stored in variables, set watches 
•	on variables to see when values changes, examine the execution path of your code. 
•	Visual Studio offers other ways to debug your code while it runs. 
•	Learn more about debugging effectively in Visual Studio: 
•	Debug your app 
•	Debugging techniques and tools 
•	Measure app performance 
•	Debug with Copilot 
•	Tips and tricks 
•	Test your code 
•	You can write high-quality code with comprehensive testing tools in Visual Studio. Unit 
•	tests give developers and testers a quick way to find logic errors in code. You can 
•	analyze how much code you're testing and see instant results in a test suite. Know the 
•	impact of every change you make with advanced features that test code while you type. 
•	Learn more about the testing tools available in Visual Studio: 
•	Use testing tools in Visual Studio 
•	Create and run unit tests 
•	Analyze code coverage 
•	Version controlWith the integrated Git features in Visual Studio, you can clone, create, or open your 
•	own repositories. The Git tool window has everything you need to commit and push 
•	changes, manage branches, and resolve merge conflicts. If you have a GitHub account, 
•	you can manage those repos directly within Visual Studio. 
•	Learn more about version control in Visual Studio: 
•	Version control with Git 
•	Visual Studio and GitHub 
•	Collaborate with others 
•	Visual Studio Live Share enables real-time collaborative development. With Live Share 
•	you can share your project with your peers, no matter the language or platform. Get to 
•	the bottom of an issue fast by allowing your team to connect, navigate, set break points, 
•	and type in your editor session. 
•	Learn more about how to collaborate with Live Share: 
•	Collaborate with Live Share 
•	Common use cases 
•	Deploy your app 
•	By deploying an application, service, or component, you distribute it for installation on 
•	other computers, devices, or servers, or in the cloud. You can choose the appropriate 
•	method in Visual Studio for the type of deployment that you need. Share your apps and 
•	code by publishing to the web or Azure, or by deploying to a network share or a local 
•	folder. 
•	Learn more about how to deploy your app using Visual Studio: 
•	Deploy your app from Visual Studio 
•	Deploy your app to a folder, a web server, Azure, or another destination 
•	Choose your Visual Studio edition 
•	There are three editions of Visual Studio: 
•	Community - free, fully featured IDE for students, open-source developers, and 
•	individual developers. 
•	Professional - a subscription based option for individual developers or small 
•	teams.Feedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Ask the community 
•	Enterprise - a subscription based option for small to large business and 
•	enterprise organizations. 
•	Compare features across Visual Studio editions and acquire the Visual Studio 
•	edition that best fits your needs. 
•	Select the following button to install Visual Studio, and choose the edition of Visual 
•	Studio. 
•	Dive into coding with one of the following language-specific tutorials: 
•	Create a simple C# console app 
•	Get started with Python 
•	Create a simple VB console app 
•	Create a C++ console app 
•	Create a Node.js and Express app 
•	To develop any type of app, or learn a language, you work in the feature rich Visual 
•	Studio Integrated Development Environment (IDE). Explore Visual Studio further with 
•	one of these introductory articles: 
•	Tour the IDE to get familiar with the IDE features and to learn how to use it for 
•	basic tasks. 
•	Cover the basics in this Learn module: Introduction to Visual Studio 
•	Install Visual Studio 
•	Download Visual Studio 
•	Get started 
•	Related content 
•	 Yes 
•	 NoCreate a C++ console app project 
•	Article • 07/06/2023 
•	The usual starting point for a C++ programmer is a "Hello, world!" application that runs 
•	on the command line. That's what you create in Visual Studio in this step. 
•	Prerequisites 
•	Have Visual Studio with the Desktop development with C++ workload installed 
•	and running on your computer. If it's not installed yet, see Install C++ support in 
•	Visual Studio. 
•	Create your app project 
•	Visual Studio uses projects to organize the code for an app, and solutions to organize 
•	your projects. A project contains all the options, configurations, and rules used to build 
•	your apps. It manages the relationship between all the project's files and any external 
•	files. To create your app, first, create a new project and solution. 
•	1. In Visual Studio, open the File menu and choose New > Project to open the Create 
•	a new Project dialog. Select the Console App template that has C++, Windows, 
•	and Console tags, and then choose Next.2. In the Configure your new project dialog, enter HelloWorld in the Project name 
•	edit box. Choose Create to create the project. 
•	Visual Studio creates a new project. It's ready for you to add and edit your source 
•	code. By default, the Console App template provides source code for a "Hello 
•	World" app, like this: 
•	When the code looks like this in the editor, you're ready to go on to the next step 
•	and build your app.I ran into a problem. 
•	Next steps 
•	Build and run a C++ project 
•	Troubleshooting guide 
•	Come here for solutions to common issues when you create your first C++ project. 
•	Create your app project: issues 
•	The New Project dialog should show a Console App template that has C++, Windows, 
•	and Console tags. If you don't see it, there are two possible causes. It might be filtered 
•	out of the list, or it might not be installed. First, check the filter dropdowns at the top of 
•	the list of templates. Set them to C++, Windows, and Console. The C++ Console App 
•	template should appear; otherwise, the Desktop development with C++ workload isn't 
•	installed. 
•	To install Desktop development with C++, you can run the installer right from the New 
•	Project dialog. Choose the Install more tools and features link at the bottom of the 
•	template list to start the installer. If the User Account Control dialog requests 
•	permissions, choose Yes. In the installer, make sure the Desktop development with C++ 
•	workload is checked. Then choose Modify to update your Visual Studio installation. 
•	If another project with the same name already exists, choose another name for your 
•	project. Or, delete the existing project and try again. To delete an existing project, delete 
•	the solution folder (the folder that contains the helloworld.sln file) in File Explorer. 
•	Go back.Build and run a C++ console app 
•	project 
•	Article • 07/01/2024 
•	In Create a C++ console app project you created a C++ console app project and 
•	entered your code. Now you can build and run it within Visual Studio. Then, run it as a 
•	stand-alone app from the command line. 
•	Prerequisites 
•	Have Visual Studio with the Desktop development with C++ workload installed 
•	and running on your computer. If it's not installed, follow the steps in Install C++ 
•	support in Visual Studio. 
•	Create a "Hello, World!" project. By default, it contains code to print Hello World! . 
•	If you haven't done this step yet, follow the steps in Create a C++ console app 
•	project. 
•	If Visual Studio looks like this, you're ready to build and run your app: 
•	Build and run your code in Visual Studio1. To build your project, from the main menu choose Build > Build Solution. The 
•	Output window shows the results of the build process. 
•	2. To run the code, on the menu bar, choose Debug, Start without debugging. 
•	A console window opens and then runs your app. When you start a console app in 
•	Visual Studio, it runs your code, then prints "Press any key to continue . . ." to give 
•	you a chance to see the output.Congratulations! You created your first "Hello, world!" console app in Visual Studio! 
•	Press a key to dismiss the console window and return to Visual Studio. 
•	I ran into a problem. 
•	Run your code in a command window 
•	Normally, you run console apps at the command prompt, not in Visual Studio. Once 
•	Visual Studio builds your app, you can run it from a command window. Here's how to 
•	find and run your new app in a command prompt window. 
•	1. In Solution Explorer, select the HelloWorld solution (not the HelloWorld project) 
•	and right-click to open the context menu. Choose Open Folder in File Explorer to 
•	open a File Explorer window in the HelloWorld solution folder. 
•	2. In the File Explorer window, open the x64 folder and then the Debug folder. This 
•	folder contains your app, HelloWorld.exe , and debugging files. Hold down the 
•	Shift key and right-click on HelloWorld.exe to open the context menu. Choose 
•	Copy as path to copy the path to your app to the clipboard. If you see 
•	HelloWorld.exe.recipe , it's because you did the Open Folder in File Explorer step 
•	on the HelloWorld project instead of the HelloWorld solution. Navigate up a level in 
•	File Explorer to get to the solution folder. This folder also contains a x64\Debug\ 
•	folder, where HelloWorld.exe is. 
•	3. To open a command prompt window, press Windows+R to open the Run dialog. 
•	Enter cmd.exe in the Open textbox, then choose OK to run a command prompt 
•	window. 
•	4. In the command prompt window, right-click to paste the path to your app into the 
•	command prompt. Press Enter to run your app.Congratulations, you built and ran a console app in Visual Studio! 
•	I ran into a problem. 
•	Next Steps 
•	Once you build and run this simple app, you're ready for more complex projects. For 
•	more information, see Using the Visual Studio IDE for C++ Desktop Development. It has 
•	more detailed walkthroughs that explore the capabilities of Microsoft C++ in Visual 
•	Studio. 
•	Troubleshooting guide 
•	Come here for solutions to common issues when you create your first C++ project. 
•	Build and run your code in Visual Studio: issues 
•	If red squiggles appear under anything in the source code editor, the build may have 
•	errors or warnings. Check that your code matches the example in spelling, punctuation, 
•	and case. 
•	Go back. 
•	Run your code in a command window: issuesFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	If the path shown in File Explorer ends in \HelloWorld\HelloWorld , you opened the 
•	HelloWorld project instead of the HelloWorld solution. You won't see your app in the 
•	x64\Debug folder. Navigate up a level in File Explorer to get to the solution folder, the 
•	first HelloWorld in the path. This folder also contains a x64\Debug folder, where your 
•	app is. 
•	You can also navigate to the solution x64\Debug folder at the command line to run your 
•	app. Your app won't run from other directories without specifying the path to the app. 
•	However, you can copy your app to another directory and run it from there. It's also 
•	possible to copy it to a directory specified by your PATH environment variable, then run 
•	it from anywhere. 
•	If you don't see Copy as path in the shortcut menu, dismiss the menu, and then hold 
•	down the Shift key while you open it again. This command is just for convenience. You 
•	can also copy the path to the folder from the File Explorer search bar, and paste it into 
•	the Run dialog, and then enter the name of your executable at the end. It's just a little 
•	more typing, but it has the same result. 
•	Go back. 
•	 Yes 
•	 NoWelcome back to C++ - Modern C++ 
•	Article • 11/07/2022 
•	Since its creation, C++ has become one of the most widely used programming 
•	languages in the world. Well-written C++ programs are fast and efficient. The language 
•	is more flexible than other languages: It can work at the highest levels of abstraction, 
•	and down at the level of the silicon. C++ supplies highly optimized standard libraries. It 
•	enables access to low-level hardware features, to maximize speed and minimize memory 
•	requirements. C++ can create almost any kind of program: Games, device drivers, HPC, 
•	cloud, desktop, embedded, and mobile apps, and much more. Even libraries and 
•	compilers for other programming languages get written in C++. 
•	One of the original requirements for C++ was backward compatibility with the C 
•	language. As a result, C++ has always permitted C-style programming, with raw 
•	pointers, arrays, null-terminated character strings, and other features. They may enable 
•	great performance, but can also spawn bugs and complexity. The evolution of C++ has 
•	emphasized features that greatly reduce the need to use C-style idioms. The old C 
•	programming facilities are still there when you need them. However, in modern C++ 
•	code you should need them less and less. Modern C++ code is simpler, safer, more 
•	elegant, and still as fast as ever. 
•	The following sections provide an overview of the main features of modern C++. Unless 
•	noted otherwise, the features listed here are available in C++11 and later. In the 
•	Microsoft C++ compiler, you can set the /std compiler option to specify which version 
•	of the standard to use for your project. 
•	Resources and smart pointers 
•	One of the major classes of bugs in C-style programming is the memory leak. Leaks are 
•	often caused by a failure to call delete for memory that was allocated with new . 
•	Modern C++ emphasizes the principle of resource acquisition is initialization (RAII). The 
•	idea is simple. Resources (heap memory, file handles, sockets, and so on) should be 
•	owned by an object. That object creates, or receives, the newly allocated resource in its 
•	constructor, and deletes it in its destructor. The principle of RAII guarantees that all 
•	resources get properly returned to the operating system when the owning object goes 
•	out of scope. 
•	To support easy adoption of RAII principles, the C++ Standard Library provides three 
•	smart pointer types: std::unique_ptr, std::shared_ptr, and std::weak_ptr. A smart pointer 
•	handles the allocation and deletion of the memory it owns. The following exampleshows a class with an array member that is allocated on the heap in the call to 
•	make_unique() . The calls to new and delete are encapsulated by the unique_ptr class. 
•	When a widget object goes out of scope, the unique_ptr destructor will be invoked and 
•	it will release the memory that was allocated for the array. 
•	C++ 
•	Whenever possible, use a smart pointer to manage heap memory. If you must use the 
•	new and delete operators explicitly, follow the principle of RAII. For more information, 
•	see Object lifetime and resource management (RAII). 
•	C-style strings are another major source of bugs. By using std::string and std::wstring, 
•	you can eliminate virtually all the errors associated with C-style strings. You also gain the 
•	benefit of member functions for searching, appending, prepending, and so on. Both are 
•	highly optimized for speed. When passing a string to a function that requires only read 
•	only access, in C++17 you can use std::string_view for even greater performance benefit. 
•	The standard library containers all follow the principle of RAII. They provide iterators for 
•	safe traversal of elements. And, they're highly optimized for performance and have been 
•	thoroughly tested for correctness. By using these containers, you eliminate the potential 
•	#include <memory> 
•	class widget 
•	{ 
•	private: 
•	std::unique_ptr<int[]> data; 
•	public: 
•	widget(const int size) { data = std::make_unique<int[]>(size); } 
•	void do_something() {} 
•	}; 
•	void functionUsingWidget() { 
•	widget w(1000000); // lifetime automatically tied to enclosing scope 
•	// constructs w, including the w.data gadget member 
•	// ... 
•	w.do_something(); 
•	// ... 
•	} // automatic destruction and deallocation for w and w.data 
•	std::string and std::string_view 
•	std::vector and other Standard Library 
•	containersfor bugs or inefficiencies that might be introduced in custom data structures. Instead of 
•	raw arrays, use vector as a sequential container in C++. 
•	C++ 
•	vector<string> apples; 
•	apples.push_back("Granny Smith"); 
•	Use map (not unordered_map ) as the default associative container. Use set, multimap, 
•	and multiset for degenerate and multi cases. 
•	C++ 
•	map<string, string> apple_color; 
•	// ... 
•	apple_color["Granny Smith"] = "Green"; 
•	When performance optimization is needed, consider using: 
•	Unordered associative containers such as unordered_map. These have lower per 
•	element overhead and constant-time lookup, but they can be harder to use 
•	correctly and efficiently. 
•	Sorted vector . For more information, see Algorithms. 
•	Don't use C-style arrays. For older APIs that need direct access to the data, use accessor 
•	methods such as f(vec.data(), vec.size()); instead. For more information about 
•	containers, see C++ Standard Library Containers. 
•	Standard Library algorithms 
•	Before you assume that you need to write a custom algorithm for your program, first 
•	review the C++ Standard Library algorithms. The Standard Library contains an ever 
•	growing assortment of algorithms for many common operations such as searching, 
•	sorting, filtering, and randomizing. The math library is extensive. In C++17 and later, 
•	parallel versions of many algorithms are provided. 
•	Here are some important examples: 
•	for_each , the default traversal algorithm (along with range-based for loops). 
•	transform , for not-in-place modification of container elements 
•	find_if , the default search algorithm. 
•	sort , lower_bound , and the other default sorting and searching algorithms.To write a comparator, use strict < and use named lambdas when you can. 
•	C++ 
•	C++11 introduced the auto keyword for use in variable, function, and template 
•	declarations. auto tells the compiler to deduce the type of the object so that you don't 
•	have to type it explicitly. auto is especially useful when the deduced type is a nested 
•	template: 
•	C++ 
•	C-style iteration over arrays and containers is prone to indexing errors and is also 
•	tedious to type. To eliminate these errors, and make your code more readable, use 
•	range-based for loops with both Standard Library containers and raw arrays. For more 
•	information, see Range-based for statement. 
•	C++ 
•	auto comp = [](const widget& w1, const widget& w2) 
•	{ return w1.weight() < w2.weight(); } 
•	sort( v.begin(), v.end(), comp ); 
•	auto i = lower_bound( v.begin(), v.end(), widget{0}, comp ); 
•	auto instead of explicit type names 
•	map<int,list<string>>::iterator i = m.begin(); // C-style 
•	auto i = m.begin(); // modern C++ 
•	Range-based for loops 
•	#include <iostream> 
•	#include <vector> 
•	int main() 
•	{ 
•	std::vector<int> v {1,2,3}; 
•	// C-style 
•	for(int i = 0; i < v.size(); ++i) 
•	{ 
•	std::cout << v[i]; 
•	}Macros in C and C++ are tokens that are processed by the preprocessor before 
•	compilation. Each instance of a macro token is replaced with its defined value or 
•	expression before the file is compiled. Macros are commonly used in C-style 
•	programming to define compile-time constant values. However, macros are error-prone 
•	and difficult to debug. In modern C++, you should prefer constexpr variables for 
•	compile-time constants: 
•	C++ 
•	In modern C++, you can use brace initialization for any type. This form of initialization is 
•	especially convenient when initializing arrays, vectors, or other containers. In the 
•	following example, v2 is initialized with three instances of S . v3 is initialized with three 
•	instances of S that are themselves initialized using braces. The compiler infers the type 
•	of each element based on the declared type of v3 . 
•	C++ 
•	// Modern C++: 
•	for(auto& num : v) 
•	{ 
•	std::cout << num; 
•	} 
•	} 
•	constexpr expressions instead of macros 
•	#define SIZE 10 // C-style 
•	constexpr int size = 10; // modern C++ 
•	Uniform initialization 
•	#include <vector> 
•	struct S 
•	{ 
•	std::string name; 
•	float num; 
•	S(std::string s, float f) : name(s), num(f) {} 
•	}; 
•	int main() 
•	{ 
•	// C-style initialization 
•	std::vector<S> v; 
•	S s1("Norah", 2.7);For more information, see Brace initialization. 
•	Modern C++ provides move semantics, which make it possible to eliminate unnecessary 
•	memory copies. In earlier versions of the language, copies were unavoidable in certain 
•	situations. A move operation transfers ownership of a resource from one object to the 
•	next without making a copy. Some classes own resources such as heap memory, file 
•	handles, and so on. When you implement a resource-owning class, you can define a 
•	move constructor and move assignment operator for it. The compiler chooses these 
•	special members during overload resolution in situations where a copy isn't needed. The 
•	Standard Library container types invoke the move constructor on objects if one is 
•	defined. For more information, see Move Constructors and Move Assignment Operators 
•	(C++). 
•	In C-style programming, a function can be passed to another function by using a 
•	function pointer. Function pointers are inconvenient to maintain and understand. The 
•	function they refer to may be defined elsewhere in the source code, far away from the 
•	point at which it's invoked. Also, they're not type-safe. Modern C++ provides function 
•	objects, classes that override the operator() operator, which enables them to be called 
•	like a function. The most convenient way to create function objects is with inline lambda 
•	expressions. The following example shows how to use a lambda expression to pass a 
•	function object, that the find_if function will invoke on each element in the vector: 
•	C++ 
•	S s2("Frank", 3.5); 
•	S s3("Jeri", 85.9); 
•	v.push_back(s1); 
•	v.push_back(s2); 
•	v.push_back(s3); 
•	// Modern C++: 
•	std::vector<S> v2 {s1, s2, s3}; 
•	// or... 
•	std::vector<S> v3{ {"Norah", 2.7}, {"Frank", 3.5}, {"Jeri", 85.9} }; 
•	} 
•	Move semantics 
•	Lambda expressionsThe lambda expression [=](int i) { return i > x && i < y; } can be read as "function 
•	that takes a single argument of type int and returns a boolean that indicates whether 
•	the argument is greater than x and less than y ." Notice that the variables x and y 
•	from the surrounding context can be used in the lambda. The [=] specifies that those 
•	variables are captured by value; in other words, the lambda expression has its own 
•	copies of those values. 
•	Modern C++ emphasizes exceptions, not error codes, as the best way to report and 
•	handle error conditions. For more information, see Modern C++ best practices for 
•	exceptions and error handling. 
•	Use the C++ Standard Library std::atomic struct and related types for inter-thread 
•	communication mechanisms. 
•	Unions are commonly used in C-style programming to conserve memory by enabling 
•	members of different types to occupy the same memory location. However, unions 
•	aren't type-safe and are prone to programming errors. C++17 introduces the 
•	std::variant class as a more robust and safe alternative to unions. The std::visit function 
•	can be used to access the members of a variant type in a type-safe manner. 
•	C++ Language Reference 
•	Lambda Expressions 
•	C++ Standard Library 
•	Microsoft C/C++ language conformance 
•	std::vector<int> v {1,2,3,4,5}; 
•	int x = 2; 
•	int y = 4; 
•	auto result = find_if(begin(v), end(v), [=](int i) { return i > x && i < 
•	y; }); 
•	Exceptions 
•	std::atomic 
•	std::variant (C++17) 
•	See alsoFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	 Yes 
•	 NoCreate a console calculator in C++ 
•	Article • 10/08/2024 
•	The usual starting point for a C++ programmer is a "Hello, world!" application that runs 
•	on the command line. You start with that in this article, and then move on to something 
•	more challenging: a calculator app. 
•	Prerequisites 
•	Visual Studio with the Desktop development with C++ workload installed and 
•	running on your computer. To install it, see Install C++ support in Visual Studio. 
•	This tutorial demonstrates a feature called edit and continue which allows you to 
•	make changes to your code while the app is running. To enable edit and continue, 
•	from the main menu select Tools > Options > Debugging > General and ensure 
•	that Require source files to exactly match the original version is checked. 
•	Create your app project 
•	Visual Studio uses projects to organize the code for an app, and solutions to organize 
•	one or more projects. A project contains all the options, configurations, and rules used 
•	to build an app. It also manages the relationship between all the project's files and any 
•	external files. To create your app, first, create a new project and solution. 
•	1. Start Visual Studio--the Visual Studio Start dialog box appears. Select Create a new 
•	project to get started.2. In the Create a new project dialog, set the language dropdown to C++, set the 
•	platform dropdown to Windows, select Console App from the list of project types, 
•	then select Next. 
•	） Important 
•	Make sure you select the C++ version of the Console App template. It has the 
•	C++, Windows, and Console tags, and the icon has "++" in the corner.3. In the Configure your new project dialog box, select the Project name text box, 
•	name your new project CalculatorTutorial, then select Create. 
•	An empty C++ Windows console application 'Hello World' app is created. Console 
•	applications use a Windows console window to display output and accept user 
•	input. In Visual Studio, an editor window opens and shows the generated code: 
•	C++ 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	int main() 
•	{ 
•	std::cout << "Hello World!\n"; 
•	} 
•	// Run program: Ctrl + F5 or Debug > Start Without Debugging menu 
•	// Debug program: F5 or Debug > Start Debugging menu 
•	// Tips for Getting Started: 
•	// 1. Use the Solution Explorer window to add/manage files 
•	// 2. Use the Team Explorer window to connect to source control 
•	// 3. Use the Output window to see build output and other messages 
•	// 4. Use the Error List window to view errors 
•	// 5. Go to Project > Add New Item to create new code files, or 
•	Project > Add Existing Item to add existing code files to the project// 6. In the future, to open this project again, go to File > Open > 
•	Project and select the .sln file 
•	Verify that your new app builds and runs 
•	The template for a new Windows console application creates a simple C++ "Hello 
•	World" app. At this point, you can see how Visual Studio builds and runs the apps you 
•	create right from the IDE. 
•	1. To build your project, select Build Solution from the Build menu. The Output 
•	window shows the results of the build process. 
•	2. To run the code, on the menu bar, select Debug > Start without debugging 
•	(Ctrl+F5).A console window opens and your app runs within it. 
•	When you start a console app in Visual Studio, it runs your code, then prints "Press 
•	any key to close this window . . ." to give you a chance to see the output. 
•	Congratulations! You created your first "Hello, world!" console app in Visual Studio! 
•	3. Press a key to dismiss the console window and return to Visual Studio. 
•	You now have the tools to build and run your app after every change, to verify that the 
•	code still works as you expect. Later, we show you how to debug it if it doesn't. 
•	Now let's modify the code in this template to be a calculator app. 
•	1. Replace the contents of the CalculatorTutorial.cpp file with the following code so 
•	that it matches this example: 
•	C++ 
•	Edit the code 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	using namespace std; 
•	int main() 
•	{ 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b |Understanding the code: 
•	The #include statement brings in code in other files. Sometimes, you 
•	may see a filename surrounded by angle brackets like <iostream> . The 
•	angle brackets instruct the compiler to look for the iostream header file 
•	first in the standard system directories, and if not found, to look in 
•	directories specific to the project. Other times, you may see a filename 
•	surrounded by quotes like "someHeader.h" . The quotes instruct the 
•	compiler to skip looking in the standard system directories and instead 
•	only look in directories specific to the project. 
•	The using namespace std; tells the compiler to expect code from the 
•	C++ Standard Library to be used in this file. Without this line, each 
•	keyword from the library would have to be preceded with std:: to 
•	denote its scope. For instance, without that line, each reference to cout 
•	would be written as std::cout . The using statement is added to make it 
•	more convenient to access code in another namespace. 
•	The cout keyword is used to print to standard output in C++. The << 
•	operator tells the compiler to send whatever is to the right of it to the 
•	standard output. 
•	The endl keyword is like the Enter key; it ends the line and moves the 
•	cursor to the next line. It's a better practice to put a \n inside the string 
•	(contained by "" ) to do the same thing because endl always flushes the 
•	buffer which can hurt the performance of the program. But since this is a 
•	very small app, endl is used instead. 
•	All C++ statements must end with semicolons and all C++ applications 
•	must contain a main() function. This function is what the program runs at 
•	a*b | a/b" 
•	<< endl; 
•	return 0; 
•	} 
•	// Run program: Ctrl + F5 or Debug > Start Without Debugging menu 
•	// Debug program: F5 or Debug > Start Debugging menu 
•	// Tips for Getting Started: 
•	// 1. Use the Solution Explorer window to add/manage files 
•	// 2. Use the Team Explorer window to connect to source control 
•	// 3. Use the Output window to see build output and other messages 
•	// 4. Use the Error List window to view errors 
•	// 5. Go to Project > Add New Item to create new code files, or 
•	Project > Add Existing Item to add existing code files to the project 
•	// 6. In the future, to open this project again, go to File > Open > 
•	Project and select the .sln filethe start. All code must be accessible from main() in order to be used. 
•	2. To save the file, press Ctrl+S, or select the floppy disk icon in the toolbar under the 
•	menu bar. 
•	3. To run the application, press Ctrl+F5 or go to the Debug menu and select Start 
•	Without Debugging. You should see a console window appear that looks like this. 
•	4. Close the console window when you're done. 
•	Add code to do some math 
•	A class is like a blueprint for an object that does something. In this case, we define a 
•	calculator class to contain the math logic. 
•	Add a Calculator class 
•	1. Go to the Project menu and select Add Class. In the Class Name edit box, enter 
•	Calculator. Select OK. 
•	Two new files get added to your project. To save all your changed files at once, 
•	press Ctrl+Shift+S. It's a keyboard shortcut for File > Save All. There's also a 
•	toolbar button for Save All, an icon of two floppy disks, found beside the Savebutton. In general, it's good practice to do Save All frequently, so you don't miss 
•	saving any changes. 
•	The Add Class wizard creates .h and .cpp files that have the same name as the 
•	class. You can see a full list of your project files in the Solution Explorer window, 
•	visible on the side of the IDE. If the window isn't visible, open it from the menu bar 
•	via View > Solution Explorer. 
•	You can open a file by double-clicking it in the Solution Explorer window. Double 
•	click Calculator.h to open it. 
•	2. Replace the contents of Calculator.h with the following code so that the file now 
•	looks like this: 
•	C++ 
•	Understanding the code 
•	This code declares a new function called Calculate , which handles math 
•	operations for addition, subtraction, multiplication, and division. 
•	#pragma once 
•	class Calculator 
•	{ 
•	public: 
•	double Calculate(double x, char oper, double y); 
•	};C++ code is organized into header ( .h ) files and source ( .cpp ) files. 
•	Some other file extensions are supported by various compilers, but these 
•	are the main ones to know about. Functions and variables are normally 
•	declared, that is, given a name and a type, in header files, and 
•	implemented, or given a definition, in source files. To access code defined 
•	in another file, you can use #include "filename.h" , where filename.h is 
•	the name of the file that declares the variables or functions you want to 
•	use. 
•	It's good practice to organize your code into different files based on what 
•	it does, so it's easy to find the code you need later. In our case, we define 
•	the Calculator class separately from the file containing the main() 
•	function, but we plan to reference the Calculator class in main() . 
•	3. A green squiggle appears under Calculate because although the Calculate 
•	function is declared, it isn't defined. Hover over Calculate , click the down arrow on 
•	the screwdriver icon, and select Create definition of 'Calculate' in Calculator.cpp . 
•	This code is added to Calculator.cpp :Currently, it just returns 0.0. Let's change that. 
•	4. Switch to the Calculator.cpp file in the editor window. Replace the contents of 
•	Calculator::Calculate(double x, char oper, double y) with: 
•	C++ 
•	Understanding the code 
•	The function Calculate takes a number, an operator, and a second 
•	number. Then it performs the requested operation on the two numbers. 
•	The switch statement checks which operator was provided, and executes 
•	the case corresponding to that operation. The default: case is a fallback 
•	double Calculator::Calculate(double x, char oper, double y) 
•	{ 
•	switch(oper) 
•	{ 
•	case '+': 
•	return x + y; 
•	case '-': 
•	return x - y; 
•	case '*': 
•	return x * y; 
•	case '/': 
•	return x / y; 
•	default: 
•	return 0.0; 
•	} 
•	}in case the user types an operator that isn't handled by any of the 
•	preceding case statements. It's best to handle invalid user input in a 
•	more elegant way, but this is beyond the scope of this tutorial. 
•	The double keyword denotes a type of number that supports decimals. 
•	This type of number is called a floating-point number, and double means 
•	a floating point number that has extra precision. This way, the calculator 
•	can handle both decimal math and integer math. The Calculate function 
•	is required to always return a double-precision floating point number due 
•	to the double at the start of the code (this denotes the function's return 
•	type), which is why we return 0.0 in the default case. 
•	The .h file declares the function prototype, which tells the compiler 
•	upfront what parameters it requires, and what return type to expect from 
•	it. The .cpp file has all the implementation details of the function. 
•	If you build and run the code again at this point, it immediately exits after asking which 
•	operation to perform. So, modify the main function to do multiple calculations. 
•	1. Update the main function in CalculatorTutorial.cpp as follows: 
•	C++ 
•	Call the Calculator class member functions 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	#include "Calculator.h" 
•	using namespace std; 
•	int main() 
•	{ 
•	double x = 0.0; 
•	double y = 0.0; 
•	double result = 0.0; 
•	char oper = '+'; 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b | 
•	a*b | a/b" 
•	<< endl; 
•	Calculator c; 
•	while (true) 
•	{Understanding the code 
•	Since C++ programs always start at the main() function, we need to call 
•	our other code from there, so an #include statement is needed to make 
•	that code visible to our main() function. 
•	The variables x , y , oper , and result are declared to store the first 
•	number, second number, operator, and final result, respectively. It's 
•	always good practice to give them some initial values to avoid undefined 
•	behavior, which is what is done here. 
•	The Calculator c; line declares an object named c as an instance of the 
•	Calculator class. The class itself is just a blueprint for how calculators 
•	work; the object is the specific calculator that does the math. 
•	The while (true) statement is a loop. The code inside the loop executes 
•	over and over again as long as the condition inside the () holds true. 
•	Since the condition is simply listed as true , it's always true, so the loop 
•	runs forever. To close the program, the user must manually close the 
•	console window. Otherwise, the program always waits for new input. 
•	The cin keyword accepts input from the user. The input stream is smart 
•	enough to process a line of text entered in the console window and place 
•	it inside each of the variables listed, in order. 
•	The c.Calculate(x, oper, y); expression calls the Calculate function 
•	defined earlier, and supplies the entered input values and the requested 
•	operation. The function then returns a number that is stored in result . 
•	Finally, result is printed to the console and the user sees the result of 
•	the calculation. 
•	Now test the program again to make sure everything works properly. 
•	1. Press Ctrl+F5 to rebuild and start the app. 
•	2. Enter 5+5 , and press Enter. Verify that the result is 10. 
•	cin >> x >> oper >> y; 
•	result = c.Calculate(x, oper, y); 
•	cout << "Result " << "of " << x << oper << y << " is: " << 
•	result << endl; 
•	} 
•	return 0; 
•	} 
•	Build and test the code again3. Stop the program by closing the console window. 
•	Debug the app 
•	Since the user is free to type anything into the console window, let's make sure the 
•	calculator handles unexpected input. Instead of running the program, let's debug it so 
•	we can inspect what it's doing step-by-step. 
•	Run the app in the debugger 
•	1. In CalcuatorTutorial.cpp , set a breakpoint on the line: result = c.Calculate(x, 
•	oper, y); . To set the breakpoint, click next to the line in the gray vertical bar along 
•	the left edge of the editor window so that a red dot appears. 
•	Now when we debug the program, execution pauses at that line. We already have 
•	a rough idea that the program works for simple cases. Since we don't want to 
•	pause execution every time we call Calculate() , let's make the breakpoint 
•	conditional.2. Right-click the red dot that represents the breakpoint, and select Conditions. In 
•	the edit box for the condition, enter (y == 0) && (oper == '/') . Select the Close 
•	button to save the breakpoint condition. 
•	Now, execution pauses at the breakpoint when the app tries to divide by 0. 
•	3. To debug the program, press F5, or select the Local Windows Debugger debugger 
•	toolbar button that has the green arrow icon. In your console app, if you enter 
•	something like "5 - 0", the program behaves normally and keeps running. 
•	However, if you type "10 / 0", it pauses at the breakpoint. You can put any number 
•	of spaces between the operator and numbers: cin is smart enough to parse the 
•	input appropriately.Useful windows in the debugger 
•	When you debug your code, you may notice that some new windows appear. These 
•	windows can assist your debugging experience. Take a look at the Autos window. The 
•	Autos window shows you the current values of variables used at least three lines before 
•	and up to the current line. If you don't see the Autos window, from the main menu 
•	select Debug > Windows > Autos. 
•	To see all of the variables from that function, switch to the Locals window. Because this 
•	is a small function, the Autos and Locals window show the same variables. But you can 
•	modify the values of these variables in the Locals window while debugging to see what 
•	effect they would have on the program. In this case, we leave them alone. Open the 
•	Locals window by selecting Locals at the bottom of the Autos window, or by selecting 
•	from the main menu Debug > Windows > Locals.You can also hover over variables in the code to see their current values at the point 
•	where execution is currently paused. Make sure the editor window is in focus by clicking 
•	on it first. 
•	Continue debugging 
•	1. The yellow arrow on the left shows the current point of execution. The current line 
•	calls Calculate , so press F11 to Step Into the function. Now you're executing code 
•	in the body of the Calculate function. Be careful with Step Into because it steps 
•	into any functions on the line you're on, including standard library functions. It's 
•	fine to step into the standard library, but you may be more interested in focusing 
•	on your code instead of library code. 
•	2. Now that the point of execution is at the start of the Calculate function, press F10 
•	to move to the next line in the program's execution. F10 is also known as Step 
•	Over. You can use Step Over to move from line to line, without delving into the 
•	details of what is occurring in each part of the line. In general, you should use Step 
•	Over instead of Step Into unless you want to dive more deeply into code that is 
•	being called from elsewhere (as you did to reach the body of Calculate ). 
•	3. Continue using F10 to Step Over each line until you get back to the main() 
•	function in the other file, and stop on the cout line.The program is doing what's expected: it takes the first number, and divides it by 
•	the second. On the cout line, hover over the result variable or take a look at 
•	result in the Autos window. Its value is inf , which doesn't look right. 
•	Let's fix it. The cout line outputs whatever value is stored in result , so when you 
•	step one more line forward using F10, the console window displays: 
•	This result is because division by zero is undefined, so the program doesn't have a 
•	numerical answer for the requested operation. 
•	Fix the "divide by zero" error 
•	Let's handle division by zero more gracefully so that it's easier for the user to 
•	understand the problem. 
•	1. Make the following changes in CalculatorTutorial.cpp . You can leave the 
•	program running as you edit, thanks to a debugger feature called Edit andContinue. Add an if statement following cin >> x >> oper >> y; to check for 
•	division by zero and output a message to the user if it happens. Otherwise, the 
•	result is printed. 
•	C++ 
•	2. Press F5 once. Program execution continues until it has to pause to ask for user 
•	input. Enter 10 / 0 again. Now, a more helpful message is printed. The user is 
•	asked for more input, and the program continues executing normally. 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	#include "Calculator.h" 
•	using namespace std; 
•	int main() 
•	{ 
•	double x = 0.0; 
•	double y = 0.0; 
•	double result = 0.0; 
•	char oper = '+'; 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b | 
•	a*b | a/b" << endl; 
•	Calculator c; 
•	while (true) 
•	{ 
•	cin >> x >> oper >> y; 
•	if (oper == '/' && y == 0) 
•	{ 
•	cout << "Math error: Attempted to divide by zero!" << endl; 
•	continue; 
•	} 
•	else 
•	{ 
•	result = c.Calculate(x, oper, y); 
•	} 
•	cout << "Result " << "of " << x << oper << y << " is: " << 
•	result << endl; 
•	} 
•	return 0; 
•	}７ Note 
•	When you edit code while in debugging mode, there's a risk of code 
•	becoming stale. This happens when the debugger is still running your old 
•	code, and has not yet updated it with your changes. The debugger displays a 
•	dialog to inform you when this happens. Sometimes, you may need to press 
•	F5 to refresh the code being executed. In particular, if you make a change 
•	inside a function while the point of execution is inside that function, you need 
•	to step out of the function, then back into it again to get the updated code. If 
•	that doesn't work and you see an error message, you can stop debugging by 
•	clicking on the red square in the toolbar under the menus at the top of the 
•	IDE, then start debugging again by entering F5 or by choosing the green 
•	"play" arrow beside the stop button on the toolbar. 
•	Another reason edit and continue may fail is if you see a message that says 
•	"The Require source files to exactly match the original version setting under 
•	Debug->Options->General needs to be enabled..." To fix this, from the main 
•	menu select Tools > Options > Debugging > General and ensure that 
•	Require source files to exactly match the original version is checked. 
•	Understanding the Run and Debug shortcuts 
•	F5, or Debug > Start Debugging, starts a debugging session, if one isn't 
•	already active, and runs the program until a breakpoint is hit or the 
•	program needs user input. If no user input is needed and no breakpoint 
•	is available to hit, the program terminates and the console window closes 
•	itself when the program finishes running. If your program outputs to the 
•	console, use Ctrl+F5 or set a breakpoint before you press F5 to keep the 
•	window open. 
•	Ctrl+F5, or Debug > Start Without Debugging, runs the application 
•	without going into debug mode. This is slightly faster than debugging, 
•	and the console window stays open after the program finishes executing. 
•	F10, known as Step Over, lets you iterate through code, line-by-line, and 
•	visualize how the code is run and what variable values are at each step of 
•	execution.F11, known as Step Into, works similarly to Step Over, except it steps into 
•	any functions called on the line of execution. For example, if the line 
•	being executed calls a function, pressing F11 moves the pointer into the 
•	body of the function, so you can follow the function's code being run 
•	before coming back to the line you started at. Pressing F10 steps over the 
•	function call and just moves to the next line; the function call still 
•	happens, but the program doesn't pause to show you what it's doing. 
•	Close the app 
•	If it's still running, close the console window to stop the calculator app. 
•	Add Git source control 
•	Now that you've created an app, you might want to add it to a Git repository. We've got 
•	you covered. Visual Studio makes that process easy with Git tools you can use directly 
•	from the IDE. 
•	 Tip 
•	Git is the most widely used modern version control system, so whether you're a 
•	professional developer or you're learning how to code, Git can be very useful. If 
•	you're new to Git, the https://git-scm.com/ website is a good place to start. 
•	There, you can find cheat sheets, a popular online book, and Git Basics videos. 
•	To associate your code with Git, you start by creating a new Git repository where your 
•	code is located. Here's how: 
•	1. In the status bar at the bottom-right corner of Visual Studio, select Add to Source 
•	Control, and then select Git. 
•	2. In the Create a Git repository dialog box, sign in to GitHub.The repository name auto-populates based on your folder location. By default, 
•	your new repository is private, which means you're the only one who can access it. 
•	 Tip 
•	Whether your repository is public or private, it's best to have a remote backup 
•	of your code stored securely on GitHub. Even if you aren't working with a 
•	team, a remote repository makes your code available to you from any 
•	computer. 
•	3. Select Create and Push. 
•	After you create your repository, status details appear in the status bar. 
•	The first icon with the arrows shows how many outgoing/incoming commits are in 
•	your current branch. You can use this icon to pull any incoming commits or push 
•	any outgoing commits. You can also choose to view these commits first. To do so, 
•	select the icon, and then select View Outgoing/Incoming.Feedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	The second icon with the pencil shows the number of uncommitted changes to 
•	your code. You can select this icon to view those changes in the Git Changes 
•	window. 
•	To learn more about how to use Git with your app, see the Visual Studio version control 
•	documentation. 
•	Congratulations! You completed the code for the calculator app, built and debugged it, 
•	and added it to a repo, all in Visual Studio. 
•	Learn more about Visual Studio for C++ 
•	The finished app 
•	Next steps 
•	 Yes 
•	 NoGet started with C++/WinRT 
•	Article • 02/13/2023 
•	） Important 
•	For info about setting up Visual Studio for C++/WinRT development—including 
•	installing and using the C++/WinRT Visual Studio Extension (VSIX) and the NuGet 
•	package (which together provide project template and build support)—see Visual 
•	Studio support for C++/WinRT. 
•	To get you up to speed with using C++/WinRT, this topic walks through a simple code 
•	example based on a new Windows Console Application (C++/WinRT) project. This 
•	topic also shows how to add C++/WinRT support to a Windows Desktop application 
•	project. 
•	７ Note 
•	While we recommend that you develop with the latest versions of Visual Studio and 
•	the Windows SDK, if you're using Visual Studio 2017 (version 15.8.0 or later), and 
•	targeting the Windows SDK version 10.0.17134.0 (Windows 10, version 1803), then 
•	a newly created C++/WinRT project may fail to compile with the error "error C3861: 
•	'from_abi': identifier not found", and with other errors originating in base.h. The 
•	solution is to either target a later (more conformant) version of the Windows SDK, 
•	or set project property C/C++ > Language > Conformance mode: No (also, if 
•	/permissive- appears in project property C/C++ > Language > Command Line 
•	under Additional Options, then delete it). 
•	A C++/WinRT quick-start 
•	Create a new Windows Console Application (C++/WinRT) project. 
•	Edit pch.h and main.cpp to look like this. 
•	C++/WinRT 
•	// pch.h 
•	#pragma once 
•	#include <winrt/Windows.Foundation.Collections.h>C++/WinRT 
•	Let's take the short code example above piece by piece, and explain what's going on in 
•	each part. 
•	C++/WinRT 
•	With the default project settings, the included headers come from the Windows SDK, 
•	inside the folder 
•	%WindowsSdkDir%Include<WindowsTargetPlatformVersion>\cppwinrt\winrt . Visual Studio 
•	includes that path in its IncludePath macro. But there's no strict dependency on the 
•	#include <winrt/Windows.Web.Syndication.h> 
•	#include <iostream> 
•	// main.cpp 
•	#include "pch.h" 
•	using namespace winrt; 
•	using namespace Windows::Foundation; 
•	using namespace Windows::Web::Syndication; 
•	int main() 
•	{ 
•	winrt::init_apartment(); 
•	Uri rssFeedUri{ L"https://blogs.windows.com/feed" }; 
•	SyndicationClient syndicationClient; 
•	syndicationClient.SetRequestHeader(L"User-Agent", L"Mozilla/5.0 
•	(compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)"); 
•	SyndicationFeed syndicationFeed = 
•	syndicationClient.RetrieveFeedAsync(rssFeedUri).get(); 
•	for (const SyndicationItem syndicationItem : syndicationFeed.Items()) 
•	{ 
•	winrt::hstring titleAsHstring = syndicationItem.Title().Text(); 
•	// A workaround to remove the trademark symbol from the title 
•	string, because it causes issues in this case. 
•	std::wstring titleAsStdWstring{ titleAsHstring.c_str() }; 
•	titleAsStdWstring.erase(remove(titleAsStdWstring.begin(), 
•	titleAsStdWstring.end(), L'™'), titleAsStdWstring.end()); 
•	titleAsHstring = titleAsStdWstring; 
•	std::wcout << titleAsHstring.c_str() << std::endl; 
•	} 
•	} 
•	#include <winrt/Windows.Foundation.Collections.h> 
•	#include <winrt/Windows.Web.Syndication.h>Windows SDK, because your project (via the cppwinrt.exe tool) generates those same 
•	headers into your project's $(GeneratedFilesDir) folder. They'll be loaded from that 
•	folder if they can't be found elsewhere, or if you change your project settings. 
•	The headers contain Windows APIs projected into C++/WinRT. In other words, for each 
•	Windows type, C++/WinRT defines a C++-friendly equivalent (called the projected type). 
•	A projected type has the same fully-qualified name as the Windows type, but it's placed 
•	in the C++ winrt namespace. Putting these includes in your precompiled header 
•	reduces incremental build times. 
•	） Important 
•	Whenever you want to use a type from a Windows namespaces, you must #include 
•	the corresponding C++/WinRT Windows namespace header file, as shown above. 
•	The corresponding header is the one with the same name as the type's namespace. 
•	For example, to use the C++/WinRT projection for the 
•	Windows::Foundation::Collections::PropertySet runtime class, include the 
•	winrt/Windows.Foundation.Collections.h header. 
•	It is common for a C++/WinRT projection header to automatically include related 
•	namespace header files. For example, winrt/Windows.Foundation.Collections.h 
•	includes winrt/Windows.Foundation.h . But you shouldn't rely on this behavior, since 
•	it's an implementation detail that changes over time. You must explicitly include 
•	any headers that you need. 
•	C++/WinRT 
•	using namespace winrt; 
•	using namespace Windows::Foundation; 
•	using namespace Windows::Web::Syndication; 
•	The using namespace directives are optional, but convenient. The pattern shown above 
•	for such directives (allowing unqualified name lookup for anything in the winrt 
•	namespace) is suitable for when you're beginning a new project and C++/WinRT is the 
•	only language projection you're using inside of that project. If, on the other hand, you're 
•	mixing C++/WinRT code with C++/CX and/or SDK application binary interface (ABI) 
•	code (you're either porting from, or interoperating with, one or both of those models), 
•	then see the topics Interop between C++/WinRT and C++/CX, Move to C++/WinRT 
•	from C++/CX, and Interop between C++/WinRT and the ABI. 
•	C++/WinRTwinrt::init_apartment(); 
•	The call to winrt::init_apartment initializes the thread in the Windows Runtime; by 
•	default, in a multithreaded apartment. The call also initializes COM. 
•	C++/WinRT 
•	Uri rssFeedUri{ L"https://blogs.windows.com/feed" }; 
•	SyndicationClient syndicationClient; 
•	Stack-allocate two objects: they represent the uri of the Windows blog, and a 
•	syndication client. We construct the uri with a simple wide string literal (see String 
•	handling in C++/WinRT for more ways you can work with strings). 
•	C++/WinRT 
•	SyndicationFeed syndicationFeed = 
•	syndicationClient.RetrieveFeedAsync(rssFeedUri).get(); 
•	SyndicationClient::RetrieveFeedAsync is an example of an asynchronous Windows 
•	Runtime function. The code example receives an asynchronous operation object from 
•	RetrieveFeedAsync, and it calls get on that object to block the calling thread and wait 
•	for the result (which is a syndication feed, in this case). For more about concurrency, and 
•	for non-blocking techniques, see Concurrency and asynchronous operations with 
•	C++/WinRT. 
•	C++/WinRT 
•	for (const SyndicationItem syndicationItem : syndicationFeed.Items()) { ... 
•	} 
•	SyndicationFeed.Items is a range, defined by the iterators returned from begin and end 
•	functions (or their constant, reverse, and constant-reverse variants). Because of this, you 
•	can enumerate Items with either a range-based for statement, or with the std::for_each 
•	template function. Whenever you iterate over a Windows Runtime collection like this, 
•	you'll need to #include <winrt/Windows.Foundation.Collections.h> . 
•	C++/WinRT 
•	winrt::hstring titleAsHstring = syndicationItem.Title().Text(); 
•	// Omitted: there's a little bit of extra work here to remove the trademark 
•	symbol from the title text.std::wcout << titleAsHstring.c_str() << std::endl; 
•	Gets the feed's title text, as a winrt::hstring object (more details in String handling in 
•	C++/WinRT). The hstring is then output, via the c_str function, which reflects the pattern 
•	used with C++ Standard Library strings. 
•	As you can see, C++/WinRT encourages modern, and class-like, C++ expressions such 
•	as syndicationItem.Title().Text() . This is a different, and cleaner, programming style 
•	from traditional COM programming. You don't need to directly initialize COM, nor work 
•	with COM pointers. 
•	Nor do you need to handle HRESULT return codes. C++/WinRT converts error HRESULTs 
•	to exceptions such as winrt::hresult-error for a natural and modern programming style. 
•	For more info about error-handling, and code examples, see Error handling with 
•	C++/WinRT. 
•	Modify a Windows Desktop application project 
•	to add C++/WinRT support 
•	Some desktop projects (for example, the WinUI 3 templates in Visual Studio) have 
•	C++/WinRT support built in. 
•	But this section shows you how you can add C++/WinRT support to any Windows 
•	Desktop application project that you might have. If you don't have an existing Windows 
•	Desktop application project, then you can follow along with these steps by first creating 
•	one. For example, open Visual Studio and create a Visual C++ > Windows Desktop > 
•	Windows Desktop Application project. 
•	You can optionally install the C++/WinRT Visual Studio Extension (VSIX) and the 
•	NuGet package. For details, see Visual Studio support for C++/WinRT. 
•	Set project properties 
•	Go to project property General > Windows SDK Version, and select All Configurations 
•	and All Platforms. Ensure that Windows SDK Version is set to 10.0.17134.0 (Windows 
•	10, version 1803) or greater. 
•	Confirm that you're not affected by Why won't my new project compile?. 
•	Because C++/WinRT uses features from the C++17 standard, set project property 
•	C/C++ > Language > C++ Language Standard to ISO C++17 Standard (/std:c++17).The precompiled header 
•	The default project template creates a precompiled header for you, named either 
•	framework.h , or stdafx.h . Rename that to pch.h . If you have a stdafx.cpp file, then 
•	rename that to pch.cpp . Set project property C/C++ > Precompiled Headers > 
•	Precompiled Header to Create (/Yc), and Precompiled Header File to pch.h. 
•	Find and replace all #include "framework.h" (or #include "stdafx.h" ) with #include 
•	"pch.h" . 
•	In pch.h , include winrt/base.h . 
•	C++/WinRT 
•	// pch.h 
•	... 
•	#include <winrt/base.h> 
•	Linking 
•	The C++/WinRT language projection depends on certain Windows Runtime free (non 
•	member) functions, and entry points, that require linking to the WindowsApp.lib 
•	umbrella library. This section describes three ways of satisfying the linker. 
•	The first option is to add to your Visual Studio project all of the C++/WinRT MSBuild 
•	properties and targets. To do this, install the Microsoft.Windows.CppWinRT NuGet 
•	package into your project. Open the project in Visual Studio, click Project > Manage 
•	NuGet Packages... > Browse, type or paste Microsoft.Windows.CppWinRT in the search 
•	box, select the item in search results, and then click Install to install the package for that 
•	project. 
•	You can also use project link settings to explicitly link WindowsApp.lib . Or, you can do it 
•	in source code (in pch.h , for example) like this. 
•	C++/WinRT 
•	#pragma comment(lib, "windowsapp") 
•	You can now compile and link, and add C++/WinRT code to your project (for example, 
•	code similar to that shown in the A C++/WinRT quick-start section, above). 
•	The three main scenarios for C++/WinRTAs you use and become familiar with C++/WinRT, and work through the rest of the 
•	documentation here, you'll likely notice that there are three main scenarios, as described 
•	in the following sections. 
•	Consuming Windows APIs and types 
•	In other words, using, or calling APIs. For example, making API calls to communicate 
•	using Bluetooth; to stream and present video; to integrate with the Windows shell; and 
•	so on. C++/WinRT fully and uncompromisingly supports this category of scenario. For 
•	more info, see Consume APIs with C++/WinRT. 
•	Authoring Windows APIs and types 
•	In other words, producing APIs and types. For example, producing the kinds of APIs 
•	described in the section above; or the graphics APIs; the storage and file system APIs; 
•	the networking APIs, and so on. For more info, see Author APIs with C++/WinRT. 
•	Authoring APIs with C++/WinRT is a little more involved than consuming them, because 
•	you must use IDL to define the shape of the API before you can implement it. There's a 
•	walkthrough of doing that in XAML controls; bind to a C++/WinRT property. 
•	XAML applications 
•	This scenario is about building applications and controls on the XAML UI framework. 
•	Working in a XAML application amounts to a combination of consuming and authoring. 
•	But since XAML is the dominant UI framework on Windows today, and its influence over 
•	the Windows Runtime is proportionate to that, it deserves its own category of scenario. 
•	Be aware that XAML works best with programming languages that offer reflection. In 
•	C++/WinRT, you sometimes have to do a little extra work in order to interoperate with 
•	the XAML framework. All of those cases are covered in the documentation. Good places 
•	to start are XAML controls; bind to a C++/WinRT property and XAML custom 
•	(templated) controls with C++/WinRT. 
•	Sample apps written in C++/WinRT 
•	See Where can I find C++/WinRT sample apps?. 
•	Important APIsFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	SyndicationClient::RetrieveFeedAsync method 
•	SyndicationFeed.Items property 
•	winrt::hstring struct 
•	winrt::hresult-error struct 
•	C++/CX 
•	Error handling with C++/WinRT 
•	Interop between C++/WinRT and C++/CX 
•	Interop between C++/WinRT and the ABI 
•	Move to C++/WinRT from C++/CX 
•	String handling in C++/WinRT 
•	Related topics 
•	 Yes 
•	 NoFeedback 
•	Was this page helpful? 
•	Get help at Microsoft Q&A 
•	Get Started with Win32 and C++ 
•	Article • 01/27/2022 
•	The aim of this Get Started series is to teach you how to write a desktop program in 
•	C++ using Win32 and COM APIs. 
•	In the first module, you'll learn step-by-step how to create and show a window. Later 
•	modules will introduce the Component Object Model (COM), graphics and text, and 
•	user input. 
•	For this series, it is assumed that you have a good working knowledge of C++ 
•	programming. No previous experience with Windows programming is assumed. If you 
•	are new to C++, learning material is available in the C++ language documentation . 
•	Topic 
•	Description 
•	Intro to Win32 
•	programming in C++ 
•	This section describes some of the basic terminology and coding 
•	conventions used in Windows programming. 
•	Module 1. Your First 
•	Windows Program 
•	In this module, you will create a simple Windows program that 
•	shows a blank window. 
•	Module 2. Using COM in 
•	Your Windows Program 
•	This module introduces the Component Object Model (COM), 
•	which underlies many of the modern Windows APIs. 
•	Module 3. Windows 
•	Graphics 
•	This module introduces the Windows graphics architecture, with a 
•	focus on Direct2D. 
•	Module 4. User Input 
•	This module describes mouse and keyboard input. 
•	Sample Code 
•	Contains links to download the sample code for this series. 
•	In this section 
•	ﾂ Yes 
•	ﾄ NoCreate a simple Universal Windows 
•	Platform (UWP) game with DirectX 
•	Article • 10/20/2022 
•	In this set of tutorials, you'll learn how to use DirectX and C++/WinRT to create the basic 
•	Universal Windows Platform (UWP) sample game named Simple3DGameDX. The 
•	gameplay takes place in a simple first-person 3D shooting gallery. 
•	７ Note 
•	The link from which you can download the Simple3DGameDX sample game itself is 
•	Direct3D sample game. The C++/WinRT source code is in the folder named 
•	cppwinrt . For info about other UWP sample apps, see Sample applications for 
•	Windows development. 
•	These tutorials cover all of the major parts of a game, including the processes for 
•	loading assets such as arts and meshes, creating a main game loop, implementing a 
•	simple rendering pipeline, and adding sound and controls. 
•	You'll also see UWP game development techniques and considerations. We'll focus on 
•	key UWP DirectX game development concepts, and call out Windows-Runtime-specific 
•	considerations around those concepts. 
•	Objective 
•	To learn about the basic concepts and components of a UWP DirectX game, and to 
•	become more comfortable designing UWP games with DirectX. 
•	What you need to know 
•	For this tutorial, you need to be familiar with these subjects. 
•	C++/WinRT. C++/WinRT is a standard modern C++17 language projection for 
•	Windows APIs, implemented as a header-file-based library, and designed to 
•	provide you with first-class access to the modern Windows APIs. 
•	Basic linear algebra and Newtonian physics concepts. 
•	Basic graphics programming terminology. 
•	Basic Windows programming concepts. 
•	Basic familiarity with the Direct2D and Direct3D 11 APIs.The Simple3DGameDX sample game implements a simple first-person 3D shooting 
•	gallery, where the player fires balls at moving targets. Hitting each target awards a set 
•	number of points, and the player can progress through 6 levels of increasing challenge. 
•	At the end of the levels, the points are tallied, and the player is awarded a final score. 
•	The sample demonstrates these game concepts. 
•	Interoperation between DirectX 11.1 and the Windows Runtime 
•	A first-person 3D perspective and camera 
•	Stereoscopic 3D effects 
•	Collision-detection between objects in 3D 
•	Handling player input for mouse, touch, and Xbox controller controls 
•	Audio mixing and playback 
•	A basic game state-machine 
•	Topic 
•	Description 
•	Set up the 
•	game project 
•	The first step in developing your game is to set up a project in Microsoft Visual 
•	Studio. After you've configured a project specifically for game development, you 
•	could later re-use it as a kind of template. 
•	Define the 
•	game's UWP 
•	app framework 
•	The first step in coding a Universal Windows Platform (UWP) game is building 
•	the framework that lets the app object interact with Windows. 
•	Game flow 
•	management 
•	Define the high-level state machine to enable player and system interaction. 
•	Learn how UI interacts with the overall game's state machine and how to create 
•	event handlers for UWP games. 
•	Direct3D UWP shooting gallery sampleTopic 
•	Description 
•	Define the 
•	main game 
•	object 
•	Now, we look at the details of the sample game's main object and how the rules 
•	it implements translate into interactions with the game world. 
•	Rendering 
•	framework I: 
•	Intro to 
•	rendering 
•	Learn how to develop the rendering pipeline to display graphics. Intro to 
•	rendering. 
•	Rendering 
•	framework II: 
•	Game 
•	rendering 
•	Learn how to assemble the rendering pipeline to display graphics. Game 
•	rendering, set up and prepare data. 
•	Add a user 
•	interface 
•	Learn how to add a 2D user interface overlay to a DirectX UWP game. 
•	Add controls 
•	Now, we take a look at how the sample game implements move-look controls 
•	in a 3-D game, and how to develop basic touch, mouse, and game controller 
•	controls. 
•	Add sound 
•	Develop a simple sound engine using XAudio2 APIs to playback game music 
•	and sound effects. 
•	Extend the 
•	sample game 
•	Learn how to implement a XAML overlay for a UWP DirectX game.Create a console calculator in C++ 
•	Article • 10/08/2024 
•	The usual starting point for a C++ programmer is a "Hello, world!" application that runs 
•	on the command line. You start with that in this article, and then move on to something 
•	more challenging: a calculator app. 
•	Prerequisites 
•	Visual Studio with the Desktop development with C++ workload installed and 
•	running on your computer. To install it, see Install C++ support in Visual Studio. 
•	This tutorial demonstrates a feature called edit and continue which allows you to 
•	make changes to your code while the app is running. To enable edit and continue, 
•	from the main menu select Tools > Options > Debugging > General and ensure 
•	that Require source files to exactly match the original version is checked. 
•	Create your app project 
•	Visual Studio uses projects to organize the code for an app, and solutions to organize 
•	one or more projects. A project contains all the options, configurations, and rules used 
•	to build an app. It also manages the relationship between all the project's files and any 
•	external files. To create your app, first, create a new project and solution. 
•	1. Start Visual Studio--the Visual Studio Start dialog box appears. Select Create a new 
•	project to get started.2. In the Create a new project dialog, set the language dropdown to C++, set the 
•	platform dropdown to Windows, select Console App from the list of project types, 
•	then select Next. 
•	） Important 
•	Make sure you select the C++ version of the Console App template. It has the 
•	C++, Windows, and Console tags, and the icon has "++" in the corner.3. In the Configure your new project dialog box, select the Project name text box, 
•	name your new project CalculatorTutorial, then select Create. 
•	An empty C++ Windows console application 'Hello World' app is created. Console 
•	applications use a Windows console window to display output and accept user 
•	input. In Visual Studio, an editor window opens and shows the generated code: 
•	C++ 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	int main() 
•	{ 
•	std::cout << "Hello World!\n"; 
•	} 
•	// Run program: Ctrl + F5 or Debug > Start Without Debugging menu 
•	// Debug program: F5 or Debug > Start Debugging menu 
•	// Tips for Getting Started: 
•	// 1. Use the Solution Explorer window to add/manage files 
•	// 2. Use the Team Explorer window to connect to source control 
•	// 3. Use the Output window to see build output and other messages 
•	// 4. Use the Error List window to view errors 
•	// 5. Go to Project > Add New Item to create new code files, or 
•	Project > Add Existing Item to add existing code files to the project// 6. In the future, to open this project again, go to File > Open > 
•	Project and select the .sln file 
•	Verify that your new app builds and runs 
•	The template for a new Windows console application creates a simple C++ "Hello 
•	World" app. At this point, you can see how Visual Studio builds and runs the apps you 
•	create right from the IDE. 
•	1. To build your project, select Build Solution from the Build menu. The Output 
•	window shows the results of the build process. 
•	2. To run the code, on the menu bar, select Debug > Start without debugging 
•	(Ctrl+F5).A console window opens and your app runs within it. 
•	When you start a console app in Visual Studio, it runs your code, then prints "Press 
•	any key to close this window . . ." to give you a chance to see the output. 
•	Congratulations! You created your first "Hello, world!" console app in Visual Studio! 
•	3. Press a key to dismiss the console window and return to Visual Studio. 
•	You now have the tools to build and run your app after every change, to verify that the 
•	code still works as you expect. Later, we show you how to debug it if it doesn't. 
•	Now let's modify the code in this template to be a calculator app. 
•	1. Replace the contents of the CalculatorTutorial.cpp file with the following code so 
•	that it matches this example: 
•	C++ 
•	Edit the code 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	using namespace std; 
•	int main() 
•	{ 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b |Understanding the code: 
•	The #include statement brings in code in other files. Sometimes, you 
•	may see a filename surrounded by angle brackets like <iostream> . The 
•	angle brackets instruct the compiler to look for the iostream header file 
•	first in the standard system directories, and if not found, to look in 
•	directories specific to the project. Other times, you may see a filename 
•	surrounded by quotes like "someHeader.h" . The quotes instruct the 
•	compiler to skip looking in the standard system directories and instead 
•	only look in directories specific to the project. 
•	The using namespace std; tells the compiler to expect code from the 
•	C++ Standard Library to be used in this file. Without this line, each 
•	keyword from the library would have to be preceded with std:: to 
•	denote its scope. For instance, without that line, each reference to cout 
•	would be written as std::cout . The using statement is added to make it 
•	more convenient to access code in another namespace. 
•	The cout keyword is used to print to standard output in C++. The << 
•	operator tells the compiler to send whatever is to the right of it to the 
•	standard output. 
•	The endl keyword is like the Enter key; it ends the line and moves the 
•	cursor to the next line. It's a better practice to put a \n inside the string 
•	(contained by "" ) to do the same thing because endl always flushes the 
•	buffer which can hurt the performance of the program. But since this is a 
•	very small app, endl is used instead. 
•	All C++ statements must end with semicolons and all C++ applications 
•	must contain a main() function. This function is what the program runs at 
•	a*b | a/b" 
•	<< endl; 
•	return 0; 
•	} 
•	// Run program: Ctrl + F5 or Debug > Start Without Debugging menu 
•	// Debug program: F5 or Debug > Start Debugging menu 
•	// Tips for Getting Started: 
•	// 1. Use the Solution Explorer window to add/manage files 
•	// 2. Use the Team Explorer window to connect to source control 
•	// 3. Use the Output window to see build output and other messages 
•	// 4. Use the Error List window to view errors 
•	// 5. Go to Project > Add New Item to create new code files, or 
•	Project > Add Existing Item to add existing code files to the project 
•	// 6. In the future, to open this project again, go to File > Open > 
•	Project and select the .sln filethe start. All code must be accessible from main() in order to be used. 
•	2. To save the file, press Ctrl+S, or select the floppy disk icon in the toolbar under the 
•	menu bar. 
•	3. To run the application, press Ctrl+F5 or go to the Debug menu and select Start 
•	Without Debugging. You should see a console window appear that looks like this. 
•	4. Close the console window when you're done. 
•	Add code to do some math 
•	A class is like a blueprint for an object that does something. In this case, we define a 
•	calculator class to contain the math logic. 
•	Add a Calculator class 
•	1. Go to the Project menu and select Add Class. In the Class Name edit box, enter 
•	Calculator. Select OK. 
•	Two new files get added to your project. To save all your changed files at once, 
•	press Ctrl+Shift+S. It's a keyboard shortcut for File > Save All. There's also a 
•	toolbar button for Save All, an icon of two floppy disks, found beside the Savebutton. In general, it's good practice to do Save All frequently, so you don't miss 
•	saving any changes. 
•	The Add Class wizard creates .h and .cpp files that have the same name as the 
•	class. You can see a full list of your project files in the Solution Explorer window, 
•	visible on the side of the IDE. If the window isn't visible, open it from the menu bar 
•	via View > Solution Explorer. 
•	You can open a file by double-clicking it in the Solution Explorer window. Double 
•	click Calculator.h to open it. 
•	2. Replace the contents of Calculator.h with the following code so that the file now 
•	looks like this: 
•	C++ 
•	Understanding the code 
•	This code declares a new function called Calculate , which handles math 
•	operations for addition, subtraction, multiplication, and division. 
•	#pragma once 
•	class Calculator 
•	{ 
•	public: 
•	double Calculate(double x, char oper, double y); 
•	};C++ code is organized into header ( .h ) files and source ( .cpp ) files. 
•	Some other file extensions are supported by various compilers, but these 
•	are the main ones to know about. Functions and variables are normally 
•	declared, that is, given a name and a type, in header files, and 
•	implemented, or given a definition, in source files. To access code defined 
•	in another file, you can use #include "filename.h" , where filename.h is 
•	the name of the file that declares the variables or functions you want to 
•	use. 
•	It's good practice to organize your code into different files based on what 
•	it does, so it's easy to find the code you need later. In our case, we define 
•	the Calculator class separately from the file containing the main() 
•	function, but we plan to reference the Calculator class in main() . 
•	3. A green squiggle appears under Calculate because although the Calculate 
•	function is declared, it isn't defined. Hover over Calculate , click the down arrow on 
•	the screwdriver icon, and select Create definition of 'Calculate' in Calculator.cpp . 
•	This code is added to Calculator.cpp :Currently, it just returns 0.0. Let's change that. 
•	4. Switch to the Calculator.cpp file in the editor window. Replace the contents of 
•	Calculator::Calculate(double x, char oper, double y) with: 
•	C++ 
•	Understanding the code 
•	The function Calculate takes a number, an operator, and a second 
•	number. Then it performs the requested operation on the two numbers. 
•	The switch statement checks which operator was provided, and executes 
•	the case corresponding to that operation. The default: case is a fallback 
•	double Calculator::Calculate(double x, char oper, double y) 
•	{ 
•	switch(oper) 
•	{ 
•	case '+': 
•	return x + y; 
•	case '-': 
•	return x - y; 
•	case '*': 
•	return x * y; 
•	case '/': 
•	return x / y; 
•	default: 
•	return 0.0; 
•	} 
•	}in case the user types an operator that isn't handled by any of the 
•	preceding case statements. It's best to handle invalid user input in a 
•	more elegant way, but this is beyond the scope of this tutorial. 
•	The double keyword denotes a type of number that supports decimals. 
•	This type of number is called a floating-point number, and double means 
•	a floating point number that has extra precision. This way, the calculator 
•	can handle both decimal math and integer math. The Calculate function 
•	is required to always return a double-precision floating point number due 
•	to the double at the start of the code (this denotes the function's return 
•	type), which is why we return 0.0 in the default case. 
•	The .h file declares the function prototype, which tells the compiler 
•	upfront what parameters it requires, and what return type to expect from 
•	it. The .cpp file has all the implementation details of the function. 
•	If you build and run the code again at this point, it immediately exits after asking which 
•	operation to perform. So, modify the main function to do multiple calculations. 
•	1. Update the main function in CalculatorTutorial.cpp as follows: 
•	C++ 
•	Call the Calculator class member functions 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	#include "Calculator.h" 
•	using namespace std; 
•	int main() 
•	{ 
•	double x = 0.0; 
•	double y = 0.0; 
•	double result = 0.0; 
•	char oper = '+'; 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b | 
•	a*b | a/b" 
•	<< endl; 
•	Calculator c; 
•	while (true) 
•	{Understanding the code 
•	Since C++ programs always start at the main() function, we need to call 
•	our other code from there, so an #include statement is needed to make 
•	that code visible to our main() function. 
•	The variables x , y , oper , and result are declared to store the first 
•	number, second number, operator, and final result, respectively. It's 
•	always good practice to give them some initial values to avoid undefined 
•	behavior, which is what is done here. 
•	The Calculator c; line declares an object named c as an instance of the 
•	Calculator class. The class itself is just a blueprint for how calculators 
•	work; the object is the specific calculator that does the math. 
•	The while (true) statement is a loop. The code inside the loop executes 
•	over and over again as long as the condition inside the () holds true. 
•	Since the condition is simply listed as true , it's always true, so the loop 
•	runs forever. To close the program, the user must manually close the 
•	console window. Otherwise, the program always waits for new input. 
•	The cin keyword accepts input from the user. The input stream is smart 
•	enough to process a line of text entered in the console window and place 
•	it inside each of the variables listed, in order. 
•	The c.Calculate(x, oper, y); expression calls the Calculate function 
•	defined earlier, and supplies the entered input values and the requested 
•	operation. The function then returns a number that is stored in result . 
•	Finally, result is printed to the console and the user sees the result of 
•	the calculation. 
•	Now test the program again to make sure everything works properly. 
•	1. Press Ctrl+F5 to rebuild and start the app. 
•	2. Enter 5+5 , and press Enter. Verify that the result is 10. 
•	cin >> x >> oper >> y; 
•	result = c.Calculate(x, oper, y); 
•	cout << "Result " << "of " << x << oper << y << " is: " << 
•	result << endl; 
•	} 
•	return 0; 
•	} 
•	Build and test the code again3. Stop the program by closing the console window. 
•	Debug the app 
•	Since the user is free to type anything into the console window, let's make sure the 
•	calculator handles unexpected input. Instead of running the program, let's debug it so 
•	we can inspect what it's doing step-by-step. 
•	Run the app in the debugger 
•	1. In CalcuatorTutorial.cpp , set a breakpoint on the line: result = c.Calculate(x, 
•	oper, y); . To set the breakpoint, click next to the line in the gray vertical bar along 
•	the left edge of the editor window so that a red dot appears. 
•	Now when we debug the program, execution pauses at that line. We already have 
•	a rough idea that the program works for simple cases. Since we don't want to 
•	pause execution every time we call Calculate() , let's make the breakpoint 
•	conditional.2. Right-click the red dot that represents the breakpoint, and select Conditions. In 
•	the edit box for the condition, enter (y == 0) && (oper == '/') . Select the Close 
•	button to save the breakpoint condition. 
•	Now, execution pauses at the breakpoint when the app tries to divide by 0. 
•	3. To debug the program, press F5, or select the Local Windows Debugger debugger 
•	toolbar button that has the green arrow icon. In your console app, if you enter 
•	something like "5 - 0", the program behaves normally and keeps running. 
•	However, if you type "10 / 0", it pauses at the breakpoint. You can put any number 
•	of spaces between the operator and numbers: cin is smart enough to parse the 
•	input appropriately.Useful windows in the debugger 
•	When you debug your code, you may notice that some new windows appear. These 
•	windows can assist your debugging experience. Take a look at the Autos window. The 
•	Autos window shows you the current values of variables used at least three lines before 
•	and up to the current line. If you don't see the Autos window, from the main menu 
•	select Debug > Windows > Autos. 
•	To see all of the variables from that function, switch to the Locals window. Because this 
•	is a small function, the Autos and Locals window show the same variables. But you can 
•	modify the values of these variables in the Locals window while debugging to see what 
•	effect they would have on the program. In this case, we leave them alone. Open the 
•	Locals window by selecting Locals at the bottom of the Autos window, or by selecting 
•	from the main menu Debug > Windows > Locals.You can also hover over variables in the code to see their current values at the point 
•	where execution is currently paused. Make sure the editor window is in focus by clicking 
•	on it first. 
•	Continue debugging 
•	1. The yellow arrow on the left shows the current point of execution. The current line 
•	calls Calculate , so press F11 to Step Into the function. Now you're executing code 
•	in the body of the Calculate function. Be careful with Step Into because it steps 
•	into any functions on the line you're on, including standard library functions. It's 
•	fine to step into the standard library, but you may be more interested in focusing 
•	on your code instead of library code. 
•	2. Now that the point of execution is at the start of the Calculate function, press F10 
•	to move to the next line in the program's execution. F10 is also known as Step 
•	Over. You can use Step Over to move from line to line, without delving into the 
•	details of what is occurring in each part of the line. In general, you should use Step 
•	Over instead of Step Into unless you want to dive more deeply into code that is 
•	being called from elsewhere (as you did to reach the body of Calculate ). 
•	3. Continue using F10 to Step Over each line until you get back to the main() 
•	function in the other file, and stop on the cout line.The program is doing what's expected: it takes the first number, and divides it by 
•	the second. On the cout line, hover over the result variable or take a look at 
•	result in the Autos window. Its value is inf , which doesn't look right. 
•	Let's fix it. The cout line outputs whatever value is stored in result , so when you 
•	step one more line forward using F10, the console window displays: 
•	This result is because division by zero is undefined, so the program doesn't have a 
•	numerical answer for the requested operation. 
•	Fix the "divide by zero" error 
•	Let's handle division by zero more gracefully so that it's easier for the user to 
•	understand the problem. 
•	1. Make the following changes in CalculatorTutorial.cpp . You can leave the 
•	program running as you edit, thanks to a debugger feature called Edit andContinue. Add an if statement following cin >> x >> oper >> y; to check for 
•	division by zero and output a message to the user if it happens. Otherwise, the 
•	result is printed. 
•	C++ 
•	2. Press F5 once. Program execution continues until it has to pause to ask for user 
•	input. Enter 10 / 0 again. Now, a more helpful message is printed. The user is 
•	asked for more input, and the program continues executing normally. 
•	// CalculatorTutorial.cpp : This file contains the 'main' function. 
•	Program execution begins and ends there. 
•	// 
•	#include <iostream> 
•	#include "Calculator.h" 
•	using namespace std; 
•	int main() 
•	{ 
•	double x = 0.0; 
•	double y = 0.0; 
•	double result = 0.0; 
•	char oper = '+'; 
•	cout << "Calculator Console Application" << endl << endl; 
•	cout << "Please enter the operation to perform. Format: a+b | a-b | 
•	a*b | a/b" << endl; 
•	Calculator c; 
•	while (true) 
•	{ 
•	cin >> x >> oper >> y; 
•	if (oper == '/' && y == 0) 
•	{ 
•	cout << "Math error: Attempted to divide by zero!" << endl; 
•	continue; 
•	} 
•	else 
•	{ 
•	result = c.Calculate(x, oper, y); 
•	} 
•	cout << "Result " << "of " << x << oper << y << " is: " << 
•	result << endl; 
•	} 
•	return 0; 
•	}７ Note 
•	When you edit code while in debugging mode, there's a risk of code 
•	becoming stale. This happens when the debugger is still running your old 
•	code, and has not yet updated it with your changes. The debugger displays a 
•	dialog to inform you when this happens. Sometimes, you may need to press 
•	F5 to refresh the code being executed. In particular, if you make a change 
•	inside a function while the point of execution is inside that function, you need 
•	to step out of the function, then back into it again to get the updated code. If 
•	that doesn't work and you see an error message, you can stop debugging by 
•	clicking on the red square in the toolbar under the menus at the top of the 
•	IDE, then start debugging again by entering F5 or by choosing the green 
•	"play" arrow beside the stop button on the toolbar. 
•	Another reason edit and continue may fail is if you see a message that says 
•	"The Require source files to exactly match the original version setting under 
•	Debug->Options->General needs to be enabled..." To fix this, from the main 
•	menu select Tools > Options > Debugging > General and ensure that 
•	Require source files to exactly match the original version is checked. 
•	Understanding the Run and Debug shortcuts 
•	F5, or Debug > Start Debugging, starts a debugging session, if one isn't 
•	already active, and runs the program until a breakpoint is hit or the 
•	program needs user input. If no user input is needed and no breakpoint 
•	is available to hit, the program terminates and the console window closes 
•	itself when the program finishes running. If your program outputs to the 
•	console, use Ctrl+F5 or set a breakpoint before you press F5 to keep the 
•	window open. 
•	Ctrl+F5, or Debug > Start Without Debugging, runs the application 
•	without going into debug mode. This is slightly faster than debugging, 
•	and the console window stays open after the program finishes executing. 
•	F10, known as Step Over, lets you iterate through code, line-by-line, and 
•	visualize how the code is run and what variable values are at each step of 
•	execution.F11, known as Step Into, works similarly to Step Over, except it steps into 
•	any functions called on the line of execution. For example, if the line 
•	being executed calls a function, pressing F11 moves the pointer into the 
•	body of the function, so you can follow the function's code being run 
•	before coming back to the line you started at. Pressing F10 steps over the 
•	function call and just moves to the next line; the function call still 
•	happens, but the program doesn't pause to show you what it's doing. 
•	Close the app 
•	If it's still running, close the console window to stop the calculator app. 
•	Add Git source control 
•	Now that you've created an app, you might want to add it to a Git repository. We've got 
•	you covered. Visual Studio makes that process easy with Git tools you can use directly 
•	from the IDE. 
•	 Tip 
•	Git is the most widely used modern version control system, so whether you're a 
•	professional developer or you're learning how to code, Git can be very useful. If 
•	you're new to Git, the https://git-scm.com/ website is a good place to start. 
•	There, you can find cheat sheets, a popular online book, and Git Basics videos. 
•	To associate your code with Git, you start by creating a new Git repository where your 
•	code is located. Here's how: 
•	1. In the status bar at the bottom-right corner of Visual Studio, select Add to Source 
•	Control, and then select Git. 
•	2. In the Create a Git repository dialog box, sign in to GitHub.The repository name auto-populates based on your folder location. By default, 
•	your new repository is private, which means you're the only one who can access it. 
•	 Tip 
•	Whether your repository is public or private, it's best to have a remote backup 
•	of your code stored securely on GitHub. Even if you aren't working with a 
•	team, a remote repository makes your code available to you from any 
•	computer. 
•	3. Select Create and Push. 
•	After you create your repository, status details appear in the status bar. 
•	The first icon with the arrows shows how many outgoing/incoming commits are in 
•	your current branch. You can use this icon to pull any incoming commits or push 
•	any outgoing commits. You can also choose to view these commits first. To do so, 
•	select the icon, and then select View Outgoing/Incoming.Feedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	The second icon with the pencil shows the number of uncommitted changes to 
•	your code. You can select this icon to view those changes in the Git Changes 
•	window. 
•	To learn more about how to use Git with your app, see the Visual Studio version control 
•	documentation. 
•	Congratulations! You completed the code for the calculator app, built and debugged it, 
•	and added it to a repo, all in Visual Studio. 
•	Learn more about Visual Studio for C++ 
•	The finished app 
•	Next steps 
•	 Yes 
•	 NoGet started with C++/WinRT 
•	Article • 02/13/2023 
•	） Important 
•	For info about setting up Visual Studio for C++/WinRT development—including 
•	installing and using the C++/WinRT Visual Studio Extension (VSIX) and the NuGet 
•	package (which together provide project template and build support)—see Visual 
•	Studio support for C++/WinRT. 
•	To get you up to speed with using C++/WinRT, this topic walks through a simple code 
•	example based on a new Windows Console Application (C++/WinRT) project. This 
•	topic also shows how to add C++/WinRT support to a Windows Desktop application 
•	project. 
•	７ Note 
•	While we recommend that you develop with the latest versions of Visual Studio and 
•	the Windows SDK, if you're using Visual Studio 2017 (version 15.8.0 or later), and 
•	targeting the Windows SDK version 10.0.17134.0 (Windows 10, version 1803), then 
•	a newly created C++/WinRT project may fail to compile with the error "error C3861: 
•	'from_abi': identifier not found", and with other errors originating in base.h. The 
•	solution is to either target a later (more conformant) version of the Windows SDK, 
•	or set project property C/C++ > Language > Conformance mode: No (also, if 
•	/permissive- appears in project property C/C++ > Language > Command Line 
•	under Additional Options, then delete it). 
•	A C++/WinRT quick-start 
•	Create a new Windows Console Application (C++/WinRT) project. 
•	Edit pch.h and main.cpp to look like this. 
•	C++/WinRT 
•	// pch.h 
•	#pragma once 
•	#include <winrt/Windows.Foundation.Collections.h>C++/WinRT 
•	Let's take the short code example above piece by piece, and explain what's going on in 
•	each part. 
•	C++/WinRT 
•	With the default project settings, the included headers come from the Windows SDK, 
•	inside the folder 
•	%WindowsSdkDir%Include<WindowsTargetPlatformVersion>\cppwinrt\winrt . Visual Studio 
•	includes that path in its IncludePath macro. But there's no strict dependency on the 
•	#include <winrt/Windows.Web.Syndication.h> 
•	#include <iostream> 
•	// main.cpp 
•	#include "pch.h" 
•	using namespace winrt; 
•	using namespace Windows::Foundation; 
•	using namespace Windows::Web::Syndication; 
•	int main() 
•	{ 
•	winrt::init_apartment(); 
•	Uri rssFeedUri{ L"https://blogs.windows.com/feed" }; 
•	SyndicationClient syndicationClient; 
•	syndicationClient.SetRequestHeader(L"User-Agent", L"Mozilla/5.0 
•	(compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)"); 
•	SyndicationFeed syndicationFeed = 
•	syndicationClient.RetrieveFeedAsync(rssFeedUri).get(); 
•	for (const SyndicationItem syndicationItem : syndicationFeed.Items()) 
•	{ 
•	winrt::hstring titleAsHstring = syndicationItem.Title().Text(); 
•	// A workaround to remove the trademark symbol from the title 
•	string, because it causes issues in this case. 
•	std::wstring titleAsStdWstring{ titleAsHstring.c_str() }; 
•	titleAsStdWstring.erase(remove(titleAsStdWstring.begin(), 
•	titleAsStdWstring.end(), L'™'), titleAsStdWstring.end()); 
•	titleAsHstring = titleAsStdWstring; 
•	std::wcout << titleAsHstring.c_str() << std::endl; 
•	} 
•	} 
•	#include <winrt/Windows.Foundation.Collections.h> 
•	#include <winrt/Windows.Web.Syndication.h>Windows SDK, because your project (via the cppwinrt.exe tool) generates those same 
•	headers into your project's $(GeneratedFilesDir) folder. They'll be loaded from that 
•	folder if they can't be found elsewhere, or if you change your project settings. 
•	The headers contain Windows APIs projected into C++/WinRT. In other words, for each 
•	Windows type, C++/WinRT defines a C++-friendly equivalent (called the projected type). 
•	A projected type has the same fully-qualified name as the Windows type, but it's placed 
•	in the C++ winrt namespace. Putting these includes in your precompiled header 
•	reduces incremental build times. 
•	） Important 
•	Whenever you want to use a type from a Windows namespaces, you must #include 
•	the corresponding C++/WinRT Windows namespace header file, as shown above. 
•	The corresponding header is the one with the same name as the type's namespace. 
•	For example, to use the C++/WinRT projection for the 
•	Windows::Foundation::Collections::PropertySet runtime class, include the 
•	winrt/Windows.Foundation.Collections.h header. 
•	It is common for a C++/WinRT projection header to automatically include related 
•	namespace header files. For example, winrt/Windows.Foundation.Collections.h 
•	includes winrt/Windows.Foundation.h . But you shouldn't rely on this behavior, since 
•	it's an implementation detail that changes over time. You must explicitly include 
•	any headers that you need. 
•	C++/WinRT 
•	using namespace winrt; 
•	using namespace Windows::Foundation; 
•	using namespace Windows::Web::Syndication; 
•	The using namespace directives are optional, but convenient. The pattern shown above 
•	for such directives (allowing unqualified name lookup for anything in the winrt 
•	namespace) is suitable for when you're beginning a new project and C++/WinRT is the 
•	only language projection you're using inside of that project. If, on the other hand, you're 
•	mixing C++/WinRT code with C++/CX and/or SDK application binary interface (ABI) 
•	code (you're either porting from, or interoperating with, one or both of those models), 
•	then see the topics Interop between C++/WinRT and C++/CX, Move to C++/WinRT 
•	from C++/CX, and Interop between C++/WinRT and the ABI. 
•	C++/WinRTwinrt::init_apartment(); 
•	The call to winrt::init_apartment initializes the thread in the Windows Runtime; by 
•	default, in a multithreaded apartment. The call also initializes COM. 
•	C++/WinRT 
•	Uri rssFeedUri{ L"https://blogs.windows.com/feed" }; 
•	SyndicationClient syndicationClient; 
•	Stack-allocate two objects: they represent the uri of the Windows blog, and a 
•	syndication client. We construct the uri with a simple wide string literal (see String 
•	handling in C++/WinRT for more ways you can work with strings). 
•	C++/WinRT 
•	SyndicationFeed syndicationFeed = 
•	syndicationClient.RetrieveFeedAsync(rssFeedUri).get(); 
•	SyndicationClient::RetrieveFeedAsync is an example of an asynchronous Windows 
•	Runtime function. The code example receives an asynchronous operation object from 
•	RetrieveFeedAsync, and it calls get on that object to block the calling thread and wait 
•	for the result (which is a syndication feed, in this case). For more about concurrency, and 
•	for non-blocking techniques, see Concurrency and asynchronous operations with 
•	C++/WinRT. 
•	C++/WinRT 
•	for (const SyndicationItem syndicationItem : syndicationFeed.Items()) { ... 
•	} 
•	SyndicationFeed.Items is a range, defined by the iterators returned from begin and end 
•	functions (or their constant, reverse, and constant-reverse variants). Because of this, you 
•	can enumerate Items with either a range-based for statement, or with the std::for_each 
•	template function. Whenever you iterate over a Windows Runtime collection like this, 
•	you'll need to #include <winrt/Windows.Foundation.Collections.h> . 
•	C++/WinRT 
•	winrt::hstring titleAsHstring = syndicationItem.Title().Text(); 
•	// Omitted: there's a little bit of extra work here to remove the trademark 
•	symbol from the title text.std::wcout << titleAsHstring.c_str() << std::endl; 
•	Gets the feed's title text, as a winrt::hstring object (more details in String handling in 
•	C++/WinRT). The hstring is then output, via the c_str function, which reflects the pattern 
•	used with C++ Standard Library strings. 
•	As you can see, C++/WinRT encourages modern, and class-like, C++ expressions such 
•	as syndicationItem.Title().Text() . This is a different, and cleaner, programming style 
•	from traditional COM programming. You don't need to directly initialize COM, nor work 
•	with COM pointers. 
•	Nor do you need to handle HRESULT return codes. C++/WinRT converts error HRESULTs 
•	to exceptions such as winrt::hresult-error for a natural and modern programming style. 
•	For more info about error-handling, and code examples, see Error handling with 
•	C++/WinRT. 
•	Modify a Windows Desktop application project 
•	to add C++/WinRT support 
•	Some desktop projects (for example, the WinUI 3 templates in Visual Studio) have 
•	C++/WinRT support built in. 
•	But this section shows you how you can add C++/WinRT support to any Windows 
•	Desktop application project that you might have. If you don't have an existing Windows 
•	Desktop application project, then you can follow along with these steps by first creating 
•	one. For example, open Visual Studio and create a Visual C++ > Windows Desktop > 
•	Windows Desktop Application project. 
•	You can optionally install the C++/WinRT Visual Studio Extension (VSIX) and the 
•	NuGet package. For details, see Visual Studio support for C++/WinRT. 
•	Set project properties 
•	Go to project property General > Windows SDK Version, and select All Configurations 
•	and All Platforms. Ensure that Windows SDK Version is set to 10.0.17134.0 (Windows 
•	10, version 1803) or greater. 
•	Confirm that you're not affected by Why won't my new project compile?. 
•	Because C++/WinRT uses features from the C++17 standard, set project property 
•	C/C++ > Language > C++ Language Standard to ISO C++17 Standard (/std:c++17).The precompiled header 
•	The default project template creates a precompiled header for you, named either 
•	framework.h , or stdafx.h . Rename that to pch.h . If you have a stdafx.cpp file, then 
•	rename that to pch.cpp . Set project property C/C++ > Precompiled Headers > 
•	Precompiled Header to Create (/Yc), and Precompiled Header File to pch.h. 
•	Find and replace all #include "framework.h" (or #include "stdafx.h" ) with #include 
•	"pch.h" . 
•	In pch.h , include winrt/base.h . 
•	C++/WinRT 
•	// pch.h 
•	... 
•	#include <winrt/base.h> 
•	Linking 
•	The C++/WinRT language projection depends on certain Windows Runtime free (non 
•	member) functions, and entry points, that require linking to the WindowsApp.lib 
•	umbrella library. This section describes three ways of satisfying the linker. 
•	The first option is to add to your Visual Studio project all of the C++/WinRT MSBuild 
•	properties and targets. To do this, install the Microsoft.Windows.CppWinRT NuGet 
•	package into your project. Open the project in Visual Studio, click Project > Manage 
•	NuGet Packages... > Browse, type or paste Microsoft.Windows.CppWinRT in the search 
•	box, select the item in search results, and then click Install to install the package for that 
•	project. 
•	You can also use project link settings to explicitly link WindowsApp.lib . Or, you can do it 
•	in source code (in pch.h , for example) like this. 
•	C++/WinRT 
•	#pragma comment(lib, "windowsapp") 
•	You can now compile and link, and add C++/WinRT code to your project (for example, 
•	code similar to that shown in the A C++/WinRT quick-start section, above). 
•	The three main scenarios for C++/WinRTAs you use and become familiar with C++/WinRT, and work through the rest of the 
•	documentation here, you'll likely notice that there are three main scenarios, as described 
•	in the following sections. 
•	Consuming Windows APIs and types 
•	In other words, using, or calling APIs. For example, making API calls to communicate 
•	using Bluetooth; to stream and present video; to integrate with the Windows shell; and 
•	so on. C++/WinRT fully and uncompromisingly supports this category of scenario. For 
•	more info, see Consume APIs with C++/WinRT. 
•	Authoring Windows APIs and types 
•	In other words, producing APIs and types. For example, producing the kinds of APIs 
•	described in the section above; or the graphics APIs; the storage and file system APIs; 
•	the networking APIs, and so on. For more info, see Author APIs with C++/WinRT. 
•	Authoring APIs with C++/WinRT is a little more involved than consuming them, because 
•	you must use IDL to define the shape of the API before you can implement it. There's a 
•	walkthrough of doing that in XAML controls; bind to a C++/WinRT property. 
•	XAML applications 
•	This scenario is about building applications and controls on the XAML UI framework. 
•	Working in a XAML application amounts to a combination of consuming and authoring. 
•	But since XAML is the dominant UI framework on Windows today, and its influence over 
•	the Windows Runtime is proportionate to that, it deserves its own category of scenario. 
•	Be aware that XAML works best with programming languages that offer reflection. In 
•	C++/WinRT, you sometimes have to do a little extra work in order to interoperate with 
•	the XAML framework. All of those cases are covered in the documentation. Good places 
•	to start are XAML controls; bind to a C++/WinRT property and XAML custom 
•	(templated) controls with C++/WinRT. 
•	Sample apps written in C++/WinRT 
•	See Where can I find C++/WinRT sample apps?. 
•	Important APIsFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Get help at Microsoft Q&A 
•	SyndicationClient::RetrieveFeedAsync method 
•	SyndicationFeed.Items property 
•	winrt::hstring struct 
•	winrt::hresult-error struct 
•	C++/CX 
•	Error handling with C++/WinRT 
•	Interop between C++/WinRT and C++/CX 
•	Interop between C++/WinRT and the ABI 
•	Move to C++/WinRT from C++/CX 
•	String handling in C++/WinRT 
•	Related topics 
•	 Yes 
•	 NoFeedback 
•	Was this page helpful? 
•	Get help at Microsoft Q&A 
•	Get Started with Win32 and C++ 
•	Article • 01/27/2022 
•	The aim of this Get Started series is to teach you how to write a desktop program in 
•	C++ using Win32 and COM APIs. 
•	In the first module, you'll learn step-by-step how to create and show a window. Later 
•	modules will introduce the Component Object Model (COM), graphics and text, and 
•	user input. 
•	For this series, it is assumed that you have a good working knowledge of C++ 
•	programming. No previous experience with Windows programming is assumed. If you 
•	are new to C++, learning material is available in the C++ language documentation . 
•	Topic 
•	Description 
•	Intro to Win32 
•	programming in C++ 
•	This section describes some of the basic terminology and coding 
•	conventions used in Windows programming. 
•	Module 1. Your First 
•	Windows Program 
•	In this module, you will create a simple Windows program that 
•	shows a blank window. 
•	Module 2. Using COM in 
•	Your Windows Program 
•	This module introduces the Component Object Model (COM), 
•	which underlies many of the modern Windows APIs. 
•	Module 3. Windows 
•	Graphics 
•	This module introduces the Windows graphics architecture, with a 
•	focus on Direct2D. 
•	Module 4. User Input 
•	This module describes mouse and keyboard input. 
•	Sample Code 
•	Contains links to download the sample code for this series. 
•	In this section 
•	ﾂ Yes 
•	ﾄ NoCreating an MFC Application 
•	Article • 02/14/2023 
•	An MFC application is an executable application for Windows that is based on the 
•	Microsoft Foundation Class (MFC) Library. MFC executables generally fall into five types: 
•	standard Windows applications, dialog boxes, forms-based applications, Explorer-style 
•	applications, and Web browser-style applications. For more information, see: 
•	Using the Classes to Write Windows Applications 
•	Creating and Displaying Dialog Boxes 
•	Creating a Forms-Based MFC Application 
•	Creating a File Explorer-Style MFC Application 
•	Creating a Web Browser-Style MFC Application 
•	The MFC Application Wizard generates the appropriate classes and files for any of these 
•	types of applications, depending on the options you select in the wizard. 
•	The easiest way to create an MFC application is to use the MFC Application Wizard (MFC 
•	App project in Visual Studio 2019). To create an MFC console application (a command 
•	line program that uses MFC libraries but runs in the console window), use the Windows 
•	Desktop Wizard and choose the Console Application and MFC Headers options. 
•	To create an MFC forms or dialog-based 
•	application 
•	1. From the main menu, choose File > New > Project. 
•	2. Enter "MFC" into the search box and then choose MFC App from the result list. 
•	3. Modify the defaults as needed, then press Create to open the MFC Application 
•	Wizard. 
•	4. Modify the configuration values as needed, then press Finish. 
•	For more information, see Creating a forms-based MFC application.To create an MFC console application 
•	An MFC console application is a command-line program that uses MFC libraries but 
•	runs in the console window. 
•	1. From the main menu, choose File > New > Project. 
•	2. Enter "Desktop" into the search box and then choose Windows Desktop Wizard 
•	from the result list, then press Next. 
•	3. Modify the project name and location as needed, then press Create to open the 
•	Windows Desktop Wizard. 
•	4. Check the MFC Headers box and set other values as needed, then press OK.Once your project is created, you can view the files created in Solution Explorer. For 
•	more information about the files the wizard creates for your project, see the project 
•	generated file ReadMe.txt. For more information about the file types, see File Types 
•	Created for Visual Studio C++ projects. 
•	See also 
•	Adding Functionality with Code Wizards 
•	Property PagesWalkthrough: Create and use your own 
•	Dynamic Link Library (C++) 
•	Article • 12/10/2021 
•	This step-by-step walkthrough shows how to use the Visual Studio IDE to create your 
•	own dynamic link library (DLL) written in Microsoft C++ (MSVC). Then it shows how to 
•	use the DLL from another C++ app. DLLs (also known as shared libraries in UNIX-based 
•	operating systems) are one of the most useful kinds of Windows components. You can 
•	use them as a way to share code and resources, and to shrink the size of your apps. 
•	DLLs can even make it easier to service and extend your apps. 
•	In this walkthrough, you'll create a DLL that implements some math functions. Then 
•	you'll create a console app that uses the functions from the DLL. You'll also get an 
•	introduction to some of the programming techniques and conventions used in Windows 
•	DLLs. 
•	This walkthrough covers these tasks: 
•	Create a DLL project in Visual Studio. 
•	Add exported functions and variables to the DLL. 
•	Create a console app project in Visual Studio. 
•	Use the functions and variables imported from the DLL in the console app. 
•	Run the completed app. 
•	Like a statically linked library, a DLL exports variables, functions, and resources by name. 
•	A client app imports the names to use those variables, functions, and resources. Unlike a 
•	statically linked library, Windows connects the imports in your app to the exports in a 
•	DLL at load time or at run time, instead of connecting them at link time. Windows 
•	requires extra information that isn't part of the standard C++ compilation model to 
•	make these connections. The MSVC compiler implements some Microsoft-specific 
•	extensions to C++ to provide this extra information. We explain these extensions as we 
•	go. 
•	This walkthrough creates two Visual Studio solutions; one that builds the DLL, and one 
•	that builds the client app. The DLL uses the C calling convention. It can be called from 
•	apps written in other programming languages, as long as the platform, calling 
•	conventions, and linking conventions match. The client app uses implicit linking, whereWindows links the app to the DLL at load-time. This linking lets the app call the DLL 
•	supplied functions just like the functions in a statically linked library. 
•	This walkthrough doesn't cover some common situations. The code doesn't show the 
•	use of C++ DLLs by other programming languages. It doesn't show how to create a 
•	resource-only DLL, or how to use explicit linking to load DLLs at run-time rather than at 
•	load-time. Rest assured, you can use MSVC and Visual Studio to do all these things. 
•	Even though the code of the DLL is written in C++, we've used C-style interfaces for the 
•	exported functions. There are two main reasons for this: First, many other languages 
•	support imports of C-style functions. The client app doesn't have to be written in C++. 
•	Second, it avoids some common pitfalls related to exported classes and member 
•	functions. It's easy to make hard-to-diagnose errors when exporting classes, since 
•	everything referred to within a class declaration has to have an instantiation that's also 
•	exported. This restriction applies to DLLs, but not static libraries. If your classes are plain 
•	old-data style, you shouldn't run into this issue. 
•	For links to more information about DLLs, see Create C/C++ DLLs in Visual Studio. For 
•	more information about implicit linking and explicit linking, see Determine which linking 
•	method to use. For information about creating C++ DLLs for use with programming 
•	languages that use C-language linkage conventions, see Exporting C++ functions for 
•	use in C-language executables. For information about how to create DLLs for use with 
•	.NET languages, see Calling DLL Functions from Visual Basic Applications. 
•	Prerequisites 
•	A computer that runs Microsoft Windows 7 or later versions. We recommend the 
•	latest version of Windows for the best development experience. 
•	A copy of Visual Studio. For information on how to download and install Visual 
•	Studio, see Install Visual Studio. When you run the installer, make sure that the 
•	Desktop development with C++ workload is checked. Don't worry if you didn't 
•	install this workload when you installed Visual Studio. You can run the installer 
•	again and install it now. 
•	An understanding of the basics of using the Visual Studio IDE. If you've used 
•	Windows desktop apps before, you can probably keep up. For an introduction, seeVisual Studio IDE feature tour. 
•	An understanding of enough of the fundamentals of the C++ language to follow 
•	along. Don't worry, we don't do anything too complicated. 
•	Create the DLL project 
•	In this set of tasks, you create a project for your DLL, add code, and build it. To begin, 
•	start the Visual Studio IDE, and sign in if you need to. The instructions vary slightly 
•	depending on which version of Visual Studio you're using. Make sure you have the 
•	correct version selected in the control in the upper left of this page. 
•	To create a DLL project in Visual Studio 2019 
•	1. On the menu bar, choose File > New > Project to open the Create a New Project 
•	dialog box. 
•	2. At the top of the dialog, set Language to C++, set Platform to Windows, and set 
•	Project type to Library. 
•	3. From the filtered list of project types, select Dynamic-link Library (DLL), and then 
•	choose Next. 
•	4. In the Configure your new project page, enter MathLibrary in the Project name 
•	box to specify a name for the project. Leave the default Location and Solution 
•	name values. Set Solution to Create new solution. Uncheck Place solution and 
•	project in the same directory if it's checked. 
•	5. Choose the Create button to create the project.When the solution is created, you can see the generated project and source files in the 
•	Solution Explorer window in Visual Studio. 
•	Right now, this DLL doesn't do very much. Next, you'll create a header file to declare the 
•	functions your DLL exports, and then add the function definitions to the DLL to make it 
•	more useful. 
•	To add a header file to the DLL 
•	1. To create a header file for your functions, on the menu bar, choose Project > Add 
•	New Item. 
•	2. In the Add New Item dialog box, in the left pane, select Visual C++. In the center 
•	pane, select Header File (.h). Specify MathLibrary.h as the name for the header file.3. Choose the Add button to generate a blank header file, which is displayed in a new 
•	editor window. 
•	4. Replace the contents of the header file with this code: 
•	C++ 
•	// MathLibrary.h - Contains declarations of math functions 
•	#pragma once 
•	#ifdef MATHLIBRARY_EXPORTS 
•	#define MATHLIBRARY_API __declspec(dllexport) 
•	#else 
•	#define MATHLIBRARY_API __declspec(dllimport) 
•	#endif 
•	// The Fibonacci recurrence relation describes a sequence F 
•	// where F(n) is { n = 0, a 
•	// { n = 1, bThis header file declares some functions to produce a generalized Fibonacci sequence, 
•	given two initial values. A call to fibonacci_init(1, 1) generates the familiar Fibonacci 
•	number sequence. 
•	Notice the preprocessor statements at the top of the file. The new project template for a 
•	DLL project adds <PROJECTNAME>_EXPORTS to the defined preprocessor macros. In this 
•	example, Visual Studio defines MATHLIBRARY_EXPORTS when your MathLibrary DLL project 
•	is built. 
•	When the MATHLIBRARY_EXPORTS macro is defined, the MATHLIBRARY_API macro sets the 
•	__declspec(dllexport) modifier on the function declarations. This modifier tells the 
•	compiler and linker to export a function or variable from the DLL for use by other 
•	applications. When MATHLIBRARY_EXPORTS is undefined, for example, when the header file 
•	is included by a client application, MATHLIBRARY_API applies the __declspec(dllimport) 
•	modifier to the declarations. This modifier optimizes the import of the function or 
•	variable in an application. For more information, see dllexport, dllimport. 
•	1. In Solution Explorer, right-click on the Source Files node and choose Add > New 
•	Item. Create a new .cpp file called MathLibrary.cpp, in the same way that you 
•	added a new header file in the previous step. 
•	// { n > 1, F(n-2) + F(n-1) 
•	// for some initial integral values a and b. 
•	// If the sequence is initialized F(0) = 1, F(1) = 1, 
•	// then this relation produces the well-known Fibonacci 
•	// sequence: 1, 1, 2, 3, 5, 8, 13, 21, 34, ... 
•	// Initialize a Fibonacci relation sequence 
•	// such that F(0) = a, F(1) = b. 
•	// This function must be called before any other function. 
•	extern "C" MATHLIBRARY_API void fibonacci_init( 
•	const unsigned long long a, const unsigned long long b); 
•	// Produce the next value in the sequence. 
•	// Returns true on success and updates current value and index; 
•	// false on overflow, leaves current value and index unchanged. 
•	extern "C" MATHLIBRARY_API bool fibonacci_next(); 
•	// Get the current value in the sequence. 
•	extern "C" MATHLIBRARY_API unsigned long long fibonacci_current(); 
•	// Get the position of the current value in the sequence. 
•	extern "C" MATHLIBRARY_API unsigned fibonacci_index(); 
•	To add an implementation to the DLL2. In the editor window, select the tab for MathLibrary.cpp if it's already open. If not, 
•	in Solution Explorer, double-click MathLibrary.cpp in the Source Files folder of the 
•	MathLibrary project to open it. 
•	3. In the editor, replace the contents of the MathLibrary.cpp file with the following 
•	code: 
•	C++ 
•	// MathLibrary.cpp : Defines the exported functions for the DLL. 
•	#include "pch.h" // use stdafx.h in Visual Studio 2017 and earlier 
•	#include <utility> 
•	#include <limits.h> 
•	#include "MathLibrary.h" 
•	// DLL internal state variables: 
•	static unsigned long long previous_; // Previous value, if any 
•	static unsigned long long current_; // Current sequence value 
•	static unsigned index_; // Current seq. position 
•	// Initialize a Fibonacci relation sequence 
•	// such that F(0) = a, F(1) = b. 
•	// This function must be called before any other function. 
•	void fibonacci_init( 
•	const unsigned long long a, 
•	const unsigned long long b) 
•	{ 
•	index_ = 0; 
•	current_ = a; 
•	previous_ = b; // see special case when initialized 
•	} 
•	// Produce the next value in the sequence. 
•	// Returns true on success, false on overflow. 
•	bool fibonacci_next() 
•	{ 
•	// check to see if we'd overflow result or position 
•	if ((ULLONG_MAX - previous_ < current_) || 
•	(UINT_MAX == index_)) 
•	{ 
•	return false; 
•	} 
•	// Special case when index == 0, just return b value 
•	if (index_ > 0) 
•	{ 
•	// otherwise, calculate next sequence value 
•	previous_ += current_; 
•	} 
•	std::swap(current_, previous_); 
•	++index_; 
•	return true; 
•	}To verify that everything works so far, compile the dynamic link library. To compile, 
•	choose Build > Build Solution on the menu bar. The DLL and related compiler output 
•	are placed in a folder called Debug directly below the solution folder. If you create a 
•	Release build, the output is placed in a folder called Release. The output should look 
•	something like this: 
•	Output 
•	Congratulations, you've created a DLL using Visual Studio! Next, you'll create a client 
•	app that uses the functions exported by the DLL. 
•	When you create a DLL, think about how client apps may use it. To call the functions or 
•	access the data exported by a DLL, client source code must have the declarations 
•	available at compile time. At link time, the linker requires information to resolve the 
•	function calls or data accesses. A DLL supplies this information in an import library, a file 
•	that contains information about how to find the functions and data, instead of the actual 
•	code. And at run time, the DLL must be available to the client, in a location that the 
•	operating system can find. 
•	// Get the current value in the sequence. 
•	unsigned long long fibonacci_current() 
•	{ 
•	return current_; 
•	} 
•	// Get the current index position in the sequence. 
•	unsigned fibonacci_index() 
•	{ 
•	return index_; 
•	} 
•	1>------ Build started: Project: MathLibrary, Configuration: Debug Win32 --- 
•	--- 
•	1>pch.cpp 
•	1>dllmain.cpp 
•	1>MathLibrary.cpp 
•	1>Generating Code... 
•	1> Creating library 
•	C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.lib and object 
•	C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.exp 
•	1>MathLibrary.vcxproj -> 
•	C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.dll 
•	========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ========== 
•	Create a client app that uses the DLLWhether it's your own or from a third-party, your client app project needs several pieces 
•	of information to use a DLL. It needs to find the headers that declare the DLL exports, 
•	the import libraries for the linker, and the DLL itself. One solution is to copy all of these 
•	files into your client project. For third-party DLLs that are unlikely to change while your 
•	client is in development, this method may be the best way to use them. However, when 
•	you also build the DLL, it's better to avoid duplication. If you make a local copy of DLL 
•	files that are under development, you may accidentally change a header file in one copy 
•	but not the other, or use an out-of-date library. 
•	To avoid out-of-sync code, we recommend you set the include path in your client 
•	project to include the DLL header files directly from your DLL project. Also, set the 
•	library path in your client project to include the DLL import libraries from the DLL 
•	project. And finally, copy the built DLL from the DLL project into your client build output 
•	directory. This step allows your client app to use the same DLL code you build. 
•	To create a client app in Visual Studio 
•	1. On the menu bar, choose File > New > Project to open the Create a new project 
•	dialog box. 
•	2. At the top of the dialog, set Language to C++, set Platform to Windows, and set 
•	Project type to Console. 
•	3. From the filtered list of project types, choose Console App then choose Next. 
•	4. In the Configure your new project page, enter MathClient in the Project name box 
•	to specify a name for the project. Leave the default Location and Solution name 
•	values. Set Solution to Create new solution. Uncheck Place solution and project in 
•	the same directory if it's checked. 
•	5. Choose the Create button to create the client project.A minimal console application project is created for you. The name for the main source 
•	file is the same as the project name that you entered earlier. In this example, it's named 
•	MathClient.cpp. You can build it, but it doesn't use your DLL yet. 
•	Next, to call the MathLibrary functions in your source code, your project must include 
•	the MathLibrary.h file. You could copy this header file into your client app project, then 
•	add it to the project as an existing item. This method can be a good choice for third 
•	party libraries. However, if you're working on the code for your DLL and your client at 
•	the same time, the header files could get out of sync. To avoid this issue, set the 
•	Additional Include Directories path in your project to include the path to the original 
•	header. 
•	To add the DLL header to your include path 
•	1. Right-click on the MathClient node in Solution Explorer to open the Property 
•	Pages dialog. 
•	2. In the Configuration drop-down box, select All Configurations if it's not already 
•	selected. 
•	3. In the left pane, select Configuration Properties > C/C++ > General. 
•	4. In the property pane, select the drop-down control next to the Additional Include 
•	Directories edit box, and then choose Edit.5. Double-click in the top pane of the Additional Include Directories dialog box to 
•	enable an edit control. Or, choose the folder icon to create a new entry. 
•	6. In the edit control, specify the path to the location of the MathLibrary.h header 
•	file. You can choose the ellipsis (...) control to browse to the correct folder. 
•	You can also enter a relative path from your client source files to the folder that 
•	contains the DLL header files. If you followed the directions to put your client 
•	project in a separate solution from the DLL, the relative path should look like this: 
•	..\..\MathLibrary\MathLibrary 
•	If your DLL and client projects are in the same solution, the relative path might 
•	look like this: 
•	..\MathLibrary 
•	When the DLL and client projects are in other folders, adjust the relative path to 
•	match. Or, use the ellipsis control to browse for the folder. 
•	7. After you've entered the path to the header file in the Additional Include 
•	Directories dialog box, choose the OK button. In the Property Pages dialog box, 
•	choose the OK button to save your changes. 
•	You can now include the MathLibrary.h file and use the functions it declares in your 
•	client application. Replace the contents of MathClient.cpp by using this code: 
•	C++This code can be compiled, but not linked. If you build the client app now, the error list 
•	shows several LNK2019 errors. That's because your project is missing some information: 
•	You haven't specified that your project has a dependency on the MathLibrary.lib library 
•	yet. And, you haven't told the linker how to find the MathLibrary.lib file. 
•	To fix this issue, you could copy the library file directly into your client app project. The 
•	linker would find and use it automatically. However, if both the library and the client app 
•	are under development, that might lead to changes in one copy that aren't shown in the 
•	other. To avoid this issue, you can set the Additional Dependencies property to tell the 
•	build system that your project depends on MathLibrary.lib. And, you can set an 
•	Additional Library Directories path in your project to include the path to the original 
•	library when you link. 
•	1. Right-click on the MathClient node in Solution Explorer and choose Properties to 
•	open the Property Pages dialog. 
•	2. In the Configuration drop-down box, select All Configurations if it's not already 
•	selected. It ensures that any property changes apply to both Debug and Release 
•	builds. 
•	3. In the left pane, select Configuration Properties > Linker > Input. In the property 
•	pane, select the drop-down control next to the Additional Dependencies edit box, 
•	and then choose Edit. 
•	// MathClient.cpp : Client app for MathLibrary DLL. 
•	// #include "pch.h" Uncomment for Visual Studio 2017 and earlier 
•	#include <iostream> 
•	#include "MathLibrary.h" 
•	int main() 
•	{ 
•	// Initialize a Fibonacci relation sequence. 
•	fibonacci_init(1, 1); 
•	// Write out the sequence values until overflow. 
•	do { 
•	std::cout << fibonacci_index() << ": " 
•	<< fibonacci_current() << std::endl; 
•	} while (fibonacci_next()); 
•	// Report count of values written before overflow. 
•	std::cout << fibonacci_index() + 1 << 
•	" Fibonacci sequence values fit in an " << 
•	"unsigned 64-bit integer." << std::endl; 
•	} 
•	To add the DLL import library to your project4. In the Additional Dependencies dialog, add MathLibrary.lib to the list in the top 
•	edit control. 
•	5. Choose OK to go back to the Property Pages dialog box. 
•	6. In the left pane, select Configuration Properties > Linker > General. In the 
•	property pane, select the drop-down control next to the Additional Library 
•	Directories edit box, and then choose Edit.7. Double-click in the top pane of the Additional Library Directories dialog box to 
•	enable an edit control. In the edit control, specify the path to the location of the 
•	MathLibrary.lib file. By default, it's in a folder called Debug directly under the DLL 
•	solution folder. If you create a release build, the file is placed in a folder called 
•	Release. You can use the $(IntDir) macro so that the linker can find your DLL, no 
•	matter which kind of build you create. If you followed the directions to put your 
•	client project in a separate solution from the DLL project, the relative path should 
•	look like this: 
•	..\..\MathLibrary\$(IntDir) 
•	If your DLL and client projects are in other locations, adjust the relative path to 
•	match.8. Once you've entered the path to the library file in the Additional Library 
•	Directories dialog box, choose the OK button to go back to the Property Pages 
•	dialog box. Choose OK to save the property changes. 
•	Your client app can now compile and link successfully, but it still doesn't have everything 
•	it needs to run. When the operating system loads your app, it looks for the MathLibrary 
•	DLL. If it can't find the DLL in certain system directories, the environment path, or the 
•	local app directory, the load fails. Depending on the operating system, you'll see an 
•	error message like this: 
•	One way to avoid this issue is to copy the DLL to the directory that contains your client 
•	executable as part of the build process. You can add a Post-Build Event to your project, 
•	to add a command that copies the DLL to your build output directory. The command 
•	specified here copies the DLL only if it's missing or has changed. It uses macros to copy 
•	to and from the Debug or Release locations, based on your build configuration. 
•	To copy the DLL in a post-build event 
•	1. Right-click on the MathClient node in Solution Explorer and choose Properties to 
•	open the Property Pages dialog.2. In the Configuration drop-down box, select All Configurations if it isn't already 
•	selected. 
•	3. In the left pane, select Configuration Properties > Build Events > Post-Build 
•	Event. 
•	4. In the property pane, select the edit control in the Command Line field. If you 
•	followed the directions to put your client project in a separate solution from the 
•	DLL project, then enter this command: 
•	xcopy /y /d "..\..\MathLibrary\$(IntDir)MathLibrary.dll" "$(OutDir)" 
•	If your DLL and client projects are in other directories, change the relative path to 
•	the DLL to match. 
•	5. Choose the OK button to save your changes to the project properties. 
•	Now your client app has everything it needs to build and run. Build the application by 
•	choosing Build > Build Solution on the menu bar. The Output window in Visual Studio 
•	should have something like the following example depending on your version of Visual 
•	Studio: 
•	Output 
•	1>------ Build started: Project: MathClient, Configuration: Debug Win32 ---- 
•	-- 
•	1>MathClient.cpp 
•	1>MathClient.vcxproj ->C:\Users\username\Source\Repos\MathClient\Debug\MathClient.exe 
•	1>1 File(s) copied 
•	========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ========== 
•	Congratulations, you've created an application that calls functions in your DLL. Now run 
•	your application to see what it does. On the menu bar, choose Debug > Start Without 
•	Debugging. Visual Studio opens a command window for the program to run in. The last 
•	part of the output should look like: 
•	Press any key to dismiss the command window. 
•	Now that you've created a DLL and a client application, you can experiment. Try setting 
•	breakpoints in the code of the client app, and run the app in the debugger. See what 
•	happens when you step into a library call. Add other functions to the library, or write 
•	another client app that uses your DLL. 
•	When you deploy your app, you must also deploy the DLLs it uses. The simplest way to 
•	make the DLLs that you build, or that you include from third parties, available is to put 
•	them in the same directory as your app. It's known as app-local deployment. For more 
•	information about deployment, see Deployment in Visual C++. 
•	See also 
•	Calling DLL Functions from Visual Basic ApplicationsWalkthrough: Create and use a static 
•	library 
•	Article • 10/29/2021 
•	This step-by-step walkthrough shows how to create a static library (.lib file) for use with 
•	C++ apps. Using a static library is a great way to reuse code. Rather than 
•	reimplementing the same routines in every app that requires the functionality, you write 
•	them one time in a static library and then reference it from the apps. Code linked from a 
•	static library becomes part of your app—you don't have to install another file to use the 
•	code. 
•	This walkthrough covers these tasks: 
•	Create a static library project 
•	Add a class to the static library 
•	Create a C++ console app that references the static library 
•	Use the functionality from the static library in the app 
•	Run the app 
•	Prerequisites 
•	An understanding of the fundamentals of the C++ language. 
•	Create a static library project 
•	The instructions for how to create the project vary depending on your version of Visual 
•	Studio. To see the documentation for your preferred version of Visual Studio, use the 
•	Version selector control. It's found at the top of the table of contents on this page. 
•	To create a static library project in Visual Studio 
•	1. On the menu bar, choose File > New > Project to open the Create a New Project 
•	dialog. 
•	2. At the top of the dialog, set Language to C++, set Platform to Windows, and set 
•	Project type to Library.3. From the filtered list of project types, select Windows Desktop Wizard, then 
•	choose Next. 
•	4. In the Configure your new project page, enter MathLibrary in the Project name 
•	box to specify a name for the project. Enter StaticMath in the Solution name box. 
•	Choose the Create button to open the Windows Desktop Project dialog. 
•	5. In the Windows Desktop Project dialog, under Application type, select Static 
•	Library (.lib). 
•	6. Under Additional options, uncheck the Precompiled header check box if it's 
•	checked. Check the Empty project box. 
•	7. Choose OK to create the project. 
•	1. To create a header file for a new class, right-click to open the shortcut menu for 
•	the MathLibrary project in Solution Explorer, and then choose Add > New Item. 
•	2. In the Add New Item dialog box, select Visual C++ > Code. In the center pane, 
•	select Header File (.h). Specify a name for the header file—for example, 
•	MathLibrary.h—and then choose the Add button. A nearly blank header file is 
•	displayed. 
•	3. Add a declaration for a class named Arithmetic to do common mathematical 
•	operations such as addition, subtraction, multiplication, and division. The code 
•	should resemble: 
•	C++ 
•	Add a class to the static library 
•	To add a class to the static library 
•	// MathLibrary.h 
•	#pragma once 
•	namespace MathLibrary 
•	{ 
•	class Arithmetic 
•	{ 
•	public: 
•	// Returns a + b 
•	static double Add(double a, double b); 
•	// Returns a - b 
•	static double Subtract(double a, double b);4. To create a source file for the new class, open the shortcut menu for the 
•	MathLibrary project in Solution Explorer, and then choose Add > New Item. 
•	5. In the Add New Item dialog box, in the center pane, select C++ File (.cpp). Specify 
•	a name for the source file—for example, MathLibrary.cpp—and then choose the 
•	Add button. A blank source file is displayed. 
•	6. Use this source file to implement the functionality for class Arithmetic . The code 
•	should resemble: 
•	C++ 
•	// Returns a * b 
•	static double Multiply(double a, double b); 
•	// Returns a / b 
•	static double Divide(double a, double b); 
•	}; 
•	} 
•	// MathLibrary.cpp 
•	// compile with: cl /c /EHsc MathLibrary.cpp 
•	// post-build command: lib MathLibrary.obj 
•	#include "MathLibrary.h" 
•	namespace MathLibrary 
•	{ 
•	double Arithmetic::Add(double a, double b) 
•	{ 
•	return a + b; 
•	} 
•	double Arithmetic::Subtract(double a, double b) 
•	{ 
•	return a - b; 
•	} 
•	double Arithmetic::Multiply(double a, double b) 
•	{ 
•	return a * b; 
•	} 
•	double Arithmetic::Divide(double a, double b) 
•	{ 
•	return a / b; 
•	} 
•	}7. To build the static library, select Build > Build Solution on the menu bar. The build 
•	creates a static library, MathLibrary.lib, that can be used by other programs. 
•	７ Note 
•	When you build on the Visual Studio command line, you must build the 
•	program in two steps. First, run cl /c /EHsc MathLibrary.cpp to compile the 
•	code and create an object file that's named MathLibrary.obj. (The cl 
•	command invokes the compiler, Cl.exe, and the /c option specifies compile 
•	without linking. For more information, see /c (Compile Without Linking).) 
•	Second, run lib MathLibrary.obj to link the code and create the static library 
•	MathLibrary.lib. (The lib command invokes the Library Manager, Lib.exe. For 
•	more information, see LIB Reference.) 
•	Create a C++ console app that references the 
•	static library 
•	To create a C++ console app that references the static 
•	library in Visual Studio 
•	1. In Solution Explorer, right-click on the top node, Solution 'StaticMath', to open 
•	the shortcut menu. Choose Add > New Project to open the Add a New Project 
•	dialog. 
•	2. At the top of the dialog, set the Project type filter to Console. 
•	3. From the filtered list of project types, choose Console App then choose Next. In 
•	the next page, enter MathClient in the Name box to specify a name for the project. 
•	4. Choose the Create button to create the client project. 
•	5. After you create a console app, an empty program is created for you. The name for 
•	the source file is the same as the name that you chose earlier. In the example, it's 
•	named MathClient.cpp . 
•	Use the functionality from the static library in 
•	the appTo use the functionality from the static library in the app 
•	1. Before you can use the math routines in the static library, you must reference it. 
•	Open the shortcut menu for the MathClient project in Solution Explorer, and then 
•	choose Add > Reference. 
•	2. The Add Reference dialog box lists the libraries that you can reference. The 
•	Projects tab lists the projects in the current solution and any libraries they 
•	reference. Open the Projects tab, select the MathLibrary check box, and then 
•	choose the OK button. 
•	3. To reference the MathLibrary.h header file, you must modify the included 
•	directories path. In Solution Explorer, right-click on MathClient to open the 
•	shortcut menu. Choose Properties to open the MathClient Property Pages dialog 
•	box. 
•	4. In the MathClient Property Pages dialog box, set the Configuration drop-down to 
•	All Configurations. Set the Platform drop-down to All Platforms. 
•	5. Select the Configuration Properties > C/C++ > General property page. In the 
•	Additional Include Directories property, specify the path of the MathLibrary 
•	directory, or browse for it. 
•	To browse for the directory path: 
•	a. Open the Additional Include Directories property value drop-down list, and 
•	then choose Edit. 
•	b. In the Additional Include Directories dialog box, double-click in the top of the 
•	text box. Then choose the ellipsis button (...) at the end of the line. 
•	c. In the Select Directory dialog box, navigate up a level, and then select the 
•	MathLibrary directory. Then choose the Select Folder button to save your 
•	selection. 
•	d. In the Additional Include Directories dialog box, choose the OK button. 
•	e. In the Property Pages dialog box, choose the OK button to save your changes 
•	to the project. 
•	6. You can now use the Arithmetic class in this app by including the #include 
•	"MathLibrary.h" header in your code. Replace the contents of MathClient.cpp with 
•	this code: 
•	C++7. To build the executable, choose Build > Build Solution on the menu bar. 
•	1. Make sure that MathClient is selected as the default project. To select it, right-click 
•	to open the shortcut menu for MathClient in Solution Explorer, and then choose 
•	Set as StartUp Project. 
•	2. To run the project, on the menu bar, choose Debug > Start Without Debugging. 
•	The output should resemble: 
•	Output 
•	// MathClient.cpp 
•	// compile with: cl /EHsc MathClient.cpp /link MathLibrary.lib 
•	#include <iostream> 
•	#include "MathLibrary.h" 
•	int main() 
•	{ 
•	double a = 7.4; 
•	int b = 99; 
•	std::cout << "a + b = " << 
•	MathLibrary::Arithmetic::Add(a, b) << std::endl; 
•	std::cout << "a - b = " << 
•	MathLibrary::Arithmetic::Subtract(a, b) << std::endl; 
•	std::cout << "a * b = " << 
•	MathLibrary::Arithmetic::Multiply(a, b) << std::endl; 
•	std::cout << "a / b = " << 
•	MathLibrary::Arithmetic::Divide(a, b) << std::endl; 
•	return 0; 
•	} 
•	Run the app 
•	To run the app 
•	a + b = 106.4 
•	a - b = -91.6 
•	a * b = 732.6 
•	a / b = 0.0747475 
•	See alsoWalkthrough: Creating and Using a Dynamic Link Library (C++) 
•	Desktop Applications (Visual C++)Walkthrough: Compile a C++/CLI 
•	program that targets the CLR in Visual 
•	Studio 
•	Article • 10/29/2021 
•	By using C++/CLI you can create C++ programs that use .NET classes as well as native 
•	C++ types. C++/CLI is intended for use in console applications and in DLLs that wrap 
•	native C++ code and make it accessible from .NET programs. To create a Windows user 
•	interface based on .NET, use C# or Visual Basic. 
•	For this procedure, you can type your own C++ program or use one of the sample 
•	programs. The sample program that we use in this procedure creates a text file named 
•	textfile.txt, and saves it to the project directory. 
•	Prerequisites 
•	An understanding of the fundamentals of the C++ language. 
•	In Visual Studio 2017 and later, C++/CLI support is an optional component. To 
•	install it, open the Visual Studio Installer from the Windows Start menu. Make sure 
•	that the Desktop development with C++ tile is checked, and in the Optional 
•	components section, also check C++/CLI Support. 
•	Create a new project 
•	The following steps vary depending on which version of Visual Studio you are using. To 
•	see the documentation for your preferred version of Visual Studio, use the Version 
•	selector control. It's found at the top of the table of contents on this page. 
•	To create a C++/CLI project in Visual Studio 
•	1. In Solution Explorer, right-click on the top to open the Create a New Project 
•	dialog box. 
•	2. At the top of the dialog, type CLR in the search box and then choose CLR Empty 
•	Project from the results list. 
•	3. Choose the Create button to create the project.Add a source file 
•	1. If Solution Explorer isn't visible, click Solution Explorer on the View menu. 
•	2. Add a new source file to the project: 
•	Right-click the Source Files folder in Solution Explorer, point to Add, and 
•	click New Item. 
•	Click C++ File (.cpp) and type a file name and then click Add. 
•	The .cpp file appears in the Source Files folder in Solution Explorer and a tabbed 
•	window appears where you type the code you want in that file. 
•	3. Click in the newly created tab in Visual Studio and type a valid Visual C++ 
•	program, or copy and paste one of the sample programs. 
•	For example, you can use the How to: Write a Text File (C++/CLI) sample program 
•	(in the File Handling and I/O node of the Programming Guide). 
•	If you use the sample program, notice that you use the gcnew keyword instead of 
•	new when creating a .NET object, and that gcnew returns a handle ( ^ ) rather than a 
•	pointer ( * ): 
•	StreamWriter^ sw = gcnew StreamWriter(fileName); 
•	For more information on C++/CLI syntax, see Component Extensions for Runtime 
•	Platforms. 
•	4. On the Build menu, click Build Solution. 
•	The Output window displays information about the compilation progress, such as 
•	the location of the build log and a message that indicates the build status. 
•	If you make changes and run the program without doing a build, a dialog box 
•	might indicate that the project is out of date. Select the checkbox on this dialog 
•	before you click OK if you want Visual Studio to always use the current versions of 
•	files instead of prompting you each time it builds the application. 
•	5. On the Debug menu, click Start without Debugging. 
•	6. If you used the sample program, when you run the program a command window is 
•	displayed that indicates the text file has been created. 
•	The textfile.txt text file is now located in your project directory. You can open this 
•	file by using Notepad.７ Note 
•	Choosing the empty CLR project template automatically set the /clr 
•	compiler option. To verify this, right-click the project in Solution Explorer and 
•	clicking Properties, and then check the Common Language Runtime support 
•	option in the General node of Configuration Properties. 
•	See also 
•	C++ Language Reference 
•	Projects and build systemsCreate a simple Universal Windows 
•	Platform (UWP) game with DirectX 
•	Article • 10/20/2022 
•	In this set of tutorials, you'll learn how to use DirectX and C++/WinRT to create the basic 
•	Universal Windows Platform (UWP) sample game named Simple3DGameDX. The 
•	gameplay takes place in a simple first-person 3D shooting gallery. 
•	７ Note 
•	The link from which you can download the Simple3DGameDX sample game itself is 
•	Direct3D sample game. The C++/WinRT source code is in the folder named 
•	cppwinrt . For info about other UWP sample apps, see Sample applications for 
•	Windows development. 
•	These tutorials cover all of the major parts of a game, including the processes for 
•	loading assets such as arts and meshes, creating a main game loop, implementing a 
•	simple rendering pipeline, and adding sound and controls. 
•	You'll also see UWP game development techniques and considerations. We'll focus on 
•	key UWP DirectX game development concepts, and call out Windows-Runtime-specific 
•	considerations around those concepts. 
•	Objective 
•	To learn about the basic concepts and components of a UWP DirectX game, and to 
•	become more comfortable designing UWP games with DirectX. 
•	What you need to know 
•	For this tutorial, you need to be familiar with these subjects. 
•	C++/WinRT. C++/WinRT is a standard modern C++17 language projection for 
•	Windows APIs, implemented as a header-file-based library, and designed to 
•	provide you with first-class access to the modern Windows APIs. 
•	Basic linear algebra and Newtonian physics concepts. 
•	Basic graphics programming terminology. 
•	Basic Windows programming concepts. 
•	Basic familiarity with the Direct2D and Direct3D 11 APIs.The Simple3DGameDX sample game implements a simple first-person 3D shooting 
•	gallery, where the player fires balls at moving targets. Hitting each target awards a set 
•	number of points, and the player can progress through 6 levels of increasing challenge. 
•	At the end of the levels, the points are tallied, and the player is awarded a final score. 
•	The sample demonstrates these game concepts. 
•	Interoperation between DirectX 11.1 and the Windows Runtime 
•	A first-person 3D perspective and camera 
•	Stereoscopic 3D effects 
•	Collision-detection between objects in 3D 
•	Handling player input for mouse, touch, and Xbox controller controls 
•	Audio mixing and playback 
•	A basic game state-machine 
•	Topic 
•	Description 
•	Set up the 
•	game project 
•	The first step in developing your game is to set up a project in Microsoft Visual 
•	Studio. After you've configured a project specifically for game development, you 
•	could later re-use it as a kind of template. 
•	Define the 
•	game's UWP 
•	app framework 
•	The first step in coding a Universal Windows Platform (UWP) game is building 
•	the framework that lets the app object interact with Windows. 
•	Game flow 
•	management 
•	Define the high-level state machine to enable player and system interaction. 
•	Learn how UI interacts with the overall game's state machine and how to create 
•	event handlers for UWP games. 
•	Direct3D UWP shooting gallery sampleTopic 
•	Description 
•	Define the 
•	main game 
•	object 
•	Now, we look at the details of the sample game's main object and how the rules 
•	it implements translate into interactions with the game world. 
•	Rendering 
•	framework I: 
•	Intro to 
•	rendering 
•	Learn how to develop the rendering pipeline to display graphics. Intro to 
•	rendering. 
•	Rendering 
•	framework II: 
•	Game 
•	rendering 
•	Learn how to assemble the rendering pipeline to display graphics. Game 
•	rendering, set up and prepare data. 
•	Add a user 
•	interface 
•	Learn how to add a 2D user interface overlay to a DirectX UWP game. 
•	Add controls 
•	Now, we take a look at how the sample game implements move-look controls 
•	in a 3-D game, and how to develop basic touch, mouse, and game controller 
•	controls. 
•	Add sound 
•	Develop a simple sound engine using XAudio2 APIs to playback game music 
•	and sound effects. 
•	Extend the 
•	sample game 
•	Learn how to implement a XAML overlay for a UWP DirectX game.Tutorial: Open a project from a repo 
•	Article • 12/19/2024 
•	In this tutorial, you use Visual Studio to connect to a repository, or repo, for the first 
•	time, clone it, and then open a project from it. 
•	In this tutorial, you learn how to: 
•	＂ Open a project from a GitHub repo 
•	＂ Browse to an Azure DevOps repo 
•	Prerequisites 
•	If you don't have Visual Studio yet, go to Visual Studio downloads to install it for 
•	free. 
•	Open a project from a GitHub repo 
•	Visual Studio makes it easy to open a project from a repo. You can do so when you start 
•	Visual Studio, or you can do so directly from within the Visual Studio IDE. 
•	Here's how. 
•	Use the start window 
•	1. Open Visual Studio. 
•	2. On the start window, select Clone a repository. 
•	3. Enter or type the repository location, and then select Clone. 
•	 
•	4. If you're not already signed in, you might be prompted to sign into Visual Studio 
•	or your GitHub account. 
•	 Tip 
•	For more information about signing in to Visual Studio, see Sign in or switch 
•	Visual Studio user accounts. For specific information about how to use yourGitHub account to sign in, see Add your GitHub accounts to your Visual 
•	Studio keychain. You might receive a trust notification. For more information, 
•	see Configure trust settings for files and folders. 
•	View files in Solution Explorer 
•	Visual Studio loads the solutions from the repository by using the Folder View in 
•	Solution Explorer. 
•	You can view a solution in Solution View by double-clicking its .sln file. 
•	You can select Switch Views to switch between folder view and solution view. 
•	 TipYou can change from the default Folder View to Solution View from the Git menu. 
•	Select Settings > Source Control > Git Global Settings > Automatically load the 
•	solution when opening a Git repository. 
•	Open a project locally from a previously cloned GitHub repo 
•	1. Open Visual Studio. 
•	2. On the start window, select Open a project or solution. 
•	Visual Studio opens an instance of File Explorer, where you can browse to your 
•	solution or project, and then select it to open it. 
•	 Tip 
•	If you opened the project or solution recently, select it from the Open recent 
•	section. 
•	Start coding! 
•	Use the IDE 
•	You can also use the Git menu or the Select Repository control in the Visual Studio IDE 
•	to interact with a repository's folders and files.Here's how. 
•	To clone a repo and open a project 
•	1. In the Visual Studio IDE, select the Git menu, and then select Clone Repository. 
•	2. Follow the prompts to connect to the Git repository that includes the files that 
•	you're looking for. 
•	To open local folders and files 
•	1. In the Visual Studio IDE, select the Git menu, select Local Repositories, and then 
•	select Open Local Repository. 
•	2. Follow the prompts to connect to the Git repository that has the files that you're 
•	looking for. 
•	Browse to an Azure DevOps repo 
•	Here's how to browse to and clone an Azure DevOps repo by using Visual Studio. 
•	1. Open Visual Studio. 
•	2. On the start window, select Clone a repository. 
•	3. In the Browse a repository section, select Azure DevOps. 
•	4. Follow the prompts to clone an Azure DevOps repo that includes the files that 
•	you're looking for, and then open your project. 
•	Related content 
•	Feel free to dive into any of the following language-specific tutorials:Feedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Ask the community 
•	Visual Studio tutorials | C# 
•	Visual Studio tutorials | Visual Basic 
•	Visual Studio tutorials | C++ 
•	Visual Studio tutorials | Python 
•	Visual Studio tutorials | JavaScript, TypeScript, and Node.js 
•	For more information, see: 
•	About Git in Visual Studio 
•	Brpwse a repo 
•	Manage a repo 
•	 Yes 
•	 NoLearn to use the code editor 
•	Article • 01/24/2025 
•	In this 10-minute introduction to the code editor in Visual Studio, we'll add code to a file 
•	to look at some of the ways that Visual Studio makes writing, navigating, and 
•	understanding code easier. 
•	If you haven't already installed Visual Studio, go to the Visual Studio downloads page 
•	to install it for free. 
•	This article assumes you're already familiar with a programming language. If you aren't, 
•	we suggest you look at one of the programming quickstarts first, such as create a web 
•	app with Python or C#, or create a console app with Visual Basic or C++. 
•	 Tip 
•	To follow along with this article, make sure you have the C# settings selected for 
•	Visual Studio. For information about selecting settings for the integrated 
•	development environment (IDE), see Select environment settings. 
•	Create a new code file 
•	Start by creating a new file and adding some code to it. 
•	1. Open Visual Studio. Select the Esc key, or select Continue without code on the 
•	start window, to open the development environment. 
•	2. From the File menu on the menu bar, select New > File, or select the Ctrl+N keys. 
•	3. In the New File dialog box, under the General category, select C# Class, and then 
•	select Open. 
•	A new file opens in the editor with the skeleton of a C# class.Use GitHub Copilot 
•	GitHub Copilot acts as an AI pair programmer to provide autocomplete-style code 
•	completions and context-aware multi-line code suggestions, as you code, in real-time, 
•	right in the editor. GitHub Copilot turns natural language prompts including comments 
•	and method names into coding suggestions. You can view and incorporate suggestions 
•	from GitHub Copilot directly within the editor. 
•	Try GitHub Copilot 
•	Let's use Copilot to generate code suggestions: 
•	1. Place your cursor just below the final closing brace } in the file. 
•	2. Type a natural language comment: // Add a method to add two numbers and Enter. 
•	3. GitHub Copilot generates a code suggestion for you. The suggested 
•	implementation shows in gray text. 
•	4. To accept the suggestion, select Tab. 
•	Let's use Copilot Chat to submit a coding-related question as a prompt: 
•	1. Select the GitHub Copilot badge in the upper-right corner of the IDE. 
•	2. Select Open Chat Window from the dropdown. 
•	3. Enter the following prompt in the chat window: 
•	Copilot prompt 
•	Generate sample code for a simple C# method to add two numbers. 
•	4. Copilot Chat generates sample code in response to your prompt. 
•	GitHub Copilot is powered by AI, so surprises and mistakes are possible. For more 
•	information, see GitHub Copilot FAQs . 
•	Get started with GitHub Copilot in Visual Studio. Note that it requires Visual Studio 2022 
•	version 17.8 or later. 
•	Use code snippetsVisual Studio provides useful code snippets that you can use to quickly and easily 
•	generate commonly used code blocks. Code snippets are available for different 
•	programming languages including C#, Visual Basic, and C++. 
•	Let's add the C# void Main snippet to our file. 
•	1. Place your cursor just above the final closing brace } in the file, and type the 
•	characters svm . 
•	A pop-up dialog box appears with information about the svm code snippet. 
•	2. Select the Tab key twice to insert the code snippet. 
•	You'll see the static void Main() method signature get added to the file. The 
•	Main() method is the entry point for C# applications. 
•	Available code snippets vary for different programming languages. You can look at the 
•	available code snippets for your language by choosing Edit > IntelliSense > Insert 
•	Snippet or by selecting the Ctrl+K, Ctrl+X keys, and then choosing the folder for your 
•	programming language. For C#, the snippet list looks like this:The list includes snippets for creating a class, a constructor, a for loop, an if or switch 
•	statement, and more. 
•	The Text Editor toolbar, which is the row of buttons under the menu bar in Visual Studio, 
•	helps make you more productive as you code. For example, you can toggle IntelliSense 
•	completion mode, increase or decrease a line indent, or comment out code that you 
•	don't want to compile. 
•	Let's comment out some code. 
•	1. Paste the following code into the Main() method body. 
•	C# 
•	Comment out code 
•	// someWords is a string array. 
•	string[] someWords = { 
•	"the", 
•	"quick", 
•	"brown", 
•	"fox", 
•	"jumps" 
•	};2. We're not using the moreWords variable, but we might use it later so we don't want 
•	to delete it. Instead, we'll comment out those lines. Select the entire definition of 
•	moreWords down to the closing semicolon, and then choose the Comment out the 
•	selected lines button on the Text Editor toolbar. If you prefer to use the keyboard, 
•	select Ctrl+K, Ctrl+C. 
•	The C# comment characters // are added to the beginning of each selected line 
•	to comment out the code. 
•	When you want to uncomment lines, you can select them, and then choose the 
•	Uncomment the selected lines button on the Text Editor toolbar. If you prefer to 
•	use the keyboard, select Ctrl+K, Ctrl+U. 
•	We don't want to see the empty constructor that was generated for Class1 , so to 
•	unclutter our view of the code, let's collapse it. Choose the small gray box with the 
•	minus sign inside it in the margin of the first line of the constructor. Or, if you prefer to 
•	use the keyboard, place the cursor anywhere in the constructor code and select the 
•	Ctrl+M, Ctrl+M keys. 
•	string[] moreWords = { 
•	"over", 
•	"the", 
•	"lazy", 
•	"dog" 
•	}; 
•	// Alphabetically sort the words. 
•	IEnumerable<string> query = from word in someWords 
•	orderby word 
•	select word; 
•	Collapse code blocksThe code block collapses to just the first line, followed by an ellipsis ( ... ). To expand 
•	the code block again, select the same gray box that now has a plus sign in it, or select 
•	Ctrl+M, Ctrl+M again. This feature is called Outlining and is especially useful when 
•	you're collapsing long methods or entire classes. 
•	View symbol definitions 
•	The Visual Studio editor makes it easy to inspect the definition of a type, method, or 
•	variable. One way is to go to the definition, in whichever file has it, by choosing Go to 
•	Definition or by selecting the F12 key anywhere a symbol is referenced. An even quicker 
•	way that doesn't move your focus away from the code you're working on is to use Peek 
•	Definition. 
•	Let's peek at the definition of the string type. 
•	1. Right-click on any occurrence of string and choose Peek Definition from the 
•	content menu. Or, select the Alt+F12 keys. 
•	A pop-up window appears with the definition of the String class. You can scroll 
•	within the pop-up window, or even peek at the definition of another type from the 
•	peeked code. 
•	2. Close the peek definition window by choosing the small box with an "x" at the top 
•	right of the pop-up window. 
•	Use IntelliSense to complete words 
•	IntelliSense is an invaluable resource when you're coding. It can show you information 
•	about available members of a type, or parameter details for different overloads of amethod. You can also use IntelliSense to complete a word after you type enough 
•	characters to disambiguate it. 
•	Let's add a line of code to print out the ordered strings to the console window, which is 
•	the standard place for output from the program to go. 
•	1. Below the query variable, start typing the following code: 
•	C# 
•	You'll see an IntelliSense pop-up appear with information about the query symbol. 
•	2. To insert the rest of the word query by using IntelliSense word completion, select 
•	the Tab key. 
•	3. Finish off the code block to look like the following code. You can practice further 
•	with code snippets by entering cw and then selecting Tab twice to generate the 
•	Console.WriteLine statement. 
•	C# 
•	Nobody gets code right the first time, and one of the things you might have to change 
•	is the name of a variable or method. Let's try out Visual Studio's refactor functionality to 
•	rename the someWords variable to unsortedWords . 
•	foreach (string str in qu 
•	foreach (string str in query) 
•	{ 
•	Console.WriteLine(str); 
•	} 
•	Refactor a name1. Place your cursor over the definition of the someWords variable, and choose 
•	Rename from the right-click or context menu, or select the F2 key. 
•	A Rename dialog box appears at the top right of the editor. 
•	2. Enter the desired name unsortedWords. You'll see that the reference to 
•	unsortedWords in the query assignment statement is also automatically renamed. 
•	Before you select the Enter key, select the Include comments checkbox in the 
•	Rename pop-up box. 
•	3. Select the Enter key. 
•	Both occurrences of someWords in your code have been renamed, as well as the 
•	text someWords in your code comment. 
•	Next steps 
•	Learn about projects and solutionsFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Ask the community 
•	GitHub Copilot Completions in Visual Studio 
•	GitHub Copilot Chat in Visual Studio 
•	Code snippets 
•	Navigate code 
•	Outlining 
•	Go To Definition and Peek Definition 
•	Refactoring 
•	Use IntelliSense 
•	See also 
•	 Yes 
•	 NoCompile and build in Visual Studio 
•	Article • 02/03/2025 
•	For a first introduction to building within the IDE, see Walkthrough: Building an 
•	application. 
•	You can use any of the following methods to build an application: the Visual Studio IDE, 
•	the MSBuild command-line tools, and Azure Pipelines: 
•	Build Method 
•	Benefits 
•	IDE 
•	- Create builds immediately and test them in a debugger. 
•	- Run multi-processor builds for C++ and C# projects. 
•	- Customize different aspects of the build system. 
•	CMake 
•	- Build C++ projects using the CMake tool 
•	- Use the same build system across Linux and Windows platforms. 
•	MSBuild command 
•	line 
•	- Build projects without installing Visual Studio. 
•	- Run multi-processor builds for all project types. 
•	- Customize most areas of the build system. 
•	Azure Pipelines 
•	- Automate your build process as part of a continuous 
•	integration/continuous delivery pipeline. 
•	- Apply automated tests with every build. 
•	- Employ virtually unlimited cloud-based resources for build processes. 
•	- Modify the build workflow and create build activities to perform deeply 
•	customized tasks. 
•	The documentation in this section goes into further details of the IDE-based build 
•	process. For more information on the other methods, see CMake, MSBuild and Azure 
•	Pipelines, respectively. 
•	When you create a project, Visual Studio created default build configurations for the 
•	project and the solution that contains the project. These configurations define how the 
•	solutions and projects are built and deployed. Project configurations in particular are 
•	unique for a target platform (such as Windows or Linux) and build type (such as debug 
•	or release). You can edit these configurations however you like, and can also create your 
•	own configurations as needed. 
•	ﾉ Expand table 
•	Building from the IDEFeedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Ask the community 
•	For a first introduction to building within the IDE, see Walkthrough: Building an 
•	application. 
•	Next, see Building and cleaning projects and solutions in Visual Studio to learn about 
•	the different customizations you can make to the process. Customizations include 
•	changing output directories, specifying custom build events, managing project 
•	dependencies, managing build log files, and suppressing compiler warnings. 
•	From there, you can explore a variety of other tasks: 
•	Understand build configurations 
•	Configure projects to target platforms 
•	Manage project and solution properties. 
•	Specify build events in C# and Visual Basic 
•	Set build options 
•	Build multiple projects in parallel 
•	Building (compiling) website projects 
•	CMake projects in Visual Studio 
•	Related content 
•	 Yes 
•	 NoQuickstart: Debug with C++ using the 
•	Visual Studio debugger 
•	Article • 01/12/2024 
•	The Visual Studio debugger provides many powerful features to help you debug your 
•	apps. This topic provides a quick way to learn some of the basic features. 
•	1. Open Visual Studio and create a project. 
•	Press Esc to close the start window. Type Ctrl + Q to open the search box, type 
•	c++, choose Templates, then choose Create new Console App project. In the 
•	dialog box that appears, choose Create. 
•	If you don't see the Windows Console Application project template, go to Tools > 
•	Get Tools and Features..., which opens the Visual Studio Installer. The Visual Studio 
•	Installer launches. Choose the Desktop development with C++ workload, then 
•	choose Modify. 
•	Visual Studio creates the project. 
•	2. In MyDbgApp.cpp, replace the following code 
•	C++ 
•	with this code (do not remove #include "stdafx.h" ): 
•	C++ 
•	Create a new project 
•	int main() 
•	{ 
•	return 0; 
•	} 
•	#include <list> 
•	#include <iostream> 
•	using namespace std; 
•	void doWork() 
•	{ 
•	list <int> c1;A breakpoint is a marker that indicates where Visual Studio should suspend your running 
•	code so you can take a look at the values of variables, or the behavior of memory, or 
•	whether or not a branch of code is getting run. It is the most basic feature in debugging. 
•	1. To set the breakpoint, click in the gutter to the left of the doWork function call (or 
•	select the line of code and press F9). 
•	2. Now press F5 (or choose Debug > Start Debugging). 
•	The debugger pauses where you set the breakpoint. The statement where the 
•	debugger and app execution is paused is indicated by the yellow arrow. The line 
•	with the doWork function call has not yet executed. 
•	c1.push_back(10); 
•	c1.push_back(20); 
•	const list <int> c2 = c1; 
•	const int &i = c2.front(); 
•	const int &j = c2.front(); 
•	cout << "The first element is " << i << endl; 
•	cout << "The second element is " << j << endl; 
•	} 
•	int main() 
•	{ 
•	doWork(); 
•	} 
•	Set a breakpoint 
•	 TipIf you have a breakpoint in a loop or recursion, or if you have many 
•	breakpoints that you frequently step through, use a conditional breakpoint to 
•	make sure that your code is suspended ONLY when specific conditions are 
•	met. A conditional breakpoint saves time and can also make it easier to debug 
•	issues that are hard to reproduce. 
•	When trying to debug memory-related failures in C++, you can also use 
•	breakpoints to inspect address values (look for NULL) and reference counts. 
•	Navigate code 
•	There are different commands to instruct the debugger to continue. We show a useful 
•	code navigation command that is available starting in Visual Studio 2017. 
•	While paused at the breakpoint, hover over the statement c1.push_back(20) until the 
•	green Run to click button appears, and then press the Run to click button. 
•	The app continues execution, calling doWork , and pauses on the line of code where you 
•	clicked the button. 
•	Common keyboard commands used to step through code include F10 and F11. For more 
•	in-depth instructions, see First look at the debugger. 
•	Inspect variables in a datatip 
•	1. In the current line of code (marked by the yellow execution pointer), hover over 
•	the c1 object with your mouse to show a datatip.The datatip shows you the current value of the c1 variable and allows you to 
•	inspect its properties. When debugging, if you see a value you don't expect, you 
•	probably have a bug in the preceding or calling lines of code. 
•	2. Expand the datatip to look at the current property values of the c1 object. 
•	3. If you want to pin the datatip so that you can continue to see the value of c1 while 
•	you execute code, click the small pin icon. (You can move the pinned datatip to a 
•	convenient location.) 
•	Edit code and continue debugging 
•	If you identify a change that you want to test in your code while in the middle of a 
•	debugging session, you can do that, too. 
•	1. Click the second instance of c2.front() and change c2.front() to c2.back() . 
•	2. Press F10 (or Debug > Step Over) a few times to advance the debugger and 
•	execute the edited code. 
•	F10 advances the debugger one statement at a time, but steps over functions 
•	instead of stepping into them (the code that you skip still executes). 
•	For more information on using edit-and-continue and on feature limitations, see Edit 
•	and Continue.Feedback 
•	Was this page helpful? 
•	In this tutorial, you've learned how to start the debugger, step through code, and 
•	inspect variables. You may want to get a high-level look at debugger features along with 
•	links to more information. 
•	Next steps 
•	First look at the debugger 
•	 Yes 
•	 NoWrite unit tests for C/C++ in Visual 
•	Studio 
•	Article • 12/16/2024 
•	You can write and run your C++ unit tests by using the Test Explorer window. It works 
•	just like it does for other languages. For more information about using Test Explorer, 
•	see Run unit tests with Test Explorer. 
•	７ Note 
•	Some features such as Live Unit Testing, Coded UI Tests and IntelliTest aren't 
•	supported for C++. 
•	Visual Studio includes these C++ test frameworks with no extra downloads required: 
•	Microsoft Unit Testing Framework for C++ 
•	Google Test 
•	Boost.Test 
•	CTest 
•	You can use the installed frameworks, or write your own test adapter for whatever 
•	framework you want to use within Visual Studio. A test adapter integrates unit tests with 
•	the Test Explorer window. Several non-Microsoft adapters are available on the Visual 
•	Studio Marketplace . For more information, see Install unit test frameworks. 
•	Visual Studio 2017 and later (Professional and Enterprise) 
•	C++ unit test projects support CodeLens. 
•	Visual Studio 2017 and later (all editions) 
•	Google Test Adapter is included as a default component of the Desktop 
•	development with C++ workload. It has a project template that you can add to 
•	a solution. Right-click on the solution node in Solution Explorer and choose 
•	Add > New Project on the shortcut menu to add the project template. It also 
•	has options you can configure by using Tools > Options. For more information, 
•	see How to: Use Google Test in Visual Studio. 
•	Boost.Test is included as a default component of the Desktop development 
•	with C++ workload. It's integrated with Test Explorer, but currently doesn'thave a project template. You must manually configure it. For more information, 
•	see How to: Use Boost.Test in Visual Studio. 
•	CTest support is included with the C++ CMake tools component, which is part 
•	of the Desktop development with C++ workload. For more information, see 
•	How to: Use CTest in Visual Studio. 
•	Earlier versions of Visual Studio 
•	You can download the Google Test adapter and Boost.Test Adapter extensions on 
•	the Visual Studio Marketplace. Find them at Test adapter for Boost.Test and Test 
•	adapter for Google Test . 
•	 Tip 
•	You can also use Copilot /tests slash command to generate unit tests from code. 
•	For example, you can type /tests using Boost framework to generate Boost.Test 
•	tests. For more information, see Use slash commands in Copilot Chat. 
•	Basic test workflow 
•	The following sections show the basic steps to get you started with C++ unit testing. 
•	The basic configuration is similar for both the Microsoft and Google Test frameworks. 
•	Boost.Test requires that you manually create a test project. 
•	Create a test project in Visual Studio 2022 
•	Define and run unit tests inside one or more test projects. A test project creates a 
•	separate app that calls the code in your executable and reports on its behavior. Create 
•	test projects in the same solution as the code you want to test. 
•	To add a new test project to an existing solution: 
•	1. Right-click on the Solution node in Solution Explorer. 
•	2. In the context menu, choose Add > New Project. 
•	3. Set Language to C++ and type test in the search box. The following screenshot 
•	shows the test projects that are available when the Desktop Development with 
•	C++ and the UWP Development workload are installed:Create references to other projects in the solution 
•	To enable access to the functions in the project under test, add a reference to the 
•	project in your test project. In Solution Explorer, expand your test project. Right-click 
•	References and then select Add > Reference. In the Add Reference dialog box, choose 
•	the projects you want to test.Link to object or library files 
•	If the test code doesn't export the functions that you want to test, add the output .obj 
•	or .lib files to the dependencies of the test project. For more information, see To link 
•	the tests to the object or library files. Don't include object files that have a main function 
•	or another standard entry point such as wmain , WinMain , or DllMain . When you add new 
•	source files to your project, update the test project dependencies to include the 
•	corresponding object files. 
•	Add #include directives for header files 
•	In your unit test .cpp file, add an #include directive for any header files that declare the 
•	types and functions you want to test. Type #include " , and then IntelliSense activates to 
•	help you choose. Repeat for any more headers. Tip 
•	To avoid having to type the full path in each include statement in the source file, 
•	add the required folders in Project > Properties > C/C++ > General > Additional 
•	Include Directories. 
•	Write test methods 
•	７ Note 
•	This section shows syntax for the Microsoft Unit Testing Framework for C/C++. For 
•	more information, see Microsoft.VisualStudio.TestTools.CppUnitTestFramework 
•	API reference. 
•	For Google Test documentation, see Google Test primer . For Boost.Test, see 
•	Boost Test library: The unit test framework . 
•	The .cpp file in your test project has a stub class and method defined for you. They 
•	show an example of how to write test code. The signatures use the TEST_CLASS and 
•	TEST_METHOD macros, which make the methods discoverable from the Test Explorer 
•	window.TEST_CLASS and TEST_METHOD are part of the Microsoft Native Test Framework. Test 
•	Explorer discovers test methods in other supported frameworks in a similar way. 
•	A TEST_METHOD returns void. To produce a test result, use the static methods in the 
•	Assert class to test actual results against expected results. In the following example, 
•	assume MyClass has a constructor that takes a std::string . This example shows how 
•	you can test that the constructor initializes the class the way you expect: 
•	C++ 
•	In the previous example, the result of the Assert::AreEqual call determines whether the 
•	test passes or fails. The Assert class contains many other methods to compare expected 
•	results with actual results. 
•	You can add traits to test methods to specify test owners, priority, and other 
•	information. You can then use these values to sort and group tests in Test Explorer. For 
•	more information, see Run unit tests with Test Explorer. 
•	1. On the Test menu, choose Test Explorer. The following illustration shows a test 
•	project before you run tests. 
•	TEST_METHOD(TestClassInit) 
•	{ 
•	std::string name = "Bill"; 
•	MyClass mc(name); 
•	Assert::AreEqual(name, mc.GetName()); 
•	} 
•	Run the tests７ Note 
•	CTest integration with Test Explorer is not yet available. Run CTest tests from 
•	the CMake main menu. 
•	2. If any of your tests are missing from the window, build the test project by right 
•	clicking its node in Solution Explorer and choosing Build or Rebuild. 
•	3. In Test Explorer, choose Run All, or select the specific tests you want to run. Right 
•	click on a test for other options, including running it in debug mode with 
•	breakpoints enabled. After all the tests run, the window shows the tests that 
•	passed and the ones that failed. 
•	For failed tests, the message displays details that help to diagnose the cause. Right-click 
•	on the failing test for a pop-up menu. Choose Debug to step through the function 
•	where the failure occurred.For more information on using Test Explorer, see Run unit tests with Test Explorer. 
•	For more information on unit testing, see Unit test basics. 
•	Use CodeLens 
•	Visual Studio 2017 and later (Professional and Enterprise editions) 
•	CodeLens lets you quickly see the status of a unit test without leaving the code editor. 
•	Initialize CodeLens for a C++ unit test project in any of the following ways: 
•	Edit and build your test project or solution. 
•	Rebuild your project or solution. 
•	Run tests from the Test Explorer window. 
•	After you initialize CodeLens, you can see the test status icons above each unit test. 
•	 
•	Choose the icon for more information, or to run or debug the unit test:Feedback 
•	Was this page helpful? 
•	Provide product feedback 
•	| Ask the community 
•	Unit test your code 
•	Related content 
•	 Yes 
•	 NoWalkthrough: Compiling a Native C++ 
•	Program on the Command Line 
•	Article • 02/08/2022 
•	Visual Studio includes a command-line C and C++ compiler. You can use it to create 
•	everything from basic console apps to Universal Windows Platform apps, Desktop apps, 
•	device drivers, and .NET components. 
•	In this walkthrough, you create a basic, "Hello, World"-style C++ program by using a 
•	text editor, and then compile it on the command line. If you'd like to try the Visual 
•	Studio IDE instead of using the command line, see Walkthrough: Working with Projects 
•	and Solutions (C++) or Using the Visual Studio IDE for C++ Desktop Development. 
•	In this walkthrough, you can use your own C++ program instead of typing the one 
•	that's shown. Or, you can use a C++ code sample from another help article. 
•	Prerequisites 
•	To complete this walkthrough, you must have installed either Visual Studio and the 
•	optional Desktop development with C++ workload, or the command-line Build Tools 
•	for Visual Studio. 
•	Visual Studio is an integrated development environment (IDE). It supports a full-featured 
•	editor, resource managers, debuggers, and compilers for many languages and 
•	platforms. Versions available include the free Visual Studio Community edition, and all 
•	can support C and C++ development. For information on how to download and install 
•	Visual Studio, see Install C++ support in Visual Studio. 
•	The Build Tools for Visual Studio installs only the command-line compilers, tools, and 
•	libraries you need to build C and C++ programs. It's perfect for build labs or classroom 
•	exercises and installs relatively quickly. To install only the command-line tools, look for 
•	Build Tools for Visual Studio on the Visual Studio Downloads page. 
•	Before you can build a C or C++ program on the command line, verify that the tools are 
•	installed, and you can access them from the command line. Visual C++ has complex 
•	requirements for the command-line environment to find the tools, headers, and libraries 
•	it uses. You can't use Visual C++ in a plain command prompt window without doing 
•	some preparation. Fortunately, Visual C++ installs shortcuts for you to launch a 
•	developer command prompt that has the environment set up for command line builds. 
•	Unfortunately, the names of the developer command prompt shortcuts and wherethey're located are different in almost every version of Visual C++ and on different 
•	versions of Windows. Your first walkthrough task is finding the right one to use. 
•	７ Note 
•	A developer command prompt shortcut automatically sets the correct paths for the 
•	compiler and tools, and for any required headers and libraries. You must set these 
•	environment values yourself if you use a regular Command Prompt window. For 
•	more information, see Use the MSVC toolset from the command line. We 
•	recommend you use a developer command prompt shortcut instead of building 
•	your own. 
•	Open a developer command prompt 
•	1. If you have installed Visual Studio 2017 or later on Windows 10 or later, open the 
•	Start menu and choose All apps. Scroll down and open the Visual Studio folder 
•	(not the Visual Studio application). Choose Developer Command Prompt for VS to 
•	open the command prompt window. 
•	If you have installed Microsoft Visual C++ Build Tools 2015 on Windows 10 or 
•	later, open the Start menu and choose All apps. Scroll down and open the Visual 
•	C++ Build Tools folder. Choose Visual C++ 2015 x86 Native Tools Command 
•	Prompt to open the command prompt window. 
•	You can also use the Windows search function to search for "developer command 
•	prompt" and choose one that matches your installed version of Visual Studio. Use 
•	the shortcut to open the command prompt window. 
•	2. Next, verify that the Visual C++ developer command prompt is set up correctly. In 
•	the command prompt window, enter cl and verify that the output looks 
•	something like this: 
•	Output 
•	C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl 
•	Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	usage: cl [ option... ] filename... [ /link linkoption... ] 
•	There may be differences in the current directory or version numbers. These values 
•	depend on the version of Visual C++ and any updates installed. If the aboveoutput is similar to what you see, then you're ready to build C or C++ programs at 
•	the command line. 
•	７ Note 
•	If you get an error such as "'cl' is not recognized as an internal or external 
•	command, operable program or batch file," error C1034, or error LNK1104 
•	when you run the cl command, then either you are not using a developer 
•	command prompt, or something is wrong with your installation of Visual C++. 
•	You must fix this issue before you can continue. 
•	If you can't find the developer command prompt shortcut, or if you get an error 
•	message when you enter cl , then your Visual C++ installation may have a 
•	problem. Try reinstalling the Visual C++ component in Visual Studio, or reinstall 
•	the Microsoft Visual C++ Build Tools. Don't go on to the next section until the cl 
•	command works. For more information about installing and troubleshooting Visual 
•	C++, see Install Visual Studio. 
•	７ Note 
•	Depending on the version of Windows on the computer and the system 
•	security configuration, you might have to right-click to open the shortcut 
•	menu for the developer command prompt shortcut and then choose Run as 
•	administrator to successfully build and run the program that you create by 
•	following this walkthrough. 
•	Create a Visual C++ source file and compile it on the 
•	command line 
•	1. In the developer command prompt window, enter md c:\hello to create a 
•	directory, and then enter cd c:\hello to change to that directory. This directory is 
•	where both your source file and the compiled program get created. 
•	2. Enter notepad hello.cpp in the command prompt window. 
•	Choose Yes when Notepad prompts you to create a new file. This step opens a 
•	blank Notepad window, ready for you to enter your code in a file named hello.cpp. 
•	3. In Notepad, enter the following lines of code:C++ 
•	This code is a simple program that will write one line of text on the screen and 
•	then exit. To minimize errors, copy this code and paste it into Notepad. 
•	4. Save your work! In Notepad, on the File menu, choose Save. 
•	Congratulations, you've created a C++ source file, hello.cpp, that is ready to 
•	compile. 
•	5. Switch back to the developer command prompt window. Enter dir at the 
•	command prompt to list the contents of the c:\hello directory. You should see the 
•	source file hello.cpp in the directory listing, which looks something like: 
•	Output 
•	The dates and other details will differ on your computer. 
•	#include <iostream> 
•	using namespace std; 
•	int main() 
•	{ 
•	cout << "Hello, world, from Visual C++!" << endl; 
•	} 
•	c:\hello>dir 
•	Volume in drive C has no label. 
•	Volume Serial Number is CC62-6545 
•	Directory of c:\hello 
•	05/24/2016 05:36 PM <DIR> . 
•	05/24/2016 05:36 PM <DIR> .. 
•	05/24/2016 05:37 PM 115 hello.cpp 
•	1 File(s) 115 bytes 
•	2 Dir(s) 571,343,446,016 bytes free 
•	７ Note 
•	If you don't see your source code file, hello.cpp , make sure the current 
•	working directory in your command prompt is the C:\hello directory you 
•	created. Also make sure that this is the directory where you saved your source 
•	file. And make sure that you saved the source code with a .cpp file name 
•	extension, not a .txt extension. Your source file gets saved in the current 
•	directory as a .cpp file automatically if you open Notepad at the commandprompt by using the notepad hello.cpp command. Notepad's behavior is 
•	different if you open it another way: By default, Notepad appends a .txt 
•	extension to new files when you save them. It also defaults to saving files in 
•	your Documents directory. To save your file with a .cpp extension in Notepad, 
•	choose File > Save As. In the Save As dialog, navigate to your C:\hello folder 
•	in the directory tree view control. Then use the Save as type dropdown 
•	control to select All Files (*.*). Enter hello.cpp in the File name edit control, 
•	and then choose Save to save the file. 
•	6. At the developer command prompt, enter cl /EHsc hello.cpp to compile your 
•	program. 
•	The cl.exe compiler generates an .obj file that contains the compiled code, and 
•	then runs the linker to create an executable program named hello.exe. This name 
•	appears in the lines of output information that the compiler displays. The output of 
•	the compiler should look something like: 
•	Output 
•	c:\hello>cl /EHsc hello.cpp 
•	Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	hello.cpp 
•	Microsoft (R) Incremental Linker Version 14.10.25017.0 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	/out:hello.exe 
•	hello.obj 
•	７ Note 
•	If you get an error such as "'cl' is not recognized as an internal or external 
•	command, operable program or batch file," error C1034, or error LNK1104, 
•	your developer command prompt is not set up correctly. For information on 
•	how to fix this issue, go back to the Open a developer command prompt 
•	section. 
•	７ Note 
•	If you get a different compiler or linker error or warning, review your source 
•	code to correct any errors, then save it and run the compiler again. Forinformation about specific errors, use the search box to look for the error 
•	number. 
•	7. To run the hello.exe program, at the command prompt, enter hello . 
•	The program displays this text and exits: 
•	Output 
•	Hello, world, from Visual C++! 
•	Congratulations, you've compiled and run a C++ program by using the command 
•	line tools. 
•	Next steps 
•	This "Hello, World" example is about as simple as a C++ program can get. Real world 
•	programs usually have header files, more source files, and link to libraries. 
•	You can use the steps in this walkthrough to build your own C++ code instead of typing 
•	the sample code shown. These steps also let you build many C++ code sample 
•	programs that you find elsewhere. You can put your source code and build your apps in 
•	any writeable directory. By default, the Visual Studio IDE creates projects in your user 
•	folder, in a source\repos subfolder. Older versions may put projects in a 
•	Documents\Visual Studio <version>\Projects folder. 
•	To compile a program that has additional source code files, enter them all on the 
•	command line, like: 
•	cl /EHsc file1.cpp file2.cpp file3.cpp 
•	The /EHsc command-line option instructs the compiler to enable standard C++ 
•	exception handling behavior. Without it, thrown exceptions can result in undestroyed 
•	objects and resource leaks. For more information, see /EH (Exception Handling Model). 
•	When you supply additional source files, the compiler uses the first input file to create 
•	the program name. In this case, it outputs a program called file1.exe. To change the 
•	name to program1.exe, add an /out linker option: 
•	cl /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe 
•	And to catch more programming mistakes automatically, we recommend you compile 
•	by using either the /W3 or /W4 warning level option:cl /W4 /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe 
•	The compiler, cl.exe, has many more options. You can apply them to build, optimize, 
•	debug, and analyze your code. For a quick list, enter cl /? at the developer command 
•	prompt. You can also compile and link separately and apply linker options in more 
•	complex build scenarios. For more information on compiler and linker options and 
•	usage, see C/C++ Building Reference. 
•	You can use NMAKE and makefiles, MSBuild and project files, or CMake, to configure 
•	and build more complex projects on the command line. For more information on using 
•	these tools, see NMAKE Reference, MSBuild, and CMake projects in Visual Studio. 
•	The C and C++ languages are similar, but not the same. The MSVC compiler uses a 
•	simple rule to determine which language to use when it compiles your code. By default, 
•	the MSVC compiler treats files that end in .c as C source code, and files that end in 
•	.cpp as C++ source code. To force the compiler to treat all files as C++ independent of 
•	file name extension, use the /TP compiler option. 
•	The MSVC compiler includes a C Runtime Library (CRT) that conforms to the ISO C99 
•	standard, with minor exceptions. Portable code generally compiles and runs as expected. 
•	Certain obsolete library functions, and several POSIX function names, are deprecated by 
•	the MSVC compiler. The functions are supported, but the preferred names have 
•	changed. For more information, see Security Features in the CRT and Compiler Warning 
•	(level 3) C4996. 
•	See also 
•	C++ Language Reference 
•	Projects and build systems 
•	MSVC Compiler OptionsWalkthrough: Compile a C program on 
•	the command line 
•	Article • 05/10/2022 
•	The Visual Studio build tools include a C compiler that you can use to create everything 
•	from basic console programs to full Windows Desktop applications, mobile apps, and 
•	more. Microsoft C/C++ (MSVC) is a C and C++ compiler that, in its latest versions, 
•	conforms to some of the latest C language standards, including C11 and C17. 
•	This walkthrough shows how to create a basic, "Hello, World"-style C program by using 
•	a text editor, and then compile it on the command line. If you'd rather work in C++ on 
•	the command line, see Walkthrough: Compiling a Native C++ Program on the 
•	Command Line. If you'd like to try the Visual Studio IDE instead of using the command 
•	line, see Walkthrough: Working with Projects and Solutions (C++) or Using the Visual 
•	Studio IDE for C++ Desktop Development. 
•	Prerequisites 
•	To complete this walkthrough, you must have installed either Visual Studio or the Build 
•	Tools for Visual Studio and the optional Desktop development with C++ workload. 
•	Visual Studio is a powerful integrated development environment that supports a full 
•	featured editor, resource managers, debuggers, and compilers for many languages and 
•	platforms. For information on these features and how to download and install Visual 
•	Studio, including the free Visual Studio Community edition, see Install Visual Studio. 
•	The Build Tools for Visual Studio version of Visual Studio installs only the command-line 
•	toolset, the compilers, tools, and libraries you need to build C and C++ programs. It's 
•	perfect for build labs or classroom exercises and installs relatively quickly. To install only 
•	the command-line toolset, download Build Tools for Visual Studio from the Visual Studio 
•	downloads page and run the installer. In the Visual Studio installer, select the Desktop 
•	development with C++ workload (in older versions of Visual Studio, select the C++ 
•	build tools workload), and choose Install. 
•	When you've installed the tools, there's another tool you'll use to build a C or C++ 
•	program on the command line. MSVC has complex requirements for the command-line 
•	environment to find the tools, headers, and libraries it uses. You can't use MSVC in a 
•	plain command prompt window without some preparation. You need a developer 
•	command prompt window, which is a regular command prompt window that has all the 
•	required environment variables set. Fortunately, Visual Studio installs shortcuts for youto launch developer command prompts that have the environment set up for command 
•	line builds. Unfortunately, the names of the developer command prompt shortcuts and 
•	where they're located are different in almost every version of Visual Studio and on 
•	different versions of Windows. Your first walkthrough task is to find the right shortcut to 
•	use. 
•	７ Note 
•	A developer command prompt shortcut automatically sets the correct paths for the 
•	compiler and tools, and for any required headers and libraries. Some of these 
•	values are different for each build configuration. You must set these environment 
•	values yourself if you don't use one of the shortcuts. For more information, see Use 
•	the MSVC toolset from the command line. Because the build environment is 
•	complex, we strongly recommend you use a developer command prompt shortcut 
•	instead of building your own. 
•	These instructions vary depending on which version of Visual Studio you're using. To see 
•	the documentation for your preferred version of Visual Studio, use the Version selector 
•	control. It's found at the top of the table of contents on this page. 
•	Open a developer command prompt in Visual 
•	Studio 2022 
•	If you've installed Visual Studio 2022 on Windows 10 or later, open the Start menu, and 
•	choose All apps. Then, scroll down and open the Visual Studio 2022 folder (not the 
•	Visual Studio 2022 app). Choose Developer Command Prompt for VS 2022 to open the 
•	command prompt window. 
•	If you're using a different version of Windows, look in your Start menu or Start page for 
•	a Visual Studio tools folder that contains a developer command prompt shortcut. You 
•	can also use the Windows search function to search for "developer command prompt" 
•	and choose one that matches your installed version of Visual Studio. Use the shortcut to 
•	open the command prompt window. 
•	Next, verify that the developer command prompt is set up correctly. In the command 
•	prompt window, enter cl (or CL , case doesn't matter for the compiler name, but it does 
•	matter for compiler options). The output should look something like this: 
•	OutputC:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl 
•	Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	usage: cl [ option... ] filename... [ /link linkoption... ] 
•	There may be differences in the current directory or version numbers, depending on the 
•	version of Visual Studio and any updates installed. If the above output is similar to what 
•	you see, then you're ready to build C or C++ programs at the command line. 
•	７ Note 
•	If you get an error such as "'cl' is not recognized as an internal or external 
•	command, operable program or batch file," error C1034, or error LNK1104 when 
•	you run the cl command, then either you are not using a developer command 
•	prompt, or something is wrong with your installation of Visual Studio. You must fix 
•	this issue before you can continue. 
•	If you can't find the developer command prompt shortcut, or if you get an error 
•	message when you enter cl , then your Visual Studio installation may have a problem. If 
•	you're using Visual Studio 2017 or later, try reinstalling the Desktop development with 
•	C++ workload in the Visual Studio installer. For details, see Install C++ support in Visual 
•	Studio. Or, reinstall the Build Tools from the Visual Studio downloads page. Don't go 
•	on to the next section until the cl command works. For more information about 
•	installing and troubleshooting Visual Studio, see Install Visual Studio. 
•	７ Note 
•	Depending on the version of Windows on the computer and the system security 
•	configuration, you might have to right-click to open the shortcut menu for the 
•	developer command prompt shortcut and then choose Run as Administrator to 
•	successfully build and run the program that you create by following this 
•	walkthrough. 
•	Create a C source file and compile it on the 
•	command line 
•	1. In the developer command prompt window, enter cd c:\ to change the current 
•	working directory to the root of your C: drive. Next, enter md c:\hello to create adirectory, and then enter cd c:\hello to change to that directory. This directory 
•	will hold your source file and the compiled program. 
•	2. Enter notepad hello.c at the developer command prompt. In the Notepad alert 
•	dialog that pops up, choose Yes to create a new hello.c file in your working 
•	directory. 
•	3. In Notepad, enter the following lines of code: 
•	C 
•	4. On the Notepad menu bar, choose File > Save to save hello.c in your working 
•	directory. 
•	5. Switch back to the developer command prompt window. Enter dir at the 
•	command prompt to list the contents of the c:\hello directory. You should see 
•	the source file hello.c in the directory listing, which looks something like: 
•	Output 
•	The dates and other details will differ on your computer. If you don't see your 
•	source code file, hello.c , make sure you've changed to the c:\hello directory 
•	you created, and in Notepad, make sure that you saved your source file in this 
•	#include <stdio.h> 
•	int main() 
•	{ 
•	printf("Hello, World! This is a native C program compiled on the 
•	command line.\n"); 
•	return 0; 
•	} 
•	C:\hello>dir 
•	Volume in drive C has no label. 
•	Volume Serial Number is CC62-6545 
•	Directory of C:\hello 
•	10/02/2017 03:46 PM <DIR> . 
•	10/02/2017 03:46 PM <DIR> .. 
•	10/02/2017 03:36 PM 143 hello.c 
•	1 File(s) 143 bytes 
•	2 Dir(s) 514,900,566,016 bytes freedirectory. Also make sure that you saved the source code with a .c file name 
•	extension, not a .txt extension. 
•	6. To compile your program, enter cl hello.c at the developer command prompt. 
•	You can see the executable program name, hello.exe, in the lines of output 
•	information that the compiler displays: 
•	Output 
•	c:\hello>cl hello.c 
•	Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	hello.c 
•	Microsoft (R) Incremental Linker Version 14.10.25017.0 
•	Copyright (C) Microsoft Corporation. All rights reserved. 
•	/out:hello.exe 
•	hello.obj 
•	７ Note 
•	If you get an error such as "'cl' is not recognized as an internal or external 
•	command, operable program or batch file," error C1034, or error LNK1104, 
•	your developer command prompt is not set up correctly. For information on 
•	how to fix this issue, go back to the Open a developer command prompt 
•	section. 
•	If you get a different compiler or linker error or warning, review your source 
•	code to correct any errors, then save it and run the compiler again. For 
•	information about specific errors, use the search box at the top of this page to 
•	look for the error number. 
•	7. To run your program, enter hello at the command prompt. 
•	The program displays this text and then exits: 
•	Output 
•	Hello, World! This is a native C program compiled on the command line. 
•	Congratulations, you've compiled and run a C program by using the command 
•	line.Next steps 
•	This "Hello, World" example is about as basic as a C program can get. Real world 
•	programs have header files and more source files, link in libraries, and do useful work. 
•	You can use the steps in this walkthrough to build your own C code instead of typing 
•	the sample code shown. You can also build many C code sample programs that you find 
•	elsewhere. To compile a program that has more source code files, enter them all on the 
•	command line: 
•	cl file1.c file2.c file3.c 
•	The compiler outputs a program called file1.exe . To change the name to 
•	program1.exe , add an /out linker option: 
•	cl file1.c file2.c file3.c /link /out:program1.exe 
•	And to catch more programming mistakes automatically, we recommend you compile 
•	by using either the /W3 or /W4 warning level option: 
•	cl /W4 file1.c file2.c file3.c /link /out:program1.exe 
•	The compiler, cl.exe, has many more options you can apply to build, optimize, debug, 
•	and analyze your code. For a quick list, enter cl /? at the developer command prompt. 
•	You can also compile and link separately and apply linker options in more complex build 
•	scenarios. For more information on compiler and linker options and usage, see C/C++ 
•	Building Reference. 
•	You can use NMAKE and makefiles, or MSBuild and project files to configure and build 
•	more complex projects on the command line. For more information on using these 
•	tools, see NMAKE Reference and MSBuild. 
•	The C and C++ languages are similar, but not the same. The Microsoft C/C++ compiler 
•	(MSVC) uses a basic rule to determine which language to use when it compiles your 
•	code. By default, the MSVC compiler treats all files that end in .c as C source code, and 
•	all files that end in .cpp as C++ source code. To force the compiler to treat all files as C 
•	no matter the file name extension, use the /TC compiler option. 
•	By default, MSVC is compatible with the ANSI C89 and ISO C99 standards, but not 
•	strictly conforming. In most cases, portable C code will compile and run as expected. 
•	The compiler provides optional support for the changes in ISO C11/C17. To compile with 
•	C11/C17 support, use the compiler flag /std:c11 or /std:c17 . C11/C17 support requires 
•	Windows SDK 10.0.20201.0 or later. Windows SDK 10.0.22000.0 or later isrecommended. You can download the latest SDK from the Windows SDK page. For more 
•	information, and instructions on how to install and use this SDK for C development, see 
•	Install C11 and C17 support in Visual Studio. 
•	Certain library functions and POSIX function names are deprecated by MSVC. The 
•	functions are supported, but the preferred names have changed. For more information, 
•	see Security Features in the CRT and Compiler Warning (level 3) C4996. 
•	See also 
•	Walkthrough: Creating a Standard C++ Program (C++) 
•	C Language Reference 
•	Projects and build systems 
•	CompatibilityWalkthrough: Compiling a C++/CX 
•	Program on the Command Line 
•	Article • 03/01/2023 
•	７ Note 
•	For new UWP apps and components, we recommend that you use C++/WinRT, a 
•	standard C++17 language projection for Windows Runtime APIs. C++/WinRT is 
•	available in the Windows SDK from version 1803 (10.0.17134.0) onward. 
•	C++/WinRT is implemented entirely in header files, and is designed to provide you 
•	with first-class access to the modern Windows API. 
•	The Microsoft C++ compiler (MSVC) supports C++ component extensions (C++/CX), 
•	which has additional types and operators to target the Windows Runtime programming 
•	model. You can use C++/CX to build apps for Universal Windows Platform (UWP), and 
•	Windows desktop. For more information, see A Tour of C++/CX and Component 
•	Extensions for Runtime Platforms. 
•	In this walkthrough, you use a text editor to create a basic C++/CX program, and then 
•	compile it on the command line. (You can use your own C++/CX program instead of 
•	typing the one that's shown, or you can use a C++/CX code sample from another help 
•	article. This technique is useful for building and testing small modules that have no UI 
•	elements.) 
•	７ Note 
•	You can also use the Visual Studio IDE to compile C++/CX programs. Because the 
•	IDE includes design, debugging, emulation, and deployment support that isn't 
•	available on the command line, we recommend that you use the IDE to build 
•	Universal Windows Platform (UWP) apps. For more information, see Create a UWP 
•	app in C++. 
•	Prerequisites 
•	You understand the fundamentals of the C++ language. 
•	Compiling a C++/CX ProgramTo enable compilation for C++/CX, you must use the /ZW compiler option. The MSVC 
•	compiler generates an .exe file that targets the Windows Runtime, and links to the 
•	required libraries. 
•	To compile a C++/CX application on the command line 
•	1. Open a Developer Command Prompt window. For specific instructions, see To 
•	open a developer command prompt window. 
•	Administrator credentials may be required to successfully compile the code, 
•	depending on the computer's operating system and configuration. To run the 
•	command prompt window as an administrator, right-click to open the shortcut 
•	menu for the command prompt and then choose More > Run as administrator. 
•	2. Change the current working directory in the command prompt window to a 
•	directory you can write to, such as your Documents directory. 
•	3. At the command prompt, enter notepad basiccx.cpp. 
•	Choose Yes when you're prompted to create a file. 
•	4. In Notepad, enter these lines: 
•	C++ 
•	using namespace Platform; 
•	int main(Platform::Array<Platform::String^>^ args) 
•	{ 
•	Platform::Details::Console::WriteLine("This is a C++/CX program."); 
•	} 
•	5. On the menu bar, choose File > Save. 
•	You've created a C++ source file that uses the Windows Runtime Platform 
•	namespace namespace. 
•	6. At the command prompt, enter cl /EHsc /ZW basiccx.cpp /link 
•	/SUBSYSTEM:CONSOLE . The cl.exe compiler compiles the source code into an .obj 
•	file, and then runs the linker to generate an executable program named 
•	basiccx.exe. The /EHsc compiler option specifies the C++ exception-handling 
•	model, and the /link flag specifies a console application. 
•	7. To run the basiccx.exe program, at the command prompt, enter basiccx.The program displays this text and exits: 
•	Output 
•	This is a C++/CX program. 
•	See also 
•	Projects and build systems 
•	MSVC Compiler OptionsWalkthrough: Compiling a C++/CLI 
•	Program on the Command Line 
•	Article • 02/24/2023 
•	You can create Visual C++ programs that target the Common Language Runtime (CLR) 
•	and use the .NET Framework, and build them on the command line. Visual C++ supports 
•	the C++/CLI programming language, which has additional types and operators to target 
•	the .NET programming model. For general information about the C++/CLI language, see 
•	.NET Programming with C++/CLI (Visual C++). 
•	In this walkthrough, you use a text editor to create a basic C++/CLI program, and then 
•	compile it on the command line. (You can use your own C++/CLI program instead of 
•	typing the one that's shown, or you can use a C++/CLI code sample from another help 
•	article. This technique is useful for building and testing small modules that have no UI 
•	elements.) 
•	Prerequisites 
•	You understand the fundamentals of the C++ language. 
•	Compiling a C++/CLI Program 
•	The following steps show how to compile a C++/CLI console application that uses .NET 
•	Framework classes. 
•	To enable compilation for C++/CLI, you must use the /clr compiler option. The MSVC 
•	compiler generates an .exe file that contains MSIL code—or mixed MSIL and native code 
•	—and links to the required .NET Framework libraries. 
•	To compile a C++/CLI application on the command line 
•	1. Open a Developer Command Prompt window. For specific instructions, see To 
•	open a developer command prompt window. 
•	Administrator credentials may be required to successfully compile the code, 
•	depending on the computer's operating system and configuration. To run the 
•	command prompt window as an administrator, right-click to open the shortcut 
•	menu for the command prompt and then choose More > Run as administrator.2. Change the current working directory in the command prompt window to a 
•	directory you can write to, such as your Documents directory. 
•	3. At the command prompt, enter notepad basicclr.cpp . 
•	Choose Yes when you're prompted to create a file. 
•	4. In Notepad, enter these lines: 
•	C++ 
•	int main() 
•	{ 
•	System::Console::WriteLine("This is a C++/CLI program."); 
•	} 
•	5. On the menu bar, choose File > Save. 
•	You've created a Visual C++ source file that uses a .NET Framework class (Console) 
•	in the System namespace. 
•	6. At the command prompt, enter cl /clr basicclr.cpp . The cl.exe compiler 
•	compiles the source code into an .obj file that contains MSIL, and then runs the 
•	linker to generate an executable program named basicclr.exe. 
•	7. To run the basicclr.exe program, at the command prompt, enter basicclr . 
•	The program displays this text and exits: 
•	Output 
•	This is a C++/CLI program. 
•	See also 
•	C++ Language Reference 
•	Projects and build systems 
•	MSVC Compiler Options
2.	
•	
________________________________________
C++ Standard Library reference (STL)
•	Article
•	08/17/2022 
•	
A C++ program can call on a large number of functions from this conforming implementation of the C++ Standard Library. These functions perform services such as input and output and provide efficient implementations of frequently used operations.
For more information about linking with the appropriate Visual C++ runtime .lib file, see C runtime (CRT) and C++ Standard Library (STL) .lib files.
Note
Microsoft's implementation of the C++ Standard Library is often referred to as the STL or Standard Template Library. Although C++ Standard Library is the official name of the library as defined in ISO 14882, due to the popular use of "STL" and "Standard Template Library" in search engines, we occasionally use those names to make it easier to find our documentation.
From a historical perspective, "STL" originally referred to the Standard Template Library written by Alexander Stepanov. Parts of that library were standardized in the C++ Standard Library, along with the ISO C runtime library, parts of the Boost library, and other functionality. Sometimes "STL" is used to refer to the containers and algorithms parts of the C++ Standard Library adapted from Stepanov's STL. In this documentation, Standard Template Library (STL) refers to the C++ Standard Library as a whole.
In this section
C++ Standard Library overview Provides an overview of the Microsoft implementation of the C++ Standard Library.
iostream programming Provides an overview of iostream programming.
Header files reference Provides links to reference topics about the C++ Standard Library header files, with code examples.
Use the Microsoft C++ toolset from the command line
•	Article
•	03/02/2023 
•	
In this article
1.	Download and install the tools 
2.	How to use the command-line tools 
3.	Path and environment variables for command-line builds 
4.	Developer command prompt shortcuts 
You can build C and C++ applications on the command line by using tools that are included in Visual Studio. The Microsoft C++ (MSVC) compiler toolset is also downloadable as a standalone package. You don't need to install the Visual Studio IDE if you don't plan to use it.
Note
This article is about how to set up an environment to use the individual compilers, linkers, librarian, and other basic tools. The native project build system in Visual Studio, based on MSBuild, doesn't use the environment as described in this article. For more information on how to use MSBuild from the command line, see MSBuild on the command line - C++.
Download and install the tools
If you've installed Visual Studio and a C++ workload, you have all the command-line tools. For information on how to install C++ and Visual Studio, see Install C++ support in Visual Studio. If you only want the command-line toolset, download the Build Tools for Visual Studio. When you run the downloaded executable, it updates and runs the Visual Studio Installer. To install only the tools you need for C++ development, select the Desktop development with C++ workload. You can select optional libraries and toolsets to include under Installation details. To build code by using the Visual Studio 2015, 2017, or 2019 toolsets, select the optional MSVC v140, v141, or v142 build tools. When you're satisfied with your selections, choose Install.
How to use the command-line tools
When you choose one of the C++ workloads in the Visual Studio Installer, it installs the Visual Studio platform toolset. A platform toolset has all the C and C++ tools for a specific Visual Studio version. The tools include the C/C++ compilers, linkers, assemblers, and other build tools, and matching libraries and header files. You can use all of these tools at the command line. They're also used internally by the Visual Studio IDE. There are separate x86-hosted and x64-hosted compilers and tools to build code for x86, x64, ARM, and ARM64 targets. Each set of tools for a particular host and target build architecture is stored in its own directory.
To work correctly, the tools require several specific environment variables to be set. These variables are used to add the tools to the path, and to set the locations of include files, library files, and SDKs. To make it easy to set these environment variables, the installer creates customized command files, or batch files, during installation. You can run one of these command files to set a specific host and target build architecture, Windows SDK version, and platform toolset. For convenience, the installer also creates shortcuts in your Start menu. The shortcuts open developer command prompt windows by using these command files for specific combinations of host and target. These shortcuts ensure all the required environment variables are set and ready to use.
The required environment variables are specific to your installation and to the build architecture you choose. They also might be changed by product updates or upgrades. This variability is one reason why we recommend you use an installed command prompt shortcut or command file, instead of setting the environment variables yourself.
The toolsets, command files, and shortcuts installed depend on your computer processor and the options you selected during installation. The x86-hosted tools and cross tools that build x86 and x64 code are always installed. If you have 64-bit Windows, the x64-hosted tools and cross tools that build x86 and x64 code are also installed. If you choose the optional C++ Universal Windows Platform tools, then the x86 and x64 tools that build ARM and ARM64 code also get installed. Other workloads may install these and other tools.
Path and environment variables for command-line builds
The MSVC command-line tools use the PATH, TMP, INCLUDE, LIB, and LIBPATH environment variables, and also use other environment variables specific to your installed tools, platforms, and SDKs. Even a simple Visual Studio installation may set twenty or more environment variables. This complexity is why we strongly recommend that you use a developer command prompt shortcut or one of the customized command files. We don't recommend you set these variables in the Windows environment yourself.
To see which environment variables are set by a developer command prompt shortcut, you can use the SET command. Open a plain command prompt window and capture the output of the SET command for a baseline. Open a developer command prompt window and capture the output of the SET command for comparison. Use a diff tool such as the one built into Visual Studio to highlight the environment variables set by the developer command prompt. For more information about the compiler and linker environment variables, see CL environment variables.
Developer command prompt shortcuts
The command prompt shortcuts are installed in a version-specific Visual Studio folder in your Windows Start menu. Here's a list of the base command prompt shortcuts and the build architectures they support:
•	Developer Command Prompt - Sets the environment to use 32-bit, x86-native tools to build 32-bit, x86-native code.
•	x86 Native Tools Command Prompt - Sets the environment to use 32-bit, x86-native tools to build 32-bit, x86-native code.
•	x64 Native Tools Command Prompt - Sets the environment to use 64-bit, x64-native tools to build 64-bit, x64-native code.
•	x86_x64 Cross Tools Command Prompt - Sets the environment to use 32-bit, x86-native tools to build 64-bit, x64-native code.
•	x64_x86 Cross Tools Command Prompt - Sets the environment to use 64-bit, x64-native tools to build 32-bit, x86-native code.
The Start menu folder and shortcut names vary depending on the installed version of Visual Studio. If you set one, they also depend on the installation Nickname. For example, suppose you installed Visual Studio 2022, and you gave it a nickname of Latest. The developer command prompt shortcut is named Developer Command Prompt for VS 2022 (Latest), in a folder named Visual Studio 2022.
Note
Several command-line tools or tool options may require Administrator permission. If you have permission issues when you use them, we recommend that you open the developer command prompt window by using the Run as Administrator option. Right-click to open the shortcut menu for the command prompt window, then choose More, Run as administrator.
To open a developer command prompt window
1.	On the desktop, open the Windows Start menu. In Windows 11, choose the All apps button to open the list of installed apps. In Windows 10, the list is open to the left. Scroll down the list to find and open the folder (not the app) for your version of Visual Studio, for example, Visual Studio 2022.
2.	In the folder, choose the Developer Command Prompt for your version of Visual Studio. This shortcut starts a developer command prompt window that uses the default build architecture of 32-bit, x86-native tools to build 32-bit, x86-native code. If you prefer a non-default build architecture, choose one of the native or cross tools command prompts to specify the host and target architecture.
For an even faster way to open a developer command prompt, enter developer command prompt in the desktop search box. Then choose the result you want.
Note
By default, the current working directory in a developer command prompt is the root of your Visual Studio installation in the Program Files directory. This isn't an appropriate location for your code and projects. Change the current working directory to another location before you create a project. The IDE creates projects in your user directory, typically in %USERPROFILE%\source\repos.
Developer command file locations
If you prefer to set the build environment in an existing command prompt window, you can use one of the command files created by the installer. We recommend you set the environment in a new command prompt window. We don't recommend you later switch environments in the same command window.
The command file location depends on the version of Visual Studio you installed, and on choices you made during installation. For Visual Studio 2019, the typical installation location on a 64-bit system is in \Program Files\Microsoft Visual Studio\2022\<edition>. The <edition> may be Community, Professional, Enterprise, BuildTools, or another nickname you supplied.
The primary developer command prompt command file, VsDevCmd.bat, is located in the Common7\Tools subdirectory. When no parameters are specified, it sets the environment to use the x86-native tools to build 32-bit x86 code.
More command files are available to set up specific build architectures. The command files available depend on the Visual Studio workloads and options you've installed. In Visual Studio 2017 and Visual Studio 2019, you'll find them in the VC\Auxiliary\Build subdirectory.
These command files set default parameters and call VsDevCmd.bat to set up the specified build architecture environment. A typical installation may include these command files:
Command File	Host and Target architectures
vcvars32.bat	Use the 32-bit x86-native tools to build 32-bit x86 code.
vcvars64.bat	Use the 64-bit x64-native tools to build 64-bit x64 code.
vcvarsx86_amd64.bat	Use the 32-bit x86-native cross tools to build 64-bit x64 code.
vcvarsamd64_x86.bat	Use the 64-bit x64-native cross tools to build 32-bit x86 code.
vcvarsx86_arm.bat	Use the 32-bit x86-native cross tools to build ARM code.
vcvarsamd64_arm.bat	Use the 64-bit x64-native cross tools to build ARM code.
vcvarsx86_arm64.bat	Use the 32-bit x86-native cross tools to build ARM64 code.
vcvarsamd64_arm64.bat	Use the 64-bit x64-native cross tools to build ARM64 code.
vcvarsall.bat	Use parameters to specify the host and target architectures, Windows SDK, and platform choices. For a list of supported options, call by using a /help parameter.
Caution
The vcvarsall.bat file and other Visual Studio command files can vary from computer to computer. Do not replace a missing or damaged vcvarsall.bat file by using a file from another computer. Rerun the Visual Studio installer to replace the missing file.
The vcvarsall.bat file also varies from version to version. If the current version of Visual Studio is installed on a computer that also has an earlier version of Visual Studio, do not run vcvarsall.bat or another Visual Studio command file from different versions in the same command prompt window.
Use the developer tools in an existing command window
The simplest way to specify a particular build architecture in an existing command window is to use the vcvarsall.bat file. Use vcvarsall.bat to set environment variables to configure the command line for native 32-bit or 64-bit compilation. Arguments let you specify cross-compilation to x86, x64, ARM, or ARM64 processors. You can target Microsoft Store, Universal Windows Platform, or Windows Desktop platforms. You can even specify which Windows SDK to use, and select the platform toolset version.
When used with no arguments, vcvarsall.bat configures the environment variables to use the current x86-native compiler for 32-bit Windows Desktop targets. You can add arguments to configure the environment to use any of the native or cross compiler tools. vcvarsall.bat displays an error message if you specify a configuration that's not installed, or not available on your computer.
vcvarsall syntax
vcvarsall.bat [architecture] [platform_type] [winsdk_version] [-vcvars_ver=vcversion] [spectre_mode]
architecture
This optional argument specifies the host and target architecture to use. If architecture isn't specified, the default build environment is used. These arguments are supported:
architecture	Compiler	Host computer architecture	Build output (target) architecture
x86	x86 32-bit native	x86, x64	x86
x86_amd64 or x86_x64	x64 on x86 cross	x86, x64	x64
x86_arm	ARM on x86 cross	x86, x64	ARM
x86_arm64	ARM64 on x86 cross	x86, x64	ARM64
amd64 or x64	x64 64-bit native	x64	x64
amd64_x86 or x64_x86	x86 on x64 cross	x64	x86
amd64_arm or x64_arm	ARM on x64 cross	x64	ARM
amd64_arm64 or x64_arm64	ARM64 on x64 cross	x64	ARM64
platform_type
This optional argument allows you to specify store or uwp as the platform type. By default, the environment is set to build desktop or console apps.
winsdk_version
Optionally specifies the version of the Windows SDK to use. By default, the latest installed Windows SDK is used. To specify the Windows SDK version, you can use a full Windows SDK number such as 10.0.10240.0, or specify 8.1 to use the Windows 8.1 SDK.
vcversion
Optionally specifies the Visual Studio compiler toolset to use. By default, the environment is set to use the current Visual Studio compiler toolset.
Use -vcvars_ver=14.2x.yyyyy to specify a specific version of the Visual Studio 2019 compiler toolset.
Use -vcvars_ver=14.29 to specify the latest version of the Visual Studio 2019 compiler toolset.
Use -vcvars_ver=14.0 to specify the Visual Studio 2015 compiler toolset.
spectre_mode
Leave this parameter out to use libraries without Spectre mitigations. Use the value spectre to use libraries with Spectre mitigations.
To set up the build environment in an existing command prompt window
1.	At the command prompt, use the CD command to change to the Visual Studio installation directory. Then, use CD again to change to the subdirectory that contains the configuration-specific command files. For Visual Studio 2019 and Visual Studio 2017, use the VC\Auxiliary\Build subdirectory. For Visual Studio 2015, use the VC subdirectory.
2.	Enter the command for your preferred developer environment. For example, to build ARM code for UWP on a 64-bit platform, using the latest Windows SDK and Visual Studio compiler toolset, use this command line:
vcvarsall.bat amd64_arm uwp
Create your own command prompt shortcut
Open the Properties dialog for a developer command prompt shortcut to see the command target used. For example, the target for the x64 Native Tools Command Prompt for VS 2019 shortcut is something similar to:
%comspec% /k "C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat"
The architecture-specific batch files set the architecture parameter and call vcvarsall.bat. You can pass the same options to these batch files as you would pass to vcvarsall.bat, or you can just call vcvarsall.bat directly. To specify parameters for your own command shortcut, add them to the end of the command in double-quotes. For example, here's a shortcut to build ARM code for UWP on a 64-bit platform, using the latest Windows SDK. To use an earlier compiler toolset, specify the version number. Use something like this command target in your shortcut:
%comspec% /k "C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Auxiliary\Build\vcvarsall.bat" amd64_arm uwp -vcvars_ver=14.29
Adjust the path to reflect your Visual Studio installation directory. The vcvarsall.bat file has additional information about specific version numbers.
Command-line tools
To build a C/C++ project at a command prompt, Visual Studio provides these command-line tools:
CL
Use the compiler (cl.exe) to compile and link source code files into apps, libraries, and DLLs.
Link
Use the linker (link.exe) to link compiled object files and libraries into apps and DLLs.
When you build on the command line, the F1 command isn't available for instant help. Instead, you can use a search engine to get information about warnings, errors, and messages. You can also download and use the offline help files. To use the search in Microsoft Learn, enter your query in the search box at the top of any article.
Command-line project management tools
By default, the Visual Studio IDE uses native project build systems based on MSBuild. You can invoke MSBuild directly to build projects without using the IDE. You can also use the devenv command to use Visual Studio to build projects and solutions. Visual Studio also supports build systems based on CMake or NMake.
MSBuild
Use MSBuild (msbuild.exe) and a project file (.vcxproj) to configure a build and invoke the toolset without loading the Visual Studio IDE. It's equivalent to running the Build project or Build Solution command in the Visual Studio IDE. MSBuild has advantages over the IDE when you build at the command line. You don't have to install the full IDE on all your build servers and build pipelines. You avoid the extra overhead of the IDE. MSBuild runs in containerized build environments, and supports a binary logger.
DEVENV
Use DEVENV (devenv.exe) combined with a command-line switch such as /Build or /Clean to execute certain build commands without displaying the Visual Studio IDE.
CMake
CMake (cmake.exe) is a cross-platform, open-source tool for defining build processes that run on multiple platforms. CMake can configure and control native build tools for its supported platforms, such as MSBuild and Make. For more information about CMake, see the CMake documentation.
NMAKE
Use NMAKE (nmake.exe) to build C++ projects by using a traditional makefile.
Note
Starting in Visual Studio 2019 version 16.5, MSBuild and DEVENV don't use the command-line environment to control the toolset and libraries used.
In this section
These articles show how to build apps on the command line, and describe how to customize the command-line build environment. Some show how to use 64-bit toolsets, and target x86, x64, ARM, and ARM64 platforms. They also describe use of the command-line build tools MSBuild and NMAKE.
Walkthrough: Compiling a native C++ program on the command line
Gives an example that shows how to create and compile a C++ program on the command line.
Walkthrough: Compile a C program on the command line
Describes how to compile a program written in the C programming language.
Walkthrough: Compiling a C++/CLI program on the command line
Describes how to create and compile a C++/CLI program that uses the .NET Framework.
Walkthrough: Compiling a C++/CX program on the command line
Describes how to create and compile a C++/CX program that uses the Windows Runtime.
NMAKE reference
Provides links to articles that describe the Microsoft Program Maintenance Utility (NMAKE.EXE).
MSBuild on the command line - C++
Provides links to articles that discuss how to use msbuild.exe from the command line.
Related sections
/MD, /MT, /LD (Use run-time library)
Describes how to use these compiler options to use a Debug or Release run-time library.
C/C++ compiler options
Provides links to articles that discuss the C and C++ compiler options and CL.exe.
MSVC linker options
Provides links to articles that discuss the linker options and LINK.exe.
Additional MSVC build tools
Provides links to the C/C++ build tools that are included in Visual Studio.
See also
Azure Virtual Desktop Readiness Resources | Microsoft Partner 
Opportunity and Use Cases
Azure Well-Architected Azure Virtual Desktop Workload Assessment 
AVD Stories 
________________________________________
Training Resources
Azure Virtual Desktop Academy 
AVD Academy Resources 
Azure Virtual Desktop Landing Zone Accelerator (LZA) 
________________________________________
Roadmap and Best Practices
AVD Community Blogs 
AVD/Citrix/VMware/Azure Stack HCI Bill of Materials 
AVD Level 300 Customer/Partner Deck 
ur overall results
EXCELLENT 
You are all set! Your results look strong and meet the necessary criteria for success. 
CRITICAL 0-1 Critical: 0 to 1 
MODERATE 1-2 Moderate: 1 to 2 
EXCELLENT 2-3 Excellent: 2 to 3 
Your result: 3/3 3 out of 3 
Categories that influenced your results
Azure Virtual Desktop Readiness Resources | Microsoft Partner 
EXCELLENT 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
Azure Virtual Desktop | Microsoft Partner - Mar 4, 2025 - 11:55:56 AM									
									
									
Your overall results	Excellent	'3/3'							
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Excellent	'3/3'							
									
									
									
Category	Link-Text	Link	Priority	ReportingCategory	ReportingSubcategory	Weight	Context	CompleteY/N	Note
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Azure Well-Architected Azure Virtual Desktop Workload Assessment	https://learn.microsoft.com/en-us/assessments/1ef67c4e-b8d1-4193-b850-d192089ae33d/sessions/6356b690-ba16-4dec-80a3-1e99a2021723?mode=pre-assessment&id=1ef67c4e-b8d1-4193-b850-d192089ae33d&session=6356b690-ba16-4dec-80a3-1e99a2021723	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	AVD Stories	https://azure.microsoft.com/en-us/products/virtual-desktop/#Customerstories	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Azure Virtual Desktop Academy	https://microsoft.github.io/PartnerResources/skilling/microsoft-infrastructure-academy/avd	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	AVD Academy Resources	https://microsoft.github.io/PartnerResources/skilling/microsoft-infrastructure-academy/resources/azure-virtual-desktop	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Azure Virtual Desktop Landing Zone Accelerator (LZA)	https://github.com/Azure/avdaccelerator	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	AVD Community Blogs	https://techcommunity.microsoft.com/t5/azure-virtual-desktop-blog/bg-p/AzureVirtualDesktopBlog	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	AVD/Citrix/VMware/Azure Stack HCI Bill of Materials	https://onedrive.live.com/?authkey=%21ACWW%2Deoxp2zM6FQ&id=D242F3D2FC2D88CC%21484&cid=D242F3D2FC2D88CC	High			0		N	
Azure Virtual Desktop Readiness Resources | Microsoft Partner	AVD Level 300 Customer/Partner Deck	https://1drv.ms/p/s!AsyILfzS80LSiAa_HEmJ_F5WuZRl?e=Osgzmf	High			0		N	
-----------									
									
Category	Question	Answers	Selected Answer	Note					
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Opportunity and Use Cases	Azure Well-Architected Azure Virtual Desktop Workload Assessment	Azure Well-Architected Azure Virtual Desktop Workload Assessment						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Opportunity and Use Cases	AVD Stories	AVD Stories						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Training Resources	Azure Virtual Desktop Academy	Azure Virtual Desktop Academy						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Training Resources	AVD Academy Resources	AVD Academy Resources						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Training Resources	Azure Virtual Desktop Landing Zone Accelerator (LZA)	Azure Virtual Desktop Landing Zone Accelerator (LZA)						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Roadmap and Best Practices	AVD Community Blogs	AVD Community Blogs						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Roadmap and Best Practices	AVD/Citrix/VMware/Azure Stack HCI Bill of Materials	AVD/Citrix/VMware/Azure Stack HCI Bill of Materials						
Azure Virtual Desktop Readiness Resources | Microsoft Partner	Roadmap and Best Practices	AVD Level 300 Customer/Partner Deck	AVD Level 300 Customer/Partner Deck						
									
									
hown below are the assessment's questions and how they were answered. 
 Show all original responses available for each question. 
________________________________________
Retail Readiness Resources 
Messaging and Use Cases
Microsoft Cloud for Retail Partner Messaging Framework 
Microsoft Cloud for Retail through-partner AI Narrative 
Microsoft Retail Industry Priority Scenarios 
Microsoft Cloud for Retail Reference architectures 
________________________________________
Training Resources
Get started with Microsoft Cloud for Retail Self-Paced training 
Get started with Store Operations Assist in Microsoft Cloud for Retail Self-Paced Training 
Discover Microsoft AI for leaders in retail Self-Paced Training 
Get started with Smart Store Analytics in Microsoft Cloud for Retail Self-Paced Training 
Integrate Store Operations Assist with Microsoft Teams Self-Paced Training 
________________________________________
Marketplace Offer Development Resources 
Marketplace Training and Support Resources
Sell Through the Commercial Marketplace 
Microsoft Commercial Marketplace Publisher FAQ 
Mastering the Marketplace: Office Hours 
________________________________________
Retail Cosell Acceleration Resources 
Go-To-Market Assets & Recommended Seller Training
Retail Partner Industry Sales Kits 
Microsoft Cloud for Retail Partner Assets 
Recommended Sellers Training: Get started with Microsoft Cloud for Retail 
________________________________________
Your overall results
EXCELLENT 
You are all set! Your results look strong and meet the necessary criteria for success. 
CRITICAL 0-1 Critical: 0 to 1 
MODERATE 1-2 Moderate: 1 to 2 
EXCELLENT 2-4 Excellent: 2 to 4 
Your result: 4/4 4 out of 4 
Categories that influenced your results
Retail Readiness Resources 
EXCELLENT 
Marketplace Offer Development Resources 
EXCELLENT 
Retail Cosell Acceleration Resources 
EXCELLENT 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
Microsoft Cloud for Retail Adoption Guide | Microsoft Partners - Mar 4, 2025 - 11:59:59 AM								
								
								
Your overall results	Excellent	'4/4'						
Retail Readiness Resources	Excellent	'4/5'						
Marketplace Offer Development Resources	Excellent	'3/3'						
Retail Cosell Acceleration Resources	Excellent	'3/3'						
								
								
	https://learn.microsoft.com							
								
Category	Link-Text	Link	Priority	ReportingCategory	ReportingSubcategory	Weight	Context	CompleteY/N
Retail Readiness Resources	Microsoft Cloud for Retail Partner Messaging Framework	https://assetsprod.microsoft.com/mpn/en-us/microsoft-cloud-for-retail-through-partner-messaging-framework.docx	High			0		N
Retail Readiness Resources	Microsoft Cloud for Retail through-partner AI Narrative	https://assetsprod.microsoft.com/mpn/en-us/microsoft-cloud-for-retail-through-partner-ai-narrative.pptx	High			0		N
Retail Readiness Resources	Microsoft Retail Industry Priority Scenarios 	https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/industry/retail/industry-priority-scenarios	High			0		N
Retail Readiness Resources	Overview of Microsoft Cloud for Retail reference architectures	https://learn.microsoft.com/en-us/industry/retail/architecture/overview	High			0		N
Retail Readiness Resources	Get started with Microsoft Cloud for Retail Self-Paced training 	https://learn.microsoft.com/en-us/training/paths/get-started-retail/	High			0		N
Retail Readiness Resources	Get started with Store Operations Assist in Microsoft Cloud for Retail Self-Paced Training 	https://learn.microsoft.com/en-us/training/paths/get-started-store-operations-assist/?source=recommendations	High			0		N
Retail Readiness Resources	Discover Microsoft AI for leaders in retail Self-Paced Training 	https://learn.microsoft.com/en-us/training/paths/discover-microsoft-ai-leaders-retail/	High			0		N
Retail Readiness Resources	Get started with Smart Store Analytics in Microsoft Cloud for Retail Self-Paced Training 	https://learn.microsoft.com/en-us/training/paths/get-started-smart-store-analytics/	High			0		N
Retail Readiness Resources	Integrate Store Operations Assist with Microsoft Teams Self-Paced Training 	https://learn.microsoft.com/en-us/training/paths/retail-store-operations-assist-teams/	High			0		N
Marketplace Offer Development Resources	Sell Through the Commercial Marketplace	https://learn.microsoft.com/en-us/training/paths/sell-through-commercial-marketplace/	High			0		N
Marketplace Offer Development Resources	Microsoft Commercial Marketplace Publisher FAQ	https://learn.microsoft.com/en-us/partner-center/marketplace/marketplace-faq-publisher-guide	High			0		N
Marketplace Offer Development Resources	Mastering the Marketplace: Office Hours	https://aka.ms/MTMofficehours	High			0		N
Retail Cosell Acceleration Resources	Retail Partner Industry Sales Kits	https://partner.microsoft.com/en-us/asset/collection/retail-to-partner-industry-sales-kit#/	High			0		N
Retail Cosell Acceleration Resources	Microsoft Cloud for Retail Partner Assets	https://partner.microsoft.com/en-us/asset/collection/microsoft-cloud-retail-partner-assets#/	High			0		N
Retail Cosell Acceleration Resources	Recommended Sellers Training: Get started with Microsoft Cloud for Retail	https://learn.microsoft.com/en-us/training/paths/get-started-retail/	High			0		N
-----------								
								
Shown below are the assessment's questions and how they were answered. 
 Show all original responses available for each question. 
________________________________________
Sustainability Readiness Resources 
Opportunity and Use Cases
This is AI … for Sustainability 
Microsoft Cloud for Sustainability: ESG and the Future of Business 
________________________________________
Training Resources
Microsoft Cloud for Sustainability Training Collection 
Pre-sales licenses for Sustainability Manager sandbox Environments for Microsoft Partners 
Fabric Technical Resources 
Microsoft Cloud for Sustainability Technical Summit 
________________________________________
Roadmap and Best Practices
Well-Architected for Microsoft Cloud for Sustainability 
What's new in Microsoft Cloud for Sustainability overview 
________________________________________
Marketplace Offer Development Resources 
Marketplace Training and Support Resources
Sell Through the Commercial Marketplace 
Microsoft Commercial Marketplace Publisher FAQ 
Mastering the Marketplace: Office Hours 
Your overall results
EXCELLENT 
You are all set! Your results look strong and meet the necessary criteria for success. 
CRITICAL 0-1 Critical: 0 to 1 
MODERATE 1-2 Moderate: 1 to 2 
EXCELLENT 2-3 Excellent: 2 to 3 
Your result: 3/3 3 out of 3 
Categories that influenced your results
Sustainability Readiness Resources 
EXCELLENT 
Marketplace Offer Development Resources 
EXCELLENT 
Sustainability Cosell Acceleration Resources 
EXCELLENT 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
Microsoft Cloud for Sustainability Adoption Guide | Microsoft Partners - Mar 4, 2025 - 12:03:23 PM									
									
									
Your overall results	Excellent	'3/3'							
Sustainability Readiness Resources	Excellent	'3/4'							
Marketplace Offer Development Resources	Excellent	'3/3'							
Sustainability Cosell Acceleration Resources	Excellent	'2/2'							
									
									
									
Category	Link-Text	Link	Priority	ReportingCategory	ReportingSubcategory	Weight	Context	CompleteY/N	Note
Sustainability Readiness Resources	This is AI … for Sustainability	https://info.microsoft.com/ww-landing-this-is-AI-for-sustainability.html?ocid=cmmop4zodtb	High			0		N	
Sustainability Readiness Resources	Microsoft Cloud for Sustainability: ESG and the Future of Business	https://www.linkedin.com/learning/microsoft-cloud-for-sustainability-esg-and-the-future-of-business	High			0		N	
Sustainability Readiness Resources	Microsoft Cloud for Sustainability Training Collection 	https://aka.ms/mcfslearningpaths	High			0		N	
Sustainability Readiness Resources	Pre-sales licenses for Sustainability Manager sandbox Environments for Microsoft Partners	https://experience.dynamics.com/requestlicense/	High			0		N	
Sustainability Readiness Resources	Well-Architected for Microsoft Cloud for Sustainability	https://learn.microsoft.com/en-us/industry/well-architected/sustainability/	High			0		N	
Sustainability Readiness Resources	Roadmap: What's new in Microsoft Cloud for Sustainability overview	https://learn.microsoft.com/en-us/industry/sustainability/whats-new	High			0		N	
Sustainability Readiness Resources	Fabric Technical Resources	https://learn.microsoft.com/en-us/credentials/certifications/fabric-analytics-engineer-associate/?practice-assessment-type=certification	High			0		N	
Sustainability Readiness Resources	Microsoft Cloud for Sustainability Technical Summit	https://aka.ms/mcfstechsummit	High			0		N	
Marketplace Offer Development Resources	Sell Through the Commercial Marketplace	https://learn.microsoft.com/en-us/training/paths/sell-through-commercial-marketplace/	High			0		N	
Marketplace Offer Development Resources	Microsoft Commercial Marketplace Publisher FAQ	https://learn.microsoft.com/en-us/partner-center/marketplace/marketplace-faq-publisher-guide	High			0		N	
Marketplace Offer Development Resources	Mastering the Marketplace: Office Hours	https://aka.ms/MTMofficehours	High			0		N	
Sustainability Cosell Acceleration Resources	Sustainability Marketing Campaigns	https://partner.microsoft.com/en-us/asset/collection/sustainability-marketing-campaigns#/	High			0		N	
Sustainability Cosell Acceleration Resources	Recommended Training for Sellers: Get started with Microsoft Cloud for Sustainability	https://learn.microsoft.com/en-us/training/paths/get-started-sustainability/	High			0		N	
-----------									
									
Category	Question	Answers	Selected Answer	Note					
Sustainability Readiness Resources	Opportunity and Use Cases	This is AI … for Sustainability	This is AI … for Sustainability						
Sustainability Readiness Resources	Opportunity and Use Cases	Microsoft Cloud for Sustainability: ESG and the Future of Business	Microsoft Cloud for Sustainability: ESG and the Future of Business						
Sustainability Readiness Resources	Training Resources	Microsoft Cloud for Sustainability Training Collection 	Microsoft Cloud for Sustainability Training Collection 						
Sustainability Readiness Resources	Training Resources	Pre-sales licenses for Sustainability Manager sandbox Environments for Microsoft Partners	Pre-sales licenses for Sustainability Manager sandbox Environments for Microsoft Partners						
Sustainability Readiness Resources	Training Resources	Fabric Technical Resources 	Fabric Technical Resources 						
Sustainability Readiness Resources	Training Resources	Microsoft Cloud for Sustainability Technical Summit	Microsoft Cloud for Sustainability Technical Summit						
Sustainability Readiness Resources	Roadmap and Best Practices	Well-Architected for Microsoft Cloud for Sustainability	Well-Architected for Microsoft Cloud for Sustainability						
Sustainability Readiness Resources	Roadmap and Best Practices	What's new in Microsoft Cloud for Sustainability overview	What's new in Microsoft Cloud for Sustainability overview						
Marketplace Offer Development Resources	Marketplace Training and Support Resources 	Sell Through the Commercial Marketplace	Sell Through the Commercial Marketplace						
Marketplace Offer Development Resources	Marketplace Training and Support Resources 	Microsoft Commercial Marketplace Publisher FAQ	Microsoft Commercial Marketplace Publisher FAQ						
Marketplace Offer Development Resources	Marketplace Training and Support Resources 	Mastering the Marketplace: Office Hours	Mastering the Marketplace: Office Hours						
Sustainability Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	Sustainability Marketing Campaigns	Sustainability Marketing Campaigns						
Sustainability Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	Recommended Sellers Training: Get started with Microsoft Cloud for Sustainability	Recommended Sellers Training: Get started with Microsoft Cloud for Sustainability						
									

 
 
 
 
 
 
 


This message was sent to tshingombefiston@gmail.com. If you don't want to receive these emails from this company in the future, please go to:
https://ms.icims.com/icims2/?r=11B617365170&contactId=129540225 LLM Assistance for Memory Safety
Nausheen Mohammed, Akash Lal, Aseem Rastogi, Rahul Sharma
Microsoft Research, India
Email: mdjnausheen786@gmail.com, {akashl, aseemr, rahsha}@microsoft.com
Subhajit Roy
IIT-Kanpur, India
Email: subhajit@iitk.ac.in
Abstract—Memory safety violations in low-level code, written
in languages like C, continues to remain one of the major
sources of software vulnerabilities. One method of removing
such violations by construction is to port C code to a safe C
dialect. Such dialects rely on programmer-supplied annotations
to guarantee safety with minimal runtime overhead. This porting,
however, is a manual process that imposes significant burden on
the programmer and, hence, there has been limited adoption of
this technique.
The task of porting not only requires inferring annotations,
but may also need refactoring/rewriting of the code to make
it amenable to such annotations. In this paper, we use Large
Language Models (LLMs) towards addressing both these con￾cerns. We show how to harness LLM capabilities to do complex
code reasoning as well as rewriting of large codebases. We also
present a novel framework for whole-program transformations
that leverages lightweight static analysis to break the transfor￾mation into smaller steps that can be carried out effectively by
an LLM. We implement our ideas in a tool called MSA that
targets the CheckedC dialect. We evaluate MSA on several micro￾benchmarks, as well as real-world code ranging up to 20K lines of
code. We showcase superior performance compared to a vanilla
LLM baseline, as well as demonstrate improvement over a state￾of-the-art symbolic (non-LLM) technique.
I. INTRODUCTION
Legacy C-programs are pervasive, which makes mem￾ory corruption vulnerabilities a major problem for software
systems. This problem has attracted a wealth of attention
for decades but memory safety violations continue to re￾main one of the major sources of cyber attacks. From
memorysafety.org: “Microsoft estimates that 70% of all
vulnerabilities in their products over the last decade have
been memory safety issues. Google estimated that 90% of
Android vulnerabilities in the wild are memory safety issues.
An analysis found that more than 80% of the exploited
vulnerabilities were memory safety issues.”
Researchers have proposed safe dialects of C, such as
Checked-C [1], Deputy [2], Cyclone [3], etc. These all use
static analysis and lightweight runtime checks to ensure formal
memory safety guarantees at low runtime overheads. However,
these techniques require source-level annotations. The manual
cost of adding these annotations, along with the code rewriting
that enable such annotations in the first place, are the main
hurdle for adoption of these dialects.
Recently, Large Language Models (LLMs) have shown
promise in improving the productivity of software developers
[4]. LLMs are highly versatile and accomplish diverse tasks
surprisingly well, given the right instructions as prompts.
Motivated by their novel capabilities, we present MSA, a
tool that leverages LLMs to help port C to Checked-C. We
are unaware of any prior LLM or Machine Learning based
approach for this task. Although recent symbolic analyses have
shown promising results [5], our evaluation shows that they
miss out on many annotations and do not perform refactoring.
Our main contribution is a novel framework that tightly
couples LLMs and symbolic representations. We show a
general recipe of breaking whole program transformations
into smaller tasks that can fit into LLM prompts, where each
task has a code snippet and a symbolic context that contains
relevant information about the other parts of the program that
are not included in the snippet (Section IV). MSA works in
multiple phases, where each phase is an instantiation of this
recipe for a different task. We present the prompts that we
used for each phase (Section V).
LLMs help compensate for shortcomings in symbolic in￾ference techniques by dealing with complex code patterns,
as well as performing refactoring where needed to allow for
further annotations in the code. For instance, if a procedure
signature is modified, then the effects have to be propagated
to its caller, possibly transitively. Our evaluation shows that
LLMs are able to accomplish this task well when provided
a sufficiently detailed prompt. On the other hand, LLMs can
hallucinate, thus, using symbolic information where available
helps improve overall accuracy. Finally, note that any anno￾tations generated by our tool are checked by the Checked C
compiler. Hence, even if the LLM falters and generates an
incorrect annotation, memory safety is not compromised—the
Checked C compiler will either give a compilation error or
instrument the code with a check that will fail at runtime. The
higher the accuracy of MSA, the less is the amount of time
developers have to spend porting to Checked C.
Although this paper focuses on memory safety, we believe
our contributions have wider ramifications in formal veri￾fication of real-world software. At a high level, any such
verification task requires three steps. First step is to rewrite
the code so that it is amenable to verification. Second step is
to annotate the code with contracts (invariants, type qualifiers,
etc.). The third and final step is to check that the code
satisfies the contracts, usually with an automated verifier.
These steps are interconnected, and any failure in the third
step has to be fixed by repeating the first two. While symbolic
techniques have been devised towards the second step, for
inferring contracts, the first step has generally not received
much attention. Given that LLMs have shown great promise in
tedious programming tasks, it is a natural research direction to
explore whether they can help with the first two steps, leaving
the third untouched in order to avoid compromising soundness.
Our work answers this question in the affirmative for the task
of memory safety of C.
To summarize, we make the following contributions:
• We present MSA, the first LLM-based assistant for porting
C to Checked-C. MSA performs transformations that are
out-of-reach of existing (symbolic-only) assistants.
• We present a novel recipe for breaking a whole program
transformation into smaller tasks that can fit into LLM
prompts.
• We evaluate MSA on real world C-programs, ranging up
to 20K lines of code, showing that it can successfully
infer 86% of the required annotations correctly.
We plan to open-source the implementation of MSA, along
with all the prompt templates that it uses.1 The rest of this
paper is organized as follows. Section II provides a back￾ground on Checked C, followed by examples that illustrate
the challenges of the porting process from C code. Section III
provides background on the state-of-the-art symbolic tool for
Checked C inference. Our technical contributions follow next.
We provide our generic recipe for whole program transfor￾mations using LLMs (Section IV) and then we show how
MSA instantiates this recipe to overcomes the challenges in the
porting process (Section V). We evaluate MSA (Section VI),
discuss threats to validity (Section VII), and survey related
work (Section VIII).
II. CHALLENGES IN PORTING C TO CHECKED C
Checked C is a safe dialect of C, inspired from Deputy
[2] and Cyclone [3]. It differs from its predecessors in that
it allows checked and unchecked code to coexist. Checked
regions guarantee spatial memory safety, i.e, any illegal out
of bounds memory access is caught and the program is termi￾nated. More precisely, Checked C satisfies a blame property
where any illegal access can be blamed on the unchecked parts
of the code [1].
Checked Pointer Types: Checked C introduces three
checked pointer types, namely, ptr<T>, arr<T> and
nt_arr<T> in place of the C pointer type T*. (These
names are abbreviated from their actual names, _Ptr<T>,
_Array_ptr<T> and _Nt_Array_ptr<T> for brevity.)
The ptr type is used for pointers that point to a single
object (or null) and are not involved in pointer arithmetic.
The compiler inserts a null check at every dereference of a
ptr type for spatial safety.
The arr type is used for pointers that point to an array of
values. It is accompanied by a bounds expression that specifies
the range of memory that the pointer can access. These decla￾rations appear as arr<T> p : bounds(lo, hi) where
lo and hi are expressions that evaluate to the lower and upper
bounds of the array, respectively. In addition to the null check,
a bounds check of lo <= (p+i) && (p+i) < hi is
also inserted at every dereference *(p+i) for an arr.
1See https://aka.ms/checkedc-annotation-inference.
There are other shorthand annotations, such as count(n)
or byte_count(n) that specify the number of elements
or bytes that the pointer can access, starting from its current
value. These checks are inserted at higher-level passes of the
compiler, and may get optimized away by lower-level passes in
the compiler if it manages to prove that accesses are within the
supplied bounds. This combination of type-assistance and low￾level optimizations makes the Checked C approach appealing
compared to other safe C approaches; portions of the FreeBSD
kernel that were ported to Checked C reported essentially no
runtime overhead [6].
The nt_arr type is used for pointers that point to
null-terminated arrays, mostly strings. An annotation of
count(n) implies that the array has at least n+ 1 elements,
the last being the null value. An interesting feature of nt_arr
is that its bounds can be widened until a null character is
found. Hence, while(*p != 0) p++; is a valid way to
access nt_arr<T> p:count(0). Each time *p does not
equal the null character, its bound can be widened by 1.
Challenges: Next, we explain some of the challenges in
porting C to Checked C through examples. In the changelogs
below, the C-code in red needs to be replaced with code in
green for a successful port. The examples in this section are
derived from real world C programs used in our evaluation,
and they are beyond the capabilities of existing inference tools
(Section III).
The first challenge is in handling nested pointers. Given a
nested pointer, e.g., long** pt, it is not possible in Checked
C to separately annotate the buffers pt[0], pt[1], etc., with
their sizes. The idiomatic way to handle this situation is to
replace the nested pointer with an array of structs, where the
struct has a buffer with its associated length. Correspondingly,
every access to pt throughout the program must be modified
to respect this new interface. A real-world example follows:
void AllocAssign(void) {
ulong net; ulong n = channelNets+1;
costMatrix =
- (long**) malloc(n * sizeof(long *));
+ (arr<struct arr_of_long>)
+ malloc(n * sizeof(struct arr_of_long));
for (net = 1; net <= channelNets; net++) {
- costMatrix[net] =
+ costMatrix[net].ptr =
malloc((channelTracks+2) * sizeof(long));
+ costMatrix[net].len = channelTracks+2;
}
}
Here, costMatrix has been converted from a nested pointer
to an array of structs, where each struct has a buffer ptr
and its associated length len. Whenever the buffers in
costMatrix are allocated or reassigned, the newly intro￾duced size field len must be updated accordingly.
Next, we present an example where annotating a buffer
with its bounds requires involved arithmetic reasoning within a
loop. Consider the following code where the loop runs longs
number of times with 4 bytes in the buffer buf accessed per
loop iteration:
static void byteReverse(
- unsigned char* buf,
+ arr<unsigned char> buf: count(longs * 4),
unsigned longs) {
uint32_t t;
do {
t = (uint32_t)
((unsigned) buf[3] << 8 | buf[2]) << 16 |
((unsigned) buf[1] << 8 | buf[0]);
*(uint32_t *) buf = t; buf += 4;
} while (--longs);
}
By analyzing this loop, we can conclude that buf has a
size of count(longs * 4). Existing tools [5] struggle to
infer bounds that have expressions with arithmetic. While the
above loop had deterministic behavior, the following is more
complicated.
struct bin_to_ascii_ret
vsf_ascii_bin_to_ascii(
- const char* p_in,
+ arr<const char> p_in: count(in_len),
- char* p_out,
+ arr<char> p_out: count(in_len * 2),
unsigned int in_len, int prev_cr) {
...
while (indexx < in_len) {
char the_char = p_in[indexx];
if (the_char == ’\n’ && last_char != ’\r’){
*p_out++ = ’\r’;
written++;
}
*p_out++ = the_char;
indexx++;
...
Here, the buffer p_in must be annotated with its length
in_len and, for memory safety, p_out must have a size
of (in_len*2) to handle the worst case loop behavior.
Often the annotation process is not local and requires
refactoring several functions. Consider the following code:
static int countint (lua_Integer key,
- unsigned int* nums
+ arr<unsigned int> nums: count(count_nums),
+ int count_nums
) {
unsigned int k = arrayindex(key);
if (k != 0) {
nums[luaO_ceillog2(k)]++;
...
Just looking at the original C code of countint, it is
impossible to annotate the buffer nums with its size. The
programmer likely has some custom invariant in mind to keep
the indexing within bounds. It is not possible to explain custom
invariants to the Checked C compiler. Thus, the idiomatic
way to enforce safety with Checked C is to introduce a new
argument count_nums that stores the array size and use it
to annotate nums, then require callers to pass the appropriate
size. Let’s consider a caller of countint next.
static int numusehash (
- const Table* t,
+ ptr<Table> t,
- unsigned int* nums,
+ arr<unsigned int> nums: count(count_nums),
+ int count_nums,
unsigned int* pna) {
...
- ause += countint(keyival(n),nums)
+ ause += countint(keyival(n),nums,count_nums)
...
Here, the call to countint must be modified to match
its new signature. Furthermore, numusehash must annotate
nums with its size in its signature. Accordingly, the signature
also needs an extra argument count_nums. Next, the callers
of numusehash also need to be updated to supply this extra
argument. We show one such caller next:
static void rehash(lua_State* L,
- Table* t, const TValue* ek
+ ptr<Table> t, ptr<const TValue> ek
) {
unsigned int nums[MAXABITS + 1];
...
- total += numusehash(t,nums,&na);
+ total += numusehash(t,nums,MAXABITS+1,&na);
...
- na += countint(ivalue(ek),nums);
+ na += countint(ivalue(ek),nums,MAXABITS+1);
...
}
In the above code, the new parameter count_nums is set to
its correct value MAXABITS+1 in the calls to countint and
numusehash. We are unaware of any prior tool that performs
such a whole program refactoring of C-code automatically.
III. BACKGROUND ON SYMBOLIC INFERENCE WITH 3C
3C [5] is a static-analysis-based tool to help developers
port C code to Checked C. It consists of two components, a
type inference algorithm called typ3c and a bounds inference
algorithm called boun3c, that are executed one after the
other. We briefly discuss these algorithms, their strengths and
limitations since MSA uses 3C.
typ3c uses type qualifier inference [7] to convert legacy
pointers to checked pointer types. Pointers that are used
unsafely, for instance, in unsafe casts (e.g., casting an int to
int*), are not converted to checked pointers. This is because
the Checked C compiler cannot provide safety guarantees for
such pointers. typ3c then classifies checked pointers into one
of ptr, arr, and nt_arr depending on their use.
Once the checked pointers have been identified, boun3c
infers bounds for arr and nt_arr pointers. It works by
constructing a dataflow graph that tracks the flow of arrays
along with their bounds, starting from their allocation site
where the bounds information is available. boun3c is designed
to be sound (i.e., inferred annotations are correct) but not
complete (not all possible annotation are inferred). In fact, as
our evaluation will show, boun3c misses several annotations.
One limitation of boun3c is that it can only infer bounds
that involve a single variable or a constant. Thus, bounds that
involve expressions with arithmetic will be missed for sure.
Further, boun3c is largely limited to inferring count-style
annotations, not bounds annotations that have both a lower
and upper bound. boun3c offers some heuristics that attempt
to come up with more annotations, but these annotations can
be unsound. Furthermore, in some cases, no good bound exists
without rewriting the program, which boun3c is not prepared
to do.
Note that 3C, as a combination of typ3c followed by
boun3c, does not attempt to fully port from C to Checked
C. The resulting code, for instance, is not guaranteed to
pass the Checked C compiler. This is because several bounds
annotations might still be missing, as well as some dynamic
casts might be necessary to pass the type checker of Checked
C. 3C is, thus, an assistance in the porting process. We carry
on with this design philosophy in this paper, striving to provide
even more assistance without guaranteeing a complete port to
Checked C.
IV. WHOLE-PROGRAM TRANSFORMATION WITH LLMS
As illustrated in Section II, the task of porting to Checked
C requires making several changes throughout the program.
Even with the increasing prompt sizes, it is still unreasonable
to expect entire code to fit inside a single prompt. Furthermore,
we found that even when we can fit larger parts of a program in
a single prompt, the accuracy of an LLM is lower when asked
to make several changes, compared to doing fewer changes to
a smaller piece of code (see Section VI).
The challenge then is to break a whole-program transfor￾mation into multiple smaller tasks. With LLMs, each infer￾ence query is treated independently of ones made previously,
therefore, any query on some part of the code must provide
enough context about the rest of the code in order to carry
out the task effectively. We address these challenges through
static analysis.
A. Dependency Graph Generation
We use a lightweight static analysis that goes across all
input source files and constructs a data structure that we
call as a dependency graph. Nodes of this graph are all the
top-level declarations in the program. These can either be
procedures (both its signature and its body), type declarations
(struct, union, enum), global variable declarations or
macro definitions. There is a directed edge from node n1 to
n2 if n2 is directly used by n1, as follows:
• Procedures. If n1 is a procedure, then we place out-going
edges from n1 to all procedures that are directly called
by it, as well as all types, globals and macros that appear
somewhere inside n1. We only consider direct calls. For
indirect calls through a function pointer, there will be an
edge to the type declaration of the pointer’s type, not to
potential targets of the pointer.
• Types. If n1 is a type definition, then we place out-going
edges to all types and macros that appear in the definition.
• Globals. If n1 is the declaration of a global variable, then
we place an out-going edge to the type of the variable or
any macro that the declaration might use.
 typedef struct {

 enum e f;

 ...

 } Typ

void foo(Typ p){

 p.f = MACRO

}

void bar() { 
 foo(g);

 }

enum e {

 ...

}

# define

 MACRO ...

Fig. 1: Example of a dependency graph
• Macros. There are no out-going edges from macros.
Transformation of macros is currently outside the scope
of our analysis. We didn’t find a need for it in our
experiments.
The requirements of this analysis are purposefully kept
simple for ease of implementation. We use clang to parse
and construct ASTs of all input source files. We then perform
linking at the AST level to resolve procedure calls and dump
the dependency graph; see Figure 1 for an example.
As part of this analysis, we also record additional informa￾tion for each node that can be obtained easily from its AST
representation. For instance, for a procedure, we keep track
of its signature, argument list, type of each argument, type of
each local variable, etc.
B. Generic Whole-Program Transformation
Porting to Checked C requires not just adding annotations,
but also supporting edits that allows for the presence of an
annotation in the first place. Inspired from previous experience
of porting C to Checked C (like in [1], [8], [5]), we define
three different programs transformations, which are applied
sequentially in order. Each of these transformation follow a
common structure, shown in Algorithm 1.
Algorithm 1 Whole-Program Transformation with LLMs
1: procedure PROGRAMTRANSFORMATION(D, T )
2: for d ∈ Nodes(D) do
3: refactored[d] := False, oldcode[d] := d.code
4: end for
5: for d ∈ BOTTOMUPORDERING(D) do
6: prompt ← PROMPTTEMPLATE( )
7: prompt.task ← TASKDESCRIPTION(T )
8: prompt.example ← TASKEXAMPLE(T )
9: prompt.prelude ← d.succ
10: prompt.code ← d.code
11: prompt.refactor history ← {(oldcode[u],
u.code): u ∈ d.succ, refactored[u] }
12: prompt.elements ← TASKELEMENTS(d, T )
13: response ← LLM(prompt)
14: d.code ← APPLYPATCH(response, d.code)
15: refactored[d] ← SIGNATURECHANGED(response)
16: end for
17: end procedure
Algorithm 1 takes the dependency graph (D) of the input
program, as well as a description of task-specific information
Typ g;

% (1) CheckedC Preamble
Checked C has three checked pointer types that support
following annotations:
...
% (2) Task definition
{{Task definition}}
% (3) Propagate changes
Similar changes have been made in other parts of the
code. Given the refactor history, update the current
code accordingly.
% (4) Output format
Each change must be outputted as a block with original
lines and refactored lines in the below format. Output
a series of such blocks, one for every change.
...
% (5) Example
Consider this example input and output as a reference.
{{Task example}}
% (6) Code
Here is relevant context for the given code
{{prelude}}
This is the code that must be transformed
{{code}}
This is a history of the previous changes
{{refactor_history}}
Perform the given task on these parts of the code:
{{task_specific_code_elements}}
Fig. 2: Prompt template for Whole-Program Transformation
(T ), and outputs a new program that is the result of applying
T to the input program. The algorithm goes over the input
program one declaration at a time, and instructs an LLM to
preform a rewriting according to T .
The template of the LLM prompt is shown in Figure 2. It
consists of various sections. The first section is a preamble
on Checked C that defines its various annotations (e.g., arr),
their meaning (e.g., it is a pointer to an array) as well as the
syntax rules to follow (e.g., bounds annotation appears after a
colon).
The next section of the prompt (2) carries a description
of the task T (e.g., “infer bounds of arrays”). Next (3) is an
instruction telling the model that prior edits have been made to
the program, and it must edit the given snippet to respect those
refactorings. For instance, when a callee method signature is
modified, the call to that method must be modified as well.
Section 4 of the prompt defines an output format that the
model should follow. Instead of asking the model to produce
the entire modified code, prior work has found it useful to
instead ask for a “diff” or a patch that can be applied to the
original code. We simply follow the prompt used in prior work
[9] to obtain a patch from the LLM. Any other format or
formatting instructions can be used as well.
Section 5 of the prompt is an example of the task. For each
task, we only include one or two fixed hard-coded examples.
Section 6 of the prompt includes the relevant code snippets
from the input program. This includes context for the current
code (called “prelude”), the code that must be transformed
Checked C
Codebase
C Codebase
3C
Partially Converted
Checked C Codebase
Replace Nested
Arrays
Infer Bounds
Introduce new
bounds variables LLM
Dependency
Graph
MSA Program
transformation
MSA
Static
Analysis
Fig. 3: Workflow of porting C code to Checked C with MSA.
(code) as well as previous code refactorings (refactor history).
Finally, the prompt also includes some code-specific elements.
For instance, for the task of inferring bounds of arrays, we
explicitly list the variable names with array types in order to
help focus the attention of the model on those variables.
Getting back to Algorithm 1, it starts (lines 2 to 4) by
keeping track of the original code (oldcode) as well as
remembering what parts of the code have been refactored
(refactored), initially none. It then makes one pass over
all declarations in the code. These declarations are picked in
a bottom-up order, using a reverse topological sorting of the
dependency graph. In general, the dependency graph can have
cycles because of recursive types or recursive procedures; we
break these cycles arbitrarily in order to limit the transforma￾tion to a single pass over the program text.
For each declaration d, the prompt in instantiated with
task-specific as well as code-specific details. Code prelude
is computed as all immediate successors of d in D, i.e., all
code elements that are referenced directly in d. For brevity,
when including a procedure in the prelude, we only include
its signature and not its body. The refactor history includes all
changes made to these successors of d so far, if any.
When the LLM is prompted, it returns a patch (possibly
empty) that should be applied to d. We apply this patch to
update d. Finally, we set refactored[d] to true if the patch
was non-empty, i.e, d was updated. When d is a procedure,
we set refactored[d] to true only when the signature of d
was changed by the patch.
V. MSA DESIGN AND IMPLEMENTATION
The design of MSA is illustrated in Figure 3. The tool is a
combination of symbolic as well as LLM-based components.
As a design principle, we rely on symbolic components
whenever they exist or are easy to implement. Tasks that are
either complex to do symbolically (e.g. knowing if a code
pattern respects null-termination of a given array) or require
an LLM’s flexibility (e.g., refactoring to accommodate a new
struct field) are left to LLM-based components.
MSA feeds input C code to the 3C tool to produce partially￾converted CheckedC code. 3C is quite fast (especially com-
You are given a list of Checked C declarations and a
partially converted Checked C code snippet. Array of
arr<T> is not supported in Checked C. Your task
is to replace them with an array of struct having a
pointer field ’ptr’ and a bounds field ’len’. You will
also have to replace the uses of the nested array with
the uses of the struct ’ptr’ field instead. Make sure
to update the ’len’ field whenever the ’ptr’ field is
updated.
Fig. 4: Task description for replacing nested arrays with structs
From:
int foo(arr<arr<int>> a, int i) {
return a[i][i];
}
To:
// New struct
typedef struct arr_of_int {
arr<int> ptr : count(len);
int len;
} arr_of_int;
// type of a changes
int foo(arr<struct arr_of_int> a, int i) {
// nested pointer access via the ptr field
return a[i].ptr[i];
}
Fig. 5: An example of the transformation (“From” to “To”) for
nested arrays that is provided to the LLM. The code comments
are included as well.
pared to LLM inference times), thus it serves us well to
use it as a source of cheap and sound annotations. We turn
off the heuristics in boun3c, which we observed to produce
incorrect annotations. We leave heuristics to the LLM-based
components of MSA. The role of MSA, thus, is to annotate the
unannotated checked pointers in the program produced by 3C.
MSA takes the output of 3C, constructs its dependency
graph, and uses it in subsequent LLM-based program trans￾formations. MSA is parametric on the choice of the LLM,
although we only evaluate with GPT4. In order to account for
the randomness in the LLM’s response, MSA asks for multiple
completions (i.e., responses) for each LLM query. The default
setting is 10, although it can be changed by the user depending
on their time budget. Multiple completions produce multiple
code patches; MSA takes a majority vote among these patches.
We now describe the three program transformation tasks.
A. Replacing Nested Arrays with Structs
As mentioned in Section II, the type arr<arr<T>> is not
allowed in Checked C syntax. The recommended way is to
replace it with arr<struct arr_of_T>, where struct
arr_of_T is a new structure with two fields, one of type
arr<T> for storing the inner array, and the other of type int
for storing the bound of this array. The rest of the program
should change to use this structure. For instance, the bounds
field must be updated when the corresponding array field is
set or updated.
Determine and assign ’count(..)’ or ’bounds(.., ..)’
expressions for each att and nt_arr in the
given function. To find valid bounds for a pointer p,
examine all uses of p and set bounds that encompass every
access. Alternatively, adopt the bounds from the pointer
from which p was assigned.
You will be provided a list of pointer variable names
along with their declaration line number. You must
choose one of the following rules for each of them.
[A0] Infer a valid bounds expression:
Provide a ’count(..)’ or ’bounds(..,..)’ expression
at the line of declaration. Choose this only when
you are completely sure that the bounds are valid.
[A1] Say unknown:
When there is not enough information to infer bounds
for a pointer, it is okay to leave the annotated line
same as the original line. Follow this by explaining
why enough information is not available. This can be
chosen when there is not a clear upper bound to all
accesses through the pointer or the pointer depends on
other pointers whose bounds are not known.
[A2] Change an arr to nt_arr:
If you cannot infer the bounds to arr p but you do
know that p is terminated with a null character from
its use, you can change its type to nt_arr.
Make sure to also change the pointers that p was
derived from to nt_arr in such a case. This can
also be due to a callee now taking nt_arr
instead of arr due to an earlier refactor.
[A3] Add a parameter for bounds:
If you cannot infer a reasonable bound for a pointer
parameter, add a new parameter to store its bounds and
use that in the bounds expression. Going ahead, all
calls of this function will have to be passed this
extra bounds argument.
Fig. 6: Task description for inferring bounds
Figure 4 shows the description for this task that is used
in conjunction with the template shown in Figure 2 to carry
out the program transformation. MSA first adds the declaration
of struct arr_of_T, once for each type T such that
the type arr<arr<T>> appears in the input program. This
step is done symbolically, at the AST level. MSA then uses
Algorithm 1 to carry out the required transformations in the
program to use this new type. Figure 5 shows the example
that is included in the prompt. The task-specific elements that
are included in the prompt are the names of variables with
refactored types (e.g., a for the example in Figure 5).
B. Inferring Bounds Annotations
The second transformation does the actual inference task
of adding bounds annotations for arr and nt_arr pointers.
The LLM is asked to annotate array pointers based on their
usage in the code snippet that is presented to it. Because
this pass traverses the code in a bottom-up fashion, when
the LLM is presented the code of a certain procedure, it will
also get presented with its context. This context will include
callee signatures, which have already been annotated because
they came before in the dependency-graph order. This allows
transitivity of the inferred annotations.
The task description for this transformation is the most
detailed among the three passes and is shown in Figure 6. It
From:
struct x { int f; int g; }
int foo(arr<struct x> a, int i) {
int j = a[i].f;
arr<struct x> p = a;
return a[j].f;
}
To:
// [A3] As j is read from the heap, the access
// a[j] could be anything. Moreover, j is not
// in scope at line 1. Since ’a’ is a pointer
// parameter, add a bounds parameter instead
// of saying ’unknown’.
int foo(arr<struct x> a : count(count_for_a),
int count_for_a, int i) {
int j = a[i].f;
// [A0] As p is assigned a, the bounds for a
// are valid for p too.
arr<struct x> p : count(count_for_a) = a;
return a[j].f;
}
From:
void foo() {
char a[10]; nt_arr<char> p = a;
}
To:
void foo() {
char a[10];
// [A0] When an array is converted to nt_arr
// the count is the size of the array - 1.
nt_arr<char> p : count(9) = a;
}
Fig. 7: Examples of inferring bounds for arr and nt_arr
lists down four different rules (A0—A3). The first rule (A0)
is for inferring bounds “when the model is sure of it” and the
second rule (A1) provides an escape hatch for the same. The
idea behind A1 is to reduce hallucinations when the model
is not confident of inferring bounds; that is, the model should
choose to leave things unannotated rather than add an incorrect
one. The third rule (A2) rectifies inaccuracies in typ3c where
it fails to identify that certain arrays are null-terminated. In
our experience, we found that this happens because typ3c is
sometimes unable to identify that a comparison to the null
character is being used to break out of a loop through the
array. In other cases, it lacks an understanding of standard
string operations (from stdlib), which also establish that
a given array is (intended to be) null-terminated. An LLM
can compensate for these limitations by promoting arr to
nt_arr, helping gain information about the length of the
array. Finally, the last rule (A3) instructs the model that if
the bound of a parameter is not obvious from its use in the
code, then it should add a new parameter to the procedure,
and pass the obligation to the callers (which are yet to
undergo transformation) to pass the appropriate bounds in the
newly added parameter. Note that the prompt only says what
annotations it wants, it does not say how to obtain them. The
complexity of actually doing program analysis is completely
You are given a Checked C code snippet, with a history of
refactors. The refactors introduce a new variable to
store the bounds of a pointer variable, which can be a
struct field or a global variable. Update the newly
introduced bounds variable with the correct bounds
whenever its corresponding pointer variable is assigned a
new value. Make the update in the same statement as the
assignment.
Fig. 8: Task description for adding new bounds variables
left to the model.
Figure 7 shows two examples that are provided to the
model. The first example shows applications of rules A0 and
A3 for arr, and the latter example shows an application
of rule A0 for nt_arr, where it makes a note of the off￾by-one computation for bounds of null-terminated arrays. In
terms of program elements that are provided in the prompt
of Figure 2, we give variable names of all arr and nt_arr
typed variables that are currently unannotated.
MSA follows Algorithm 1 with the above task description
to make changes to the program, with a few minor changes.
It restricts the bottom-up traversal to only the procedures in
the program, not the other top-level declarations. That is, it
goes bottom-up on the program call graph. As mentioned in
Section IV, we break cycles in the call graph arbitrarily. This
implies that the inference accuracy can suffer for mutually
recursive procedures. It is an interesting future work to in￾vestigate the use of a fix-point iteration over the mutually￾recursive cycle to improve accuracy. Further, when looking
at a particular procedure p, the model is also allowed to
add annotations on any globals or struct fields that p uses,
which are anyway present in the prelude of p. Finally, globals
and struct fields can be used in multiple procedures, each of
which are only considered one-by-one. Thus, it is possible
that different procedures produce conflicting annotations for
globals or struct fields. In this case, MSA detects this conflict in
a post-processing step and drops the corresponding annotation.
These missing annotations are left for the third transformation
that follows next.
C. Annotating Globals and Struct Fields
Annotations for global variables as well as struct fields have
a global scope. That is, these annotations are expected to
hold throughout the lifetime of the program. Consequently,
it is possible that the previous pass, which only consider one
procedure at a time, fails to infer a consistent bound for them.
In these cases, the third pass takes over.
MSA creates a new variable for storing the bounds of the
respectively element. In particular, it creates a new int-valued
global variable called count_for_g for each global variable
g of type arr that is unannotated so far. It adds the annotation
count(count_for_g) to the declaration of g. MSA also
creates a new int-valued field called count_for_f for field
f (in the same struct) of type arr that is unannotated so
far. It adds the annotation count(count_for_f) to the
field f. These changes are made symbolically by MSA and
From:
void foo(arr<struct x> a, int i) {
a[i].p = malloc(sizeof(int) * 10);
}
To:
struct x {
int count_for_p;
arr<int> p: count(count_for_p);
}
void foo(arr<struct x> a, int i){
a[i].p = malloc(sizeof(int) * 10),
a[i].count_for_p = 10;
}
Fig. 9: Example of transformation for globals and struct fields
added to the refactor history. MSA then runs Algorithm 1 with
the task description shown in Figure 8. This transformation
instructs the model to update the bounds variable each time the
corresponding array is assigned. Figure 9 shows the example
that is provided in the prompt. In terms of program elements,
MSA provides the names of the global variables and struct
fields for whom the additional variables have been introduced.
VI. EVALUATION
In this section we evaluate MSA empirically. We use gpt-
4-32k from Azure OpenAI Service as the LLM in these
experiments. We divide our experiments into two categories:
(a) benchmarking effectiveness of the different components
of our algorithm and the prompt template, and (b) evaluating
the effectiveness of MSA in inferring Checked C annotations
in real-world codebases. We also present our experience on
porting vsftpd, one of our real-world benchmarks, end-to-end.
A. Benchmarking the MSA algorithm
We vary different components of our algorithm and compare
the results to show their relative effectiveness. We consider:
(a) the background about Checked C and specific inference
instructions in the prompt template, and (b) modular inference
with dependency-order traversal of the codebase.
For this experiment, we use a subset of the Olden [10] and
Ptrdist [11] benchmarks, with code sizes that allow the entire
program to fit in a single prompt. For large codebases, modular
inference is a necessity, however, we explore if modularity
helps even for small programs that may fit in a single prompt.
We define a trivial algorithm that uses a prompt, consisting of
some instructions followed by a full C program, and queries
the LLM to obtain its output. Within this algorithm, we vary
the instructions part of the prompt with the following versions:
• V0: no background on Checked C or specific inference
instructions to the LLM,
• V1: background on Checked C and inference instructions,
as explained in Section IV.
Version V0’s performance was extremely poor, with the
LLM often bailing out either by citing the problem as too hard
Total boun3c V1 (non-modular) MSA
Inf Correct Inf Correct
mst 11 8 (72%) 5 3 (27%) 11 11 (100%)
power 7 7 (100%) 1 1 (14%) 7 7 (100%)
em3d 22 13 (59%) 13 11 (50%) 22 17 (77%)
anagram 13 2 (15%) 7 4 (30%) 13 11 (84%)
TABLE I: Comparison with boun3c and a non-modular ver￾sion of MSA on Olden (mst, power, and em3d) and Ptrdist
(anagram) benchmarks. The numbers in parentheses indicate
the percentage of total annotations inferred correctly.
lua icecast thttpd libarchive vsftpd
0
50
100
150
200
250
300
boun3c
MSA Correct
MSA Incorrect
MSA Unannotated
Fig. 10: MSA performance on real-world codebases.
or by saying there are no pointers to be annotated. Results for
V1 and MSA are shown in Table I (it also shows numbers for
boun3c). For each benchmark, the table shows the total number
of bounds annotations required, the number of annotations
inferred by the algorithm (Inf), and the number of correct
annotations amongst them (Correct). For determining which
of the inferred annotations are correct, we manually prepare
annotated versions of these benchmarks that compile with the
Checked C compiler and pass the runtime tests. Then, an
inferred annotation is defined to be correct if it matches the
manual annotation in these ground-truth versions.
As the table shows, while MSA correctly infers 86% of the
annotations on-average, the non-modular version V1 infers
only 35%. There are 5 cases across these benchmarks where
refactoring instructions—absent from V1 but present in MSA—
play a role. Otherwise, the only difference is modular analysis.
Conclusion. Without the Checked C background and infer￾ence instructions in the prompt, LLMs cannot infer annotations
even for small programs. With instructions, modular analysis
is more effective than fitting the entire (small) program in a
prompt. Thus, it is better to focus LLM on one procedure at
a time, providing it the dependencies in the context.
B. Inferring annotations in real-world codebases
Table II shows the details of real-world benchmarks that we
picked from 3C experiments [5], where 3C could not infer a
reasonable number of annotations. These benchmarks cover a
Number of Pointers
LOC RB b3c b3ch Remaining
lua 19.4K 332 53 31 279 (126 + 153)
icecast 18.2K 311 47 5 264 (26 + 238)
thttpd 7.6K 240 88 7 152 (31 + 121)
vsftpd 14.7K 134 22 15 112 (26 + 86)
libarchive 146.8K 150 35 3 115 (63 + 52)
TABLE II: Benchmark details. RB is the number of required
bound annotations. b3c is the number of annotations inferred
by boun3c, while b3ch is the number of additional annotations
inferred by boun3c heuristics. Remaining (divided into arr
and nt_arr) is the difference of RB and b3c.
variety of different domains (language interpreter, http server,
ftp server, media server, compression library, etc.) and come
from a list recommended by the Checked C community [12].
For each benchmark, the table shows the size of the benchmark
(in terms of lines of code), total number of pointers that
required an annotation (RB), the number of pointers annotated
by boun3c (b3c), additional pointers that boun3c heuristics in￾fer (b3ch), and the number of remaining unannotated pointers
(RB - b3c). We discount the boun3c heuristics from rest of
our experiments; first, the number of additional annotations
that they infer over boun3c is not substantial, and second, on
manual inspection, nearly a third of them seemed incorrect
to us. Hence, we consider Remaining as the target for MSA.
For libarchive, we ran MSA on the whole codebase, but
analyzed only a subset of the annotations for correctness (150
unannotated pointers), due to time constraints.
Figure 10 plots the performance of MSA on these bench￾marks. We categorize the inferred annotations into Correct
and Incorrect based on a manual inspection of the inferred
annotations. In total, MSA infers 877 annotations across all
benchmarks, out of which 797 annotations are correct and
80 are incorrect. Thus, MSA correctly infers 86% of the
annotations remaining after boun3c (797/922). Of the 797
correctly inferred annotations, 212 are array pointer bound
annotations (78% of remaining array pointer bounds) while
585 are NT array bounds annotations (90% of remaining NT
array bounds); of these 585 NT array annotations, 532 (91%)
are count(0) annotations whereas only 9% (26/272) of
the array pointer bounds annotations missed by boun3c are
count(0).
Below is a code snippet from icecast that shows a couple
of annotations that MSA infers but boun3c could not:
// MD5Update(...,
// arr<char> buf:count(n), int n);
//
// util_bin_to_hex(..., int n)
// : nt_arr<char> count (n * 2);
nt_arr<char> get_hash
(const char *data: nt_arr<char>, int len) {
...
MD5Update(&context, data, len); ...
return (util_bin_to_hex(digest, 16));
}
MSA constructs the context for get_hash, shown as com￾ments, and from this information, it is able to infer that data
Functions Globals, structs Queries Input, Output size
lua 10 7 246 2627, 1895
icecast 45 2 192 2998, 1988
thttpd 82 6 104 2861, 3441
vsftpd 6 0 111 2322, 1600
libarchive 58 89 805 3360, 1847
TABLE III: Number of refactorings applied by MSA, total
number of queries made to the LLM and average number of
input and output tokens per query
has count len and the returned value has count 32. boun3c
is unable to infer the return type annotation because it is not
able to infer the n*2 annotation for util_bin_to_hex (it
doesn’t support arithmetic expressions in annotations). It is
also unable to infer annotations for data as one of the call
sites for get_hash is get_hash(p, strlen(p)), and
boun3c is unable to correlate the two parameters of the call.
Following is an example from thttpd where MSA suc￾cessfully changes an arr annotation from typ3c to nt_arr.
static void defang(arr<char> str, ...) {
arr<char> cp1 = (void *) 0;
for(cp1 = str; *cp1 != ’\0’; cp1++) {
// access *cp1
}
Here, typ3c marks the str argument and cp1 as
arr<char>. However, analyzing the access patterns
(loop iterating until the null character), MSA infers an
nt_arr<char> type with count(0) annotation for both of
them. There were also multiple instances when MSA refactors
the code to allow additional annotations. For example:
void luaL_setfuncs (arr<const luaL_Reg> l) {
for (; l->name != NULL; l++) { ... }
}
In this function, from lua, the array pointer l is incremented
until its name field is NULL. Since there is no reason￾able annotation for it in the code as written, MSA adds a
bounds argument l_count to the function and the annotation
count(l_count) to l.
Out of the 877 annotations that MSA infers, 80 (9%) are
incorrect. Most of these are subtle cases where pointers are
accessed with unusual patterns. E.g., in the following snippet
from lua, the pointer is accessed with a negative index:
copy2buff(StkId top:arr<StackValue>, int n) {
do {
// use *(top - n)
} while (--n > 0);
}
MSA infers count(n) for the top pointer, whereas the
correct annotation would be bound(top - n, top). Im￾proving performance on such code patterns is future work.
The annotations that MSA does not infer (45/922) are mostly
due to the A1 rule of Figure 6. In very few cases, the LLM
produced annotations that referred to variables that are not
in scope; these are dropped automatically by MSA as a post￾processing step.
Table III shows the number of function call and globals
and struct refactorings that MSA applies per benchmark. The
column Functions includes both the number of function pa￾rameters added as well as modifications to respective function
calls. Similarly, the column for globals and structs include
both the number of global variables and struct fields added
as well as their corresponding assignments. For real-world
codebases, the nested pointers to struct transformation did not
appear (while one case of this appears in Table I).
Table III also shows the number of LLM queries required
per benchmark, and the average number of input and output
tokens (including all completions) per query.
Conclusion. When porting real-world codebases to Checked
C, 3C leaves a substantial number of pointers unannotated.
MSA is able to infer majority of these pointers (86% in our
experiments). We observe that MSA is able to infer annotations
that require sophisticated code reasoning. We also observe
that porting is not just about inferring annotations; code edits,
function refactorings, globals and struct refactoring are also
commonplace. Their support in MSA is important for real￾world codebases.
C. vsftpd: End-to-end case study
We present a case study on end-to-end porting of vsftpd.
In this exercise, we take the output of MSA and make further
edits so that it successfully compiles with Checked C. We
started by reverting the incorrect annotations and adding the
missing annotations in the MSA output. This includes the red
and blue regions in the vsftpd bar in Figure 10; we corrected
3 incorrect annotations requiring 6 edits and added 8 missing
annotations requiring 22 edits. The remaining work involved
passing the Checked C compiler. For that, we had to change
a further 148 lines in the code. These changes are the known
caveats in making a codebase compile with Checked C [13].
For example, we had to add dynamic bound casts (that are
checked at runtime) and assume casts, when the Checked C
compiler could not reason about the bounds due to, e.g., lack
of flow-sensitivity. An example is as follows:
// p : nt_arr<char> count(0)
if (p[0] != ’-’)
{...}
else
{ // access p[1] }
In the else branch, accessing p[1] is safe because we
know that p is an nt_arr and that p[0] is not null. However,
the Checked C compiler is unable to reason about this, so we
added an assume bound cast to bypass the checker. In a few
other cases, the code was using the same pointer variable to
represent different sized arrays. For such cases, we added new
variables for differently sized arrays so that all variables are
used in a bound-consistent manner. Once the code compiled,
we were able to run the executable and start the FTP server.
We were prepared to debug any runtime crashes due to failed
checks inserted by Checked C (this can be caused either by a
real memory-safety violation in the code, or due to incorrect
dynamic casts). However, we did not encounter any such cases.
Conclusion. Although this was only one case study, our
experience showed that MSA annotation indeed helped. MSA
roughly performed 58% of the work requires for end-to-end
porting (250/426 edits). It inferred 123 annotations correctly
which led to 250 edits, leaving 11 annotations for manual
work, requiring 28 edits. In contrast, manually adding all the
112 annotations missed by 3C would have required much
more effort. Further 148 edits were required to make the
code compile; these edits were the easiest conceptually. We
acknowledge that further work is required in this space to
make a claim on end-to-end porting.
VII. THREATS TO VALIDITY
One potential threat to validity is data contamination, if the
Checked C versions of programs were part of the training data
of the LLM. Given our use of LLMs from OpenAI, whose
training data is not publicly known, there is no good way
to completely rule it out. We note that Checked C versions
of icecast, thttpd and vsftpd are indeed available
publicly. However, there are no publicly available Checked
C versions of lua and libarchive, to the best of our
knowledge. The results across these benchmarks are largely
consistent. Further, the LLM demonstrates poor knowledge of
Checked C, unable to carry out the task without a background
(V0, Section VI). Our contribution of whole-program trans￾formations in a modular fashion stands, irrespective of data
contamination (V1 vs. MSA, Section VI). Also, Checked C
code is extremely rare compared to other languages.
Another internal threat is our manual assessment of the
correctness of annotations produced by MSA. We counter this
by having multiple authors make independent assessment, then
discussing to reach consensus. In some cases (Table I and
Section VI-C), we validate correctness using the compiler, and
found that our assessments were indeed correct.
An external threat to validity is that GPT4 can get updated
over time by OpenAI, changing the performance of MSA. We
also make no claim on the results that will be obtained with
other LLMs.
VIII. RELATED WORK
There are several approaches for memory safety. One set of
tools use binary instrumentation to ensure safety of memory
accesses [14], [15], [16]. These do not require recompilation,
but suffer from high performance overheads. Overheads are
lower for source-level instrumentation tools, at the cost of
needing recompilation, but still high enough to prohibit pro￾duction use [17], [18], [19]. Cyclone [3] is a safe dialect of
C that extends pointers with labels (ordinary, never-null, and
fat) and uses them to instrument safety checks. Deputy [2]
provides bounded pointers and tagged unions. Checked C takes
inspiration from this line of work and goes much further in
building a production-ready compiler [20].
There has been a flurry of recent work in using LLMs
to help improve the productivity of software developers. Our
work builds along in this direction, while focusing specifically
on memory safety through a safe C dialect. We are unaware of
prior LLM-based (or ML-based) work for this problem; and
we have already presented a detailed comparion against 3C,
the state-of-the-art symbolic tool for this problem.
LLMs have been extensively used for program synthe￾sis [21], [22], [23], [24], [25], including both code generation
(generating a program from a natural language description)
and completion (automatically completing an incomplete code
fragment). Recent auto-completion systems are even able to
operate across files within a repository [26]. There have
also been proposals that use LLMs to synthesize repair
patches [27], [28], [29], surpassing the capabilities of current
automated program repair tools. In the direction of software
security, Pearce et al. [30] train their own GPT2 model to eval￾uate the efficacy of LLMs at generating and repairing software
vulnerabilities. Their study is restricted to small “vulnerability
patterns” that lead to well-known CWE/CVEs. In the space of
LLMs for software engineering, our contribution on whole￾program transformations, with the ability of making several
correlated edits to a program using a simple task description,
is novel. We refer the reader to survey papers [31], [32] for
more work on leveraging LLMs for software engineering.
There is also a series of work that explores the synergy of
LLMs with program analysis. Llift [33] combines LLMs with
static analysis tools to identify use-before-initialization bugs in
the Linux kernel. Lemur [34] uses LLMs to infer loop invari￾ants that are validated by a symbolic verifier. However, Lemur
is evaluated only on small benchmarks that fit in a single LLM
prompt. Our whole program transformation framework and
techniques should be applicable to loop invariant inference as
well. Chakroborty et al. [35] develop techniques to rank LLM￾generated candidate loop invariants. It is an interesting future
work to investigate if similar rankers can be developed for
ranking LLM-generated candidates for Checked C annotations.
IX. CONCLUSION
Large Language Models have demonstrated promising ca￾pabilities for software engineering tasks. Tools like Github
Copilot are used by millions of developers. However, for
reliability of the LLM-generated code, the developers are
on their own. On the other side, formal verification tools
provide strong guarantees but are difficult to deploy on a
large scale. They require annotations, program refactorings,
etc. to be effective. Combining LLM program comprehension
capabilities with formal verification tools provides best of both
the worlds. While tedious tasks of annotating and refactoring
code can be delegated to LLMs, they need not be trusted—
formal verification tools can do the validation. In this paper,
we have presented a general framework to combine LLMs
with formal verification tools, instantiated with the concrete
problem of inferring memory safety annotations. On our
benchmarks, we find that LLMs are able to reason about the
code to generate annotations, refactoring the code as and when
required. Still, they are outside the Trusted Computing Base as
the Checked C compiler catches any LLM mistakes (statically
or at runtime). We invite the community to further explore the
synergy between formal methods and LLMs.
REFERENCES
[1] A. S. Elliott, A. Ruef, M. Hicks, and D. Tarditi, “Checked c: Making c
safe by extension,” in 2018 IEEE Cybersecurity Development (SecDev),
2018, pp. 53–60.
[2] J. Condit, M. Harren, Z. Anderson, D. Gay, and G. C. Necula,
“Dependent types for low-level programming,” in Proceedings of the
16th European Symposium on Programming, ser. ESOP’07. Berlin,
Heidelberg: Springer-Verlag, 2007, p. 520–535.
[3] T. Jim, J. G. Morrisett, D. Grossman, M. W. Hicks, J. Cheney, and
Y. Wang, “Cyclone: A safe dialect of c,” in Proceedings of the General
Track of the Annual Conference on USENIX Annual Technical Confer￾ence, ser. ATEC ’02. USA: USENIX Association, 2002, p. 275–288.
[4] A. Ziegler, E. Kalliamvakou, X. A. Li, A. Rice, D. Rifkin, S. Simister,
G. Sittampalam, and E. Aftandilian, “Measuring github copilot’s impact
on productivity,” Commun. ACM, vol. 67, no. 3, p. 54–63, feb 2024.
[Online]. Available: https://doi.org/10.1145/3633453
[5] A. Machiry, J. Kastner, M. McCutchen, A. Eline, K. Headley,
and M. Hicks, “C to checked c by 3c,” Proc. ACM Program.
Lang., vol. 6, no. OOPSLA1, apr 2022. [Online]. Available:
https://doi.org/10.1145/3527322
[6] J. Duan, Y. Yang, J. Zhou, and J. Criswell, “Refactoring the freebsd
kernel with checked C,” in IEEE Secure Development, SecDev 2020,
Atlanta, GA, USA, September 28-30, 2020. IEEE, 2020, pp. 15–22.
[Online]. Available: https://doi.org/10.1109/SecDev45635.2020.00018
[7] J. S. Foster, M. Fahndrich, and A. Aiken, “A theory of type ¨
qualifiers,” in Proceedings of the ACM SIGPLAN 1999 Conference on
Programming Language Design and Implementation, ser. PLDI ’99.
New York, NY, USA: Association for Computing Machinery, 1999, p.
192–203. [Online]. Available: https://doi.org/10.1145/301618.301665
[8] A. Ruef, L. Lampropoulos, I. Sweet, D. Tarditi, and M. Hicks,
“Achieving safety incrementally with checked C,” in Principles of
Security and Trust - 8th International Conference, POST 2019, Held
as Part of the European Joint Conferences on Theory and Practice
of Software, ETAPS 2019, Prague, Czech Republic, April 6-11, 2019,
Proceedings, ser. Lecture Notes in Computer Science, F. Nielson and
D. Sands, Eds., vol. 11426. Springer, 2019, pp. 76–98. [Online].
Available: https://doi.org/10.1007/978-3-030-17138-4\ 4
[9] P. Deligiannis, A. Lal, N. Mehrotra, and A. Rastogi, “Fixing rust
compilation errors using LLMs,” CoRR, vol. abs/2308.05177, 2023.
[Online]. Available: https://doi.org/10.48550/arXiv.2308.05177
[10] A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren, “Supporting
dynamic data structures on distributed-memory machines,” ACM Trans.
Program. Lang. Syst., 1995.
[11] T. M. Austin, S. E. Breach, and G. S. Sohi, “Efficient detection of all
pointer and array access errors,” ser. PLDI ’94, 1994.
[12] Checked C, “Benchmarks for evaluating checked C,” https://github.com/
microsoft/checkedc/wiki/Benchmarks-for-evaluating-Checked-C, 2019.
[13] CheckedC Wiki, https://github.com/checkedc/checkedc/wiki/
C-Conversion-Tips, 2023.
[14] R. Hastings and B. Joyce, “Purify: Fast detection of memory leaks and
access errors,” in Proceedings of the Summer 1992 USENIX Conference,
1992, pp. 125–138.
[15] N. Nethercote and J. Seward, “Valgrind: a framework for heavyweight
dynamic binary instrumentation,” in Proceedings of the 28th
ACM SIGPLAN Conference on Programming Language Design
and Implementation, ser. PLDI ’07. New York, NY, USA: Association
for Computing Machinery, 2007, p. 89–100. [Online]. Available:
https://doi.org/10.1145/1250734.1250746
[16] M. Burrows, S. N. Freund, and J. L. Wiener, “Run-time type checking for
binary programs,” in Proceedings of the 12th International Conference
on Compiler Construction, 2003.
[17] T. M. Austin, S. E. Breach, and G. S. Sohi, “Efficient detection
of all pointer and array access errors,” in Proceedings of the ACM
SIGPLAN’94 Conference on Programming Language Design and Imple￾mentation (PLDI), Orlando, Florida, USA, June 20-24, 1994, V. Sarkar,
B. G. Ryder, and M. L. Soffa, Eds., 1994.
[18] G. C. Necula, S. McPeak, and W. Weimer, “Ccured: type-safe retrofitting
of legacy code,” in Proceedings of the 29th ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, ser. POPL ’02.
New York, NY, USA: Association for Computing Machinery, 2002, p.
128–139. [Online]. Available: https://doi.org/10.1145/503272.503286
[19] S. Nagarakatte, J. Zhao, M. M. K. Martin, and S. Zdancewic, “Soft￾bound: highly compatible and complete spatial memory safety for c,”
in Proceedings of the 2009 ACM SIGPLAN Conference on Program￾ming Language Design and Implementation, PLDI 2009, M. Hind and
A. Diwan, Eds. ACM, 2009.
[20] Checked C, “Checked C clang compiler repository,” https://github.com/
checkedc/checkedc-llvm-project, 2024.
[21] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond,
T. Eccles, J. Keeling, F. Gimeno, A. D. Lago, T. Hubert, P. Choy,
C. de Masson d’Autume, I. Babuschkin, X. Chen, P.-S. Huang,
J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, D. J. Mankowitz,
E. S. Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu, and
O. Vinyals, “Competition-level code generation with alphacode,”
Science, vol. 378, no. 6624, pp. 1092–1097, 2022. [Online]. Available:
https://www.science.org/doi/abs/10.1126/science.abq1158
[22] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese,
and C. Xiong, “Codegen: An open large language model for code with
multi-turn program synthesis,” in ICLR, 2023.
[23] G. Poesia, A. Polozov, V. Le, A. Tiwari, G. Soares, C. Meek,
and S. Gulwani, “Synchromesh: Reliable code generation from pre￾trained language models,” in International Conference on Learning
Representations, 2022. [Online]. Available: https://openreview.net/
forum?id=KmtVD97J43e
[24] F. F. Xu, U. Alon, G. Neubig, and V. J. Hellendoorn, “A systematic
evaluation of large language models of code,” in Proceedings
of the 6th ACM SIGPLAN International Symposium on Machine
Programming, ser. MAPS 2022. New York, NY, USA: Association
for Computing Machinery, 2022, p. 1–10. [Online]. Available:
https://doi.org/10.1145/3520312.3534862
[25] P. Vaithilingam, T. Zhang, and E. L. Glassman, “Expectation vs.
experience: Evaluating the usability of code generation tools powered
by large language models,” in Extended Abstracts of the 2022 CHI
Conference on Human Factors in Computing Systems, ser. CHI EA
’22. New York, NY, USA: Association for Computing Machinery,
2022. [Online]. Available: https://doi.org/10.1145/3491101.3519665
[26] T. Liu, C. Xu, and J. McAuley, “Repobench: Benchmarking repository￾level code auto-completion systems,” in The Twelfth International
Conference on Learning Representations, 2024. [Online]. Available:
https://openreview.net/forum?id=pPjZIOuQuF
[27] C. S. Xia, Y. Wei, and L. Zhang, “Automated program repair in the era
of large pre-trained language models,” in ICSE, 2023.
[28] J. A. Prenner, H. Babii, and R. Robbes, “Can openai’s codex fix bugs?
an evaluation on quixbugs,” in Proceedings of the Third International
Workshop on Automated Program Repair, ser. APR ’22. New York,
NY, USA: Association for Computing Machinery, 2022, p. 69–75.
[Online]. Available: https://doi.org/10.1145/3524459.3527351
[29] N. Nashid, M. Sintaha, and A. Mesbah, “Retrieval-based prompt se￾lection for code-related few-shot learning,” in 2023 IEEE/ACM 45th
International Conference on Software Engineering (ICSE), 2023.
[30] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt, “Examining
zero-shot vulnerability repair with large language models,” in 2023 IEEE
Symposium on Security and Privacy (SP). Los Alamitos, CA, USA:
IEEE Computer Society, may 2023, pp. 2339–2356. [Online]. Available:
https://doi.ieeecomputersociety.org/10.1109/SP46215.2023.10179420
[31] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sengupta, S. Yoo,
and J. M. Zhang, “Large language models for software engineering: Sur￾vey and open problems,” in 2023 IEEE/ACM International Conference
on Software Engineering: Future of Software Engineering (ICSE-FoSE).
IEEE Computer Society, may 2023, pp. 31–53.
[32] X. Hou, Y. Zhao, Y. Liu, Z. Yang, K. Wang, L. Li, X. Luo, D. Lo,
J. Grundy, and H. Wang, “Large language models for software engi￾neering: A systematic literature review,” arXiv:2308.10620, 2023.
[33] H. Li, Y. Hao, Y. Zhai, and Z. Qian, “Enhancing static analysis for
practical bug detection: An LLM-integrated approach,” in Proceedings
of the ACM on Programming Languages (PACMPL), Issue OOPSLA,
2024.
[34] H. Wu, C. Barrett, and N. Narodytska, “Lemur: Integrating large
language models in automated program verification,” in The 3rd
Workshop on Mathematical Reasoning and AI at NeurIPS’23, 2023.
[Online]. Available: https://openreview.net/forum?id=NxHl2SPhyT
[35] S. Chakraborty, S. K. Lahiri, S. Fakhoury, A. Lal, M. Musuvathi,
A. Rastogi, A. Senthilnathan, R. Sharma, and N. Swamy, “Ranking
LLM-generated loop invariants for program verification,” in The
2023 Conference on Empirical Methods in Natural Language
Processing, 2023. [Online]. Available: https://openreview.net/forum?id=
R7f5euZ9RAHow are you managing the configuration of your workload?
We automate creation of Azure Analysis Services instances with ARM templates, PowerShell scripts, or Bicep files. 
We use Dynamic Management Views (DMVs) in Analysis Services to monitor server instances. 
We monitor server metrics provided by Azure Monitor (memory, CPU usage, number of client connections, query resource consumption, etc.). 
We enable diagnostic logging for Azure Analysis Services to monitor and send logs to Azure storage, stream them to Azure Event Hubs, or export them to Azure Monitor logs. 
We add resource health alerts for metrics such as memory usage, memory limit High, and memory limit Hard. 
None of the above. 
________________________________________
What operational considerations are you making regarding the deployment of your workload?
We're becoming familiar with Azure Analysis Services resource and object limits to learn what happens when those resource limits are hit or exceeded, and describe the resource governance mechanisms used to enforce these limits. 
No routine and manual operational changes are performed outside of IaC (Infrastructure as Code) to prevent configuration drift by enforcing consistency representing desired environment states. 
Critical test environments have 1:1 parity with the production environment. 
None of the above. 
________________________________________
What processes and procedures have you adopted to optimize workload operability?
Specific methodologies, like DevOps, are used to structure the development and operations process. 
We leverage central Azure monitoring tools like Azure Monitor. 
Data analysts, data engineers, development teams, and the operations team collaborate to resolve production issues that are clearly defined and well understood. 
Operational shortcomings and failures are analyzed, post-mortems are performed and used to improve and refine operational procedures. 
There are tools or processes in place, such as Microsoft Entra Privileged Identity Management, to grant access to critical instances on a just-in-time basis. 
Azure Resource Tags are used to enrich our AAS instance with operational metadata. 
There are tools and processes, like Azure Policy, in place to govern available services, enforce mandatory operational functionality and ensure compliance. 
________________________________________
How are you monitoring for a healthy workload?
We use Azure Monitor to perform more in-depth diagnostics, track performance, and identify trends using the platform metrics. 
We use Azure Diagnostics to offload Platform logs. 
We use Extended Events. 
We use Dynamic Management Views (DMVs). 
________________________________________
Analysis Services: Performance Efficiency 
How are you designing your workload to scale?
We maintain a healthy workload by automating the scaling of the Azure Analysis Services instances. 
We use read-only replicas scale-out to have queries return consistent data while processing data. 
We separate the processing server from the query pool to ensure that client queries aren't affected by processing operations. 
None of the above. 
________________________________________
How are you handling user load?
We create a query pool with up to seven additional query replicas (eight total, including the server). 
We simplify the query or its calculations if the query is too memory intensive. 
________________________________________
How are you ensuring that you have sufficient memory?
We monitor datasets to not exceed available server resource memory. 
We monitor the memory usage broken out by database. 
None of the above. 
________________________________________
How are you managing your data to handle scale?
We use partitioning to take advantage of incremental loads. 
We refresh (process) in-memory models to update cached data from data sources. 
We keep the data model as simple as possible by removing unneeded columns and keeping the size to the minimum, paying attention to the data types. 
None of the above. 
________________________________________
How are you monitoring to ensure the workload is scaling appropriately?
With Azure service principal support, we perform unattended refresh operations using PowerShell, TOM, TMSL, or REST to make sure our model data is always up to date. 
We implement asynchronous refresh with the REST APIs to mitigate long-running operations. 
None of the above. 
________________________________________
Data Factory: Reliability 
Data Factory: Security 
Data Factory: Cost Optimization 
Data Factory: Operational Excellence 
Data Factory: Performance Efficiency 
Azure Databricks: Reliability 
How do you implement reliability Best Practices?
We deploy workspaces in multiple subscriptions based on service limits, including Databricks workspace limits and Azure subscription limits. 
We leverage clusters pools with TTL=60 min, or interactive clusters for job-based scenarios where we expect to spin up or down quickly. 
We stagger job-based clusters in the same workspace for scenarios requiring quick spin up and down of job clusters at less than 5 minutes as the recommended interval. 
We use Cluster Scoped Init scripts rather than global or named scripts. 
We ensure that we've configured an appropriate level of data redundancy for our use case. 
None of the above. 
________________________________________
How do you implement disaster recovery scenarios?
We disable RA-GRS stores in development subscriptions to reduce cost. 
We use RA-GRS storage accounts only when required to meet disaster planning. 
We enable soft delete, snapshot, and point in time recovery (PITR) for storage. 
We perform daily backups of Databricks configuration. 
We use the cluster log delivery feature to manage logs. 
________________________________________
Azure Databricks: Security 
How do you implement security Best Practices?
We store any production data in default Azure Databricks file system (DBFS) folders. 
We deploy the Databricks workspace in our virtual network. 
We review and plan to implement controls in Microsoft Blueprints for HiTrust / HIPAA and PCI/DSS. 
We have a process in place to periodically regenerate our account keys. 
We implement a security development lifecycle and threat model to assess risks in our application. 
We enable advanced threat protection for storage. 
________________________________________
How do you implement authentication controls?
We enable access control lists to configure permissions at the workspace, clusters, pools, jobs, and data tables. 
We use credential passthrough to authenticate automatically. 
We use Azure Key Vault (AKV) to store secrets, including credentials. 
We enable customer manage keys (CMK) for notebooks and root Databricks File System (DBFS). 
We enable Oauth authentication. 
________________________________________
How do you implement encryption on your clusters?
We encrypt traffic between clusters and worker nodes. 
We set up a minimum transport layer security (TLS) version for all storage accounts to TLS 1.2. 
We limit shared access signature (third-party tools) tokens to HTTPS connections only. 
None of the above. 
________________________________________
How do you implement security at the networking level?
We enable IP access lists to restrict access to certain IP addresses. 
We limit private IP addresses. 
We leverage Azure Private Endpoint. 
We leverage No Public IP (NPIP). 
We safelist service principals' names and personal access tokens. 
We enable virtual network (Vnet) injection. 
None of the above. 
________________________________________
How do you audit and monitor your Databricks platform for security?
We enable audit logging. 
We ingest log data into a security information and event manager (SIEM) for security monitoring. 
We review and reconcile user access. 
________________________________________
Azure Databricks: Cost Optimization 
How do you implement cost optimization Best Practices?
Users can share autoscaling clusters rather than each user having to create a separate cluster. 
We leverage the right SKU for the scenario, that is, Jobs Compute for data engineering and Batch ELT workload with single Jobs Compute cluster. 
We use chargeback scenarios. 
We review file formats and compute and network and identify areas for cost optimization. 
We regularly use the delta optimizer to merge small files into larger files. 
None of the above. 
________________________________________
How do you implement cost savings?
We pre-purchase commit units and reserve VM instances when possible. 
We choose Azure regions that offer the lowest cost while meeting performance requirements. 
None of the above. 
________________________________________
How do you monitor Azure Databricks costs?
We monitor costs of clusters using the cost analysis report. 
We set up budget alerts to monitor costs. 
We use Databricks Overwatch. 
None of the above. 
________________________________________
Azure Databricks: Operational Excellence 
How do you implement operational Best Practices?
We do regular performance, scalability, and stress testing. 
We build a process to review Azure Advisor and Azure Security Center recommendations on a regular cadence. 
We review and address platform changes from the release notes. 
We split workspaces for Dev, QA, and Production. 
We use automated clusters for production jobs instead of interactive clusters. 
We run auto-optimization to improve performance for the downstream. 
We optimize and curate delta tables (silver tables). 
We review the continuous integration and continuous deployment (CI/CD) automation framework. 
We run monthly log reviews to validate environment health. 
We terminate and rebuild clusters on a frequent basis to ensure Databricks clusters are patched by Microsoft. 
________________________________________
How do you monitor your Databricks platform for operations?
We enable logging and alerting for all components in the Databricks platform. 
We use dashboards to visualize metrics. 
We set up any cluster activity monitoring. 
We enable storage account logging. 
We put a single point of log aggregation in place. 
We use Network Watcher to collect and Monitor network activity. 
We ensure that all application-level monitoring is enabled. 
We use a single pane of glass with telemetry using Log Analytics logs to EventHub for consumption by other systems. 
We consider ingesting selected logs from Azure storage accounts to Azure Monitor. 
We monitor for 500 errors by Databricks, Blob storage, or other HTTP endpoints. 
We implement cluster secure management. 
________________________________________
What components of your Azure environment do you monitor as part of your operations practice?
We use approved time synchronization sources. 
We configure central security log management. 
We enable audit logging for Azure resources. 
We collect security logs from operating systems. 
We configure security log storage retention. 
We monitor and review logs. 
We enable alerts for anomalous activities. 
We centralize anti-malware logging. 
We enable DNS query logging. 
We enable command-line audit logging. 
________________________________________
Azure Databricks: Performance Efficiency 
How do you implement performance Best Practices?
We choose the correct cluster size by doing iterative performance testing. 
We regularly conduct rigorous quality and unit testing to validate performance that meets requirements. 
We leverage the auto-scaling feature with auto-terminate. 
We turn shuffle off for optimal performance. 
We check for data skew. 
We ensure that the file size and format are homogenous. 
We consistently use DataFrame API and SparkSQL. 
We avoid user-defined functions (UDFs) , especially in Python or R. 
We consider and test repartitioning if we need to join large tables. 
We ensure Azure limits are increased, for example, Public IP limits and so on. 
________________________________________
How do you optimize performance efficiency?
We reorder skew joins. 
We optimize for performance with Delta Lake format to get the best price to performance ratio. 
We partition our data. 
We check for large shuffle joins and try replacing them with broadcasts. 
We use Delta Lake with Z-order and optimize the latest Databricks Runtime (DBR) to get the best performance. 
We use Parquet file format. 
We use Delta-Cache. 
________________________________________
How do you test performance efficiency on the Azure Databricks clusters?
We run a proof of concept to determine how often to execute based on data ingestion and query patterns. 
We engage with Azure Engineers to ensure that capacity can be handled in the backend and limits get increased. 
We engage with the networking team during testing. 
We ensure throttling is not hit by setting up Azure Data Lake Storage Gen 2 limits. 
We review all Azure and Databricks limits. 
We develop a medium-sized cluster of 2-8 nodes, with VMs matched to the workload class, as explained earlier. 
We run end to end tests on larger representative data while measuring CPU, memory, and I/O used by the cluster at an aggregate level. 
We optimize the cluster to remove bottlenecks. 
________________________________________
How do you monitor your Databricks platform for performance efficiency?
We troubleshoot performance bottlenecks by using dashboards to identify job and stage latency and streaming throughput. 
We validate whether upstream components can sustain the load required to pass through them. 
We run scheduled optimization on delta tables. 
We tune shuffle for optimal performance. 
We use autoscaling methodologies whenever possible. 
We partition our data following Best Practices. 
None of the above. 
________________________________________
How do you support interactive analytics using shared high-concurrency clusters?
We deploy a shared cluster instead of letting each user create their cluster. 
We create the shared cluster in High Concurrency mode instead of Standard mode. 
We configure security on the shared high concurrency cluster. 
None of the above. 
________________________________________
Data Explorer: Reliability 
What reliability targets and metrics have you defined for your application?
Ensure that the average CPU is running at 80% capacity or less and cache utilization is 100%. 
Use Resource Health to monitor the status of Azure Data Explorer. 
________________________________________
How have you ensured that your application architecture is resilient to failures?
This question was left unanswered 
________________________________________
How are you handling disaster recovery for this workload?
This question was left unanswered 
________________________________________
How do you monitor and measure application health?
This question was left unanswered 
________________________________________
Data Explorer: Security 
What action are you taking to meet your compliance and governance requirements?
This question was left unanswered 
________________________________________
How are you protecting data for this workload?
This question was left unanswered 
________________________________________
How are you managing identity for this workload?
This question was left unanswered 
________________________________________
How do you keep your Azure Data Explorer cluster from being exposed to the internet?
This question was left unanswered 
________________________________________
Data Explorer: Cost optimization 
What actions are you taking to optimize cloud costs?
This question was left unanswered 
________________________________________
How do you ensure that cloud resources are appropriately provisioned?
This question was left unanswered 
________________________________________
How is your organization modeling cloud costs?
This question was left unanswered 
________________________________________
How do you manage the storage footprint of your digital assets?
This question was left unanswered 
________________________________________
How are you monitoring your costs?
This question was left unanswered 
________________________________________
What tradeoffs have you made to optimize for cost?
This question was left unanswered 
________________________________________
Data Explorer: Operational excellence 
How are you designing your applications to take DevOps into account?
This question was left unanswered 
________________________________________
How are you managing the configuration of your workload?
This question was left unanswered 
________________________________________
What considerations are you making around the deployment of your infrastructure?
This question was left unanswered 
________________________________________
Are you using best practices for Kusto queries?
This question was left unanswered 
________________________________________
How are you monitoring your deployments and workload?
This question was left unanswered 
________________________________________
Data Explorer: Performance efficiency 
How are you designing your workload to scale?
This question was left unanswered 
________________________________________
How do you optimize Azure Data Explorer workloads for performance?
This question was left unanswered 
________________________________________
How are you ensuring that you have sufficient capacity?
This question was left unanswered 
________________________________________
How are you monitoring to ensure the workload is scaling appropriately?
This question was left unanswered 
________________________________________
Synapse: Reliability 
What reliability targets and metrics have you defined for your application?
This question was left unanswered 
________________________________________
How have you ensured that your application architecture is resilient to failures?
This question was left unanswered 
________________________________________
How have you ensured required capacity and services are available in targeted regions?
This question was left unanswered 
________________________________________
How are you handling disaster recovery for this workload?
This question was left unanswered 
________________________________________
What decisions have been taken to ensure the application platform meets your reliability requirements?
This question was left unanswered 
________________________________________
How does your application logic handle exceptions and errors?
This question was left unanswered 
________________________________________
What decisions have been taken to ensure networking and connectivity meets your reliability requirements?
This question was left unanswered 
________________________________________
What reliability allowances for scalability and performance have you made?
This question was left unanswered 
________________________________________
What reliability allowances for security have you made?
This question was left unanswered 
________________________________________
What reliability allowances for operations have you made?
This question was left unanswered 
________________________________________
How do you test the application to ensure it is fault tolerant?
This question was left unanswered 
________________________________________
How do you monitor and measure application health?
This question was left unanswered 
________________________________________
Synapse: Security 
What design considerations did you make in your workload in regards to security?
This question was left unanswered 
________________________________________
What considerations for compliance and governance do you need to take?
This question was left unanswered 
________________________________________
How are you managing encryption for this workload?
This question was left unanswered 
________________________________________
How are you managing identity for this workload?
This question was left unanswered 
________________________________________
How have you secured the network of your workload?
This question was left unanswered 
________________________________________
What tradeoffs do you need to make to meet your security goals?
This question was left unanswered 
________________________________________
How are you ensuring your critical accounts are protected?
This question was left unanswered 
________________________________________
Synapse: Cost Optimization 
What actions are you taking to optimize cloud costs?
This question was left unanswered 
________________________________________
How do you ensure that cloud resources are appropriately provisioned?
This question was left unanswered 
________________________________________
How is your organization modeling cloud costs?
This question was left unanswered 
________________________________________
How do you manage the storage footprint of your digital assets?
This question was left unanswered 
________________________________________
How are you monitoring your costs?
This question was left unanswered 
________________________________________
What trade-offs have you made to optimize for cost?
This question was left unanswered 
________________________________________
Synapse: Operational Excellence 
How are you designing your applications to take into account DevOps?
This question was left unanswered 
________________________________________
How are you managing the configuration of your workload?
This question was left unanswered 
________________________________________
What considerations are you making around the deployment of your infrastructure?
This question was left unanswered 
________________________________________
How is development done on this workload?
This question was left unanswered 
________________________________________
How are you monitoring your deployments and workload?
This question was left unanswered 
________________________________________
How are you integrating your workloads?
This question was left unanswered 
________________________________________
Synapse: Performance Efficiency 
How are you designing your workload to scale?
This question was left unanswered 
________________________________________
How do you optimize Synapse workloads for performance?
This question was left unanswered 
________________________________________
How are you ensuring you have sufficient capacity?
This question was left unanswered 
________________________________________
How are you managing your data to handle scale?
This question was left unanswered 
________________________________________
How are you monitoring to ensure the workload is scaling appropriately?
This question was left unanswered 
________________________________________
ADLS Gen2: Reliability 
How have you ensured that your application architecture is resilient to failures?
This question was left unanswered 
________________________________________
How have you ensured required capacity and services are available in targeted regions?
This question was left unanswered 
________________________________________
How are you handling disaster recovery for this workload?
This question was left unanswered 
________________________________________
How does your application logic handle exceptions and errors?
This question was left unanswered 
________________________________________
What decisions have been taken to ensure networking and connectivity meets your reliability requirements?
This question was left unanswered 
________________________________________
How do you monitor and measure application health?
This question was left unanswered 
________________________________________
How do you mitigate accidental deletion of your data?
This question was left unanswered 
________________________________________
How do you ensure the availability of your most critical datasets?
This question was left unanswered 
________________________________________
How do you ensure that the data is reliable?
This question was left unanswered 
________________________________________
ADLS Gen2: Security 
What design considerations did you make in your workload with regard to security?
This question was left unanswered 
________________________________________
What considerations for compliance and governance do you need to take?
This question was left unanswered 
________________________________________
How are you managing encryption for this workload?
This question was left unanswered 
________________________________________
How are you managing identity and authorization for this workload?
This question was left unanswered 
________________________________________
How have you secured the network of your workload?
This question was left unanswered 
________________________________________
What tradeoffs do you need to make to meet your security goals?
This question was left unanswered 
________________________________________
ADLS Gen2: Cost Optimization 
What actions are you taking to optimize cloud costs?
This question was left unanswered 
________________________________________
How are you monitoring your costs?
This question was left unanswered 
________________________________________
ADLS Gen2: Operational Excellence 
What tooling do you leverage to monitor your ADLS accounts?
This question was left unanswered 
________________________________________
What considerations are you making around the deployment of your workload?
This question was left unanswered 
________________________________________
How are you integrating your workloads?
This question was left unanswered 
________________________________________
What processes and procedures have you adopted to optimize workload operability?
This question was left unanswered 
________________________________________
Has the data been organized in the data lake to optimize for access, performance, and usability?
This question was left unanswered 
________________________________________
How do you make your data discoverable for users?
This question was left unanswered 
________________________________________
ADLS Gen2: Performance Efficiency 
How are you designing your workload to scale?
This question was left unanswered 
________________________________________
How do you optimize ADLS workloads for performance?
This question was left unanswered 
________________________________________
How are you managing your data to handle scale?
This question was left unanswered 
________________________________________
How are you ensuring you have sufficient capacity?
Review ADLS Gen2 product limits. 
Monitor ADLS Gen2 resource utilization, query activity, and other metrics that have limitations. 
None of the above 
________________________________________
•	Previous Versions 
•	Blog 
•	Contribute 
•	Privacy 
•	Terms of Use 
•	Trademarks 
•	© Microsoft 2025
our overall results
LOW 
Room to improve. It looks like there are key items needing attention. Review the recommendations to see what actions you can take to improve your results. 
LOW 0-12 Low: 0 to 12 
MODERATE 12-23 Moderate: 12 to 23 
EXCELLENT 23-35 Excellent: 23 to 35 
Your result: 10/35 10 out of 35 
Categories that influenced your results
Azure AI Fundamentals 
LOW 
Designing and Implementing a Microsoft Azure AI Solution 
MODERATE 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
Azure AI Fundamentals 
Fundamental AI Concepts
Azure AI Bot Service 
________________________________________
Fundamentals of question answering with the Language Service
"Create an empty knowledge base, and then manually copy and paste the FAQ entries into it. 
________________________________________
Fundamentals of Azure AI Document Intelligence
Azure AI Vision resource 
________________________________________
Fundamentals of Azure OpenAI Service
Azure OpenAI is Microsoft's version of ChatGPT, a chatbot that uses generative AI models. 
________________________________________
Designing and Implementing a Microsoft Azure AI Solution 
Prepare to develop AI solutions on Azure
Absolutely correct values based on conditional logic. 
________________________________________
Secure Azure AI services
Switch the app to use the secondary key 
________________________________________
Deploy Azure AI services in containers
Client applications must pass a subscription key to the Azure resource endpoint before using the container. 
________________________________________
Make recommendations with Azure AI Personalizer
In the Azure portal, go to the Monitor page for your AI Personalizer resource, and view the Personalizer average reward. 
________________________________________
Analyze images
Tags 
________________________________________
Classify images
"Image classification (multiclass) 
________________________________________
Detect, analyze, and recognize faces
Location 
________________________________________
Analyze video
Use the Azure AI Vision service to extract key frames from the video. 
________________________________________
Build a question answering solution
Create an empty knowledge base and manually enter the FAQ questions and answers. 
________________________________________
Build a conversational language understanding model
Intents 
________________________________________
Develop an app with Azure AI Language
Sentiment analysis 
________________________________________
Create a custom text classification solution
A multiple label classification project 
________________________________________
Create a custom named entity extraction solution
Recall 
________________________________________
Translate text with the Azure AI Translator service
Detect 
________________________________________
Create speech-enabled apps with Azure AI services
The location and one of the keys 
________________________________________
Translate speech with the Azure AI Speech service
SpeechConfig 
________________________________________
Create an Azure Cognitive Search solution
Add a JSON file that defines an Azure AI Search index to the blob container. 
________________________________________
Create a custom skill for Azure Cognitive Search
Create a custom skill that uses an Azure Machine Learning model to predict the sentiment for a document. 
________________________________________
Create a knowledge store with Azure Cognitive Search
Merge 
________________________________________
Enrich a search index using Language Studio
Conversational language understanding. 
________________________________________
Implement advanced search features in Azure Cognitive Search
^ 
________________________________________
Build an Azure Machine Learning custom skill for Azure Cognitive Search
Real-time endpoint 
________________________________________
Maintain an Azure Cognitive Search Solution
Create an Azure Cognitive Search service with a Storage Optimized service tier and at least two replicas. 
________________________________________
Use semantic search to get better search results in Azure Cognitive Search
As many results as the BM25 ranking function returns. 
________________________________________
Improve search results using vector search in Azure Cognitive Search
To create a search to match text input. 
________________________________________
Plan an Azure AI Document Intelligence solution
A Composed model. 
________________________________________
Use prebuilt Azure AI Document Intelligence models
Read model. 
________________________________________
Create a composed Form Recognizer model
modelId 
________________________________________
Generate code with Azure OpenAI Service
Increase in efficiency and productivity 
________________________________________
Generate images with Azure OpenAI Service
GPT-35-Turbo 
________________________________________
Fundamentals of Responsible Generative AI
To make a legal case that indemnifies you from responsibility for 
AI Engineer Skill Assessment  - Mar 4, 2025 - 1:05:49 PM													
													
													
Your overall results	Low	'10/35'											
Azure AI Fundamentals	Low	'0/4'											
Designing and Implementing a Microsoft Azure AI Solution	Moderate	'10/31'											
													
													
													
Category	Link-Text	Link	Priority	ReportingCategory	ReportingSubcategory	Weight	Context	CompleteY/N	Note				
Azure AI Fundamentals		https://learn.microsoft.com	High			0		N					
Azure AI Fundamentals	Microsoft Azure AI Fundamentals: Computer Vision	https://learn.microsoft.com/en-us/training/paths/explore-computer-vision-microsoft-azure/	High			0		N					
Azure AI Fundamentals	Microsoft Azure AI Fundamentals: Natural Language Processing	https://learn.microsoft.com/en-us/training/paths/explore-natural-language-processing/	High			0		N					
Azure AI Fundamentals	Microsoft Azure AI Fundamentals: Document Intelligence and Knowledge Mining	https://learn.microsoft.com/en-us/training/paths/document-intelligence-knowledge-mining/	High			0		N					
Azure AI Fundamentals	Microsoft Azure AI Fundamentals: Generative AI	https://learn.microsoft.com/en-us/training/paths/introduction-generative-ai/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution		https://learn.microsoft.com	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Get started with Azure AI Services	https://learn.microsoft.com/en-us/training/paths/get-started-azure-ai/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Develop decision support solutions with Azure AI Services	https://learn.microsoft.com/en-us/training/paths/develop-decision-support/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Create computer vision solutions with Azure AI Vision	https://learn.microsoft.com/en-us/training/paths/create-computer-vision-solutions-azure-ai/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Develop natural language processing solutions with Azure AI Services	https://learn.microsoft.com/en-us/training/paths/develop-language-solutions-azure-ai/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Implement knowledge mining with Azure Cognitive Search	https://learn.microsoft.com/en-us/training/paths/implement-knowledge-mining-azure-cognitive-search/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Develop solutions with Azure AI Document Intelligence	https://learn.microsoft.com/en-us/training/paths/extract-data-from-forms-document-intelligence/	High			0		N					
Designing and Implementing a Microsoft Azure AI Solution	Develop Generative AI solutions with Azure OpenAI Service	https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/	High			0		N					
-----------													
													
Category	Question	Answers	Selected Answer	Note									
Azure AI Fundamentals	Fundamental AI Concepts 	Azure Machine Learning											
Azure AI Fundamentals	Fundamental AI Concepts 	Azure AI Bot Service	Azure AI Bot Service										
Azure AI Fundamentals	Fundamental AI Concepts 	Azure AI Language											
Azure AI Fundamentals	Fundamentals of machine learning 	Regression											
Azure AI Fundamentals	Fundamentals of machine learning 	Classification											
Azure AI Fundamentals	Fundamentals of machine learning 	Clustering											
Azure AI Fundamentals	Fundamentals of Azure AI services 	A multi-service resource that includes all the AI services											
Azure AI Fundamentals	Fundamentals of Azure AI services 	A single-service resource for each AI service											
Azure AI Fundamentals	Fundamentals of Azure AI services 	It's not possible to see costs for individual AI services											
Azure AI Fundamentals	Fundamentals of Computer Vision 	Timestamps in photograph metadata											
Azure AI Fundamentals	Fundamentals of Computer Vision 	Pixels											
Azure AI Fundamentals	Fundamentals of Computer Vision 	Image file names											
Azure AI Fundamentals	Fundamentals of Facial Recognition 	A pair of coordinates for each face, indicating the center of the face											
Azure AI Fundamentals	Fundamentals of Facial Recognition 	Two pairs of coordinates for each face, indicating the location of the eyes											
Azure AI Fundamentals	Fundamentals of Facial Recognition 	A set of coordinates for each face, defining a rectangular bounding box around the face											
Azure AI Fundamentals	Fundamentals of optical character recognition 	Azure AI Vision											
Azure AI Fundamentals	Fundamentals of optical character recognition 	Azure AI services											
Azure AI Fundamentals	Fundamentals of optical character recognition 	Azure AI Language											
Azure AI Fundamentals	Fundamentals of Text Analysis with the Language Service 	Sentiment analysis											
Azure AI Fundamentals	Fundamentals of Text Analysis with the Language Service 	Key phrase extraction											
Azure AI Fundamentals	Fundamentals of Text Analysis with the Language Service 	Entity detection											
Azure AI Fundamentals	Fundamentals of question answering with the Language Service 	"Create an empty knowledge base, and then manually copy and paste the FAQ entries into it.	"Create an empty knowledge base, and then manually copy and paste the FAQ entries into it.										
Azure AI Fundamentals	Fundamentals of question answering with the Language Service 	Import the existing FAQ document into a new knowledge base.											
Azure AI Fundamentals	Fundamentals of question answering with the Language Service 	Import a pre-defined chit-chat data source.											
Azure AI Fundamentals	Fundamentals of conversational language understanding 	Azure AI Speech											
Azure AI Fundamentals	Fundamentals of conversational language understanding 	Azure AI Language											
Azure AI Fundamentals	Fundamentals of conversational language understanding 	Azure AI services											
Azure AI Fundamentals	Fundamentals of Azure AI Speech 	Speech											
Azure AI Fundamentals	Fundamentals of Azure AI Speech 	Language											
Azure AI Fundamentals	Fundamentals of Azure AI Speech 	Azure AI services											
Azure AI Fundamentals	Fundamentals of Azure AI Document Intelligence 	Azure AI Vision resource	Azure AI Vision resource										
Azure AI Fundamentals	Fundamentals of Azure AI Document Intelligence 	Azure AI Document Intelligence or Azure AI services resource.											
Azure AI Fundamentals	Fundamentals of Azure AI Document Intelligence 	Azure AI Language resource.											
Azure AI Fundamentals	Fundamentals of Knowledge Mining with Azure Cognitive Search 	CSV											
Azure AI Fundamentals	Fundamentals of Knowledge Mining with Azure Cognitive Search 	SQL											
Azure AI Fundamentals	Fundamentals of Knowledge Mining with Azure Cognitive Search 	JSON											
Azure AI Fundamentals	Fundamentals of Generative AI 	Models that only work with one language.											
Azure AI Fundamentals	Fundamentals of Generative AI 	Models that only work with small amounts of data.											
Azure AI Fundamentals	Fundamentals of Generative AI 	Models that use deep learning to process and understand natural language on a massive scale.											
Azure AI Fundamentals	Fundamentals of Azure OpenAI Service 	Azure OpenAI is Microsoft's version of ChatGPT, a chatbot that uses generative AI models.	Azure OpenAI is Microsoft's version of ChatGPT, a chatbot that uses generative AI models.										
Azure AI Fundamentals	Fundamentals of Azure OpenAI Service 	ChatGPT and OpenAI are chatbots that generate natural language, code, and images. Azure OpenAI provides access to these two chatbots.											
Azure AI Fundamentals	Fundamentals of Azure OpenAI Service 	OpenAI is a research company that developed ChatGPT, a chatbot that uses generative AI models. Azure OpenAI provides access to many of OpenAI's AI models.											
Azure AI Fundamentals	Fundamentals of Responsible Generative AI 	To make a legal case that indemnifies you from responsibility for harms caused by the solution											
Azure AI Fundamentals	Fundamentals of Responsible Generative AI 	To document the purpose, expected use, and potential harms for the solution											
Azure AI Fundamentals	Fundamentals of Responsible Generative AI 	To evaluate the cost of cloud services required to implement your solution											
Designing and Implementing a Microsoft Azure AI Solution	Prepare to develop AI solutions on Azure	Absolutely correct values based on conditional logic.	Absolutely correct values based on conditional logic.										
Designing and Implementing a Microsoft Azure AI Solution	Prepare to develop AI solutions on Azure	Randomly selected values with an equal chance of selection.											
Designing and Implementing a Microsoft Azure AI Solution	Prepare to develop AI solutions on Azure	Probabilistic values based on correlations found in training data.											
Designing and Implementing a Microsoft Azure AI Solution	Create and consume Azure AI services	The application must specify a valid subscription key for the Azure resource.											
Designing and Implementing a Microsoft Azure AI Solution	Create and consume Azure AI services	The user of the application must enter a user name and password associated with the Azure subscription.											
Designing and Implementing a Microsoft Azure AI Solution	Create and consume Azure AI services	Access to Azure AI Services is granted to anonymous users by default.											
Designing and Implementing a Microsoft Azure AI Solution	Secure Azure AI services	Switch the app to use the secondary key	Switch the app to use the secondary key										
Designing and Implementing a Microsoft Azure AI Solution	Secure Azure AI services	Change the resource endpoint											
Designing and Implementing a Microsoft Azure AI Solution	Secure Azure AI services	Enable a firewall											
Designing and Implementing a Microsoft Azure AI Solution	Monitor Azure AI services	Create an alert.											
Designing and Implementing a Microsoft Azure AI Solution	Monitor Azure AI services	Configure diagnostic settings.											
Designing and Implementing a Microsoft Azure AI Solution	Monitor Azure AI services	Create a dashboard.											
Designing and Implementing a Microsoft Azure AI Solution	Deploy Azure AI services in containers	Client applications must pass a subscription key to the Azure resource endpoint before using the container.	Client applications must pass a subscription key to the Azure resource endpoint before using the container.										
Designing and Implementing a Microsoft Azure AI Solution	Deploy Azure AI services in containers	The container must be able to connect to the Azure resource endpoint to send usage data for billing.											
Designing and Implementing a Microsoft Azure AI Solution	Deploy Azure AI services in containers	All data passed from the client application to the container is forwarded to the Azure resource endpoint.											
Designing and Implementing a Microsoft Azure AI Solution	Make recommendations with Azure AI Personalizer	In the Azure portal, go to the Monitor page for your AI Personalizer resource, and view the Personalizer average reward.	In the Azure portal, go to the Monitor page for your AI Personalizer resource, and view the Personalizer average reward.										
Designing and Implementing a Microsoft Azure AI Solution	Make recommendations with Azure AI Personalizer	In the Azure portal, go to the Monitor page for your AI Personalizer resource, and view the Baseline average reward.											
Designing and Implementing a Microsoft Azure AI Solution	Make recommendations with Azure AI Personalizer	In the Azure portal, go to the Monitor page for your AI Personalizer resource, and view the Reward achievement ratio.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze images	Tags	Tags										
Designing and Implementing a Microsoft Azure AI Solution	Analyze images	Description											
Designing and Implementing a Microsoft Azure AI Solution	Analyze images	Categories											
Designing and Implementing a Microsoft Azure AI Solution	Classify images	"Image classification (multiclass)	"Image classification (multiclass)										
Designing and Implementing a Microsoft Azure AI Solution	Classify images	Image classification (multilabel)											
Designing and Implementing a Microsoft Azure AI Solution	Classify images	Object detection											
Designing and Implementing a Microsoft Azure AI Solution	Detect objects in images	The location and class of specific classes of object in an image.											
Designing and Implementing a Microsoft Azure AI Solution	Detect objects in images	The class of the main subject of an image.											
Designing and Implementing a Microsoft Azure AI Solution	Detect objects in images	The file type of an image.											
Designing and Implementing a Microsoft Azure AI Solution	Detect, analyze, and recognize faces	Location	Location										
Designing and Implementing a Microsoft Azure AI Solution	Detect, analyze, and recognize faces	Type of eye-glasses											
Designing and Implementing a Microsoft Azure AI Solution	Detect, analyze, and recognize faces	Occlusion											
Designing and Implementing a Microsoft Azure AI Solution	Read Text in Images and Documents with the Azure AI Vision Service	Only total content and pages of text.											
Designing and Implementing a Microsoft Azure AI Solution	Read Text in Images and Documents with the Azure AI Vision Service	Pages, words and lines of text.											
Designing and Implementing a Microsoft Azure AI Solution	Read Text in Images and Documents with the Azure AI Vision Service	Total content, pages, words and lines of text.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze video	Use the Azure AI Vision service to extract key frames from the video.	Use the Azure AI Vision service to extract key frames from the video.										
Designing and Implementing a Microsoft Azure AI Solution	Analyze video	Upload the video to Azure Video Indexer and index it.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze video	Store the video file in an Azure blob store container.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze text with Azure AI Language	Use the Azure AI Language service to extract key phrases.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze text with Azure AI Language	Use the Azure AI Language service to perform sentiment analysis of the comments.											
Designing and Implementing a Microsoft Azure AI Solution	Analyze text with Azure AI Language	Use the Azure AI Language service to extract named entities from the comments.											
Designing and Implementing a Microsoft Azure AI Solution	Build a question answering solution	Create an empty knowledge base and manually enter the FAQ questions and answers.	Create an empty knowledge base and manually enter the FAQ questions and answers.										
Designing and Implementing a Microsoft Azure AI Solution	Build a question answering solution	Create a new knowledge base, importing the existing FAQ document.											
Designing and Implementing a Microsoft Azure AI Solution	Build a question answering solution	"Create a new knowledge base, selecting only the Professional chit-chat source.											
Designing and Implementing a Microsoft Azure AI Solution	Build a conversational language understanding model	Intents	Intents										
Designing and Implementing a Microsoft Azure AI Solution	Build a conversational language understanding model	Utterances											
Designing and Implementing a Microsoft Azure AI Solution	Build a conversational language understanding model	Entities											
Designing and Implementing a Microsoft Azure AI Solution	Develop an app with Azure AI Language	Sentiment analysis	Sentiment analysis										
Designing and Implementing a Microsoft Azure AI Solution	Develop an app with Azure AI Language	Key phrase extraction											
Designing and Implementing a Microsoft Azure AI Solution	Develop an app with Azure AI Language	Entity recognition											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom text classification solution	A single label classification project											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom text classification solution	A multiple label classification project	A multiple label classification project										
Designing and Implementing a Microsoft Azure AI Solution	Create a custom text classification solution	A varied label classification project											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom named entity extraction solution	Recall	Recall										
Designing and Implementing a Microsoft Azure AI Solution	Create a custom named entity extraction solution	Precision											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom named entity extraction solution	F1 score											
Designing and Implementing a Microsoft Azure AI Solution	Translate text with the Azure AI Translator service	Detect	Detect										
Designing and Implementing a Microsoft Azure AI Solution	Translate text with the Azure AI Translator service	Translate											
Designing and Implementing a Microsoft Azure AI Solution	Translate text with the Azure AI Translator service	Transliterate											
Designing and Implementing a Microsoft Azure AI Solution	Create speech-enabled apps with Azure AI services	The location and one of the keys	The location and one of the keys										
Designing and Implementing a Microsoft Azure AI Solution	Create speech-enabled apps with Azure AI services	The primary and secondary keys											
Designing and Implementing a Microsoft Azure AI Solution	Create speech-enabled apps with Azure AI services	The endpoint and one of the keys											
Designing and Implementing a Microsoft Azure AI Solution	Translate speech with the Azure AI Speech service	SpeechConfig	SpeechConfig										
Designing and Implementing a Microsoft Azure AI Solution	Translate speech with the Azure AI Speech service	SpeechTranslationConfig											
Designing and Implementing a Microsoft Azure AI Solution	Translate speech with the Azure AI Speech service	AudioConfig											
Designing and Implementing a Microsoft Azure AI Solution	Create an Azure Cognitive Search solution	Add a JSON file that defines an Azure AI Search index to the blob container.	Add a JSON file that defines an Azure AI Search index to the blob container.										
Designing and Implementing a Microsoft Azure AI Solution	Create an Azure Cognitive Search solution	Enable anonymous access for the blob container.											
Designing and Implementing a Microsoft Azure AI Solution	Create an Azure Cognitive Search solution	In an Azure AI Services resource, and add a data source that references the container where the files are stored.											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom skill for Azure Cognitive Search	Create a custom skill that uses an Azure Machine Learning model to predict the sentiment for a document.	Create a custom skill that uses an Azure Machine Learning model to predict the sentiment for a document.										
Designing and Implementing a Microsoft Azure AI Solution	Create a custom skill for Azure Cognitive Search	Create a custom skill that calls the Azure AI Language service to predict the sentiment of each document.											
Designing and Implementing a Microsoft Azure AI Solution	Create a custom skill for Azure Cognitive Search	Add the built-in Sentiment skill to the skillset used by the indexer.											
Designing and Implementing a Microsoft Azure AI Solution	Create a knowledge store with Azure Cognitive Search	Merge	Merge										
Designing and Implementing a Microsoft Azure AI Solution	Create a knowledge store with Azure Cognitive Search	Shaper											
Designing and Implementing a Microsoft Azure AI Solution	Create a knowledge store with Azure Cognitive Search	Split											
Designing and Implementing a Microsoft Azure AI Solution	Enrich a search index using Language Studio	Conversational language understanding.	Conversational language understanding.										
Designing and Implementing a Microsoft Azure AI Solution	Enrich a search index using Language Studio	Analyze sentiment.											
Designing and Implementing a Microsoft Azure AI Solution	Enrich a search index using Language Studio	Custom text classification.											
Designing and Implementing a Microsoft Azure AI Solution	Implement advanced search features in Azure Cognitive Search	+											
Designing and Implementing a Microsoft Azure AI Solution	Implement advanced search features in Azure Cognitive Search	^	^										
Designing and Implementing a Microsoft Azure AI Solution	Implement advanced search features in Azure Cognitive Search	!											
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure Machine Learning custom skill for Azure Cognitive Search	Real-time endpoint	Real-time endpoint										
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure Machine Learning custom skill for Azure Cognitive Search	Web service											
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure Machine Learning custom skill for Azure Cognitive Search	Batch endpoint											
Designing and Implementing a Microsoft Azure AI Solution	Search data outside the Azure platform in Azure Cognitive Search using Azure Data Factory	You can only upload one document at a time.											
Designing and Implementing a Microsoft Azure AI Solution	Search data outside the Azure platform in Azure Cognitive Search using Azure Data Factory	The JSON can't contain complex data types like arrays.											
Designing and Implementing a Microsoft Azure AI Solution	Search data outside the Azure platform in Azure Cognitive Search using Azure Data Factory	You have to define the index in the Azure portal first.											
Designing and Implementing a Microsoft Azure AI Solution	Maintain an Azure Cognitive Search Solution	Create an Azure Cognitive Search service with a Storage Optimized service tier and at least two replicas.	Create an Azure Cognitive Search service with a Storage Optimized service tier and at least two replicas.										
Designing and Implementing a Microsoft Azure AI Solution	Maintain an Azure Cognitive Search Solution	Create an Azure Cognitive Search service with any Standard service tier and at least three replicas.											
Designing and Implementing a Microsoft Azure AI Solution	Maintain an Azure Cognitive Search Solution	Create an Azure Cognitive Search service with a High-density service tier and one replica.											
Designing and Implementing a Microsoft Azure AI Solution	Use semantic search to get better search results in Azure Cognitive Search	Up to 50.											
Designing and Implementing a Microsoft Azure AI Solution	Use semantic search to get better search results in Azure Cognitive Search	As many results as the BM25 ranking function returns.	As many results as the BM25 ranking function returns.										
Designing and Implementing a Microsoft Azure AI Solution	Use semantic search to get better search results in Azure Cognitive Search	Up to 25.											
Designing and Implementing a Microsoft Azure AI Solution	Improve search results using vector search in Azure Cognitive Search	To create a search to match text input.	To create a search to match text input.										
Designing and Implementing a Microsoft Azure AI Solution	Improve search results using vector search in Azure Cognitive Search	When you need to find matches across different types of data. from a search index.											
Designing and Implementing a Microsoft Azure AI Solution	Improve search results using vector search in Azure Cognitive Search	To upload and index a document library.											
Designing and Implementing a Microsoft Azure AI Solution	Plan an Azure AI Document Intelligence solution	A Read model.											
Designing and Implementing a Microsoft Azure AI Solution	Plan an Azure AI Document Intelligence solution	A Layout model.											
Designing and Implementing a Microsoft Azure AI Solution	Plan an Azure AI Document Intelligence solution	A Composed model.	A Composed model.										
Designing and Implementing a Microsoft Azure AI Solution	Use prebuilt Azure AI Document Intelligence models	Read model.	Read model.										
Designing and Implementing a Microsoft Azure AI Solution	Use prebuilt Azure AI Document Intelligence models	General document model.											
Designing and Implementing a Microsoft Azure AI Solution	Use prebuilt Azure AI Document Intelligence models	ID document model.											
Designing and Implementing a Microsoft Azure AI Solution	Extract data from forms with Azure Document Intelligence	Train Model and Get Model Labels											
Designing and Implementing a Microsoft Azure AI Solution	Extract data from forms with Azure Document Intelligence	Analyze Invoice and Get Analyze Invoice Result											
Designing and Implementing a Microsoft Azure AI Solution	Extract data from forms with Azure Document Intelligence	Create Azure Document Intelligence and Get Analyze Invoice Result											
Designing and Implementing a Microsoft Azure AI Solution	Create a composed Form Recognizer model	modelId	modelId										
Designing and Implementing a Microsoft Azure AI Solution	Create a composed Form Recognizer model	status											
Designing and Implementing a Microsoft Azure AI Solution	Create a composed Form Recognizer model	docType											
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure AI Document Intelligence custom skill for Azure Cognitive Search	formUrl											
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure AI Document Intelligence custom skill for Azure Cognitive Search	recordId											
Designing and Implementing a Microsoft Azure AI Solution	Build an Azure AI Document Intelligence custom skill for Azure Cognitive Search	formSasToken											
Designing and Implementing a Microsoft Azure AI Solution	Get started with Azure OpenAI Service	text-davinci-003											
Designing and Implementing a Microsoft Azure AI Solution	Get started with Azure OpenAI Service	gpt-35-turbo											
Designing and Implementing a Microsoft Azure AI Solution	Get started with Azure OpenAI Service	text-embedding-ada-002 (Version 2)											
Designing and Implementing a Microsoft Azure AI Solution	Build natural language solutions with Azure OpenAI Service	Chat, Embedding, and Completion											
Designing and Implementing a Microsoft Azure AI Solution	Build natural language solutions with Azure OpenAI Service	Key, Endpoint, and Deployment name											
Designing and Implementing a Microsoft Azure AI Solution	Build natural language solutions with Azure OpenAI Service	Summary, Deployment name, and Endpoint											
Designing and Implementing a Microsoft Azure AI Solution	Apply prompt engineering with Azure OpenAI Service	By using complex instructions that are difficult to understand											
Designing and Implementing a Microsoft Azure AI Solution	Apply prompt engineering with Azure OpenAI Service	By providing clear and descriptive instructions											
Designing and Implementing a Microsoft Azure AI Solution	Apply prompt engineering with Azure OpenAI Service	By using vague prompts											
Designing and Implementing a Microsoft Azure AI Solution	Generate code with Azure OpenAI Service	Increase in efficiency and productivity	Increase in efficiency and productivity										
Designing and Implementing a Microsoft Azure AI Solution	Generate code with Azure OpenAI Service	Increase in bugs and readability											
Designing and Implementing a Microsoft Azure AI Solution	Generate code with Azure OpenAI Service	Increase in time spent coding											
Designing and Implementing a Microsoft Azure AI Solution	Generate images with Azure OpenAI Service	DALL-E											
Designing and Implementing a Microsoft Azure AI Solution	Generate images with Azure OpenAI Service	GPT-35-Turbo	GPT-35-Turbo										
Designing and Implementing a Microsoft Azure AI Solution	Generate images with Azure OpenAI Service	Text-Davinci											
Designing and Implementing a Microsoft Azure AI Solution	Use your own data with Azure OpenAI Service	Create their own AI chat models											
Designing and Implementing a Microsoft Azure AI Solution	Use your own data with Azure OpenAI Service	Access Azure OpenAI without an approved subscription											
Designing and Implementing a Microsoft Azure AI Solution	Use your own data with Azure OpenAI Service	Use supported AI chat models that can reference specific sources of data											
Designing and Implementing a Microsoft Azure AI Solution	Fundamentals of Responsible Generative AI	To make a legal case that indemnifies you from responsibility for harms caused by the solution.	To make a legal case that indemnifies you from responsibility for harms caused by the solution.										
Designing and Implementing a Microsoft Azure AI Solution	Fundamentals of Responsible Generative AI	To document the purpose, expected use, and potential harms for the solution.											
Designing and Implementing a Microsoft Azure AI Solution	Fundamentals of Responsible Generative AI	To evaluate the cost of cloud services required to implement your solution.											
													
													
													

Your overall results
EXCELLENT 
You are all set! Your results look strong and meet the necessary criteria for success. 
CRITICAL 0-33 Critical: 0 to 33 
MODERATE 33-67 Moderate: 33 to 67 
EXCELLENT 67-100 Excellent: 67 to 100 
Your result: 100/100 100 out of 100 
Categories that influenced your results
Azure Machine Learning: Cost Optimization 
EXCELLENT 
Azure Machine Learning: Operational Excellence 
EXCELLENT 
Azure Machine Learning: Performance Efficiency 
EXCELLENT 
Azure Machine Learning: Reliability 
EXCELLENT 
Azure Machine Learning: Security 
EXCELLENT 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
Azure Machine Learning: Cost Optimization 
What steps are you taking to optimize cloud costs in Azure Machine Learning?
We use cost management tools to plan and track costs. 
We identify and use the right-sized compute for machine learning models. 
We're considering the use of local compute or remote managed compute for automated machine learning to reduce costs.  
We optimize our cloud investment with cost management. 
We use an appropriately sized compute instance and compute cluster for training and inference.  
None of the above. 
________________________________________
How does your organization model and monitor cloud costs for Azure Machine Learning?
We plan and manage costs for Azure Machine Learning. 
We utilize cost alerts for Azure Machine Learning. 
We create and manage Azure budgets. 
None of the above. 
________________________________________
What actions do you typically take for cost optimization in Azure Machine Learning?
We configure our training clusters to autoscale. 
We set quotas on our subscription and workspaces. 
We set termination policies on our training job. 
We use low-priority virtual machines (VMs). 
We schedule compute instances to shut down and start up automatically. 
We use an Azure Reserved VM Instance. 
We train locally. 
We parallelize training. 
We set data retention and deletion policies. 
We deploy resources to the same region. 
________________________________________
How do you ensure that you have sufficient capacity?
We adhere to Azure Machine Learning subscription limits for compute and pipelines. 
We review service limits in Azure Machine Learning. 
We adhere to Azure Machine Learning subscription limits for storage. 
None of the above. 
________________________________________
Azure Machine Learning: Operational Excellence 
How are you managing your machine learning lifecycle through automation using MLOps?
We use machine learning pipelines to orchestrate the workflow.  
We use GitHub Actions with Azure Machine Learning.  
We use MLFlow to track and manage ML modeling projects.  
We use the Team Data Science Process for the data science project lifecycle.  
None of the above. 
________________________________________
What considerations are you making around the deployment of your infrastructure?
We segregate environments into development, test, and production workspaces.  
We understand the Azure subscription limits that might impact this workload. 
We use the Azure security baseline for Azure Machine Learning.  
We set up separate workspaces for each publish environment. 
None of the above. 
________________________________________
How is development done on Azure Machine Learning workloads?
We use Python SDK or CLI to develop machine learning jobs. 
We use low-code Azure Machine Learning designer to author experiments.  
We use the Azure Machine Learning Notebook or Jupyter Notebook to author the experiment.  
We use Azure Machine Learning automated GUI to author the experiment.  
We use ONNX and deep learning libraries, such as Tensorflow, PyTorch, Keras, and others. 
We use Responsible AI in our development practice. 
None of the above. 
________________________________________
How do you monitor your Azure Machine Learning deployments?
We monitor a deployed model by collecting and evaluating model data. 
We enable logging in machine learning training runs.  
We use alert rules and events in our application.  
We analyze Azure Machine Learning platform metrics and logs from Azure Monitor. 
None of the above. 
________________________________________
How do you manage the configuration of Azure Machine Learning deployments?
We use code-based (SDK or CLI) definitions of our training jobs. 
We use code-based definitions of our compute targets.  
None of the above. 
________________________________________
How do you test your MLOps infrastructure?
We use unit, regression, and integration testing with CI/CD for MLOps.  
None of the above. 
________________________________________
Azure Machine Learning: Performance Efficiency 
How are you designing your Azure Machine Learning training workload to scale?
We use data partitioning strategy to run experiments in parallel, if possible. 
We use autoscaling on clusters, where appropriate.  
We use Azure Machine Learning pipeline step to process large amounts of data asynchronously and in parallel. 
None of the above. 
________________________________________
How are you designing your Azure Machine Learning service to meet performance requirements?
We use appropriate compute SKUs and sizes for different machine learning workloads. 
We use the appropriate compute target types based on your workload requirements and environments.  
We use datastore and dataset mounts for reusability throughout workload. 
For unstructured files, we optimize performance by mounting data files to the compute target. 
We use advanced automated ML options to increase performance/ROI on experiment run time.  
________________________________________
How do you optimize data processing speeds for Azure Machine Learning workloads?
We set up Azure Machine Learning datastores/datasets to connect and access data from various storage services. 
We use distributed training with Azure Machine Learning, where possible.  
We use datasets/datastores to improve manageability, performance, and scale when working with data. 
________________________________________
How do you monitor model performance and lifecycle activities?
We leverage Azure Machine Learning monitoring capabilities, such as model run logs and metrics.  
We enable logging in Azure Machine Learning training runs. 
We use Azure Monitor to monitor the performance of our model. 
We leverage the Azure Machine Learning workspace job console to track workload progress. 
________________________________________
How do you autoscale Azure Machine Learning compute resources to handle performance for training and inferencing?
We leverage Azure Machine Learning capabilities to autoscale the training compute nodes based on our benchmarking. 
We leverage multinode scaling capabilities for model training. 
We leverage production-grade model deployment and autoscaling inference using Azure Kubernetes Service cluster. 
________________________________________
Azure Machine Learning: Reliability 
What reliability considerations have you defined for your Azure Machine Learning workload?
We use a Managed Batch Endpoint for parallel batch processing. 
We use a Managed Endpoint for scalable, self-managed service. 
We use Azure Kubernetes Service (AKS) for high-scale production deployments with fast response time. 
We manage and increase quotas for resources with Azure Machine Learning. 
None of the above. 
________________________________________
How do you ensure that your application architecture is resilient to failures?
We version and track Azure Machine Learning datasets. 
We enable logging in machine learning training runs to support handling exceptions and errors. 
We publish Azure Machine Learning components and environments. 
None of the above. 
________________________________________
What decisions have you made to ensure the application platform meets your reliability requirements?
We use scaling options for applications in Azure Kubernetes Service (AKS). 
We use a managed endpoint for scalable deployments. 
We manage a compute cluster in your Azure Machine Learning workspace. 
We built a failover plan for business continuity and disaster recovery to respond to failures and disasters. 
None of the above. 
________________________________________
How do you monitor and measure both the health of a training run and the health of deployed service?
We collect machine learning log files in Application Insights.  
We version and track Azure Machine Learning datasets. 
We use native application monitoring. 
None of the above. 
________________________________________
What framework do you use to interpret ML models and help train unbiased models?
We check trained models for fairness. 
We perform error analysis for trained models for reliability and safety. 
We interpret trained models for transparency. 
We perform causal analysis to understand how data impacts model decisions. 
None of the above. 
________________________________________
Azure Machine Learning: Security 
What design considerations did you make in your workload in regard to security?
We use role-based access control (RBAC) to manage access to Azure Machine Learning workspaces. 
We use Microsoft Entra ID for identity management and authentication of Azure Machine Learning users and processes for Azure Machine Learning resources and workflows. 
We use MLOps practices for security guidance, model management, deployment, and monitoring with Azure Machine Learning. 
We use appropriate recommendations for the Azure Machine Learning security baseline to improve security posture. 
We review and implement appropriate guidelines from Azure Machine Learning best practices for enterprise security. 
None of the above. 
________________________________________
What considerations for compliance and governance have you made for your Azure Machine Learning workload?
We implemented a security and governance plan in accordance with guidance. 
We audit and manage Azure Machine Learning using Azure Policy.  
None of the above. 
________________________________________
How do you manage encryption for workloads?
We use data encryption with Azure Machine Learning. 
None of the above. 
________________________________________
How do you manage identity for Azure Machine Learning workloads?
When running Azure Machine Learning workloads in Azure Kubernetes Service, we use Microsoft Entra Workload ID with Azure Machine Learning. 
We use managed identities with Azure Machine Learning for access control. 
None of the above. 
________________________________________
How have you secured the network for your workload?
We use virtual networks (VNets) to secure an Azure Machine Learning workspace during setup. 
We use virtual networks (VNets) to secure an Azure Machine Learning training environment.  
We configured Azure Private Link for Azure Machine Learning to enable private endpoint for inferencing. 
We secured an Azure Machine Learning inferencing environment with virtual networks (VNets). 
We use Azure Machine Learning studio in an Azure virtual network (VNet). 
We use TLS to secure web service through Azure Machine Learning. 
None of the above. 
________________________________________
How do you adhere to responsible ML principles in your design?
We use practices to protect users' data privacy in machine learning.  
We work on encrypted data with homomorphic encryption.  
We use model interpretability with Azure Machine Learning.  
We assess fairness in machine learning models using open-source packages in Azure Machine Learning.  
We perform causal inference on trained models. 
Your overall results
EXCELLENT 
You are all set! Your results look strong and meet the necessary criteria for success. 
CRITICAL 0-2 Critical: 0 to 2 
MODERATE 2-4 Moderate: 2 to 4 
EXCELLENT 4-6 Excellent: 4 to 6 
Your result: 6/6 6 out of 6 
Categories that influenced your results
AVS | Readiness Resources 
EXCELLENT 
AVS | Marketplace Offer Development Resources 
EXCELLENT 
AVS | Specialization Resources 
EXCELLENT 
AVS | Cosell Acceleration Resources 
EXCELLENT 
You can find out how to improve on individual categories by reviewing the recommendations below in the report. 
AVS | Readiness Resources

Opportunity and Use Cases
Migrating VMware vSphere workloads to Azure VMware Solution
Extending hybrid and multi-cloud agility
High availability and disaster recovery for VMware workloads
Desktop virtualization
Azure Migrate and Modernize and Azure Innovate

Training Resources
Introduction
Learning Path
Learning Resources
Overview Video
AVS Academy
VMware TechZone
VMware for Azure VMware Solution Master Specialist Exam
AVS LAB Automation
VMware AVS Hands-on Labs
AVS Workshop Lab Guide

Deployment Guidance
Landing Zone Accelerator
Landing Zone Accelerator GitHub Repository
Landing Zone Assessment Review
Landing Zone Assessment Network Design Guide
Deployment Checklist
Azure Well-Architected Assessment for AVS
Azure Well-Architected Documentation for AVS
Azure Proactive Resiliency Library for AVS
AVS Updates
AVS | Marketplace Offer Development Resources

Marketplace Training and Support Resources
Sell through the commercial marketplace
Plan a Consulting Service Offer, applicable for AVS Service
Partner Got-To-Market Toolbox
AVS | Specialization Resources

AVS Specialization details
Specialization Overview
Specialization Video
Specialization Audit Checklist
Specialization Assessment
AVS | Cosell Acceleration Resources

Go-To-Market Assets & Recommended Sellers Training
AVS Customer Story
IDC white paper: The Business Value of Azure VMware Solution
Digital Marketing Campaign (On Demand)
AVS Pricing Reference
AVS Go Big for Partners
AVS Partner Assets Collection
AVS Pros (LinkedIn Group)
Partners Incentives and Programs
AVS Bootcamp Sales Track
Azure VMware Solution (AVS) | Microsoft Partner - Mar 4, 2025 - 1:22:59 PM									
									
									
Your overall results	Excellent	'6/6'							
AVS | Readiness Resources	Excellent	'8/10'							
AVS | Marketplace Offer Development Resources	Excellent	'3/3'							
AVS | Specialization Resources	Excellent	'4/4'							
AVS | Cosell Acceleration Resources	Excellent	'9/9'							
									
									
									
Category	Link-Text	Link	Priority	ReportingCategory	ReportingSubcategory	Weight	Context	CompleteY/N	Note
AVS | Readiness Resources	Introduction	https://learn.microsoft.com/en-us/azure/azure-vmware/introduction	High			0		N	
AVS | Readiness Resources	Learning Resources	https://aka.ms/AVSLearningResources	High			0		N	
AVS | Readiness Resources	 Learning Path	https://aka.ms/AVSLearningPath	High			0		N	
AVS | Readiness Resources	Overview Video	https://aka.ms/AVSWhiteboard	High			0		N	
AVS | Readiness Resources	AVS Academy	https://aka.ms/AVSAcademy	High			0		N	
AVS | Readiness Resources	VMware for Azure VMware Solution Master Specialist Exam	https://aka.ms/AVSExam 	High			0		N	
AVS | Readiness Resources	VMware TechZone	https://aka.ms/AVSTechZone	High			0		N	
AVS | Readiness Resources	Landing Zone Accelerator	https://aka.ms/AVSLZA	High			0		N	
AVS | Readiness Resources	Landing Zone Accelerator GitHub Repository	https://aka.ms/AVSLZAAuto	High			0		N	
AVS | Readiness Resources	Landing Zone Assessment Review	https://aka.ms/AVSLZAReview	High			0		N	
AVS | Readiness Resources	Landing Zone Assessment Network Design Guide	https://aka.ms/AVSNDG 	High			0		N	
AVS | Readiness Resources	Deployment Checklist	https://aka.ms/AVSChecklists	High			0		N	
AVS | Readiness Resources	Azure Well-Architected Assessment for AVS	https://aka.ms/AVSWAF 	High			0		N	
AVS | Readiness Resources	Azure Well-Architected Documentation for AVS	https://aka.ms/AVSWAFdocs	High			0		N	
AVS | Readiness Resources	Azure Proactive Resiliency Library for AVS	https://aka.ms/AVSAPRL	High			0		N	
AVS | Readiness Resources	AVS Updates 	https://aka.ms/AVSUpdates	High			0		N	
AVS | Readiness Resources	Migrating VMware vSphere workloads to Azure VMware Solution	https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/azure-vmware/migrate	High			0		N	
AVS | Readiness Resources	Extending hybrid and multi-cloud agility	https://learn.microsoft.com/en-us/azure/azure-vmware/enable-vmware-cds-with-azure	High			0		N	
AVS | Readiness Resources	High availability and disaster recovery for VMware workloads	https://learn.microsoft.com/en-us/azure/azure-vmware/disaster-recovery-using-vmware-site-recovery-manager	High			0		N	
AVS | Readiness Resources	Azure VMware Solution for Desktop virtualization	https://learn.microsoft.com/en-us/azure/azure-vmware/azure-vmware-solution-horizon	High			0		N	
AVS | Readiness Resources	AVS LAB Automation	https://github.com/azure/avslabs	High			0		N	
AVS | Readiness Resources	VMware AVS Hands-on Labs	https://aka.ms/AVSHOL	High			0		N	
AVS | Readiness Resources	AVS Workshop Lab Guide	https://aka.ms/AVSHub	High			0		N	
AVS | Marketplace Offer Development Resources	Sell through the commercial marketplace	https://learn.microsoft.com/en-us/training/paths/sell-through-commercial-marketplace/	High			0		N	
AVS | Marketplace Offer Development Resources	Plan a Consulting Service Offer, applicable for AVS Service	https://learn.microsoft.com/en-us/partner-center/marketplace/plan-consulting-service-offer	High			0		N	
AVS | Marketplace Offer Development Resources	Partner Got-To-Market Toolbox	http://aka.ms/gtmtoolbox	High			0		N	
AVS | Specialization Resources	 Specialization Overview	https://aka.ms/AVSSpecial	High			0		N	
AVS | Specialization Resources	 Specialization Video	https://aka.ms/AVSAdvSpecVideo	High			0		N	
AVS | Specialization Resources	 Specialization Audit Checklist	https://aka.ms/AVSAdvSpecAudit	High			0		N	
AVS | Specialization Resources	 Specialization Assessment	https://aka.ms/AVSAdvSpecAssess	High			0		N	
AVS | Cosell Acceleration Resources	AVS Customer Story	https://aka.ms/AVSCustomerSuccess	High			0		N	
AVS | Cosell Acceleration Resources	IDC white paper: The Business Value of Azure VMware Solution	https://aka.ms/AVSIDC 	High			0		N	
AVS | Cosell Acceleration Resources	Digital Marketing Campaign (On Demand)	https://aka.ms/AVSDMK 	High			0		N	
AVS | Cosell Acceleration Resources	AVS Pricing Reference	https://aka.ms/AVSPricing	High			0		N	
AVS | Cosell Acceleration Resources	AVS Go Big for Partners	https://aka.ms/AVSPartnerGoBig	High			0		N	
AVS | Cosell Acceleration Resources	AVS Partner Assets Collection	https://aka.ms/AVSPartnerAssets 	High			0		N	
AVS | Cosell Acceleration Resources	AVS Pros (LinkedIn Group)	https://aka.ms/AVSPros	High			0		N	
AVS | Cosell Acceleration Resources	Partners Incentives and Programs	https://aka.ms/PartnerIncentivesResources 	High			0		N	
AVS | Cosell Acceleration Resources	AVS Bootcamp Sales Track	https://aka.ms/avsbootcamp2023	High			0		N	
-----------									
									
Category	Question	Answers	Selected Answer	Note					
AVS | Readiness Resources	Opportunity and Use Cases	Migrating VMware vSphere workloads to Azure VMware Solution	Migrating VMware vSphere workloads to Azure VMware Solution						
AVS | Readiness Resources	Opportunity and Use Cases	Extending hybrid and multi-cloud agility	Extending hybrid and multi-cloud agility						
AVS | Readiness Resources	Opportunity and Use Cases	High availability and disaster recovery for VMware workloads
High availability and disaster recovery for VMware workloads						
AVS | Readiness Resources	Opportunity and Use Cases	Desktop virtualization	Desktop virtualization						
AVS | Readiness Resources	Opportunity and Use Cases	Azure Migrate and Modernize and Azure Innovate	Azure Migrate and Modernize and Azure Innovate						
AVS | Readiness Resources	Training Resources	Introduction	Introduction						
AVS | Readiness Resources	Training Resources	Learning Path	Learning Path						
AVS | Readiness Resources	Training Resources	Learning Resources	Learning Resources						
AVS | Readiness Resources	Training Resources	Overview Video	Overview Video						
AVS | Readiness Resources	Training Resources	AVS Academy	AVS Academy						
AVS | Readiness Resources	Training Resources	VMware TechZone	VMware TechZone						
AVS | Readiness Resources	Training Resources	VMware for Azure VMware Solution Master Specialist Exam	VMware for Azure VMware Solution Master Specialist Exam						
AVS | Readiness Resources	Training Resources	AVS LAB Automation	AVS LAB Automation						
AVS | Readiness Resources	Training Resources	VMware AVS Hands-on Labs	VMware AVS Hands-on Labs						
AVS | Readiness Resources	Training Resources	AVS Workshop Lab Guide	AVS Workshop Lab Guide						
AVS | Readiness Resources	Deployment Guidance	Landing Zone Accelerator	Landing Zone Accelerator						
AVS | Readiness Resources	Deployment Guidance	Landing Zone Accelerator GitHub Repository	Landing Zone Accelerator GitHub Repository						
AVS | Readiness Resources	Deployment Guidance	Landing Zone Assessment Review	Landing Zone Assessment Review						
AVS | Readiness Resources	Deployment Guidance	Landing Zone Assessment Network Design Guide	Landing Zone Assessment Network Design Guide						
AVS | Readiness Resources	Deployment Guidance	Deployment Checklist	Deployment Checklist						
AVS | Readiness Resources	Deployment Guidance	Azure Well-Architected Assessment for AVS	Azure Well-Architected Assessment for AVS						
AVS | Readiness Resources	Deployment Guidance	Azure Well-Architected Documentation for AVS	Azure Well-Architected Documentation for AVS						
AVS | Readiness Resources	Deployment Guidance	Azure Proactive Resiliency Library for AVS	Azure Proactive Resiliency Library for AVS						
AVS | Readiness Resources	Deployment Guidance	VMware Workloads Assessment using Azure Migrate							
AVS | Readiness Resources	Deployment Guidance	AVS Updates 	AVS Updates 						
AVS | Marketplace Offer Development Resources	Marketplace Training and Support Resources	Sell through the commercial marketplace	Sell through the commercial marketplace						
AVS | Marketplace Offer Development Resources	Marketplace Training and Support Resources	Plan a Consulting Service Offer, applicable for AVS Service	Plan a Consulting Service Offer, applicable for AVS Service						
AVS | Marketplace Offer Development Resources	Marketplace Training and Support Resources	Partner Got-To-Market Toolbox	Partner Got-To-Market Toolbox						
AVS | Specialization Resources	AVS Specialization details	 Specialization Overview	 Specialization Overview						
AVS | Specialization Resources	AVS Specialization details	 Specialization Video	 Specialization Video						
AVS | Specialization Resources	AVS Specialization details	 Specialization Audit Checklist	 Specialization Audit Checklist						
AVS | Specialization Resources	AVS Specialization details	 Specialization Assessment	 Specialization Assessment						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Customer Story	AVS Customer Story						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	IDC white paper: The Business Value of Azure VMware Solution	IDC white paper: The Business Value of Azure VMware Solution						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	Digital Marketing Campaign (On Demand)	Digital Marketing Campaign (On Demand)						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Pricing Reference	AVS Pricing Reference						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Go Big for Partners	AVS Go Big for Partners						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Partner Assets Collection	AVS Partner Assets Collection						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Pros (LinkedIn Group)	AVS Pros (LinkedIn Group)						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	Partners Incentives and Programs	Partners Incentives and Programs						
AVS | Cosell Acceleration Resources	Go-To-Market Assets & Recommended Sellers Training	AVS Bootcamp Sales Track	AVS Bootcamp Sales Track						
									
									
Tell us about your PDF experience.
Install C and C++ support in Visual
Studio
Article • 12/09/2021
If you haven't downloaded and installed Visual Studio and the Microsoft C/C++ tools
yet, here's how to get started.
Visual Studio 2022 Installation
Welcome to Visual Studio 2022! In this version, it's easy to choose and install just the
features you need. And because of its reduced minimum footprint, it installs quickly and
with less system impact.
７ Note
This topic applies to installation of Visual Studio on Windows. Visual Studio Code
is a lightweight, cross-platform development environment that runs on Windows,
Mac, and Linux systems. The Microsoft C/C++ for Visual Studio Code extension
supports IntelliSense, debugging, code formatting, auto-completion. Visual Studio
for Mac doesn't support Microsoft C++, but does support .NET languages and
cross-platform development. For installation instructions, see Install Visual Studio
for Mac.
Want to know more about what else is new in this version? See the Visual Studio release
notes.
Ready to install? We'll walk you through it, step-by-step.
Step 1 - Make sure your computer is ready for Visual
Studio
Before you begin installing Visual Studio:
1. Check the system requirements. These requirements help you know whether your
computer supports Visual Studio 2022.
2. Apply the latest Windows updates. These updates ensure that your computer has
both the latest security updates and the required system components for Visual
Studio.
3. Reboot. The reboot ensures that any pending installs or updates don't hinder the
Visual Studio install.
4. Free up space. Remove unneeded files and applications from your %SystemDrive%
by, for example, running the Disk Cleanup app.
For questions about running previous versions of Visual Studio side by side with Visual
Studio 2022, see the Visual Studio 2022 Platform Targeting and Compatibility page.
Step 2 - Download Visual Studio
Next, download the Visual Studio bootstrapper file. To do so, choose the following
button to go to the Visual Studio download page. Select the edition of Visual Studio that
you want and choose the Free trial or Free download button.
Download Visual Studio
Step 3 - Install the Visual Studio installer
Run the bootstrapper file you downloaded to install the Visual Studio Installer. This new
lightweight installer includes everything you need to both install and customize Visual
Studio.
1. From your Downloads folder, double-click the bootstrapper that matches or is
similar to one of the following files:
vs_community.exe for Visual Studio Community
vs_professional.exe for Visual Studio Professional
vs_enterprise.exe for Visual Studio Enterprise
If you receive a User Account Control notice, choose Yes to allow the bootstrapper
to run.
2. We'll ask you to acknowledge the Microsoft License Terms and the Microsoft
Privacy Statement . Choose Continue.
Step 4 - Choose workloads
After the installer is installed, you can use it to customize your installation by selecting
the workloads, or feature sets, that you want. Here's how.
1. Find the workload you want in the Installing Visual Studio screen.
For core C and C++ support, choose the "Desktop development with C++"
workload. It comes with the default core editor, which includes basic code editing
support for over 20 languages, the ability to open and edit code from any folder
without requiring a project, and integrated source code control.
Additional workloads support other kinds of development. For example, choose
the "Universal Windows Platform development" workload to create apps that use
the Windows Runtime for the Microsoft Store. Choose "Game development with
C++" to create games that use DirectX, Unreal, and Cocos2d. Choose "Linux
development with C++" to target Linux platforms, including IoT development.
The Installation details pane lists the included and optional components installed
by each workload. You can select or deselect optional components in this list. For
example, to support development by using the Visual Studio 2017 or 2015
compiler toolsets, choose the MSVC v141 or MSVC v140 optional components. You
can add support for MFC, the experimental Modules language extension,
IncrediBuild, and more.
2. After you choose the workload(s) and optional components you want, choose
Install.
Next, status screens appear that show the progress of your Visual Studio
installation.
 Tip
At any time after installation, you can install workloads or components that you
didn't install initially. If you have Visual Studio open, go to Tools > Get Tools and
Features... which opens the Visual Studio Installer. Or, open Visual Studio Installer
from the Start menu. From there, you can choose the workloads or components
that you wish to install. Then, choose Modify.
Step 5 - Choose individual components (Optional)
If you don't want to use the Workloads feature to customize your Visual Studio
installation, or you want to add more components than a workload installs, you can do
so by installing or adding individual components from the Individual components tab.
Choose what you want, and then follow the prompts.
Step 6 - Install language packs (Optional)
By default, the installer program tries to match the language of the operating system
when it runs for the first time. To install Visual Studio in a language of your choosing,
choose the Language packs tab from the Visual Studio Installer, and then follow the
prompts.
Change the installer language from the command line
Another way that you can change the default language is by running the installer from
the command line. For example, you can force the installer to run in English by using the
following command: vs_installer.exe --locale en-US . The installer will remember this
setting when it's run the next time. The installer supports the following language tokens:
zh-cn, zh-tw, cs-cz, en-us, es-es, fr-fr, de-de, it-it, ja-jp, ko-kr, pl-pl, pt-br, ru-ru, and tr-tr.
Step 7 - Change the installation location (Optional)
You can reduce the installation footprint of Visual Studio on your system drive. You can
choose to move the download cache, shared components, SDKs, and tools to different
drives, and keep Visual Studio on the drive that runs it the fastest.
） Important
You can select a different drive only when you first install Visual Studio. If you've
already installed it and want to change drives, you must uninstall Visual Studio and
then reinstall it.
Step 8 - Start developing
1. After Visual Studio installation is complete, choose the Launch button to get
started developing with Visual Studio.
2. On the start window, choose Create a new project.
3. In the search box, enter the type of app you want to create to see a list of available
templates. The list of templates depends on the workload(s) that you chose during
installation. To see different templates, choose different workloads.
You can also filter your search for a specific programming language by using the
Language drop-down list. You can filter by using the Platform list and the Project
type list, too.
4. Visual Studio opens your new project, and you're ready to code!
When Visual Studio is running, you're ready to continue to the next step.
Next Steps
Create a C++ project
What is Visual Studio?
Article • 06/19/2024
Visual Studio is a powerful developer tool that you can use to complete the entire
development cycle in one place. It's a comprehensive integrated development
environment (IDE) that you can use to write, edit, debug, and build code. Then deploy
your app. Visual Studio includes compilers, code completion tools, source control,
extensions, and many other features to enhance every stage of the software
development process.
With the variety of features and languages support in Visual Studio, you can grow from
writing your first "Hello World" program to developing and deploying apps. For
example, build, debug, and test .NET and C++ apps, edit ASP.NET pages in the web
designer view, develop cross-platform mobile and desktop apps with .NET, or build
responsive Web UIs in C#.
To install Visual Studio, select the following button, and choose the edition of Visual
Studio to download.
Download Visual Studio
Why use Visual Studio?
Visual Studio provides developers a feature rich development environment to develop
high-quality code efficiently and collaboratively.
Workload-based installer - install only what you need
Powerful coding tools and features - everything you need to build your apps in
one place
Multiple language support - code in C++, C#, JavaScript, TypeScript, Python, and
more
Cross-platform development - build apps for any platform
Version control integration - collaborate on code with team mates
AI-assisted development - write code more efficiently with AI assistance
Discover Visual Studio
Visual Studio supports different parts of the software development cycle.
Develop your code
Visual Studio IDE provides many features that make it easier for you to write and
manage your code with confidence. For example, code quickly and accurately with AI￾assisted development tools. These tools include GitHub Copilot and IntelliCode. Make
quick improvements to your code using light bulbs that suggest actions, or
expand/collapse blocks of code using outlining. Organize and explore your code with
the Solution Explorer that shows your code organized by files or the Class View that
shows your code organized by classes.
Learn more about all the features in the IDE that help you organize and edit content:
Code editor
Personalize the IDE and the editor
Organize code
Tips and tricks
AI-assisted development
GitHub Copilot, GitHub Copilot Chat, and IntelliCode assist developers in writing code
faster and with greater accuracy, help develop a deeper understanding of the codebase,
and help with other development tasks such as writing unit tests, debugging, and
profiling.
Learn more about AI-assisted development in Visual Studio:
Get started with GitHub Copilot in Visual Studio:
Install and manage GitHub Copilot
Use GitHub Copilot Completions in Visual Studio
Use GitHub Copilot Chat in Visual Studio
Debug with Copilot
Build your app
You can compile and build your applications to create builds immediately and test them
in a debugger. You can run multi-processor builds for C++ and C# projects. Visual
Studio also provides several options that you can configure when you build applications.
You can create a custom build configuration in addition to the built-in configurations,
hide certain warning messages, or increase build output information.
Learn more about how to compile and build in Visual Studio:
Create build configurations for your project
Build an application
Debug your code
Integrated debugging in Visual Studio enables you to debug, profile, and diagnose with
ease. You step through your code and look at the values stored in variables, set watches
on variables to see when values changes, examine the execution path of your code.
Visual Studio offers other ways to debug your code while it runs.
Learn more about debugging effectively in Visual Studio:
Debug your app
Debugging techniques and tools
Measure app performance
Debug with Copilot
Tips and tricks
Test your code
You can write high-quality code with comprehensive testing tools in Visual Studio. Unit
tests give developers and testers a quick way to find logic errors in code. You can
analyze how much code you're testing and see instant results in a test suite. Know the
impact of every change you make with advanced features that test code while you type.
Learn more about the testing tools available in Visual Studio:
Use testing tools in Visual Studio
Create and run unit tests
Analyze code coverage
Version control
With the integrated Git features in Visual Studio, you can clone, create, or open your
own repositories. The Git tool window has everything you need to commit and push
changes, manage branches, and resolve merge conflicts. If you have a GitHub account,
you can manage those repos directly within Visual Studio.
Learn more about version control in Visual Studio:
Version control with Git
Visual Studio and GitHub
Collaborate with others
Visual Studio Live Share enables real-time collaborative development. With Live Share
you can share your project with your peers, no matter the language or platform. Get to
the bottom of an issue fast by allowing your team to connect, navigate, set break points,
and type in your editor session.
Learn more about how to collaborate with Live Share:
Collaborate with Live Share
Common use cases
Deploy your app
By deploying an application, service, or component, you distribute it for installation on
other computers, devices, or servers, or in the cloud. You can choose the appropriate
method in Visual Studio for the type of deployment that you need. Share your apps and
code by publishing to the web or Azure, or by deploying to a network share or a local
folder.
Learn more about how to deploy your app using Visual Studio:
Deploy your app from Visual Studio
Deploy your app to a folder, a web server, Azure, or another destination
Choose your Visual Studio edition
There are three editions of Visual Studio:
Community - free, fully featured IDE for students, open-source developers, and
individual developers.
Professional - a subscription based option for individual developers or small
teams.
Feedback
Was this page helpful?
Provide product feedback | Ask the community
Enterprise - a subscription based option for small to large business and
enterprise organizations.
Compare features across Visual Studio editions and acquire the Visual Studio
edition that best fits your needs.
Select the following button to install Visual Studio, and choose the edition of Visual
Studio.
Dive into coding with one of the following language-specific tutorials:
Create a simple C# console app
Get started with Python
Create a simple VB console app
Create a C++ console app
Create a Node.js and Express app
To develop any type of app, or learn a language, you work in the feature rich Visual
Studio Integrated Development Environment (IDE). Explore Visual Studio further with
one of these introductory articles:
Tour the IDE to get familiar with the IDE features and to learn how to use it for
basic tasks.
Cover the basics in this Learn module: Introduction to Visual Studio
Install Visual Studio
Download Visual Studio
Get started
Related content
 Yes  No
Create a C++ console app project
Article • 07/06/2023
The usual starting point for a C++ programmer is a "Hello, world!" application that runs
on the command line. That's what you create in Visual Studio in this step.
Prerequisites
Have Visual Studio with the Desktop development with C++ workload installed
and running on your computer. If it's not installed yet, see Install C++ support in
Visual Studio.
Create your app project
Visual Studio uses projects to organize the code for an app, and solutions to organize
your projects. A project contains all the options, configurations, and rules used to build
your apps. It manages the relationship between all the project's files and any external
files. To create your app, first, create a new project and solution.
1. In Visual Studio, open the File menu and choose New > Project to open the Create
a new Project dialog. Select the Console App template that has C++, Windows,
and Console tags, and then choose Next.
2. In the Configure your new project dialog, enter HelloWorld in the Project name
edit box. Choose Create to create the project.
Visual Studio creates a new project. It's ready for you to add and edit your source
code. By default, the Console App template provides source code for a "Hello
World" app, like this:
When the code looks like this in the editor, you're ready to go on to the next step
and build your app.
I ran into a problem.
Next steps
Build and run a C++ project
Troubleshooting guide
Come here for solutions to common issues when you create your first C++ project.
Create your app project: issues
The New Project dialog should show a Console App template that has C++, Windows,
and Console tags. If you don't see it, there are two possible causes. It might be filtered
out of the list, or it might not be installed. First, check the filter dropdowns at the top of
the list of templates. Set them to C++, Windows, and Console. The C++ Console App
template should appear; otherwise, the Desktop development with C++ workload isn't
installed.
To install Desktop development with C++, you can run the installer right from the New
Project dialog. Choose the Install more tools and features link at the bottom of the
template list to start the installer. If the User Account Control dialog requests
permissions, choose Yes. In the installer, make sure the Desktop development with C++
workload is checked. Then choose Modify to update your Visual Studio installation.
If another project with the same name already exists, choose another name for your
project. Or, delete the existing project and try again. To delete an existing project, delete
the solution folder (the folder that contains the helloworld.sln file) in File Explorer.
Go back.
Build and run a C++ console app
project
Article • 07/01/2024
In Create a C++ console app project you created a C++ console app project and
entered your code. Now you can build and run it within Visual Studio. Then, run it as a
stand-alone app from the command line.
Prerequisites
Have Visual Studio with the Desktop development with C++ workload installed
and running on your computer. If it's not installed, follow the steps in Install C++
support in Visual Studio.
Create a "Hello, World!" project. By default, it contains code to print Hello World! .
If you haven't done this step yet, follow the steps in Create a C++ console app
project.
If Visual Studio looks like this, you're ready to build and run your app:
Build and run your code in Visual Studio
1. To build your project, from the main menu choose Build > Build Solution. The
Output window shows the results of the build process.
2. To run the code, on the menu bar, choose Debug, Start without debugging.
A console window opens and then runs your app. When you start a console app in
Visual Studio, it runs your code, then prints "Press any key to continue . . ." to give
you a chance to see the output.
Congratulations! You created your first "Hello, world!" console app in Visual Studio!
Press a key to dismiss the console window and return to Visual Studio.
I ran into a problem.
Run your code in a command window
Normally, you run console apps at the command prompt, not in Visual Studio. Once
Visual Studio builds your app, you can run it from a command window. Here's how to
find and run your new app in a command prompt window.
1. In Solution Explorer, select the HelloWorld solution (not the HelloWorld project)
and right-click to open the context menu. Choose Open Folder in File Explorer to
open a File Explorer window in the HelloWorld solution folder.
2. In the File Explorer window, open the x64 folder and then the Debug folder. This
folder contains your app, HelloWorld.exe , and debugging files. Hold down the
Shift key and right-click on HelloWorld.exe to open the context menu. Choose
Copy as path to copy the path to your app to the clipboard. If you see
HelloWorld.exe.recipe , it's because you did the Open Folder in File Explorer step
on the HelloWorld project instead of the HelloWorld solution. Navigate up a level in
File Explorer to get to the solution folder. This folder also contains a x64\Debug\
folder, where HelloWorld.exe is.
3. To open a command prompt window, press Windows+R to open the Run dialog.
Enter cmd.exe in the Open textbox, then choose OK to run a command prompt
window.
4. In the command prompt window, right-click to paste the path to your app into the
command prompt. Press Enter to run your app.
Congratulations, you built and ran a console app in Visual Studio!
I ran into a problem.
Next Steps
Once you build and run this simple app, you're ready for more complex projects. For
more information, see Using the Visual Studio IDE for C++ Desktop Development. It has
more detailed walkthroughs that explore the capabilities of Microsoft C++ in Visual
Studio.
Troubleshooting guide
Come here for solutions to common issues when you create your first C++ project.
Build and run your code in Visual Studio: issues
If red squiggles appear under anything in the source code editor, the build may have
errors or warnings. Check that your code matches the example in spelling, punctuation,
and case.
Go back.
Run your code in a command window: issues
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
If the path shown in File Explorer ends in \HelloWorld\HelloWorld , you opened the
HelloWorld project instead of the HelloWorld solution. You won't see your app in the
x64\Debug folder. Navigate up a level in File Explorer to get to the solution folder, the
first HelloWorld in the path. This folder also contains a x64\Debug folder, where your
app is.
You can also navigate to the solution x64\Debug folder at the command line to run your
app. Your app won't run from other directories without specifying the path to the app.
However, you can copy your app to another directory and run it from there. It's also
possible to copy it to a directory specified by your PATH environment variable, then run
it from anywhere.
If you don't see Copy as path in the shortcut menu, dismiss the menu, and then hold
down the Shift key while you open it again. This command is just for convenience. You
can also copy the path to the folder from the File Explorer search bar, and paste it into
the Run dialog, and then enter the name of your executable at the end. It's just a little
more typing, but it has the same result.
Go back.
 Yes  No
Welcome back to C++ - Modern C++
Article • 11/07/2022
Since its creation, C++ has become one of the most widely used programming
languages in the world. Well-written C++ programs are fast and efficient. The language
is more flexible than other languages: It can work at the highest levels of abstraction,
and down at the level of the silicon. C++ supplies highly optimized standard libraries. It
enables access to low-level hardware features, to maximize speed and minimize memory
requirements. C++ can create almost any kind of program: Games, device drivers, HPC,
cloud, desktop, embedded, and mobile apps, and much more. Even libraries and
compilers for other programming languages get written in C++.
One of the original requirements for C++ was backward compatibility with the C
language. As a result, C++ has always permitted C-style programming, with raw
pointers, arrays, null-terminated character strings, and other features. They may enable
great performance, but can also spawn bugs and complexity. The evolution of C++ has
emphasized features that greatly reduce the need to use C-style idioms. The old C￾programming facilities are still there when you need them. However, in modern C++
code you should need them less and less. Modern C++ code is simpler, safer, more
elegant, and still as fast as ever.
The following sections provide an overview of the main features of modern C++. Unless
noted otherwise, the features listed here are available in C++11 and later. In the
Microsoft C++ compiler, you can set the /std compiler option to specify which version
of the standard to use for your project.
Resources and smart pointers
One of the major classes of bugs in C-style programming is the memory leak. Leaks are
often caused by a failure to call delete for memory that was allocated with new .
Modern C++ emphasizes the principle of resource acquisition is initialization (RAII). The
idea is simple. Resources (heap memory, file handles, sockets, and so on) should be
owned by an object. That object creates, or receives, the newly allocated resource in its
constructor, and deletes it in its destructor. The principle of RAII guarantees that all
resources get properly returned to the operating system when the owning object goes
out of scope.
To support easy adoption of RAII principles, the C++ Standard Library provides three
smart pointer types: std::unique_ptr, std::shared_ptr, and std::weak_ptr. A smart pointer
handles the allocation and deletion of the memory it owns. The following example
shows a class with an array member that is allocated on the heap in the call to
make_unique() . The calls to new and delete are encapsulated by the unique_ptr class.
When a widget object goes out of scope, the unique_ptr destructor will be invoked and
it will release the memory that was allocated for the array.
C++
Whenever possible, use a smart pointer to manage heap memory. If you must use the
new and delete operators explicitly, follow the principle of RAII. For more information,
see Object lifetime and resource management (RAII).
C-style strings are another major source of bugs. By using std::string and std::wstring,
you can eliminate virtually all the errors associated with C-style strings. You also gain the
benefit of member functions for searching, appending, prepending, and so on. Both are
highly optimized for speed. When passing a string to a function that requires only read￾only access, in C++17 you can use std::string_view for even greater performance benefit.
The standard library containers all follow the principle of RAII. They provide iterators for
safe traversal of elements. And, they're highly optimized for performance and have been
thoroughly tested for correctness. By using these containers, you eliminate the potential
#include <memory>
class widget
{
private:
 std::unique_ptr<int[]> data;
public:
 widget(const int size) { data = std::make_unique<int[]>(size); }
 void do_something() {}
};
void functionUsingWidget() {
 widget w(1000000); // lifetime automatically tied to enclosing scope
 // constructs w, including the w.data gadget member
 // ...
 w.do_something();
 // ...
} // automatic destruction and deallocation for w and w.data
std::string and std::string_view
std::vector and other Standard Library
containers
for bugs or inefficiencies that might be introduced in custom data structures. Instead of
raw arrays, use vector as a sequential container in C++.
C++
vector<string> apples;
apples.push_back("Granny Smith");
Use map (not unordered_map ) as the default associative container. Use set, multimap,
and multiset for degenerate and multi cases.
C++
map<string, string> apple_color;
// ...
apple_color["Granny Smith"] = "Green";
When performance optimization is needed, consider using:
Unordered associative containers such as unordered_map. These have lower per￾element overhead and constant-time lookup, but they can be harder to use
correctly and efficiently.
Sorted vector . For more information, see Algorithms.
Don't use C-style arrays. For older APIs that need direct access to the data, use accessor
methods such as f(vec.data(), vec.size()); instead. For more information about
containers, see C++ Standard Library Containers.
Standard Library algorithms
Before you assume that you need to write a custom algorithm for your program, first
review the C++ Standard Library algorithms. The Standard Library contains an ever￾growing assortment of algorithms for many common operations such as searching,
sorting, filtering, and randomizing. The math library is extensive. In C++17 and later,
parallel versions of many algorithms are provided.
Here are some important examples:
for_each , the default traversal algorithm (along with range-based for loops).
transform , for not-in-place modification of container elements
find_if , the default search algorithm.
sort , lower_bound , and the other default sorting and searching algorithms.
To write a comparator, use strict < and use named lambdas when you can.
C++
C++11 introduced the auto keyword for use in variable, function, and template
declarations. auto tells the compiler to deduce the type of the object so that you don't
have to type it explicitly. auto is especially useful when the deduced type is a nested
template:
C++
C-style iteration over arrays and containers is prone to indexing errors and is also
tedious to type. To eliminate these errors, and make your code more readable, use
range-based for loops with both Standard Library containers and raw arrays. For more
information, see Range-based for statement.
C++
auto comp = [](const widget& w1, const widget& w2)
 { return w1.weight() < w2.weight(); }
sort( v.begin(), v.end(), comp );
auto i = lower_bound( v.begin(), v.end(), widget{0}, comp );
auto instead of explicit type names
map<int,list<string>>::iterator i = m.begin(); // C-style
auto i = m.begin(); // modern C++
Range-based for loops
#include <iostream>
#include <vector>
int main()
{
 std::vector<int> v {1,2,3};
 // C-style
 for(int i = 0; i < v.size(); ++i)
 {
 std::cout << v[i];
 }
Macros in C and C++ are tokens that are processed by the preprocessor before
compilation. Each instance of a macro token is replaced with its defined value or
expression before the file is compiled. Macros are commonly used in C-style
programming to define compile-time constant values. However, macros are error-prone
and difficult to debug. In modern C++, you should prefer constexpr variables for
compile-time constants:
C++
In modern C++, you can use brace initialization for any type. This form of initialization is
especially convenient when initializing arrays, vectors, or other containers. In the
following example, v2 is initialized with three instances of S . v3 is initialized with three
instances of S that are themselves initialized using braces. The compiler infers the type
of each element based on the declared type of v3 .
C++
 // Modern C++:
 for(auto& num : v)
 {
 std::cout << num;
 }
}
constexpr expressions instead of macros
#define SIZE 10 // C-style
constexpr int size = 10; // modern C++
Uniform initialization
#include <vector>
struct S
{
 std::string name;
 float num;
 S(std::string s, float f) : name(s), num(f) {}
};
int main()
{
 // C-style initialization
 std::vector<S> v;
 S s1("Norah", 2.7);
For more information, see Brace initialization.
Modern C++ provides move semantics, which make it possible to eliminate unnecessary
memory copies. In earlier versions of the language, copies were unavoidable in certain
situations. A move operation transfers ownership of a resource from one object to the
next without making a copy. Some classes own resources such as heap memory, file
handles, and so on. When you implement a resource-owning class, you can define a
move constructor and move assignment operator for it. The compiler chooses these
special members during overload resolution in situations where a copy isn't needed. The
Standard Library container types invoke the move constructor on objects if one is
defined. For more information, see Move Constructors and Move Assignment Operators
(C++).
In C-style programming, a function can be passed to another function by using a
function pointer. Function pointers are inconvenient to maintain and understand. The
function they refer to may be defined elsewhere in the source code, far away from the
point at which it's invoked. Also, they're not type-safe. Modern C++ provides function
objects, classes that override the operator() operator, which enables them to be called
like a function. The most convenient way to create function objects is with inline lambda
expressions. The following example shows how to use a lambda expression to pass a
function object, that the find_if function will invoke on each element in the vector:
C++
 S s2("Frank", 3.5);
 S s3("Jeri", 85.9);
 v.push_back(s1);
 v.push_back(s2);
 v.push_back(s3);
 // Modern C++:
 std::vector<S> v2 {s1, s2, s3};
 // or...
 std::vector<S> v3{ {"Norah", 2.7}, {"Frank", 3.5}, {"Jeri", 85.9} };
}
Move semantics
Lambda expressions
The lambda expression [=](int i) { return i > x && i < y; } can be read as "function
that takes a single argument of type int and returns a boolean that indicates whether
the argument is greater than x and less than y ." Notice that the variables x and y
from the surrounding context can be used in the lambda. The [=] specifies that those
variables are captured by value; in other words, the lambda expression has its own
copies of those values.
Modern C++ emphasizes exceptions, not error codes, as the best way to report and
handle error conditions. For more information, see Modern C++ best practices for
exceptions and error handling.
Use the C++ Standard Library std::atomic struct and related types for inter-thread
communication mechanisms.
Unions are commonly used in C-style programming to conserve memory by enabling
members of different types to occupy the same memory location. However, unions
aren't type-safe and are prone to programming errors. C++17 introduces the
std::variant class as a more robust and safe alternative to unions. The std::visit function
can be used to access the members of a variant type in a type-safe manner.
C++ Language Reference
Lambda Expressions
C++ Standard Library
Microsoft C/C++ language conformance
 std::vector<int> v {1,2,3,4,5};
 int x = 2;
 int y = 4;
 auto result = find_if(begin(v), end(v), [=](int i) { return i > x && i <
y; });
Exceptions
std::atomic
std::variant (C++17)
See also
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
Create a console calculator in C++
Article • 10/08/2024
The usual starting point for a C++ programmer is a "Hello, world!" application that runs
on the command line. You start with that in this article, and then move on to something
more challenging: a calculator app.
Prerequisites
Visual Studio with the Desktop development with C++ workload installed and
running on your computer. To install it, see Install C++ support in Visual Studio.
This tutorial demonstrates a feature called edit and continue which allows you to
make changes to your code while the app is running. To enable edit and continue,
from the main menu select Tools > Options > Debugging > General and ensure
that Require source files to exactly match the original version is checked.
Create your app project
Visual Studio uses projects to organize the code for an app, and solutions to organize
one or more projects. A project contains all the options, configurations, and rules used
to build an app. It also manages the relationship between all the project's files and any
external files. To create your app, first, create a new project and solution.
1. Start Visual Studio--the Visual Studio Start dialog box appears. Select Create a new
project to get started.
2. In the Create a new project dialog, set the language dropdown to C++, set the
platform dropdown to Windows, select Console App from the list of project types,
then select Next.
） Important
Make sure you select the C++ version of the Console App template. It has the
C++, Windows, and Console tags, and the icon has "++" in the corner.
3. In the Configure your new project dialog box, select the Project name text box,
name your new project CalculatorTutorial, then select Create.
An empty C++ Windows console application 'Hello World' app is created. Console
applications use a Windows console window to display output and accept user
input. In Visual Studio, an editor window opens and shows the generated code:
C++
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
int main()
{
 std::cout << "Hello World!\n";
}
// Run program: Ctrl + F5 or Debug > Start Without Debugging menu
// Debug program: F5 or Debug > Start Debugging menu
// Tips for Getting Started:
// 1. Use the Solution Explorer window to add/manage files
// 2. Use the Team Explorer window to connect to source control
// 3. Use the Output window to see build output and other messages
// 4. Use the Error List window to view errors
// 5. Go to Project > Add New Item to create new code files, or
Project > Add Existing Item to add existing code files to the project
// 6. In the future, to open this project again, go to File > Open >
Project and select the .sln file
Verify that your new app builds and runs
The template for a new Windows console application creates a simple C++ "Hello
World" app. At this point, you can see how Visual Studio builds and runs the apps you
create right from the IDE.
1. To build your project, select Build Solution from the Build menu. The Output
window shows the results of the build process.
2. To run the code, on the menu bar, select Debug > Start without debugging
(Ctrl+F5).
A console window opens and your app runs within it.
When you start a console app in Visual Studio, it runs your code, then prints "Press
any key to close this window . . ." to give you a chance to see the output.
Congratulations! You created your first "Hello, world!" console app in Visual Studio!
3. Press a key to dismiss the console window and return to Visual Studio.
You now have the tools to build and run your app after every change, to verify that the
code still works as you expect. Later, we show you how to debug it if it doesn't.
Now let's modify the code in this template to be a calculator app.
1. Replace the contents of the CalculatorTutorial.cpp file with the following code so
that it matches this example:
C++
Edit the code
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
using namespace std;
int main()
{
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
Understanding the code:
The #include statement brings in code in other files. Sometimes, you
may see a filename surrounded by angle brackets like <iostream> . The
angle brackets instruct the compiler to look for the iostream header file
first in the standard system directories, and if not found, to look in
directories specific to the project. Other times, you may see a filename
surrounded by quotes like "someHeader.h" . The quotes instruct the
compiler to skip looking in the standard system directories and instead
only look in directories specific to the project.
The using namespace std; tells the compiler to expect code from the
C++ Standard Library to be used in this file. Without this line, each
keyword from the library would have to be preceded with std:: to
denote its scope. For instance, without that line, each reference to cout
would be written as std::cout . The using statement is added to make it
more convenient to access code in another namespace.
The cout keyword is used to print to standard output in C++. The <<
operator tells the compiler to send whatever is to the right of it to the
standard output.
The endl keyword is like the Enter key; it ends the line and moves the
cursor to the next line. It's a better practice to put a \n inside the string
(contained by "" ) to do the same thing because endl always flushes the
buffer which can hurt the performance of the program. But since this is a
very small app, endl is used instead.
All C++ statements must end with semicolons and all C++ applications
must contain a main() function. This function is what the program runs at
a*b | a/b"
 << endl;
 return 0;
}
// Run program: Ctrl + F5 or Debug > Start Without Debugging menu
// Debug program: F5 or Debug > Start Debugging menu
// Tips for Getting Started:
// 1. Use the Solution Explorer window to add/manage files
// 2. Use the Team Explorer window to connect to source control
// 3. Use the Output window to see build output and other messages
// 4. Use the Error List window to view errors
// 5. Go to Project > Add New Item to create new code files, or
Project > Add Existing Item to add existing code files to the project
// 6. In the future, to open this project again, go to File > Open >
Project and select the .sln file
the start. All code must be accessible from main() in order to be used.
2. To save the file, press Ctrl+S, or select the floppy disk icon in the toolbar under the
menu bar.
3. To run the application, press Ctrl+F5 or go to the Debug menu and select Start
Without Debugging. You should see a console window appear that looks like this.
4. Close the console window when you're done.
Add code to do some math
A class is like a blueprint for an object that does something. In this case, we define a
calculator class to contain the math logic.
Add a Calculator class
1. Go to the Project menu and select Add Class. In the Class Name edit box, enter
Calculator. Select OK.
Two new files get added to your project. To save all your changed files at once,
press Ctrl+Shift+S. It's a keyboard shortcut for File > Save All. There's also a
toolbar button for Save All, an icon of two floppy disks, found beside the Save
button. In general, it's good practice to do Save All frequently, so you don't miss
saving any changes.
The Add Class wizard creates .h and .cpp files that have the same name as the
class. You can see a full list of your project files in the Solution Explorer window,
visible on the side of the IDE. If the window isn't visible, open it from the menu bar
via View > Solution Explorer.
You can open a file by double-clicking it in the Solution Explorer window. Double￾click Calculator.h to open it.
2. Replace the contents of Calculator.h with the following code so that the file now
looks like this:
C++
Understanding the code
This code declares a new function called Calculate , which handles math
operations for addition, subtraction, multiplication, and division.
#pragma once
class Calculator
{
public:
 double Calculate(double x, char oper, double y);
};
C++ code is organized into header ( .h ) files and source ( .cpp ) files.
Some other file extensions are supported by various compilers, but these
are the main ones to know about. Functions and variables are normally
declared, that is, given a name and a type, in header files, and
implemented, or given a definition, in source files. To access code defined
in another file, you can use #include "filename.h" , where filename.h is
the name of the file that declares the variables or functions you want to
use.
It's good practice to organize your code into different files based on what
it does, so it's easy to find the code you need later. In our case, we define
the Calculator class separately from the file containing the main()
function, but we plan to reference the Calculator class in main() .
3. A green squiggle appears under Calculate because although the Calculate
function is declared, it isn't defined. Hover over Calculate , click the down arrow on
the screwdriver icon, and select Create definition of 'Calculate' in Calculator.cpp .
This code is added to Calculator.cpp :
Currently, it just returns 0.0. Let's change that.
4. Switch to the Calculator.cpp file in the editor window. Replace the contents of
Calculator::Calculate(double x, char oper, double y) with:
C++
Understanding the code
The function Calculate takes a number, an operator, and a second
number. Then it performs the requested operation on the two numbers.
The switch statement checks which operator was provided, and executes
the case corresponding to that operation. The default: case is a fallback
double Calculator::Calculate(double x, char oper, double y)
{
 switch(oper)
 {
 case '+':
 return x + y;
 case '-':
 return x - y;
 case '*':
 return x * y;
 case '/':
 return x / y;
 default:
 return 0.0;
 }
}
in case the user types an operator that isn't handled by any of the
preceding case statements. It's best to handle invalid user input in a
more elegant way, but this is beyond the scope of this tutorial.
The double keyword denotes a type of number that supports decimals.
This type of number is called a floating-point number, and double means
a floating point number that has extra precision. This way, the calculator
can handle both decimal math and integer math. The Calculate function
is required to always return a double-precision floating point number due
to the double at the start of the code (this denotes the function's return
type), which is why we return 0.0 in the default case.
The .h file declares the function prototype, which tells the compiler
upfront what parameters it requires, and what return type to expect from
it. The .cpp file has all the implementation details of the function.
If you build and run the code again at this point, it immediately exits after asking which
operation to perform. So, modify the main function to do multiple calculations.
1. Update the main function in CalculatorTutorial.cpp as follows:
C++
Call the Calculator class member functions
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
#include "Calculator.h"
using namespace std;
int main()
{
 double x = 0.0;
 double y = 0.0;
 double result = 0.0;
 char oper = '+';
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
a*b | a/b"
 << endl;
 Calculator c;
 while (true)
 {
Understanding the code
Since C++ programs always start at the main() function, we need to call
our other code from there, so an #include statement is needed to make
that code visible to our main() function.
The variables x , y , oper , and result are declared to store the first
number, second number, operator, and final result, respectively. It's
always good practice to give them some initial values to avoid undefined
behavior, which is what is done here.
The Calculator c; line declares an object named c as an instance of the
Calculator class. The class itself is just a blueprint for how calculators
work; the object is the specific calculator that does the math.
The while (true) statement is a loop. The code inside the loop executes
over and over again as long as the condition inside the () holds true.
Since the condition is simply listed as true , it's always true, so the loop
runs forever. To close the program, the user must manually close the
console window. Otherwise, the program always waits for new input.
The cin keyword accepts input from the user. The input stream is smart
enough to process a line of text entered in the console window and place
it inside each of the variables listed, in order.
The c.Calculate(x, oper, y); expression calls the Calculate function
defined earlier, and supplies the entered input values and the requested
operation. The function then returns a number that is stored in result .
Finally, result is printed to the console and the user sees the result of
the calculation.
Now test the program again to make sure everything works properly.
1. Press Ctrl+F5 to rebuild and start the app.
2. Enter 5+5 , and press Enter. Verify that the result is 10.
 cin >> x >> oper >> y;
 result = c.Calculate(x, oper, y);
 cout << "Result " << "of " << x << oper << y << " is: " <<
result << endl;
 }
 return 0;
}
Build and test the code again
3. Stop the program by closing the console window.
Debug the app
Since the user is free to type anything into the console window, let's make sure the
calculator handles unexpected input. Instead of running the program, let's debug it so
we can inspect what it's doing step-by-step.
Run the app in the debugger
1. In CalcuatorTutorial.cpp , set a breakpoint on the line: result = c.Calculate(x,
oper, y); . To set the breakpoint, click next to the line in the gray vertical bar along
the left edge of the editor window so that a red dot appears.
Now when we debug the program, execution pauses at that line. We already have
a rough idea that the program works for simple cases. Since we don't want to
pause execution every time we call Calculate() , let's make the breakpoint
conditional.
2. Right-click the red dot that represents the breakpoint, and select Conditions. In
the edit box for the condition, enter (y == 0) && (oper == '/') . Select the Close
button to save the breakpoint condition.
Now, execution pauses at the breakpoint when the app tries to divide by 0.
3. To debug the program, press F5, or select the Local Windows Debugger debugger
toolbar button that has the green arrow icon. In your console app, if you enter
something like "5 - 0", the program behaves normally and keeps running.
However, if you type "10 / 0", it pauses at the breakpoint. You can put any number
of spaces between the operator and numbers: cin is smart enough to parse the
input appropriately.
Useful windows in the debugger
When you debug your code, you may notice that some new windows appear. These
windows can assist your debugging experience. Take a look at the Autos window. The
Autos window shows you the current values of variables used at least three lines before
and up to the current line. If you don't see the Autos window, from the main menu
select Debug > Windows > Autos.
To see all of the variables from that function, switch to the Locals window. Because this
is a small function, the Autos and Locals window show the same variables. But you can
modify the values of these variables in the Locals window while debugging to see what
effect they would have on the program. In this case, we leave them alone. Open the
Locals window by selecting Locals at the bottom of the Autos window, or by selecting
from the main menu Debug > Windows > Locals.
You can also hover over variables in the code to see their current values at the point
where execution is currently paused. Make sure the editor window is in focus by clicking
on it first.
Continue debugging
1. The yellow arrow on the left shows the current point of execution. The current line
calls Calculate , so press F11 to Step Into the function. Now you're executing code
in the body of the Calculate function. Be careful with Step Into because it steps
into any functions on the line you're on, including standard library functions. It's
fine to step into the standard library, but you may be more interested in focusing
on your code instead of library code.
2. Now that the point of execution is at the start of the Calculate function, press F10
to move to the next line in the program's execution. F10 is also known as Step
Over. You can use Step Over to move from line to line, without delving into the
details of what is occurring in each part of the line. In general, you should use Step
Over instead of Step Into unless you want to dive more deeply into code that is
being called from elsewhere (as you did to reach the body of Calculate ).
3. Continue using F10 to Step Over each line until you get back to the main()
function in the other file, and stop on the cout line.
The program is doing what's expected: it takes the first number, and divides it by
the second. On the cout line, hover over the result variable or take a look at
result in the Autos window. Its value is inf , which doesn't look right.
Let's fix it. The cout line outputs whatever value is stored in result , so when you
step one more line forward using F10, the console window displays:
This result is because division by zero is undefined, so the program doesn't have a
numerical answer for the requested operation.
Fix the "divide by zero" error
Let's handle division by zero more gracefully so that it's easier for the user to
understand the problem.
1. Make the following changes in CalculatorTutorial.cpp . You can leave the
program running as you edit, thanks to a debugger feature called Edit and
Continue. Add an if statement following cin >> x >> oper >> y; to check for
division by zero and output a message to the user if it happens. Otherwise, the
result is printed.
C++
2. Press F5 once. Program execution continues until it has to pause to ask for user
input. Enter 10 / 0 again. Now, a more helpful message is printed. The user is
asked for more input, and the program continues executing normally.
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
#include "Calculator.h"
using namespace std;
int main()
{
 double x = 0.0;
 double y = 0.0;
 double result = 0.0;
 char oper = '+';
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
a*b | a/b" << endl;
 Calculator c;
 while (true)
 {
 cin >> x >> oper >> y;
 if (oper == '/' && y == 0)
 {
 cout << "Math error: Attempted to divide by zero!" << endl;
 continue;
 }
 else
 {
 result = c.Calculate(x, oper, y);
 }
 cout << "Result " << "of " << x << oper << y << " is: " <<
result << endl;
 }
 return 0;
}
７ Note
When you edit code while in debugging mode, there's a risk of code
becoming stale. This happens when the debugger is still running your old
code, and has not yet updated it with your changes. The debugger displays a
dialog to inform you when this happens. Sometimes, you may need to press
F5 to refresh the code being executed. In particular, if you make a change
inside a function while the point of execution is inside that function, you need
to step out of the function, then back into it again to get the updated code. If
that doesn't work and you see an error message, you can stop debugging by
clicking on the red square in the toolbar under the menus at the top of the
IDE, then start debugging again by entering F5 or by choosing the green
"play" arrow beside the stop button on the toolbar.
Another reason edit and continue may fail is if you see a message that says
"The Require source files to exactly match the original version setting under
Debug->Options->General needs to be enabled..." To fix this, from the main
menu select Tools > Options > Debugging > General and ensure that
Require source files to exactly match the original version is checked.
Understanding the Run and Debug shortcuts
F5, or Debug > Start Debugging, starts a debugging session, if one isn't
already active, and runs the program until a breakpoint is hit or the
program needs user input. If no user input is needed and no breakpoint
is available to hit, the program terminates and the console window closes
itself when the program finishes running. If your program outputs to the
console, use Ctrl+F5 or set a breakpoint before you press F5 to keep the
window open.
Ctrl+F5, or Debug > Start Without Debugging, runs the application
without going into debug mode. This is slightly faster than debugging,
and the console window stays open after the program finishes executing.
F10, known as Step Over, lets you iterate through code, line-by-line, and
visualize how the code is run and what variable values are at each step of
execution.
F11, known as Step Into, works similarly to Step Over, except it steps into
any functions called on the line of execution. For example, if the line
being executed calls a function, pressing F11 moves the pointer into the
body of the function, so you can follow the function's code being run
before coming back to the line you started at. Pressing F10 steps over the
function call and just moves to the next line; the function call still
happens, but the program doesn't pause to show you what it's doing.
Close the app
If it's still running, close the console window to stop the calculator app.
Add Git source control
Now that you've created an app, you might want to add it to a Git repository. We've got
you covered. Visual Studio makes that process easy with Git tools you can use directly
from the IDE.
 Tip
Git is the most widely used modern version control system, so whether you're a
professional developer or you're learning how to code, Git can be very useful. If
you're new to Git, the https://git-scm.com/ website is a good place to start.
There, you can find cheat sheets, a popular online book, and Git Basics videos.
To associate your code with Git, you start by creating a new Git repository where your
code is located. Here's how:
1. In the status bar at the bottom-right corner of Visual Studio, select Add to Source
Control, and then select Git.
2. In the Create a Git repository dialog box, sign in to GitHub.
The repository name auto-populates based on your folder location. By default,
your new repository is private, which means you're the only one who can access it.
 Tip
Whether your repository is public or private, it's best to have a remote backup
of your code stored securely on GitHub. Even if you aren't working with a
team, a remote repository makes your code available to you from any
computer.
3. Select Create and Push.
After you create your repository, status details appear in the status bar.
The first icon with the arrows shows how many outgoing/incoming commits are in
your current branch. You can use this icon to pull any incoming commits or push
any outgoing commits. You can also choose to view these commits first. To do so,
select the icon, and then select View Outgoing/Incoming.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
The second icon with the pencil shows the number of uncommitted changes to
your code. You can select this icon to view those changes in the Git Changes
window.
To learn more about how to use Git with your app, see the Visual Studio version control
documentation.
Congratulations! You completed the code for the calculator app, built and debugged it,
and added it to a repo, all in Visual Studio.
Learn more about Visual Studio for C++
The finished app
Next steps
 Yes  No
Get started with C++/WinRT
Article • 02/13/2023
） Important
For info about setting up Visual Studio for C++/WinRT development—including
installing and using the C++/WinRT Visual Studio Extension (VSIX) and the NuGet
package (which together provide project template and build support)—see Visual
Studio support for C++/WinRT.
To get you up to speed with using C++/WinRT, this topic walks through a simple code
example based on a new Windows Console Application (C++/WinRT) project. This
topic also shows how to add C++/WinRT support to a Windows Desktop application
project.
７ Note
While we recommend that you develop with the latest versions of Visual Studio and
the Windows SDK, if you're using Visual Studio 2017 (version 15.8.0 or later), and
targeting the Windows SDK version 10.0.17134.0 (Windows 10, version 1803), then
a newly created C++/WinRT project may fail to compile with the error "error C3861:
'from_abi': identifier not found", and with other errors originating in base.h. The
solution is to either target a later (more conformant) version of the Windows SDK,
or set project property C/C++ > Language > Conformance mode: No (also, if
/permissive- appears in project property C/C++ > Language > Command Line
under Additional Options, then delete it).
A C++/WinRT quick-start
Create a new Windows Console Application (C++/WinRT) project.
Edit pch.h and main.cpp to look like this.
C++/WinRT
// pch.h
#pragma once
#include <winrt/Windows.Foundation.Collections.h>
C++/WinRT
Let's take the short code example above piece by piece, and explain what's going on in
each part.
C++/WinRT
With the default project settings, the included headers come from the Windows SDK,
inside the folder
%WindowsSdkDir%Include<WindowsTargetPlatformVersion>\cppwinrt\winrt . Visual Studio
includes that path in its IncludePath macro. But there's no strict dependency on the
#include <winrt/Windows.Web.Syndication.h>
#include <iostream>
// main.cpp
#include "pch.h"
using namespace winrt;
using namespace Windows::Foundation;
using namespace Windows::Web::Syndication;
int main()
{
 winrt::init_apartment();
 Uri rssFeedUri{ L"https://blogs.windows.com/feed" };
 SyndicationClient syndicationClient;
 syndicationClient.SetRequestHeader(L"User-Agent", L"Mozilla/5.0
(compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)");
 SyndicationFeed syndicationFeed =
syndicationClient.RetrieveFeedAsync(rssFeedUri).get();
 for (const SyndicationItem syndicationItem : syndicationFeed.Items())
 {
 winrt::hstring titleAsHstring = syndicationItem.Title().Text();
 
 // A workaround to remove the trademark symbol from the title
string, because it causes issues in this case.
 std::wstring titleAsStdWstring{ titleAsHstring.c_str() };
 titleAsStdWstring.erase(remove(titleAsStdWstring.begin(),
titleAsStdWstring.end(), L'™'), titleAsStdWstring.end());
 titleAsHstring = titleAsStdWstring;
 std::wcout << titleAsHstring.c_str() << std::endl;
 }
}
#include <winrt/Windows.Foundation.Collections.h>
#include <winrt/Windows.Web.Syndication.h>
Windows SDK, because your project (via the cppwinrt.exe tool) generates those same
headers into your project's $(GeneratedFilesDir) folder. They'll be loaded from that
folder if they can't be found elsewhere, or if you change your project settings.
The headers contain Windows APIs projected into C++/WinRT. In other words, for each
Windows type, C++/WinRT defines a C++-friendly equivalent (called the projected type).
A projected type has the same fully-qualified name as the Windows type, but it's placed
in the C++ winrt namespace. Putting these includes in your precompiled header
reduces incremental build times.
） Important
Whenever you want to use a type from a Windows namespaces, you must #include
the corresponding C++/WinRT Windows namespace header file, as shown above.
The corresponding header is the one with the same name as the type's namespace.
For example, to use the C++/WinRT projection for the
Windows::Foundation::Collections::PropertySet runtime class, include the
winrt/Windows.Foundation.Collections.h header.
It is common for a C++/WinRT projection header to automatically include related
namespace header files. For example, winrt/Windows.Foundation.Collections.h
includes winrt/Windows.Foundation.h . But you shouldn't rely on this behavior, since
it's an implementation detail that changes over time. You must explicitly include
any headers that you need.
C++/WinRT
using namespace winrt;
using namespace Windows::Foundation;
using namespace Windows::Web::Syndication;
The using namespace directives are optional, but convenient. The pattern shown above
for such directives (allowing unqualified name lookup for anything in the winrt
namespace) is suitable for when you're beginning a new project and C++/WinRT is the
only language projection you're using inside of that project. If, on the other hand, you're
mixing C++/WinRT code with C++/CX and/or SDK application binary interface (ABI)
code (you're either porting from, or interoperating with, one or both of those models),
then see the topics Interop between C++/WinRT and C++/CX, Move to C++/WinRT
from C++/CX, and Interop between C++/WinRT and the ABI.
C++/WinRT
winrt::init_apartment();
The call to winrt::init_apartment initializes the thread in the Windows Runtime; by
default, in a multithreaded apartment. The call also initializes COM.
C++/WinRT
Uri rssFeedUri{ L"https://blogs.windows.com/feed" };
SyndicationClient syndicationClient;
Stack-allocate two objects: they represent the uri of the Windows blog, and a
syndication client. We construct the uri with a simple wide string literal (see String
handling in C++/WinRT for more ways you can work with strings).
C++/WinRT
SyndicationFeed syndicationFeed =
syndicationClient.RetrieveFeedAsync(rssFeedUri).get();
SyndicationClient::RetrieveFeedAsync is an example of an asynchronous Windows
Runtime function. The code example receives an asynchronous operation object from
RetrieveFeedAsync, and it calls get on that object to block the calling thread and wait
for the result (which is a syndication feed, in this case). For more about concurrency, and
for non-blocking techniques, see Concurrency and asynchronous operations with
C++/WinRT.
C++/WinRT
for (const SyndicationItem syndicationItem : syndicationFeed.Items()) { ...
}
SyndicationFeed.Items is a range, defined by the iterators returned from begin and end
functions (or their constant, reverse, and constant-reverse variants). Because of this, you
can enumerate Items with either a range-based for statement, or with the std::for_each
template function. Whenever you iterate over a Windows Runtime collection like this,
you'll need to #include <winrt/Windows.Foundation.Collections.h> .
C++/WinRT
winrt::hstring titleAsHstring = syndicationItem.Title().Text();
// Omitted: there's a little bit of extra work here to remove the trademark
symbol from the title text.
std::wcout << titleAsHstring.c_str() << std::endl;
Gets the feed's title text, as a winrt::hstring object (more details in String handling in
C++/WinRT). The hstring is then output, via the c_str function, which reflects the pattern
used with C++ Standard Library strings.
As you can see, C++/WinRT encourages modern, and class-like, C++ expressions such
as syndicationItem.Title().Text() . This is a different, and cleaner, programming style
from traditional COM programming. You don't need to directly initialize COM, nor work
with COM pointers.
Nor do you need to handle HRESULT return codes. C++/WinRT converts error HRESULTs
to exceptions such as winrt::hresult-error for a natural and modern programming style.
For more info about error-handling, and code examples, see Error handling with
C++/WinRT.
Modify a Windows Desktop application project
to add C++/WinRT support
Some desktop projects (for example, the WinUI 3 templates in Visual Studio) have
C++/WinRT support built in.
But this section shows you how you can add C++/WinRT support to any Windows
Desktop application project that you might have. If you don't have an existing Windows
Desktop application project, then you can follow along with these steps by first creating
one. For example, open Visual Studio and create a Visual C++ > Windows Desktop >
Windows Desktop Application project.
You can optionally install the C++/WinRT Visual Studio Extension (VSIX) and the
NuGet package. For details, see Visual Studio support for C++/WinRT.
Set project properties
Go to project property General > Windows SDK Version, and select All Configurations
and All Platforms. Ensure that Windows SDK Version is set to 10.0.17134.0 (Windows
10, version 1803) or greater.
Confirm that you're not affected by Why won't my new project compile?.
Because C++/WinRT uses features from the C++17 standard, set project property
C/C++ > Language > C++ Language Standard to ISO C++17 Standard (/std:c++17).
The precompiled header
The default project template creates a precompiled header for you, named either
framework.h , or stdafx.h . Rename that to pch.h . If you have a stdafx.cpp file, then
rename that to pch.cpp . Set project property C/C++ > Precompiled Headers >
Precompiled Header to Create (/Yc), and Precompiled Header File to pch.h.
Find and replace all #include "framework.h" (or #include "stdafx.h" ) with #include
"pch.h" .
In pch.h , include winrt/base.h .
C++/WinRT
// pch.h
...
#include <winrt/base.h>
Linking
The C++/WinRT language projection depends on certain Windows Runtime free (non￾member) functions, and entry points, that require linking to the WindowsApp.lib
umbrella library. This section describes three ways of satisfying the linker.
The first option is to add to your Visual Studio project all of the C++/WinRT MSBuild
properties and targets. To do this, install the Microsoft.Windows.CppWinRT NuGet
package into your project. Open the project in Visual Studio, click Project > Manage
NuGet Packages... > Browse, type or paste Microsoft.Windows.CppWinRT in the search
box, select the item in search results, and then click Install to install the package for that
project.
You can also use project link settings to explicitly link WindowsApp.lib . Or, you can do it
in source code (in pch.h , for example) like this.
C++/WinRT
#pragma comment(lib, "windowsapp")
You can now compile and link, and add C++/WinRT code to your project (for example,
code similar to that shown in the A C++/WinRT quick-start section, above).
The three main scenarios for C++/WinRT
As you use and become familiar with C++/WinRT, and work through the rest of the
documentation here, you'll likely notice that there are three main scenarios, as described
in the following sections.
Consuming Windows APIs and types
In other words, using, or calling APIs. For example, making API calls to communicate
using Bluetooth; to stream and present video; to integrate with the Windows shell; and
so on. C++/WinRT fully and uncompromisingly supports this category of scenario. For
more info, see Consume APIs with C++/WinRT.
Authoring Windows APIs and types
In other words, producing APIs and types. For example, producing the kinds of APIs
described in the section above; or the graphics APIs; the storage and file system APIs;
the networking APIs, and so on. For more info, see Author APIs with C++/WinRT.
Authoring APIs with C++/WinRT is a little more involved than consuming them, because
you must use IDL to define the shape of the API before you can implement it. There's a
walkthrough of doing that in XAML controls; bind to a C++/WinRT property.
XAML applications
This scenario is about building applications and controls on the XAML UI framework.
Working in a XAML application amounts to a combination of consuming and authoring.
But since XAML is the dominant UI framework on Windows today, and its influence over
the Windows Runtime is proportionate to that, it deserves its own category of scenario.
Be aware that XAML works best with programming languages that offer reflection. In
C++/WinRT, you sometimes have to do a little extra work in order to interoperate with
the XAML framework. All of those cases are covered in the documentation. Good places
to start are XAML controls; bind to a C++/WinRT property and XAML custom
(templated) controls with C++/WinRT.
Sample apps written in C++/WinRT
See Where can I find C++/WinRT sample apps?.
Important APIs
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
SyndicationClient::RetrieveFeedAsync method
SyndicationFeed.Items property
winrt::hstring struct
winrt::hresult-error struct
C++/CX
Error handling with C++/WinRT
Interop between C++/WinRT and C++/CX
Interop between C++/WinRT and the ABI
Move to C++/WinRT from C++/CX
String handling in C++/WinRT
Related topics
 Yes  No
Feedback
Was this page helpful?
Get help at Microsoft Q&A
Get Started with Win32 and C++
Article • 01/27/2022
The aim of this Get Started series is to teach you how to write a desktop program in
C++ using Win32 and COM APIs.
In the first module, you'll learn step-by-step how to create and show a window. Later
modules will introduce the Component Object Model (COM), graphics and text, and
user input.
For this series, it is assumed that you have a good working knowledge of C++
programming. No previous experience with Windows programming is assumed. If you
are new to C++, learning material is available in the C++ language documentation .
Topic Description
Intro to Win32
programming in C++
This section describes some of the basic terminology and coding
conventions used in Windows programming.
Module 1. Your First
Windows Program
In this module, you will create a simple Windows program that
shows a blank window.
Module 2. Using COM in
Your Windows Program
This module introduces the Component Object Model (COM),
which underlies many of the modern Windows APIs.
Module 3. Windows
Graphics
This module introduces the Windows graphics architecture, with a
focus on Direct2D.
Module 4. User Input This module describes mouse and keyboard input.
Sample Code Contains links to download the sample code for this series.
In this section
ﾂ Yes ﾄ No
Create a simple Universal Windows
Platform (UWP) game with DirectX
Article • 10/20/2022
In this set of tutorials, you'll learn how to use DirectX and C++/WinRT to create the basic
Universal Windows Platform (UWP) sample game named Simple3DGameDX. The
gameplay takes place in a simple first-person 3D shooting gallery.
７ Note
The link from which you can download the Simple3DGameDX sample game itself is
Direct3D sample game. The C++/WinRT source code is in the folder named
cppwinrt . For info about other UWP sample apps, see Sample applications for
Windows development.
These tutorials cover all of the major parts of a game, including the processes for
loading assets such as arts and meshes, creating a main game loop, implementing a
simple rendering pipeline, and adding sound and controls.
You'll also see UWP game development techniques and considerations. We'll focus on
key UWP DirectX game development concepts, and call out Windows-Runtime-specific
considerations around those concepts.
Objective
To learn about the basic concepts and components of a UWP DirectX game, and to
become more comfortable designing UWP games with DirectX.
What you need to know
For this tutorial, you need to be familiar with these subjects.
C++/WinRT. C++/WinRT is a standard modern C++17 language projection for
Windows APIs, implemented as a header-file-based library, and designed to
provide you with first-class access to the modern Windows APIs.
Basic linear algebra and Newtonian physics concepts.
Basic graphics programming terminology.
Basic Windows programming concepts.
Basic familiarity with the Direct2D and Direct3D 11 APIs.
The Simple3DGameDX sample game implements a simple first-person 3D shooting
gallery, where the player fires balls at moving targets. Hitting each target awards a set
number of points, and the player can progress through 6 levels of increasing challenge.
At the end of the levels, the points are tallied, and the player is awarded a final score.
The sample demonstrates these game concepts.
Interoperation between DirectX 11.1 and the Windows Runtime
A first-person 3D perspective and camera
Stereoscopic 3D effects
Collision-detection between objects in 3D
Handling player input for mouse, touch, and Xbox controller controls
Audio mixing and playback
A basic game state-machine
Topic Description
Set up the
game project
The first step in developing your game is to set up a project in Microsoft Visual
Studio. After you've configured a project specifically for game development, you
could later re-use it as a kind of template.
Define the
game's UWP
app framework
The first step in coding a Universal Windows Platform (UWP) game is building
the framework that lets the app object interact with Windows.
Game flow
management
Define the high-level state machine to enable player and system interaction.
Learn how UI interacts with the overall game's state machine and how to create
event handlers for UWP games.
Direct3D UWP shooting gallery sample
Topic Description
Define the
main game
object
Now, we look at the details of the sample game's main object and how the rules
it implements translate into interactions with the game world.
Rendering
framework I:
Intro to
rendering
Learn how to develop the rendering pipeline to display graphics. Intro to
rendering.
Rendering
framework II:
Game
rendering
Learn how to assemble the rendering pipeline to display graphics. Game
rendering, set up and prepare data.
Add a user
interface
Learn how to add a 2D user interface overlay to a DirectX UWP game.
Add controls Now, we take a look at how the sample game implements move-look controls
in a 3-D game, and how to develop basic touch, mouse, and game controller
controls.
Add sound Develop a simple sound engine using XAudio2 APIs to playback game music
and sound effects.
Extend the
sample game
Learn how to implement a XAML overlay for a UWP DirectX game.
Create a console calculator in C++
Article • 10/08/2024
The usual starting point for a C++ programmer is a "Hello, world!" application that runs
on the command line. You start with that in this article, and then move on to something
more challenging: a calculator app.
Prerequisites
Visual Studio with the Desktop development with C++ workload installed and
running on your computer. To install it, see Install C++ support in Visual Studio.
This tutorial demonstrates a feature called edit and continue which allows you to
make changes to your code while the app is running. To enable edit and continue,
from the main menu select Tools > Options > Debugging > General and ensure
that Require source files to exactly match the original version is checked.
Create your app project
Visual Studio uses projects to organize the code for an app, and solutions to organize
one or more projects. A project contains all the options, configurations, and rules used
to build an app. It also manages the relationship between all the project's files and any
external files. To create your app, first, create a new project and solution.
1. Start Visual Studio--the Visual Studio Start dialog box appears. Select Create a new
project to get started.
2. In the Create a new project dialog, set the language dropdown to C++, set the
platform dropdown to Windows, select Console App from the list of project types,
then select Next.
） Important
Make sure you select the C++ version of the Console App template. It has the
C++, Windows, and Console tags, and the icon has "++" in the corner.
3. In the Configure your new project dialog box, select the Project name text box,
name your new project CalculatorTutorial, then select Create.
An empty C++ Windows console application 'Hello World' app is created. Console
applications use a Windows console window to display output and accept user
input. In Visual Studio, an editor window opens and shows the generated code:
C++
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
int main()
{
 std::cout << "Hello World!\n";
}
// Run program: Ctrl + F5 or Debug > Start Without Debugging menu
// Debug program: F5 or Debug > Start Debugging menu
// Tips for Getting Started:
// 1. Use the Solution Explorer window to add/manage files
// 2. Use the Team Explorer window to connect to source control
// 3. Use the Output window to see build output and other messages
// 4. Use the Error List window to view errors
// 5. Go to Project > Add New Item to create new code files, or
Project > Add Existing Item to add existing code files to the project
// 6. In the future, to open this project again, go to File > Open >
Project and select the .sln file
Verify that your new app builds and runs
The template for a new Windows console application creates a simple C++ "Hello
World" app. At this point, you can see how Visual Studio builds and runs the apps you
create right from the IDE.
1. To build your project, select Build Solution from the Build menu. The Output
window shows the results of the build process.
2. To run the code, on the menu bar, select Debug > Start without debugging
(Ctrl+F5).
A console window opens and your app runs within it.
When you start a console app in Visual Studio, it runs your code, then prints "Press
any key to close this window . . ." to give you a chance to see the output.
Congratulations! You created your first "Hello, world!" console app in Visual Studio!
3. Press a key to dismiss the console window and return to Visual Studio.
You now have the tools to build and run your app after every change, to verify that the
code still works as you expect. Later, we show you how to debug it if it doesn't.
Now let's modify the code in this template to be a calculator app.
1. Replace the contents of the CalculatorTutorial.cpp file with the following code so
that it matches this example:
C++
Edit the code
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
using namespace std;
int main()
{
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
Understanding the code:
The #include statement brings in code in other files. Sometimes, you
may see a filename surrounded by angle brackets like <iostream> . The
angle brackets instruct the compiler to look for the iostream header file
first in the standard system directories, and if not found, to look in
directories specific to the project. Other times, you may see a filename
surrounded by quotes like "someHeader.h" . The quotes instruct the
compiler to skip looking in the standard system directories and instead
only look in directories specific to the project.
The using namespace std; tells the compiler to expect code from the
C++ Standard Library to be used in this file. Without this line, each
keyword from the library would have to be preceded with std:: to
denote its scope. For instance, without that line, each reference to cout
would be written as std::cout . The using statement is added to make it
more convenient to access code in another namespace.
The cout keyword is used to print to standard output in C++. The <<
operator tells the compiler to send whatever is to the right of it to the
standard output.
The endl keyword is like the Enter key; it ends the line and moves the
cursor to the next line. It's a better practice to put a \n inside the string
(contained by "" ) to do the same thing because endl always flushes the
buffer which can hurt the performance of the program. But since this is a
very small app, endl is used instead.
All C++ statements must end with semicolons and all C++ applications
must contain a main() function. This function is what the program runs at
a*b | a/b"
 << endl;
 return 0;
}
// Run program: Ctrl + F5 or Debug > Start Without Debugging menu
// Debug program: F5 or Debug > Start Debugging menu
// Tips for Getting Started:
// 1. Use the Solution Explorer window to add/manage files
// 2. Use the Team Explorer window to connect to source control
// 3. Use the Output window to see build output and other messages
// 4. Use the Error List window to view errors
// 5. Go to Project > Add New Item to create new code files, or
Project > Add Existing Item to add existing code files to the project
// 6. In the future, to open this project again, go to File > Open >
Project and select the .sln file
the start. All code must be accessible from main() in order to be used.
2. To save the file, press Ctrl+S, or select the floppy disk icon in the toolbar under the
menu bar.
3. To run the application, press Ctrl+F5 or go to the Debug menu and select Start
Without Debugging. You should see a console window appear that looks like this.
4. Close the console window when you're done.
Add code to do some math
A class is like a blueprint for an object that does something. In this case, we define a
calculator class to contain the math logic.
Add a Calculator class
1. Go to the Project menu and select Add Class. In the Class Name edit box, enter
Calculator. Select OK.
Two new files get added to your project. To save all your changed files at once,
press Ctrl+Shift+S. It's a keyboard shortcut for File > Save All. There's also a
toolbar button for Save All, an icon of two floppy disks, found beside the Save
button. In general, it's good practice to do Save All frequently, so you don't miss
saving any changes.
The Add Class wizard creates .h and .cpp files that have the same name as the
class. You can see a full list of your project files in the Solution Explorer window,
visible on the side of the IDE. If the window isn't visible, open it from the menu bar
via View > Solution Explorer.
You can open a file by double-clicking it in the Solution Explorer window. Double￾click Calculator.h to open it.
2. Replace the contents of Calculator.h with the following code so that the file now
looks like this:
C++
Understanding the code
This code declares a new function called Calculate , which handles math
operations for addition, subtraction, multiplication, and division.
#pragma once
class Calculator
{
public:
 double Calculate(double x, char oper, double y);
};
C++ code is organized into header ( .h ) files and source ( .cpp ) files.
Some other file extensions are supported by various compilers, but these
are the main ones to know about. Functions and variables are normally
declared, that is, given a name and a type, in header files, and
implemented, or given a definition, in source files. To access code defined
in another file, you can use #include "filename.h" , where filename.h is
the name of the file that declares the variables or functions you want to
use.
It's good practice to organize your code into different files based on what
it does, so it's easy to find the code you need later. In our case, we define
the Calculator class separately from the file containing the main()
function, but we plan to reference the Calculator class in main() .
3. A green squiggle appears under Calculate because although the Calculate
function is declared, it isn't defined. Hover over Calculate , click the down arrow on
the screwdriver icon, and select Create definition of 'Calculate' in Calculator.cpp .
This code is added to Calculator.cpp :
Currently, it just returns 0.0. Let's change that.
4. Switch to the Calculator.cpp file in the editor window. Replace the contents of
Calculator::Calculate(double x, char oper, double y) with:
C++
Understanding the code
The function Calculate takes a number, an operator, and a second
number. Then it performs the requested operation on the two numbers.
The switch statement checks which operator was provided, and executes
the case corresponding to that operation. The default: case is a fallback
double Calculator::Calculate(double x, char oper, double y)
{
 switch(oper)
 {
 case '+':
 return x + y;
 case '-':
 return x - y;
 case '*':
 return x * y;
 case '/':
 return x / y;
 default:
 return 0.0;
 }
}
in case the user types an operator that isn't handled by any of the
preceding case statements. It's best to handle invalid user input in a
more elegant way, but this is beyond the scope of this tutorial.
The double keyword denotes a type of number that supports decimals.
This type of number is called a floating-point number, and double means
a floating point number that has extra precision. This way, the calculator
can handle both decimal math and integer math. The Calculate function
is required to always return a double-precision floating point number due
to the double at the start of the code (this denotes the function's return
type), which is why we return 0.0 in the default case.
The .h file declares the function prototype, which tells the compiler
upfront what parameters it requires, and what return type to expect from
it. The .cpp file has all the implementation details of the function.
If you build and run the code again at this point, it immediately exits after asking which
operation to perform. So, modify the main function to do multiple calculations.
1. Update the main function in CalculatorTutorial.cpp as follows:
C++
Call the Calculator class member functions
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
#include "Calculator.h"
using namespace std;
int main()
{
 double x = 0.0;
 double y = 0.0;
 double result = 0.0;
 char oper = '+';
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
a*b | a/b"
 << endl;
 Calculator c;
 while (true)
 {
Understanding the code
Since C++ programs always start at the main() function, we need to call
our other code from there, so an #include statement is needed to make
that code visible to our main() function.
The variables x , y , oper , and result are declared to store the first
number, second number, operator, and final result, respectively. It's
always good practice to give them some initial values to avoid undefined
behavior, which is what is done here.
The Calculator c; line declares an object named c as an instance of the
Calculator class. The class itself is just a blueprint for how calculators
work; the object is the specific calculator that does the math.
The while (true) statement is a loop. The code inside the loop executes
over and over again as long as the condition inside the () holds true.
Since the condition is simply listed as true , it's always true, so the loop
runs forever. To close the program, the user must manually close the
console window. Otherwise, the program always waits for new input.
The cin keyword accepts input from the user. The input stream is smart
enough to process a line of text entered in the console window and place
it inside each of the variables listed, in order.
The c.Calculate(x, oper, y); expression calls the Calculate function
defined earlier, and supplies the entered input values and the requested
operation. The function then returns a number that is stored in result .
Finally, result is printed to the console and the user sees the result of
the calculation.
Now test the program again to make sure everything works properly.
1. Press Ctrl+F5 to rebuild and start the app.
2. Enter 5+5 , and press Enter. Verify that the result is 10.
 cin >> x >> oper >> y;
 result = c.Calculate(x, oper, y);
 cout << "Result " << "of " << x << oper << y << " is: " <<
result << endl;
 }
 return 0;
}
Build and test the code again
3. Stop the program by closing the console window.
Debug the app
Since the user is free to type anything into the console window, let's make sure the
calculator handles unexpected input. Instead of running the program, let's debug it so
we can inspect what it's doing step-by-step.
Run the app in the debugger
1. In CalcuatorTutorial.cpp , set a breakpoint on the line: result = c.Calculate(x,
oper, y); . To set the breakpoint, click next to the line in the gray vertical bar along
the left edge of the editor window so that a red dot appears.
Now when we debug the program, execution pauses at that line. We already have
a rough idea that the program works for simple cases. Since we don't want to
pause execution every time we call Calculate() , let's make the breakpoint
conditional.
2. Right-click the red dot that represents the breakpoint, and select Conditions. In
the edit box for the condition, enter (y == 0) && (oper == '/') . Select the Close
button to save the breakpoint condition.
Now, execution pauses at the breakpoint when the app tries to divide by 0.
3. To debug the program, press F5, or select the Local Windows Debugger debugger
toolbar button that has the green arrow icon. In your console app, if you enter
something like "5 - 0", the program behaves normally and keeps running.
However, if you type "10 / 0", it pauses at the breakpoint. You can put any number
of spaces between the operator and numbers: cin is smart enough to parse the
input appropriately.
Useful windows in the debugger
When you debug your code, you may notice that some new windows appear. These
windows can assist your debugging experience. Take a look at the Autos window. The
Autos window shows you the current values of variables used at least three lines before
and up to the current line. If you don't see the Autos window, from the main menu
select Debug > Windows > Autos.
To see all of the variables from that function, switch to the Locals window. Because this
is a small function, the Autos and Locals window show the same variables. But you can
modify the values of these variables in the Locals window while debugging to see what
effect they would have on the program. In this case, we leave them alone. Open the
Locals window by selecting Locals at the bottom of the Autos window, or by selecting
from the main menu Debug > Windows > Locals.
You can also hover over variables in the code to see their current values at the point
where execution is currently paused. Make sure the editor window is in focus by clicking
on it first.
Continue debugging
1. The yellow arrow on the left shows the current point of execution. The current line
calls Calculate , so press F11 to Step Into the function. Now you're executing code
in the body of the Calculate function. Be careful with Step Into because it steps
into any functions on the line you're on, including standard library functions. It's
fine to step into the standard library, but you may be more interested in focusing
on your code instead of library code.
2. Now that the point of execution is at the start of the Calculate function, press F10
to move to the next line in the program's execution. F10 is also known as Step
Over. You can use Step Over to move from line to line, without delving into the
details of what is occurring in each part of the line. In general, you should use Step
Over instead of Step Into unless you want to dive more deeply into code that is
being called from elsewhere (as you did to reach the body of Calculate ).
3. Continue using F10 to Step Over each line until you get back to the main()
function in the other file, and stop on the cout line.
The program is doing what's expected: it takes the first number, and divides it by
the second. On the cout line, hover over the result variable or take a look at
result in the Autos window. Its value is inf , which doesn't look right.
Let's fix it. The cout line outputs whatever value is stored in result , so when you
step one more line forward using F10, the console window displays:
This result is because division by zero is undefined, so the program doesn't have a
numerical answer for the requested operation.
Fix the "divide by zero" error
Let's handle division by zero more gracefully so that it's easier for the user to
understand the problem.
1. Make the following changes in CalculatorTutorial.cpp . You can leave the
program running as you edit, thanks to a debugger feature called Edit and
Continue. Add an if statement following cin >> x >> oper >> y; to check for
division by zero and output a message to the user if it happens. Otherwise, the
result is printed.
C++
2. Press F5 once. Program execution continues until it has to pause to ask for user
input. Enter 10 / 0 again. Now, a more helpful message is printed. The user is
asked for more input, and the program continues executing normally.
// CalculatorTutorial.cpp : This file contains the 'main' function.
Program execution begins and ends there.
//
#include <iostream>
#include "Calculator.h"
using namespace std;
int main()
{
 double x = 0.0;
 double y = 0.0;
 double result = 0.0;
 char oper = '+';
 cout << "Calculator Console Application" << endl << endl;
 cout << "Please enter the operation to perform. Format: a+b | a-b |
a*b | a/b" << endl;
 Calculator c;
 while (true)
 {
 cin >> x >> oper >> y;
 if (oper == '/' && y == 0)
 {
 cout << "Math error: Attempted to divide by zero!" << endl;
 continue;
 }
 else
 {
 result = c.Calculate(x, oper, y);
 }
 cout << "Result " << "of " << x << oper << y << " is: " <<
result << endl;
 }
 return 0;
}
７ Note
When you edit code while in debugging mode, there's a risk of code
becoming stale. This happens when the debugger is still running your old
code, and has not yet updated it with your changes. The debugger displays a
dialog to inform you when this happens. Sometimes, you may need to press
F5 to refresh the code being executed. In particular, if you make a change
inside a function while the point of execution is inside that function, you need
to step out of the function, then back into it again to get the updated code. If
that doesn't work and you see an error message, you can stop debugging by
clicking on the red square in the toolbar under the menus at the top of the
IDE, then start debugging again by entering F5 or by choosing the green
"play" arrow beside the stop button on the toolbar.
Another reason edit and continue may fail is if you see a message that says
"The Require source files to exactly match the original version setting under
Debug->Options->General needs to be enabled..." To fix this, from the main
menu select Tools > Options > Debugging > General and ensure that
Require source files to exactly match the original version is checked.
Understanding the Run and Debug shortcuts
F5, or Debug > Start Debugging, starts a debugging session, if one isn't
already active, and runs the program until a breakpoint is hit or the
program needs user input. If no user input is needed and no breakpoint
is available to hit, the program terminates and the console window closes
itself when the program finishes running. If your program outputs to the
console, use Ctrl+F5 or set a breakpoint before you press F5 to keep the
window open.
Ctrl+F5, or Debug > Start Without Debugging, runs the application
without going into debug mode. This is slightly faster than debugging,
and the console window stays open after the program finishes executing.
F10, known as Step Over, lets you iterate through code, line-by-line, and
visualize how the code is run and what variable values are at each step of
execution.
F11, known as Step Into, works similarly to Step Over, except it steps into
any functions called on the line of execution. For example, if the line
being executed calls a function, pressing F11 moves the pointer into the
body of the function, so you can follow the function's code being run
before coming back to the line you started at. Pressing F10 steps over the
function call and just moves to the next line; the function call still
happens, but the program doesn't pause to show you what it's doing.
Close the app
If it's still running, close the console window to stop the calculator app.
Add Git source control
Now that you've created an app, you might want to add it to a Git repository. We've got
you covered. Visual Studio makes that process easy with Git tools you can use directly
from the IDE.
 Tip
Git is the most widely used modern version control system, so whether you're a
professional developer or you're learning how to code, Git can be very useful. If
you're new to Git, the https://git-scm.com/ website is a good place to start.
There, you can find cheat sheets, a popular online book, and Git Basics videos.
To associate your code with Git, you start by creating a new Git repository where your
code is located. Here's how:
1. In the status bar at the bottom-right corner of Visual Studio, select Add to Source
Control, and then select Git.
2. In the Create a Git repository dialog box, sign in to GitHub.
The repository name auto-populates based on your folder location. By default,
your new repository is private, which means you're the only one who can access it.
 Tip
Whether your repository is public or private, it's best to have a remote backup
of your code stored securely on GitHub. Even if you aren't working with a
team, a remote repository makes your code available to you from any
computer.
3. Select Create and Push.
After you create your repository, status details appear in the status bar.
The first icon with the arrows shows how many outgoing/incoming commits are in
your current branch. You can use this icon to pull any incoming commits or push
any outgoing commits. You can also choose to view these commits first. To do so,
select the icon, and then select View Outgoing/Incoming.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
The second icon with the pencil shows the number of uncommitted changes to
your code. You can select this icon to view those changes in the Git Changes
window.
To learn more about how to use Git with your app, see the Visual Studio version control
documentation.
Congratulations! You completed the code for the calculator app, built and debugged it,
and added it to a repo, all in Visual Studio.
Learn more about Visual Studio for C++
The finished app
Next steps
 Yes  No
Get started with C++/WinRT
Article • 02/13/2023
） Important
For info about setting up Visual Studio for C++/WinRT development—including
installing and using the C++/WinRT Visual Studio Extension (VSIX) and the NuGet
package (which together provide project template and build support)—see Visual
Studio support for C++/WinRT.
To get you up to speed with using C++/WinRT, this topic walks through a simple code
example based on a new Windows Console Application (C++/WinRT) project. This
topic also shows how to add C++/WinRT support to a Windows Desktop application
project.
７ Note
While we recommend that you develop with the latest versions of Visual Studio and
the Windows SDK, if you're using Visual Studio 2017 (version 15.8.0 or later), and
targeting the Windows SDK version 10.0.17134.0 (Windows 10, version 1803), then
a newly created C++/WinRT project may fail to compile with the error "error C3861:
'from_abi': identifier not found", and with other errors originating in base.h. The
solution is to either target a later (more conformant) version of the Windows SDK,
or set project property C/C++ > Language > Conformance mode: No (also, if
/permissive- appears in project property C/C++ > Language > Command Line
under Additional Options, then delete it).
A C++/WinRT quick-start
Create a new Windows Console Application (C++/WinRT) project.
Edit pch.h and main.cpp to look like this.
C++/WinRT
// pch.h
#pragma once
#include <winrt/Windows.Foundation.Collections.h>
C++/WinRT
Let's take the short code example above piece by piece, and explain what's going on in
each part.
C++/WinRT
With the default project settings, the included headers come from the Windows SDK,
inside the folder
%WindowsSdkDir%Include<WindowsTargetPlatformVersion>\cppwinrt\winrt . Visual Studio
includes that path in its IncludePath macro. But there's no strict dependency on the
#include <winrt/Windows.Web.Syndication.h>
#include <iostream>
// main.cpp
#include "pch.h"
using namespace winrt;
using namespace Windows::Foundation;
using namespace Windows::Web::Syndication;
int main()
{
 winrt::init_apartment();
 Uri rssFeedUri{ L"https://blogs.windows.com/feed" };
 SyndicationClient syndicationClient;
 syndicationClient.SetRequestHeader(L"User-Agent", L"Mozilla/5.0
(compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)");
 SyndicationFeed syndicationFeed =
syndicationClient.RetrieveFeedAsync(rssFeedUri).get();
 for (const SyndicationItem syndicationItem : syndicationFeed.Items())
 {
 winrt::hstring titleAsHstring = syndicationItem.Title().Text();
 
 // A workaround to remove the trademark symbol from the title
string, because it causes issues in this case.
 std::wstring titleAsStdWstring{ titleAsHstring.c_str() };
 titleAsStdWstring.erase(remove(titleAsStdWstring.begin(),
titleAsStdWstring.end(), L'™'), titleAsStdWstring.end());
 titleAsHstring = titleAsStdWstring;
 std::wcout << titleAsHstring.c_str() << std::endl;
 }
}
#include <winrt/Windows.Foundation.Collections.h>
#include <winrt/Windows.Web.Syndication.h>
Windows SDK, because your project (via the cppwinrt.exe tool) generates those same
headers into your project's $(GeneratedFilesDir) folder. They'll be loaded from that
folder if they can't be found elsewhere, or if you change your project settings.
The headers contain Windows APIs projected into C++/WinRT. In other words, for each
Windows type, C++/WinRT defines a C++-friendly equivalent (called the projected type).
A projected type has the same fully-qualified name as the Windows type, but it's placed
in the C++ winrt namespace. Putting these includes in your precompiled header
reduces incremental build times.
） Important
Whenever you want to use a type from a Windows namespaces, you must #include
the corresponding C++/WinRT Windows namespace header file, as shown above.
The corresponding header is the one with the same name as the type's namespace.
For example, to use the C++/WinRT projection for the
Windows::Foundation::Collections::PropertySet runtime class, include the
winrt/Windows.Foundation.Collections.h header.
It is common for a C++/WinRT projection header to automatically include related
namespace header files. For example, winrt/Windows.Foundation.Collections.h
includes winrt/Windows.Foundation.h . But you shouldn't rely on this behavior, since
it's an implementation detail that changes over time. You must explicitly include
any headers that you need.
C++/WinRT
using namespace winrt;
using namespace Windows::Foundation;
using namespace Windows::Web::Syndication;
The using namespace directives are optional, but convenient. The pattern shown above
for such directives (allowing unqualified name lookup for anything in the winrt
namespace) is suitable for when you're beginning a new project and C++/WinRT is the
only language projection you're using inside of that project. If, on the other hand, you're
mixing C++/WinRT code with C++/CX and/or SDK application binary interface (ABI)
code (you're either porting from, or interoperating with, one or both of those models),
then see the topics Interop between C++/WinRT and C++/CX, Move to C++/WinRT
from C++/CX, and Interop between C++/WinRT and the ABI.
C++/WinRT
winrt::init_apartment();
The call to winrt::init_apartment initializes the thread in the Windows Runtime; by
default, in a multithreaded apartment. The call also initializes COM.
C++/WinRT
Uri rssFeedUri{ L"https://blogs.windows.com/feed" };
SyndicationClient syndicationClient;
Stack-allocate two objects: they represent the uri of the Windows blog, and a
syndication client. We construct the uri with a simple wide string literal (see String
handling in C++/WinRT for more ways you can work with strings).
C++/WinRT
SyndicationFeed syndicationFeed =
syndicationClient.RetrieveFeedAsync(rssFeedUri).get();
SyndicationClient::RetrieveFeedAsync is an example of an asynchronous Windows
Runtime function. The code example receives an asynchronous operation object from
RetrieveFeedAsync, and it calls get on that object to block the calling thread and wait
for the result (which is a syndication feed, in this case). For more about concurrency, and
for non-blocking techniques, see Concurrency and asynchronous operations with
C++/WinRT.
C++/WinRT
for (const SyndicationItem syndicationItem : syndicationFeed.Items()) { ...
}
SyndicationFeed.Items is a range, defined by the iterators returned from begin and end
functions (or their constant, reverse, and constant-reverse variants). Because of this, you
can enumerate Items with either a range-based for statement, or with the std::for_each
template function. Whenever you iterate over a Windows Runtime collection like this,
you'll need to #include <winrt/Windows.Foundation.Collections.h> .
C++/WinRT
winrt::hstring titleAsHstring = syndicationItem.Title().Text();
// Omitted: there's a little bit of extra work here to remove the trademark
symbol from the title text.
std::wcout << titleAsHstring.c_str() << std::endl;
Gets the feed's title text, as a winrt::hstring object (more details in String handling in
C++/WinRT). The hstring is then output, via the c_str function, which reflects the pattern
used with C++ Standard Library strings.
As you can see, C++/WinRT encourages modern, and class-like, C++ expressions such
as syndicationItem.Title().Text() . This is a different, and cleaner, programming style
from traditional COM programming. You don't need to directly initialize COM, nor work
with COM pointers.
Nor do you need to handle HRESULT return codes. C++/WinRT converts error HRESULTs
to exceptions such as winrt::hresult-error for a natural and modern programming style.
For more info about error-handling, and code examples, see Error handling with
C++/WinRT.
Modify a Windows Desktop application project
to add C++/WinRT support
Some desktop projects (for example, the WinUI 3 templates in Visual Studio) have
C++/WinRT support built in.
But this section shows you how you can add C++/WinRT support to any Windows
Desktop application project that you might have. If you don't have an existing Windows
Desktop application project, then you can follow along with these steps by first creating
one. For example, open Visual Studio and create a Visual C++ > Windows Desktop >
Windows Desktop Application project.
You can optionally install the C++/WinRT Visual Studio Extension (VSIX) and the
NuGet package. For details, see Visual Studio support for C++/WinRT.
Set project properties
Go to project property General > Windows SDK Version, and select All Configurations
and All Platforms. Ensure that Windows SDK Version is set to 10.0.17134.0 (Windows
10, version 1803) or greater.
Confirm that you're not affected by Why won't my new project compile?.
Because C++/WinRT uses features from the C++17 standard, set project property
C/C++ > Language > C++ Language Standard to ISO C++17 Standard (/std:c++17).
The precompiled header
The default project template creates a precompiled header for you, named either
framework.h , or stdafx.h . Rename that to pch.h . If you have a stdafx.cpp file, then
rename that to pch.cpp . Set project property C/C++ > Precompiled Headers >
Precompiled Header to Create (/Yc), and Precompiled Header File to pch.h.
Find and replace all #include "framework.h" (or #include "stdafx.h" ) with #include
"pch.h" .
In pch.h , include winrt/base.h .
C++/WinRT
// pch.h
...
#include <winrt/base.h>
Linking
The C++/WinRT language projection depends on certain Windows Runtime free (non￾member) functions, and entry points, that require linking to the WindowsApp.lib
umbrella library. This section describes three ways of satisfying the linker.
The first option is to add to your Visual Studio project all of the C++/WinRT MSBuild
properties and targets. To do this, install the Microsoft.Windows.CppWinRT NuGet
package into your project. Open the project in Visual Studio, click Project > Manage
NuGet Packages... > Browse, type or paste Microsoft.Windows.CppWinRT in the search
box, select the item in search results, and then click Install to install the package for that
project.
You can also use project link settings to explicitly link WindowsApp.lib . Or, you can do it
in source code (in pch.h , for example) like this.
C++/WinRT
#pragma comment(lib, "windowsapp")
You can now compile and link, and add C++/WinRT code to your project (for example,
code similar to that shown in the A C++/WinRT quick-start section, above).
The three main scenarios for C++/WinRT
As you use and become familiar with C++/WinRT, and work through the rest of the
documentation here, you'll likely notice that there are three main scenarios, as described
in the following sections.
Consuming Windows APIs and types
In other words, using, or calling APIs. For example, making API calls to communicate
using Bluetooth; to stream and present video; to integrate with the Windows shell; and
so on. C++/WinRT fully and uncompromisingly supports this category of scenario. For
more info, see Consume APIs with C++/WinRT.
Authoring Windows APIs and types
In other words, producing APIs and types. For example, producing the kinds of APIs
described in the section above; or the graphics APIs; the storage and file system APIs;
the networking APIs, and so on. For more info, see Author APIs with C++/WinRT.
Authoring APIs with C++/WinRT is a little more involved than consuming them, because
you must use IDL to define the shape of the API before you can implement it. There's a
walkthrough of doing that in XAML controls; bind to a C++/WinRT property.
XAML applications
This scenario is about building applications and controls on the XAML UI framework.
Working in a XAML application amounts to a combination of consuming and authoring.
But since XAML is the dominant UI framework on Windows today, and its influence over
the Windows Runtime is proportionate to that, it deserves its own category of scenario.
Be aware that XAML works best with programming languages that offer reflection. In
C++/WinRT, you sometimes have to do a little extra work in order to interoperate with
the XAML framework. All of those cases are covered in the documentation. Good places
to start are XAML controls; bind to a C++/WinRT property and XAML custom
(templated) controls with C++/WinRT.
Sample apps written in C++/WinRT
See Where can I find C++/WinRT sample apps?.
Important APIs
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
SyndicationClient::RetrieveFeedAsync method
SyndicationFeed.Items property
winrt::hstring struct
winrt::hresult-error struct
C++/CX
Error handling with C++/WinRT
Interop between C++/WinRT and C++/CX
Interop between C++/WinRT and the ABI
Move to C++/WinRT from C++/CX
String handling in C++/WinRT
Related topics
 Yes  No
Feedback
Was this page helpful?
Get help at Microsoft Q&A
Get Started with Win32 and C++
Article • 01/27/2022
The aim of this Get Started series is to teach you how to write a desktop program in
C++ using Win32 and COM APIs.
In the first module, you'll learn step-by-step how to create and show a window. Later
modules will introduce the Component Object Model (COM), graphics and text, and
user input.
For this series, it is assumed that you have a good working knowledge of C++
programming. No previous experience with Windows programming is assumed. If you
are new to C++, learning material is available in the C++ language documentation .
Topic Description
Intro to Win32
programming in C++
This section describes some of the basic terminology and coding
conventions used in Windows programming.
Module 1. Your First
Windows Program
In this module, you will create a simple Windows program that
shows a blank window.
Module 2. Using COM in
Your Windows Program
This module introduces the Component Object Model (COM),
which underlies many of the modern Windows APIs.
Module 3. Windows
Graphics
This module introduces the Windows graphics architecture, with a
focus on Direct2D.
Module 4. User Input This module describes mouse and keyboard input.
Sample Code Contains links to download the sample code for this series.
In this section
ﾂ Yes ﾄ No
Creating an MFC Application
Article • 02/14/2023
An MFC application is an executable application for Windows that is based on the
Microsoft Foundation Class (MFC) Library. MFC executables generally fall into five types:
standard Windows applications, dialog boxes, forms-based applications, Explorer-style
applications, and Web browser-style applications. For more information, see:
Using the Classes to Write Windows Applications
Creating and Displaying Dialog Boxes
Creating a Forms-Based MFC Application
Creating a File Explorer-Style MFC Application
Creating a Web Browser-Style MFC Application
The MFC Application Wizard generates the appropriate classes and files for any of these
types of applications, depending on the options you select in the wizard.
The easiest way to create an MFC application is to use the MFC Application Wizard (MFC
App project in Visual Studio 2019). To create an MFC console application (a command￾line program that uses MFC libraries but runs in the console window), use the Windows
Desktop Wizard and choose the Console Application and MFC Headers options.
To create an MFC forms or dialog-based
application
1. From the main menu, choose File > New > Project.
2. Enter "MFC" into the search box and then choose MFC App from the result list.
3. Modify the defaults as needed, then press Create to open the MFC Application
Wizard.
4. Modify the configuration values as needed, then press Finish.
For more information, see Creating a forms-based MFC application.
To create an MFC console application
An MFC console application is a command-line program that uses MFC libraries but
runs in the console window.
1. From the main menu, choose File > New > Project.
2. Enter "Desktop" into the search box and then choose Windows Desktop Wizard
from the result list, then press Next.
3. Modify the project name and location as needed, then press Create to open the
Windows Desktop Wizard.
4. Check the MFC Headers box and set other values as needed, then press OK.
Once your project is created, you can view the files created in Solution Explorer. For
more information about the files the wizard creates for your project, see the project￾generated file ReadMe.txt. For more information about the file types, see File Types
Created for Visual Studio C++ projects.
See also
Adding Functionality with Code Wizards
Property Pages
Walkthrough: Create and use your own
Dynamic Link Library (C++)
Article • 12/10/2021
This step-by-step walkthrough shows how to use the Visual Studio IDE to create your
own dynamic link library (DLL) written in Microsoft C++ (MSVC). Then it shows how to
use the DLL from another C++ app. DLLs (also known as shared libraries in UNIX-based
operating systems) are one of the most useful kinds of Windows components. You can
use them as a way to share code and resources, and to shrink the size of your apps.
DLLs can even make it easier to service and extend your apps.
In this walkthrough, you'll create a DLL that implements some math functions. Then
you'll create a console app that uses the functions from the DLL. You'll also get an
introduction to some of the programming techniques and conventions used in Windows
DLLs.
This walkthrough covers these tasks:
Create a DLL project in Visual Studio.
Add exported functions and variables to the DLL.
Create a console app project in Visual Studio.
Use the functions and variables imported from the DLL in the console app.
Run the completed app.
Like a statically linked library, a DLL exports variables, functions, and resources by name.
A client app imports the names to use those variables, functions, and resources. Unlike a
statically linked library, Windows connects the imports in your app to the exports in a
DLL at load time or at run time, instead of connecting them at link time. Windows
requires extra information that isn't part of the standard C++ compilation model to
make these connections. The MSVC compiler implements some Microsoft-specific
extensions to C++ to provide this extra information. We explain these extensions as we
go.
This walkthrough creates two Visual Studio solutions; one that builds the DLL, and one
that builds the client app. The DLL uses the C calling convention. It can be called from
apps written in other programming languages, as long as the platform, calling
conventions, and linking conventions match. The client app uses implicit linking, where
Windows links the app to the DLL at load-time. This linking lets the app call the DLL￾supplied functions just like the functions in a statically linked library.
This walkthrough doesn't cover some common situations. The code doesn't show the
use of C++ DLLs by other programming languages. It doesn't show how to create a
resource-only DLL, or how to use explicit linking to load DLLs at run-time rather than at
load-time. Rest assured, you can use MSVC and Visual Studio to do all these things.
Even though the code of the DLL is written in C++, we've used C-style interfaces for the
exported functions. There are two main reasons for this: First, many other languages
support imports of C-style functions. The client app doesn't have to be written in C++.
Second, it avoids some common pitfalls related to exported classes and member
functions. It's easy to make hard-to-diagnose errors when exporting classes, since
everything referred to within a class declaration has to have an instantiation that's also
exported. This restriction applies to DLLs, but not static libraries. If your classes are plain￾old-data style, you shouldn't run into this issue.
For links to more information about DLLs, see Create C/C++ DLLs in Visual Studio. For
more information about implicit linking and explicit linking, see Determine which linking
method to use. For information about creating C++ DLLs for use with programming
languages that use C-language linkage conventions, see Exporting C++ functions for
use in C-language executables. For information about how to create DLLs for use with
.NET languages, see Calling DLL Functions from Visual Basic Applications.
Prerequisites
A computer that runs Microsoft Windows 7 or later versions. We recommend the
latest version of Windows for the best development experience.
A copy of Visual Studio. For information on how to download and install Visual
Studio, see Install Visual Studio. When you run the installer, make sure that the
Desktop development with C++ workload is checked. Don't worry if you didn't
install this workload when you installed Visual Studio. You can run the installer
again and install it now.
An understanding of the basics of using the Visual Studio IDE. If you've used
Windows desktop apps before, you can probably keep up. For an introduction, see
Visual Studio IDE feature tour.
An understanding of enough of the fundamentals of the C++ language to follow
along. Don't worry, we don't do anything too complicated.
Create the DLL project
In this set of tasks, you create a project for your DLL, add code, and build it. To begin,
start the Visual Studio IDE, and sign in if you need to. The instructions vary slightly
depending on which version of Visual Studio you're using. Make sure you have the
correct version selected in the control in the upper left of this page.
To create a DLL project in Visual Studio 2019
1. On the menu bar, choose File > New > Project to open the Create a New Project
dialog box.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Library.
3. From the filtered list of project types, select Dynamic-link Library (DLL), and then
choose Next.
4. In the Configure your new project page, enter MathLibrary in the Project name
box to specify a name for the project. Leave the default Location and Solution
name values. Set Solution to Create new solution. Uncheck Place solution and
project in the same directory if it's checked.
5. Choose the Create button to create the project.
When the solution is created, you can see the generated project and source files in the
Solution Explorer window in Visual Studio.
Right now, this DLL doesn't do very much. Next, you'll create a header file to declare the
functions your DLL exports, and then add the function definitions to the DLL to make it
more useful.
To add a header file to the DLL
1. To create a header file for your functions, on the menu bar, choose Project > Add
New Item.
2. In the Add New Item dialog box, in the left pane, select Visual C++. In the center
pane, select Header File (.h). Specify MathLibrary.h as the name for the header file.
3. Choose the Add button to generate a blank header file, which is displayed in a new
editor window.
4. Replace the contents of the header file with this code:
C++
// MathLibrary.h - Contains declarations of math functions
#pragma once
#ifdef MATHLIBRARY_EXPORTS
#define MATHLIBRARY_API __declspec(dllexport)
#else
#define MATHLIBRARY_API __declspec(dllimport)
#endif
// The Fibonacci recurrence relation describes a sequence F
// where F(n) is { n = 0, a
// { n = 1, b
This header file declares some functions to produce a generalized Fibonacci sequence,
given two initial values. A call to fibonacci_init(1, 1) generates the familiar Fibonacci
number sequence.
Notice the preprocessor statements at the top of the file. The new project template for a
DLL project adds <PROJECTNAME>_EXPORTS to the defined preprocessor macros. In this
example, Visual Studio defines MATHLIBRARY_EXPORTS when your MathLibrary DLL project
is built.
When the MATHLIBRARY_EXPORTS macro is defined, the MATHLIBRARY_API macro sets the
__declspec(dllexport) modifier on the function declarations. This modifier tells the
compiler and linker to export a function or variable from the DLL for use by other
applications. When MATHLIBRARY_EXPORTS is undefined, for example, when the header file
is included by a client application, MATHLIBRARY_API applies the __declspec(dllimport)
modifier to the declarations. This modifier optimizes the import of the function or
variable in an application. For more information, see dllexport, dllimport.
1. In Solution Explorer, right-click on the Source Files node and choose Add > New
Item. Create a new .cpp file called MathLibrary.cpp, in the same way that you
added a new header file in the previous step.
// { n > 1, F(n-2) + F(n-1)
// for some initial integral values a and b.
// If the sequence is initialized F(0) = 1, F(1) = 1,
// then this relation produces the well-known Fibonacci
// sequence: 1, 1, 2, 3, 5, 8, 13, 21, 34, ...
// Initialize a Fibonacci relation sequence
// such that F(0) = a, F(1) = b.
// This function must be called before any other function.
extern "C" MATHLIBRARY_API void fibonacci_init(
 const unsigned long long a, const unsigned long long b);
// Produce the next value in the sequence.
// Returns true on success and updates current value and index;
// false on overflow, leaves current value and index unchanged.
extern "C" MATHLIBRARY_API bool fibonacci_next();
// Get the current value in the sequence.
extern "C" MATHLIBRARY_API unsigned long long fibonacci_current();
// Get the position of the current value in the sequence.
extern "C" MATHLIBRARY_API unsigned fibonacci_index();
To add an implementation to the DLL
2. In the editor window, select the tab for MathLibrary.cpp if it's already open. If not,
in Solution Explorer, double-click MathLibrary.cpp in the Source Files folder of the
MathLibrary project to open it.
3. In the editor, replace the contents of the MathLibrary.cpp file with the following
code:
C++
// MathLibrary.cpp : Defines the exported functions for the DLL.
#include "pch.h" // use stdafx.h in Visual Studio 2017 and earlier
#include <utility>
#include <limits.h>
#include "MathLibrary.h"
// DLL internal state variables:
static unsigned long long previous_; // Previous value, if any
static unsigned long long current_; // Current sequence value
static unsigned index_; // Current seq. position
// Initialize a Fibonacci relation sequence
// such that F(0) = a, F(1) = b.
// This function must be called before any other function.
void fibonacci_init(
 const unsigned long long a,
 const unsigned long long b)
{
 index_ = 0;
 current_ = a;
 previous_ = b; // see special case when initialized
}
// Produce the next value in the sequence.
// Returns true on success, false on overflow.
bool fibonacci_next()
{
 // check to see if we'd overflow result or position
 if ((ULLONG_MAX - previous_ < current_) ||
 (UINT_MAX == index_))
 {
 return false;
 }
 // Special case when index == 0, just return b value
 if (index_ > 0)
 {
 // otherwise, calculate next sequence value
 previous_ += current_;
 }
 std::swap(current_, previous_);
 ++index_;
 return true;
}
To verify that everything works so far, compile the dynamic link library. To compile,
choose Build > Build Solution on the menu bar. The DLL and related compiler output
are placed in a folder called Debug directly below the solution folder. If you create a
Release build, the output is placed in a folder called Release. The output should look
something like this:
Output
Congratulations, you've created a DLL using Visual Studio! Next, you'll create a client
app that uses the functions exported by the DLL.
When you create a DLL, think about how client apps may use it. To call the functions or
access the data exported by a DLL, client source code must have the declarations
available at compile time. At link time, the linker requires information to resolve the
function calls or data accesses. A DLL supplies this information in an import library, a file
that contains information about how to find the functions and data, instead of the actual
code. And at run time, the DLL must be available to the client, in a location that the
operating system can find.
// Get the current value in the sequence.
unsigned long long fibonacci_current()
{
 return current_;
}
// Get the current index position in the sequence.
unsigned fibonacci_index()
{
 return index_;
}
1>------ Build started: Project: MathLibrary, Configuration: Debug Win32 ---
---
1>pch.cpp
1>dllmain.cpp
1>MathLibrary.cpp
1>Generating Code...
1> Creating library
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.lib and object
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.exp
1>MathLibrary.vcxproj ->
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.dll
========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========
Create a client app that uses the DLL
Whether it's your own or from a third-party, your client app project needs several pieces
of information to use a DLL. It needs to find the headers that declare the DLL exports,
the import libraries for the linker, and the DLL itself. One solution is to copy all of these
files into your client project. For third-party DLLs that are unlikely to change while your
client is in development, this method may be the best way to use them. However, when
you also build the DLL, it's better to avoid duplication. If you make a local copy of DLL
files that are under development, you may accidentally change a header file in one copy
but not the other, or use an out-of-date library.
To avoid out-of-sync code, we recommend you set the include path in your client
project to include the DLL header files directly from your DLL project. Also, set the
library path in your client project to include the DLL import libraries from the DLL
project. And finally, copy the built DLL from the DLL project into your client build output
directory. This step allows your client app to use the same DLL code you build.
To create a client app in Visual Studio
1. On the menu bar, choose File > New > Project to open the Create a new project
dialog box.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Console.
3. From the filtered list of project types, choose Console App then choose Next.
4. In the Configure your new project page, enter MathClient in the Project name box
to specify a name for the project. Leave the default Location and Solution name
values. Set Solution to Create new solution. Uncheck Place solution and project in
the same directory if it's checked.
5. Choose the Create button to create the client project.
A minimal console application project is created for you. The name for the main source
file is the same as the project name that you entered earlier. In this example, it's named
MathClient.cpp. You can build it, but it doesn't use your DLL yet.
Next, to call the MathLibrary functions in your source code, your project must include
the MathLibrary.h file. You could copy this header file into your client app project, then
add it to the project as an existing item. This method can be a good choice for third￾party libraries. However, if you're working on the code for your DLL and your client at
the same time, the header files could get out of sync. To avoid this issue, set the
Additional Include Directories path in your project to include the path to the original
header.
To add the DLL header to your include path
1. Right-click on the MathClient node in Solution Explorer to open the Property
Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it's not already
selected.
3. In the left pane, select Configuration Properties > C/C++ > General.
4. In the property pane, select the drop-down control next to the Additional Include
Directories edit box, and then choose Edit.
5. Double-click in the top pane of the Additional Include Directories dialog box to
enable an edit control. Or, choose the folder icon to create a new entry.
6. In the edit control, specify the path to the location of the MathLibrary.h header
file. You can choose the ellipsis (...) control to browse to the correct folder.
You can also enter a relative path from your client source files to the folder that
contains the DLL header files. If you followed the directions to put your client
project in a separate solution from the DLL, the relative path should look like this:
..\..\MathLibrary\MathLibrary
If your DLL and client projects are in the same solution, the relative path might
look like this:
..\MathLibrary
When the DLL and client projects are in other folders, adjust the relative path to
match. Or, use the ellipsis control to browse for the folder.
7. After you've entered the path to the header file in the Additional Include
Directories dialog box, choose the OK button. In the Property Pages dialog box,
choose the OK button to save your changes.
You can now include the MathLibrary.h file and use the functions it declares in your
client application. Replace the contents of MathClient.cpp by using this code:
C++
This code can be compiled, but not linked. If you build the client app now, the error list
shows several LNK2019 errors. That's because your project is missing some information:
You haven't specified that your project has a dependency on the MathLibrary.lib library
yet. And, you haven't told the linker how to find the MathLibrary.lib file.
To fix this issue, you could copy the library file directly into your client app project. The
linker would find and use it automatically. However, if both the library and the client app
are under development, that might lead to changes in one copy that aren't shown in the
other. To avoid this issue, you can set the Additional Dependencies property to tell the
build system that your project depends on MathLibrary.lib. And, you can set an
Additional Library Directories path in your project to include the path to the original
library when you link.
1. Right-click on the MathClient node in Solution Explorer and choose Properties to
open the Property Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it's not already
selected. It ensures that any property changes apply to both Debug and Release
builds.
3. In the left pane, select Configuration Properties > Linker > Input. In the property
pane, select the drop-down control next to the Additional Dependencies edit box,
and then choose Edit.
// MathClient.cpp : Client app for MathLibrary DLL.
// #include "pch.h" Uncomment for Visual Studio 2017 and earlier
#include <iostream>
#include "MathLibrary.h"
int main()
{
 // Initialize a Fibonacci relation sequence.
 fibonacci_init(1, 1);
 // Write out the sequence values until overflow.
 do {
 std::cout << fibonacci_index() << ": "
 << fibonacci_current() << std::endl;
 } while (fibonacci_next());
 // Report count of values written before overflow.
 std::cout << fibonacci_index() + 1 <<
 " Fibonacci sequence values fit in an " <<
 "unsigned 64-bit integer." << std::endl;
}
To add the DLL import library to your project
4. In the Additional Dependencies dialog, add MathLibrary.lib to the list in the top
edit control.
5. Choose OK to go back to the Property Pages dialog box.
6. In the left pane, select Configuration Properties > Linker > General. In the
property pane, select the drop-down control next to the Additional Library
Directories edit box, and then choose Edit.
7. Double-click in the top pane of the Additional Library Directories dialog box to
enable an edit control. In the edit control, specify the path to the location of the
MathLibrary.lib file. By default, it's in a folder called Debug directly under the DLL
solution folder. If you create a release build, the file is placed in a folder called
Release. You can use the $(IntDir) macro so that the linker can find your DLL, no
matter which kind of build you create. If you followed the directions to put your
client project in a separate solution from the DLL project, the relative path should
look like this:
..\..\MathLibrary\$(IntDir)
If your DLL and client projects are in other locations, adjust the relative path to
match.
8. Once you've entered the path to the library file in the Additional Library
Directories dialog box, choose the OK button to go back to the Property Pages
dialog box. Choose OK to save the property changes.
Your client app can now compile and link successfully, but it still doesn't have everything
it needs to run. When the operating system loads your app, it looks for the MathLibrary
DLL. If it can't find the DLL in certain system directories, the environment path, or the
local app directory, the load fails. Depending on the operating system, you'll see an
error message like this:
One way to avoid this issue is to copy the DLL to the directory that contains your client
executable as part of the build process. You can add a Post-Build Event to your project,
to add a command that copies the DLL to your build output directory. The command
specified here copies the DLL only if it's missing or has changed. It uses macros to copy
to and from the Debug or Release locations, based on your build configuration.
To copy the DLL in a post-build event
1. Right-click on the MathClient node in Solution Explorer and choose Properties to
open the Property Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it isn't already
selected.
3. In the left pane, select Configuration Properties > Build Events > Post-Build
Event.
4. In the property pane, select the edit control in the Command Line field. If you
followed the directions to put your client project in a separate solution from the
DLL project, then enter this command:
xcopy /y /d "..\..\MathLibrary\$(IntDir)MathLibrary.dll" "$(OutDir)"
If your DLL and client projects are in other directories, change the relative path to
the DLL to match.
5. Choose the OK button to save your changes to the project properties.
Now your client app has everything it needs to build and run. Build the application by
choosing Build > Build Solution on the menu bar. The Output window in Visual Studio
should have something like the following example depending on your version of Visual
Studio:
Output
1>------ Build started: Project: MathClient, Configuration: Debug Win32 ----
--
1>MathClient.cpp
1>MathClient.vcxproj ->
C:\Users\username\Source\Repos\MathClient\Debug\MathClient.exe
1>1 File(s) copied
========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========
Congratulations, you've created an application that calls functions in your DLL. Now run
your application to see what it does. On the menu bar, choose Debug > Start Without
Debugging. Visual Studio opens a command window for the program to run in. The last
part of the output should look like:
Press any key to dismiss the command window.
Now that you've created a DLL and a client application, you can experiment. Try setting
breakpoints in the code of the client app, and run the app in the debugger. See what
happens when you step into a library call. Add other functions to the library, or write
another client app that uses your DLL.
When you deploy your app, you must also deploy the DLLs it uses. The simplest way to
make the DLLs that you build, or that you include from third parties, available is to put
them in the same directory as your app. It's known as app-local deployment. For more
information about deployment, see Deployment in Visual C++.
See also
Calling DLL Functions from Visual Basic Applications
Walkthrough: Create and use a static
library
Article • 10/29/2021
This step-by-step walkthrough shows how to create a static library (.lib file) for use with
C++ apps. Using a static library is a great way to reuse code. Rather than
reimplementing the same routines in every app that requires the functionality, you write
them one time in a static library and then reference it from the apps. Code linked from a
static library becomes part of your app—you don't have to install another file to use the
code.
This walkthrough covers these tasks:
Create a static library project
Add a class to the static library
Create a C++ console app that references the static library
Use the functionality from the static library in the app
Run the app
Prerequisites
An understanding of the fundamentals of the C++ language.
Create a static library project
The instructions for how to create the project vary depending on your version of Visual
Studio. To see the documentation for your preferred version of Visual Studio, use the
Version selector control. It's found at the top of the table of contents on this page.
To create a static library project in Visual Studio
1. On the menu bar, choose File > New > Project to open the Create a New Project
dialog.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Library.
3. From the filtered list of project types, select Windows Desktop Wizard, then
choose Next.
4. In the Configure your new project page, enter MathLibrary in the Project name
box to specify a name for the project. Enter StaticMath in the Solution name box.
Choose the Create button to open the Windows Desktop Project dialog.
5. In the Windows Desktop Project dialog, under Application type, select Static
Library (.lib).
6. Under Additional options, uncheck the Precompiled header check box if it's
checked. Check the Empty project box.
7. Choose OK to create the project.
1. To create a header file for a new class, right-click to open the shortcut menu for
the MathLibrary project in Solution Explorer, and then choose Add > New Item.
2. In the Add New Item dialog box, select Visual C++ > Code. In the center pane,
select Header File (.h). Specify a name for the header file—for example,
MathLibrary.h—and then choose the Add button. A nearly blank header file is
displayed.
3. Add a declaration for a class named Arithmetic to do common mathematical
operations such as addition, subtraction, multiplication, and division. The code
should resemble:
C++
Add a class to the static library
To add a class to the static library
// MathLibrary.h
#pragma once
namespace MathLibrary
{
 class Arithmetic
 {
 public:
 // Returns a + b
 static double Add(double a, double b);
 // Returns a - b
 static double Subtract(double a, double b);
4. To create a source file for the new class, open the shortcut menu for the
MathLibrary project in Solution Explorer, and then choose Add > New Item.
5. In the Add New Item dialog box, in the center pane, select C++ File (.cpp). Specify
a name for the source file—for example, MathLibrary.cpp—and then choose the
Add button. A blank source file is displayed.
6. Use this source file to implement the functionality for class Arithmetic . The code
should resemble:
C++
 // Returns a * b
 static double Multiply(double a, double b);
 // Returns a / b
 static double Divide(double a, double b);
 };
}
// MathLibrary.cpp
// compile with: cl /c /EHsc MathLibrary.cpp
// post-build command: lib MathLibrary.obj
#include "MathLibrary.h"
namespace MathLibrary
{
 double Arithmetic::Add(double a, double b)
 {
 return a + b;
 }
 double Arithmetic::Subtract(double a, double b)
 {
 return a - b;
 }
 double Arithmetic::Multiply(double a, double b)
 {
 return a * b;
 }
 double Arithmetic::Divide(double a, double b)
 {
 return a / b;
 }
}
7. To build the static library, select Build > Build Solution on the menu bar. The build
creates a static library, MathLibrary.lib, that can be used by other programs.
７ Note
When you build on the Visual Studio command line, you must build the
program in two steps. First, run cl /c /EHsc MathLibrary.cpp to compile the
code and create an object file that's named MathLibrary.obj. (The cl
command invokes the compiler, Cl.exe, and the /c option specifies compile
without linking. For more information, see /c (Compile Without Linking).)
Second, run lib MathLibrary.obj to link the code and create the static library
MathLibrary.lib. (The lib command invokes the Library Manager, Lib.exe. For
more information, see LIB Reference.)
Create a C++ console app that references the
static library
To create a C++ console app that references the static
library in Visual Studio
1. In Solution Explorer, right-click on the top node, Solution 'StaticMath', to open
the shortcut menu. Choose Add > New Project to open the Add a New Project
dialog.
2. At the top of the dialog, set the Project type filter to Console.
3. From the filtered list of project types, choose Console App then choose Next. In
the next page, enter MathClient in the Name box to specify a name for the project.
4. Choose the Create button to create the client project.
5. After you create a console app, an empty program is created for you. The name for
the source file is the same as the name that you chose earlier. In the example, it's
named MathClient.cpp .
Use the functionality from the static library in
the app
To use the functionality from the static library in the app
1. Before you can use the math routines in the static library, you must reference it.
Open the shortcut menu for the MathClient project in Solution Explorer, and then
choose Add > Reference.
2. The Add Reference dialog box lists the libraries that you can reference. The
Projects tab lists the projects in the current solution and any libraries they
reference. Open the Projects tab, select the MathLibrary check box, and then
choose the OK button.
3. To reference the MathLibrary.h header file, you must modify the included
directories path. In Solution Explorer, right-click on MathClient to open the
shortcut menu. Choose Properties to open the MathClient Property Pages dialog
box.
4. In the MathClient Property Pages dialog box, set the Configuration drop-down to
All Configurations. Set the Platform drop-down to All Platforms.
5. Select the Configuration Properties > C/C++ > General property page. In the
Additional Include Directories property, specify the path of the MathLibrary
directory, or browse for it.
To browse for the directory path:
a. Open the Additional Include Directories property value drop-down list, and
then choose Edit.
b. In the Additional Include Directories dialog box, double-click in the top of the
text box. Then choose the ellipsis button (...) at the end of the line.
c. In the Select Directory dialog box, navigate up a level, and then select the
MathLibrary directory. Then choose the Select Folder button to save your
selection.
d. In the Additional Include Directories dialog box, choose the OK button.
e. In the Property Pages dialog box, choose the OK button to save your changes
to the project.
6. You can now use the Arithmetic class in this app by including the #include
"MathLibrary.h" header in your code. Replace the contents of MathClient.cpp with
this code:
C++
7. To build the executable, choose Build > Build Solution on the menu bar.
1. Make sure that MathClient is selected as the default project. To select it, right-click
to open the shortcut menu for MathClient in Solution Explorer, and then choose
Set as StartUp Project.
2. To run the project, on the menu bar, choose Debug > Start Without Debugging.
The output should resemble:
Output
// MathClient.cpp
// compile with: cl /EHsc MathClient.cpp /link MathLibrary.lib
#include <iostream>
#include "MathLibrary.h"
int main()
{
 double a = 7.4;
 int b = 99;
 std::cout << "a + b = " <<
 MathLibrary::Arithmetic::Add(a, b) << std::endl;
 std::cout << "a - b = " <<
 MathLibrary::Arithmetic::Subtract(a, b) << std::endl;
 std::cout << "a * b = " <<
 MathLibrary::Arithmetic::Multiply(a, b) << std::endl;
 std::cout << "a / b = " <<
 MathLibrary::Arithmetic::Divide(a, b) << std::endl;
 return 0;
}
Run the app
To run the app
a + b = 106.4
a - b = -91.6
a * b = 732.6
a / b = 0.0747475
See also
Walkthrough: Creating and Using a Dynamic Link Library (C++)
Desktop Applications (Visual C++)
Walkthrough: Compile a C++/CLI
program that targets the CLR in Visual
Studio
Article • 10/29/2021
By using C++/CLI you can create C++ programs that use .NET classes as well as native
C++ types. C++/CLI is intended for use in console applications and in DLLs that wrap
native C++ code and make it accessible from .NET programs. To create a Windows user
interface based on .NET, use C# or Visual Basic.
For this procedure, you can type your own C++ program or use one of the sample
programs. The sample program that we use in this procedure creates a text file named
textfile.txt, and saves it to the project directory.
Prerequisites
An understanding of the fundamentals of the C++ language.
In Visual Studio 2017 and later, C++/CLI support is an optional component. To
install it, open the Visual Studio Installer from the Windows Start menu. Make sure
that the Desktop development with C++ tile is checked, and in the Optional
components section, also check C++/CLI Support.
Create a new project
The following steps vary depending on which version of Visual Studio you are using. To
see the documentation for your preferred version of Visual Studio, use the Version
selector control. It's found at the top of the table of contents on this page.
To create a C++/CLI project in Visual Studio
1. In Solution Explorer, right-click on the top to open the Create a New Project
dialog box.
2. At the top of the dialog, type CLR in the search box and then choose CLR Empty
Project from the results list.
3. Choose the Create button to create the project.
Add a source file
1. If Solution Explorer isn't visible, click Solution Explorer on the View menu.
2. Add a new source file to the project:
Right-click the Source Files folder in Solution Explorer, point to Add, and
click New Item.
Click C++ File (.cpp) and type a file name and then click Add.
The .cpp file appears in the Source Files folder in Solution Explorer and a tabbed
window appears where you type the code you want in that file.
3. Click in the newly created tab in Visual Studio and type a valid Visual C++
program, or copy and paste one of the sample programs.
For example, you can use the How to: Write a Text File (C++/CLI) sample program
(in the File Handling and I/O node of the Programming Guide).
If you use the sample program, notice that you use the gcnew keyword instead of
new when creating a .NET object, and that gcnew returns a handle ( ^ ) rather than a
pointer ( * ):
StreamWriter^ sw = gcnew StreamWriter(fileName);
For more information on C++/CLI syntax, see Component Extensions for Runtime
Platforms.
4. On the Build menu, click Build Solution.
The Output window displays information about the compilation progress, such as
the location of the build log and a message that indicates the build status.
If you make changes and run the program without doing a build, a dialog box
might indicate that the project is out of date. Select the checkbox on this dialog
before you click OK if you want Visual Studio to always use the current versions of
files instead of prompting you each time it builds the application.
5. On the Debug menu, click Start without Debugging.
6. If you used the sample program, when you run the program a command window is
displayed that indicates the text file has been created.
The textfile.txt text file is now located in your project directory. You can open this
file by using Notepad.
７ Note
Choosing the empty CLR project template automatically set the /clr
compiler option. To verify this, right-click the project in Solution Explorer and
clicking Properties, and then check the Common Language Runtime support
option in the General node of Configuration Properties.
See also
C++ Language Reference
Projects and build systems
Create a simple Universal Windows
Platform (UWP) game with DirectX
Article • 10/20/2022
In this set of tutorials, you'll learn how to use DirectX and C++/WinRT to create the basic
Universal Windows Platform (UWP) sample game named Simple3DGameDX. The
gameplay takes place in a simple first-person 3D shooting gallery.
７ Note
The link from which you can download the Simple3DGameDX sample game itself is
Direct3D sample game. The C++/WinRT source code is in the folder named
cppwinrt . For info about other UWP sample apps, see Sample applications for
Windows development.
These tutorials cover all of the major parts of a game, including the processes for
loading assets such as arts and meshes, creating a main game loop, implementing a
simple rendering pipeline, and adding sound and controls.
You'll also see UWP game development techniques and considerations. We'll focus on
key UWP DirectX game development concepts, and call out Windows-Runtime-specific
considerations around those concepts.
Objective
To learn about the basic concepts and components of a UWP DirectX game, and to
become more comfortable designing UWP games with DirectX.
What you need to know
For this tutorial, you need to be familiar with these subjects.
C++/WinRT. C++/WinRT is a standard modern C++17 language projection for
Windows APIs, implemented as a header-file-based library, and designed to
provide you with first-class access to the modern Windows APIs.
Basic linear algebra and Newtonian physics concepts.
Basic graphics programming terminology.
Basic Windows programming concepts.
Basic familiarity with the Direct2D and Direct3D 11 APIs.
The Simple3DGameDX sample game implements a simple first-person 3D shooting
gallery, where the player fires balls at moving targets. Hitting each target awards a set
number of points, and the player can progress through 6 levels of increasing challenge.
At the end of the levels, the points are tallied, and the player is awarded a final score.
The sample demonstrates these game concepts.
Interoperation between DirectX 11.1 and the Windows Runtime
A first-person 3D perspective and camera
Stereoscopic 3D effects
Collision-detection between objects in 3D
Handling player input for mouse, touch, and Xbox controller controls
Audio mixing and playback
A basic game state-machine
Topic Description
Set up the
game project
The first step in developing your game is to set up a project in Microsoft Visual
Studio. After you've configured a project specifically for game development, you
could later re-use it as a kind of template.
Define the
game's UWP
app framework
The first step in coding a Universal Windows Platform (UWP) game is building
the framework that lets the app object interact with Windows.
Game flow
management
Define the high-level state machine to enable player and system interaction.
Learn how UI interacts with the overall game's state machine and how to create
event handlers for UWP games.
Direct3D UWP shooting gallery sample
Topic Description
Define the
main game
object
Now, we look at the details of the sample game's main object and how the rules
it implements translate into interactions with the game world.
Rendering
framework I:
Intro to
rendering
Learn how to develop the rendering pipeline to display graphics. Intro to
rendering.
Rendering
framework II:
Game
rendering
Learn how to assemble the rendering pipeline to display graphics. Game
rendering, set up and prepare data.
Add a user
interface
Learn how to add a 2D user interface overlay to a DirectX UWP game.
Add controls Now, we take a look at how the sample game implements move-look controls
in a 3-D game, and how to develop basic touch, mouse, and game controller
controls.
Add sound Develop a simple sound engine using XAudio2 APIs to playback game music
and sound effects.
Extend the
sample game
Learn how to implement a XAML overlay for a UWP DirectX game.
Tutorial: Open a project from a repo
Article • 12/19/2024
In this tutorial, you use Visual Studio to connect to a repository, or repo, for the first
time, clone it, and then open a project from it.
In this tutorial, you learn how to:
＂ Open a project from a GitHub repo
＂ Browse to an Azure DevOps repo
Prerequisites
If you don't have Visual Studio yet, go to Visual Studio downloads to install it for
free.
Open a project from a GitHub repo
Visual Studio makes it easy to open a project from a repo. You can do so when you start
Visual Studio, or you can do so directly from within the Visual Studio IDE.
Here's how.
Use the start window
1. Open Visual Studio.
2. On the start window, select Clone a repository.

3. Enter or type the repository location, and then select Clone.

4. If you're not already signed in, you might be prompted to sign into Visual Studio
or your GitHub account.
 Tip
For more information about signing in to Visual Studio, see Sign in or switch
Visual Studio user accounts. For specific information about how to use your
GitHub account to sign in, see Add your GitHub accounts to your Visual
Studio keychain. You might receive a trust notification. For more information,
see Configure trust settings for files and folders.
View files in Solution Explorer
Visual Studio loads the solutions from the repository by using the Folder View in
Solution Explorer.
You can view a solution in Solution View by double-clicking its .sln file.
You can select Switch Views to switch between folder view and solution view.
 Tip
You can change from the default Folder View to Solution View from the Git menu.
Select Settings > Source Control > Git Global Settings > Automatically load the
solution when opening a Git repository.
Open a project locally from a previously cloned GitHub repo
1. Open Visual Studio.
2. On the start window, select Open a project or solution.
Visual Studio opens an instance of File Explorer, where you can browse to your
solution or project, and then select it to open it.
 Tip
If you opened the project or solution recently, select it from the Open recent
section.
Start coding!
Use the IDE
You can also use the Git menu or the Select Repository control in the Visual Studio IDE
to interact with a repository's folders and files.
Here's how.
To clone a repo and open a project
1. In the Visual Studio IDE, select the Git menu, and then select Clone Repository.
2. Follow the prompts to connect to the Git repository that includes the files that
you're looking for.
To open local folders and files
1. In the Visual Studio IDE, select the Git menu, select Local Repositories, and then
select Open Local Repository.
2. Follow the prompts to connect to the Git repository that has the files that you're
looking for.
Browse to an Azure DevOps repo
Here's how to browse to and clone an Azure DevOps repo by using Visual Studio.
1. Open Visual Studio.
2. On the start window, select Clone a repository.

3. In the Browse a repository section, select Azure DevOps.
4. Follow the prompts to clone an Azure DevOps repo that includes the files that
you're looking for, and then open your project.
Related content
Feel free to dive into any of the following language-specific tutorials:
Feedback
Was this page helpful?
Provide product feedback | Ask the community
Visual Studio tutorials | C#
Visual Studio tutorials | Visual Basic
Visual Studio tutorials | C++
Visual Studio tutorials | Python
Visual Studio tutorials | JavaScript, TypeScript, and Node.js
For more information, see:
About Git in Visual Studio
Brpwse a repo
Manage a repo
 Yes  No
Learn to use the code editor
Article • 01/24/2025
In this 10-minute introduction to the code editor in Visual Studio, we'll add code to a file
to look at some of the ways that Visual Studio makes writing, navigating, and
understanding code easier.
If you haven't already installed Visual Studio, go to the Visual Studio downloads page
to install it for free.
This article assumes you're already familiar with a programming language. If you aren't,
we suggest you look at one of the programming quickstarts first, such as create a web
app with Python or C#, or create a console app with Visual Basic or C++.
 Tip
To follow along with this article, make sure you have the C# settings selected for
Visual Studio. For information about selecting settings for the integrated
development environment (IDE), see Select environment settings.
Create a new code file
Start by creating a new file and adding some code to it.
1. Open Visual Studio. Select the Esc key, or select Continue without code on the
start window, to open the development environment.
2. From the File menu on the menu bar, select New > File, or select the Ctrl+N keys.
3. In the New File dialog box, under the General category, select C# Class, and then
select Open.
A new file opens in the editor with the skeleton of a C# class.
Use GitHub Copilot
GitHub Copilot acts as an AI pair programmer to provide autocomplete-style code
completions and context-aware multi-line code suggestions, as you code, in real-time,
right in the editor. GitHub Copilot turns natural language prompts including comments
and method names into coding suggestions. You can view and incorporate suggestions
from GitHub Copilot directly within the editor.
Try GitHub Copilot
Let's use Copilot to generate code suggestions:
1. Place your cursor just below the final closing brace } in the file.
2. Type a natural language comment: // Add a method to add two numbers and Enter.
3. GitHub Copilot generates a code suggestion for you. The suggested
implementation shows in gray text.
4. To accept the suggestion, select Tab.

Let's use Copilot Chat to submit a coding-related question as a prompt:
1. Select the GitHub Copilot badge in the upper-right corner of the IDE.
2. Select Open Chat Window from the dropdown.
3. Enter the following prompt in the chat window:
Copilot prompt
Generate sample code for a simple C# method to add two numbers.
4. Copilot Chat generates sample code in response to your prompt.
GitHub Copilot is powered by AI, so surprises and mistakes are possible. For more
information, see GitHub Copilot FAQs .
Get started with GitHub Copilot in Visual Studio. Note that it requires Visual Studio 2022
version 17.8 or later.
Use code snippets
Visual Studio provides useful code snippets that you can use to quickly and easily
generate commonly used code blocks. Code snippets are available for different
programming languages including C#, Visual Basic, and C++.
Let's add the C# void Main snippet to our file.
1. Place your cursor just above the final closing brace } in the file, and type the
characters svm .
A pop-up dialog box appears with information about the svm code snippet.
2. Select the Tab key twice to insert the code snippet.
You'll see the static void Main() method signature get added to the file. The
Main() method is the entry point for C# applications.
Available code snippets vary for different programming languages. You can look at the
available code snippets for your language by choosing Edit > IntelliSense > Insert
Snippet or by selecting the Ctrl+K, Ctrl+X keys, and then choosing the folder for your
programming language. For C#, the snippet list looks like this:
The list includes snippets for creating a class, a constructor, a for loop, an if or switch
statement, and more.
The Text Editor toolbar, which is the row of buttons under the menu bar in Visual Studio,
helps make you more productive as you code. For example, you can toggle IntelliSense
completion mode, increase or decrease a line indent, or comment out code that you
don't want to compile.
Let's comment out some code.
1. Paste the following code into the Main() method body.
C#
Comment out code
// someWords is a string array.
string[] someWords = {
 "the",
 "quick",
 "brown",
 "fox",
 "jumps"
};
2. We're not using the moreWords variable, but we might use it later so we don't want
to delete it. Instead, we'll comment out those lines. Select the entire definition of
moreWords down to the closing semicolon, and then choose the Comment out the
selected lines button on the Text Editor toolbar. If you prefer to use the keyboard,
select Ctrl+K, Ctrl+C.
The C# comment characters // are added to the beginning of each selected line
to comment out the code.
When you want to uncomment lines, you can select them, and then choose the
Uncomment the selected lines button on the Text Editor toolbar. If you prefer to
use the keyboard, select Ctrl+K, Ctrl+U.
We don't want to see the empty constructor that was generated for Class1 , so to
unclutter our view of the code, let's collapse it. Choose the small gray box with the
minus sign inside it in the margin of the first line of the constructor. Or, if you prefer to
use the keyboard, place the cursor anywhere in the constructor code and select the
Ctrl+M, Ctrl+M keys.
string[] moreWords = {
 "over",
 "the",
 "lazy",
 "dog"
};
// Alphabetically sort the words.
IEnumerable<string> query = from word in someWords
 orderby word
 select word;
Collapse code blocks
The code block collapses to just the first line, followed by an ellipsis ( ... ). To expand
the code block again, select the same gray box that now has a plus sign in it, or select
Ctrl+M, Ctrl+M again. This feature is called Outlining and is especially useful when
you're collapsing long methods or entire classes.
View symbol definitions
The Visual Studio editor makes it easy to inspect the definition of a type, method, or
variable. One way is to go to the definition, in whichever file has it, by choosing Go to
Definition or by selecting the F12 key anywhere a symbol is referenced. An even quicker
way that doesn't move your focus away from the code you're working on is to use Peek
Definition.
Let's peek at the definition of the string type.
1. Right-click on any occurrence of string and choose Peek Definition from the
content menu. Or, select the Alt+F12 keys.
A pop-up window appears with the definition of the String class. You can scroll
within the pop-up window, or even peek at the definition of another type from the
peeked code.
2. Close the peek definition window by choosing the small box with an "x" at the top
right of the pop-up window.
Use IntelliSense to complete words
IntelliSense is an invaluable resource when you're coding. It can show you information
about available members of a type, or parameter details for different overloads of a
method. You can also use IntelliSense to complete a word after you type enough
characters to disambiguate it.
Let's add a line of code to print out the ordered strings to the console window, which is
the standard place for output from the program to go.
1. Below the query variable, start typing the following code:
C#
You'll see an IntelliSense pop-up appear with information about the query symbol.
2. To insert the rest of the word query by using IntelliSense word completion, select
the Tab key.
3. Finish off the code block to look like the following code. You can practice further
with code snippets by entering cw and then selecting Tab twice to generate the
Console.WriteLine statement.
C#
Nobody gets code right the first time, and one of the things you might have to change
is the name of a variable or method. Let's try out Visual Studio's refactor functionality to
rename the someWords variable to unsortedWords .
foreach (string str in qu
foreach (string str in query)
{
 Console.WriteLine(str);
}
Refactor a name
1. Place your cursor over the definition of the someWords variable, and choose
Rename from the right-click or context menu, or select the F2 key.
A Rename dialog box appears at the top right of the editor.
2. Enter the desired name unsortedWords. You'll see that the reference to
unsortedWords in the query assignment statement is also automatically renamed.
Before you select the Enter key, select the Include comments checkbox in the
Rename pop-up box.
3. Select the Enter key.
Both occurrences of someWords in your code have been renamed, as well as the
text someWords in your code comment.
Next steps
Learn about projects and solutions
Feedback
Was this page helpful?
Provide product feedback | Ask the community
GitHub Copilot Completions in Visual Studio
GitHub Copilot Chat in Visual Studio
Code snippets
Navigate code
Outlining
Go To Definition and Peek Definition
Refactoring
Use IntelliSense
See also
 Yes  No
Compile and build in Visual Studio
Article • 02/03/2025
For a first introduction to building within the IDE, see Walkthrough: Building an
application.
You can use any of the following methods to build an application: the Visual Studio IDE,
the MSBuild command-line tools, and Azure Pipelines:
Build Method Benefits
IDE - Create builds immediately and test them in a debugger.
- Run multi-processor builds for C++ and C# projects.
- Customize different aspects of the build system.
CMake - Build C++ projects using the CMake tool
- Use the same build system across Linux and Windows platforms.
MSBuild command
line
- Build projects without installing Visual Studio.
- Run multi-processor builds for all project types.
- Customize most areas of the build system.
Azure Pipelines - Automate your build process as part of a continuous
integration/continuous delivery pipeline.
- Apply automated tests with every build.
- Employ virtually unlimited cloud-based resources for build processes.
- Modify the build workflow and create build activities to perform deeply
customized tasks.
The documentation in this section goes into further details of the IDE-based build
process. For more information on the other methods, see CMake, MSBuild and Azure
Pipelines, respectively.
When you create a project, Visual Studio created default build configurations for the
project and the solution that contains the project. These configurations define how the
solutions and projects are built and deployed. Project configurations in particular are
unique for a target platform (such as Windows or Linux) and build type (such as debug
or release). You can edit these configurations however you like, and can also create your
own configurations as needed.
ﾉ Expand table
Building from the IDE
Feedback
Was this page helpful?
Provide product feedback | Ask the community
For a first introduction to building within the IDE, see Walkthrough: Building an
application.
Next, see Building and cleaning projects and solutions in Visual Studio to learn about
the different customizations you can make to the process. Customizations include
changing output directories, specifying custom build events, managing project
dependencies, managing build log files, and suppressing compiler warnings.
From there, you can explore a variety of other tasks:
Understand build configurations
Configure projects to target platforms
Manage project and solution properties.
Specify build events in C# and Visual Basic
Set build options
Build multiple projects in parallel
Building (compiling) website projects
CMake projects in Visual Studio
Related content
 Yes  No
Quickstart: Debug with C++ using the
Visual Studio debugger
Article • 01/12/2024
The Visual Studio debugger provides many powerful features to help you debug your
apps. This topic provides a quick way to learn some of the basic features.
1. Open Visual Studio and create a project.
Press Esc to close the start window. Type Ctrl + Q to open the search box, type
c++, choose Templates, then choose Create new Console App project. In the
dialog box that appears, choose Create.
If you don't see the Windows Console Application project template, go to Tools >
Get Tools and Features..., which opens the Visual Studio Installer. The Visual Studio
Installer launches. Choose the Desktop development with C++ workload, then
choose Modify.
Visual Studio creates the project.
2. In MyDbgApp.cpp, replace the following code
C++
with this code (do not remove #include "stdafx.h" ):
C++
Create a new project
int main()
{
 return 0;
}
#include <list>
#include <iostream>
using namespace std;
void doWork()
{
 list <int> c1;
A breakpoint is a marker that indicates where Visual Studio should suspend your running
code so you can take a look at the values of variables, or the behavior of memory, or
whether or not a branch of code is getting run. It is the most basic feature in debugging.
1. To set the breakpoint, click in the gutter to the left of the doWork function call (or
select the line of code and press F9).
2. Now press F5 (or choose Debug > Start Debugging).
The debugger pauses where you set the breakpoint. The statement where the
debugger and app execution is paused is indicated by the yellow arrow. The line
with the doWork function call has not yet executed.
 c1.push_back(10);
 c1.push_back(20);
 const list <int> c2 = c1;
 const int &i = c2.front();
 const int &j = c2.front();
 cout << "The first element is " << i << endl;
 cout << "The second element is " << j << endl;
}
int main()
{
 doWork();
}
Set a breakpoint
 Tip
If you have a breakpoint in a loop or recursion, or if you have many
breakpoints that you frequently step through, use a conditional breakpoint to
make sure that your code is suspended ONLY when specific conditions are
met. A conditional breakpoint saves time and can also make it easier to debug
issues that are hard to reproduce.
When trying to debug memory-related failures in C++, you can also use
breakpoints to inspect address values (look for NULL) and reference counts.
Navigate code
There are different commands to instruct the debugger to continue. We show a useful
code navigation command that is available starting in Visual Studio 2017.
While paused at the breakpoint, hover over the statement c1.push_back(20) until the
green Run to click button appears, and then press the Run to click button.
The app continues execution, calling doWork , and pauses on the line of code where you
clicked the button.
Common keyboard commands used to step through code include F10 and F11. For more
in-depth instructions, see First look at the debugger.
Inspect variables in a datatip
1. In the current line of code (marked by the yellow execution pointer), hover over
the c1 object with your mouse to show a datatip.
The datatip shows you the current value of the c1 variable and allows you to
inspect its properties. When debugging, if you see a value you don't expect, you
probably have a bug in the preceding or calling lines of code.
2. Expand the datatip to look at the current property values of the c1 object.
3. If you want to pin the datatip so that you can continue to see the value of c1 while
you execute code, click the small pin icon. (You can move the pinned datatip to a
convenient location.)
Edit code and continue debugging
If you identify a change that you want to test in your code while in the middle of a
debugging session, you can do that, too.
1. Click the second instance of c2.front() and change c2.front() to c2.back() .
2. Press F10 (or Debug > Step Over) a few times to advance the debugger and
execute the edited code.
F10 advances the debugger one statement at a time, but steps over functions
instead of stepping into them (the code that you skip still executes).
For more information on using edit-and-continue and on feature limitations, see Edit
and Continue.
Feedback
Was this page helpful?
In this tutorial, you've learned how to start the debugger, step through code, and
inspect variables. You may want to get a high-level look at debugger features along with
links to more information.
Next steps
First look at the debugger
 Yes  No
Write unit tests for C/C++ in Visual
Studio
Article • 12/16/2024
You can write and run your C++ unit tests by using the Test Explorer window. It works
just like it does for other languages. For more information about using Test Explorer,
see Run unit tests with Test Explorer.
７ Note
Some features such as Live Unit Testing, Coded UI Tests and IntelliTest aren't
supported for C++.
Visual Studio includes these C++ test frameworks with no extra downloads required:
Microsoft Unit Testing Framework for C++
Google Test
Boost.Test
CTest
You can use the installed frameworks, or write your own test adapter for whatever
framework you want to use within Visual Studio. A test adapter integrates unit tests with
the Test Explorer window. Several non-Microsoft adapters are available on the Visual
Studio Marketplace . For more information, see Install unit test frameworks.
Visual Studio 2017 and later (Professional and Enterprise)
C++ unit test projects support CodeLens.
Visual Studio 2017 and later (all editions)
Google Test Adapter is included as a default component of the Desktop
development with C++ workload. It has a project template that you can add to
a solution. Right-click on the solution node in Solution Explorer and choose
Add > New Project on the shortcut menu to add the project template. It also
has options you can configure by using Tools > Options. For more information,
see How to: Use Google Test in Visual Studio.
Boost.Test is included as a default component of the Desktop development
with C++ workload. It's integrated with Test Explorer, but currently doesn't
have a project template. You must manually configure it. For more information,
see How to: Use Boost.Test in Visual Studio.
CTest support is included with the C++ CMake tools component, which is part
of the Desktop development with C++ workload. For more information, see
How to: Use CTest in Visual Studio.
Earlier versions of Visual Studio
You can download the Google Test adapter and Boost.Test Adapter extensions on
the Visual Studio Marketplace. Find them at Test adapter for Boost.Test and Test
adapter for Google Test .
 Tip
You can also use Copilot /tests slash command to generate unit tests from code.
For example, you can type /tests using Boost framework to generate Boost.Test
tests. For more information, see Use slash commands in Copilot Chat.
Basic test workflow
The following sections show the basic steps to get you started with C++ unit testing.
The basic configuration is similar for both the Microsoft and Google Test frameworks.
Boost.Test requires that you manually create a test project.
Create a test project in Visual Studio 2022
Define and run unit tests inside one or more test projects. A test project creates a
separate app that calls the code in your executable and reports on its behavior. Create
test projects in the same solution as the code you want to test.
To add a new test project to an existing solution:
1. Right-click on the Solution node in Solution Explorer.
2. In the context menu, choose Add > New Project.
3. Set Language to C++ and type test in the search box. The following screenshot
shows the test projects that are available when the Desktop Development with
C++ and the UWP Development workload are installed:
Create references to other projects in the solution
To enable access to the functions in the project under test, add a reference to the
project in your test project. In Solution Explorer, expand your test project. Right-click
References and then select Add > Reference. In the Add Reference dialog box, choose
the projects you want to test.
Link to object or library files
If the test code doesn't export the functions that you want to test, add the output .obj
or .lib files to the dependencies of the test project. For more information, see To link
the tests to the object or library files. Don't include object files that have a main function
or another standard entry point such as wmain , WinMain , or DllMain . When you add new
source files to your project, update the test project dependencies to include the
corresponding object files.
Add #include directives for header files
In your unit test .cpp file, add an #include directive for any header files that declare the
types and functions you want to test. Type #include " , and then IntelliSense activates to
help you choose. Repeat for any more headers.
 Tip
To avoid having to type the full path in each include statement in the source file,
add the required folders in Project > Properties > C/C++ > General > Additional
Include Directories.
Write test methods
７ Note
This section shows syntax for the Microsoft Unit Testing Framework for C/C++. For
more information, see Microsoft.VisualStudio.TestTools.CppUnitTestFramework
API reference.
For Google Test documentation, see Google Test primer . For Boost.Test, see
Boost Test library: The unit test framework .
The .cpp file in your test project has a stub class and method defined for you. They
show an example of how to write test code. The signatures use the TEST_CLASS and
TEST_METHOD macros, which make the methods discoverable from the Test Explorer
window.
TEST_CLASS and TEST_METHOD are part of the Microsoft Native Test Framework. Test
Explorer discovers test methods in other supported frameworks in a similar way.
A TEST_METHOD returns void. To produce a test result, use the static methods in the
Assert class to test actual results against expected results. In the following example,
assume MyClass has a constructor that takes a std::string . This example shows how
you can test that the constructor initializes the class the way you expect:
C++
In the previous example, the result of the Assert::AreEqual call determines whether the
test passes or fails. The Assert class contains many other methods to compare expected
results with actual results.
You can add traits to test methods to specify test owners, priority, and other
information. You can then use these values to sort and group tests in Test Explorer. For
more information, see Run unit tests with Test Explorer.
1. On the Test menu, choose Test Explorer. The following illustration shows a test
project before you run tests.
TEST_METHOD(TestClassInit)
{
 std::string name = "Bill";
 MyClass mc(name);
 Assert::AreEqual(name, mc.GetName());
}
Run the tests
７ Note
CTest integration with Test Explorer is not yet available. Run CTest tests from
the CMake main menu.
2. If any of your tests are missing from the window, build the test project by right￾clicking its node in Solution Explorer and choosing Build or Rebuild.
3. In Test Explorer, choose Run All, or select the specific tests you want to run. Right￾click on a test for other options, including running it in debug mode with
breakpoints enabled. After all the tests run, the window shows the tests that
passed and the ones that failed.
For failed tests, the message displays details that help to diagnose the cause. Right-click
on the failing test for a pop-up menu. Choose Debug to step through the function
where the failure occurred.
For more information on using Test Explorer, see Run unit tests with Test Explorer.
For more information on unit testing, see Unit test basics.
Use CodeLens
Visual Studio 2017 and later (Professional and Enterprise editions)
CodeLens lets you quickly see the status of a unit test without leaving the code editor.
Initialize CodeLens for a C++ unit test project in any of the following ways:
Edit and build your test project or solution.
Rebuild your project or solution.
Run tests from the Test Explorer window.
After you initialize CodeLens, you can see the test status icons above each unit test.

Choose the icon for more information, or to run or debug the unit test:
Feedback
Was this page helpful?
Provide product feedback | Ask the community
Unit test your code
Related content
 Yes  No
Walkthrough: Compiling a Native C++
Program on the Command Line
Article • 02/08/2022
Visual Studio includes a command-line C and C++ compiler. You can use it to create
everything from basic console apps to Universal Windows Platform apps, Desktop apps,
device drivers, and .NET components.
In this walkthrough, you create a basic, "Hello, World"-style C++ program by using a
text editor, and then compile it on the command line. If you'd like to try the Visual
Studio IDE instead of using the command line, see Walkthrough: Working with Projects
and Solutions (C++) or Using the Visual Studio IDE for C++ Desktop Development.
In this walkthrough, you can use your own C++ program instead of typing the one
that's shown. Or, you can use a C++ code sample from another help article.
Prerequisites
To complete this walkthrough, you must have installed either Visual Studio and the
optional Desktop development with C++ workload, or the command-line Build Tools
for Visual Studio.
Visual Studio is an integrated development environment (IDE). It supports a full-featured
editor, resource managers, debuggers, and compilers for many languages and
platforms. Versions available include the free Visual Studio Community edition, and all
can support C and C++ development. For information on how to download and install
Visual Studio, see Install C++ support in Visual Studio.
The Build Tools for Visual Studio installs only the command-line compilers, tools, and
libraries you need to build C and C++ programs. It's perfect for build labs or classroom
exercises and installs relatively quickly. To install only the command-line tools, look for
Build Tools for Visual Studio on the Visual Studio Downloads page.
Before you can build a C or C++ program on the command line, verify that the tools are
installed, and you can access them from the command line. Visual C++ has complex
requirements for the command-line environment to find the tools, headers, and libraries
it uses. You can't use Visual C++ in a plain command prompt window without doing
some preparation. Fortunately, Visual C++ installs shortcuts for you to launch a
developer command prompt that has the environment set up for command line builds.
Unfortunately, the names of the developer command prompt shortcuts and where
they're located are different in almost every version of Visual C++ and on different
versions of Windows. Your first walkthrough task is finding the right one to use.
７ Note
A developer command prompt shortcut automatically sets the correct paths for the
compiler and tools, and for any required headers and libraries. You must set these
environment values yourself if you use a regular Command Prompt window. For
more information, see Use the MSVC toolset from the command line. We
recommend you use a developer command prompt shortcut instead of building
your own.
Open a developer command prompt
1. If you have installed Visual Studio 2017 or later on Windows 10 or later, open the
Start menu and choose All apps. Scroll down and open the Visual Studio folder
(not the Visual Studio application). Choose Developer Command Prompt for VS to
open the command prompt window.
If you have installed Microsoft Visual C++ Build Tools 2015 on Windows 10 or
later, open the Start menu and choose All apps. Scroll down and open the Visual
C++ Build Tools folder. Choose Visual C++ 2015 x86 Native Tools Command
Prompt to open the command prompt window.
You can also use the Windows search function to search for "developer command
prompt" and choose one that matches your installed version of Visual Studio. Use
the shortcut to open the command prompt window.
2. Next, verify that the Visual C++ developer command prompt is set up correctly. In
the command prompt window, enter cl and verify that the output looks
something like this:
Output
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
usage: cl [ option... ] filename... [ /link linkoption... ]
There may be differences in the current directory or version numbers. These values
depend on the version of Visual C++ and any updates installed. If the above
output is similar to what you see, then you're ready to build C or C++ programs at
the command line.
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104
when you run the cl command, then either you are not using a developer
command prompt, or something is wrong with your installation of Visual C++.
You must fix this issue before you can continue.
If you can't find the developer command prompt shortcut, or if you get an error
message when you enter cl , then your Visual C++ installation may have a
problem. Try reinstalling the Visual C++ component in Visual Studio, or reinstall
the Microsoft Visual C++ Build Tools. Don't go on to the next section until the cl
command works. For more information about installing and troubleshooting Visual
C++, see Install Visual Studio.
７ Note
Depending on the version of Windows on the computer and the system
security configuration, you might have to right-click to open the shortcut
menu for the developer command prompt shortcut and then choose Run as
administrator to successfully build and run the program that you create by
following this walkthrough.
Create a Visual C++ source file and compile it on the
command line
1. In the developer command prompt window, enter md c:\hello to create a
directory, and then enter cd c:\hello to change to that directory. This directory is
where both your source file and the compiled program get created.
2. Enter notepad hello.cpp in the command prompt window.
Choose Yes when Notepad prompts you to create a new file. This step opens a
blank Notepad window, ready for you to enter your code in a file named hello.cpp.
3. In Notepad, enter the following lines of code:
C++
This code is a simple program that will write one line of text on the screen and
then exit. To minimize errors, copy this code and paste it into Notepad.
4. Save your work! In Notepad, on the File menu, choose Save.
Congratulations, you've created a C++ source file, hello.cpp, that is ready to
compile.
5. Switch back to the developer command prompt window. Enter dir at the
command prompt to list the contents of the c:\hello directory. You should see the
source file hello.cpp in the directory listing, which looks something like:
Output
The dates and other details will differ on your computer.
#include <iostream>
using namespace std;
int main()
{
 cout << "Hello, world, from Visual C++!" << endl;
}
c:\hello>dir
 Volume in drive C has no label.
 Volume Serial Number is CC62-6545
 Directory of c:\hello
05/24/2016 05:36 PM <DIR> .
05/24/2016 05:36 PM <DIR> ..
05/24/2016 05:37 PM 115 hello.cpp
 1 File(s) 115 bytes
 2 Dir(s) 571,343,446,016 bytes free
７ Note
If you don't see your source code file, hello.cpp , make sure the current
working directory in your command prompt is the C:\hello directory you
created. Also make sure that this is the directory where you saved your source
file. And make sure that you saved the source code with a .cpp file name
extension, not a .txt extension. Your source file gets saved in the current
directory as a .cpp file automatically if you open Notepad at the command
prompt by using the notepad hello.cpp command. Notepad's behavior is
different if you open it another way: By default, Notepad appends a .txt
extension to new files when you save them. It also defaults to saving files in
your Documents directory. To save your file with a .cpp extension in Notepad,
choose File > Save As. In the Save As dialog, navigate to your C:\hello folder
in the directory tree view control. Then use the Save as type dropdown
control to select All Files (*.*). Enter hello.cpp in the File name edit control,
and then choose Save to save the file.
6. At the developer command prompt, enter cl /EHsc hello.cpp to compile your
program.
The cl.exe compiler generates an .obj file that contains the compiled code, and
then runs the linker to create an executable program named hello.exe. This name
appears in the lines of output information that the compiler displays. The output of
the compiler should look something like:
Output
c:\hello>cl /EHsc hello.cpp
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
hello.cpp
Microsoft (R) Incremental Linker Version 14.10.25017.0
Copyright (C) Microsoft Corporation. All rights reserved.
/out:hello.exe
hello.obj
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104,
your developer command prompt is not set up correctly. For information on
how to fix this issue, go back to the Open a developer command prompt
section.
７ Note
If you get a different compiler or linker error or warning, review your source
code to correct any errors, then save it and run the compiler again. For
information about specific errors, use the search box to look for the error
number.
7. To run the hello.exe program, at the command prompt, enter hello .
The program displays this text and exits:
Output
Hello, world, from Visual C++!
Congratulations, you've compiled and run a C++ program by using the command￾line tools.
Next steps
This "Hello, World" example is about as simple as a C++ program can get. Real world
programs usually have header files, more source files, and link to libraries.
You can use the steps in this walkthrough to build your own C++ code instead of typing
the sample code shown. These steps also let you build many C++ code sample
programs that you find elsewhere. You can put your source code and build your apps in
any writeable directory. By default, the Visual Studio IDE creates projects in your user
folder, in a source\repos subfolder. Older versions may put projects in a
Documents\Visual Studio <version>\Projects folder.
To compile a program that has additional source code files, enter them all on the
command line, like:
cl /EHsc file1.cpp file2.cpp file3.cpp
The /EHsc command-line option instructs the compiler to enable standard C++
exception handling behavior. Without it, thrown exceptions can result in undestroyed
objects and resource leaks. For more information, see /EH (Exception Handling Model).
When you supply additional source files, the compiler uses the first input file to create
the program name. In this case, it outputs a program called file1.exe. To change the
name to program1.exe, add an /out linker option:
cl /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe
And to catch more programming mistakes automatically, we recommend you compile
by using either the /W3 or /W4 warning level option:
cl /W4 /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe
The compiler, cl.exe, has many more options. You can apply them to build, optimize,
debug, and analyze your code. For a quick list, enter cl /? at the developer command
prompt. You can also compile and link separately and apply linker options in more
complex build scenarios. For more information on compiler and linker options and
usage, see C/C++ Building Reference.
You can use NMAKE and makefiles, MSBuild and project files, or CMake, to configure
and build more complex projects on the command line. For more information on using
these tools, see NMAKE Reference, MSBuild, and CMake projects in Visual Studio.
The C and C++ languages are similar, but not the same. The MSVC compiler uses a
simple rule to determine which language to use when it compiles your code. By default,
the MSVC compiler treats files that end in .c as C source code, and files that end in
.cpp as C++ source code. To force the compiler to treat all files as C++ independent of
file name extension, use the /TP compiler option.
The MSVC compiler includes a C Runtime Library (CRT) that conforms to the ISO C99
standard, with minor exceptions. Portable code generally compiles and runs as expected.
Certain obsolete library functions, and several POSIX function names, are deprecated by
the MSVC compiler. The functions are supported, but the preferred names have
changed. For more information, see Security Features in the CRT and Compiler Warning
(level 3) C4996.
See also
C++ Language Reference
Projects and build systems
MSVC Compiler Options
Walkthrough: Compile a C program on
the command line
Article • 05/10/2022
The Visual Studio build tools include a C compiler that you can use to create everything
from basic console programs to full Windows Desktop applications, mobile apps, and
more. Microsoft C/C++ (MSVC) is a C and C++ compiler that, in its latest versions,
conforms to some of the latest C language standards, including C11 and C17.
This walkthrough shows how to create a basic, "Hello, World"-style C program by using
a text editor, and then compile it on the command line. If you'd rather work in C++ on
the command line, see Walkthrough: Compiling a Native C++ Program on the
Command Line. If you'd like to try the Visual Studio IDE instead of using the command
line, see Walkthrough: Working with Projects and Solutions (C++) or Using the Visual
Studio IDE for C++ Desktop Development.
Prerequisites
To complete this walkthrough, you must have installed either Visual Studio or the Build
Tools for Visual Studio and the optional Desktop development with C++ workload.
Visual Studio is a powerful integrated development environment that supports a full￾featured editor, resource managers, debuggers, and compilers for many languages and
platforms. For information on these features and how to download and install Visual
Studio, including the free Visual Studio Community edition, see Install Visual Studio.
The Build Tools for Visual Studio version of Visual Studio installs only the command-line
toolset, the compilers, tools, and libraries you need to build C and C++ programs. It's
perfect for build labs or classroom exercises and installs relatively quickly. To install only
the command-line toolset, download Build Tools for Visual Studio from the Visual Studio
downloads page and run the installer. In the Visual Studio installer, select the Desktop
development with C++ workload (in older versions of Visual Studio, select the C++
build tools workload), and choose Install.
When you've installed the tools, there's another tool you'll use to build a C or C++
program on the command line. MSVC has complex requirements for the command-line
environment to find the tools, headers, and libraries it uses. You can't use MSVC in a
plain command prompt window without some preparation. You need a developer
command prompt window, which is a regular command prompt window that has all the
required environment variables set. Fortunately, Visual Studio installs shortcuts for you
to launch developer command prompts that have the environment set up for command
line builds. Unfortunately, the names of the developer command prompt shortcuts and
where they're located are different in almost every version of Visual Studio and on
different versions of Windows. Your first walkthrough task is to find the right shortcut to
use.
７ Note
A developer command prompt shortcut automatically sets the correct paths for the
compiler and tools, and for any required headers and libraries. Some of these
values are different for each build configuration. You must set these environment
values yourself if you don't use one of the shortcuts. For more information, see Use
the MSVC toolset from the command line. Because the build environment is
complex, we strongly recommend you use a developer command prompt shortcut
instead of building your own.
These instructions vary depending on which version of Visual Studio you're using. To see
the documentation for your preferred version of Visual Studio, use the Version selector
control. It's found at the top of the table of contents on this page.
Open a developer command prompt in Visual
Studio 2022
If you've installed Visual Studio 2022 on Windows 10 or later, open the Start menu, and
choose All apps. Then, scroll down and open the Visual Studio 2022 folder (not the
Visual Studio 2022 app). Choose Developer Command Prompt for VS 2022 to open the
command prompt window.
If you're using a different version of Windows, look in your Start menu or Start page for
a Visual Studio tools folder that contains a developer command prompt shortcut. You
can also use the Windows search function to search for "developer command prompt"
and choose one that matches your installed version of Visual Studio. Use the shortcut to
open the command prompt window.
Next, verify that the developer command prompt is set up correctly. In the command
prompt window, enter cl (or CL , case doesn't matter for the compiler name, but it does
matter for compiler options). The output should look something like this:
Output
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
usage: cl [ option... ] filename... [ /link linkoption... ]
There may be differences in the current directory or version numbers, depending on the
version of Visual Studio and any updates installed. If the above output is similar to what
you see, then you're ready to build C or C++ programs at the command line.
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104 when
you run the cl command, then either you are not using a developer command
prompt, or something is wrong with your installation of Visual Studio. You must fix
this issue before you can continue.
If you can't find the developer command prompt shortcut, or if you get an error
message when you enter cl , then your Visual Studio installation may have a problem. If
you're using Visual Studio 2017 or later, try reinstalling the Desktop development with
C++ workload in the Visual Studio installer. For details, see Install C++ support in Visual
Studio. Or, reinstall the Build Tools from the Visual Studio downloads page. Don't go
on to the next section until the cl command works. For more information about
installing and troubleshooting Visual Studio, see Install Visual Studio.
７ Note
Depending on the version of Windows on the computer and the system security
configuration, you might have to right-click to open the shortcut menu for the
developer command prompt shortcut and then choose Run as Administrator to
successfully build and run the program that you create by following this
walkthrough.
Create a C source file and compile it on the
command line
1. In the developer command prompt window, enter cd c:\ to change the current
working directory to the root of your C: drive. Next, enter md c:\hello to create a
directory, and then enter cd c:\hello to change to that directory. This directory
will hold your source file and the compiled program.
2. Enter notepad hello.c at the developer command prompt. In the Notepad alert
dialog that pops up, choose Yes to create a new hello.c file in your working
directory.
3. In Notepad, enter the following lines of code:
C
4. On the Notepad menu bar, choose File > Save to save hello.c in your working
directory.
5. Switch back to the developer command prompt window. Enter dir at the
command prompt to list the contents of the c:\hello directory. You should see
the source file hello.c in the directory listing, which looks something like:
Output
The dates and other details will differ on your computer. If you don't see your
source code file, hello.c , make sure you've changed to the c:\hello directory
you created, and in Notepad, make sure that you saved your source file in this
#include <stdio.h>
int main()
{
 printf("Hello, World! This is a native C program compiled on the
command line.\n");
 return 0;
}
C:\hello>dir
 Volume in drive C has no label.
 Volume Serial Number is CC62-6545
 Directory of C:\hello
10/02/2017 03:46 PM <DIR> .
10/02/2017 03:46 PM <DIR> ..
10/02/2017 03:36 PM 143 hello.c
 1 File(s) 143 bytes
 2 Dir(s) 514,900,566,016 bytes free
directory. Also make sure that you saved the source code with a .c file name
extension, not a .txt extension.
6. To compile your program, enter cl hello.c at the developer command prompt.
You can see the executable program name, hello.exe, in the lines of output
information that the compiler displays:
Output
c:\hello>cl hello.c
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
hello.c
Microsoft (R) Incremental Linker Version 14.10.25017.0
Copyright (C) Microsoft Corporation. All rights reserved.
/out:hello.exe
hello.obj
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104,
your developer command prompt is not set up correctly. For information on
how to fix this issue, go back to the Open a developer command prompt
section.
If you get a different compiler or linker error or warning, review your source
code to correct any errors, then save it and run the compiler again. For
information about specific errors, use the search box at the top of this page to
look for the error number.
7. To run your program, enter hello at the command prompt.
The program displays this text and then exits:
Output
Hello, World! This is a native C program compiled on the command line.
Congratulations, you've compiled and run a C program by using the command
line.
Next steps
This "Hello, World" example is about as basic as a C program can get. Real world
programs have header files and more source files, link in libraries, and do useful work.
You can use the steps in this walkthrough to build your own C code instead of typing
the sample code shown. You can also build many C code sample programs that you find
elsewhere. To compile a program that has more source code files, enter them all on the
command line:
cl file1.c file2.c file3.c
The compiler outputs a program called file1.exe . To change the name to
program1.exe , add an /out linker option:
cl file1.c file2.c file3.c /link /out:program1.exe
And to catch more programming mistakes automatically, we recommend you compile
by using either the /W3 or /W4 warning level option:
cl /W4 file1.c file2.c file3.c /link /out:program1.exe
The compiler, cl.exe, has many more options you can apply to build, optimize, debug,
and analyze your code. For a quick list, enter cl /? at the developer command prompt.
You can also compile and link separately and apply linker options in more complex build
scenarios. For more information on compiler and linker options and usage, see C/C++
Building Reference.
You can use NMAKE and makefiles, or MSBuild and project files to configure and build
more complex projects on the command line. For more information on using these
tools, see NMAKE Reference and MSBuild.
The C and C++ languages are similar, but not the same. The Microsoft C/C++ compiler
(MSVC) uses a basic rule to determine which language to use when it compiles your
code. By default, the MSVC compiler treats all files that end in .c as C source code, and
all files that end in .cpp as C++ source code. To force the compiler to treat all files as C
no matter the file name extension, use the /TC compiler option.
By default, MSVC is compatible with the ANSI C89 and ISO C99 standards, but not
strictly conforming. In most cases, portable C code will compile and run as expected.
The compiler provides optional support for the changes in ISO C11/C17. To compile with
C11/C17 support, use the compiler flag /std:c11 or /std:c17 . C11/C17 support requires
Windows SDK 10.0.20201.0 or later. Windows SDK 10.0.22000.0 or later is
recommended. You can download the latest SDK from the Windows SDK page. For more
information, and instructions on how to install and use this SDK for C development, see
Install C11 and C17 support in Visual Studio.
Certain library functions and POSIX function names are deprecated by MSVC. The
functions are supported, but the preferred names have changed. For more information,
see Security Features in the CRT and Compiler Warning (level 3) C4996.
See also
Walkthrough: Creating a Standard C++ Program (C++)
C Language Reference
Projects and build systems
Compatibility
Walkthrough: Compiling a C++/CX
Program on the Command Line
Article • 03/01/2023
７ Note
For new UWP apps and components, we recommend that you use C++/WinRT, a
standard C++17 language projection for Windows Runtime APIs. C++/WinRT is
available in the Windows SDK from version 1803 (10.0.17134.0) onward.
C++/WinRT is implemented entirely in header files, and is designed to provide you
with first-class access to the modern Windows API.
The Microsoft C++ compiler (MSVC) supports C++ component extensions (C++/CX),
which has additional types and operators to target the Windows Runtime programming
model. You can use C++/CX to build apps for Universal Windows Platform (UWP), and
Windows desktop. For more information, see A Tour of C++/CX and Component
Extensions for Runtime Platforms.
In this walkthrough, you use a text editor to create a basic C++/CX program, and then
compile it on the command line. (You can use your own C++/CX program instead of
typing the one that's shown, or you can use a C++/CX code sample from another help
article. This technique is useful for building and testing small modules that have no UI
elements.)
７ Note
You can also use the Visual Studio IDE to compile C++/CX programs. Because the
IDE includes design, debugging, emulation, and deployment support that isn't
available on the command line, we recommend that you use the IDE to build
Universal Windows Platform (UWP) apps. For more information, see Create a UWP
app in C++.
Prerequisites
You understand the fundamentals of the C++ language.
Compiling a C++/CX Program
To enable compilation for C++/CX, you must use the /ZW compiler option. The MSVC
compiler generates an .exe file that targets the Windows Runtime, and links to the
required libraries.
To compile a C++/CX application on the command line
1. Open a Developer Command Prompt window. For specific instructions, see To
open a developer command prompt window.
Administrator credentials may be required to successfully compile the code,
depending on the computer's operating system and configuration. To run the
command prompt window as an administrator, right-click to open the shortcut
menu for the command prompt and then choose More > Run as administrator.
2. Change the current working directory in the command prompt window to a
directory you can write to, such as your Documents directory.
3. At the command prompt, enter notepad basiccx.cpp.
Choose Yes when you're prompted to create a file.
4. In Notepad, enter these lines:
C++
using namespace Platform;
int main(Platform::Array<Platform::String^>^ args)
{
 Platform::Details::Console::WriteLine("This is a C++/CX program.");
}
5. On the menu bar, choose File > Save.
You've created a C++ source file that uses the Windows Runtime Platform
namespace namespace.
6. At the command prompt, enter cl /EHsc /ZW basiccx.cpp /link
/SUBSYSTEM:CONSOLE . The cl.exe compiler compiles the source code into an .obj
file, and then runs the linker to generate an executable program named
basiccx.exe. The /EHsc compiler option specifies the C++ exception-handling
model, and the /link flag specifies a console application.
7. To run the basiccx.exe program, at the command prompt, enter basiccx.
The program displays this text and exits:
Output
This is a C++/CX program.
See also
Projects and build systems
MSVC Compiler Options
Walkthrough: Compiling a C++/CLI
Program on the Command Line
Article • 02/24/2023
You can create Visual C++ programs that target the Common Language Runtime (CLR)
and use the .NET Framework, and build them on the command line. Visual C++ supports
the C++/CLI programming language, which has additional types and operators to target
the .NET programming model. For general information about the C++/CLI language, see
.NET Programming with C++/CLI (Visual C++).
In this walkthrough, you use a text editor to create a basic C++/CLI program, and then
compile it on the command line. (You can use your own C++/CLI program instead of
typing the one that's shown, or you can use a C++/CLI code sample from another help
article. This technique is useful for building and testing small modules that have no UI
elements.)
Prerequisites
You understand the fundamentals of the C++ language.
Compiling a C++/CLI Program
The following steps show how to compile a C++/CLI console application that uses .NET
Framework classes.
To enable compilation for C++/CLI, you must use the /clr compiler option. The MSVC
compiler generates an .exe file that contains MSIL code—or mixed MSIL and native code
—and links to the required .NET Framework libraries.
To compile a C++/CLI application on the command line
1. Open a Developer Command Prompt window. For specific instructions, see To
open a developer command prompt window.
Administrator credentials may be required to successfully compile the code,
depending on the computer's operating system and configuration. To run the
command prompt window as an administrator, right-click to open the shortcut
menu for the command prompt and then choose More > Run as administrator.
2. Change the current working directory in the command prompt window to a
directory you can write to, such as your Documents directory.
3. At the command prompt, enter notepad basicclr.cpp .
Choose Yes when you're prompted to create a file.
4. In Notepad, enter these lines:
C++
int main()
{
 System::Console::WriteLine("This is a C++/CLI program.");
}
5. On the menu bar, choose File > Save.
You've created a Visual C++ source file that uses a .NET Framework class (Console)
in the System namespace.
6. At the command prompt, enter cl /clr basicclr.cpp . The cl.exe compiler
compiles the source code into an .obj file that contains MSIL, and then runs the
linker to generate an executable program named basicclr.exe.
7. To run the basicclr.exe program, at the command prompt, enter basicclr .
The program displays this text and exits:
Output
This is a C++/CLI program.
See also
C++ Language Reference
Projects and build systems
MSVC Compiler Options
Tell us about your PDF experience.
C/C++ projects and build systems in
Visual Studio
Article • 12/09/2021
You can use Visual Studio to edit, compile, and build any C++ code base with full
IntelliSense support without having to convert that code into a Visual Studio project or
compile with the MSVC toolset. For example, you can edit a cross-platform CMake
project in Visual Studio on a Windows machine, then compile it for Linux using g++ on
a remote Linux machine.
C++ compilation
To build a C++ program means to compile source code from one or more files and then
link those files into an executable file (.exe), a dynamic-load library (.dll) or a static library
(.lib).
Basic C++ compilation involves three main steps:
The C++ preprocessor transforms all the #directives and macro definitions in each
source file. This creates a translation unit.
The C++ compiler compiles each translation unit into object files (.obj), applying
whatever compiler options have been set.
The linker merges the object files into a single executable, applying the linker
options that have been set.
The MSVC toolset
The Microsoft C++ compiler, linker, standard libraries, and related utilities make up the
MSVC compiler toolset (also called a toolchain or "build tools"). These are included in
Visual Studio. You can also download and use the command-line toolset as a free
standalone package. For more information, see Build Tools for Visual Studio on the
Visual Studio Downloads page.
You can build simple programs by invoking the MSVC compiler (cl.exe) directly from the
command line. The following command accepts a single source code file, and invokes
cl.exe to build an executable called hello.exe:
Windows Command Prompt
cl /EHsc hello.cpp
Here the compiler (cl.exe) automatically invokes the C++ preprocessor and the linker to
produce the final output file. For more information, see Building on the command line.
Build systems and projects
Most real-world programs use some kind of build system to manage complexities of
compiling multiple source files for multiple configurations (debug vs. release), multiple
platforms (x86, x64, ARM, and so on), custom build steps, and even multiple executables
that must be compiled in a certain order. You make settings in a build configuration
file(s), and the build system accepts that file as input before it invokes the compiler. The
set of source code files and build configuration files needed to build an executable file is
called a project.
The following list shows various options for Visual Studio Projects - C++:
create a Visual Studio project by using the Visual Studio IDE and configure it by
using property pages. Visual Studio projects produce programs that run on
Windows. For an overview, see Compiling and Building in the Visual Studio
documentation.
open a folder that contains a CMakeLists.txt file. CMake support is integrated into
Visual Studio. You can use the IDE to edit, test, and debug without modifying the
CMake files in any way. This enables you to work in the same CMake project as
others who might be using different editors. CMake is the recommended approach
for cross-platform development. For more information, see CMake projects.
open a loose folder of source files with no project file. Visual Studio will use
heuristics to build the files. This is an easy way to compile and run small console
applications. For more information, see Open Folder projects.
open a folder that contains a makefile, or any other build system configuration file.
You can configure Visual Studio to invoke any arbitrary build commands by adding
JSON files to the folder. For more information, see Open Folder projects.
Open a Windows makefile in Visual Studio. For more information, see NMAKE
Reference.
MSBuild from the command line
You can invoke MSBuild from the command line by passing it a .vcxproj file along with
command-line options. This approach requires a good understanding of MSBuild, and is
recommended only when necessary. For more information, see MSBuild.
In This Section
Visual Studio projects
How to create, configure, and build C++ projects in Visual Studio using its native build
system (MSBuild).
CMake projects
How to code, build, and deploy CMake projects in Visual Studio.
Open Folder projects
How to use Visual Studio to code, build, and deploy C++ projects based on any arbitrary
build system, or no build system at all.
Release builds
How to create and troubleshoot optimized release builds for deployment to end users.
Use the MSVC toolset from the command line
Discusses how to use the C/C++ compiler and build tools directly from the command
line rather than using the Visual Studio IDE.
Building DLLs in Visual Studio
How to create, debug, and deploy C/C++ DLLs (shared libraries) in Visual Studio.
Walkthrough: Creating and Using a Static Library
How to create a .lib binary file.
Building C/C++ Isolated Applications and Side-by-side Assemblies
Describes the deployment model for Windows Desktop applications, based on the idea
of isolated applications and side-by-side assemblies.
Configure C++ projects for 64-bit, x64 targets
How to target 64-bit x64 hardware with the MSVC build tools.
Configure C++ projects for ARM processors
How to use the MSVC build tools to target ARM hardware.
Optimizing Your Code
How to optimize your code in various ways including program guided optimizations.
Configuring Programs for Windows XP
How to target Windows XP with the MSVC build tools.
C/C++ Building Reference
Provides links to reference articles about program building in C++, compiler and linker
options, and various build tools.
Visual Studio projects - C++
Article • 10/04/2023
A Visual Studio project is a collection of code files and assets such as icons, images, and
so on, that are built together using the MSBuild build system. MSBuild is the native build
system for Visual Studio and is generally the best build system to use for Windows￾specific programs. MSBuild is tightly integrated with Visual Studio, but you can also use
it from the command line.
For information about upgrading MSBuild projects from older versions of Visual Studio,
see the Microsoft C++ Porting and Upgrading Guide.
For cross-platform projects, or projects that use open-source libraries, we recommend
using CMake projects in Visual Studio in Visual Studio 2017 and later.
Create a Visual Studio C++ project
1. Create a C++ project by choosing File > New > Project.
2. In the Create a new project dialog, set the Language dropdown to C++. This
filters the list of project templates to C++ projects. You can filter the templates by
setting the Platform, Project Type, or by entering keywords in the search box.
3. Select a project template, then choose Next.
4. On the Configure your new project page, enter project-specific settings such as
the project name or location and then choose Create to create your project.
For more information about the default project templates included in Visual Studio, see
C++ project templates in Visual Studio.
You can create your own project templates. For more information, see How to: Create
project templates.
After you create a project, it appears in the Solution Explorer window:
When you create a new project, a solution file (.sln) is also created. A Visual Studio
solution is a collection of one or more projects. You can add another project to the
solution by right-clicking the solution name in Solution Explorer > Add > New project.
The solution file coordinates build dependencies when you have multiple related
projects. Compiler options are set at the project level.
Add code, icons, and other assets to a project
Add source code files, icons, or any other items to your project by right-clicking on the
project in Solution Explorer and choosing Add > New or Add > Existing.
Add third-party libraries to a project
Over 900 C++ open source libraries are available via the vcpkg package manager. Run
the Visual Studio integration step to set up the paths to that library when you reference
it from any Visual Studio project.
They're also commercial third-party libraries that you can install. Follow their installation
instructions.
Set compiler options and build properties
To configure build settings for a project, right-click on the project in Solution Explorer
and choose Properties. For more information, see Set C++ compiler and build
properties in Visual Studio.
Compile and run a project
To compile and run the new project, press F5 or click the debug dropdown with the
green arrow on the main toolbar. The configuration dropdown is where you choose
whether to perform a Debug or Release build (or some other custom configuration).
A new project compiles without errors. When adding your own code, you might
occasionally introduce an error or trigger a warning. An error prevents the build from
completing; a warning doesn't. All errors and warnings appear both in the Output
Window and in the Error List when you build the project.
In the Error List, you can press F1 on the highlighted error to go to its documentation
topic.
See also
Create a project from existing code
Set C++ compiler and build properties in Visual Studio
Custom build steps and build events
Reference libraries and components at build time
Organize project output files
Projects and build systems
Microsoft C++ porting and upgrade guide
Set compiler and build properties
Article • 03/20/2024
In the IDE, properties expose the information needed to build a project. This information
includes the application name, extension (such as DLL, LIB, EXE), compiler options, linker
options, debugger settings, custom build steps, and many other things. Typically, you
use property pages to view and modify these properties. To access the property pages,
choose Project > project-name Properties from the main menu, or right-click on the
project node in Solution Explorer and choose Properties.
Default properties
When you create a project, the system assigns values for various properties. The defaults
vary somewhat depending on the kind of project and what options you choose in the
app wizard. For example, an ATL project has properties related to MIDL files, but these
properties are absent in a basic console application. The default properties are shown in
the General pane in the Property Pages:
Applying properties to build configurations
and target platforms
Some properties, such as the application name, apply to all build variations and target
platforms, whether it's a debug or release build. But most properties are configuration￾dependent. To generate the correct code, the compiler has to know both the specific
platform the program runs on and which specific compiler options to use. So when you
set a property, it's important to pay attention to which configuration and platform the
new value should apply to. Should it apply only to Debug Win32 builds, or should it also
apply to Debug ARM64 and Debug x64? For example, the Optimization property, by
default, is set to Maximize Speed (/O2) in a Release configuration, but is disabled in the
Debug configuration.
You can always see and change the configuration and platform a property value should
apply to. The following illustration shows the property pages with the configuration and
platform information controls at the top. When the Optimization property is set here, it
only applies to Debug Win32 builds, the currently active configuration, as shown by the
red arrows.
The following illustration shows the same project property page, but the configuration
has been changed to Release. Note the different value for the Optimization property.
Also note that the active configuration is still Debug. You can set properties for any
configuration here; it doesn't have to be the active one.
Target platforms
Target platform refers to the kind of device and operating system that the executable
will run on. You can build a project for more than one platform. The available target
platforms for C++ projects depend on the kind of project. They include but aren't
limited to Win32, x64, ARM, ARM64, Android, and iOS. The x86 target platform that you
might see in Configuration Manager is identical to Win32 in native C++ projects.
Win32 means 32-bit Windows and x64 means 64-bit Windows. For more information
about these two platforms, see Running 32-bit applications.
The Any CPU target platform value that you might see in Configuration Manager has
no effect on native C++ projects. It's only relevant for C++/CLI and other .NET project
types. For more information, see /CLRIMAGETYPE (Specify Type of CLR Image).
For more information about setting properties for a Debug build, see:
Project settings for a C++ debug configuration
Debugger Settings and Preparation
Debugging Preparation: Visual C++ Project Types
Specify symbol (.pdb) and source files in the Visual Studio debugger
C++ compiler and linker options
C++ compiler and linker options are located under the C/C++ and Linker nodes in the
left pane under Configuration Properties. These options translate directly to command￾line options that are passed to the compiler. To read documentation about a specific
option, select the option in the center pane and press F1. Or, you can browse
documentation for all the options at MSVC compiler options and MSVC linker options.
The Property Pages dialog box shows only the property pages that are relevant to the
current project. For example, if the project doesn't have an .idl file, the MIDL property
page isn't displayed. For more information about the settings on each property page,
see Property Pages (C++).
Directory and path values
MSBuild supports the use of compile-time constants for certain string values, such as
include directories and paths, called macros. A macro can refer to a value that's defined
by Visual Studio or the MSBuild system, or to a user-defined value. Macros look like
$(macro-name) or %(item-macro-name) . They're exposed in the property pages, where
you can refer to and modify them by using the Property Editor. Use macros instead of
hard-coded values such as directory paths. Macros make it easier to share property
settings between machines and between versions of Visual Studio. And, you can better
ensure that your project settings participate correctly in property inheritance.
The following illustration shows the property pages for a Visual Studio C++ project. In
the left pane, the VC++ Directories rule is selected, and the right pane lists the
properties that are associated with that rule. The property values are often macros, such
as $(VC_SourcePath) :
You can use the Property Editor to view the values of all available macros.
Predefined macros
Global macros:
Global macros apply to all items in a project configuration. A global macro has the
syntax $(name) . An example of a global macro is $(VCInstallDir) , which stores the
root directory of your Visual Studio installation. A global macro corresponds to a
PropertyGroup in MSBuild.
Item macros
Item macros have the syntax %(name) . For a file, an item macro applies only to that
file—for example, you can use %(AdditionalIncludeDirectories) to specify include
directories that apply only to a particular file. This kind of item macro corresponds
to an ItemGroup metadata in MSBuild. When used in the context of a project
configuration, an item macro applies to all files of a certain type. For example, the
C/C++ Preprocessor Definitions configuration property can take a %
(PreprocessorDefinitions) item macro that applies to all .cpp files in the project.
This kind of item macro corresponds to an ItemDefinitionGroup metadata in
MSBuild. For more information, see Item Definitions.
User-defined macros
You can create user-defined macros to use as variables in project builds. For example,
you could create a user-defined macro that provides a value to a custom build step or a
custom build tool. A user-defined macro is a name/value pair. In a project file, use the
$(name) notation to access the value.
A user-defined macro is stored in a property sheet. If your project doesn't already
contain a property sheet, you can create one by following the steps under Share or
reuse Visual Studio project settings.
To create a user-defined macro
1. Open the Property Manager window. (On the menu bar, choose View > Property
Manager or View > Other Windows > Property Manager.) Open the shortcut
menu for a property sheet (its name ends in .user ) and then choose Properties.
The Property Pages dialog box for that property sheet opens.
2. In the left pane of the dialog box, select User Macros. In the right pane, choose the
Add Macro button to open the Add User Macro dialog box.
3. In the dialog box, specify a name and value for the macro. Optionally, select the
Set this macro as an environment variable in the build environment check box.
Property Editor
You can use the Property Editor to modify certain string properties and select macros as
values. To access the Property Editor, select a property on a property page and then
choose the down arrow button on the right. If the drop-down list contains <Edit>, then
you can choose it to display the Property Editor for that property.
In the Property Editor, you can choose the Macros button to view the available macros
and their current values. The following illustration shows the Property Editor for the
Additional Include Directories property after the Macros button was chosen. When the
Inherit from parent or project defaults check box is selected and you add a new value,
it's appended to any values that are currently being inherited. If you clear the check box,
your new value replaces the inherited values. In most cases, leave the check box
selected.
Add an include directory to the set of default
directories
When you add an include directory to a project, it's important not to override all the
default directories. The correct way to add a directory is to append the new path, for
example " C:\MyNewIncludeDir\ ", and then to Append the $(IncludePath) macro to the
property value.
Quickly browse and search all properties
The All Options property page (under the Configuration Properties > C/C++ node in
the Property Pages dialog box) provides a quick way to browse and search the
properties that are available in the current context. It has a special search box and a
simple syntax to help you filter results:
No prefix:
Search in property names only (case-insensitive substring).
' / ' or ' - ':
Search only in compiler switches (case-insensitive prefix)
v :
Search only in values (case-insensitive substring).
Set environment variables for a build
The MSVC compiler (cl.exe) recognizes certain environment variables, specifically LIB ,
LIBPATH , PATH , and INCLUDE . When you build with the IDE, the properties that are set in
the VC++ Directories Property Page are used to set those environment variables. If LIB ,
LIBPATH , and INCLUDE values have already been set, for example by a Developer
Command Prompt, they're replaced with the values of the corresponding MSBuild
properties. The build then prepends the value of the VC++ Directories executable
directories property to PATH . You can set a user-defined environment variable by
creating a user-defined macro and then checking the box that says Set this macro as an
environment variable in the build environment.
Set environment variables for a debugging
session
In the left pane of the project's Property Pages dialog box, expand Configuration
Properties and then select Debugging.
In the right pane, modify the Environment or Merge Environment project settings and
then choose the OK button.
In this section
Share or reuse Visual Studio project settings
How to create a .props file with custom build settings that can be shared or reused.
Project property inheritance
Describes the order of evaluation for the .props , .targets , .vcxproj files, and
environment variables in the build process.
Modify properties and targets without changing the project file
How to create temporary build settings without having to modify a project file.
See also
Visual Studio Projects - C++
.vcxproj and .props file structure
Property page XML files
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
Share or reuse Visual Studio project
settings
Article • 02/08/2022
To create a custom group of settings that you can share with others or reuse in multiple
projects, use Property Manager to create a property sheet (a .props file) to store the
settings for each kind of project that you want to be able to reuse or share with others.
Using property sheets are far less error-prone than other ways of creating "global"
settings.
） Important
The problem with *.user files
Past versions of Visual Studio used global property sheets that had a .user file
name extension and were located in the \
<userprofile>\AppData\Local\Microsoft\MSBuild\v4.0\ folder. We no longer
recommend these files because they set properties for project configurations on a
per-user, per-computer basis. Such "global" settings can interfere with builds,
especially when you are targeting more than one platform on your build computer.
For example, if you have both an MFC project and Windows Phone project, the
.user properties would be invalid for one of them. Reusable property sheets are
more flexible and more robust.
Although .user files are still installed by Visual Studio and participate in property
inheritance, they're empty by default. The best practice is to delete any reference to
them in Property Manager to ensure that your projects operate independently of
any per-user, per-computer settings. This practice is important to ensure correct
behavior in a SCC (source code control) environment.
To display Property Manager, on the menu bar, choose View > Property Manager or
View > Other Windows > Property Manager, depending on your settings.
If you want to apply a common, frequently used set of properties to multiple projects,
you can use Property Manager to capture them in a reusable property sheet file, which
by convention has a .props file name extension. You can apply the sheet (or sheets) to
new projects so you don't have to set those properties from scratch.
Under each configuration node, you see nodes for each property sheet that applies to
that configuration. The system adds property sheets that set common values based on
options you choose in the app wizard when you create the project. Right-click any node
and choose Properties to see the properties that apply to that node. All the property
sheets are imported automatically into the project's primary property sheet
( ms.cpp.props ) and are evaluated in the order they appear in Property Manager. You can
move them to change the evaluation order. Property sheets that are evaluated later
override the values in previously evaluated sheets. For more information about the order
of evaluation in the .vcxproj file, the .props and .targets files, environment variables,
and the command line, see Project property inheritance.
If you choose Add New Project Property Sheet and then select, for example, the
MyProps.props property sheet, a property page dialog box appears. Notice that it
applies to the MyProps property sheet; any changes you make are written to the sheet,
not to the project file (.vcxproj).
Properties in a property sheet are overridden if the same property is set directly in the
.vcxproj file.
You can import a property sheet as often as required. Multiple projects in a solution can
inherit settings from the same property sheet, and a project can have multiple sheets. A
property sheet itself can inherit settings from another property sheet.
You can also create a common property sheet for multiple configurations. To create a
property sheet for each configuration, open the shortcut menu for one of them, choose
Add Existing Property Sheet, and then add the other sheets. However, if you use a
common property sheet, properties you set for all configurations that the sheet applies
to. The IDE doesn't show which projects or other property sheets inherit from a given
property sheet.
In large solutions that have many projects, it can be useful to create a common property
sheet for all the projects in the solution. Create the property sheet as usual. Use
Property Manager to add that property sheet to each project in the solution. If
necessary at the project level, you can add another property sheet to set project-specific
values.
） Important
A .props file by default does not participate in source control because it isn't
created as a project item. You can manually add the file as a solution item if you
want to include it in source control.
To create a property sheet
1. On the menu bar, choose View > Property Manager or View > Other Windows >
Property Manager. The Property Manager opens.
2. To define the scope of the property sheet, select the item to which it applies. This
item can be a particular configuration, or another property sheet. Open the
shortcut menu for this item and then choose Add New Project Property Sheet.
Specify a name and location.
3. In Property Manager, open the new property sheet and then set the properties
you want to include.
Property inheritance in Visual Studio
projects
Article • 08/03/2021
The Visual Studio native project system is based on MSBuild. MSBuild defines file
formats and rules for building projects of any kind. It manages most of the complexity
of building for multiple configurations and platforms. You'll find it useful to understand
how it works. That's especially important if you want to define custom configurations.
Or, to create reusable sets of properties that you can share and import into multiple
projects.
The .vcxproj file, .props files and .targets files
Project properties are stored in several files. Some are stored directly in the .vcxproj
project file. Others come from other .targets or .props files that the project file
imports and which supply default values. You'll find the Visual Studio project files in a
locale-specific folder under the base directory, %VSINSTALLDIR%MSBuild\Microsoft\VC\
<version> . The <version> is specific to the version of Visual Studio. It's v160 for Visual
Studio 2019.
Properties are also stored in any custom .props files that you might add to your own
project. We highly recommend that you NOT edit those files manually. Instead, use the
property pages in the IDE to modify all properties, especially the ones that participate in
inheritance, unless you have a deep understanding of MSBuild and .vcxproj files.
As shown earlier, the same property for the same configuration may be assigned a
different value in these different files. When you build a project, the MSBuild engine
evaluates the project file and all the imported files in a well-defined order that's
described later. As each file is evaluated, any property values defined in that file will
override the existing values. Any values that aren't specified are inherited from files that
were evaluated earlier. When you set a property with property pages, it's also important
to pay attention to where you set it. If you set a property to "X" in a .props file, but the
property is set to "Y" in the project file, then the project will build with the property set
to "Y". If the same property is set to "Z" on a project item, such as a .cpp file, then the
MSBuild engine will use the "Z" value.
Here's the basic inheritance tree:
1. Default settings from the MSBuild CPP Toolset (the Microsoft.Cpp.Default.props
file in the base directory, which is imported by the .vcxproj file.)
2. Property sheets
3. .vcxproj file. (This file can override the default and property sheet settings.)
4. Items metadata
 Tip
On a property page, a property in bold is defined in the current context. A property
in normal font is inherited.
View an expanded project file with all imported
values
Sometimes it's useful to view the expanded file to determine how a given property value
is inherited. To view the expanded version, enter the following command at a Visual
Studio command prompt. (Change the placeholder file names to the one you want to
use.)
msbuild /pp:temp.txt myapp.vcxproj
Expanded project files can be large and difficult to understand unless you're familiar
with MSBuild. Here's the basic structure of a project file:
1. Fundamental project properties, which aren't exposed in the IDE.
2. Import of Microsoft.cpp.default.props , which defines some basic, toolset￾independent properties.
3. Global Configuration properties (exposed as PlatformToolset and Project default
properties on the Configuration General page. These properties determine which
toolset and intrinsic property sheets are imported in Microsoft.cpp.props in the
next step.
4. Import of Microsoft.cpp.props , which sets most of the project defaults.
5. Import of all property sheets, including .user files. These property sheets can
override everything except the PlatformToolset and Project default properties.
6. The rest of the project configuration properties. These values can override what
was set in the property sheets.
7. Items (files) together with their metadata. These items are always the last word in
MSBuild evaluation rules, even if they occur before other properties and imports.
For more information, see MSBuild Properties.
Build configurations
A configuration is just an arbitrary group of properties that are given a name. Visual
Studio provides Debug and Release configurations. Each sets various properties
appropriately for a debug build or release build. You can use the Configuration
Manager to define custom configurations. They're a convenient way to group properties
for a specific flavor of build.
To get a better idea of build configurations, open Property Manager. You can open it by
choosing View > Property Manager or View > Other Windows > Property Manager,
depending on your settings. Property Manager has nodes for each configuration and
platform pair in the project. Under each of these nodes are nodes for property sheets
( .props files) that set some specific properties for that configuration.
For example, you can go to the General pane in the Property Pages. Change the
Character Set property to "Not Set" instead of "Use Unicode", and then click OK. The
Property Manager now shows no Unicode Support property sheet. It's removed for the
current configuration, but it's still there for other configurations.
For more information about Property Manager and property sheets, see Share or reuse
Visual Studio C++ project settings.
 Tip
The .user file is a legacy feature. We recommend that you delete it, to keep
properties correctly grouped according to configuration and platform.
How to: Modify C++ project properties
and targets without changing the
project file
Article • 07/28/2023
You can override project properties and targets from the MSBuild command prompt
without changing the project file. This is useful when you want to apply some properties
temporarily or occasionally. It assumes some knowledge of MSBuild. For more
information, see MSBuild.
） Important
You can use the XML Editor in Visual Studio, or any text editor, to create the .props
or .targets file. Don't use the Property Manager in this scenario because it adds the
properties to the project file.
To override project properties:
1. Create a .props file that specifies the properties you want to override.
2. From the command prompt: set
ForceImportBeforeCppTargets="C:\sources\my_props.props"
To override project targets:
1. Create a .targets file with their implementation or a particular target
2. From the command prompt: set ForceImportAfterCppTargets
="C:\sources\my_target.targets"
You can also set either option on the msbuild command line by using the /p: option:
Windows Command Prompt
msbuild myproject.sln
/p:ForceImportBeforeCppTargets="C:\sources\my_props.props"
msbuild myproject.sln
/p:ForceImportAfterCppTargets="C:\sources\my_target.targets"
Overriding properties and targets in this way is equivalent to adding the following
imports to all .vcxproj files in the solution:
XML
<Import Project="C:\sources\my_props.props" />
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
<Import Project="C:\sources\my_target.targets" />
Clang/LLVM support in Visual Studio
projects
Article • 03/20/2024
You can use Visual Studio 2019 version 16.2 and later with Clang/LLVM to edit, build,
and debug C++ Visual Studio projects (MSBuild) that target Windows or Linux.
Install
For the best IDE support in Visual Studio, we recommend using the latest Clang
compiler tools for Windows. If you don't already have the tools, you can install them by
opening the Visual Studio Installer and choosing C++ Clang tools for Windows under
Desktop development with C++ optional components. You may prefer to use an
existing Clang installation on your machine; if so, choose MSBuild support for LLVM
(clang-cl) toolset.
The Microsoft C++ Standard Library requires at least Clang 8.0.0.
Later versions of Visual Studio provide newer versions of the Clang toolset. The bundled
version of Clang gets updated automatically to stay current with updates in the
Microsoft implementation of the Standard Library. For example, Visual Studio 2019
version 16.11 includes Clang v12.
Configure a Windows project to use Clang
tools
To configure a Visual Studio project to use Clang, right-click on the project node in
Solution Explorer and choose Properties. Typically, you should first choose All
configurations at the top of the dialog. Then, under General > Platform Toolset, choose
LLVM (clang-cl) and then OK.
If you're using the Clang tools that are bundled with Visual Studio, no extra steps are
required. For Windows projects, Visual Studio by default invokes Clang in clang-cl
mode. It links with the Microsoft implementation of the Standard Library. By default,
clang-cl.exe is located in *%VCINSTALLDIR%\Tools\Llvm\bin\* and
*%VCINSTALLDIR%\Tools\Llvm\x64\bin\* .
If you're using a custom Clang installation, you can change the value of the
LLVMInstallDir property. For more information, see Set a custom LLVM location.
Configure a Linux project to use Clang tools
For Linux projects, Visual Studio uses the Clang GCC-compatible frontend. The project
properties and nearly all compiler flags are identical
To configure a Visual Studio Linux project to use Clang:
1. Right-click on the project node in Solution Explorer and choose Properties.
2. Typically, you should first choose All configurations at the top of the dialog.
3. Under General > Platform Toolset, choose Clang for Windows Subsystem for
Linux if you're using Windows Subsystem for Linux (WSL). Choose Clang for
Remote Linux if you're using a remote machine or VM.
4. Press OK.
On Linux, Visual Studio by default uses the first Clang location that it finds in the PATH
environment property. If you're using a custom Clang installation, then either change
the value of the LLVMInstallDir property or else enter the path under Project >
Properties > Configuration Properties > VC++ DIrectories > Executable Directories.
For more information, see Set a custom LLVM location.
To set a custom path to LLVM and set a custom LLVM toolset version for one or more
projects, create a Directory.build.props file. Then, add that file to the root folder of any
project. You can add it to the root solution folder to apply it to all projects in the
solution. The file should look like this example (but use your actual LLVM path and
version number):
XML
Set a custom LLVM location and toolset
<Project>
 <PropertyGroup>
 <LLVMInstallDir>C:\MyLLVMRootDir</LLVMInstallDir>
 <LLVMToolsVersion>15.0.0</LLVMToolsVersion>
 </PropertyGroup>
</Project>
Set a custom LLVM toolset version in the IDE
Starting in Visual Studio 2019 version 16.9, you can set a custom toolset version for
LLVM in Visual Studio. To set this property in a project:
1. Open the project's Property Pages dialog box. For more information, see Set C++
compiler and build properties.
2. Select the Configuration Properties > General property page.
3. Modify the Platform Toolset property to LLVM (clang-cl), if it isn't already set.
Choose Apply to save your changes.
4. Select the Configuration Properties > Advanced property page.
5. Modify the LLVM Toolset Version property to your preferred version, and then
choose OK to save your changes.
The LLVM Toolset Version property only appears when the LLVM platform toolset is
selected.
When you add a Directory.build.props file to a project or solution, the settings appear
as the default in the project Property Pages dialog. However, changes to these
properties in Visual Studio override the settings in the Directory.build.props file.
Set properties, edit, build, and debug
After you have set up a Clang configuration, right-click again on the project node and
choose Reload project. You can now build and debug the project using the Clang tools.
Visual Studio detects that you're using the Clang compiler and provides IntelliSense,
highlighting, navigation, and other editing features. Errors and warnings are displayed in
the Output Window. The project property pages for a Clang configuration are similar to
the ones for MSVC. However, some compiler-dependent features such as Edit and
Continue aren't available for Clang configurations. You can set a Clang compiler or linker
option that isn't available in the property pages. Add it manually in the property pages
under Configuration Properties > C/C++ (or Linker) > Command Line > Additional
Options.
When debugging, you can use breakpoints, memory and data visualization, and most
other debugging features.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
Consuming libraries and components
Article • 03/02/2022
C++ projects often need to call functions or access data in a binary file such as static
library (LIB files), DLL, Windows Runtime component, COM component, or .NET
assembly. In these cases, you have to configure the project so that it can find that binary
at build time. The specific steps depend on the type of your project, the type of the
binary, and whether the binary gets built in the same solution as your project.
Consuming libraries downloaded via vcpkg
To consume a library that you have downloaded by using the vcpkg package manager,
you can ignore the instructions below. For more information, see vcpkg.io .
Consuming static libraries
If your static library project gets built in the same solution:
1. #include the header file(s) for the static library using quotation marks. In a typical
solution, the path starts with ../<library project name> . IntelliSense will help you
find it.
2. Add a reference to the static library project. Right-click on References under the
application project node in Solution Explorer and choose Add Reference.
If the static library isn't part of the solution:
1. Right-click on the application project node in Solution Explorer and then choose
Properties.
2. In the VC++ Directories property page, add the path to the directory that contains
the LIB file to Library Paths. Then, add the path to the library header file(s) to
Include Directories.
3. In the Linker > Input property page, add the name of the LIB file to Additional
Dependencies.
Dynamic link libraries
If the DLL gets built as part of the same solution as the application, follow the same
steps as for a static library.
If the DLL isn't part of the application solution, you need: the DLL file, the header(s) with
prototypes for the exported functions and classes, and a LIB file that provides the
necessary linking information.
1. Copy the DLL to the output folder of your project, or to another folder in the
standard Windows search path for DLLs. For more information, see Dynamic-Link
Library Search Order.
2. Follow steps 1-3 for static libraries to provide the paths to the headers and LIB file.
COM objects
If your native C++ application needs to consume a COM object, and that object is
registered, then all you have to do is call CoCreateInstance and pass in the CLSID of the
object. The system will find it in the Windows Registry and load it. A C++/CLI project can
consume a COM object in the same way. Or, it can consume it by adding a reference to
it from the Add References > COM list and consuming it through its Runtime callable
wrapper.
.NET assemblies and Windows Runtime
Components
In UWP or C++/CLI projects, you consume .NET assemblies or Windows Runtime
Components by adding a reference to the assembly or component. Under the
References node in a UWP or C++/CLI project, you see references to commonly used
components. Right-click on the References node in Solution Explorer to bring up the
Reference Manager and browse through the components available on the system.
Choose the Browse button to navigate to any folder that contains a custom component.
Because .NET assemblies and Windows Runtime components contain built-in type
information, you can view their methods and classes by right-clicking and choosing
View in Object Browser.
Reference properties
Each kind of reference has properties. You can view the properties by selecting the
reference in Solution Explorer and pressing Alt + Enter, or else right-clicking and
choosing Properties. Some properties are read-only and some are modifiable. However,
typically you don't have to manually modify these properties.
ActiveX reference properties
ActiveX reference properties are available only for references to COM components.
These properties get displayed only when you select a COM component in the
References pane. The properties aren't modifiable.
Control Full Path
Displays the directory path of the referenced control.
Control GUID
Displays the GUID for the ActiveX control.
Control Version
Displays the version of the referenced ActiveX control.
Type Library Name
Displays the name of the referenced type library.
Wrapper Tool
Displays the tool that's used to build the interop assembly from the referenced
COM library or ActiveX control.
Assembly reference properties (C++/CLI)
Assembly reference properties are available only for references to .NET Framework
assemblies in C++/CLI projects. These properties get displayed only when you select a
.NET Framework assembly in the References pane. The properties aren't modifiable.
Relative Path
Displays the relative path from the project directory to the referenced assembly.
Build properties
The following properties are available on various kinds of references. They enable you to
specify how to build with references.
Copy Local
Specifies whether to automatically copy the referenced assembly to the target
location during a build.
Copy Local Satellite Assemblies (C++/CLI)
Specifies whether to automatically copy the satellite assemblies of the referenced
assembly to the target location during a build. Only used if Copy Local is true .
Reference Assembly Output
Specifies that this assembly gets used in the build process. If true , the assembly
gets used on the compiler command line during the build.
Project-to-project reference properties
The following properties define a project-to-project reference from the project that's
selected in the References pane to another project in the same solution. For more
information, see Managing references in a project.
Link Library Dependencies
When this property is True, the project system links the LIB files that the
independent project produces into the dependent project. Typically, you'll specify
True.
Project Identifier
Uniquely identifies the independent project. The property value is an internal
system GUID that isn't modifiable.
Use Library Dependency Inputs
When this property is False, the project system won't link the OBJ files for the
library that the independent project produces into the dependent project. That's
why this value disables incremental linking. Typically, you'll specify False because
building the application can take a long time if there are many independent
projects.
Read-only reference properties (COM & .NET)
The following properties exist on COM and .NET assembly references, and aren't
modifiable.
Assembly Name
Displays the assembly name for the referenced assembly.
Culture
Displays the culture of the selected reference.
Description
Displays the description of the selected reference.
Full Path
Displays the directory path of the referenced assembly.
Identity
For the .NET Framework assemblies, displays the full path. For COM components,
displays the GUID.
Label
Displays the label of the reference.
Name
Displays the name of the reference.
Public Key Token
Displays the public key token used to identify the referenced assembly.
Strong Name
true if the referenced assembly has a strong name. A strong named assembly has
a unique version.
Version
Displays the version of the referenced assembly.
See also
C++ project property page reference
Set C++ compiler and build properties in Visual Studio
How to: Organize Project Output Files
for Builds
Article • 08/03/2021
This topic describes best practices for organizing project output files. Build errors can
occur when you set up project output files incorrectly. This topic also outlines the
advantages and disadvantages of each alternative for organizing your project output
files.
Referencing CLR Assemblies
To reference assemblies with #using
1. You can reference an assembly directly from your code by using the #using
directive, such as #using <System.Data.dll> . For more information, see #using
Directive.
The file specified can be a .dll, .exe, .netmodule, or .obj, as long as it is in MSIL. The
referenced component can be built in any language. Using this option, you will
have access to IntelliSense since the metadata will be extracted from the MSIL. The
file in question must be in the path for the project; otherwise, the project will not
compile and IntelliSense will not be available. An easy way to determine whether
the file is in the path is to right-click on the #using line and choose the Open
document command. You will be notified if the file cannot be found.
If you do not want to put the full path to the file, you can use the /AI compiler
option to edit the search path for #using references. For more information, see /AI
(Specify Metadata Directories).
To reference assemblies with /FU
1. Instead of referencing an assembly directly from a code file as described above,
you can use the /FU compiler option. The advantage to this method is that you do
not have to add a separate #using statement to every file that references a given
assembly.
To set this option, open the Properties Pages for the project. Expand the
Configuration Properties node, and then expand the C/C++ node and select
Advanced. Add the desired assemblies next to Force #using. For more information,
see /FU (Name Forced #using File).
To reference assemblies with Add New Reference
1. This is the easiest way to use CLR assemblies. First, make sure the project is
compiled with the /clr compiler option. Then, right click the project from the
Solution Explorer and select Add, References. The Property Pages dialog will
appear.
2. From the Property Pages dialog, select Add New Reference. A dialog will appear
listing all .NET, COM, and other assemblies available in the current project. Select
the desired assembly and click OK.
Once a project reference is set, the corresponding dependencies are automatically
handled. In addition, since metadata is part of an assembly, there is no need to
add a header file or prototype the elements that are being used from managed
assemblies.
Referencing Native DLLs or Static Libraries
To reference native DLLs or static libraries
1. Reference the appropriate header file in your code using the #include directive.
The header file must be in the include path or part of the current project. For more
information, see #include Directive (C/C++).
2. You can also set project dependencies. Setting project dependencies guarantees
two things. First, it ensures that projects are built in the right order so that a
project can always find the dependent files it needs. Second, it implicitly adds the
dependent project's output directory to the path so that files can be found easily
at link-time.
3. To deploy the application, you will need to place the DLL in an appropriate place.
This can be one of the following:
a. The same path as the executable.
b. Anywhere in the system path (the path environment variable).
c. In the side-by-side assembly. For more information, see Building C/C++ Side￾by-side Assemblies.
Working with Multiple Projects
By default, projects are built such that all output files are created in a subdirectory of the
project directory. The directory is named based on the build configuration (e.g. Debug
or Release). In order for sibling projects to refer to each other, each project must
explicitly add the other project output directories to their path in order for linking to
succeed. This is done automatically when you set the project dependencies. However, if
you do not use dependencies, you must carefully handle this because builds can
become very difficult to manage. For example, when a project has Debug and Release
configurations, and it includes an external library from a sibling project, it should use a
different library file depending on which configuration is being built. Thus, hard-coding
these paths can be tricky.
All essential output files (such as executables, incremental linker files, and PDB files) are
copied into a common solution directory. Thus, when working with a solution that
contains a number of C++ projects with equivalent configurations, all the output files
are centralized for simplified linking and deployment. You can be sure that their
application/library will work as expected if they keep those files together (since the files
are guaranteed to be in the path).
The location of output files can be a major issue when deploying to a production
environment. While running projects in the IDE, the paths to included libraries are not
necessarily the same as in the production environment. For example, if you have #using
"../../lib/debug/mylib.dll" in your code but then deploy mylib.dll into a different
relative position, the application will fail at runtime. To prevent this, you should avoid
using relative paths in #include statements in your code. It is better to ensure that the
necessary files are in the project build path and similarly ensuring that the
corresponding production files are properly placed.
How to specify where output files go
1. The location of project output settings can be found in the project's Property
Pages. Expand the node next to Configuration Properties and select General. The
output location is specified next to Output Directory. For more information, see
General Property Page (Project).
See also
C++ project types in Visual Studio
Understanding Custom Build Steps and
Build Events
Article • 08/03/2021
From within the Visual C++ development environment, there are three basic ways to
customize the build process:
Custom Build Steps
A custom build step is a build rule associated with a project. A custom build step
can specify a command line to execute, any additional input or output files, and a
message to display. For more information, see How to: Add a Custom Build Step to
MSBuild Projects.
Custom Build Tools
A custom build tool is a build rule associated with one or more files. A custom
build step can pass input files to a custom build tool, which results in one or more
output files. For example, the help files in an MFC application are built with a
custom build tool. For more information, see How to: Add Custom Build Tools to
MSBuild Projects and Specifying Custom Build Tools.
Build Events
Build events let you customize a project's build. There are three build events: pre￾build, pre-link, and post-build. A build event lets you specify an action to occur at a
specific time in the build process. For example, you could use a build event to
register a file with regsvr32.exe after the project finishes building. For more
information, see Specifying Build Events.
Troubleshooting Build Customizations can help you ensure that your custom build steps
and build events run as expected.
The output format of a custom build step or build event can also enhance the usability
of the tool. For more information, see Formatting the Output of a Custom Build Step or
Build Event.
For each project in a solution, build events and custom build steps run in the following
order along with other build steps:
1. Pre-Build event
2. Custom build tools on individual files
3. MIDL
4. Resource compiler
5. The C/C++ compiler
6. Pre-Link event
7. Linker or Librarian (as appropriate)
8. Manifest Tool
9. BSCMake
10. Custom build step on the project
11. Post-Build event
The custom build step on the project and a post-build event run sequentially after all
other build processes finish.
In this section
Specify Custom Build Tools
Specify Build Events
Troubleshoot Build Customizations
Format the Output of a Custom Build Step or Build Event
See also
Visual Studio Projects - C++
Common macros for build commands and properties
Specify custom build tools
Article • 08/03/2021
A custom build tool provides the build system with the information it needs to build
specific input files. A custom build tool specifies a command to run, a list of input files, a
list of output files that are generated by the command, and an optional description of
the tool.
For general information about custom build tools and custom build steps, see
Understanding Custom Build Steps and Build Events.
To specify a custom build tool
1. Open the project's Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Choose Configuration Properties to enable the Configuration box. In the
Configuration box, select the configuration for which you want to specify a custom
build tool.
3. In Solution Explorer, select the input file for the custom build tool.
If the Custom Build Tool folder does not appear, the file extension of the file you
selected is associated with a default tool. For example, the default tool for .c and
.cpp files is the compiler. To override a default tool setting, in the Configuration
Properties node, in the General folder, in the Item Type property, choose Custom
Build Tool. Choose Apply and the Custom Build Tool node is displayed.
4. In the Custom Build Tool node, in the General folder, specify the properties
associated with the custom build tool:
In Additional Dependencies, specify any additional files beyond the one for
which the custom build tool is being defined (the file associated with the
custom build tool is implicitly considered an input to the tool). Having
additional input files is not a requirement for a custom build tool. If you have
more than one additional input, separate them with semicolons.
If an Additional Dependencies file's date is later than the input file, then the
custom build tool is run. If all of the Additional Dependencies files are older
than the input file, and the input file is older than the Outputs property file,
then the custom build tool is not run.
For example, suppose you have a custom build tool that takes MyInput.x as
input and generates MyInput.cpp, and that MyInput.x includes a header file,
MyHeader.h. You can specify MyHeader.h as an input dependency to
MyInput.x, and the build system will build MyInput.cpp when it is out-of-date
with respect to MyInput.x or MyHeader.h.
Input dependencies can also ensure that your custom build tools run in the
order you need them to. In the preceding example, suppose that MyHeader.h
is actually the output of a custom build tool. Because MyHeader.h is a
dependency of MyInput.x, the build system will first build Myheader.h before
running the custom build tool on MyInput.x.
In Command Line, specify a command as if you were specifying it at the
command prompt. Specify a valid command or batch file, and any required
input or output files. Specify the call batch command before the name of a
batch file to guarantee that all subsequent commands are executed.
Multiple input and output files can be specified symbolically with MSBuild
macros. For information on how to specify the location of files, or the names
of sets of files, see Common macros for build commands and properties.
Because the '%' character is reserved by MSBuild, if you specify an
environment variable replace each % escape character with the %25
hexadecimal escape sequence. For example, replace %WINDIR% with
%25WINDIR%25. MSBuild replaces each %25 sequence with the % character
before it accesses the environment variable.
In Description, enter a descriptive message about this custom build tool. The
message is printed to the Output window when the build system processes
this tool.
In Outputs, specify the name of the output file. This is a required entry;
without a value for this property, the custom build tool will not run. If a
custom build tool has more than one output, separate file names with a
semicolon.
The name of the output file should be the same as it is specified in the
Command Line property. The project build system will look for the file and
check its date. If the output file is older than the input file or if the output file
is not found, the custom build tool is run. If all of the Additional
Dependencies files are older than the input file, and the input file is older
than the file specified in the Outputs property, the custom build tool is not
run.
If you want the build system to operate on an output file generated by the custom build
tool, you must manually add it to the project. The custom build tool will update the file
during the build.
Example
Assume that you want to include a file named parser.l in your project. You have a lexical
analyzer, lexer.exe, on your executable path. You want to use it to process parser.l to
produce a .c file that has the same base name (parser.c).
First, add parser.l and parser.c to the project. If the files do not yet exist, add a reference
to the files. Create a custom build tool for parser.l and enter the following in the
Commands property:
lexer %(FullPath) .%(Filename).c
This command runs the lexical analyzer on parser.l and outputs parser.c to the project
directory.
In the Outputs property, enter the following:
.%(Filename).c
When you build the project, the build system compares the timestamps of parser.l and
parser.c. If parser.l is more recent, or if parser.c doesn't exist, the build system runs the
value of the Command Line property to bring parser.c up to date. Since parser.c was
also added to the project, the build system then compiles parser.c.
See also
Common macros for build commands and properties
Troubleshooting Build Customizations
Specifying build events
Article • 08/03/2021
You can use build events to specify commands that run before the build starts, before
the link process, or after the build finishes.
Build events are executed only if the build successfully reaches those points in the build
process. If an error occurs in the build, the post-build event does not occur; if the error
occurs before the linking phase, neither the pre-link nor the post-build event occurs.
Additionally, if no files need to be linked, the pre-link event does not occur. The pre-link
event is also not available in projects that do not contain a link step.
If no files need to be built, no build events occur.
For general information on build events, see Understanding Custom Build Steps and
Build Events.
To specify a build event
1. In Solution Explorer, select the project for which you want to specify the build
event.
2. Open the project's Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
3. In the Build Events folder, select a build event property page.
4. Specify the properties associated with the build event:
In Command Line, specify a command as if you were specifying it at the
command prompt. Specify a valid command or batch file, and any required
input or output files. Specify the call batch command before the name of a
batch file to guarantee that all subsequent commands are executed.
Multiple input and output files can be specified symbolically with MSBuild
macros. For information on how to specify the location of files, or the names
of sets of files, see Common macros for build commands and properties.
Because the '%' character is reserved by MSBuild, if you specify an
environment variable replace each % escape character with the %25
hexadecimal escape sequence. For example, replace %WINDIR% with
%25WINDIR%25. MSBuild replaces each %25 sequence with the % character
before it accesses the environment variable.
In Description, type a description for this event. The description is printed to
the Output window when this event occurs.
In Excluded From Build, specify Yes if you do not want the event to run.
See also
Understanding Custom Build Steps and Build Events
Common macros for build commands and properties
Troubleshooting Build Customizations
Troubleshooting Build Customizations
Article • 08/03/2021
If your custom build steps or events are not behaving as you expect, there are several
things you can do to try to understand what is going wrong.
Make sure that the files your custom build steps generate match the files you
declare as outputs.
If your custom build steps generate any files that are inputs or dependencies of
other build steps (custom or otherwise), make sure that those files are added to
your project. And make sure that the tools that consume those files execute after
the custom build step.
To display what your custom build step is actually doing, add @echo on as the first
command. The build events and build steps are put in a temporary .bat file and run
when the project is built. Therefore, you can add error checking to your build event
or build step commands.
Examine the build log in the intermediate files directory to see what actually
executed. The path and name of the build log is represented by the MSBuild
macro expression, $(IntDir)\$(MSBuildProjectName).log.
Modify your project settings to collect more than the default amount of
information in the build log. On the Tools menu, click Options. In the Options
dialog box, click the Projects and Solutions node and then click the Build and Run
node. Then, in the MSBuild project build log file verbosity box, click Detailed.
Verify the values of any file name or directory macros you are using. You can echo
macros individually, or you can add copy %0 command.bat to the start of your
custom build step, which will copy your custom build step's commands to
command.bat with all macros expanded.
Run custom build steps and build events individually to check their behavior.
See also
Understanding Custom Build Steps and Build Events
Formatting the output of a custom build
step or build event
Article • 03/22/2022
If the output of a custom build step or build event is formatted correctly, users get the
following benefits:
Warnings and errors are counted in the Output window.
Output appears in the Task List window.
Clicking on the output in the Output window displays the appropriate location.
F1 operations are enabled in the Task List window or Output window.
Output format
The format of the output should be:
{ filename ( line-number [ , column-number] ) | tool-name } : [ any-text ] { error |
warning } code-type-and-number : localizable-string [ any-text ]
Where:
{ a | b } is a choice of either a or b,
[ item ] is an optional string or parameter,
text represents a literal.
For example:
C:\sourcefile.cpp(134) : error C2143: syntax error : missing ';' before '}'
LINK : fatal error LNK1104: cannot open file 'some-library.lib'
See also
Understanding custom build steps and build events
How to: Create a C++ Project from
Existing Code
Article • 08/13/2024
In Visual Studio, you can port existing code files into a C++ project using the Create
New Project From Existing Code Files wizard. This wizard creates a project solution that
uses the MSBuild system to manage source files and build configuration. It works best
with relatively simple projects that don't have complex folder hierarchies. The wizard
isn't available in older Express editions of Visual Studio.
Porting existing code files into a C++ project enables the use of native MSBuild project
management features built into the IDE. If you prefer to use your existing build system,
such as nmake makefiles, CMake, or alternatives, you can use the Open Folder or CMake
options instead. For more information, see Open Folder projects for C++ or CMake
projects in Visual Studio. Both options let you use IDE features such as IntelliSense and
Project Properties.
To create a C++ project from existing code
The following instructions assume that Visual Studio is running and is past the start
page. If you are on the Visual Studio start page, choose Continue without code to open
the IDE.
1. On the File menu, select New > Project From Existing Code.
2. The Create New Project from Existing Code Files wizard opens. Choose what type
of project to create from the dropdown: Visual C++, Visual Basic, or C#. Then
choose Next to continue.
3. Specify your project location, the directory for your source files, and the kinds of
files the wizard imports into the new project. Choose Next to continue.
Setting Description
Project file
location
Specifies the directory path of the new project. This location is where the
wizard deposits all the files (and subdirectories) of the new project.
Select Browse to display the Project file location dialog. Navigate to the
right folder and specify the directory that contains the new project.
Project name Specifies the name of the new project. Project files, which have file
extensions such as .vcxproj adopts this name and existing code files keep
their original name.
Add files to the
project from
these folders
Check to set the wizard to copy existing code files from their original
directories (that are specified in the list box below this control) into the
new project.
Check Add Subfolders to specify copying code files from all
subdirectories into the project. The directories are listed in the Folder
column.
- Select Add to display the Add files to the project from this folder
dialog box, to specify directories the wizard searches for existing code
ﾉ Expand table
Setting Description
files.
- Select Remove to delete the directory path selected in the list box.
In the File types to add to the project box, specify the kinds of files that
the wizard adds to the new project based on the given file extensions.
File extensions are preceded with the asterisk wildcard character and are
delimited in the list of file extensions by a semicolon.
Show all files in
Solution
Explorer
Specifies that all files in the new project to be visible and displayed in
the Solution Explorer window. This option is enabled by default.
4. Specify the project settings to use such as the build environment for the new
project and the build settings to match a specific type of new project to generate.
Choose Next to continue.
ﾉ Expand table
Setting Description
Use Visual
Studio
Specifies to use build tools that are included in Visual Studio for building the
new project. This option is selected by default.
Select Project Type to specify the type of project the wizard generates.
Choose Windows application project, Console application project,
Dynamically linked library (DLL) project, or Static library (LIB) project.
Check Add support for ATL to add ATL support to the new project.
Check Add support for MFC to add MFC support to the new project.
Check Add support for the Common Language Runtime to add CLR
programming support to the project. Choose the Common Language
Runtime Support for compliance type, such as Common Language Runtime
(old syntax) for compliance with Managed Extensions for C++ syntax, the
CLR programming syntax before Visual Studio 2005.
Use
external
build
system
Specifies to use build tools that aren't included in Visual Studio for building
the new project. When this option is selected, you can specify build
command lines on the Specify Debug Configuration Settings and Specify
Release Configuration Settings pages.
７ Note
5. Specify the Debug configuration settings to use. Choose Next to continue.
Setting Description
Build command line Specifies the command line that builds the project. Enter the name
of the compiler (plus any switches or arguments) or the build scripts
that you want to use to build the project.
Rebuild command
line
Specifies the command line that rebuilds the new project.
Clean command
line
Specifies the command line to delete support files generated by the
build tools for the project.
Output (for
debugging)
Specifies the directory path of the output files for the Debug
configuration of the project.
Preprocessor
definitions (/D)
Defines preprocessor symbols for the project, see /D (Preprocessor
Definitions).
Include search path
(/I)
Specifies directory paths the compiler searches to resolve file
references passed to preprocessor directives in the project, see /I
(Additional Include Directories).
Forced included
files (/FI)
Specifies header files to process when building the project, see /FI
(Name Forced Include File).
.NET assembly
search path (/AI)
Specifies the directory paths that the compiler searches to resolve
.NET assembly references passed to preprocessor directives in the
project, see /AI (Specify Metadata Directories).
Forced using .NET
assemblies (/FU)
Specifies .NET assemblies to process when building the project, see
/FU (Name Forced #using File).
When the Use External Build System option is checked, the IDE doesn't build
the project, so the /D, /I, /FI, /AI, or /FU options aren't required for
compilation. However, these options must be set correctly in order for
IntelliSense to function properly.
ﾉ Expand table
７ Note
The Build, Rebuild, Clean command line, and Output (for debugging)
settings are only enabled if the Use external build system option is selected
on the Specify Project Settings page.
6. Specify the Release configuration settings to use, these settings are the same as
the Debug configuration settings.
7. Choose Finish to generate the new project.
７ Note
Here you can check Same as Debug configuration to specify that the wizard
will generate Release configuration project settings identical to Debug
configuration project settings. This option is checked by default. All other
options on this page are inactive unless you uncheck this box.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
Open Folder support for C++ build
systems in Visual Studio
Article • 11/07/2022
In Visual Studio 2017 and later, the "Open Folder" feature enables you to open a folder
of source files and immediately start coding with support for IntelliSense, browsing,
refactoring, debugging, and so on. As you edit, create, move, or delete files, Visual
Studio tracks the changes automatically and continuously updates its IntelliSense index.
No .sln or .vcxproj files are loaded; if needed, you can specify custom tasks as well as
build and launch parameters through simple .json files. This feature enables you to
integrate any third-party build system into Visual Studio. For general information about
Open Folder, see Develop code in Visual Studio without projects or solutions.
CMake is integrated in the Visual Studio IDE as a component of the C++ desktop
workload. The workflow for CMake is not identical to the workflow described in this
article. If you are using CMake, see CMake projects in Visual Studio. You can also use
CMake to build Qt projects, or you can use the Qt Visual Studio Extension for either
Visual Studio 2015 or Visual Studio 2017.
To use the Visual Studio IDE with a build system or compiler toolset that is not directly
supported from the main menu select File | Open | Folder or press Ctrl + Shift + Alt +
O. Navigate to the folder that contains your source code files. To build the project,
configure IntelliSense and set debugging parameters, you add three JSON files:
File Description
CppProperties.json Specify custom configuration information for browsing. Create this file, if
needed, in your root project folder. (Not used in CMake projects.)
tasks.vs.json Specify custom build commands. Accessed via the Solution Explorer context
menu item Configure Tasks.
launch.vs.json Specify command line arguments for the debugger. Accessed via the
Solution Explorer context menu item Debug and Launch Settings.
CMake and Qt
Other build systems
For IntelliSense and browsing behavior such as Go to Definition to work correctly, Visual
Studio needs to know which compiler you are using, where the system headers are, and
where any additional include files are located if they are not directly in the folder you
have opened (the workspace folder). To specify a configuration, you can choose Manage
Configurations from the dropdown in the main toolbar:
Visual Studio offers the following default configurations:
If, for example, you choose x64-Debug, Visual Studio creates a file called
CppProperties.json in your root project folder:
JSON
Configure code navigation with
CppProperties.json
{
 "configurations": [
 {
 "inheritEnvironments": [
 "msvc_x64"
This configuration inherits the environment variables of the Visual Studio x64 Developer
Command Prompt. One of those variables is INCLUDE and you can refer to it here by
using the ${env.INCLUDE} macro. The includePath property tells Visual Studio where to
look for all the sources that it needs for IntelliSense. In this case, it says "look in the all
the directories specified by the INCLUDE environment variable, and also all the
directories in the current working folder tree." The name property is the name that will
appear in the dropdown, and can be anything you like. The defines property provides
hints to IntelliSense when it encounters conditional compilation blocks. The
intelliSenseMode property provides some additional hints based on the compiler type.
Several options are available for MSVC, GCC, and Clang.
If you add the MinGW-W64 configuration, the JSON looks this this:
JSON
 ],
 "name": "x64-Debug",
 "includePath": [
 "${env.INCLUDE}",
 "${workspaceRoot}\\**"
 ],
 "defines": [
 "WIN32",
 "_DEBUG",
 "UNICODE",
 "_UNICODE"
 ],
 "intelliSenseMode": "windows-msvc-x64"
 }
 ]
}
７ Note
If Visual Studio seems to be ignoring settings in CppProperties.json, try adding an
exception to your .gitignore file like this: !/CppProperties.json .
Default configuration for MinGW-w64
{
 "configurations": [
 {
 "inheritEnvironments": [
 "mingw_64"
 ],
Note the environments block. It defines properties that behave like environment
variables and are available not only in the CppProperties.json file, but also in the other
configuration files task.vs.json and launch.vs.json. The Mingw64 configuration inherits the
mingw_w64 environment, and uses its INCLUDE property to specify the value for
includePath . You can add other paths to this array property as needed.`
The intelliSenseMode property is set to a value appropriate for GCC. For more
information on all these properties, see CppProperties schema reference.
When everything is working correctly, you will see IntelliSense from the GCC headers
when you hover over a type:
 "name": "Mingw64",
 "includePath": [
 "${env.INCLUDE}",
 "${workspaceRoot}\\**"
 ],
 "intelliSenseMode": "linux-gcc-x64",
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
 "TOOLSET_VERSION": "9.1.0",
 "PATH":
"${env.BIN_ROOT};${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MINGW64_ROOT
}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${env.MINGW64_ROO
T}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_ROOT}\\include\\
c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR}",
 "environment": "mingw_64"
 }
 ]
 }
 ]
}
Enable IntelliSense diagnostics
If you are not seeing the IntelliSense that you expect, you can troubleshoot by going to
Tools > Options > Text Editor > C/C++ > Advanced and setting Enable Logging to
true . To start with, try setting Logging Level to 5, and Logging Filters to 8.
Output is piped to the Output Window and is visible when you choose *Show Output
From: Visual C++ Log. The output contains, among other things, the list of actual include
paths that IntelliSense is trying to use. If the paths do not match the ones in
CppProperties.json, try closing the folder and deleting the .vs subfolder which contains
cached browsing data.
Define build tasks with tasks.vs.json
You can automate build scripts or any other external operations on the files you have in
your current workspace by running them as tasks directly in the IDE. You can configure a
new task by right-clicking on a file or folder and selecting Configure Tasks.
This creates (or opens) the tasks.vs.json file in the .vs folder which Visual Studio creates in
your root project folder. You can define any arbitrary task in this file and then invoke it
from the Solution Explorer context menu. To continue the GCC example, the following
snippet shows a complete tasks.vs.json file with as single task that invokes g++.exe to
build a project. Assume the project contains a single file called hello.cpp.
JSON
The JSON file is placed in the .vs subfolder. To see that folder, click on the Show All Files
button at the top of Solution Explorer. You can run this task by right-clicking on the
{
 "version": "0.2.1",
 "tasks": [
 {
 "taskLabel": "build hello",
 "appliesTo": "/",
 "type": "default",
 "command": "g++",
 "args": [
 "-g",
 "-o",
 "hello",
 "hello.cpp"
 ]
 }
 ]
}
root node in Solution Explorer and choosing build hello. When the task completes you
should see a new file, hello.exe in Solution Explorer.
You can define many kinds of tasks. The following example shows a tasks.vs.json file that
defines a single task. taskLabel defines the name that appears in the context menu.
appliesTo defines which files the command can be performed on. The command property
refers to the COMSPEC environment variable, which identifies the path for the console
(cmd.exe on Windows). You can also reference environment variables that are declared
in CppProperties.json or CMakeSettings.json. The args property specifies the command
line to be invoked. The ${file} macro retrieves the selected file in Solution Explorer.
The following example will display the filename of the currently selected .cpp file.
JSON
After saving tasks.vs.json, you can right-click any .cpp file in the folder, choose Echo
filename from the context menu, and see the file name displayed in the Output window.
For more information, see Tasks.vs.json schema reference.
To customize your program's command line arguments and debugging instructions,
right-click on the executable in Solution Explorer and select Debug and Launch
Settings. This will open an existing launch.vs.json file, or if none exists, it will create a
new file with a set of minimal launch settings. First you are given a choice of what kind
of debug session you want to configure. For debugging a MinGw-w64 project, we
choose C/C++ Launch for MinGW/Cygwin (gdb). This creates a launch configuration
for using gdb.exe with some educated guesses about default values. One of those
default values is MINGW_PREFIX . You can substitute the literal path (as shown below) or
you can define a MINGW_PREFIX property in CppProperties.json:
{
 "version": "0.2.1",
 "tasks": [
 {
 "taskLabel": "Echo filename",
 "appliesTo": "*.cpp",
 "type": "command",
 "command": "${env.COMSPEC}",
 "args": ["echo ${file}"]
 }
 ]
}
Configure debugging parameters with launch.vs.json
JSON
To start debugging, choose the executable in the debug dropdown, then click the green
arrow:
You should see the Initializing Debugger dialog and then an external console window
that is running your program.
For more information, see launch.vs.json schema reference.
You can define launch settings for any executable on your computer. The following
example launches 7za and specifies additional arguments, by adding them to the args
JSON array:
JSON
{
 "version": "0.2.1",
 "defaults": {},
 "configurations": [
 {
 "type": "cppdbg",
 "name": "hello.exe",
 "project": "hello.exe",
 "cwd": "${workspaceRoot}",
 "program": "${debugInfo.target}",
 "MIMode": "gdb",
 "miDebuggerPath": "c:\\msys64\\usr\\bin\\gdb.exe",
 "externalConsole": true
 }
 ]
}
Launching other executables
{
 "version": "0.2.1",
When you save this file, the new configuration appears in the Debug Target dropdown
and you can select it to start the debugger. You can create as many debug
configurations as you like, for any number of executables. If you press F5 now, the
debugger will launch and hit any breakpoint you may have already set. All the familiar
debugger windows and their functionality are now available.
 "defaults": {},
 "configurations": [
 {
 "type": "default",
 "project": "CPP\\7zip\\Bundles\\Alone\\O\\7za.exe",
 "name": "7za.exe list content of helloworld.zip",
 "args": [ "l", "d:\\sources\\helloworld.zip" ]
 }
 ]
}
CppProperties.json reference
Article • 09/20/2022
Open Folder projects that don't use CMake can store project configuration settings for
IntelliSense in a CppProperties.json file. (CMake projects use a CMakeSettings.json file.)
A configuration consists of name/value pairs and defines #include paths, compiler
switches, and other parameters. For more information about how to add configurations
in an Open Folder project, see Open Folder projects for C++. The following sections
summarize the various settings. For a complete description of the schema, navigate to
CppProperties_schema.json, whose full path is given at the top of the code editor when
CppProperties.json is open.
A configuration may have any of the following properties:
Name Description
inheritEnvironments Specifies which environments apply to this configuration.
name The configuration name that will appear in the C++ configuration
dropdown
includePath A comma-separated list of folders that should be specified in the include
path (maps to /I for most compilers)
defines The list of macros that should be defined (maps to /D for most compilers)
compilerSwitches One or more additional switches that can influence IntelliSense behavior
forcedInclude Header to be automatically included in every compilation unit (maps to
/FI for MSVC or -include for clang)
undefines The list of macros to be undefined (maps to /U for MSVC)
intelliSenseMode The IntelliSense engine to be used. You can specify one of the predefined
architecture-specific variants for MSVC, gcc, or Clang.
environments User-defined sets of variables that behave like environment variables in a
command prompt and are accessed with the ${env.VARIABLE} macro.
The code editor shows the available options when you start to type:
Configuration properties
intelliSenseMode values
This list shows the supported values:
windows-msvc-x86
windows-msvc-x64
windows-msvc-arm
windows-msvc-arm64
android-clang-x86
android-clang-x64
android-clang-arm
android-clang-arm64
ios-clang-x86
ios-clang-x64
ios-clang-arm
ios-clang-arm64
windows-clang-x86
windows-clang-x64
windows-clang-arm
windows-clang-arm64
linux-gcc-x86
linux-gcc-x64
linux-gcc-arm
Note: The values msvc-x86 and msvc-x64 are supported for legacy reasons only. Use the
windows-msvc-* variants instead.
Pre-defined Environments
Visual Studio provides the following predefined environments for Microsoft C++ which
map to the corresponding Developer Command Prompt. When you inherit one of these
environments, you can refer to any of the environment variables by using the global
property env with this macro syntax: ${env.VARIABLE} .
Variable Name Description
vsdev The default Visual Studio environment
msvc_x86 Compile for x86 using x86 tools
msvc_x64 Compile for AMD64 using 64-bit tools
msvc_arm Compile for ARM using x86 tools
msvc_arm64 Compile for ARM64 using x86 tools
msvc_x86_x64 Compile for AMD64 using x86 tools
msvc_arm_x64 Compile for ARM using 64-bit tools
msvc_arm64_x64 Compile for ARM64 using 64-bit tools
When the Linux workload is installed, the following environments are available for
remotely targeting Linux and WSL:
Variable Name Description
linux_x86 Target x86 Linux remotely
linux_x64 Target x64 Linux remotely
linux_arm Target ARM Linux remotely
You can optionally use the environments property to define sets of variables in
CppProperties.json either globally or per-configuration. These variables behave like
environment variables in the context of an Open Folder project. You can access them
with the ${env.VARIABLE} syntax from tasks.vs.json and launch.vs.json after they're
defined here. However, they aren't necessarily set as actual environment variables in any
command prompt that Visual Studio uses internally.
Visual Studio 2019 version 16.4 and later: Configuration-specific variables defined in
CppProperties.json are automatically picked up by debug targets and tasks without the
User-defined environments
need to set inheritEnvironments . Debug targets are launched automatically with the
environment you specify in CppProperties.json .
Visual Studio 2019 version 16.3 and earlier: When you consume an environment, then
you have to specify it in the inheritsEnvironments property even if the environment is
defined as part of the same configuration; the environment property specifies the name
of the environment. The following example shows a sample configuration for enabling
IntelliSense for GCC in an MSYS2 installation. Note how the configuration both defines
and inherits the mingw_64 environment, and how the includePath property can access
the INCLUDE variable.
JSON
When you define an "environments" property inside a configuration, it overrides any
global variables that have the same names.
"configurations": [
 {
 "inheritEnvironments": [
 "mingw_64"
 ],
 "name": "Mingw64",
 "includePath ,": [
 "${env.INCLUDE}",
 "${workspaceRoot}\\**",
 ],
 "intelliSenseMode": "linux-gcc-x64",
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
 "TOOLSET_VERSION": "9.1.0",
 "PATH":
"${env.MINGW64_ROOT}\\bin;${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MIN
GW64_ROOT}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${env.MINGW64_ROO
T}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_ROOT}\\include\\
c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR};",
 "environment": "mingw_64"
 }
 ]
 }
 ]
You have access to the following built-in macros inside CppProperties.json :
Macro Description
${workspaceRoot} The full path to the workspace folder
${projectRoot} The full path to the folder where CppProperties.json is placed
${env.vsInstallDir} The full path to the folder where the running instance of Visual Studio is
installed
If your project has an include folder and also includes *windows.h * and other common
headers from the Windows SDK, you may want to update your CppProperties.json
configuration file with the following includes:
JSON
Built-in macros
Example
{
 "configurations": [
 {
 "name": "Windows",
 "includePath": [
 // local include folder
 "${workspaceRoot}\\include",
 // Windows SDK and CRT headers
 "${env.WindowsSdkDir}\\include\\${env.WindowsSDKVersion}\\ucrt",
 "${env.NETFXSDKDir}\\include\\um",
 "${env.WindowsSdkDir}\\include\\${env.WindowsSDKVersion}\\um",
 "${env.WindowsSdkDir}\\include\\${env.WindowsSDKVersion}\\shared",
 "${env.VCToolsInstallDir}\\include"
 ]
 }
 ]
}
７ Note
%WindowsSdkDir% and %VCToolsInstallDir% are not set as global environment
variables. Make sure you start devenv.exe from a Developer Command Prompt that
defines these variables. (Type "developer" in the Windows Start Menu to find a
Developer Command Prompt shortcut.)
Troubleshoot IntelliSense errors
If you aren't seeing the IntelliSense that you expect, you can troubleshoot by going to
Tools > Options > Text Editor > C/C++ > Advanced and setting Enable Logging to
true . To start with, try setting Logging Level to 5, and Logging Filters to 8.
Output is piped to the Output Window and is visible when you choose Show Output
From: Visual C++ Log. The output contains, among other things, the list of actual
include paths that IntelliSense is trying to use. If the paths don't match the ones in
CppProperties.json , try closing the folder and deleting the .vs subfolder that contains
cached browsing data.
To troubleshoot IntelliSense errors caused by missing include paths, open the Error List
tab, and then filter its output to "IntelliSense only" and error code E1696 "cannot open
source file ...".
tasks.vs.json schema reference (C++)
Article • 08/03/2021
To tell Visual Studio how to build your source code in an Open Folder project, add a
tasks.vs.json file. You can define any arbitrary task here and then invoke it from the
Solution Explorer context menu. CMake projects do not use this file because all the
build commands are specified in CMakeLists.txt. For build systems other than CMake,
tasks.vs.json is where you can specify build commands and invoke build scripts. For
general information about using tasks.vs.json, see Customize build and debug tasks for
"Open Folder" development.
A task has a type property which may have one of four values: default , launch , remote ,
or msbuild . Most tasks should use launch unless a remote connection is required.
The default properties are available on all types of tasks:
Property Type Description
taskLabel string (Required.) Specifies the task label used in the user interface.
appliesTo string (Required.) Specifies which files the command can be
performed on. The use of wildcards is supported, for example:
"", ".cpp", "/*.txt"
contextType string Allowed values: "custom", "build", "clean", "rebuild". Determines
where in the context menu the task will appear. Defaults to
"custom".
output string Specifies an output tag to your task.
inheritEnvironments array Specifies a set of environment variables inherited from multiple
sources. You can define variables in files like CMakeSettings.json
or CppProperties.json and make them available to the task
context. Visual Studio 16.4:: Specify environment variables on a
per-task basis using the env.VARIABLE_NAME syntax. To unset a
variable, set it to "null".
passEnvVars boolean Specifies whether or not to include additional environment
variables to the task context. These variables are different from
the ones defined using the envVars property. Defaults to
"true".
Default Properties
When the task type is launch , these properties are available:
Property Type Description
command string Specifies the full path of the process or
script to launch.
args array Specifies a comma-separated list of
arguments passed to the command.
launchOption string Allowed values: "None",
"ContinueOnError","IgnoreError".
Specifies how to proceed with the
command when there are errors.
workingDirectory string Specifies the directory in which the
command will run. Defaults to the
project's current working directory.
customLaunchCommand string Specifies a global scope customization
to apply before executing the command.
Useful for setting environment variables
like %PATH%.
customLaunchCommandArgs string Specifies arguments to
customLaunchCommand. (Requires
customLaunchCommand .)
env Specifies a key-value list
of custom environment
variables. For example,
"myEnv": "myVal"
commands array Specifies a list of commands to invoke in
order.
The following tasks invoke make.exe when a makefile is provided in the folder and the
Mingw64 environment has been defined in CppProperties.json, as shown in
CppProperties.json schema reference:
JSON
Launch properties
Example
 {
 "version": "0.2.1",
These tasks can be invoked from the context menu when you right click on a .cpp file in
Solution Explorer.
Remote tasks are enabled when you install the Linux development with C++ workload
and add a connection to a remote machine by using the Visual Studio Connection
Manager. A remote task runs commands on a remote system and can also copy files to
it.
When the task type is remote , these properties are available:
Property Type Description
remoteMachineName string The name of the remote machine. Must match a
machine name in Connection Manager.
command string The command to send to the remote machine. By
default commands are executed in the $HOME
directory on the remote system.
remoteWorkingDirectory string The current working directory on the remote
machine.
 "tasks": [
 {
 "taskLabel": "gcc make",
 "appliesTo": "*.cpp",
 "type": "launch",
 "contextType": "custom",
 "inheritEnvironments": [
 "Mingw64"
 ],
 "command": "make"
 },
 {
 "taskLabel": "gcc clean",
 "appliesTo": "*.cpp",
 "type": "launch",
 "contextType": "custom",
 "inheritEnvironments": [
 "Mingw64"
 ],
 "command": "make",
 "args": ["clean"]
 }
 ]
}
Remote Properties
Property Type Description
localCopyDirectory string The local directory to copy to the remote machine.
Defaults to the current working directory.
remoteCopyDirectory string The directory on the remote machine into which
localCopyDirectory is copied.
remoteCopyMethod string The method to use for copying. Allowed values:
"none", "sftp", "rsync". rsync is recommended for
large projects.
remoteCopySourcesOutputVerbosity string Allowed values: "Normal","Verbose","Diagnostic".
rsyncCommandArgs string Defaults to "-t --delete".
remoteCopyExclusionList array Comma-separated list of files in localCopyDirectory
to exclude from copy operations.
The following task will appear in the context menu when you right-click on main.cpp in
Solution Explorer. It depends on a remote machine called ubuntu in Connection
Manager. The task copies the current open folder in Visual Studio into the sample
directory on the remote machine and then invokes g++ to build the program.
JSON
Example
{
 "version": "0.2.1",
 "tasks": [
 {
 "taskLabel": "Build",
 "appliesTo": "main.cpp",
 "type": "remote",
 "contextType": "build",
 "command": "g++ main.cpp",
 "remoteMachineName": "ubuntu",
 "remoteCopyDirectory": "~/sample",
 "remoteCopyMethod": "sftp",
 "remoteWorkingDirectory": "~/sample/hello",
 "remoteCopySourcesOutputVerbosity": "Verbose"
 }
 ]
}
MSBuild properties
When the task type is msbuild , these properties are available:
Property Type Description
verbosity string Specifies the MSBuild project build output verbosityAllowed values:
"Quiet", "Minimal", "Normal", "Detailed", "Diagnostic".
toolsVersion string Specifies the toolset version to build the project, for example "2.0",
"3.5", "4.0", "Current". Defaults to "Current".
globalProperties object Specifies a key-value list of the global properties to pass into the
project, for example, "Configuration":"Release"
properties object Specifies a key-value list of additional project only properties.
targets array Specifies the list of targets to invoke, in order, on the project. The
project's default target is used if none are specified.
launch.vs.json schema reference (C++)
Article • 03/02/2022
In Visual Studio 2017 and later versions, you can open and build code from nearly any directory-based
project without requiring a solution or project file. When there's no project or solution file, you can specify
custom build tasks and launch parameters through JSON configuration files. This article describes the
launch.vs.json file, which specifies debugging parameters. For more information about the "Open Folder"
feature, see Develop code in Visual Studio without projects or solutions.
To create the file, right-click on an executable file in Solution Explorer and choose Debug and Launch
Settings. Choose the option that most closely matches your project and then use the following properties
to modify the configuration as needed. For more information on debugging CMake projects, see Configure
CMake debugging sessions.
Property Type Description
args array Specifies the command-line arguments passed to the launched program.
buildConfigurations array A key-value pair that specifies the name of the build mode to apply the
configurations. For example, Debug or Release and the configurations to use
according to the selected build mode.
currentDir string Specifies the full directory path to the Build Target. The directory is detected
automatically unless this parameter is set.
cwd string Full path to the directory on the remote system where the program will run. Defaults
to  "${debugInfo.defaultWorkingDirectory}"
debugType string Specifies the debugging mode according to the type of code (native, managed, or
mixed). The mode is automatically detected unless this parameter is set. Allowed
values: "native" ", "managed" , "mixed" .
env array Specifies a key-value list of custom environment variables. For example: env:
{"myEnv":"myVal"} .
inheritEnvironments array Specifies a set of environment variables inherited from multiple sources. You can
define some variables in files like CMakeSettings.json or CppProperties.json and
make them available to debug context. Visual Studio 16.4: Specify environment
variables on a per-target basis using the env.VARIABLE_NAME syntax. To unset a
variable, set it to "null" .
name string Specifies the name of the entry in the Startup Item dropdown.
noDebug boolean Specifies whether to debug the launched program. The default value for this
parameter is false if not specified.
portName string Specifies the name of port when attaching to a running process.
program string The debug command to execute. Defaults to  "${debugInfo.fullTargetPath}" .
project string Specifies the relative path to the project file. Normally, you don't need to change this
value when debugging a CMake project.
Default properties
Property Type Description
projectTarget string Specifies the optional target invoked when building project . The target must match
the name in the Startup Item dropdown.
stopOnEntry boolean Specifies whether to break a soon as the process is launched and the debugger
attaches. The default value for this parameter is false .
remoteMachine string Specifies the name of the remote machine where the program is launched.
type string Specifies whether the project is a dll or exe Defaults to .exe
Property Type Description
program string Full path to program executable on the remote machine. When using CMake,
the macro ${debugInfo.fullTargetPath} can be used as the value of this field.
processId integer Optional process ID to attach the debugger to.
sourceFileMap object Optional source file mappings passed to the debug engine. Format: { "\
<Compiler source location>": "\<Editor source location>" } or { "\<Compiler
source location>": { "editorPath": "\<Editor source location>",
"useForBreakpoints": true } } . Example: { "/home/user/foo": "C:\\foo" } or
{ "/home/user/foo": { "editorPath": "c:\\foo", "useForBreakpoints": true }
} . For more information, see Source file map options.
additionalProperties string One of the sourceFileMapOptions. (See below.)
MIMode string Indicates the type of MI-enabled console debugger that the MIDebugEngine
will connect to. Allowed values are "gdb" , "lldb" .
args array Command-line arguments passed to the program.
environment array Environment variables to add to the environment for the program. Example: [
{ "name": "squid", "value": "clam" } ] .
targetArchitecture string The architecture of the debuggee. The architecture is detected automatically
unless this parameter is set. Allowed values are x86 , arm , arm64 , mips , x64 ,
amd64 , x86_64 .
visualizerFile string The .natvis file to be used when debugging this process. This option isn't
compatible with GDB pretty printing. See "showDisplayString" if you use this
setting.
showDisplayString boolean When a visualizerFile is specified, showDisplayString will enable the display
string. Turning on this option can slow performance during debugging.
remoteMachineName string The remote Linux machine that hosts gdb and the program to debug. Use the
Connection Manager for adding new Linux machines. When using CMake, the
macro ${debugInfo.remoteMachineName} can be used as the value of this field.
miDebuggerPath string The path to the MI-enabled debugger (such as gdb). When unspecified, it will
search PATH first for the debugger.
miDebuggerServerAddress string Network address of the MI-enabled debugger server to connect to. Example:
"localhost:1234" .
C++ Linux properties
Property Type Description
setupCommands array One or more GDB/LLDB commands to execute to set up the underlying
debugger. Example: "setupCommands": [ { "text": "-enable-pretty-printing",
"description": "Enable GDB pretty printing", "ignoreFailures": true }] . For
more information, see Launch setup commands.
customLaunchSetupCommands array If provided, this value replaces the default commands used to launch a target
with some other commands. For example, use "-target-attach" to attach to a
target process. An empty command list replaces the launch commands with
nothing, which can be useful if the debugger is being provided launch options
as command-line options. Example: "customLaunchSetupCommands": [ { "text":
"target-run", "description": "run target", "ignoreFailures": false }] .
launchCompleteCommand string The command to execute after the debugger is fully set up, to cause the target
process to run. Allowed values are "exec-run", "exec-continue", "None". The
default value is "exec-run".
debugServerPath string Optional full path to debug server to launch. Defaults to null.
debugServerArgs string Optional debug server args. Defaults to null.
filterStderr boolean Search stderr stream for server-started pattern and log stderr to debug output.
Defaults to false .
coreDumpPath string Optional full path to a core dump file for the specified program. Defaults to
null.
externalConsole boolean If true, a console is launched for the debuggee. If false , no console is
launched. The default for this setting is false . This option is ignored in some
cases for technical reasons.
pipeTransport string When present, this value tells the debugger to connect to a remote computer
using another executable as a pipe that will relay standard input/output
between Visual Studio and the MI-enabled debugger (such as gdb). Allowed
values: one or more Pipe Transport Options.
The following macros provide information about the debugging environment. They're useful for
customizing the launch of your app for debugging.
Macro Description Example
addressSanitizerRuntimeFlags Runtime flags used to
customize behavior of the
address sanitizer. Used to set
the environment variable
"ASAN_OPTIONS" .
"env": {"ASAN_OPTIONS":
"${addressSanitizerRuntimeFlags}:anotherFlag=true" }
defaultWorkingDirectory Set to the directory part of
"fullTargetPath" . If the CMake
variable
VS_DEBUGGER_WORKING_DIRECTORY
is defined, then
defaultWorkingDirectory is set
to that value, instead.
"cwd":"${debugInfo.defaultWorkingDirectory}"
debugInfo macros
Macro Description Example
fullTargetPath The full path to the binary
being debugged.
"program": "${debugInfo.fullTargetPath}"
linuxNatvisPath The full windows path to the
VS linux .natvis file. Usually
appears as the value
"visualizerFile" .
parentProcessId The process ID for the current
Visual Studio instance. Used as
a parameter to shellexec.
See pipeTransport example below.
remoteMachineId A unique, numeric identifier for
the connection to the remote
machine. Used as a parameter
to shellexec.
See pipeTransport example below.
remoteWorkspaceRoot Linux path to the remote copy
of the workspace.
Specify file locations on the remote machine. For example:
"args":
["${debugInfo.remoteWorkspaceRoot}/Data/MyInputFile.dat"]
resolvedRemoteMachineName The name of the target remote
machine.
"targetMachine" value in a deployment directive
shellexecPath The path to the shellexec
program that Visual Studio is
using to manage the remote
machine connection.
See pipeTransport example below
tty gdb will redirect input and
output to this device for the
program being debugged.
Used as a parameter to gdb (-
tty).
See pipeTransport example below.
windowsSubsystemPath The full path to the Windows
Subsystem for Linux instance.
The pipeTransport example below shows how to use some of the debugInfo macros defined above:
JSON
"pipeTransport": {
 "pipeProgram": "${debugInfo.shellexecPath}",
 "pipeArgs": [
 "/s",
 "${debugInfo.remoteMachineId}",
 "/p",
 "${debugInfo.parentProcessId}",
 "/c",
 "${debuggerCommand}",
 "--tty=${debugInfo.tty}"
 ],
 "pipeCmd": [
 "/s",
 "${debugInfo.remoteMachineId}",
 "/p",
 "${debugInfo.parentProcessId}",
 "/c",
Used when debugging and deploying an app on a remote machine.
Property Type Description
cwd string The working directory of the target on the remote machine. When using
CMake, the macro ${debugInfo.defaultWorkingDirectory} can be used as the
value of this field. The default value is the directory of the debug
program/command.
deploy string Specifies extra files or directories to deploy. For example:
"deploy": {"sourcePath":"<Full path to source file/directory on host
machine>", "targetPath":"<Full destination path to file/directory on
target machine>"}
deployDirectory string The location on the remote machine where project outputs are automatically
deployed to. Defaults to " C:\Windows Default Deploy Directory\<name of
app>
deployDebugRuntimeLibraries string Specifies whether to deploy the debug runtime libraries for the active
platform. Defaults to "true" if the active configurationType is "Debug"
deployRuntimeLibraries string Specifies whether to deploy the runtime libraries for the active platform.
Defaults to "true" if the active configurationType is "MinSizeRel" ,
"RelWithDebInfo" , or "Release" .
disableDeploy boolean Specifies whether files should be deployed.
remoteMachineName string Specifies the name of the remote ARM64 Windows machine where the
program is launched. May be the server name or the remote machine's IP
address.
authenticationType string Specifies the type of remote connection. Possible values are "windows" and
"none" . The default is "windows" . This value should match the authentication
setting specified on the remote debugger that is running on the remote
machine.
Used with the setupCommands property:
Property Type Description
text string The debugger command to execute.
description string Optional description for the command.
ignoreFailures boolean If true, failures from the command should be ignored. Defaults to false .
 "${debuggerCommand}"
 ]
 }
C++ Windows remote debug and deploy properties
Launch setup commands
Pipe transport options
Used with the pipeTransport property:
Property Type Description
pipeCwd string The fully qualified path to the working directory for the pipe program.
pipeProgram string The fully qualified pipe command to execute.
pipeArgs array Command-line arguments passed to the pipe program to configure the connection.
debuggerPath string The full path to the debugger on the target machine, for example /usr/bin/gdb.
pipeEnv object Environment variables passed to the pipe program.
quoteArgs boolean If individual arguments contain characters (such as spaces or tabs), should it be quoted? If
false , the debugger command will no longer be automatically quoted. Default is true .
Use with the sourceFileMap property:
Property Type Description
editorPath string The location of the source code for the editor to locate.
useForBreakpoints boolean When setting breakpoints, this source mapping should be used. If false , only the
filename and line number is used for setting breakpoints. If true , breakpoints will be set
with the full path to the file and line number only when this source mapping is used.
Otherwise just filename and line number will be used when setting breakpoints. Default
is true .
Source file map options
CMake projects in Visual Studio
Article • 03/20/2024
CMake is a cross-platform, open-source tool for defining build processes that run on
multiple platforms. This article assumes you're familiar with CMake. For more
information about CMake, see the CMake documentation . The CMake tutorial is a
good starting point to learn more.
７ Note
CMake has become more and more integrated with Visual Studio over the past few
releases. To see the documentation for your preferred version of Visual Studio, use
the Version selector control. It's found at the top of the table of contents on this
page.
Visual Studio's native support for CMake enables you to edit, build, and debug CMake
projects on Windows, the Windows Subsystem for Linux (WSL), and remote systems
from the same instance of Visual Studio. CMake project files (such as CMakeLists.txt )
are consumed directly by Visual Studio for the purposes of IntelliSense and browsing.
cmake.exe is invoked directly by Visual Studio for CMake configuration and build.
Installation
C++ CMake tools for Windows is installed as part of the Desktop development with
C++ and Linux Development with C++ workloads. Both C++ CMake tools for
Windows and Linux Development with C++ are required for cross-platform CMake
development.
For more information, see Install the C++ Linux workload in Visual Studio.
IDE integration
When you open a folder containing a CMakeLists.txt file, the following things happen.
Visual Studio adds CMake items to the Project menu, with commands for viewing
and editing CMake scripts.
The Solution Explorer displays the folder structure and files.
Visual Studio runs CMake and generates the CMake cache file ( CMakeCache.txt ) for
the default configuration. The CMake command line is displayed in the Output
Window, along with other output from CMake.
In the background, Visual Studio starts to index the source files to enable
IntelliSense, browsing information, refactoring, and so on. As you work, Visual
Studio monitors changes in the editor and also on disk to keep its index in sync
with the sources.
７ Note
Starting in Visual Studio 2022 version 17.1 Preview 2, if your top-level
CMakeLists.txt exists in a subfolder and not at the root of the workspace, you'll be
prompted whether you'd like to enable CMake integration or not. For more
information, see CMake partial activation.
Once CMake cache generation has succeeded, you can also view your projects
organized logically by targets. Choose the Select View button on the Solution Explorer
toolbar. From the list in Solution Explorer - Views, select CMake Targets View and press
Enter to open the targets view:
Choose the Show All Files button at the top of Solution Explorer to see all the CMake￾generated output in the out/build/<config> folders.
Use the CMakeLists.txt file in each project folder just as you would in any CMake
project. You can specify source files, find libraries, set compiler and linker options, and
specify other build system-related information. For more information on CMake
language services provided by Visual Studio, see Editing CMakeLists.txt files.
Visual Studio uses a CMake configuration file to drive CMake cache generation and
build. For more information, see Configuring CMake projects and Building CMake
projects.
To pass arguments to an executable at debug time, you can use another file called
launch.vs.json . For more information on debugging cross-platform CMake projects in
Visual Studio, see Debugging CMake projects.
Most Visual Studio and C++ language features are supported by CMake projects in
Visual Studio. Examples include:
Edit and Continue for CMake projects
Incredibuild integration for CMake projects
AddressSanitizer support for CMake projects
Clang/LLVM support
７ Note
For other kinds of Open Folder projects, an additional JSON file
CppProperties.json is used. This file is not relevant for CMake projects.
Configuring CMake projects
The CMake configure step generates the project build system. It's equivalent to invoking
cmake.exe from the command line. For more information on the CMake configure step,
see the CMake documentation .
Visual Studio uses a CMake configuration file to drive CMake generation and build.
CMakePresets.json is supported by Visual Studio 2019 version 16.10 or later and is the
recommended CMake configuration file. CMakePresets.json is supported directly by
CMake and can be used to drive CMake generation and build from Visual Studio, from
VS Code, in a Continuous Integration pipeline, and from the command line on Windows,
Linux, and Mac. For more information on CMakePresets.json , see Configure and build
with CMake Presets. CMakeSettings.json is available for customers using an earlier
version of Visual Studio. For more information on CMakeSettings.json , see Customize
CMake build settings.
When you make significant changes to your CMake configuration file or a
CMakeLists.txt file, Visual Studio will automatically run the CMake configure step. You
can invoke the configure step manually: Select Project > Configure Cache from the
toolbar. You can also change your configuration preferences in Tools > Options >
CMake > General.
If the configure step finishes without errors, then the information that's available drives
C++ IntelliSense and language services. It's also used in build and debug operations.
You can also open an existing CMake cache in Visual Studio. For more information, see
Open an existing cache.
Customize configuration feedback and notifications
By default, most configuration messages are suppressed unless there's an error. To see
all messages, select Tools > Options > CMake > Enable verbose CMake diagnostic
output.
You can also disable all CMake cache notifications (gold bars) by deselecting Show
CMake cache notification.
Troubleshooting CMake cache errors
If you need more information about the state of the CMake cache to diagnose a
problem, open the Project main menu or the CMakeLists.txt context menu in Solution
Explorer to run one of these commands:
View CMakeCache.txt opens the CMakeCache.txt file from the build directory in
the editor. Any edits you make here to CMakeCache.txt are wiped out if you clean
the cache. To make changes that persist after you clean the cache, see Customize
CMake settings or Configure and build with CMake Presets.
Delete Cache and Reconfigure deletes the build directory and reconfigures from a
clean cache.
Configure Cache forces the generate step to run even if Visual Studio considers
the environment up to date.
Building CMake projects
The CMake build step builds an already generated project binary tree. It's equivalent to
invoking cmake --build from the command line. For more information on the CMake
build step, see the CMake documentation .
To build a CMake project, you have these choices:
1. In the toolbar, find the Startup Item dropdown. Select the preferred target and
press F5, or choose the Run button on the toolbar. The project automatically
builds first, just like a Visual Studio solution.
2. Right-click on CMake target with CMake Targets View active in the Solution
Explorer and select Build from the context menu.
3. From the main menu, select Build > Build All. Make sure that a CMake target is
already selected in the Startup Item dropdown in the toolbar.
As you would expect, build results are shown in the Output Window and Error List.
CMake build warnings about conversions that may result in data loss such as converting
from a float to an integer, are visible. :::image-end:::
Edit build settings
Visual Studio uses a CMake configuration file to drive CMake builds. CMake
configuration files encapsulate build options like native build tool switches and
environment variables. If CMakePresets.json is your active configuration file, see
Configure and build with CMake Presets. If CMakeSettings.json is your active
configuration file, see Customize CMake build settings. CMakePresets.json is available in
Visual Studio 2019 version 16.10 or later and is the recommended CMake configuration
file.
Debugging CMake projects
All executable CMake targets are shown in the Startup Item dropdown in the toolbar. To
start debugging, select one and press the Debug > Start Debugging button in the
toolbar. In a CMake project, the "Current document" option is only valid for .cpp files.
The Debug or F5 commands first build the project if changes have been made since the
previous build. Changes to the CMake configuration file ( CMakePresets.json or
CMakeSettings.json ) or a CMakeLists.txt causes the CMake cache to be regenerated.
You can customize a CMake debugging session by setting properties in the
launch.vs.json file. To customize debug settings for a specific target, select the target
in the Startup Item dropdown and press Debug > Debug and Launch Settings for
<active-target>. For more information on CMake debugging sessions, see Configure
CMake debugging sessions.
Just My Code for CMake projects
When you build for Windows using the MSVC compiler, CMake projects have support
for Just My Code debugging. To change the Just My Code setting, go to Tools >
Options > Debugging > General.
When you build for Windows with the MSVC compiler, CMake projects have support for
Edit and Continue. Add the following code to your CMakeLists.txt file to enable Edit
and Continue.
Visual Studio allows you to debug a process running on a remote Linux system or WSL
and debug it with the GDB debugger. To get started, select Debug > Attach to
Process..., set the Connection type to SSH, and select your Connection target from the
list of connections in the Connection Manager. Select a process from the list of available
processes and press Attach. GDB must be installed on your Linux machine. For more
information on SSH connections, see the Connection Manager
Edit and Continue for CMake projects
if(MSVC)
 target_compile_options(<target> PUBLIC "/ZI")
 target_link_options(<target> PUBLIC "/INCREMENTAL")
endif()
Attach to a CMake project running on Linux
In Visual Studio 2022 version 17.1 and later, CMake functionality won't be enabled
automatically if your root folder doesn't contain a CMakeLists.txt file. Instead, a dialog
will prompt you on whether you'd like to enable CMake functionality for your project. If
you decline, CMake cache generation won't start and CMake configurations (from
CMakeSettings.json or CMakePresets.json ) won't appear in the configuration dropdown.
If you accept, you'll be taken to a workspace-level configuration file,
CMakeWorkspaceSettings.json (stored in the .vs directory), to specify the folders you'd
like to enable CMake for. (These folders contain your root CMakeLists.txt files).
The accepted properties are:
Property Description
enableCMake Enable Visual Studio's integration for this workspace.
CMake partial activation
ﾉ Expand table
Property Description
sourceDirectory A string or array of strings specifying the directory or directories with
CMakeLists.txt . Macros (such as ${workspaceRoot} ) are allowed. Relative paths
are based on the workspace root. Directories outside of the current workspace
will be ignored.
You can reach CMakeWorkspaceSettings.json through the Project > CMake Workspace
Settings menu command at any time, even if CMake functionality is currently disabled.
When you open an existing CMake cache file ( CMakeCache.txt ), Visual Studio doesn't try
to manage your cache and build tree for you. Your custom or preferred tools have
complete control over how CMake configures your project.
You can add an existing CMake cache to an open project. It's done the same way you'd
add a new configuration. For more information, see our blog post on opening an
existing cache in Visual Studio .
Visual Studio uses the CMake file-based API (in versions 3.14 and later) to populate
the editor with information specific to your project structure. For more information, see
the C++ team blog post on multi-root workspaces and file-based API .
Open an existing cache
７ Note
The default existing cache experience relies on cmake-server , which was removed
from CMake in version 3.20. To continue using existing cache functionality in Visual
Studio 2019 version 16.10 and later, take one of these steps:
Manually install CMake version 3.19 or lower. Then, set the cmakeExecutable
property in your existing cache configuration to use that version of CMake.
In your existing cache configuration, set the cacheGenerationCommand property
to let Visual Studio request the necessary CMake file-based API files. For more
information on that property, see CMakeSettings.json reference.
Use a query file to request the CMake file-based API files when generating
your cache before it's opened in Visual Studio. For query file instructions, see
the next section, Advanced CMake cache troubleshooting.
Advanced CMake cache troubleshooting
Before generating the CMake cache, your custom or preferred tools might need to
create a query file named .cmake/api/v1/query/client-MicrosoftVS/query.json in your
build output folder (the folder that contains CMakeCache.txt ). The query file should
contain this content:
JSON
{"requests":[{"kind":"cache","version":2},{"kind":"cmakeFiles","version":1},
{"kind":"codemodel","version":2}]}
When your custom or preferred tools generate your cache, CMake places files under
.cmake/api/v1/response that Visual Studio uses to populate the editor with information
specific to your project structure.
Editing CMakeLists.txt files
To edit a CMakeLists.txt file, right-click on the file in Solution Explorer and choose
Open. If you make changes to the file, a yellow status bar appears and informs you that
IntelliSense will update. It gives you a chance to cancel the update operation. For
information about CMakeLists.txt , see the CMake documentation .
As soon as you save the file, the configuration step automatically runs again and
displays information in the Output window. Errors and warnings are shown in the Error
List or Output window. Double-click on an error in the Error List to navigate to the
offending line in CMakeLists.txt .
Language services for CMake
Language services for CMake are available in Visual Studio 2019 version 16.5 or later. It
supports code navigation features like Go To Definition, Peek Definition, and Find All
References for CMake variables, functions, and targets in CMake script files. For more
information, see Code Navigation for CMake Scripts .
CMake project manipulation
CMake project manipulation is available in Visual Studio 2019 version 16.5 or later.
Project manipulation enables you to add, remove, and rename source files and targets in
your CMake project without manually editing your CMake scripts. When you add or
remove files from the Solution Explorer, Visual Studio automatically edits your CMake
project. There could be more than one place where it makes sense to add or remove a
reference to a CMake script. If so, Visual Studio asks you where you want to make the
change and displays a preview of the proposed changes. For step-by-step instructions,
see Add, Remove, and Rename Files and Targets in CMake Projects .
IntelliSense for CMake projects
By default, Visual Studio uses the IntelliSense mode that matches the compiler and
target architecture specified by the active CMake configuration.
If CMakePresets.json is your active CMake configuration file, then you can specify
IntelliSense options using intelliSenseMode and intelliSenseOptions in the Visual
Studio Settings vendor map. For more information, see the Visual Studio Settings
vendor map reference.
If CMakeSettings.json is your active CMake configuration file, then you can specify
IntelliSense options using intelliSenseMode in CMakeSettings.json . For more
information, see the CMakeSettings.json reference.
Configure IntelliSense with CMake toolchain files
In Visual Studio 2019 version 16.9 and later, Visual Studio automatically configures
IntelliSense in CMake projects based on CMake variables when you use a CMake
toolchain file. For more information, see Configure IntelliSense with CMake Toolchain
Files .
Vcpkg integration
CMake projects opened in Visual Studio integrate with vcpkg, a cross-platform C/C++
dependency manager. Before using vcpkg with Visual Studio, you must run vcpkg
integrate install . For instructions and more information about vcpkg, see:
Install and use packages with CMake in Visual Studio
vcpkg in CMake projects
If CMakeSettings.json is your active configuration file, Visual Studio automatically passes
the vcpkg toolchain file ( vcpkg.cmake ) to CMake. This behavior is disabled automatically
when you specify any other toolchain in your CMake Settings configuration.
If CMakePresets.json is your active configuration file, you'll need to set the path to
vcpkg.cmake in CMakePresets.json . We recommend using the VCPKG_ROOT environment
variable instead of an absolute path to keep the file shareable. For more information,
see Enable vcpkg integration with CMake Presets. CMakePresets.json is available in
Visual Studio 2019 version 16.10 or later and is the recommended CMake configuration
file.
Run CMake from the command line
If CMakePresets.json is your active CMake configuration file, then you can easily
reproduce your local builds outside of Visual Studio. For more information, see Run
CMake from the command line or a CI pipeline. CMakePresets.json is supported in
Visual Studio 2019 version 16.10 or later and is the recommended CMake configuration
file.
If CMakeSettings.json is your active CMake configuration file, then you'll need to
manually pass the arguments that are encoded in your CMakeSettings.json file to
CMake. If you have installed CMake from the Visual Studio Installer, you can run it from
the command line by following these steps:
1. Run the appropriate vsdevcmd.bat file (x86/x64). For more information, see
Building on the command line .
2. Switch to your output folder.
3. Run CMake to build or configure your app.
See also
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Tutorial: Create C++ cross-platform projects in Visual Studio
Configure a Linux CMake project
Connect to your remote Linux computer
Customize CMake build settings
CMakeSettings.json schema reference
Configure CMake debugging sessions
Deploy, run, and debug your Linux project
CMake predefined configuration reference
vcpkg in CMake projects
Install and use packages with CMake in Visual Studio
 Yes  No
Tutorial: Create C++ cross-platform
projects in Visual Studio
Article • 10/16/2023
Visual Studio C and C++ development isn't just for Windows anymore. This tutorial
shows how to use Visual Studio for C++ cross platform development on Windows and
Linux. It's based on CMake, so you don't have to create or generate Visual Studio
projects. When you open a folder that contains a CMakeLists.txt file, Visual Studio
configures the IntelliSense and build settings automatically. You can quickly start editing,
building, and debugging your code locally on Windows. Then, switch your configuration
to do the same on Linux, all from within Visual Studio.
In this tutorial, you learn how to:
＂ clone an open-source CMake project from GitHub
＂ open the project in Visual Studio
＂ build and debug an executable target on Windows
＂ add a connection to a Linux machine
＂ build and debug the same target on Linux
Prerequisites
Set up Visual Studio for Cross Platform C++ Development
First, install Visual Studio and choose the Desktop development with C++
and Linux development with C++ workloads. This minimal install is only 3 GB.
Depending on your download speed, installation shouldn't take more than 10
minutes.
Set up a Linux machine for Cross Platform C++ Development
Visual Studio doesn't require any specific distribution of Linux. The OS can be
running on a physical machine, in a VM, or in the cloud. You could also use the
Windows Subsystem for Linux (WSL). However, for this tutorial, a graphical
environment is required. WSL isn't recommended here, because it's intended
primarily for command-line operations.
Visual Studio requires these tools on the Linux machine: C++ compilers, gdb ,
ssh , rsync , make , and zip . On Debian-based systems, you can use this
command to install these dependencies:
Windows Command Prompt
sudo apt install -y openssh-server build-essential gdb rsync make
zip
Visual Studio requires a recent version of CMake on the Linux machine that has
server mode enabled (at least 3.8). Microsoft produces a universal build of
CMake that you can install on any Linux distro. We recommend you use this
build to ensure that you have the latest features. You can get the CMake
binaries from the Microsoft fork of the CMake repo on GitHub. Go to that
page and download the version that matches the system architecture on your
Linux machine, then mark it as an executable:
Windows Command Prompt
wget <path to binary>
chmod +x cmake-3.11.18033000-MSVC_2-Linux-x86_64.sh
You can see the options for running the script with --help . We recommend that
you use the -prefix option to specify installing in the /usr path, because
/usr/bin is the default location where Visual Studio looks for CMake. The
following example shows the Linux-x86_64 script. Change it as needed if you're
using a different target platform.
Windows Command Prompt
sudo ./cmake-3.11.18033000-MSVC_2-Linux-x86_64.sh --skip-license --
prefix=/usr
Git for windows installed on your Windows machine.
A GitHub account.
Clone an open-source CMake project from
GitHub
This tutorial uses the Bullet Physics SDK on GitHub. It provides collision detection and
physics simulations for many applications. The SDK includes sample executable
programs that compile and run without having to write other code. This tutorial doesn't
modify any of the source code or build scripts. To start, clone the bullet3 repository from
GitHub on the machine where you have Visual Studio installed.
Windows Command Prompt
git clone https://github.com/bulletphysics/bullet3.git
1. On the Visual Studio main menu, choose File > Open > CMake. Navigate to the
CMakeLists.txt file in the root of the bullet3 repo you downloaded.
As soon as you open the folder, your folder structure becomes visible in the
Solution Explorer.
This view shows you exactly what is on disk, not a logical or filtered view. By
default, it doesn't show hidden files.
2. Choose the Show all files button to see all the files in the folder.
Switch to targets view
When you open a folder that uses CMake, Visual Studio automatically generates the
CMake cache. This operation might take a few moments, depending on the size of your
project.
1. In the Output Window, select Show output from and then choose CMake to
monitor the status of the cache generation process. When the operation is
complete, it says "Target info extraction done."
After this operation completes, IntelliSense is configured. You can build the project,
and debug the application. Visual Studio now shows a logical view of the solution,
based on the targets specified in the CMakeLists files.
2. Use the Solutions and Folders button in the Solution Explorer to switch to CMake
Targets View.
Here's what that view looks like for the Bullet SDK:
Targets view provides a more intuitive view of what is in this source base. You can
see some targets are libraries and others are executables.
3. Expand a node in CMake Targets View to see its source code files, wherever those
files might be located on disk.
Add an explicit Windows x64-Debug
configuration
Visual Studio creates a default x64-Debug configuration for Windows. Configurations
are how Visual Studio understands what platform target it's going to use for CMake. The
default configuration isn't represented on disk. When you explicitly add a configuration,
Visual Studio creates a file called CMakeSettings.json. It's populated with settings for all
the configurations you specify.
1. Add a new configuration. Open the Configuration drop-down in the toolbar and
select Manage Configurations.
The CMake Settings Editor opens. Select the green plus sign on the left-hand side
of the editor to add a new configuration. The Add Configuration to
CMakeSettings dialog appears:
This dialog shows all the configurations included with Visual Studio, plus any
custom configurations that you create. If you want to continue to use a x64-Debug
configuration that should be the first one you add. Select x64-Debug, and then
choose the Select button. Visual Studio creates the CMakeSettings.json file with a
configuration for x64-Debug, and saves it to disk. You can use whatever names
you like for your configurations by changing the name parameter directly in
CMakeSettings.json.
Set a breakpoint, build, and run on Windows
In this step, we debug an example program that demonstrates the Bullet Physics library.
1. In Solution Explorer, select AppBasicExampleGui and expand it.
2. Open the file BasicExample.cpp .
3. Set a breakpoint that gets hit when you click in the running application. The click
event is handled in a method within a helper class. To quickly get there:
a. Select CommonRigidBodyBase that the struct BasicExample is derived from. It's
around line 30.
b. Right-click and choose Go to Definition. Now you're in the header
CommonRigidBodyBase.h.
c. In the browser view above your source, you should see that you're in the
CommonRigidBodyBase . To the right, you can select members to examine. Open
the drop-down and select mouseButtonCallback to go to the definition of that
function in the header.
4. Place a breakpoint on the first line within this function. It gets hit when you click a
mouse button within the window of the application, when run under the Visual
Studio debugger.
5. To launch the application, select the launch drop-down in the toolbar. It's the one
with the green play icon that says "Select Startup Item." In the drop-down, select
AppBasicExampleGui.exe. The executable name now displays on the launch button:
6. Choose the launch button to build the application and necessary dependencies,
then launch it with the Visual Studio debugger attached. After a few moments, the
running application appears:
7. Move your mouse into the application window, then click a button to trigger the
breakpoint. The breakpoint brings Visual Studio back to the foreground, and the
editor shows the line where execution is paused. You can inspect the application
variables, objects, threads, and memory, or step through your code interactively.
Choose Continue to let the application resume, and then exit it normally. Or, halt
execution within Visual Studio by using the stop button.
Add a Linux configuration and connect to the
remote machine
1. Add a Linux configuration. Right-click the CMakeSettings.json file in the Solution
Explorer view and select Add Configuration. You see the same Add Configuration
to CMakeSettings dialog as before. Select Linux-Debug this time, then save the
CMakeSettings.json file (ctrl + s).
2. Visual Studio 2019 version 16.6 or later Scroll down to the bottom of the CMake
Settings Editor and select Show advanced settings. Select Unix Makefiles as the
CMake generator, then save the CMakeSettings.json file (ctrl + s).
3. Select Linux-Debug in the configuration drop-down.
If it's the first time you're connecting to a Linux system, the Connect to Remote
System dialog appears.
If you've already added a remote connection, you can open this window by
navigating to Tools > Options > Cross Platform > Connection Manager.
4. Provide the connection information to your Linux machine and choose Connect.
Visual Studio adds that machine as to CMakeSettings.json as your default
connection for Linux-Debug. It also pulls down the headers from your remote
machine, so you get IntelliSense specific to that remote connection. Next, Visual
Studio sends your files to the remote machine and generates the CMake cache on
the remote system. These steps might take some time, depending on the speed of
your network and power of your remote machine. You know it's complete when
the message "Target info extraction done" appears in the CMake output window.
Set a breakpoint, build, and run on Linux
Because it's a desktop application, you need to provide some more configuration
information to the debug configuration.
1. In the CMake Targets view, right-click AppBasicExampleGui and choose Debug and
Launch Settings to open the launch.vs.json file that's in the hidden .vs subfolder.
This file is local to your development environment. You can move it into the root of
your project if you wish to check it in and save it with your team. In this file, a
configuration has been added for AppBasicExampleGui. These default settings
work in most cases, but not here. Because it's a desktop application, you need to
provide some additional information to launch the program so you can see it on
your Linux machine.
2. To find the value of the environment variable DISPLAY on your Linux machine, run
this command:
Windows Command Prompt
echo $DISPLAY
In the configuration for AppBasicExampleGui, there's a parameter array,
"pipeArgs". It contains a line: "${debuggerCommand}". It's the command that
launches gdb on the remote machine. Visual Studio must export the display into
this context before that command runs. For example, if the value of your display is
:1 , modify that line as follows:
Windows Command Prompt
"export DISPLAY=:1;${debuggerCommand}",
3. Launch and debug your application. Open the Select Startup Item drop-down in
the toolbar and choose AppBasicExampleGui. Next, either choose the green play
icon in the toolbar, or press F5. The application and its dependencies are built on
the remote Linux machine, then launched with the Visual Studio debugger
attached. On your remote Linux machine, you should see an application window
appear.
4. Move your mouse into the application window, and click a button. The breakpoint
is hit. Program execution pauses, Visual Studio comes back to the foreground, and
you see your breakpoint. You should also see a Linux Console Window appear in
Visual Studio. The window provides output from the remote Linux machine, and it
can also accept input for stdin . Like any Visual Studio window, you can dock it
where you prefer to see it. Its position is persisted in future sessions.
5. You can inspect the application variables, objects, threads, memory, and step
through your code interactively using Visual Studio. But this time, you're doing it
all on a remote Linux machine instead of your local Windows environment. You can
choose Continue to let the application resume and exit normally, or you can
choose the stop button, as with local execution.
6. Look at the Call Stack window and view the Calls to x11OpenGLWindow since Visual
Studio launched the application on Linux.
What you learned
In this tutorial, you cloned a code base directly from GitHub. You built, ran, and
debugged it on Windows without modifications. Then you used the same code base,
with minor configuration changes, to build, run, and debug on a remote Linux machine.
Next steps
Learn more about configuring and debugging CMake projects in Visual Studio:
CMake Projects in Visual Studio
Configure a Linux CMake project
Connect to your remote Linux computer
Customize CMake build settings
Configure CMake debugging sessions
Deploy, run, and debug your Linux project
CMake predefined configuration reference
Walkthrough: Build and debug C++
with WSL 2 and Visual Studio 2022
Article • 03/20/2024
Visual Studio 2022 introduces a native C++ toolset for Windows Subsystem for Linux
version 2 (WSL 2) development. This toolset is available now in Visual Studio 2022
version 17.0 or higher.
WSL 2 is the new, recommended version of the Windows Subsystem for Linux (WSL). It
provides better Linux file system performance, GUI support, and full system call
compatibility. Visual Studio's WSL 2 toolset allows you to use Visual Studio to build and
debug C++ code on WSL 2 distros without adding an SSH connection. You can already
build and debug C++ code on WSL 1 distros using the native WSL 1 toolset
introduced in Visual Studio 2019 version 16.1.
Visual Studio's WSL 2 toolset supports both CMake and MSBuild-based Linux projects.
CMake is our recommendation for all C++ cross-platform development with Visual
Studio. We recommend CMake because it build and debug the same project on
Windows, WSL, and remote systems.
For a video presentation of the information in this topic, see Video: Debug C++ with
WSL 2 Distributions and Visual Studio 2022.
WSL 2 toolset background
C++ cross-platform support in Visual Studio assumes all source files originate in the
Windows file system. When targeting a WSL 2 distro, Visual Studio executes a local
rsync command to copy files from the Windows file system to the WSL file system. The
local rsync copy doesn't require any user intervention. It occurs automatically when
Visual Studio detects you're using a WSL 2 distro. To learn more about the differences
between WSL 1 and WSL 2, see Comparing WSL 1 and WSL 2.
CMake Presets integration in Visual Studio supports the WSL 2 toolset. To learn more,
see CMake Presets integration in Visual Studio and Visual Studio Code and Configure
and build with CMake Presets in Visual Studio. There's also more advanced information
in this article under Advanced WSL 2 and CMake projects considerations.
Install the build tools
Install the tools necessary to build and debug on WSL 2. You'll install a recent version of
CMake using Visual Studio's CMake binary deployment in a later step.
1. Install WSL and a WSL 2 distro by following the instructions at Install WSL.
2. Assuming your distro uses apt (this walkthrough uses Ubuntu), use the following
commands to install the required build tools on your WSL 2 distro:
Bash
sudo apt update
sudo apt install g++ gdb make ninja-build rsync zip
The apt commands above install:
A C++ compiler
gdb
CMake
rsync
zip
An underlying build system generator
Cross-platform CMake development with a
WSL 2 distro
This walkthrough uses GCC and Ninja on Ubuntu. And Visual Studio 2022 version 17.0
Preview 2 or later.
Visual Studio defines a CMake project as a folder with a CMakeLists.txt file at the
project root. In this walkthrough, you create a new CMake project by using the Visual
Studio CMake Project template:
3. From the Visual Studio Get started screen, select Create a new project.
The available options are:
Clone a repository, Open a project or solution, Open a local folder, Create a new
project, or Continue without code.":::
4. In the Search for templates textbox, type "cmake". Choose the CMake Project type
and select Next. Give the project a name and location, and then select Create.
5. Enable Visual Studio's CMake Presets integration. Select Tools > Options > CMake
> General. Select Prefer using CMake Presets for configure, build, and test, then
select OK. Instead, you could have added a CMakePresets.json file to the root of
the project. For more information, see Enable CMake Presets integration.
6. To activate the integration: from the main menu, select File > Close Folder. The
Get started page appears. Under Open recent, select the folder you just closed to
reopen the folder.
7. There are three dropdowns across the Visual Studio main menu bar. Use the
dropdown on the left to select your active target system. This is the system where
CMake is invoked to configure and build the project. Visual Studio queries for WSL
installations with wsl -l -v . In the following image, WSL2: Ubuntu-20.04 is shown
selected as the Target System.
７ Note
If Visual Studio starts to configure your project automatically, read step 11 to
manage CMake binary deployment, and then continue to the step below. To
customize this behavior, see Modify automatic configuration and cache
notifications.
8. Use the dropdown in the middle to select your active Configure Preset. Configure
Presets tell Visual Studio how to invoke CMake and generate the underlying build
system. In step 7, the active Configure Preset is the linux-default Preset created by
Visual Studio. To create a custom Configure Preset, select Manage
Configurations… For more information about Configure Presets, see Select a
Configure Preset and Edit Presets.
9. Use the dropdown on the right to select your active Build Preset. Build Presets tell
Visual Studio how to invoke build. In the illustration for step 7, the active Build
Preset is the Default Build Preset created by Visual Studio. For more information
about Build Presets, see Select a Build Preset.
10. Configure the project on WSL 2. If project generation doesn't start automatically,
then manually invoke configure with Project > Configure project-name
11. If you don't have a supported version of CMake installed on your WSL 2 distro,
then Visual Studio prompts you beneath the main menu ribbon to deploy a recent
version of CMake. Select Yes to deploy CMake binaries to your WSL 2 distro.
12. Confirm that the configure step completed and that you can see the CMake
generation finished message in the Output window under the CMake pane. Build
files are written to a directory in the WSL 2 distro's file system.
13. Select the active debug target. The debug dropdown menu lists all the CMake
targets available to the project.
14. Expand the project subfolder in the Solution Explorer. In the CMakeProject.cpp file,
set a breakpoint in main() . You can also navigate to CMake targets view by
selecting the View Picker button in the Solution Explorer, highlighted in following
screenshot:
15. Select Debug > Start, or press F5. Your project builds, the executable launches on
your WSL 2 distro, and Visual Studio halts execution at the breakpoint. The output
of your program (in this case, "Hello CMake." ) is visible in the Linux Console
Window:
You've now built and debugged a C++ app with WSL 2 and Visual Studio 2022.
Advanced WSL 2 and CMake projects
considerations
Visual Studio only provides native support for WSL 2 for CMake projects that use
CMakePresets.json as the active configuration file. To migrate from CMakeSettings.json
to CMakePresets.json , see Enable CMake Presets integration in Visual Studio.
If you're targeting a WSL 2 distribution and you don't want to use the WSL 2 toolset,
then in the Visual Studio Remote Settings vendor map in CMakePresets.json , set
forceWSL1Toolset to true . For more information, see Visual Studio Remote Settings
vendor map.
If forceWSL1Tooslet is set to true, then Visual Studio doesn't maintain a copy of your
source files in the WSL file system. Instead, it accesses source files in the mounted
Windows drive ( /mnt/ …).
In most cases, it's best to use the WSL 2 toolset with WSL 2 distributions because WSL 2
is slower when project files are instead stored in the Windows file system. To learn more
about file system performance in WSL 2, see Comparing WSL 1 and WSL 2.
Specify advanced settings such as the path to the directory on WSL 2 where the project
is copied, copy source options, and rsync command arguments, in the Visual Studio
Remote Settings vendor map in CMakePresets.json . For more information, see Visual
Studio Remote Settings vendor map.
System headers are still automatically copied to the Windows file system to supply the
native IntelliSense experience. You can customize the headers that are included or
excluded from this copy in the Visual Studio Remote Settings vendor map in
CMakePresets.json .
You can change the IntelliSense mode, or specify other IntelliSense options, in the Visual
Studio Settings vendor map in CMakePresets.json . For details about the vendor map,
see Visual Studio Remote Settings vendor map.
WSL 2 and MSBuild-based Linux projects
CMake is recommended for all C++ cross-platform development with Visual Studio
because it allows you to build and debug the same project on Windows, WSL, and
remote systems.
But you may have a MSBuild-based Linux project.
If you have a MSBuild-based Linux project, then you can upgrade to the WSL 2 toolset
in Visual Studio. Right-click the project in the solution explorer, then choose Properties
> General > Platform Toolset:
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
If you're targeting a WSL 2 distribution and you don't want to use the WSL 2 toolset,
then in the Platform Toolset dropdown, select the GCC for Windows Subsystem for
Linux or Clang for Windows Subsystem for Linux toolset. If either of these toolsets are
selected, Visual Studio doesn't maintain a copy of your source files in the WSL file
system and instead accesses source files over the mounted Windows drive ( /mnt/ …).
System headers are still automatically copied to the Windows file system to provide a
native IntelliSense experience. Customize the headers that are included or excluded
from this copy in Property Pages > General.
In most cases, it's best to use the WSL 2 toolset with WSL 2 distributions because WSL 2
is slower when project files are stored in the Windows file system. To learn more, see
Comparing WSL 1 and WSL 2.
Video: Debug C++ with WSL 2 Distributions and Visual Studio 2022
Download Visual Studio 2022
Create a CMake Linux project in Visual Studio
Tutorial: Debug a CMake project on a remote Windows machine
See also
 Yes  No
Tutorial: Debug a CMake project on a
remote Windows machine
Article • 03/11/2022
This tutorial uses Visual Studio C++ on Windows to create and build a CMake project
that you can deploy and debug on a remote Windows machine. The tutorial is specific
to Windows ARM64, but the steps can be generalized for other architectures.
In Visual Studio, the default debugging experience for ARM64 is remote debugging an
ARM64 Windows machine. Configure your debug settings as shown in this tutorial.
Otherwise, when you try to debug an ARM64 CMake project, you'll get an error that
Visual Studio can't find the remote machine.
In this tutorial, you'll learn how to:
＂ create a CMake project
＂ configure a CMake project to build for ARM64
＂ configure a CMake project to run on a remote ARM64 Windows machine
＂ debug a CMake project running on a remote ARM64 Windows machine
Prerequisites
On the host machine
To set up Visual Studio for cross-platform C++ development, install the build tools for
the target architecture. For this tutorial, install the ARM64 build tools by doing these
steps:
1. Run the Visual Studio Installer. If you haven't installed Visual Studio yet, see Install
Visual Studio
2. On the Visual Studio Installer home screen, choose Modify.
3. From the choices at the top, choose Individual components.
4. Scroll down to the Compilers, build tools, and runtimes section.
5. Ensure that the following are selected:
C++ CMake tools for Windows
MSVC v142 - VS 2019 C++ ARM64 build tools (Latest) It's important that
you choose the ARM64 build tools and not the ARM build tools (look for the
64) and that you choose the version that goes with VS 2019 .
6. Select Modify to install the tools.
On the remote machine
1. Install the remote tools on the remote machine. For this tutorial, install the ARM64
tools by following the instructions in Download and Install the remote tools.
2. Start and configure the remote debugger on the remote machine. For this tutorial,
do so by following the directions in set up the remote debugger on the remote
Windows machine.
Create a CMake project
On the Windows host machine:
1. Run Visual Studio
2. From the main menu, select File > New > Project.
3. Select CMake Project > Next
4. Give the project a name and choose a location. Then select Create.
Give Visual Studio a few moments to create the project and populate the Solution
Explorer.
Configure for ARM64
To target an ARM64 Windows machine, you need to build using ARM64 build tools.
Select the Visual Studio Configuration dropdown and select Manage Configurations.
Add a new configuration by selecting Add a new configuration (the green + button).
In the CMakeSettings dialog that appears, select arm64-debug, and then choose Select:
This command adds a debug configuration named arm64-Debug to your
CmakeSettings.json file. This configuration name is a unique, friendly name that makes
it easier for you to identify these settings in the Configuration dropdown.
The Toolset dropdown is set to msvc_arm64_x64. Your settings should now look like
this:
７ Note
In the Toolset dropdown, msvc_arm64 selects 32-bit host tools to cross-compile to
ARM64, whereas msvc_arm64 x64 selects 64-bit host tools to cross-compile to
ARM64, which is what you'll do in this tutorial. For more information about the
available toolset environments, see Pre-defined environments.
Save the CMakeSettings.json file. In the configuration dropdown, select arm64-debug.
(It may take a moment after saving the CMakeSettings.json file for it to appear in the
list):
Add a debug configuration file
Next, add configuration information that tells Visual Studio where to find your remote
machine, along with other configuration details.
Change the Solution Explorer view to targets view by selecting the Switch Views
button:
Then, in the Solution Explorer, double-click CMake Targets View to see the project.
Open the project folder (in this example, CMakeProject3 Project), and then right-click
the executable and select Add Debug Configuration:
This command creates a launch.vs.json file in your project. Open it and change the
following entries to enable remote debugging:
projectTarget : this value is set for you if you added the debug configuration file
from the Solution Explorer targets view per the instructions above.
remoteMachineName : set to the IP address of the remote ARM64 machine, or its
machine name.
For more information about launch.vs.json settings, see launch.vs.json schema
reference.
７ Note
If you're using the folder view instead of the targets view in Solution Explorer,
right-click the CMakeLists.txt file and select Add Debug Configuration. This
experience differs from adding the debug configuration from the targets view in
the following ways:
You'll be asked to select a debugger (select C/C++ Remote Windows Debug).
Visual Studio will provide less configuration template information in the
launch.vs.json file so you'll need to add it yourself. You'll need to provide the
remoteMachineName and projectTarget entries. When you add the
configuration from the targets view, you only need to specify
remoteMachineName .
For the projectTarget setting value, check the startup item dropdown to get
the unique name of your target, for example, in this tutorial it is
CMakeProject3.exe '.
Start the remote debugger monitor on the
remote Windows machine
Before you run your CMake project, ensure that the Visual Studio 2019 remote
debugger is running on the remote Windows machine. You may need to change the
remote debugger options depending on your authentication situation.
For example, on the remote machine, from the Visual Studio Remote Debugger menu
bar, select Tools > Options. Set the authentication mode to match how your
environment is set up:
Then, in Visual Studio on the host machine, update the launch.vs.json file to match. For
example, if you choose No Authentication on the remote debugger, update the
launch.vs.json file in your project by adding "authenticationType": "none" to the
configurations section launch.vs.json . Otherwise, "authenticationType" defaults to
"windows" and doesn't need to be explicitly stated. This example shows a
launch.vs.json file configured for no authentication:
XAML
{
 "version": "0.2.1",
 "defaults": {},
 "configurations": [
 {
 "type": "remoteWindows",
 "authenticationType": "none"
 "name": "CMakeLists.txt",
 "project": "CMakeLists.txt",
 "projectTarget": "CMakeProject3.exe",
 "remoteMachineName": "<ip address goes here>",
 "cwd": "${debugInfo.defaultWorkingDirectory}",
 "program": "${debugInfo.fullTargetPath}",
 "deploy": [],
 "args": [],
 "env": {}
 },
 {
 "type": "default",
 "project": "CMakeLists.txt",
 "projectTarget": "CMakeProject3.exe",
 "name": "CMakeProject3.exe"
 }
 ]
}
Debug the app
On the host machine, in the Visual Studio Solution Explorer, open the CPP file for your
CMake project. If you're still in CMake Targets View, you'll need to open the
(executable) node to see it.
The default CPP file is a simple hello world console app. Set a breakpoint on return 0; .
On the Visual Studio toolbar, use the Startup Item dropdown to select the name you
specified for "name" in your launch.vs.json file:
To start debugging, on the Visual Studio toolbar choose Debug > Start Debugging (or
press F5).
If it doesn't start, ensure that the following are set correctly in the launch.vs.json file:
"remoteMachineName" should be set to the IP address, or the machine name, of the
remote ARM64 Windows machine.
"name" should match the selection in the Visual Studio startup item dropdown.
"projectTarget" should match the name of the CMake target you want to debug.
"type" should be "remoteWindows"
If the authentication type on the remote debugger is set to No Authentication,
you should have "authenticationType": "none" set in the launch.vs.json file.
If you're using Windows authentication, sign in when prompted using an account
recognized by the remote machine.
After the project builds, the app should appear on the remote ARM64 Windows
machine:
Visual Studio on the host machine should be stopped at the breakpoint for return 0; .
What you learned
In this tutorial, you created a CMake project, configured it to build for Windows on
ARM64, and debugged it on a remote ARM64 Windows machine.
Next steps
Learn more about configuring and debugging CMake projects in Visual Studio:
CMake Projects in Visual Studio
Customize CMake build settings
Configure CMake debugging sessions
CMake predefined configuration reference
launch.vs.jsonschema reference
Clang/LLVM support in Visual Studio
CMake projects
Article • 01/09/2023
You can use Visual Studio with Clang to edit and debug C++ CMake projects that target
Windows or Linux.
Windows: Starting in Visual Studio 2019 version 16.1, Visual Studio includes support for
editing, building, and debugging with Clang/LLVM in CMake projects targeting
Windows.
Linux: For Linux CMake projects, no special Visual Studio support is required. You can
install Clang using your distro's package manager, and add the appropriate commands
in the CMakeLists.txt file.
Install
For the best IDE support in Visual Studio, we recommend using the latest Clang
compiler tools for Windows. If you don't already have those, you can install them by
opening the Visual Studio Installer and choosing C++ Clang compiler for Windows
under Desktop development with C++ optional components. You may prefer to use an
existing Clang installation on your machine; if so, choose the MSBuild support for LLVM
(clang-cl) toolset component.
Create a new configuration
To add a new Clang configuration to a CMake project:
1. Right-click on CMakeLists.txt in Solution Explorer and choose CMake settings for
project.
2. Under Configurations, press the Add Configuration button:
3. Choose the desired Clang configuration (note that separate Clang configurations
are provided for Windows and Linux), then press Select:
4. To make modifications to this configuration, use the CMake Settings Editor. For
more information, see Customize CMake build settings in Visual Studio.
Modify an existing configuration to use Clang
To modify an existing configuration to use Clang, follow these steps:
1. Right-click on CMakeLists.txt in Solution Explorer and choose CMake settings for
project.
2. Under General select the Toolset dropdown and choose the desired Clang toolset:
Custom Clang locations
By default, Visual Studio looks for Clang in two places:
(Windows) The internally installed copy of Clang/LLVM that comes with the Visual
Studio installer.
(Windows and Linux) The PATH environment variable.
You can specify another location by setting the CMAKE_C_COMPILER and
CMAKE_CXX_COMPILER CMake variables in CMake Settings:
Clang compatibility modes
For Windows configurations, CMake by default invokes Clang in clang-cl mode and
links with the Microsoft implementation of the Standard Library. By default, clang-cl.exe
is located in C:\Program Files (x86)\Microsoft Visual
Studio\2019\Common7\IDE\CommonExtensions\Microsoft\Llvm\bin .
You can modify these values in CMake Settings under CMake variables and cache. Click
Show advanced variables. Scroll down to find CMAKE_CXX_COMPILER, then click the
Browse button to specify a different compiler path.
Edit, build, and debug
After you have set up a Clang configuration, you can build and debug the project. Visual
Studio detects that you're using the Clang compiler and provides IntelliSense,
highlighting, navigation, and other editing features. Errors and warnings are displayed in
the Output Window.
When debugging, you can use breakpoints, memory and data visualization, and most
other debugging features. Some compiler-dependent features such as Edit and
Continue aren't available for Clang configurations.
Create a CMake Linux project in Visual
Studio
Article • 08/03/2021
We recommend you use CMake for projects that are cross-platform or will be made
open-source. You can use CMake projects to build and debug the same source code on
Windows, the Windows Subsystem for Linux (WSL), and remote systems.
Before you begin
First, make sure you have the Visual Studio Linux workload installed, including the
CMake component. That's the Linux development with C++ workload in the Visual
Studio installer. See Install the C++ Linux workload in Visual Studio if you aren't sure you
have that installed.
Also, make sure the following are installed on the remote machine:
gcc
gdb
rsync
zip
ninja-build (Visual Studio 2019 or above)
You can use Visual Studio 2019 to build and debug on a remote Linux system or WSL,
and CMake will be invoked on that system. Cmake version 3.14 or later should be
installed on the target machine.
Make sure that the target machine has a recent version of CMake. Often, the version
offered by a distribution's default package manager isn't recent enough to support all
the features required by Visual Studio. Visual Studio 2019 detects whether a recent
version of CMake is installed on the Linux system. If none is found, Visual Studio shows
an info-bar at the top of the editor pane. It offers to install CMake for you from
https://github.com/Microsoft/CMake/releases .
With Visual Studio 2019, you can create a CMake project from scratch, or open an
existing CMake project. To create a new CMake project, follow the instructions below. Or
skip ahead to Open a CMake project folder if you already have a CMake project.
Create a new Linux CMake project
To create a new Linux CMake project in Visual Studio 2019:
1. Select File > New Project in Visual Studio, or press Ctrl + Shift + N.
2. Set the Language to C++ and search for "CMake". Then choose Next. Enter a
Name and Location, and choose Create.
Alternatively, you can open your own CMake project in Visual Studio 2019. The following
section explains how.
Visual Studio creates a minimal CMakeLists.txt file with only the name of the executable
and the minimum CMake version required. You can manually edit this file however you
like; Visual Studio will never overwrite your changes.
To help you make sense of, edit, and author your CMake scripts in Visual Studio 2019,
refer to the following resources:
In-editor documentation for CMake in Visual Studio
Code navigation for CMake scripts
Easily Add, Remove, and Rename Files and Targets in CMake Projects
Open a CMake project folder
When you open a folder that contains an existing CMake project, Visual Studio uses
variables in the CMake cache to automatically configure IntelliSense and builds. Local
configuration and debugging settings get stored in JSON files. You can optionally share
these files with others who are using Visual Studio.
Visual Studio doesn't modify the CMakeLists.txt files. This allows others working on the
same project to continue to use their existing tools. Visual Studio does regenerate the
cache when you save edits to CMakeLists.txt, or in some cases, to CMakeSettings.json. If
you're using an Existing Cache configuration, then Visual Studio doesn't modify the
cache.
For general information about CMake support in Visual Studio, see CMake projects in
Visual Studio. Read that before continuing here.
To get started, choose File > Open > Folder from the main menu or else type
devenv.exe <foldername> in a developer command prompt window. The folder you
open should have a CMakeLists.txt file in it, along with your source code.
The following example shows a simple CMakeLists.txt file and .cpp file:
C++
CMakeLists.txt:
txt
Configure a Linux CMake project
CMake Projects in Visual Studio
// hello.cpp
#include <iostream>
int main(int argc, char* argv[])
{
 std::cout << "Hello from Linux CMake \n";
}
cmake_minimum_required(VERSION 3.8)
project (hello-cmake)
add_executable(hello-cmake hello.cpp)
Next steps
See also
Configure and build with CMake Presets
in Visual Studio
Article • 06/09/2023
CMake supports two files that allow users to specify common configure, build, and test
options and share them with others: CMakePresets.json and CMakeUserPresets.json . Use
these files to drive CMake in Visual Studio and Visual Studio Code, in a continuous
integration (CI) pipeline, and from the command line.
CMakePresets.json is for saving project-wide builds. CMakeUserPresets.json is for
developers to save their own local builds. Both files are supported in Visual Studio 2019
version 16.10 or later.
This article contains information about CMakePresets.json integration with Visual Studio.
Here are helpful links:
For more information about the format of CMakePresets.json , see the official
CMake documentation .
For more information about the Microsoft vendor maps and macro expansion, see
CMakePresets.json and CMakeUserPresets.json Microsoft vendor maps.
For more information about how to use CMakePresets.json in Visual Studio Code,
see Configure and build with CMake Presets .
We recommend CMakePresets.json as an alternative to CMakeSettings.json . Visual
Studio never reads from both CMakePresets.json and CMakeSettings.json at the same
time. To enable or disable CMakePresets.json integration in Visual Studio, see Enable
CMakePresets.json in Visual Studio 2019.
Supported CMake and CMakePresets.json
versions
The supported CMakePresets.json and CMakeUserPresets.json schema versions depend
on your version of Visual Studio:
Visual Studio 2019 version 16.10 and later support schema versions 2 and 3.
Visual Studio 2022 version 17.4 preview 2 adds support for schema versions 4 and
5.
You can update the version by changing the "version" field in the root object. For an
example and more information, see CMakePresets.json format .
CMake version 3.20 or later is required when you're invoking CMake with
CMakePresets.json from the command line. However, Visual Studio reads and evaluates
CMakePresets.json and CMakeUserPresets.json itself and doesn't invoke CMake directly
with the --preset option. So, CMake version 3.20 or later isn't strictly required when
you're building with CMakePresets.json inside Visual Studio.
We recommend using at least CMake version 3.14 or later.
Enable CMakePresets.json integration in Visual
Studio
CMakePresets.json integration isn't enabled by default in Visual Studio. You can enable
it in Tools > Options > CMake > General:
） Important
Close and reopen the folder in Visual Studio to activate the integration.
In some older versions of Visual Studio, Tools > Options > CMake > General only has a
single option to enable CMakePresets.json integration:
The following table indicates when CMakePresets.json is used instead of
CMakeSettings.json to drive CMake configuration and build in Visual Studio 2022 and
Visual Studio 2019 version 16.10 and later. If no configuration file is present, default
Configure Presets are used.
In the table, "Tools > Options enabled" means Use CMakePresets.json to drive CMake
configure, build, and test is selected in Tools > Options > CMake > General.
Configuration files Tools > Options disabled Tools > Options enabled
No configuration file present CMakeSettings.json CMakePresets.json
CMakeSettings.json present CMakeSettings.json CMakePresets.json
CMakePresets.json present CMakePresets.json CMakePresets.json
Both configuration files present CMakePresets.json CMakePresets.json
By default, Visual Studio automatically invokes configure each time the active Target
System or Configure Preset changes. You can modify this behavior by selecting Never
run configure step automatically in Tools > Options > CMake > General. You can also
Modify automatic configuration and cache
notifications
disable all CMake cache notifications (gold bars) by clearing Show CMake cache
notifications.
If no CMakePresets.json or CMakeUserPresets.json file exists, or if CMakePresets.json or
CMakeUserPresets.json is invalid, Visual Studio falls back on the following default
Configure Presets:
JSON
JSON
Default Configure Presets
Windows example
{
 "name": "windows-default",
 "displayName": "Windows x64 Debug",
 "description": "Sets Ninja generator, compilers, x64 architecture, build
and install directory, debug build type",
 "generator": "Ninja",
 "binaryDir": "${sourceDir}/out/build/${presetName}",
 "architecture": {
 "value": "x64",
 "strategy": "external"
 },
 "cacheVariables": {
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}"
 },
 "vendor": {
 "microsoft.com/VisualStudioSettings/CMake/1.0": {
 "hostOS": [ "Windows" ]
 }
 }
},
Linux example
{
 "name": "linux-default",
 "displayName": "Linux Debug",
 "description": "Sets Ninja generator, compilers, build and install
directory, debug build type",
 "generator": "Ninja",
 "binaryDir": "${sourceDir}/out/build/${presetName}",
 "cacheVariables": {
If you try to open or modify a CMakePresets.json file that doesn't exist, Visual Studio
automatically creates a CMakePresets.json file with the default Configure Presets at the
root of your project.
On the Visual Studio toolbar, there are dropdowns for the Target Systems, Configure
Presets, and Build Presets when CMakePresets.json integration is enabled:
The dropdown list on the left indicates the active Target System. It's the system on which
CMake is invoked to configure and build the project. This dropdown list includes your
local machine, all SSH connections in Connection Manager by host name, and all
Windows Subsystem for Linux (WSL) installations that Visual Studio can find:
In the preceding example:
192.168.0.5 is a remote Linux system that was added to Connection Manager.
ubuntu2004 and debian are WSL installations.
Select Manage Connections to open Connection Manager.
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}"
 },
 "vendor": {
 "microsoft.com/VisualStudioSettings/CMake/1.0": {
 "hostOS": [ "Linux" ]
 },
 "microsoft.com/VisualStudioRemoteSettings/CMake/1.0": {
 "sourceDir": "$env{HOME}/.vs/$ms{projectDirName}"
 }
 }
}
Configure and build
Select a Target System
Select a Configure Preset
The dropdown list in the middle indicates the active Configure Preset. It's the
configurePreset value that's used when CMake is invoked to generate the project build
system. This dropdown list includes the union of non-hidden Configure Presets defined
in CMakePresets.json and CMakeUserPresets.json .
Visual Studio uses the value of hostOS in the Microsoft Visual Studio Settings vendor
map to hide Configure Presets that don't apply to the active Target System. For more
information, see the entry for hostOS in the table under Visual Studio Settings vendor
map.
Select Manage Configurations to open the CMakePresets.json file located at the root of
the project. CMakePresets.json is created if it doesn't already exist.
Select a Build Preset
The dropdown list on the right indicates the active Build Preset. It's the buildPreset
value that's used when CMake is invoked to build the project. This dropdown list
includes the union of non-hidden Build Presets defined in CMakePresets.json and
CMakeUserPresets.json .
All Build Presets are required to specify an associated configurePreset value. Visual
Studio hides Build Presets that don't apply to the active Configure Preset. For more
information, see the list of Build Presets .
If there are no Build Presets associated with the active Configure Preset, Visual Studio
lists the default Build Preset. The default Build Preset is equivalent to passing cmake --
build with no other arguments from the command line.
Configure
Visual Studio automatically tries to configure the project when it detects that the CMake
cache is out of date. To manually invoke the configuration, select Project > Configure
<project-name> from the main menu. It's the same as running cmake --preset
<configurePreset> from the command line, where <configurePreset> is the name of the
active Configure Preset.
To disable automatic cache generation, see Automatic configuration and cache
notifications.
Build
To build the entire project, select Build > Build All from the main menu. It's the same as
running cmake --build --preset <buildPreset> from the command line, where
<buildPreset> is the name of the active Build Preset.
To build a single target, switch to CMake Targets View in Solution Explorer. Then right￾click any target and select Build from the shortcut menu.
７ Note
Visual Studio 2019 doesn't support the buildPresets.targets option to build a
subset of targets specified in CMakePresets.json .
Run CTest
CMakePresets.json supports two menu options in Visual Studio 2019:
Test > Run CTests for <project-name> invokes CTest and runs all tests associated
with the active Configure Preset and Build Preset, with no other arguments passed
to CTest.
Test > Run Test Preset for <configurePreset> expands to show all Test Presets
associated with the active Configure Preset. Selecting a single Test Preset is the
same as running ctest --preset <testPreset> from the command line, where
<testPreset> is the name of the selected Test Preset. This option is unavailable if
no Test Presets are defined for the active Configure Preset.
In Visual Studio 2019, Test Explorer isn't integrated with CMakePresets.json .
Add new presets
In Visual Studio 2019, all commands and preset templates modify CMakePresets.json .
You can add new user-level presets by directly editing CMakeUserPresets.json .
Use a forward slash ( / ) for paths in CMakePresets.json and CMakeUserPresets.json .
Add new Configure Presets
To add a new Configure Preset to CMakePresets.json , from Solution Explorer, right-click
CMakePresets.json from Folder View and select Add Configuration from the shortcut
menu. The dialog to select a Configure Preset template appears:
Select the Windows x64 Debug template to configure on Windows systems. Select the
Linux Debug template to configure on WSL and remote Linux systems. For more
information about editing CMakePresets.json , see Edit presets.
The selected template is added to CMakePresets.json if it exists. Otherwise, the template
is copied into a new CMakePresets.json file.
Add new Build Presets and Test Presets
Visual Studio 2019 doesn't offer templates for new Build Presets and Test Presets. You
can add Build Presets and Test Presets by directly editing CMakePresets.json . For more
information, see the list of Build Presets , the list of Test Presets , or an example
CMakePresets.json file.
Edit presets
The official CMake documentation is the best resource for editing Configure Presets,
Build Presets, and Test Presets. The following information is a subset of the CMake
documentation that's especially relevant to Visual Studio developers.
You can set C and C++ compilers by using cacheVariables.CMAKE_C_COMPILER and
cacheVariables.CMAKE_CXX_COMPILER in a Configure Preset. It's equivalent to passing -D
CMAKE_C_COMPILER=<value> and -D CMAKE_CXX_COMPILER=<value> to CMake from the
command line. For more information, see CMAKE_<LANG>_COMPILER .
Use the following examples to build with cl.exe and clang-cl.exe from Visual Studio.
The C++ Clang tools for Windows components must be installed for you to build with
clang-cl .
Build with cl.exe :
JSON
Build with clang :
JSON
If you use either Visual Studio 16 2019 or Visual Studio 17 2022 as your generator,
you can use the toolset Configure Preset to specify the ClangCL toolset:
JSON
Select your compilers
"cacheVariables": {
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}",
 "CMAKE_C_COMPILER": "cl",
 "CMAKE_CXX_COMPILER": "cl"
},
"cacheVariables": {
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}",
 "CMAKE_C_COMPILER": "clang-cl",
 "CMAKE_CXX_COMPILER": "clang-cl"
},
"vendor": {
 "microsoft.com/VisualStudioSettings/CMake/1.0": {
 "intelliSenseMode": "windows-clang-x64"
 }
}
"cacheVariables": {
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}",
For more information on generators that support the toolset specification, see
CMAKE_GENERATOR_TOOLSET in the CMake documentation.
To reproduce these builds outside Visual Studio, see Run CMake from the command line
or a CI pipeline.
To build on Linux or without the Visual C++ toolset, specify the name of a compiler on
your PATH instance, or an environment variable that evaluates to the full path of a
compiler. Full paths are discouraged so that the file can remain shareable. A preset that
builds with GCC version 8 might look like this:
JSON
You can also set compilers with a CMake toolchain file. Toolchain files can be set with
cacheVariables.CMAKE_TOOLCHAIN_FILE , which is equivalent to passing -D
CMAKE_TOOLCHAIN_FILE=<value> to CMake from the command line. A CMake toolchain file
is most often used for cross-compilation. For more information about authoring CMake
toolchain files, see CMake toolchains .
},
"toolset": "ClangCL",
"vendor": {
 "microsoft.com/VisualStudioSettings/CMake/1.0": {
 "intelliSenseMode": "windows-clang-x64"
 }
}
） Important
In Visual Studio 2019, you must explicitly specify a Clang IntelliSense mode when
you're building with clang or clang-cl .
"cacheVariables": {
 "CMAKE_BUILD_TYPE": "Debug",
 "CMAKE_INSTALL_PREFIX": "${sourceDir}/out/install/${presetName}",
 "CMAKE_C_COMPILER": "gcc-8",
 "CMAKE_CXX_COMPILER": "g++-8"
},
Select your generator
The Windows and Linux Configure Preset templates both specify Ninja as the default
generator. Other common generators are the Visual Studio Generators on Windows
and Unix Makefiles on Linux and macOS. You can specify a new generator with the
generator option in a Configure Preset. It's equivalent to passing -G to CMake from the
command line.
Set architecture.strategy and toolset.strategy to set when you're building with a
Visual Studio Generator. For more information, see CMake generators .
Select your configuration type
You can set the configuration type ( Debug or Release ) for single configuration
generators by using cacheVariables.CMAKE_BUILD_TYPE . It's equivalent to passing -D
CMAKE_BUILD_TYPE=<value> to CMake from the command line. For more information, see
CMAKE_BUILD_TYPE .
Select your target and host architecture when building
with the Visual C++ toolset
You can set the target architecture (x64, Win32, ARM64, or ARM) by using
architecture.value . It's equivalent to passing -A to CMake from the command line. For
more information, see Platform Selection .
７ Note
Currently, Visual Studio Generators expect the Win32 syntax and command-line
generators (like Ninja) expect the x86 syntax when you're building for x86.
You can set the host architecture (x64 or x86) and toolset by using toolset.value . It's
equivalent to passing -T to CMake from the command line. For more information, see
Toolset Selection .
The architecture.strategy and toolset.strategy values tell CMake how to handle the
architecture and toolset fields. set means CMake sets the respective value, and
external means CMake won't set the respective value.
We recommend using set with IDE generators like the Visual Studio Generator. Use
external with command-line generators like Ninja. These values allow vendors like
Visual Studio to supply the required environment before CMake is invoked. For more
information about the architecture and toolset fields, see the list of Configure Presets .
If you don't want to source an environment, you can set architecture.strategy to
external and architecture.value to unspecified . You might find it useful not to source
an environment for any one of these reasons:
You use a toolset other than MSVC.
You use a custom toolchain, such as in embedded scenarios.
You don't need a specific environment to build.
For a full list of IDE generators that support the architecture field, see
CMAKE_GENERATOR_PLATFORM . For a full list of IDE generators that support the
toolset field, see CMAKE_GENERATOR_TOOLSET .
Use the following examples to target ARM64 with the Ninja generator, or to target
Win32 (x86) with the Visual Studio 16 2019 generator:
JSON
You can set environment variables by using the environment map. Environment
variables are inherited through the inherits field, but you can override them as you
like.
A preset's environment is the union of its own environment and the environment from
all its parents. If multiple inherits presets provide conflicting values for the same
variable, the earlier preset in the inherits list is preferred. You can unset a variable
inherited from another preset by setting it to null .
Environment variables set in a Configure Preset also automatically flow through to
associated Build Presets and Test Presets, unless inheritConfigureEnvironment is set to
false . For more information, see the list of Configure Presets .
"generator": "Ninja",
"architecture": {
 "strategy": "external",
 "value": "arm64"
},
"generator": "Visual Studio 16 2019",
"architecture": {
 "strategy": "set",
 "value": "Win32"
},
Set and reference environment variables
You can reference environment variables by using the $env{<variable-name>} and
$penv{<variable-name>} syntax. For more information, see Macro Expansion .
Configure IntelliSense for a cross-compiler
By default, Visual Studio uses the IntelliSense mode that matches your specified toolset
and target architecture. If you're cross-compiling, you might need to manually specify
the correct IntelliSense mode by using the intelliSenseMode option in the Visual Studio
Settings vendor map. For more information, see the entry for intelliSenseMode in the
table under Visual Studio Settings vendor map.
Configure and build on a remote system or the
Windows Subsystem for Linux
With CMakePresets.json support in Visual Studio, you can easily configure and build
your project on Windows, WSL, and remote systems. The steps to configure and build
your project on Windows, a remote system, or WSL are the same. However, a few
behaviors are specific to remote development.
${sourceDir} behavior in remote copy scenarios
In local scenarios (including WSL1), ${sourceDir} evaluates to the path to the project
source directory that's open in Visual Studio. In remote copy scenarios, ${sourceDir}
evaluates to the path to the project source directory on the Target System and not the
project source directory on the local machine.
The value of sourceDir in the Visual Studio Remote Settings vendor map determines the
project source directory on the Target System (defaults to
$env{HOME}/.vs/$ms{projectDirName} ). For more information, see the entry for
sourceDir in the table under Visual Studio Settings vendor map.
Local folder for remote output
Remote copy scenarios require a local directory to copy some remote files like CMake
File API response files or build files if copyBuildOutput in the Visual Studio Remote
Settings vendor map is set to true . These files are automatically copied to <local￾source-directory>/out/<remote-connection-ID>/build/${presetName} .
You'll see an error if you try to use the same Configure Preset on Windows and WSL1.
Windows and WSL1 both use the Windows file system, so CMake will try to use the
same output directory ( binaryDir ) for both the Windows and WSL1 build trees.
If you want to use the same Configure Preset with both Windows and the WSL1 toolset,
create a second Configure Preset that inherits from the original preset and specifies a
new binaryDir value. In the following example, windows-preset can be used on
Windows and base-preset can be used on WSL1:
JSON
Vcpkg helps you manage C and C++ libraries on Windows, Linux, and macOS. A vcpkg
toolchain file ( vcpkg.cmake ) must be passed to CMake to enable vcpkg integration. For
more information, see the vcpkg documentation .
Visual Studio no longer passes your vcpkg toolchain file to CMake automatically when
CMakePresets.json integration is enabled. This change eliminates Visual Studio-specific
behavior and ensures that you can reproduce your build from the command line.
Instead, set the path to vcpkg.cmake by using the VCPKG_ROOT environment variable in
CMakePresets.json :
Invoking the same Configure Preset on Windows and
WSL1
{
 "name": "windows-preset",
 "inherits": "base-preset",
 "binaryDir": "${sourceDir}/out/build/${presetName}",
 "vendor": {
 "microsoft.com/VisualStudioSettings/CMake/1.0": {
 "hostOS": "Windows"
 }
 }
}
７ Note
In Visual Studio 2019, only the WSL1 toolset is supported. You'll see this behavior
any time you invoke configure on both Windows and WSL.
Enable vcpkg integration
JSON
VCPKG_ROOT should be set to the root of your vcpkg installation. For more information,
see vcpkg environment variables.
If you're already using a CMake toolchain file and want to enable vcpkg integration, see
Using multiple toolchain files. Follow those instructions to use an external toolchain file
with a project by using vcpkg.
CMakePresets.json supports variable substitution in launch.vs.json and tasks.vs.json .
Here are some considerations:
Environment variables set in the active Configure Preset automatically flow
through to launch.vs.json and tasks.vs.json configurations. You can unset
individual environment variables in launch.vs.json and tasks.vs.json by setting
them to null . The following example sets the variable DEBUG_LOGGING_LEVEL to
null in launch.vs.json : "env": { "DEBUG_LOGGING_LEVEL": null } .
Key values set in the active Configure Preset are available for consumption in
launch.vs.json and tasks.vs.json with the syntax ${cmake.<KEY-NAME>} . For
example, use ${cmake.binaryDir} to reference the output directory of the active
Configure Preset.
Individual environment variables set in the environment map of the active
Configure Preset are available for consumption in launch.vs.json and
tasks.vs.json through the syntax ${env.<VARIABLE-NAME>} .
Update your launch.vs.json and task.vs.json files to reference CMakePresets.json
syntax instead of CMakeSettings.json syntax. Macros that reference the old
CMakeSettings.json syntax when CMakePresets.json is the active configuration file are
slated for deprecation in a future release. For example, reference the output directory of
"cacheVariables": {
 "CMAKE_TOOLCHAIN_FILE": {
 "value": "$env{VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake",
 "type": "FILEPATH"
 }
 },
Variable substitution in launch.vs.json and
tasks.vs.json
the active Configure Preset with ${cmake.binaryDir} instead of ${cmake.buildRoot} ,
because CMakePresets.json uses the binaryDir syntax.
Troubleshoot
If things aren't working as expected, you can try a few troubleshooting steps.
If either CMakePresets.json or CMakeUserPresets.json is invalid, Visual Studio will fall
back on its default behavior and show only the default Configure Presets. Visual Studio
IntelliSense can help you catch many of these JSON errors, but it won't know if you're
referencing a preset with inherits or configurePreset by the wrong name.
To check if your preset files are valid, run cmake --list-presets from the command line
at the root of your project directory. (CMake 3.20 or later is required.) If either file is
invalid, you'll see the following error:
Windows Command Prompt
CMake Error: Could not read presets from
C:/Users/<user>/source/repos/<project-name>: JSON parse error
Other troubleshooting steps include:
Delete the cache and reconfigure the project (CMake: Delete Cache and Project >
Configure <project-name>).
Close and reopen the folder in Visual Studio (File > Close Folder).
Delete the .vs folder at the root your project.
If you've identified a problem, the best way to report it is by selecting the Send
Feedback button in the upper-right corner of Visual Studio.
Enable logging for remote connections
You can enable logging for remote connections if you're having trouble connecting or
copying files to a remote system. For more information, see Logging for remote
connections.
Enable AddressSanitizer for Windows and Linux
Visual Studio supports AddressSanitizer (ASAN), a C and C++ runtime memory error
detector, for both Windows and Linux development. The addressSanitizerEnabled
option in CMakeSettings.json enables AddressSanitizer. CMakePresets.json doesn't
support this behavior.
Instead, enable and disable AddressSanitizer by setting the required compiler and linker
flags yourself. Setting them removes Visual Studio-specific behavior and ensures that
the same CMakePresets.json file can reproduce your build from the command line.
You can add the following sample to CMakeLists.txt to enable or disable
AddressSanitizer for a target:
Windows Command Prompt
The <additional-options> part lists other compilation flags, like "-fno-omit-frame￾pointer" . For more information about AddressSanitizer for Linux, see Using
AddressSanitizer . For more information about using AddressSanitizer with MSVC, see
Use AddressSanitizer from a developer command prompt.
Pass runtime flags to AddressSanitizer by using the ASAN_OPTIONS field in
launch.vs.json . ASAN_OPTIONS defaults to detect_leaks=0 when no other runtime
options are specified because LeakSanitizer isn't supported in Visual Studio.
You can use the same CMakePresets.json and CMakeUserPresets.json files to invoke
CMake in Visual Studio and from the command line. The CMake and CTest
documentation are the best resources for invoking CMake and CTest with --preset .
CMake version 3.20 or later is required.
option(ASAN_ENABLED "Build this target with AddressSanitizer" ON)
if(ASAN_ENABLED)
 if(MSVC)
 target_compile_options(<target> PUBLIC /fsanitize=address)
 else()
 target_compile_options(<target> PUBLIC -fsanitize=address <additional￾options>)
 target_link_options(<target> PUBLIC -fsanitize=address)
 endif()
endif()
Run CMake from the command line or a CI
pipeline
Sourcing the environment when building with command￾line generators on Windows
It's up to the user to configure the environment before CMake is invoked in building
with a command-line generator. If you're building with Ninja and the Visual C++ toolset
on Windows, set the environment before CMake is called to generate the build system.
You can do it by calling vcvarsall.bat with the architecture argument. The
architecture argument specifies the host and target architecture to use. For more
information, see vcvarsall syntax. If you build on Linux or on Windows with a Visual
Studio Generator, you don't need to take this step.
It's the same step that Visual Studio takes for you when the IDE invokes CMake. Visual
Studio parses the active Configure Preset for the host and target architecture specified
by toolset and architecture . Visual Studio then sources the specified environment
from vcvarsall.bat . When you build from the Windows command line with Ninja, you'll
need to take this step yourself.
vcvarsall.bat is installed with the Build Tools for Visual Studio. By default,
vcvarsall.bat is installed in C:\Program Files (x86)\Microsoft Visual Studio\2019\
<edition>\VC\Auxiliary\Build . You can add vcvarsall.bat to PATH if you use the
command-line workflow often.
Example command-line workflow
You can use the following commands to configure and build a CMake project that uses
Ninja to target ARM64 with x64 build tools. CMake version 3.20 or later is required. Run
these commands from the directory where your CMakePresets.json file is located:
Windows Command Prompt
/path/to/vcvarsall.bat x64_arm64 
cmake --list-presets=all .
cmake --preset <configurePreset-name>
cmake --build --preset <buildPreset-name> 
Example CMakePresets.json file
The CMakePresets.json file in box2d-lite contains examples of Configure Presets, Build
Presets, and Test Presets. For more information about this example, see the presentation
An Introduction to CMakePresets.json. You can see another example in the DirectXTK
project, which shows many build targets in its configurePresets section.
Next steps
Learn more about configuring and debugging CMake projects in Visual Studio:
CMake Projects in Visual Studio
Customize CMake build settings
Configure CMake debugging sessions
CMake predefined configuration reference
CMakePresets.json and
CMakeUserPresets.json Microsoft vendor
maps
Article • 02/08/2022
CMake supports two files, CMakePresets.json and CMakeUserPresets.json , that allow
users to specify common configure, build, and test options and share them with others.
CMakePresets.json and CMakeUserPresets.json can be used to drive CMake in Visual
Studio, in Visual Studio Code, in a Continuous Integration (CI) pipeline, and from the
command line.
CMakePresets.json is intended to save project-wide builds, and CMakeUserPresets.json
is intended for developers to save their own local builds. The schema for both files is
identical.
CMakePresets.json and CMakeUserPresets.json support vendor maps to store vendor￾specific information. Microsoft maintains two vendor maps with options specific to
Visual Studio and Visual Studio Code. Here we document two Microsoft vendor maps
and vendor macros. For more information about the rest of the schema, see the official
CMake documentation . It includes information about Configure Presets, Build Presets,
and Test Presets.
For more information about how to use CMakePresets.json in Visual Studio, see
Configure and build with CMake Presets in Visual Studio
For more information about how to use CMakePresets.json in Visual Studio Code, see
Configure and build with CMake Presets in VS Code
Visual Studio Settings vendor map
One vendor map with the vendor URI
microsoft.com/VisualStudioSettings/CMake/<version> is allowed per Configure Preset
and contains options specific to CMake integration in Visual Studio and Visual Studio
Code. All options in the vendor map apply to Visual Studio. Options that apply to both
Visual Studio and Visual Studio Code have been explicitly marked.
All settings in the Visual Studio Settings vendor map are optional and inherited from
Configure Presets specified by the inherits key. Only options that have been modified
are written to the file. The Visual Studio Settings vendor map is supported by both
CMakePresets.json and CMakeUserPresets.json .
The options in the Visual Studio Settings vendor map don't affect the construction of
the CMake or CTest command line. It's so the same CMakePresets.json file can be used
to drive CMake with Visual Studio, Visual Studio Code, and from the command line. The
exceptions are the cacheRoot and cmakeGenerateCommand options. These options are
specific to the Open Existing Cache scenario in Visual Studio and can't be reproduced
from the command line.
Setting Description
hostOS An array of supported operating systems (OS). Accepted values
are Windows , Linux , and macOS .
The value of hostOS is used by Visual Studio and Visual Studio
Code to hide Configure Presets that don't apply to the OS of the
target system and provide a better user experience.
If hostOS is unspecified, then Visual Studio and Visual Studio
Code will always show all Configure Presets for selection. This
field can also be a string, which is equivalent to an array
containing one string
This option is supported by both Visual Studio and Visual Studio
Code.
Setting Description
intelliSenseMode Specifies the mode used for computing IntelliSense information in
Visual Studio with the format <target>-<toolset>-<arch> . 
Accepted values:
android-clang-arm
android-clang-arm64
android-clang-x6
android-clang-x86
ios-clang-ar
ios-clang-arm64
ios-clang-x6
ios-clang-x86
linux-gcc-arm
linux-gcc-x64
linux-gcc-x86
windows-clang-arm
windows-clang-arm64
windows-clang-x64
windows-clang-x86
windows-msvc-arm
windows-msvc-arm64
windows-msvc-x64
windows-msvc-x86
If intelliSenseMode is unspecified, then Visual Studio uses the
IntelliSense mode that matches your specified compilers and
target architecture. intelliSenseMode is often used to provide
improved IntelliSense for cross-compilation.
In Visual Studio 2019, you must explicitly specify a clang
IntelliSense mode when building with clang or clang-cl.
intelliSenseOptions A map of extra IntelliSense configuration options.
useCompilerDefaults : A bool that specifies whether to use the
compiler default defines and include paths for IntelliSense. Should
only be false if the compilers in use don't support gcc-style
arguments. Defaults to true .
additionalCompilerArgs : An array of extra options to control
IntelliSense in Visual Studio. This option supports macro
expansion.
enableMicrosoftCodeAnalysis A bool that enables Microsoft code analysis in Visual Studio when
building with cl or clang-cl . Defaults to false .
Setting Description
codeAnalysisRuleset Specifies the ruleset to use when running Microsoft code analysis
in Visual Studio. You can use a path to a ruleset file, or the name
of a ruleset file installed with Visual Studio. This option supports
macro expansion.
disableExternalAnalysis A bool that specifies whether code analysis should run on
external headers in Visual Studio.
codeAnalysisExternalRuleset Specifies the ruleset to use when running Microsoft code analysis
on external header in Visual Studio. You can use a path to a
ruleset file, or the name of a ruleset file installed with Visual
Studio. This option supports macro expansion.
enableClangTidyCodeAnalysis A bool that enables clang-tidy code analysis in Visual Studio when
building with clang-cl . Defaults to false .
clangTidyChecks A comma-separated list of warnings passed to clang-tidy when
running clang-tidy code analysis in Visual Studio. Wildcards are
allowed, and the - prefix will remove checks.
cacheRoot Specifies the path to a CMake cache. This directory should
contain an existing CMakeCache.txt file. This key is only supported
by the Open Existing Cache scenario in Visual Studio. This option
supports macro expansion.
cmakeGenerateCommand A command-line tool (specified as a command-line program and
arguments, for example, gencache.bat debug ) to generate the
CMake cache. This command runs in the shell using the specified
environment of the preset when CMake configure is invoked. This
key is only supported by the Open Existing Cache scenario in
Visual Studio. This option supports macro expansion.
One vendor map with the vendor URI
microsoft.com/VisualStudioRemoteSettings/CMake/<version> is allowed per Configure
Preset and contains options specific to remote development in Visual Studio. Remote
development means you're invoking CMake on a remote SSH connection or WSL. None
of the options in the Visual Studio Remote Settings vendor map apply to Visual Studio
Code.
All settings in the Visual Studio Remote Settings vendor map are optional and inherited
from Configure Presets specified by the inherits key. Only options that have been
Visual Studio Remote Settings vendor map
modified are written to the file. The Visual Studio Remote Settings vendor map is
supported by both CMakePresets.json and CMakeUserPresets.json .
The options in the Visual Studio Settings vendor map don't affect the construction of
the CMake or CTest command line. It's so the same CMakePresets.json file can be used
to drive CMake with Visual Studio, Visual Studio Code, and from the command line.
Many of the options in the Visual Studio Remote Settings vendor map are ignored when
targeting WSL1. It's because the WSL1 toolset executes all commands locally and relies
on Windows drives mounted under the /mnt folder to access local source files from
WSL1. No source file copy is required. Options that are ignored when targeting WSL1
have been explicitly marked.
Setting Description
sourceDir Path to the directory on the remote system where the
project will be copied. Defaults to
$env{HOME}/.vs/$ms{projectDirName} . This option
supports macro expansion.
In remote copy scenarios, the macro ${sourceDir}
evaluates to the project source directory on the remote
system and not the project source directory on the
Windows machine. Remote copy scenarios include
targeting a remote SSH connection. In these cases, the
project source directory on the remote system is
determined by the value of sourceDir in the Visual
Studio Remote Settings vendor map. This option is
ignored when targeting WSL1.
copySources If true , Visual Studio will copy sources from Windows to
the remote system. Set to false if you manage file
synchronization yourself. Defaults to true . This option is
ignored when targeting WSL1.
Setting Description
copySourcesOptions An object of options related to the source copy from
Windows to the remote system. This object is ignored
when targeting WSL1.
copySourcesOptions.exclusionList : A list of paths to be
excluded when copying source files to the remote
system. A path can be the name of a file or directory, or
a relative path from the root of the copy. Defaults to [
".vs", ".git", "out" ] . This option supports macro
expansion.
copySourcesOptions.method : The method used to copy
source files to the remote system. Accepted values are
rsync and sftp . Defaults to rsync .
copySourcesOptions.concurrentCopies : The number of
concurrent copies used during the synchronization of
sources to the remote system. Defaults to 5 .
copySourcesOptions.outputVerbosity : The verbosity level
of source copy operations to the remote system.
Accepted levels are Normal , Verbose , and Diagnostic .
Defaults to Normal .
rsyncCommandArgs A list of command-line arguments passed to rsync .
Defaults to [ "-t", "--delete", "--delete-excluded" ] .
This option supports macro expansion and is ignored
when targeting WSL1.
copyBuildOutput Specifies whether to copy build output from the remote
system back to Windows. Defaults to false . This option
is ignored when targeting WSL1.
Setting Description
copyOptimizations An object of options related to source copy
optimizations. These options are ignored when
targeting WSL1.
copyOptimizations.maxSmallChange : The maximum
number of files to copy using sftp instead of rsync.
Defaults to 10.
copyOptimizations.useOptimizations : Specifies the copy
optimizations in use. Accepted values are no copy
optimizations ( None ), rsync only optimizations
( RsyncOnly ), or rsync and sftp optimizations
( RsyncAndSftp ). Defaults to RsyncAndSftp .
copyOptimizations.rsyncSingleDirectoryCommandArgs : A
list of command-line arguments passed to rsync when
copying the contents of a single directory to the remote
system. Defaults to [ "-t", "-d" ] . This option
supports macro expansion.
copyAdditionalIncludeDirectoriesList A list of paths to remote header directories to be copied
locally for IntelliSense. This option supports macro
expansion.
copyExcludeDirectoriesList A list of paths to remote header directories to not be
copied locally for IntelliSense. This option supports
macro expansion.
forceWSL1Toolset If true , Visual Studio will always use the WSL1 toolset
when targeting WSL from Visual Studio. The WSL1
toolset executes all commands locally and relies on
Windows drives mounted under the /mnt folder to
access local source files from WSL. These options may
be slower with WSL2. Defaults to false .
The WSL1 toolset will always be used in Visual Studio
2019 version 16.10. This option will be relevant once
native support for WSL2 is available.
Options for a remotePrebuildEvent and remotePostbuildEvent have been deprecated
with the adoption of CMakePresets.json .
Remote pre-build and post-build events
Encode pre-build, pre-link, and post-build events in your CMakeLists.txt using
add_custom_command . It ensures the same behavior when building with Visual
Studio and from the command line.
If you need behavior that is specific to Visual Studio, you can add a custom remote task
in tasks.vs.json . To get started, right-click on your root CMakeLists.txt in the Solution
Explorer from Folder View and select Configure Tasks. You can then add a new remote
task to your tasks.vs.json file.
The following remote task creates a directory called test on the remote Linux system:
JSON
Right-click on any CMakeLists.txt and select the mkdir option to execute this task.
The value of remoteMachineName must match the Host Name of a connection in the
Connection Manager.
The two Microsoft vendor maps, Visual Studio Settings and Visual Studio Remote
Settings , support all the macros defined by CMake. Our vendor maps support all the
macros defined by CMake. For more information, see cmake-presets Macro
Expansion . All macros and environment variables are expanded before being passed
to CMake.
Visual Studio supports vendor macros with the prefix ms . Microsoft vendor macros can
only be used in Microsoft vendor maps. CMake can't use presets that have vendor
macros outside of a vendor map.
Macro Description
$ms{projectDirName} Evaluates to the name of the open folder in Visual Studio. This macro is
used to set the default value of sourceDir in remote copy scenarios. This
macro is not supported by Visual Studio Code. Use ${sourceDirName}
instead.
{
 "taskLabel": "mkdir",
 "appliesTo": "CMakeLists.txt",
 "type": "remote",
 "command": "mkdir test",
 "remoteMachineName": "localhost"
 }
Microsoft vendor macros
Macro Description
$env{<variable￾name>}
$penv{<variable￾name>}
Reference environment variables using this syntax supported by CMake. For
more information, see cmake-presets Macro Expansion .
A few macros that were supported by CMakeSettings.json have been deprecated with
the adoption of CMakePresets.json .
Use the macros supported by CMake to construct your file paths. When you use the
macros, it ensures that the same CMakePresets.json file works inside Visual Studio and
from the command line.
Deprecated macro Recommendation
${projectFile} ${sourceDir}/CMakeLists.txt
${thisFile} ${sourceDir}/CMakePresets.json
Use the $env{HOME} syntax to reference $HOME when constructing Linux paths in the
Microsoft vendor maps.
Environment variables
Deprecated macros
Accepted shell syntax
Customize CMake build settings
Article • 12/15/2021
Visual Studio uses a CMake configuration file to drive CMake generation and build.
CMakePresets.json is supported by Visual Studio 2019 version 16.10 or later and is the
recommended CMake configuration file. CMakePresets.json is supported directly by
CMake and can be used to drive CMake generation and build from Visual Studio, from
VS Code, in a Continuous Integration pipeline, and from the command line on Windows,
Linux, and Mac. For more information on CMakePresets.json , see Configure and build
with CMake Presets.
If you maintain projects that use a CMakeSettings.json file for CMake build
configuration, Visual Studio 2019 and later versions provide a CMake settings editor.
The editor lets you add CMake configurations and customize their settings easily. It's
intended to be a simpler alternative to manually editing the CMakeSettings.json file.
However, if you prefer to edit the file directly, you can select the Edit JSON link in the
upper right of the editor.
To open the CMake settings editor, select the Configuration drop-down in the main
toolbar and choose Manage Configurations.
Now you see the Settings Editor with the installed configurations on the left.
Visual Studio provides one x64-Debug configuration by default. You can add more
configurations by choosing the green plus sign. The settings that you see in the editor
might vary depending on which configuration is selected.
The options that you choose in the editor are written to a file called CMakeSettings.json .
This file provides command-line arguments and environment variables that are passed
to CMake when you build the projects. Visual Studio never modifies CMakeLists.txt
automatically; by using CMakeSettings.json you can customize the build through Visual
Studio while leaving the CMake project files untouched so that others on your team can
consume them with whatever tools they're using.
CMake General Settings
The following settings are available under the General heading:
Configuration name
Corresponds to the name setting. This name appears in the C++ configuration
dropdown. You can use the ${name} macro to compose other property values such as
paths.
Configuration type
Corresponds to the configurationType setting. Defines the build configuration type for
the selected generator. Currently supported values are "Debug", "MinSizeRel", "Release",
and "RelWithDebInfo". It maps to CMAKE_BUILD_TYPE .
Toolset
Corresponds to the inheritedEnvironments setting. Defines the compiler environment
that's used to build the selected configuration. Supported values depend on the type of
configuration. To create a custom environment, choose the Edit JSON link in the upper
right corner of the Settings editor, and edit the CMakeSettings.json file directly.
CMake toolchain file
Path to the CMake toolchain file . This path is passed to CMake as "-
DCMAKE_TOOLCHAIN_FILE = <filepath>". Toolchain files specify locations of compilers
and toolchain utilities, and other target platform and compiler-related information. By
default, Visual Studio uses the vcpkg toolchain file if this setting is unspecified.
Build root
Corresponds to buildRoot. Maps to CMAKE_BINARY_DIR , and specifies where to
create the CMake cache. The specified folder is created if it doesn't exist.
Command arguments
The following settings are available under the Command arguments heading:
CMake command arguments
Corresponds to cmakeCommandArgs. Specifies any more command-line options
passed to CMake.
Build command arguments
Corresponds to buildCommandArgs. Specifies more switches to pass to the underlying
build system. For example, passing -v when using the Ninja generator forces Ninja to
output command lines.
CTest command arguments
Corresponds to ctestCommandArgs. Specifies more command-line options to pass to
CTest when running tests.
General settings for remote builds
For configurations such as Linux that use remote builds, the following settings are also
available:
rsync command arguments
Extra command-line options passed to rsync , a fast, versatile file-copying tool.
CMake variables and cache
These settings enable you to set CMake variables and save them in CMakeSettings.json .
They're passed to CMake at build time, and override whatever values are in the
CMakeLists.txt file. You can use this section in the same way that you might use the
CMakeGUI to view a list of all the CMake variables available to edit. Choose the Save
and generate cache button to view a list of all CMake variables available to edit,
including advanced variables (per the CMakeGUI). You can filter the list by variable
name.
Corresponds to variables. Contains a name-value pair of CMake variables passed as -D
name=value to CMake. If your CMake project build instructions specify the addition of
any variables directly to the CMake cache file, we recommend you add them here
instead.
Advanced settings
CMake generator
Corresponds to generator. Maps to the CMake -G switch, and specifies the CMake
generator to use. This property can also be used as a macro, ${generator} , when
composing other property values. Visual Studio currently supports the following CMake
generators:
"Ninja"
"Unix Makefiles"
"Visual Studio 16 2019"
"Visual Studio 16 2019 Win64"
"Visual Studio 16 2019 ARM"
"Visual Studio 15 2017"
"Visual Studio 15 2017 Win64"
"Visual Studio 15 2017 ARM"
"Visual Studio 14 2015"
"Visual Studio 14 2015 Win64"
"Visual Studio 14 2015 ARM"
Because Ninja is designed for fast build speeds instead of flexibility and function, it's set
as the default. However, some CMake projects may be unable to correctly build using
Ninja. If that occurs, you can instruct CMake to generate a Visual Studio project instead.
IntelliSense mode
The IntelliSense mode used by the IntelliSense engine. If no mode is selected, Visual
Studio inherits the mode from the specified toolset.
Install directory
The directory in which CMake installs targets. Maps to CMAKE_INSTALL_PREFIX .
CMake executable
The full path to the CMake program executable, including the file name and extension. It
allows you to use a custom version of CMake with Visual Studio. For remote builds,
specify the CMake location on the remote machine.
For configurations such as Linux that use remote builds, the following settings are also
available:
Remote CMakeLists.txt root
The directory on the remote machine that contains the root CMakeLists.txt file.
Remote install root
The directory on the remote machine in which CMake installs targets. Maps to
CMAKE_INSTALL_PREFIX .
Specifies whether to copy source files to the remote machine, and lets you specify
whether to use rsync or sftp.
You can also directly edit CMakeSettings.json to create custom configurations. The
Settings Editor has an Edit JSON button in the upper right that opens the file for
editing.
The following example shows a sample configuration, which you can use as a starting
point:
JSON
JSON IntelliSense helps you edit the CMakeSettings.json file:
Remote copy sources
Directly edit CMakeSettings.json
 {
 "name": "x86-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [ "msvc_x86" ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 },
The JSON editor also informs you when you choose incompatible settings.
For more information about each of the properties in the file, see CMakeSettings.json
schema reference.
See also
CMake Projects in Visual Studio
Configure a Linux CMake project
Connect to your remote Linux computer
Configure CMake debugging sessions
Deploy, run, and debug your Linux project
CMake predefined configuration reference
Configure CMake debugging sessions
Article • 10/26/2023
All executable CMake targets are shown in the Startup Item dropdown in the toolbar.
Select one to start a debugging session and launch the debugger.
You can also start a debug session from Solution Explorer. First, switch to CMake Targets
View in the Solution Explorer window.
Then, right-click on an executable and select Debug. This command automatically starts
debugging the selected target based on your active configuration.
Starting in Visual Studio 2022 Version 17.6, you can also start a debugging session on
your CMakeLists.txt file. To do so, just set a breakpoint in your CMakeLists.txt file and
run Configure Project with CMake Debugger from the Project dropdown.
Customize debugger settings
You can customize the debugger settings for any executable CMake target in your
project. They're found in a configuration file called launch.vs.json, located in a .vs folder
in your project root. A launch configuration file is useful in most debugging scenarios,
because you can configure and save your debugging setup details. There are three entry
points to this file:
Debug Menu: Select Debug > Debug and Launch Settings for
${activeDebugTarget} from the main menu to customize the debug configuration
specific to your active debug target. If you don't have a debug target selected, this
option is grayed out.
Targets View: Navigate to Targets View in Solution Explorer. Then, right-click on a
debug target and select Add Debug Configuration to customize the debug
configuration specific to the selected target.
Root CMakeLists.txt: Right-click on a root CMakeLists.txt and select Add Debug
Configuration to open the Select a Debugger dialog box. The dialog allows you to
add any type of debug configuration, but you must manually specify the CMake
target to invoke via the projectTarget property.
You can edit the launch.vs.json file to create debug configurations for any number of
CMake targets. When you save the file, Visual Studio creates an entry for each new
configuration in the Startup Item dropdown.
Reference keys in CMakeSettings.json
To reference any key in a CMakeSettings.json file, prepend cmake. to it in launch.vs.json.
The following example shows a simple launch.vs.json file that pulls in the value of the
remoteCopySources key in the CMakeSettings.json file for the currently selected
configuration:
JSON
Environment variables defined in CMakeSettings.json can also be used in launch.vs.json
using the syntax ${env.VARIABLE_NAME} . In Visual Studio 2019 version 16.4 and later,
debug targets are automatically launched using the environment you specify in
CMakeSettings.json. You can unset an environment variable by setting it to null.
There are many launch.vs.json properties to support all your debugging scenarios. The
following properties are common to all debug configurations, both remote and local:
projectTarget : Specifies the CMake target to invoke when building the project.
Visual Studio autopopulates this property if you enter launch.vs.json from the
Debug Menu or Targets View. This value must match the name of an existing
debug target listed in the Startup Item dropdown.
env : Additional environment variables to add using the syntax:
JSON
args : Command-line arguments passed to the program to debug.
{
 "version": "0.2.1",
 "configurations": [
 {
 "type": "default",
 "project": "CMakeLists.txt",
 "projectTarget": "CMakeHelloWorld.exe (Debug\\CMakeHelloWorld.exe)",
 "name": "CMakeHelloWorld.exe (Debug\\CMakeHelloWorld.exe)",
 "args": ["${cmake.remoteCopySources}"]
 }
 ]
}
Launch.vs.json reference
"env": {
 "DEBUG_LOGGING_LEVEL": "trace;info",
 "ENABLE_TRACING": "true"
 }
Launch.vs.json reference for remote projects
and WSL
In Visual Studio 2019 version 16.6, we added a new debug configuration of type:
cppgdb to simplify debugging on remote systems and WSL. Old debug configurations of
type: cppdbg are still supported.
Configuration type cppgdb
name : A friendly name to identify the configuration in the Startup Item dropdown.
project : Specifies the relative path to the project file. Normally, you don't need to
change this path when debugging a CMake project.
projectTarget : Specifies the CMake target to invoke when building the project.
Visual Studio autopopulates this property if you enter launch.vs.json from the
Debug Menu or Targets View. This target value must match the name of an
existing debug target listed in the Startup Item dropdown.
debuggerConfiguration : Indicates which set of debugging default values to use. In
Visual Studio 2019 version 16.6, the only valid option is gdb . Visual Studio 2019
version 16.7 or later also supports gdbserver .
args : Command-line arguments passed on startup to the program being
debugged.
env : Additional environment variables passed to the program being debugged.
For example, {"DISPLAY": "0.0"} .
processID : Linux process ID to attach to. Only used when attaching to a remote
process. For more information, see Troubleshoot attaching to processes using
GDB .
Additional options for the gdb configuration
program : Defaults to "${debugInfo.fullTargetPath}" . The Unix path to the
application to debug. Only required if different than the target executable in the
build or deploy location.
remoteMachineName : Defaults to "${debugInfo.remoteMachineName}" . Name of the
remote system that hosts the program to debug. Only required if different than
the build system. Must have an existing entry in the Connection Manager. Press
Ctrl+Space to view a list of all existing remote connections.
cwd : Defaults to "${debugInfo.defaultWorkingDirectory}" . The Unix path to the
directory on the remote system where program is run. The directory must exist.
gdbpath : Defaults to /usr/bin/gdb . Full Unix path to the gdb used to debug. Only
required if using a custom version of gdb .
preDebugCommand : A Linux command to run immediately before invoking gdb . gdb
doesn't start until the command completes. You can use the option to run a script
before the execution of gdb .
Additional options allowed with the gdbserver configuration (16.7
or later)
program : Defaults to "${debugInfo.fullTargetPath}" . The Unix path to the
application to debug. Only required if different than the target executable in the
build or deploy location.
 Tip
Deploy is not yet supported for local cross-compilation scenarios. If you are
cross-compiling on Windows (for example, using a cross-compiler on
Windows to build a Linux ARM executable) then you'll need to manually copy
the binary to the location specified by program on the remote ARM machine
before debugging.
remoteMachineName : Defaults to "${debugInfo.remoteMachineName}" . Name of the
remote system that hosts the program to debug. Only required if different than
the build system. Must have an existing entry in the Connection Manager. Press
Ctrl+Space to view a list of all existing remote connections.
cwd : Defaults to "${debugInfo.defaultWorkingDirectory}" . Full Unix path to the
directory on the remote system where program is run. The directory must exist.
gdbPath : Defaults to ${debugInfo.vsInstalledGdb} . Full Windows path to the gdb
used to debug. Defaults to the gdb installed with the Linux development with
C/C++ workload.
gdbserverPath : Defaults to usr/bin/gdbserver . Full Unix path to the gdbserver
used to debug.
preDebugCommand : A Linux command to run immediately before starting gdbserver .
gdbserver doesn't start until the command completes.
Deployment options
Use the following options to separate your build machine (defined in
CMakeSettings.json) from your remote debug machine.
remoteMachineName : Remote debug machine. Only required if different than the
build machine. Must have an existing entry in the Connection Manager. Press
Ctrl+Space to view a list of all existing remote connections.
disableDeploy : Defaults to false . Indicates whether build/debug separation is
disabled. When false , this option allows build and debug to occur on two
separate machines.
deployDirectory : Full Unix path to the directory on remoteMachineName that the
executable gets copied to.
deploy : An array of advanced deployment settings. You only need to configure
these settings when you want more granular control over the deployment process.
By default, only the files necessary for the process to debug get deployed to the
remote debug machine.
sourceMachine : The machine from which the file or directory is copied. Press
Ctrl+Space to view a list of all the remote connections stored in the Connection
Manager. When building natively on WSL, this option is ignored.
targetMachine : The machine to which the file or directory is copied. Press
Ctrl+Space to view a list of all the remote connections stored in the Connection
Manager.
sourcePath : The file or directory location on sourceMachine .
targetPath : The file or directory location on targetMachine .
deploymentType : A description of the deployment type. LocalRemote and
RemoteRemote are supported. LocalRemote means copying from the local file
system to the remote system specified by remoteMachineName in launch.vs.json.
RemoteRemote means copying from the remote build system specified in
CMakeSettings.json to the different remote system specified in launch.vs.json.
executable : Indicates whether the deployed file is an executable.
Execute custom gdb commands
Visual Studio supports executing custom gdb commands to interact with the underlying
debugger directly. For more information, see Executing custom gdb lldb commands .
Enable logging
Enable MIEngine logging to see what commands get sent to gdb , what output gdb
returns, and how long each command takes. Learn more
Configuration type cppdbg
The following options can be used when debugging on a remote system or WSL using
the cppdbg configuration type. In Visual Studio 2019 version 16.6 or later, configuration
type cppgdb is recommended.
name : A friendly name to identify the configuration in the Startup Item dropdown.
project : Specifies the relative path to the project file. Normally, you don't need to
change this value when debugging a CMake project.
projectTarget : Specifies the CMake target to invoke when building the project.
Visual Studio autopopulates this property if you enter launch.vs.json from the
Debug Menu or Targets View. This value must match the name of an existing
debug target listed in the Startup Item dropdown.
args : Command-line arguments passed on startup to the program being
debugged.
processID : Linux process ID to attach to. Only used when attaching to a remote
process. For more information, see Troubleshoot attaching to processes using
GDB .
program : Defaults to "${debugInfo.fullTargetPath}" . The Unix path to the
application to debug. Only required if different than the target executable in the
build or deploy location.
remoteMachineName : Defaults to "${debugInfo.remoteMachineName}" . Name of the
remote system that hosts the program to debug. Only required if different than
the build system. Must have an existing entry in the Connection Manager. Press
Ctrl+Space to view a list of all existing remote connections.
cwd : Defaults to "${debugInfo.defaultWorkingDirectory}" . Full Unix path to the
directory on the remote system where program is run. The directory must exist.
environment : Additional environment variables passed to the program being
debugged. For example,
JSON
 "environment": [
 {
 "name": "ENV1",
 "value": "envvalue1"
 },
 {
 "name": "ENV2",
pipeArgs : An array of command-line arguments passed to the pipe program to
configure the connection. The pipe program is used to relay standard input/output
between Visual Studio and gdb . Most of this array doesn't need to be customized
when debugging CMake projects. The exception is the ${debuggerCommand} , which
launches gdb on the remote system. It can be modified to:
Export the value of the environment variable DISPLAY on your Linux system. In
the following example, this value is :1 .
JSON
Run a script before the execution of gdb . Ensure execute permissions are set on
your script.
JSON
stopOnEntry : A boolean that specifies whether to break as soon as the process is
launched. The default is false.
visualizerFile : A .natvis file to use when debugging this process. This option is
incompatible with gdb pretty printing. Also set showDisplayString when you set
this property.
 "value": "envvalue2"
 }
 ]
"pipeArgs": [
 "/s",
 "${debugInfo.remoteMachineId}",
 "/p",
 "${debugInfo.parentProcessId}",
 "/c",
 "export DISPLAY=:1;${debuggerCommand}",
 "--tty=${debugInfo.tty}"
 ],
"pipeArgs": [
 "/s",
 "${debugInfo.remoteMachineId}",
 "/p",
 "${debugInfo.parentProcessId}",
 "/c",
 "/path/to/script.sh;${debuggerCommand}",
 "--tty=${debugInfo.tty}"
 ],
showDisplayString : A boolean that enables the display string when a
visualizerFile is specified. Setting this option to true can cause slower
performance during debugging.
setupCommands : One or more gdb command(s) to execute, to set up the underlying
debugger.
miDebuggerPath : The full path to gdb . When unspecified, Visual Studio searches
PATH first for the debugger.
Finally, all of the deployment options defined for the cppgdb configuration type
can be used by the cppdbg configuration type as well.
Debug using gdbserver
You can configure the cppdbg configuration to debug using gdbserver . You can find
more details and a sample launch configuration in the Microsoft C++ Team Blog post
Debugging Linux CMake Projects with gdbserver .
See also
CMake projects in Visual Studio
Configure a Linux CMake project
Connect to your remote Linux computer
Customize CMake build settings
Configure CMake debugging sessions
Deploy, run, and debug your Linux project
CMake predefined configuration reference
CMakeSettings.json schema reference
Article • 02/24/2023
The CMakeSettings.json file contains information that Visual Studio uses for IntelliSense
and to construct the command-line arguments that it passes to CMake for a specified
configuration and compiler environment. A configuration specifies properties that apply
to a specific platform and build-type, for example, x86-Debug or Linux-Release . Each
configuration specifies an environment, which encapsulates information about the
compiler toolset, for example MSVC, GCC, or Clang. CMake uses the command-line
arguments to regenerate the root CMakeCache.txt file and other project files for the
project. The values can be overridden in the CMakeLists.txt files.
You can add or remove configurations in the IDE and then edit them directly in the
JSON file or use the CMake Settings editor (Visual Studio 2019 and later). You can
switch between the configurations easily in the IDE to generate the various project files.
For more information, see Customize CMake build settings in Visual Studio.
Configurations
The configurations array contains all the configurations for a CMake project. For more
information about the pre-defined configurations, see CMake predefined configuration
reference. You can add any number of pre-defined or custom configurations to the file.
A configuration has these properties:
addressSanitizerEnabled : If true , compiles the program using AddressSanitizer.
On Linux, compile with -fno-omit-frame-pointer and compiler optimization level -
Os or -Oo for best results.
addressSanitizerRuntimeFlags : The runtime flags passed to AddressSanitizer in the
ASAN_OPTIONS environment variable. Format: flag1=value:flag2=value2.
buildCommandArgs : Specifies native build switches passed to CMake after --build -
- . For example, passing -v when using the Ninja generator forces Ninja to output
command lines. For more information on Ninja commands, see Ninja command
line arguments.
buildRoot : Specifies the directory in which CMake generates build scripts for the
chosen generator. Maps to -DCMAKE_BINARY_DIR switch and specifies where
CMakeCache.txt is created. If the folder doesn't exist, it's created. Supported
macros include ${workspaceRoot} , ${workspaceHash} , ${projectFile} ,
${projectDir} , ${thisFile} , ${thisFileDir} , ${name} , ${generator} ,
${env.VARIABLE} .
cacheGenerationCommand : Specifies a command-line tool and arguments, for
example gencache.bat debug to generate the cache. The command is run from the
shell in the specified environment for the configuration when the user explicitly
requests regeneration, or a CMakeLists.txt or CMakeSettings.json file is modified.
cacheRoot : Specifies the path to a CMake cache. This directory should contain an
existing CMakeCache.txt file.
clangTidyChecks : comma-separated list of warnings that's passed to clang-tidy;
wildcards are allowed and a '-' prefix removes checks.
cmakeCommandArgs : Specifies any extra command-line options to pass to CMake
when invoked to generate the project files.
cmakeToolchain : Specifies the toolchain file. It's passed to CMake using -
DCMAKE_TOOLCHAIN_FILE .
codeAnalysisRuleset : Specifies the ruleset to use when running code analysis. You
can use a full path or the filename of a ruleset file installed by Visual Studio.
configurationType : Specifies the build type configuration for the selected
generator. May be one of:
Debug
Release
MinSizeRel
RelWithDebInfo
ctestCommandArgs : Specifies any extra command-line options to pass to CTest when
running the tests.
description : The description of this configuration that appears in menus.
enableClangTidyCodeAnalysis : Use Clang-Tidy for code analysis.
enableMicrosoftCodeAnalysis : Use Microsoft code analysis tools for code analysis.
generator : Specifies the CMake generator to use for this configuration. May be
one of:
Visual Studio 2019 only:
Visual Studio 16 2019
Visual Studio 16 2019 Win64
Visual Studio 16 2019 ARM
Visual Studio 2017 and later:
Visual Studio 15 2017
Visual Studio 15 2017 Win64
Visual Studio 15 2017 ARM
Visual Studio 14 2015
Visual Studio 14 2015 Win64
Visual Studio 14 2015 ARM
Unix Makefiles
Ninja
Because Ninja is designed for fast build speeds instead of flexibility and function, it's set
as the default. However, some CMake projects may be unable to correctly build using
Ninja. If a build failure occurs, you can instruct CMake to generate Visual Studio projects
instead.
To specify a Visual Studio generator in Visual Studio 2017, open the settings editor from
the main menu by choosing CMake | Change CMake Settings. Delete "Ninja" and enter
"V". This change activates IntelliSense, which lets you choose the generator you want.
To specify a Visual Studio generator in Visual Studio 2019, right-click on the
CMakeLists.txt file in Solution Explorer and choose CMake Settings for project >
Show Advanced Settings > CMake Generator.
By default, when the active configuration specifies a Visual Studio generator, it invokes
MSBuild with -m -v:minimal arguments. To customize the build, use the
buildCommandArgs property inside the CMakeSettings.json file. Here, you can specify
MSBuild command line arguments to pass to the build system:
JSON
"buildCommandArgs": "-m:8 -v:minimal -p:PreferredToolArchitecture=x64"
installRoot : Specifies the directory in which CMake generates install targets for
the chosen generator. Supported macros include ${workspaceRoot} ,
${workspaceHash} , ${projectFile} , ${projectDir} , ${thisFile} , ${thisFileDir} ,
${name} , ${generator} , ${env.VARIABLE} .
inheritEnvironments : Specifies one or more compiler environments that this
configuration depends on. May be any custom environment or one of the
predefined environments. For more information, see Environments.
intelliSenseMode : Specifies the mode used for computing intellisense
information". The value may be one of:
windows-msvc-x86
windows-msvc-x64
windows-msvc-arm
windows-msvc-arm64
android-clang-x86
android-clang-x64
android-clang-arm
android-clang-arm64
ios-clang-x86
ios-clang-x64
ios-clang-arm
ios-clang-arm64
windows-clang-x86
windows-clang-x64
windows-clang-arm
windows-clang-arm64
linux-gcc-x86
linux-gcc-x64
linux-gcc-arm
name : names the configuration. For more information about the pre-defined
configurations, see CMake predefined configuration reference.
wslPath : the path to the launcher of an instance of Windows Subsystem for Linux.
Settings for CMake Linux projects
remoteMachineName : Specifies the name of the remote Linux machine that hosts
CMake, builds, and the debugger. Use the Connection Manager for adding new
Linux machines. Supported macros include ${defaultRemoteMachineName} .
remoteCopySourcesOutputVerbosity : Specifies the verbosity level of the source
copying operation to the remote machine. May be one of Normal , Verbose , or
Diagnostic .
remoteCopySourcesConcurrentCopies : Specifies the concurrent copies to use during
synchronization of the sources to the remote machine (sftp only).
remoteCopySourcesMethod : Specifies the method to copy files to the remote
machine. May be rsync or sftp .
remoteCMakeListsRoot : Specifies the directory on the remote machine that contains
the CMake project. Supported macros include ${workspaceRoot} ,
${workspaceHash} , ${projectFile} , ${projectDir} , ${thisFile} , ${thisFileDir} ,
${name} , ${generator} , and ${env.VARIABLE} .
remoteBuildRoot : Specifies the directory on the remote machine in which CMake
generates build scripts for the chosen generator. Supported macros include
${workspaceRoot} , ${workspaceHash} , ${projectFile} , ${projectDir} , ${thisFile} ,
${thisFileDir} , ${name} , ${generator} , ${env.VARIABLE} .
remoteInstallRoot : Specifies the directory on the remote machine in which CMake
generates install targets for the chosen generator. Supported macros include
${workspaceRoot} , ${workspaceHash} , ${projectFile} , ${projectDir} , ${thisFile} ,
${thisFileDir} , ${name} , ${generator} , and ${env.VARIABLE} , where VARIABLE is
an environment variable that's been defined at the system, user, or session level.
remoteCopySources : A boolean that specifies whether Visual Studio should copy
source files to the remote machine. The default is true. Set to false if you manage
file synchronization yourself.
remoteCopyBuildOutput : A boolean that specifies whether to copy the build outputs
from the remote system.
remoteCopyAdditionalIncludeDirectories : Additional include directories to be
copied from the remote machine to support IntelliSense. Format as
"/path1;/path2...".
remoteCopyExcludeDirectories : Include directories NOT to copy from the remote
machine. Format as "/path1;/path2...".
remoteCopyUseCompilerDefaults : Specifies whether to use the compiler's default
defines and include paths for IntelliSense. Should only be false if the compilers in
use to not support gcc-style arguments.
rsyncCommandArgs : Specifies a set of command-line options passed to rsync.
remoteCopySourcesExclusionList : An array that specifies a list of paths to be
excluded when copying source files: a path can be the name of a file/directory, or a
relative path from the root of the copy. Wildcards * and ? can be used for glob
pattern matching.
cmakeExecutable : Specifies the full path to the CMake program executable,
including the file name and extension.
remotePreGenerateCommand : Specifies the command to run before running CMake
to parse the CMakeLists.txt file.
remotePrebuildCommand : Specifies the command to run on the remote machine
before building.
remotePostbuildCommand : Specifies the command to run on the remote machine
after building.
variables : Contains a name-value pair of CMake variables that get passed as -D
name=value to CMake. If your CMake project build instructions specify the addition
of any variables directly to the CMakeCache.txt file, we recommend you add them
here instead. This example shows how to specify the name-value pairs to use the
14.14.26428 MSVC toolset:
JSON
If you don't define the "type" , the "STRING" type is assumed by default.
remoteCopyOptimizations : Visual Studio 2019 version 16.5 or later properties for
controlling source copy to the remote target. Optimizations are enabled by
default. Includes remoteCopyUseOptimizations , rsyncSingleDirectoryCommandArgs ,
and remoteCopySourcesMaxSmallChange .
An environment encapsulates the environment variables set in the process that Visual
Studio uses to invoke CMake. For MSVC projects, it captures the variables set in a
developer command prompt for a specific platform. For example, the msvc_x64_x64
environment is the same as running the Developer Command Prompt for VS {version}
with the -arch=amd64 -host_arch=amd64 arguments. You can use the env.
{<variable_name>} syntax in CMakeSettings.json to reference the individual environment
"variables": [
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "C:/Program Files (x86)/Microsoft Visual
Studio/157/Enterprise/VC/Tools/MSVC/14.14.26428/bin/HostX86/x86/cl.exe",
 "type": "FILEPATH"
 },
 {
 "name": "CMAKE_C_COMPILER",
 "value": "C:/Program Files (x86)/Microsoft Visual
Studio/157/Enterprise/VC/Tools/MSVC/14.14.26428/bin/HostX86/x86/cl.exe",
 "type": "FILEPATH"
 }
 ]
Environments
variables, for example to construct paths to folders. The following predefined
environments are provided:
linux_arm : Target ARM Linux remotely.
linux_x64 : Target x64 Linux remotely.
linux_x86 : Target x86 Linux remotely.
msvc_arm : Target ARM Windows with the MSVC compiler.
msvc_arm_x64 : Target ARM Windows with the 64-bit MSVC compiler.
msvc_arm64 : Target ARM64 Windows with the MSVC compiler.
msvc_arm64_x64 : Target ARM64 Windows with the 64-bit MSVC compiler.
msvc_arm64ec : Target ARM64EC Windows with the MSVC compiler.
msvc_arm64ec_x64 : Target ARM64EC Windows with the 64-bit MSVC compiler.
msvc_x64 : Target x64 Windows with the MSVC compiler.
msvc_x64_x64 : Target x64 Windows with the 64-bit MSVC compiler.
msvc_x86 : Target x86 Windows with the MSVC compiler.
msvc_x86_x64 : Target x86 Windows with the 64-bit MSVC compiler.
Accessing environment variables from CMakeLists.txt
From a CMakeLists.txt file, all environment variables are referenced by the syntax
$ENV{variable_name} . To see the available variables for an environment, open the
corresponding command prompt and type SET . Some of the information in
environment variables is also available through CMake system introspection variables,
but you may find it more convenient to use the environment variable. For example, you
can easily retrieve the MSVC compiler version or Windows SDK version through the
environment variables.
Custom environment variables
In CMakeSettings.json , you can define custom environment variables globally or per￾configuration in the environments array. A custom environment is a convenient way to
group a set of properties. You can use it in place of a predefined environment, or to
extend or modify a predefined environment. Each item in the environments array
consists of:
namespace : Names the environment so that its variables can be referenced from a
configuration in the form namespace.variable . The default environment object is
called env and is populated with certain system environment variables including
%USERPROFILE% .
environment : Uniquely identifies this group of variables. Allows the group to be
inherited later in an inheritEnvironments entry.
groupPriority : An integer that specifies the priority of these variables when
evaluating them. Higher number items are evaluated first.
inheritEnvironments : An array of values that specify the set of environments that
are inherited by this group. This feature lets you inherit default environments and
create custom environment variables to pass to CMake when it runs.
Visual Studio 2019 version 16.4 and later: Debug targets are automatically launched
with the environment you specify in CMakeSettings.json . You can override or add
environment variables on a per-target or per-task basis in launch.vs.json and
tasks.vs.json.
The following example defines one global variable, BuildDir , which is inherited in both
the x86-Debug and x64-Debug configurations. Each configuration uses the variable to
specify the value for the buildRoot property for that configuration. Note also how each
configuration uses the inheritEnvironments property to specify a variable that applies
only to that configuration.
JSON
{
 // The "environments" property is an array of key-value pairs of the form
 // { "EnvVar1": "Value1", "EnvVar2": "Value2" }
 "environments": [
 {
 "BuildDir":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build",
 }
 ],
 "configurations": [
 {
 "name": "x86-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 // Inherit the defaults for using the MSVC x86 compiler.
 "inheritEnvironments": [ "msvc_x86" ],
 "buildRoot": "${env.BuildDir}\\${name}" },
 {
 "name": "x64-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 // Inherit the defaults for using the MSVC x64 compiler.
 "inheritEnvironments": [ "msvc_x64" ],
 "buildRoot": "${env.BuildDir}\\${name}"
 }
In the next example, the x86-Debug configuration defines its own value for the BuildDir
property. This value overrides the value set by the global BuildDir property so that
BuildRoot evaluates to D:\custom-builddir\x86-Debug .
JSON
 ]
}
{
 "environments": [
 {
 "BuildDir": "${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}",
 }
 ],
 "configurations": [
 {
 "name": "x86-Debug",
 // The syntax for this property is the same as the global one above.
 "environments": [
 {
 // Replace the global property entirely.
 "BuildDir": "D:\\custom-builddir"
 // This environment does not specify a namespace, hence by default
"env" is assumed.
 // "namespace" : "name" would require that this variable be
referenced with "${name.BuildDir}".
 }
 ],
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [ "msvc_x86" ],
 // Evaluates to "D:\custom-builddir\x86-Debug"
 "buildRoot": "${env.BuildDir}\\${name}"
 },
 {
 "name": "x64-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [ "msvc_x64" ],
 // Since this configuration doesn't modify BuildDir, it inherits
 // from the one defined globally.
 "buildRoot": "${env.BuildDir}\\${name}"
 }
 ]
}
The following macros can be used in CMakeSettings.json :
${workspaceRoot} – the full path of the workspace folder
${workspaceHash} – hash of workspace location; useful for creating a unique
identifier for the current workspace (for example, to use in folder paths)
${projectFile} – the full path of the root CMakeLists.txt file
${projectDir} – the full path of the folder containing the root CMakeLists.txt file
${projectDirName} – the name of the folder containing the root CMakeLists.txt
file
${thisFile} – the full path of the CMakeSettings.json file
${name} – the name of the configuration
${generator} – the name of the CMake generator used in this configuration
All references to macros and environment variables in CMakeSettings.json are expanded
before being passed to the CMake command line.
If targets are unspecified, Ninja builds the 'default' target.
Windows Command Prompt
Option Description
--
version
Print ninja version ("1.7.1")
-C DIR Change to DIR before doing anything else
-f
FILE
Specify input build file (default=build.ninja )
-j N Run N jobs in parallel (default=14, derived from CPUs available)
-k N Keep going until N jobs fail (default=1)
-l N Don't start new jobs if the load average is greater than N
Macros
Ninja command-line arguments
C:\Program Files (x86)\Microsoft Visual Studio\Preview\Enterprise>ninja -?
ninja: invalid option -- `-?'
usage: ninja [options] [targets...]
Option Description
-n Dry run (don't run commands but act like they succeeded)
-v Show all command lines while building
-d
MODE
Enable debugging (use -d list to list modes)
-t
TOOL
Run a subtool (use -t list to list subtools). Ends any top-level options; further flags
are passed to the tool
-w
FLAG
Adjust warnings (use -w list to list warnings)
CMake predefined build configurations
Article • 10/29/2021
In a CMake project, build configurations are stored in a CMakeSettings.json file. When
you choose Manage Configurations from the build configuration dropdown in the main
toolbar, a dialog appears that shows the default CMake configurations available in
Visual Studio:
x86 Debug
x86 Release
x64 Debug
x64 Release
Linux-Debug
Linux-Release
IoT Debug
IoT Release
MinGW Debug
MinGW Release
When you choose a configuration, it's added to the CMakeSettings.json file in the
project's root folder. You can then use it to build your project. For information about the
configuration properties, see CMakeSettings reference.
JSON
Linux predefined build configurations:
{
 "name": "Linux-Debug",
 "generator": "Unix Makefiles",
 "remoteMachineName": "user@host",
 "configurationType": "Debug",
 "remoteCMakeListsRoot": "/var/tmp/src/${workspaceHash}/${name}",
 "cmakeExecutable": "/usr/local/bin/cmake",
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "remoteBuildRoot": "/var/tmp/build/${workspaceHash}/build/${name}",
 "remoteInstallRoot":
"/var/tmp/build/${workspaceHash}/install/${name}",
 "remoteCopySources": true,
 "remoteCopySourcesOutputVerbosity": "Normal",
 "remoteCopySourcesConcurrentCopies": "10",
 "remoteCopySourcesMethod": "rsync",
You can use these optional settings for more control:
JSON
 "remoteCopySourcesExclusionList": [
 ".vs",
 ".git"
 ],
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [
 "linux_x64"
 ]
}
{
 "name": "Linux-Release",
 "generator": "Unix Makefiles",
 "remoteMachineName": "${defaultRemoteMachineName}",
 "configurationType": "RelWithDebInfo",
 "remoteCMakeListsRoot": "/var/tmp/src/${workspaceHash}/${name}",
 "cmakeExecutable": "/usr/local/bin/cmake",
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "remoteBuildRoot": "/var/tmp/build/${workspaceHash}/build/${name}",
 "remoteInstallRoot":
"/var/tmp/build/${workspaceHash}/install/${name}",
 "remoteCopySources": true,
 "remoteCopySourcesOutputVerbosity": "Normal",
 "remoteCopySourcesConcurrentCopies": "10",
 "remoteCopySourcesMethod": "rsync",
 "remoteCopySourcesExclusionList": [
 ".vs",
 ".git"
 ],
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [
 "linux_x64"
 ]
},
{
 "remotePrebuildCommand": "",
 "remotePreGenerateCommand": "",
These options allow you to run commands on the remote system before and after
building, and before CMake generation. The values can be any command that is valid on
the remote system. The output is piped back to Visual Studio.
JSON
 "remotePostbuildCommand": "",
}
IoT predefined build configurations
{
 "name": "IoT-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [
 "gcc-arm"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "intelliSenseMode": "linux-gcc-arm",
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "arm-none-eabi-gcc.exe"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "arm-none-eabi-g++.exe"
 },
 {
 "name": "CMAKE_C_FLAGS",
 "value": "-nostartfiles"
 },
 {
 "name": "CMAKE_CXX_FLAGS",
 "value": "-nostartfiles -fno-rtti -fno-exceptions"
 },
 {
 "name": "CMAKE_CXX_STANDARD",
 "value": "14"
 },
 {
 "name": "CMAKE_SYSTEM_NAME",
 "value": "Generic"
 },
 {
 "name": "CMAKE_SYSTEM_PROCESSOR",
 "value": "arm"
 }
 ]
 },
 {
 "name": "IoT-Release",
 "generator": "Ninja",
 "configurationType": "Release",
 "inheritEnvironments": [
 "gcc-arm"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "intelliSenseMode": "linux-gcc-arm",
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "arm-none-eabi-gcc.exe"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "arm-none-eabi-g++.exe"
 },
 {
 "name": "CMAKE_C_FLAGS",
 "value": "-nostartfiles"
 },
 {
 "name": "CMAKE_CXX_FLAGS",
 "value": "-nostartfiles -fno-rtti -fno-exceptions"
 },
 {
 "name": "CMAKE_CXX_STANDARD",
 "value": "14"
 },
 {
 "name": "CMAKE_SYSTEM_NAME",
 "value": "Generic"
 },
 {
 "name": "CMAKE_SYSTEM_PROCESSOR",
 "value": "arm"
 }
 ]
 }
JSON
MinGW predefined build configurations
{
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
 "TOOLSET_VERSION": "7.3.0",
 "PATH":
"${env.MINGW64_ROOT}\\bin;${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MIN
GW64_ROOT}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.INCLUDE};${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${
env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_R
OOT}\\include\\c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR}",
 "environment": "mingw_64"
 }
 ],
 "name": "Mingw64-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [
 "mingw_64"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "intelliSenseMode": "linux-gcc-x64",
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "${env.BIN_ROOT}\\gcc.exe"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "${env.BIN_ROOT}\\g++.exe"
 }
 ]
 }
{
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
JSON
 "TOOLSET_VERSION": "7.3.0",
 "PATH":
"${env.MINGW64_ROOT}\\bin;${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MIN
GW64_ROOT}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.INCLUDE};${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${
env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_R
OOT}\\include\\c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR}",
 "environment": "mingw_64"
 }
 ],
 "name": "Mingw64-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "inheritEnvironments": [
 "mingw_64"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "intelliSenseMode": "linux-gcc-x64",
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "${env.BIN_ROOT}\\gcc.exe"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "${env.BIN_ROOT}\\g++.exe"
 }
 ]
 }
x86-64 predefined build configurations
 {
 "name": "x86-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [
 "msvc_x86"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 },
 {
 "name": "x86-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "inheritEnvironments": [
 "msvc_x86"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 },
 {
 "name": "x64-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "inheritEnvironments": [
 "msvc_x64_x64"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 },
 {
 "name": "x64-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "inheritEnvironments": [
 "msvc_x64_x64"
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 },
 {
 "name": "x86-Release2",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "inheritEnvironments": [
 "msvc_x86"
In a CMake project, build configurations are stored in a CMakeSettings.json file. When
you choose Manage Configurations from the build configuration dropdown in the main
toolbar, a dialog appears that shows the default CMake configurations available in
Visual Studio:
x86 Debug
x86 Clang Debug
x86 Release
x86 Clang Release
x64 Debug
x64 Clang Debug
x64 Release
x64 Clang Release
Linux-Debug
Linux-Release
Linux-Clang-Debug
Linux-Clang-Release
Existing Cache (remote)
Existing Cache
MinGW Debug
MinGW Release
WSL Debug
WSL Release
WSL Clang Debug
WSL Clang Release
Clang
When you choose a configuration, it's added to the CMakeSettings.json file in the
project's root folder. You can then use it to build your project.
JSON
 ],
 "buildRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\build\\${name}",
 "installRoot":
"${env.USERPROFILE}\\CMakeBuilds\\${workspaceHash}\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": ""
 }
 ]
}
{
 "configurations": [
 {
 "name": "x64-Debug",
 "generator": "Ninja",
 "configurationType": "Release",
 "inheritEnvironments": [ "msvc_x64_x64" ],
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "variables": []
 },
 {
 "name": "Linux-Debug",
 "generator": "Unix Makefiles",
 "configurationType": "Release",
 "cmakeExecutable": "/usr/bin/cmake",
 "remoteCopySourcesExclusionList": [ ".vs", ".git", "out" ],
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_x64" ],
 "remoteMachineName": "${defaultRemoteMachineName}",
 "remoteCMakeListsRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/src",
 "remoteBuildRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/build/${name}",
 "remoteInstallRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/install/${name}",
 "remoteCopySources": true,
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "remoteCopySourcesMethod": "rsync",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "Linux-Release",
 "generator": "Unix Makefiles",
 "configurationType": "RelWithDebInfo",
 "cmakeExecutable": "/usr/bin/cmake",
 "remoteCopySourcesExclusionList": [ ".vs", ".git", "out" ],
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_x64" ],
 "remoteMachineName": "${defaultRemoteMachineName}",
 "remoteCMakeListsRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/src",
 "remoteBuildRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/build/${name}",
 "remoteInstallRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/install/${name}",
 "remoteCopySources": true,
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "remoteCopySourcesMethod": "rsync",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "Linux-Clang-Debug",
 "generator": "Unix Makefiles",
 "configurationType": "Debug",
 "cmakeExecutable": "/usr/bin/cmake",
 "remoteCopySourcesExclusionList": [ ".vs", ".git", "out" ],
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_clang_x64" ],
 "remoteMachineName": "${defaultRemoteMachineName}",
 "remoteCMakeListsRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/src",
 "remoteBuildRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/build/${name}",
 "remoteInstallRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/install/${name}",
 "remoteCopySources": true,
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "remoteCopySourcesMethod": "rsync",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "Linux-Clang-Release",
 "generator": "Unix Makefiles",
 "configurationType": "RelWithDebInfo",
 "cmakeExecutable": "/usr/bin/cmake",
 "remoteCopySourcesExclusionList": [ ".vs", ".git", "out" ],
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_clang_x64" ],
 "remoteMachineName": "${defaultRemoteMachineName}",
 "remoteCMakeListsRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/src",
 "remoteBuildRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/build/${name}",
 "remoteInstallRoot":
"$HOME/.vs/${projectDirName}/${workspaceHash}/out/install/${name}",
 "remoteCopySources": true,
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "remoteCopySourcesMethod": "rsync",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "Existing Cache (Remote)",
 "cacheRoot": "",
 "remoteCopySourcesExclusionList": [ ".vs", ".git", "out" ],
 "inheritEnvironments": [ "linux_x64" ],
 "remoteMachineName": "${defaultRemoteMachineName}",
 "remoteCopySources": false,
 "rsyncCommandArgs": "-t --delete --delete-excluded",
 "remoteCopyBuildOutput": false,
 "remoteCopySourcesMethod": "rsync",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "Mingw64-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "mingw_64" ],
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
 "TOOLSET_VERSION": "7.3.0",
 "PATH":
"${env.MINGW64_ROOT}\\bin;${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MIN
GW64_ROOT}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.INCLUDE};${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${
env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_R
OOT}\\include\\c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR}",
 "environment": "mingw_64"
 }
 ],
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "${env.BIN_ROOT}\\gcc.exe",
 "type": "STRING"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "${env.BIN_ROOT}\\g++.exe",
 "type": "STRING"
 }
 ],
 "intelliSenseMode": "linux-gcc-x64"
 },
 {
 "name": "Mingw64-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "mingw_64" ],
 "environments": [
 {
 "MINGW64_ROOT": "C:\\msys64\\mingw64",
 "BIN_ROOT": "${env.MINGW64_ROOT}\\bin",
 "FLAVOR": "x86_64-w64-mingw32",
 "TOOLSET_VERSION": "7.3.0",
 "PATH":
"${env.MINGW64_ROOT}\\bin;${env.MINGW64_ROOT}\\..\\usr\\local\\bin;${env.MIN
GW64_ROOT}\\..\\usr\\bin;${env.MINGW64_ROOT}\\..\\bin;${env.PATH}",
 "INCLUDE":
"${env.INCLUDE};${env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION};${
env.MINGW64_ROOT}\\include\\c++\\${env.TOOLSET_VERSION}\\tr1;${env.MINGW64_R
OOT}\\include\\c++\\${env.TOOLSET_VERSION}\\${env.FLAVOR}",
 "environment": "mingw_64"
 }
 ],
 "variables": [
 {
 "name": "CMAKE_C_COMPILER",
 "value": "${env.BIN_ROOT}\\gcc.exe",
 "type": "STRING"
 },
 {
 "name": "CMAKE_CXX_COMPILER",
 "value": "${env.BIN_ROOT}\\g++.exe",
 "type": "STRING"
 }
 ],
 "intelliSenseMode": "linux-gcc-x64"
 },
 {
 "name": "x64-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "msvc_x64_x64" ],
 "variables": []
 },
 {
 "name": "x86-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "msvc_x86" ],
 "variables": []
 },
 {
 "name": "x86-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "msvc_x86" ],
 "variables": []
 },
 {
 "name": "x86-Clang-Debug",
 "generator": "Ninja",
 "configurationType": "Debug",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "clang_cl_x86" ],
 "variables": []
 },
 {
 "name": "x86-Clang-Release",
 "generator": "Ninja",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "-v",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "clang_cl_x86" ],
 "variables": []
 },
 {
 "name": "Existing Cache",
 "cacheRoot": "",
 "inheritEnvironments": [],
 "variables": []
 },
 {
 "name": "WSL-Debug",
 "generator": "Unix Makefiles",
 "configurationType": "Debug",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeExecutable": "/usr/bin/cmake",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_x64" ],
 "wslPath": "${defaultWSLPath}",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "WSL-Release",
 "generator": "Unix Makefiles",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeExecutable": "/usr/bin/cmake",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_x64" ],
 "wslPath": "${defaultWSLPath}",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "WSL-Clang-Debug",
 "generator": "Unix Makefiles",
 "configurationType": "Debug",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeExecutable": "/usr/bin/cmake",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_clang_x64" ],
 "wslPath": "${defaultWSLPath}",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 },
 {
 "name": "WSL-Clang-Release",
 "generator": "Unix Makefiles",
 "configurationType": "RelWithDebInfo",
 "buildRoot": "${projectDir}\\out\\build\\${name}",
 "installRoot": "${projectDir}\\out\\install\\${name}",
 "cmakeExecutable": "/usr/bin/cmake",
 "cmakeCommandArgs": "",
 "buildCommandArgs": "",
 "ctestCommandArgs": "",
 "inheritEnvironments": [ "linux_clang_x64" ],
 "wslPath": "${defaultWSLPath}",
 "addressSanitizerRuntimeFlags": "detect_leaks=0",
 "variables": []
 }
 ]
}
See also
CMake Projects in Visual Studio
Configure a Linux CMake project
Connect to your remote Linux computer
Configure CMake debugging sessions
Deploy, run, and debug your Linux project
CMake predefined configuration reference
Get started with C++ Build Insights
Article • 11/12/2024
C++ Build Insights is a collection of tools that collect data about your C++ builds, and
present it in a format that can help you answer common questions such as:
Are my builds sufficiently parallelized?
What should I include in my pre-compiled header (PCH)?
Is there a specific bottleneck I should focus on to increase my build speeds?
The main components of this technology are:
vcperf.exe , a command-line utility that you can use to collect traces for your
builds
A Windows Performance Analyzer (WPA) extension that allows you to view build
traces in WPA, and
The C++ Build Insights software development kit for creating your own tools that
consume C++ Build Insights data.
Documentation sections
vcperf and Windows Performance Analyzer
Learn how to collect build traces for your C++ projects and how to view them in WPA.
Windows Performance Basics
Discover useful WPA tips for analyzing your build traces.
C++ Build Insights SDK
An overview of the C++ Build Insights SDK.
Articles
Read these articles from the official C++ team blog for more information on C++ Build
Insights:
Introducing C++ Build Insights
Analyze your builds programmatically with the C++ Build Insights SDK
Finding build bottlenecks with C++ Build Insights
Faster builds with PCH suggestions from C++ Build Insights
Profiling template metaprograms with C++ Build Insights
Improving code generation time with C++ Build Insights
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Introducing vcperf /timetrace for C++ build time analysis
Faster C++ builds, simplified: a new metric for time
 Yes  No
Compare header units, modules, and
precompiled headers
Article • 12/05/2022
Historically, you'd include the standard library with a directive like #include <vector> .
However, it's expensive to include header files because they're reprocessed by every
source file that includes them.
Precompiled headers (PCH) were introduced to speed compilation by translating them
once and reusing the result. But precompiled headers can be difficult to maintain.
In C++20, modules were introduced as a significant improvement on header files and
precompiled headers.
Header units were introduced in C++20 as a way to temporarily bridge the gap between
header files and modules. They provide some of the speed and robustness benefits of
modules, while you migrate your code to use modules.
Then, the C++23 standard library introduced support for importing the standard library
as named modules. This is the fastest and most robust way to consume the standard
library.
To help you sort out the different options, this article compares the traditional #include
method against precompiled headers, header units, and importing named modules.
The following table is arranged by compiler processing speed and robustness, with
#include being the slowest and least robust, and import being the fastest and most
robust.
Method Summary
#include One disadvantage is that they expose macros and internal implementation.
Internal implementation is often exposed as functions and types that start with an
underscore. That's a convention to indicate that something is part of the internal
implementation and shouldn't be used.
Header files are fragile because the order of #includes can modify behavior or
break code and are affected by macro definitions.
Header files slow compilation. Particularly when multiple files include the same file
because then the header file is reprocessed multiple times.
Method Summary
Precompiled
header
A precompiled header (PCH) improves compile time by creating a compiler
memory snapshot of a set of header files. This is an improvement on repeatedly
rebuilding header files.
PCH files have restrictions that make them difficult to maintain.
PCH files are faster than #include but slower than import .
Header
units
This is a new feature in C++20 that allows you to import 'well-behaved' header
files as modules.
Header units are faster than #include , and are easier to maintain, significantly
smaller, and also faster than pre-compiled header files (PCH).
Header units are an 'in-between' step meant to help transition to named modules
in cases where you rely on macros defined in header files, since named modules
don't expose macros.
Header units are slower than importing a named module.
Header units aren't affected by macro defines unless they're specified on the
command line when the header unit is built--making them more robust than
header files.
Header units expose the macros and internal implementation defined in them just
as header file do, which named modules don't.
As a rough approximation of file size, a 250-megabyte PCH file might be
represented by an 80-megabyte header unit file.
Method Summary
Modules This is the fastest and most robust way to import functionality.
Support for importing modules was introduced in C++20. The C++23 standard
library introduces the two named modules described in this topic.
When you import std , you get the standard names such as std::vector ,
std::cout , but no extensions, no internal helpers such as _Sort_unchecked , and no
macros.
The order of imports doesn't matter because there are no macro or other side￾effects.
As a rough approximation of file size, a 250-megabyte PCH file might be
represented by an 80-megabyte header unit file, which might be represented by a
25-megabyte module.
Named modules are faster because when a named module is compiled into an
.ifc file and an .obj file, the compiler emits a structured representation of the
source code that can be loaded quickly when the module is imported. The
compiler can do some work (like name resolution) before emitting the .ifc file
because of how named modules are order-independent and macro-independent--
so this work doesn't have to be done when the module is imported. In contrast,
when a header file is consumed with #include , its contents must be preprocessed
and compiled again and again in every translation unit. 
Precompiled headers, which are compiler memory snapshots, can mitigate those
costs, but not as well as named modules.
If you can use C++20 features and the C++23 standard library in your app, use named
modules.
If you can use C++20 features but want to transition over time to modules, use header
units in the interim.
If you can't use C++20 features, use #include and consider precompiled headers.
Precompiled header files
Overview of modules in C++
Tutorial: Import the C++ standard library using modules
Walkthrough: Import STL libraries as header units
Walkthrough: Build and import header units in your Visual C++ projects
See also
Walkthrough: Build and import header
units in Microsoft Visual C++
Article • 12/05/2022
This article is about building and importing header units with Visual Studio 2022. To
learn how to import C++ standard library headers as header units, see Walkthrough:
Import STL libraries as header units. For an even faster and more robust way to import
the standard library, see Tutorial: Import the C++ standard library using modules.
Header units are the recommended alternative to precompiled header files (PCH).
Header units are easier to set up and use, are significantly smaller on disk, provide
similar performance benefits, and are more flexible than a shared PCH .
To contrast header units with other ways to include functionality in your programs, see
Compare header units, modules, and precompiled headers.
Prerequisites
To use header units, you need Visual Studio 2019 16.10 or later.
What is a header unit
A header unit is a binary representation of a header file. A header unit ends with an
.ifc extension. The same format is used for named modules.
An important difference between a header unit and a header file is that a header unit
isn't affected by macro definitions outside of the header unit. That is, you can't define a
preprocessor symbol that causes the header unit to behave differently. By the time you
import the header unit, the header unit is already compiled. That's different from how an
#include file is treated. An included file can be affected by a macro definition outside of
the header file because the header file goes through the preprocessor when you
compile the source file that includes it.
Header units can be imported in any order, which isn't true of header files. Header file
order matters because macro definitions defined in one header file might affect a
subsequent header file. Macro definitions in one header unit can't affect another header
unit.
Everything visible from a header file is also visible from a header unit, including macros
defined within the header unit.
A header file must be translated into a header unit before it can be imported. An
advantage of header units over precompiled header files (PCH) is that they can be used
in distributed builds. As long as you compile the .ifc and the program that imports it
with the same compiler, and target the same platform and architecture, a header unit
produced on one computer can be consumed on another. Unlike a PCH, when a header
unit changes, only it and what depends on it are rebuilt. Header units can be up to an
order of magnitude smaller in size than a .pch .
Header units impose fewer constraints on the required similarities of compiler switch
combinations used to create the header unit and to compile the code that consumes it
than a PCH does. However, some switch combinations and macro definitions might
create violations of the one definition rule (ODR) between various translation units.
Finally, header units are more flexible than a PCH. With a PCH, you can't choose to bring
in only one of the headers in the PCH--the compiler processes all of them. With header
units, even when you compile them together into a static library, you only bring the
contents of the header unit you import into your application.
Header units are a step in between header files and C++ 20 modules. They provide
some of the benefits of modules. They're more robust because outside macro
definitions don't affect them--so you can import them in any order. And the compiler
can process them faster than header files. But header units don't have all of the
advantages of modules because header units expose the macros defined within them
(modules don't). Unlike modules, there's no way to hide private implementation in a
header unit. To indicate private implementation with header files, different techniques
are employed like adding leading underscores to names, or putting things in an
implementation namespace. A module doesn't expose private implementation in any
form, so you don't need to do that.
Consider replacing your precompiled headers with header units. You get the same
speed advantage, but with other code hygiene and flexibility benefits as well.
Ways to compile a header unit
There are several ways to compile a file into a header unit:
Build a shared header unit project. We recommend this approach because it
provides more control over the organization and reuse of the imported header
units. Create a static library project that contains the header units that you want,
and then reference it to import the header units. For a walkthrough of this
approach, see Build a header unit static library project for header units.
Choose individual files to translate into header units. This approach gives you
file-by-file control over what is treated as a header unit. It's also useful when you
must compile a file as a header unit that, because it doesn't have the default
extension ( .ixx , .cppm , .h , .hpp ), wouldn't normally be compiled into a header
unit. This approach is demonstrated in this walkthrough. To get started, see
Approach 1: Translate a specific file into a header unit.
Automatically scan for and build header units. This approach is convenient, but is
best suited to smaller projects because it doesn't guarantee optimal build
throughput. For details about this approach, see Approach 2: Automatically scan
for header units.
As mentioned in the introduction, you can build and import STL header files as
header units, and automatically treat #include for STL library headers as import
without rewriting your code. To see how, visit Walkthrough: Import STL libraries as
header units.
This section shows how to choose a specific file to translate into a header unit. Compile
a header file as a header unit using the following steps in Visual Studio:
1. Create a new C++ console app project.
2. Replace the source file content as follows:
C++
3. Add a header file called Pythagorean.h and then replace its content with this code:
C++
Approach 1: Translate a specific file into a
header unit
#include "Pythagorean.h"
int main()
{
 PrintPythagoreanTriple(2,3);
 return 0;
}
#ifndef PYTHAGOREAN
#define PYTHAGOREAN
To enable header units, first set the C++ Language Standard to /std:c++20 or later with
the following steps:
1. In Solution Explorer, right-click the project name and choose Properties.
2. In the left pane of the project property pages window, select Configuration
Properties > General.
3. In the C++ Language Standard dropdown, select ISO C++20 Standard
(/std:c++20) or later. Choose Ok to close the dialog.
Compile the header file as a header unit:
1. In Solution Explorer, select the file you want to compile as a header unit (in this
case, Pythagorean.h ). Right-click the file and choose Properties.
2. Set the Configuration properties > General > Item Type dropdown to C/C++
compiler and choose Ok.
When you build this project later in this walkthrough, Pythagorean.h will be translated
into a header unit. It's translated into a header unit because the item type for this
header file is set to C/C++ compiler, and because the default action for .h and .hpp
files set this way is to translate the file into a header unit.
#include <iostream>
inline void PrintPythagoreanTriple(int a, int b)
{
 std::cout << "Pythagorean triple a:" << a << " b:" << b << " c:" <<
a*a + b*b << std::endl;
}
#endif
Set project properties
７ Note
This isn't required for this walkthrough, but is provided for your information. To
compile a file as a header unit that doesn't have a default header unit file extension,
like .cpp for example, set Configuration properties > C/C++ > Advanced >
Compile As to Compile as C++ Header Unit (/exportHeader):
Change your code to import the header unit
1. In the source file for the example project, change #include "Pythagorean.h" to
import "Pythagorean.h"; Don't forget the trailing semicolon. It's required for
import statements. Because it's a header file in a directory local to the project, we
used quotes with the import statement: import "file"; . In your own projects, to
compile a header unit from a system header, use angle brackets: import <file>;
2. Build the solution by selecting Build > Build Solution on the main menu. Run it to
see that it produces the expected output: Pythagorean triple a:2 b:3 c:13
In your own projects, repeat this process to compile the header files you want to import
as header units.
If you want to convert only a few header files to header units, this approach is good. But
if you have many header files that you want to compile, and the potential loss of build
performance is outweighed by the convenience of having the build system handle them
automatically, see the following section.
If you're interested in specifically importing STL library headers as header units, see
Walkthrough: Import STL libraries as header units.
Approach 2: Automatically scan for and build
header units
Because it takes time to scan all of your source files for header units, and time to build
them, the following approach is best suited for smaller projects. It doesn't guarantee
optimal build throughput.
This approach combines two Visual Studio project settings:
Scan Sources for Module Dependencies causes the build system to call the
compiler to ensure that all imported modules and header units are built before
compiling the files that depend on them. When combined with Translate Includes
to Imports, any header files included in your source that are also specified in a
header-units.json file located in the same directory as the header file, are compiled
into header units.
Translate Includes to Imports treats a header file as an import if the #include
refers to a header file that can be compiled as a header unit (as specified in a
header-units.json file), and a compiled header unit is available for the header file.
Otherwise, the header file is treated as a normal #include . The header-units.json
file is used to automatically build header units for each #include , without symbol
duplication.
You can turn on these settings in the properties for your project. To do so, right-click the
project in the Solution Explorer and choose Properties. Then choose Configuration
Properties > C/C++ > General.
Scan Sources for Module Dependencies can be set for all of the files in the project in
Project Properties as shown here, or for individual files in File Properties. Modules and
header units are always scanned. Set this option when you have a .cpp file that imports
header units that you want built automatically and might not be built yet.
These settings work together to automatically build and import header units under
these conditions:
Scan Sources for Module Dependencies scans your sources for the files and their
dependencies that can be treated as header units. Files that have the extension
.ixx , and files that have their File properties > C/C++ > Compile As property set
to Compile as C++ Header Unit (/export), are always scanned regardless of this
setting. The compiler also looks for import statements to identify header unit
dependencies. If /translateInclude is specified, the compiler also scans for
#include directives that are also specified in a header-units.json file to treat as
header units. A dependency graph is built of all the modules and header units in
your project.
Translate Includes to Imports When the compiler encounters an #include
statement, and a matching header unit file ( .ifc ) exists for the specified header
file, the compiler imports the header unit instead of treating the header file as an
#include . When combined with Scan for dependencies, the compiler finds all of
the header files that can be compiled into header units. An allowlist is consulted by
the compiler to decide which header files can compile into header units. This list is
stored in a header-units.json file that must be in the same directory as the included
file. You can see an example of a header-units.json file under the installation
directory for Visual Studio. For example, %ProgramFiles%\Microsoft Visual
Studio\2022\Enterprise\VC\Tools\MSVC\14.30.30705\include\header-units.json is
used by the compiler to determine whether a Standard Template Library header
can be compiled into a header unit. This functionality exists to serve as a bridge
with legacy code to get some benefits of header units.
The header-units.json file serves two purposes. In addition to specifying which header
files can be compiled into header units, it minimizes duplicated symbols to increase
build throughput. For more information about symbol duplication, see C++ header￾units.json reference.
These switches and the header-unit.json provide some of the benefits of header units.
The convenience comes at the cost of build throughput. This approach might not be the
best for larger projects because it doesn't guarantee optimal build times. Also, the same
header files might be reprocessed repeatedly, which increases build time. However, the
convenience might be worth it depending on the project.
These features are designed for legacy code. For new code, move to modules instead of
header units or #include files. For a tutorial on using modules, see Name modules
tutorial (C++).
For an example of how this technique is used to import STL header files as header units,
see Walkthrough: Import STL libraries as header units.
Preprocessor implications
The standard C99/C++11 conforming preprocessor is required to create and use header
units. The compiler enables the new C99/C++11 conforming preprocessor when
compiling header units by implicitly adding /Zc:preprocessor to the command line
whenever any form of /exportHeader is used. Attempting to turn it off will result in a
compilation error.
Enabling the new preprocessor affects the processing of variadic macros. For more
information, see the Variadic macros remarks section.
See also
/translateInclude
/exportHeader
/headerUnit
header-units.json
Compare header units, modules, and precompiled headers
Overview of modules in C++
Tutorial: Import the C++ standard library using modules
Walkthrough: Import STL libraries as header units
Walkthrough: Import STL libraries as
header units
Article • 12/05/2022
This walkthrough shows how to import C++ Standard Template Library (STL) libraries as
header units in Visual Studio. For an even faster and more robust way to import the
standard library, see Tutorial: Import the C++ standard library using modules.
Importing an STL header as a header unit is simpler than using precompiled header files.
Header units are easier to set up and use, are substantially smaller on disk, provide
similar performance benefits, and are more flexible than a shared PCH .
For more detailed information about what header units are and the benefits they
provide, see What is a header unit?. To contrast header units with other ways to import
the standard library, see Compare header units, modules, and precompiled headers.
Prerequisites
To use header units, use Visual Studio 2022 or later, or Visual Studio 2019 version 16.11
or later. The /std:c++20 option (or later) is required to use header units.
Two approaches to import STL headers as
header units
Before you can import an STL header, it must be compiled into a header unit. A header
unit is a binary representation of a header file. It has an .ifc extension.
The recommended approach is to create a static library that contains the built header
units for the STL headers you want to use. Then reference that library and import its
header units. This approach can result in faster builds and better reuse. To try out this
approach, see Approach 1: Create a static library of STL library header units.
Another approach is to have Visual Studio scan for the STL headers you #include in
your project, compile them into header units, and import rather than #include those
headers. This approach is useful if you have a large codebase, because you don't have to
change your source code. This approach is less flexible than the static library approach,
because it doesn't lend itself to reusing the built header units in other projects. But, you
still get the performance advantage of importing individual STL libraries as header units.
To try out this approach, see Approach 2: Scan includes for STL headers to import.
Approach 1: Create a static library of STL library
header units
The recommended way to consume STL libraries as header units is to create one or
more static library projects. These projects should consist of the STL library header units
that you want to use. Then, reference the library projects to consume those STL header
units. It's similar to using shared precompiled headers , but easier.
Header units (and modules) built in a static library project are automatically available to
referencing projects because the project system automatically adds the appropriate
/headerUnit command-line option to the compiler so that referencing projects can
import the header units.
This approach ensures that the header unit for a particular header is built only once. It
allows you to import some or all of the header units, which isn't possible with a PCH.
You can include header units in any order.
In the following example, you create a static library project consisting of the <iostream>
and <vector> header units. After the solution is built, you'll reference this shared header
unit project from another C++ project. Everywhere import <iostream>; or import
<vector>; is found, the built header unit for that library is used instead of translating the
header with the preprocessor. It improves build performance, like PCH files do, when the
same header is included in multiple files. The header won't have to be processed over
and over by the files that include it. Instead, the already processed compiled header unit
is imported.
To create a static library that contains the STL libraries <iostream> and <vector> , follow
these steps:
1. Create an empty C++ project. Name it SharedPrj.
Select Empty Project for C++ from the project types available in the Create a new
project window:
2. Add a new C++ file to the project. Change the file's content to:
C++
import <iostream>;
import <vector>;
Set project properties
Set project properties to share the header units from this project:
1. On the Visual Studio main menu, select Project > SharedPrj Properties to open
the project Property Pages dialog:
2. Select All Configurations in the Configuration dropdown list, and then select All
Platforms in the Platform dropdown list. These settings ensure that your changes
apply whether you're building for debug or release.
3. In the left pane of the project Property Pages dialog, select Configuration
Properties > General.
4. Change the Configuration Type option to Static library (.lib).
5. Change C++ Language Standard to ISO C++20 Standard (/std:c++20) (or later).
6. In the left pane of the project Property Pages dialog, select Configuration
Properties > C/C++ > General.
7. In the Scan Sources for Module Dependencies dropdown list, select Yes. (This
option causes the compiler to scan your code for dependencies that can be built
into header units):
8. Choose OK to close the project Property Pages dialog. Build the solution by
selecting Build > Build Solution on the main menu.
To import <iostream> and <vector> as header units from the static library, create a
project that references the static library as follows:
1. With the current solution still open, on the Visual Studio menu, select File > Add >
New Project.
2. In the Create a new project wizard, select the C++ Console App template and
choose Next.
3. Name the new project Walkthrough. Change the Solution dropdown to Add to
solution. Choose Create to create the project and add it to your solution.
4. Change the content of the Walkthrough.cpp source file as follows:
C++
Reference the header unit library
import <iostream>;
import <vector>;
int main()
{
 std::vector<int> numbers = {0, 1, 2};
 std::cout << numbers[1];
}
Header units require the /std:c++20 option (or later). Set the language standard by
using the following steps:
1. In Solution Explorer, right-click the Walkthrough project and select Properties to
open the project Property Pages dialog:
2. In the left pane of the Walkthrough project Property Pages dialog, select
Configuration Properties > General.
3. In the C++ Language Standard dropdown, select ISO C++20 Standard
(/std:c++20) (or later).
4. Choose OK to close the project Property Pages dialog.
In the Walkthrough project, add a reference to the SharedPrj project with the following
steps:
1. In the Walkthrough project, select the References node, and then select Add
Reference. Select SharedPrj in the list of projects:
Adding this reference causes the build system to use the header units built by
SharedPrj whenever an import in the Walkthrough project matches one of the
built header units in SharedPrj.
2. Choose OK to close the Add Reference dialog.
3. Right-click the Walkthrough project and select Set as Startup Project.
4. Build the solution. (Use Build > Build Solution on the main menu.) Run it to see
that it produces the expected output: 1
The advantage of this approach is that you can reference the static library project from
any project to reuse the header units in it. In this example, the static library contains the
<vector> and <iostream> header units.
You can make a monolithic static library project that contains all the commonly used STL
headers that you want to import from your various projects. Or you can create smaller
shared library projects for the different groupings of STL libraries that you want to
import as header units. Then reference those shared header unit projects as needed.
The result should be increased build throughput because importing a header unit
significantly reduces the work the compiler must do.
When you use this approach with your own projects, build the static library project with
compiler options that are compatible with the project that references it. For example,
STL projects should be built with the /EHsc compiler option to turn on exception
handling, and so should the projects that reference the static library project.
Use /translateInclude
The /translateInclude compiler option (available in the project Property Pages dialog
under C/C++ > General > Translate Includes to Imports) makes it easier for you to use
a header unit library in older projects that #include the STL libraries. It makes it
unnecessary to change #include directives to import in your project, while still giving
you the advantage of importing the header units instead of including them.
For example, if you have #include <vector> in your project and you reference a static
library that contains a header unit for <vector> , you don't need to manually change
#include <vector> to import <vector>; in your source code. Instead, the compiler
automatically treats #include <vector> as import <vector>; . For more information in
detail on this approach, see Approach 2: Scan includes for STL headers to import. Not all
STL header files can be compiled to a header unit. The header-units.json shipped with
Visual Studio lists which STL header files can be compiled into header units. A header
that relies on macros to specify its behavior often can't be compiled into a header unit.
An #include statement that doesn't refer to a header unit is treated as a normal
#include .
Reuse header units among projects
Header units built by a static library project are automatically available to all directly and
indirectly referencing projects. There are project settings that allow you to select which
header units should be automatically available to all referencing projects. The settings
are in project settings under VC++ Directories.
1. In Solution Explorer, right-click the project and select Properties to open the
project Property Pages dialog.
2. In the left pane of the dialog, select Configuration Properties > VC++ Directories:
The following properties control the visibility of header units to the build system:
Public Include Directories specifies project directories for header units that should
be automatically added to the include path in referencing projects.
Public C++ Module Directories specifies which project directories contain header
units that should be available to referencing projects. This property allows you to
make some header units public. It's visible to other projects, so put header units
that you want to share here. If you use this setting, for convenience, specify Public
Include Directories to automatically add your public headers to the Include path in
referencing projects.
All Modules are Public: when you use header units built as a part of a DLL project,
the symbols have to be exported from the DLL. To export module symbols
automatically, set this property to Yes.
Use a prebuilt module file
Typically, the easiest way to reuse header units among solutions is to reference a shared
header unit project from each solution.
If you must use a built header unit that you don't have the project for, you can specify
where the built .ifc file is so you can import it in your solution. To access this setting:
1. On the main menu, select Project > Properties to open the project Property Pages
dialog.
2. In the left pane of the dialog, select Configuration Properties > C/C++ > General.
3. In Additional Module Dependencies, add the modules to reference, separated by
semicolons. Here's an example of the format to use for Additional Module
Dependencies: ModuleName1=Path\To\ModuleName1.ifc;
ModuleName2=Path\To\ModuleName2.ifc
Select among multiple copies of a header unit
If you reference projects that build multiple header units, either with the same name or
for the same header file, you must specify which one to use. You might have different
versions of the header unit built with different compiler settings, for example, and must
specify the one that matches your project settings.
Use the project's Additional Header Unit Dependencies property to resolve collisions
by specifying which header unit to use. Otherwise, it isn't possible to predict which one
is picked.
To set the Additional Header Unit Dependencies property:
1. On the main menu, select Project > Properties to open the project Property Pages
dialog.
2. In the left pane of the dialog, select Configuration Properties > C/C++ > General.
3. Specify which modules or header unit files to use in Additional Header Unit
Dependencies to resolve collisions. Use this format for Additional Header Unit
Dependencies: Path\To\Header1.h= Path\To\HeaderUnit1.ifc;Path\To\Header2.h=
Path\To\ HeaderUnit2.ifc
） Important
Ensure that projects that share header units are built with compatible compilation
options. If you use compilation options when you implement the header unit that
are different from the ones you used when you created it, the compiler will issue
warnings.
７ Note
To use header units built as a part of a DLL project, set All Modules are Public to
Yes.
Approach 2: Scan includes for STL headers to
import
Another way to import STL libraries is to have Visual Studio scan for the STL headers you
#include in your project and compile them into header units. The compiler then imports
rather than includes those headers.
This option is convenient when your project includes many STL header files across many
files, or when build throughput isn't critical. This option doesn't guarantee that a header
unit for a particular header file is built only once. However, it's useful if you have a large
codebase: You don't have to change your source code to take advantage of the benefits
of header units for many of the STL libraries you use.
This approach is less flexible than the static library approach, because it doesn't lend
itself towards reusing the built header units in other projects. This approach might not
be appropriate for larger projects: It doesn't guarantee an optimal build time, since all of
the sources must be scanned for #include statements.
Not all header files can be automatically converted to header units. For example,
headers that depend on conditional compilation via macros shouldn't be converted to
header units. There's an allowlist in the form of a header-units.json file for the STL
headers that the compiler uses when /translateInclude is specified. It determines
which STL headers can be compiled into header units. The header-units.json file is
under the installation directory for Visual Studio. For example, %ProgramFiles%\Microsoft
Visual Studio\2022\Enterprise\VC\Tools\MSVC\14.30.30705\include\header-units.json .
If the STL header file isn't on the list, it's treated as a normal #include instead of
importing it as a header unit. Another advantage of the header-units.json file is that it
prevents symbol duplication in the built header units. That is, if compiling a header unit
brings in another library header multiple times, the symbols won't be duplicated.
To try out this approach, create a project that includes two STL libraries. Then, change
the project's properties so that it imports the libraries as header units instead of
including them, as described in the next section.
Follow these steps to create a project that includes two STL libraries: <iostream> and
<vector> .
1. In Visual Studio, create a new C++ console app project.
2. Replace the contents of the source file as follows:
C++
The following steps set the option that causes the compiler to scan for included headers
to translate into header units. They also set the option that causes the compiler to treat
#include as if you had written import for header files that can be treated as header
units.
1. On the main menu, select Project > Properties to open the project Property Pages
dialog.
2. Select All Configurations in the Configuration dropdown list, and then select All
Platforms in the Platform dropdown list. These settings ensure that your changes
apply whether you're building for debug or release, and other configurations.
3. In the left pane of the dialog, select Configuration Properties > C/C++ > General.
4. Set Scan Sources for Module Dependencies to Yes. This setting ensures that all
compatible header files compile into header units.
5. Set Translate Includes to Imports to Yes. This setting compiles the STL header files
listed in the header-unit.json file as header units, and then imports them instead
Create a C++ console app project
#include <iostream>;
#include <vector>;
int main()
{
 std::vector<int> numbers = {0, 1, 2};
 std::cout << numbers[1];
}
Set project options and run the project
of using the preprocessor to #include them.
6. Choose OK to save your changes and close the project Property Pages dialog.
The /std:c++20 option or later is required to use header units. To change the C++
language standard used by the compiler:
1. On the main menu, select Project > Properties to open the project Property Pages
dialog.
2. Select All Configurations in the Configuration dropdown list, and then select All
Platforms in the Platform dropdown list. These settings ensure that your changes
apply whether you're building for debug or release, and other configurations.
3. In the left pane of the project Property Pages dialog, select Configuration
Properties > General.
4. In the C++ Language Standard dropdown list, select ISO C++20 Standard
(/std:c++20) (or later).
5. Choose OK to save your changes and close the project Property Pages dialog.
6. From the main menu, build the solution by selecting Build > Build Solution.
Run the solution to verify that it produces the expected output: 1
The main consideration for whether to use this approach is the balance between
convenience and the cost of scanning all your files to determine which header files to
build as header units.
See also
Compare header units, modules, and precompiled headers
Tutorial: Import the C++ standard library using modules
Walkthrough: Build and import header units in your Visual C++ projects
/translateInclude
C++ header-units.json reference
Article • 11/09/2022
The header-units.json file serves two purposes:
Specify which header files can be translated into header units when
/translateInclude is specified.
Minimize duplicated symbols to increase build throughput.
This file must be in the same directory as the included header file. This file is only used
when /translateInclude is specified along with either /scanDependencies or
/sourceDependencies:directives.
Some header files can't be safely translated to header units. Header files that depend on
macros that aren't defined on the command line, or that aren't defined in the header
files included by the header, can't be translated to header units.
If a header defines macros that affect whether other headers are included, it can't be
safely translated. For example, given a.h , b.h and macros.h , which are all in the same
directory:
C++
The header-units.json in this directory can contain a.h and b.h , but not macros.h . The
header-units.json for this example would be similar to this:
JSON
Rationale
// a.h
#include "macros.h" // #defines MACRO=1
#ifdef MACRO
#include "b.h"
#endif
{
 "Version": "1.0",
 "BuildAsHeaderUnits": [
 // macros.h should not be listed
 "a.h",
 "b.h" 
The reason macros.h can't be listed in this header-units.json file is that during the scan
phase, the header unit ( .ifc ) might not be compiled yet for macros.h . In that case,
MACRO won't be defined when a.h is compiled. That means b.h will be missing from the
list of dependencies for a.h . Since it isn't in the list of dependencies, the build system
won't build a header unit for b.h despite it being listed in the header-units.json file.
To avoid this problem, when there's a dependency on a macro in another header file, the
header file that defines the macro is excluded from the list of files that can be compiled
into a header unit. This way the header file that defines the macro is treated as a normal
#include and MACRO will be visible so that b.h is included and listed as one of the
dependencies.
The header-units.json file is also important because it allows for automatic header unit
creation without duplicated symbols. It does this by creating "atomic" header units for
the files listed in header-units.json . The imported header units don't contain duplicated
symbols from the various #include directives that were processed while translating the
header file.
For example, consider two header files that both include a common header file. Both
header files are included by the same source file:
C++
If the compiler built header units for a.h , b.h and c.h , then the compiled header units
a.h.ifc , b.h.ifc , and c.h.ifc would each contain all of the types from b.h . Compiling
Source.cpp , which imports both a.h and c.h , would require the compiler to
deduplicate the b.h types, which would impact build performance.
 ] 
}
Preventing duplicated symbols
// a.h
#include "b.h"
// c.h
#include "b.h"
// Source.cpp
import "a.h";
import "c.h";
But if there's a header-units.json in the b.h directory, and /translateInclude is
specified, then the following happens:
1. The scan of a.h and c.h lists b.h as a header unit import in the dependency scan
files generated by the compiler.
2. The build system reads the dependency scan files and determines to build b.h.ifc
first.
3. Then the build system adds /headerUnit for b.h.ifc to the command lines for
compiling a.h and c.h . It calls the compiler to build the header units a.h.ifc and
c.h.ifc . Because /translateInclude is specified, and /headerUnit for b.h.ifc is
also specified, a.h.ifc and c.h.ifc won't contain b.h types, so there won't be
any duplication in the produced header units.
There's a headerunits.json file for the Standard Template Library (STL) headers. The
build system uses it to determine whether to create a header unit for an STL header file,
and for its dependencies. If the STL header file isn't on the list, it's treated as a normal
#include instead of importing it as a header unit.
You can see the header-units.json file under the installation directory for Visual Studio.
For example: %ProgramFiles%\Microsoft Visual
Studio\2022\Enterprise\VC\Tools\MSVC\14.30.30705\include\header-units.json
The header-units.json file starts with the schema version, followed by an array of
filenames for headers that can be built into header units.
The schema also supports comments, as shown here:
JSON
Schema
{
 "Version": "1.0",
 "BuildAsHeaderUnits": [
 // "__msvc_all_public_headers.hpp", // for testing, not production
 "__msvc_system_error_abi.hpp",
 "__msvc_tzdb.hpp",
 "__msvc_xlocinfo_types.hpp",
 "algorithm",
 "any",
 "array",
 "atomic",
 "barrier",
 "bit",
 "bitset",
 // "cassert", // design is permanently incompatible with header
units
 ...
}
Search rules
The compiler looks for this file in the same directory as the header file being processed.
If your library is organized into subdirectories, each subdirectory needs its own header￾units.json file.
See also
Walkthrough: Import STL libraries as header units
Walkthrough: Build and import header units in your Visual C++ projects
Precompiled header files
Article • 10/16/2023
When you create a new project in Visual Studio, a precompiled header file named pch.h
is added to the project. (In Visual Studio 2017 and earlier, the file was called stdafx.h .)
The purpose of the file is to speed up the build process. Any stable header files, for
example Standard Library headers such as <vector> , should be included here. The
precompiled header is compiled only when it, or any files it includes, are modified. If you
only make changes in your project source code, the build will skip compilation for the
precompiled header.
The compiler options for precompiled headers are /Y. In the project property pages, the
options are located under Configuration Properties > C/C++ > Precompiled Headers.
You can choose to not use precompiled headers, and you can specify the header file
name and the name and path of the output file.
Custom precompiled code
For large projects that take significant time to build, you may want to consider creating
custom precompiled files. The Microsoft C and C++ compilers provide options for
precompiling any C or C++ code, including inline code. Using this performance feature,
you can compile a stable body of code, store the compiled state of the code in a file,
and, during subsequent compilations, combine the precompiled code with code that's
still under development. Each later compilation is faster because the stable code doesn't
need to be recompiled.
When to precompile source code
Precompiled code is useful during the development cycle to reduce compilation time,
especially if:
You always use a large body of code that changes infrequently.
Your program comprises multiple modules, all of which use a standard set of
include files and the same compilation options. In this case, all include files can be
precompiled into one precompiled header. For more information about newer
ways to handle include files, see Compare header units, modules, and precompiled
headers.
The first compilation (the one that creates the precompiled header file) takes a bit
longer than subsequent compilations. Subsequent compilations can proceed more
quickly by including the precompiled code.
You can precompile both C and C++ programs. In C++ programming, it's common
practice to separate class interface information into header files. These header files can
later be included in programs that use the class. By precompiling these headers, you can
reduce the time a program takes to compile.
７ Note
Although you can use only one precompiled header ( .pch ) file per source file, you
can use multiple .pch files in a project.
Two choices for precompiling code
You can precompile any C or C++ code; you're not limited to precompiling only header
files.
Precompiling requires planning, but it offers much faster compilations if you precompile
source code other than simple header files.
Precompile code when you know that your source files use common sets of header files,
or when you want to include source code in your precompilation.
The precompiled-header options are /Yc (Create Precompiled Header File) and /Yu (Use
Precompiled Header File). Use /Yc to create a precompiled header. When used with the
optional hdrstop pragma, /Yc lets you precompile both header files and source code.
Select /Yu to use an existing precompiled header in the existing compilation. You can
also use /Fp with the /Yc and /Yu options to provide an alternative name for the
precompiled header.
The compiler option reference articles for /Yu and /Yc discuss how to access this
functionality in the development environment.
Precompiled header consistency rules
Because PCH files contain information about the machine environment and memory
address information about the program, you should only use a PCH file on the machine
where it was created.
Consistency rules for per-file use of
precompiled headers
The /Yu compiler option lets you specify which PCH file to use.
When you use a PCH file, the compiler assumes the same compilation environment that
was in effect when you created the PCH file, unless you specify otherwise. The
compilation environment includes the compiler options, pragmas, and so on. If the
compiler detects an inconsistency, it issues a warning and identifies the inconsistency
where possible. Such warnings don't necessarily indicate a problem with the PCH file;
they simply warn you of possible conflicts. Consistency requirements for PCH files are
described in the following sections.
Compiler option consistency
The following compiler options can trigger an inconsistency warning when using a PCH
file:
Macros created using the Preprocessor ( /D ) option must be the same between the
compilation that created the PCH file and the current compilation. The state of
defined constants isn't checked, but unpredictable results can occur if these
macros change.
PCH files don't work with the /E and /EP options.
PCH files must be created using either the Generate Browse Info ( /FR ) option or
the Exclude Local Variables ( /Fr ) option before subsequent compilations that use
the PCH file can use these options.
C 7.0-compatible ( /Z7 )
If this option is in effect when the PCH file is created, later compilations that use the
PCH file can use the debugging information.
If the C 7.0-Compatible ( /Z7 ) option isn't in effect when the PCH file is created, later
compilations that use the PCH file and /Z7 trigger a warning. The debugging
information is placed in the current .obj file, and local symbols defined in the PCH file
aren't available to the debugger.
Include path consistency
A PCH file doesn't contain information about the header include path that was in effect
when it was created. When you use a PCH file, the compiler always uses the header
include path specified in the current compilation.
Source file consistency
When you specify the Use Precompiled Header File ( /Yu ) option, the compiler ignores
all preprocessor directives (including pragmas) that appear in the source code that will
be precompiled. The compilation specified by such preprocessor directives must be the
same as the compilation used for the Create Precompiled Header File ( /Yc ) option.
Pragma consistency
Pragmas processed during the creation of a PCH file usually affect the file with which the
PCH file is later used. The comment and message pragmas don't affect the remainder of
the compilation.
These pragmas affect only the code within the PCH file; they don't affect code that later
uses the PCH file:
comment
linesize
message
page
pagesize
skip
subtitle
title
These pragmas are retained as part of a precompiled header, and affect the remainder
of a compilation that uses the precompiled header:
alloc_text
auto_inline
check_stack
code_seg
data_seg
function
include_alias
init_seg
inline_depth
inline_recursion
intrinsic
optimize
pack
pointers_to_members
setlocale
vtordisp
warning
When you use a precompiled header created using /Yc or /Yu , the compiler compares
the current compilation environment to the one that existed when you created the PCH
file. Be sure to specify an environment consistent with the previous one (using
consistent compiler options, pragmas, and so on) for the current compilation. If the
compiler detects an inconsistency, it issues a warning and identifies the inconsistency
where possible. Such warnings don't necessarily indicate a problem with the PCH file;
they simply warn you of possible conflicts. The following sections explain the
consistency requirements for precompiled headers.
This table lists compiler options that might trigger an inconsistency warning when using
a precompiled header:
Option Name Rule
/D Define constants
and macros
Must be the same between the compilation that created the
precompiled header and the current compilation. The state of
defined constants isn't checked. However, unpredictable results
can occur if your files depend on the values of the changed
constants.
/E or
/EP
Copy
preprocessor
Precompiled headers don't work with the /E or /EP option.
Consistency rules for /Yc and /Yu
Compiler option consistency
Option Name Rule
output to
standard output
/Fr or
/FR
Generate
Microsoft Source
Browser
information
For the /Fr and /FR options to be valid with the /Yu option, they
must also have been in effect when the precompiled header was
created. Subsequent compilations that use the precompiled
header also generate Source Browser information. Browser
information is placed in a single .sbr file and is referenced by
other files in the same manner as CodeView information. You can't
override the placement of Source Browser information.
/GA , /GD ,
/GE , /Gw ,
or /GW
Windows
protocol options
Must be the same between the compilation that created the
precompiled header and the current compilation. The compiler
emits a warning if these options differ.
/Zi Generate
complete
debugging
information
If this option is in effect when the precompiled header is created,
subsequent compilations that use the precompilation can use that
debugging information. If /Zi isn't in effect when the
precompiled header is created, subsequent compilations that use
the precompilation and the /Zi option trigger a warning. The
debugging information is placed in the current object file, and
local symbols defined in the precompiled header aren't available
to the debugger.
Previous sections present an overview of precompiled headers: /Yc and /Yu, the /Fp
option, and the hdrstop pragma. This section describes a method for using the manual
precompiled-header options in a project; it ends with an example makefile and the code
that it manages.
For another approach to using the manual precompiled-header options in a project,
study one of the makefiles located in the MFC\SRC directory that's created during the
default setup of Visual Studio. These makefiles take a similar approach to the one
presented in this section. They make greater use of Microsoft Program Maintenance
Utility (NMAKE) macros, and offer greater control of the build process.
７ Note
The precompiled header facility is intended for use only in C and C++ source files.
Using precompiled headers in a project
PCH files in the build process
The code base of a software project is often contained in multiple C or C++ source files,
object files, libraries, and header files. Typically, a makefile coordinates the combination
of these elements into an executable file. The following figure shows the structure of a
makefile that uses a precompiled header file. The NMAKE macro names and the file
names in this diagram are consistent with the example code found in Sample makefile
for PCH and Example code for PCH.
The figure uses three diagrammatic devices to show the flow of the build process.
Named rectangles represent each file or macro; the three macros represent one or more
files. Shaded areas represent each compile or link action. Arrows show which files and
macros are combined during the compilation or linking process.
The diagram is described in the text following the diagram.
Structure of a makefile that uses a precompiled header file:
Beginning at the top of the diagram, both STABLEHDRS and BOUNDRY are NMAKE macros
in which you list files not likely to need recompilation. These files are compiled by the
command string
CL /c /W3 /Yc$(BOUNDRY) applib.cpp myapp.cpp
only if the precompiled header file ( STABLE.pch ) doesn't exist or if you make changes to
the files listed in the two macros. In either case, the precompiled header file will contain
code only from the files listed in the STABLEHDRS macro. List the last file you want
precompiled in the BOUNDRY macro.
The files you list in these macros can be either header files or C or C++ source files. (A
single PCH file can't be used with both C and C++ sources.) You can use the hdrstop
macro to stop precompilation at some point within the BOUNDRY file. For more
information, see hdrstop.
Next in the diagram, APPLIB.obj represents the support code used in your final
application. It's created from APPLIB.cpp , the files listed in the UNSTABLEHDRS macro, and
precompiled code from the precompiled header.
MYAPP.obj represents your final application. It's created from MYAPP.cpp , the files listed
in the UNSTABLEHDRS macro, and precompiled code from the precompiled header.
Finally, the executable file ( MYAPP.EXE ) is created by linking the files listed in the OBJS
macro ( APPLIB.obj and MYAPP.obj ).
Sample makefile for PCH
The following makefile uses macros and an !IF , !ELSE , !ENDIF flow-of-control
command structure to simplify its adaptation to your project.
NMAKE
# Makefile : Illustrates the effective use of precompiled
# headers in a project
# Usage: NMAKE option
# option: DEBUG=[0|1]
# (DEBUG not defined is equivalent to DEBUG=0)
#
OBJS = myapp.obj applib.obj
# List all stable header files in the STABLEHDRS macro.
STABLEHDRS = stable.h another.h
# List the final header file to be precompiled here:
BOUNDRY = stable.h
# List header files under development here:
UNSTABLEHDRS = unstable.h
# List all compiler options common to both debug and final
# versions of your code here:
CLFLAGS = /c /W3
# List all linker options common to both debug and final
# versions of your code here:
LINKFLAGS = /nologo
!IF "$(DEBUG)" == "1"
CLFLAGS = /D_DEBUG $(CLFLAGS) /Od /Zi
LINKFLAGS = $(LINKFLAGS) /COD
LIBS = slibce
!ELSE
CLFLAGS = $(CLFLAGS) /Oselg /Gs
LINKFLAGS = $(LINKFLAGS)
LIBS = slibce
!ENDIF
myapp.exe: $(OBJS)
Aside from the STABLEHDRS , BOUNDRY , and UNSTABLEHDRS macros shown in the figure
"Structure of a Makefile That Uses a Precompiled Header File" in PCH files in the build
process, this makefile provides a CLFLAGS macro and a LINKFLAGS macro. You must use
these macros to list compiler and linker options that apply whether you build a debug
or final version of the application's executable file. There's also a LIBS macro where you
list the libraries your project requires.
The makefile also uses !IF , !ELSE , !ENDIF to detect whether you define a DEBUG symbol
on the NMAKE command line:
NMAKE
This feature makes it possible for you to use the same makefile during development and
for the final versions of your program. Use DEBUG=0 for the final versions. The following
command lines are equivalent:
NMAKE
For more information on makefiles, see NMAKE reference. Also see MSVC compiler
options and the MSVC linker options.
The following source files are used in the makefile described in PCH files in the build
process and Sample makefile for PCH. The comments contain important information.
 link $(LINKFLAGS) @<<
$(OBJS), myapp, NUL, $(LIBS), NUL;
<<
# Compile myapp
myapp.obj : myapp.cpp $(UNSTABLEHDRS) stable.pch
 $(CPP) $(CLFLAGS) /Yu$(BOUNDRY) myapp.cpp
# Compile applib
applib.obj : applib.cpp $(UNSTABLEHDRS) stable.pch
 $(CPP) $(CLFLAGS) /Yu$(BOUNDRY) applib.cpp
# Compile headers
stable.pch : $(STABLEHDRS)
 $(CPP) $(CLFLAGS) /Yc$(BOUNDRY) applib.cpp myapp.cpp
NMAKE DEBUG=[1|0]
NMAKE
NMAKE DEBUG=0
Example code for PCH
Source file ANOTHER.H :
C++
// ANOTHER.H : Contains the interface to code that is not
// likely to change.
//
#ifndef __ANOTHER_H
#define __ANOTHER_H
#include<iostream>
void savemoretime( void );
#endif // __ANOTHER_H
Source file STABLE.H :
C++
// STABLE.H : Contains the interface to code that is not likely
// to change. List code that is likely to change
// in the makefile's STABLEHDRS macro.
//
#ifndef __STABLE_H
#define __STABLE_H
#include<iostream>
void savetime( void );
#endif // __STABLE_H
Source file UNSTABLE.H :
C++
// UNSTABLE.H : Contains the interface to code that is
// likely to change. As the code in a header
// file becomes stable, remove the header file
// from the makefile's UNSTABLEHDR macro and list
// it in the STABLEHDRS macro.
//
#ifndef __UNSTABLE_H
#define __UNSTABLE_H
#include<iostream>
void notstable( void );
#endif // __UNSTABLE_H
Source file APPLIB.CPP :
C++
// APPLIB.CPP : This file contains the code that implements
// the interface code declared in the header
Source file MYAPP.CPP :
C++
Compare header units, modules, and precompiled headers
C/C++ building reference
MSVC compiler options Overview of modules in C++
Tutorial: Import the C++ standard library using modules
// files STABLE.H, ANOTHER.H, and UNSTABLE.H.
//
#include"another.h"
#include"stable.h"
#include"unstable.h"
using namespace std;
// The following code represents code that is deemed stable and
// not likely to change. The associated interface code is
// precompiled. In this example, the header files STABLE.H and
// ANOTHER.H are precompiled.
void savetime( void )
 { cout << "Why recompile stable code?\n"; }
void savemoretime( void )
 { cout << "Why, indeed?\n\n"; }
// The following code represents code that is still under
// development. The associated header file is not precompiled.
void notstable( void )
 { cout << "Unstable code requires"
 << " frequent recompilation.\n";
 }
// MYAPP.CPP : Sample application
// All precompiled code other than the file listed
// in the makefile's BOUNDRY macro (stable.h in
// this example) must be included before the file
// listed in the BOUNDRY macro. Unstable code must
// be included after the precompiled code.
//
#include"another.h"
#include"stable.h"
#include"unstable.h"
int main( void )
{
 savetime();
 savemoretime();
 notstable();
}
See also
Walkthrough: Build and import header units in your Visual C++ projects
Walkthrough: Import STL libraries as header units
Release Builds
Article • 08/03/2021
A release build uses optimizations. When you use optimizations to create a release
build, the compiler will not produce symbolic debugging information. The absence of
symbolic debugging information, along with the fact that code is not generated for
TRACE and ASSERT calls, means that the size of your executable file is reduced and will
therefore be faster.
In this section
Common Problems When Creating a Release Build
Fixing Release Build Problems
Using VERIFY Instead of ASSERT
Using the Debug Build to Check for Memory Overwrite
How to: Debug a Release Build
Checking for Memory Overwrites
Optimizing Your Code
See also
C/C++ Building Reference
How to: Create a Release Build
Article • 08/03/2021
To generate a release build of your program
1. Select Release from the Solution Configuration drop-down list, which is on the
Standard toolbar.
2. On the Build menu, click Build.
See also
Release Builds
Common Problems When Creating a
Release Build
Article • 08/03/2021
During development, you will usually build and test with a debug build of your project.
If you then build your application for a release build, you may get an access violation.
The list below shows the primary differences between a debug and a release
(nondebug) build. There are other differences, but following are the primary differences
that would cause an application to fail in a release build when it works in a debug build.
Heap Layout
Compilation
Pointer Support
Optimizations
See the /GZ (Catch Release-Build Errors in Debug Build) compiler option for information
on how to catch release build errors in debug builds.
Heap Layout
Heap layout will be the cause of about ninety percent of the apparent problems when
an application works in debug, but not release.
When you build your project for debug, you are using the debug memory allocator. This
means that all memory allocations have guard bytes placed around them. These guard
bytes detect a memory overwrite. Because heap layout is different between release and
debug versions, a memory overwrite might not create any problems in a debug build,
but may have catastrophic effects in a release build.
For more information, see Check for Memory Overwrite and Use the Debug Build To
Check for Memory Overwrite.
Compilation
Many of the MFC macros and much of the MFC implementation changes when you
build for release. In particular, the ASSERT macro evaluates to nothing in a release build,
so none of the code found in ASSERTs will be executed. For more information, see
Examine ASSERT Statements.
Some functions are inlined for increased speed in the release build. Optimizations are
generally turned on in a release build. A different memory allocator is also being used.
Pointer Support
The lack of debugging information removes the padding from your application. In a
release build, stray pointers have a greater chance of pointing to uninitialized memory
instead of pointing to debug information.
Optimizations
Depending on the nature of certain segments of code, the optimizing compiler might
generate unexpected code. This is the least likely cause of release build problems, but it
does arise on occasion. For a solution, see Optimizing Your Code.
See also
Release Builds
Fixing Release Build Problems
Fixing Release Build Problems
Article • 08/03/2021
If your code generates compile errors after switching from debug build to release build,
there are some areas you should check.
You may receive compiler warnings during an optimized (release) build that you did not
receive during a debug build.
Examine ASSERT Statements
Use the Debug Build To Check for Memory Overwrites
Turn on Generation of Debug Information for the Release Build
Check for Memory Overwrite
See also
Release Builds
Common Problems When Creating a Release Build
Optimizing Your Code
Using VERIFY Instead of ASSERT
Article • 08/03/2021
Suppose that when you run the debug version of your MFC application, there are no
problems. However, the release version of the same application crashes, returns
incorrect results, and/or exhibits some other abnormal behavior.
This problem can be caused when you place important code in an ASSERT statement to
verify that it performs correctly. Because ASSERT statements are commented out in a
release build of an MFC program, the code does not run in a release build.
If you are using ASSERT to confirm that a function call succeeded, consider using VERIFY
instead. The VERIFY macro evaluates its own arguments in both debug and release
builds of the application.
Another preferred technique is to assign the function's return value to a temporary
variable and then test the variable in an ASSERT statement.
Examine the following code fragment:
enum {
 sizeOfBuffer = 20
};
char *buf;
ASSERT(buf = (char *) calloc(sizeOfBuffer, sizeof(char) ));
strcpy_s( buf, sizeOfBuffer, "Hello, World" );
free( buf );
This code runs perfectly in a debug version of an MFC application. If the call to calloc(
) fails, a diagnostic message that includes the file and line number appears. However, in
a retail build of an MFC application:
the call to calloc( ) never occurs, leaving buf uninitialized, or
strcpy_s( ) copies " Hello, World " into a random piece of memory, possibly
crashing the application or causing the system to stop responding, or
free() attempts to free memory that was never allocated.
To use ASSERT correctly, the code sample should be changed to the following:
enum {
 sizeOfBuffer = 20
};
char *buf;
buf = (char *) calloc(sizeOfBuffer, sizeof(char) );
ASSERT( buf != NULL );
strcpy_s( buf, sizeOfBuffer, "Hello, World" );
free( buf );
Or, you can use VERIFY instead:
enum {
 sizeOfBuffer = 20
};
char *buf;
VERIFY(buf = (char *) calloc(sizeOfBuffer, sizeof(char) ));
strcpy_s( buf, sizeOfBuffer, "Hello, World" );
free( buf );
See also
Fixing Release Build Problems
Using the Debug Build to Check for
Memory Overwrite
Article • 08/03/2021
To use the debug build to check for memory overwrite, you must first rebuild your
project for debug. Then, go to the very beginning of your application's InitInstance
function and add the following line:
afxMemDF |= checkAlwaysMemDF;
The debug memory allocator puts guard bytes around all memory allocations. However,
these guard bytes don't do any good unless you check whether they have been
changed (which would indicate a memory overwrite). Otherwise, this just provides a
buffer that might, in fact, allow you to get away with a memory overwrite.
By turning on the checkAlwaysMemDF , you will force MFC to make a call to the
AfxCheckMemory function every time a call to new or delete is made. If a memory
overwrite was detected, it will generate a TRACE message that looks similar to the
following:
Damage Occurred! Block=0x5533
If you see one of these messages, you need to step through your code to determine
where the damage occurred. To isolate more precisely where the memory overwrite
occurred, you can make explicit calls to AfxCheckMemory yourself. For example:
ASSERT(AfxCheckMemory());
 DoABunchOfStuff();
 ASSERT(AfxCheckMemory());
If the first ASSERT succeeds and the second one fails, it means that the memory
overwrite must have occurred in the function between the two calls.
Depending on the nature of your application, you may find that afxMemDF causes your
program to run too slowly to even test. The afxMemDF variable causes AfxCheckMemory to
be called for every call to new and delete. In that case, you should scatter your own calls
to AfxCheckMemory ( ) as shown above, and try to isolate the memory overwrite that way.
See also
Fixing Release Build Problems
How to: Debug a Release Build
Article • 08/03/2021
You can debug a release build of an application.
To debug a release build
1. Open the Property Pages dialog box for the project. For details, see Set C++
compiler and build properties in Visual Studio.
2. Click the C/C++ node. Set Debug Information Format to C7 compatible (/Z7) or
Program Database (/Zi).
3. Expand Linker and click the General node. Set Enable Incremental Linking to No
(/INCREMENTAL:NO).
4. Select the Debugging node. Set Generate Debug Info to Yes (/DEBUG).
5. Select the Optimization node. Set References to /OPT:REF and Enable COMDAT
Folding to /OPT:ICF.
6. You can now debug your release build application. To find a problem, step through
the code (or use Just-In-Time debugging) until you find where the failure occurs,
and then determine the incorrect parameters or code.
If an application works in a debug build, but fails in a release build, one of the
compiler optimizations may be exposing a defect in the source code. To isolate the
problem, disable selected optimizations for each source code file until you locate
the file and the optimization that is causing the problem. (To expedite the process,
you can divide the files into two groups, disable optimization on one group, and
when you find a problem in a group, continue dividing until you isolate the
problem file.)
You can use /RTC to try to expose such bugs in your debug builds.
For more information, see Optimizing Your Code.
See also
Fixing Release Build Problems
Checking for Memory Overwrites
Article • 08/03/2021
If you get an access violation on a call to a heap manipulation function, it is possible
that your program has corrupted the heap. A common symptom of this situation would
be:
Access Violation in _searchseg
The _heapchk function is available in both debug and release builds (Windows NT only)
for verifying the integrity of the run time library heap. You can use _heapchk in much the
same way as the AfxCheckMemory function to isolate a heap overwrite, for example:
if(_heapchk()!=_HEAPOK)
 DebugBreak();
If this function ever fails, you need to isolate at which point the heap was corrupted.
See also
Fixing Release Build Problems
Optimizing your code
Article • 08/03/2021
By optimizing an executable, you can achieve a balance between fast execution speed
and small code size. This topic discusses some of the mechanisms that Visual Studio
provides to help you optimize code.
Language features
The following topics describe some of the optimization features in the C/C++ language.
Optimization Pragmas and Keywords
A list of keywords and pragmas that you can use in your code to improve performance.
Compiler Options Listed by Category
A list of /O compiler options that specifically affect execution speed or code size.
Rvalue Reference Declarator: &&
Rvalue references support the implementation of move semantics. If move semantics are
used to implement template libraries, the performance of applications that use those
templates can significantly improve.
The optimize pragma
If an optimized section of code causes errors or a slowdown, you can use the optimize
pragma to turn off optimization for that section.
Enclose the code between two pragmas, as shown here:
C++
#pragma optimize("", off)
// some code here
#pragma optimize("", on)
Programming practices
You might notice additional warning messages when you compile your code with
optimization. This behavior is expected because some warnings relate only to optimized
code. You can avoid many optimization problems if you heed these warnings.
Paradoxically, optimizing a program for speed could cause code to run slower. This is
because some optimizations for speed increase code size. For example, inlining
functions eliminates the overhead of function calls. However, inlining too much code
might make your program so large that the number of virtual-memory page faults
increases. Therefore, the speed gained from eliminating function calls may be lost to
memory swapping.
The following topics discuss good programming practices.
Tips for Improving Time-Critical Code
Better coding techniques can yield better performance. This topic suggests coding
techniques that can help you make sure that the time-critical parts of your code perform
satisfactorily.
Optimization Best Practices
Provides general guidelines about how best to optimize your application.
Debugging optimized code
Because optimization might change the code created by the compiler, we recommend
that you debug your application and measure its performance, and then optimize your
code.
The following topics provide information about how to debug release builds.
Debugging in Visual Studio
How to: Debug Optimized Code
Why Floating-Point Numbers May Lose Precision
The following topics provide information about how to optimize building, loading, and
executing your code.
Improving Compiler Throughput
Using Function Name Without () Produces No Code
Optimizing Inline Assembly
Specifying Compiler Optimization for an ATL Project
What optimization techniques should I use to improve the client application's
performance when loading?
In this section
Optimization Pragmas and Keywords
Improving Compiler Throughput
Why Floating-Point Numbers May Lose Precision
IEEE Floating-Point Representation
Tips for Improving Time-Critical Code
Using Function Name Without () Produces No Code
Optimization Best Practices
Profile-Guided Optimizations
Environment Variables for Profile-Guided Optimizations
PgoAutoSweep
pgomgr
pgosweep
How to: Merge Multiple PGO Profiles into a Single Profile
See also
C/C++ Building Reference
Optimization Pragmas and Keywords
Article • 08/03/2021
Several keywords and pragmas that you use in your C or C++ code affect optimization:
__asm
__assume
inline, __inline, or __forceinline
#pragma auto_inline
#pragma check_stack
#pragma function
#pragma inline_depth
#pragma inline_recursion
#pragma intrinsic
#pragma optimize
register Keyword
See also
Optimizing Your Code
Improving Compiler Throughput
Article • 08/03/2021
Use precompiled header files to build your project faster. This is important if you are
using ATL, MFC, or the Windows SDK header files.
See /Yc and /Yu.
For more information on precompiled headers, see Precompiled Header Files.
See also
Optimizing Your Code
Why Floating-Point Numbers May Lose
Precision
Article • 08/03/2021
Floating-point decimal values generally do not have an exact binary representation. This
is a side effect of how the CPU represents floating point data. For this reason, you may
experience some loss of precision, and some floating-point operations may produce
unexpected results.
This behavior is the result of one of the following:
The binary representation of the decimal number may not be exact.
There is a type mismatch between the numbers used (for example, mixing float
and double).
To resolve the behavior, most programmers either ensure that the value is greater or
less than what is needed, or they get and use a Binary Coded Decimal (BCD) library that
will maintain the precision.
Binary representation of floating-point values affects the precision and accuracy of
floating-point calculations. Microsoft Visual C++ uses IEEE floating-point format.
C
Example
// Floating-point_number_precision.c
// Compile options needed: none. Value of c is printed with a decimal
// point precision of 10 and 6 (printf rounded value by default) to
// show the difference
#include <stdio.h>
#define EPSILON 0.0001 // Define your own tolerance
#define FLOAT_EQ(x,v) (((v - EPSILON) < x) && (x <( v + EPSILON)))
int main() {
 float a, b, c;
 a = 1.345f;
 b = 1.123f;
 c = a + b;
 // if (FLOAT_EQ(c, 2.468)) // Remove comment for correct result
 if (c == 2.468) // Comment this line for correct result
 printf_s("They are equal.\n");
Output
For EPSILON, you can use the constants FLT_EPSILON, which is defined for float as
1.192092896e-07F, or DBL_EPSILON, which is defined for double as
2.2204460492503131e-016. You need to include float.h for these constants. These
constants are defined as the smallest positive number x, such that x+1.0 is not equal to
1.0. Because this is a very small number, you should employ user-defined tolerance for
calculations involving very large numbers.
Optimizing Your Code
 else
 printf_s("They are not equal! The value of c is %13.10f "
 "or %f",c,c);
}
They are not equal! The value of c is 2.4679999352 or 2.468000
Comments
See also
IEEE Floating-Point Representation
Article • 08/03/2021
Microsoft C++ (MSVC) is consistent with the IEEE numeric standards. The IEEE-754
standard describes floating-point formats, a way to represent real numbers in hardware.
There are at least five internal formats for floating-point numbers that are representable
in hardware targeted by the MSVC compiler. The compiler only uses two of them. The
single-precision (4-byte) and double-precision (8-byte) formats are used in MSVC. Single￾precision is declared using the keyword float . Double-precision is declared using the
keyword double . The IEEE standard also specifies half-precision (2-byte) and quadruple￾precision (16-byte) formats, and a double-extended-precision (10-byte) format, which
some C and C++ compilers implement as the long double data type. In the MSVC
compiler, the long double data type is treated as a distinct type, but the storage type
maps to double . There is, however, intrinsic and assembly language support for
computations using the other formats, including the double-extended-precision format,
where supported by hardware.
The values are stored as follows:
Value Stored as
single-precision sign bit, 8-bit exponent, 23-bit significand
double-precision sign bit, 11-bit exponent, 52-bit significand
In single-precision and double-precision formats, there's an assumed leading 1 in the
fractional part. The fractional part is called the significand (sometimes known as the
mantissa). This leading 1 isn't stored in memory, so the significands are actually 24 or 53
bits, even though one less bit gets stored. The double-extended-precision format
actually stores this bit.
The exponents are biased by half of their possible value. It means you subtract this bias
from the stored exponent to get the actual exponent. If the stored exponent is less than
the bias, it's actually a negative exponent.
The exponents are biased as follows:
Exponent Biased by
8-bit (single-precision) 127
11-bit (double-precision) 1023
These exponents aren't powers of ten; they're powers of two. That is, 8-bit stored
exponents can range from -127 to 127, stored as 0 to 254. The value 2 is roughly
equivalent to 10 , which is the actual limit of single-precision.
The significand is stored as a binary fraction of the form 1.XXX... . This fraction has a
value greater than or equal to 1 and less than 2. Real numbers are always stored in
normalized form. That is, the significand is left-shifted such that the high-order bit of the
significand is always 1. Because this bit is always 1, it's assumed (not stored) in the
single-precision and double-precision formats. The binary (not decimal) point is
assumed to be just to the right of the leading 1.
The format for floating-point representation is as follows:
Format byte 1 byte 2 byte 3 byte 4 ... byte n
single-precision SXXXXXXX XMMMMMMM MMMMMMMM MMMMMMMM
double-precision SXXXXXXX XXXXMMMM MMMMMMMM MMMMMMMM ... MMMMMMMM
S represents the sign bit, the X 's are the biased exponent bits, and the M 's are the
significand bits. The leftmost bit is assumed in single-precision and double-precision
formats.
To shift the binary point properly, you first unbias the exponent and then move the
binary point to the right or left the appropriate number of bits.
The floating-point formats include some values that are treated specially.
Zero can't be normalized, which makes it unrepresentable in the normalized form of a
single-precision or double-precision value. A special bit pattern of all zeroes represents
0. It's also possible to represent -0 as zero with the sign bit set, but -0 and 0 always
compare as equal.
The +∞ and −∞ values are represented by an exponent of all ones, and a significand
that's all zeroes. Positive and negative are represented by using the sign bit.
127
38
Special values
Zero
Infinities
It's possible to represent numbers of smaller magnitude than the smallest number in
normalized form. They're called subnormal or denormal numbers. If the exponent is all
zeroes and the significand is non-zero, then implicit leading bit of the significand is
considered to be zero, not one. The precision of subnormal numbers goes down as the
number of leading zeroes in the significand goes up.
It's possible to represent values that aren't real numbers, such as 0 / 0, in the IEEE
floating-point format. A value of this kind is called a NaN. A NaN is represented by an
exponent of all ones and a non-zero significand. There are two kinds of NaNs, quiet
NaNs, or QNaNs, and signaling NaNs, or SNaNs. Quiet NaNs have a leading one in the
significand, and get propagated through an expression. They represent an
indeterminate value, such as the result of dividing by infinity, or multiplying an infinity
by zero. Signaling NaNs have a leading zero in the significand. They're used for
operations that aren't valid, to signal a floating-point hardware exception.
The following are some examples in single-precision format:
For the value 2, the sign bit is zero. The stored exponent is 128, or 1000 0000 in
binary, which is 127 plus 1. The stored binary significand is (1.) 000 0000 0000 0000
0000 0000, which has an implied leading 1 and binary point, so the actual
significand is one.
Value Formula Binary representation Hexadecimal
2 1 * 2 0100 0000 0000 0000 0000 0000 0000 0000 0x40000000
The value -2. Same as +2 except that the sign bit is set. The same thing is true for
the negative of all IEEE format floating-point numbers.
Value Formula Binary representation Hexadecimal
-2 -1 * 2 1100 0000 0000 0000 0000 0000 0000 0000 0xC0000000
The value 4. Same significand, exponent increases by one (biased value is 129, or
100 0000 1 in binary.
Subnormals
NaN - Not a Number
Examples
1
1
Value Formula Binary representation Hexadecimal Value Formula Binary representation Hexadecimal
4 1 * 2 0100 0000 1000 0000 0000 0000 0000 0000 0x40800000
The value 6. Same exponent, significand is larger by half. It's (1.) 100 0000 ... 0000
0000, which, since it's a binary fraction, is 1 1/2 because the values of the fractional
digits are 1/2, 1/4, 1/8, and so forth.
Value Formula Binary representation Hexadecimal
6 1.5 * 2 0100 0000 1100 0000 0000 0000 0000 0000 0x40C00000
The value 1. Same significand as other powers of two, the biased exponent is one
less than two at 127, or 011 1111 1 in binary.
Value Formula Binary representation Hexadecimal
1 1 * 2 0011 1111 1000 0000 0000 0000 0000 0000 0x3F800000
The value 0.75. The biased exponent is 126, 011 1111 0 in binary, and the
significand is (1.) 100 0000 ... 0000 0000, which is 1 1/2.
Value Formula Binary representation Hexadecimal
0.75 1.5 * 2 0011 1111 0100 0000 0000 0000 0000 0000 0x3F400000
The value 2.5. Exactly the same as two except that the bit that represents 1/4 is set
in the significand.
Value Formula Binary representation Hexadecimal
2.5 1.25 * 2 0100 0000 0010 0000 0000 0000 0000 0000 0x40200000
1/10 is a repeating fraction in binary. The significand is a little less than 1.6, and the
biased exponent says that 1.6 is to be divided by 16. (It's 011 1101 1 in binary,
which is 123 in decimal.) The true exponent is 123 - 127 = -4, which means that the
factor by which to multiply is 2 = 1/16. The stored significand is rounded up in
the last bit in an attempt to represent the unrepresentable number as accurately as
possible. (The reason that 1/10 and 1/100 aren't exactly representable in binary is
similar to the reason that 1/3 isn't exactly representable in decimal.)
Value Formula Binary representation Hexadecimal
0.1 1.6 * 2 0011 1101 1100 1100 1100 1100 1100 1101 0x3DCCCCCD
2
2
0
-1
1
-4
-4
Zero is a special case. It uses the formula for the minimum possible representable
positive value, which is all zeroes.
Value Formula Binary representation Hexadecimal
0 1 * 2 0000 0000 0000 0000 0000 0000 0000 0000 0x00000000
Why Floating-Point Numbers May Lose Precision
-128
See also
Tips for Improving Time-Critical Code
Article • 02/07/2023
Writing fast code requires understanding all aspects of your application and how it
interacts with the system. This article suggests alternatives to some of the more obvious
coding techniques to help you ensure that the time-critical portions of your code
perform satisfactorily.
To summarize, improving time-critical code requires that you:
Know which parts of your program have to be fast.
Know the size and speed of your code.
Know the cost of new features.
Know the minimum work needed to accomplish the job.
To gather information on the performance of your code, you can use the performance
monitor (perfmon.exe).
Sections in this Article
Cache Misses and Page Faults
Sorting and Searching
MFC and Class Libraries
Shared Libraries
Heaps
Threads
Small Working Set
Cache Misses and Page Faults
Missed cache hits, on both the internal and external cache, as well as page faults (going
to secondary storage for program instructions and data) slow the performance of a
program.
A CPU cache hit can cost your program 10-20 clock cycles. An external cache hit can
cost 20-40 clock cycles. A page fault can cost a million clock cycles (assuming a
processor that handles 500 million instructions/second and a time of 2 millisecond for a
page fault). Therefore, it is in the best interest of program execution to write code that
will reduce the number of missed cache hits and page faults.
One reason for slow programs is that they take more page faults or miss the cache more
often than necessary. To avoid this problem, it's important to use data structures with
good locality of reference, which means keeping related things together. Sometimes a
data structure that looks great turns out to be horrible because of poor locality of
reference, and sometimes the reverse is true. Here are two examples:
Dynamically allocated linked lists can reduce program performance. When you
search for an item, or when you traverse a list to the end, each skipped link could
miss the cache or cause a page fault. A list implementation based on simple arrays
might be faster because of better caching and fewer page faults. Even if you allow
for the fact that the array would be harder to grow, it still might be faster.
Hash tables that use dynamically allocated linked lists can degrade performance.
By extension, hash tables that use dynamically allocated linked lists to store their
contents might perform substantially worse. In fact, in the final analysis, a simple
linear search through an array might actually be faster (depending on the
circumstances). Use of an array-based hash table (so-called "closed hashing") is an
often-overlooked implementation that frequently has superior performance.
Sorting and Searching
Sorting is inherently time consuming compared to many typical operations. The best
way to avoid unnecessary slowdown is to avoid sorting at critical times. You may be able
to:
Defer sorting until a non-performance-critical time.
Sort the data at an earlier, non-performance-critical time.
Sort only the part of the data that truly needs sorting.
Sometimes, you can build the list in sorted order. Be careful, because if you need to
insert data in sorted order, you may require a more complicated data structure with
poor locality of reference, leading to cache misses and page faults. There's no approach
that works in all cases. Try several approaches and measure the differences.
Here are some general tips for sorting:
Use a stock sort to minimize bugs.
Any work you can do beforehand to reduce the complexity of the sort is
worthwhile. If a one-time pass over your data simplifies the comparisons and
reduces the sort from O(n log n) to O(n), you'll almost certainly come out ahead.
Think about the locality of reference of the sort algorithm and the data you expect
it to run on.
There are fewer alternatives for searches than for sorting. If the search is time-critical, a
binary search or hash table lookup is almost always best, but as with sorting, you must
keep locality in mind. A linear search through a small array can be faster than a binary
search through a data structure with many pointers that causes page faults or cache
misses.
MFC and Class Libraries
The Microsoft Foundation Classes (MFC) can greatly simplify writing code. When writing
time-critical code, you should be aware of the overhead inherent in some of the classes.
Examine the MFC code that your time-critical code uses to see if it meets your
performance requirements. The following list identifies MFC classes and functions you
should be aware of:
CString MFC calls the C run-time library to allocate memory for a CString
dynamically. Generally speaking, CString is as efficient as any other dynamically
allocated string. As with any dynamically allocated string, it has the overhead of
dynamic allocation and release. Often, a simple char array on the stack can serve
the same purpose and is faster. Don't use a CString to store a constant string. Use
const char * instead. Any operation you perform with a CString object has some
overhead. Using the run-time library string functions may be faster.
CArray A CArray provides flexibility that a regular array doesn't, but your program
may not need that. If you know the specific limits for the array, you can use a
global fixed array instead. If you use CArray , use CArray::SetSize to establish its
size and specify the number of elements by which it grows when a reallocation is
necessary. Otherwise, adding elements can cause your array to be frequently
reallocated and copied, which is inefficient and can fragment memory. Also, if you
insert an item into an array, CArray moves subsequent items in memory and may
need to grow the array. These actions can cause cache misses and page faults. If
you look through the code that MFC uses, you may see that you can write
something more specific to your scenario to improve performance. Since CArray is
a template, for example, you might provide CArray specializations for specific
types.
CList CList is a doubly linked list, so element insertion is fast at the head, tail, and
at a known position ( POSITION ) in the list. Looking up an element by value or index
requires a sequential search, however, which can be slow if the list is long. If your
code doesn't require a doubly linked list, you may want to reconsider using CList .
Using a singly linked list saves the overhead of updating another pointer for all
operations and the memory for that pointer. The extra memory isn't large, but it's
another opportunity for cache misses or page faults.
IsKindOf This function can generate many calls and may access memory in
different data areas, leading to bad locality of reference. It's useful for a debug
build (in an ASSERT call, for example), but try to avoid using it in a release build.
PreTranslateMessage Use PreTranslateMessage when a particular tree of windows
needs different keyboard accelerators or when you must insert message handling
into the message pump. PreTranslateMessage alters MFC dispatch messages. If you
override PreTranslateMessage , do so only at the level needed. For example, it isn't
necessary to override CMainFrame::PreTranslateMessage if you're interested only in
messages going to children of a particular view. Override PreTranslateMessage for
the view class instead.
Don't circumvent the normal dispatch path by using PreTranslateMessage to
handle any message sent to any window. Use window procedures and MFC
message maps for that purpose.
OnIdle Idle events can occur at times you don't expect, such as between
WM_KEYDOWN and WM_KEYUP events. Timers may be a more efficient way to trigger
your code. Don't force OnIdle to be called repeatedly by generating false
messages or by always returning TRUE from an override of OnIdle , which would
never allow your thread to sleep. Again, a timer or a separate thread might be
more appropriate.
Shared libraries
Code reuse is desirable. However, if you're going to use someone else's code, you
should make sure you know exactly what it does in those cases where performance is
critical to you. The best way to understand it is by stepping through the source code or
by measuring with tools such as PView or Performance Monitor.
Heaps
Use multiple heaps with discretion. Additional heaps created with HeapCreate and
HeapAlloc let you manage and then dispose of a related set of allocations. Don't
commit too much memory. If you're using multiple heaps, pay special attention to the
amount of memory that is initially committed.
Instead of multiple heaps, you can use helper functions to interface between your code
and the default heap. Helper functions facilitate custom allocation strategies that can
improve the performance of your application. For example, if you frequently perform
small allocations, you may want to localize these allocations to one part of the default
heap. You can allocate a large block of memory and then use a helper function to
suballocate from that block. Then you won't have multiple heaps with unused memory,
because the allocation is coming out of the default heap.
In some cases, however, using the default heap can reduce locality of reference. Use
Process Viewer, Spy++, or Performance Monitor to measure the effects of moving
objects from heap to heap.
Measure your heaps so you can account for every allocation on the heap. Use the C run￾time debug heap routines to checkpoint and dump your heap. You can read the output
into a spreadsheet program like Microsoft Excel and use pivot tables to view the results.
Note the total number, size, and distribution of allocations. Compare these results with
the size of working sets. Also look at the clustering of related-sized objects.
You can also use the performance counters to monitor memory usage.
Threads
For background tasks, effective idle handling of events may be faster than using threads.
It's easier to understand locality of reference in a single-threaded program.
A good rule of thumb is to use a thread only if an operating system notification that you
block on is at the root of the background work. Threads are the best solution in such a
case because it's impractical to block a main thread on an event.
Threads also present communication problems. You must manage the communication
link between your threads, with a list of messages or by allocating and using shared
memory. Managing the communication link usually requires synchronization to avoid
race conditions and deadlock problems. This complexity can easily turn into bugs and
performance problems.
For more information, see Idle Loop Processing and Multithreading.
Small Working Set
Smaller working sets mean better locality of reference, fewer page faults, and more
cache hits. The process working set is the closest metric the operating system directly
provides for measuring locality of reference.
To set the upper and lower limits of the working set, use
SetProcessWorkingSetSize.
To get the upper and lower limits of the working set, use
GetProcessWorkingSetSize.
To view the size of the working set, use Spy++.
See also
Optimizing Your Code
Using Function Name Without ()
Produces No Code
Article • 08/03/2021
When a function name declared in your program is used without parentheses, the
compiler does not produce code. This occurs regardless of whether or not the function
takes parameters because the compiler calculates the function address; however,
because the function call operator "()" is not present, no call is made. This result is
similar to the following:
// compile with /Wall to generate a warning
int a;
a; // no code generated here either
In Visual C++, even using warning level 4 generates no diagnostic output. No warning is
issued; no code is produced.
The sample code below compiles (with a warning) and links correctly without errors but
produces no code in reference to funcn( ) . For this to work correctly, add the function
call operator "()".
#include <stdio.h>
void funcn();
int main() {
 funcn; /* missing function call operator;
 call will fail. Use funcn() */
 }
void funcn() {
 printf("\nHello World\n");
}
See also
Optimizing Your Code
Optimization best practices
Article • 08/03/2021
This document describes some best practices for optimizing C++ programs in Visual
Studio.
Compiler and Linker Options
Profile-guided optimization
Visual Studio supports profile-guided optimization (PGO). This optimization uses profile
data from training executions of an instrumented version of an application to drive later
optimization of the application. Using PGO can be time consuming, so it may not be
something that every developer uses, but we do recommend using PGO for the final
release build of a product. For more information, see Profile-Guided Optimizations.
In addition, Whole Program Optimization (also knows as Link Time Code Generation)
and the /O1 and /O2 optimizations have been improved. In general, an application
compiled with one of these options will be faster than the same application compiled
with an earlier compiler.
For more information, see /GL (Whole Program Optimization) and /O1, /O2 (Minimize
Size, Maximize Speed).
Which level of optimization to use
If at all possible, final release builds should be compiled with Profile Guided
Optimizations. If it is not possible to build with PGO, whether due to insufficient
infrastructure for running the instrumented builds or not having access to scenarios,
then we suggest building with Whole Program Optimization.
The /Gy switch is also very useful. It generates a separate COMDAT for each function,
giving the linker more flexibility when it comes to removing unreferenced COMDATs and
COMDAT folding. The only downside to using /Gy is that it can cause issues when
debugging. Therefore, it is generally recommended to use it. For more information, see
/Gy (Enable Function-Level Linking).
For linking in 64-bit environments, it is recommended to use the /OPT:REF,ICF linker
option, and in 32-bit environments, /OPT:REF is recommended. For more information,
see /OPT (Optimizations).
It is also strongly recommended to generate debug symbols, even with optimized
release builds. It doesn't affect the generated code, and it makes it a lot easier to debug
your application, if need be.
The /Op compiler option has been removed, and the following four compiler options
dealing with floating point optimizations have been added:
Option Description
/fp:precise This is the default recommendation and should be used in most cases.
/fp:fast Recommended if performance is of the utmost importance, for example in
games. This will result in the fastest performance.
/fp:strict Recommended if precise floating-point exceptions and IEEE behavior is desired.
This will result in the slowest performance.
/fp:except[-] Can be used in conjunction with /fp:strict or /fp:precise , but not /fp:fast .
For more information, see /fp (Specify Floating-Point Behavior).
In this section we will look at two declspecs that can be used in programs to help
performance: __declspec(restrict) and __declspec(noalias) .
The restrict declspec can only be applied to function declarations that return a
pointer, such as __declspec(restrict) void *malloc(size_t size);
The restrict declspec is used on functions that return unaliased pointers. This keyword
is used for the C-Runtime Library implementation of malloc since it will never return a
pointer value that is already in use in the current program (unless you are doing
something illegal, such as using memory after it has been freed).
The restrict declspec gives the compiler more information for performing compiler
optimizations. One of the hardest things for a compiler to determine is what pointers
alias other pointers, and using this information greatly helps the compiler.
It is worth pointing out that this is a promise to the compiler, not something that the
compiler will verify. If your program uses this restrict declspec inappropriately, your
program may have incorrect behavior.
Floating-point switches
Optimization declspecs
For more information, see restrict.
The noalias declspec is also applied only to functions, and indicates that the function is
a semi-pure function. A semi-pure function is one that references or modifies only
locals, arguments, and first-level indirections of arguments. This declspec is a promise to
the compiler, and if the function references globals or second-level indirections of
pointer arguments then the compiler may generate code that breaks the application.
For more information, see noalias.
Optimization pragmas
There are also several useful pragmas for helping optimize code. The first one we'll
discuss is #pragma optimize :
C++
#pragma optimize("{opt-list}", on | off)
This pragma allows you to set a given optimization level on a function-by-function basis.
This is ideal for those rare occasions where your application crashes when a given
function is compiled with optimization. You can use this to turn off optimizations for a
single function:
C++
#pragma optimize("", off)
int myFunc() {...}
#pragma optimize("", on)
For more information, see optimize.
Inlining is one of the most important optimizations that the compiler performs and here
we talk about a couple of the pragmas that help modify this behavior.
#pragma inline_recursion is useful for specifying whether or not you want the
application to be able to inline a recursive call. By default it is off. For shallow recursion
of small functions you may to turn this on. For more information, see inline_recursion.
Another useful pragma for limiting the depth of inlining is #pragma inline_depth . This is
typically useful in situations where you're trying to limit the size of a program or
function. For more information, see inline_depth.
__restrict and __assume
There are a couple of keywords in Visual Studio that can help performance: __restrict
and __assume.
First, it should be noted that __restrict and __declspec(restrict) are two different
things. While they are somewhat related, their semantics are different. __restrict is a
type qualifier, like const or volatile , but exclusively for pointer types.
A pointer that is modified with __restrict is referred to as a __restrict pointer. A
__restrict pointer is a pointer that can only be accessed through the __restrict pointer. In
other words, another pointer cannot be used to access the data pointed to by the
__restrict pointer.
__restrict can be a powerful tool for the Microsoft C++ optimizer, but use it with great
care. If used improperly, the optimizer might perform an optimization that would break
your application.
With __assume , a developer can tell the compiler to make assumptions about the value
of some variable.
For example __assume(a < 5); tells the optimizer that at that line of code the variable a
is less than 5. Again this is a promise to the compiler. If a is actually 6 at this point in the
program then the behavior of the program after the compiler has optimized may not be
what you would expect. __assume is most useful prior to switch statements and/or
conditional expressions.
There are some limitations to __assume . First, like __restrict , it is only a suggestion, so
the compiler is free to ignore it. Also, __assume currently works only with variable
inequalities against constants. It does not propagate symbolic inequalities, for example,
assume(a < b).
Intrinsic support
Intrinsics are function calls where the compiler has intrinsic knowledge about the call,
and rather than calling a function in a library, it emits code for that function. The header
file <intrin.h> contains all of the available intrinsics for each of the supported hardware
platforms.
Intrinsics give the programmer the ability to go deep into the code without having to
use assembly. There are several benefits to using intrinsics:
Your code is more portable. Several of the intrinsics are available on multiple CPU
architectures.
Your code is easier to read, since the code is still written in C/C++.
Your code gets the benefit of compiler optimizations. As the compiler gets better,
the code generation for the intrinsics improves.
For more information, see Compiler Intrinsics.
Exceptions
There is a performance hit associated with using exceptions. Some restrictions are
introduced when using try blocks that inhibit the compiler from performing certain
optimizations. On x86 platforms there is additional performance degradation from try
blocks due to additional state information that must be generated during code
execution. On the 64-bit platforms, try blocks do not degrade performance as much, but
once an exception is thrown, the process of finding the handler and unwinding the stack
can be expensive.
Therefore, it is recommended to avoid introducing try/catch blocks into code that does
not really need it. If you must use exceptions, use synchronous exceptions if possible.
For more information, see Structured Exception Handling (C/C++).
Lastly, throw exceptions for exceptional cases only. Using exceptions for general control
flow will likely make performance suffer.
See also
Optimizing Your Code
Profile-guided optimizations
Article • 10/18/2022
Profile-guided optimization (PGO) lets you optimize a whole executable file, where the
optimizer uses data from test runs of the .exe or .dll file. The data represents the likely
performance of the program in a production environment.
Profile-guided optimizations are only available for x86, x64, or ARM64 native targets.
Profile-guided optimizations aren't available for executable files that run on the
common language runtime. Even if you produce an assembly with mixed native and
managed code (by using the /clr compiler option), you can't use profile-guided
optimization on just the native code. If you attempt to build a project with these options
set in the IDE, a build error results.
７ Note
Information that's gathered from profiling test runs overrides optimizations that
would otherwise be in effect if you specify /Ob, /Os, or /Ot. For more information,
see /Ob (Inline Function Expansion) and /Os, /Ot (Favor Small Code, Favor Fast
Code).
Steps to optimize your app
To use profile-guided optimization, follow these steps to optimize your app:
Compile one or more source code files with /GL.
Each module built with /GL can be examined during profile-guided optimization
test runs to capture run-time behavior. Every module in a profile-guided
optimization build doesn't have to be compiled with /GL. However, only those
modules compiled with /GL are instrumented and later available for profile-guided
optimizations.
Link using /LTCG and /GENPROFILE or /FASTGENPROFILE.
Using both /LTCG and /GENPROFILE or /FASTGENPROFILE creates a .pgd file
when the instrumented app is run. After test-run data is added to the .pgd file, it
can be used as input to the next link step (creating the optimized image). When
specifying /GENPROFILE, you can optionally add a PGD=filename argument to
specify a nondefault name or location for the .pgd file. The combination of /LTCG
and /GENPROFILE or /FASTGENPROFILE linker options replaces the deprecated
/LTCG:PGINSTRUMENT linker option.
Profile the application.
Each time a profiled EXE session ends, or a profiled DLL is unloaded, a
appname!N.pgc file is created. A .pgc file contains information about a particular
application test run. appname is the name of your app, and N is a number starting
with 1 that's incremented based on the number of other appname!N.pgc files in the
directory. You can delete a .pgc file if the test run doesn't represent a scenario you
want to optimize.
During a test run, you can force closure of the currently open .pgc file and the
creation of a new .pgc file with the pgosweep utility (for example, when the end of
a test scenario doesn't coincide with application shutdown).
Your application can also directly invoke a PGO function, PgoAutoSweep, to
capture the profile data at the point of the call as a .pgc file. It can give you finer
control over the code covered by the captured data in your .pgc files. For an
example of how to use this function, see the PgoAutoSweep documentation.
When you create your instrumented build, by default, data collection is done in
non-thread-safe mode, which is faster but may be imprecise. By using the EXACT
argument to /GENPROFILE or /FASTGENPROFILE, you can specify data collection
in thread-safe mode, which is more precise, but slower. This option is also available
if you set the deprecated PogoSafeMode environment variable, or the deprecated
/POGOSAFEMODE linker option, when you create your instrumented build.
Link using /LTCG and /USEPROFILE.
Use both the /LTCG and /USEPROFILE linker options to create the optimized
image. This step takes as input the .pgd file. When you specify /USEPROFILE, you
can optionally add a PGD=filename argument to specify a non-default name or
location for the .pgd file. You can also specify this name by using the deprecated
/PGD linker option. The combination of /LTCG and /USEPROFILE replaces the
deprecated /LTCG:PGOPTIMIZE and /LTCG:PGUPDATE linker options.
It's even possible to create the optimized executable file and later determine that
additional profiling would be useful to create a more optimized image. If the
instrumented image and its .pgd file are available, you can do additional test runs and
rebuild the optimized image with the newer .pgd file, by using the same /LTCG and
/USEPROFILE linker options.
７ Note
Both .pgc and .pgd files are binary file types. If stored in a source control system,
avoid any automatic transformation that may be made to text files.
Optimizations performed by PGO
The profile-guided optimizations include these checks and improvements:
Inlining - For example, if a function A frequently calls function B, and function B is
relatively small, then profile-guided optimizations inline function B in function A.
Virtual Call Speculation - If a virtual call, or other call through a function pointer,
frequently targets a certain function, a profile-guided optimization can insert a
conditionally executed direct call to the frequently targeted function, and the
direct call can be inlined.
Register Allocation - Optimization based on profile data results in better register
allocation.
Basic Block Optimization - Basic block optimization allows commonly executed
basic blocks that temporally execute within a given frame to be placed in the same
set of pages (locality). It minimizes the number of pages used, which minimizes
memory overhead.
Size/Speed Optimization - Functions where the program spends the most
execution time can be optimized for speed.
Function Layout - Based on the call graph and profiled caller/callee behavior,
functions that tend to be along the same execution path are placed in the same
section.
Conditional Branch Optimization - With the value probes, profile-guided
optimizations can find if a given value in a switch statement is used more often
than other values. This value can then be pulled out of the switch statement. The
same can be done with if ... else instructions where the optimizer can order the
if ... else so that either the if or else block is placed first, depending on which
block is more frequently true.
Dead Code Separation - Code that isn't called during profiling is moved to a
special section that's appended to the end of the set of sections. It effectively
keeps this section out of the often-used pages.
EH Code Separation - Because EH code is only exceptionally executed, it can often
be moved to a separate section. It's moved when profile-guided optimizations can
determine that the exceptions occur only on exceptional conditions.
Memory Intrinsics - Whether to expand an intrinsic or not depends on whether it's
called frequently. An intrinsic can also be optimized based on the block size of
moves or copies.
Next steps
Read more about these environment variables, functions, and tools you can use in
profile-guided optimizations:
Environment variables for profile-guided optimizations
These variables were used to specify run-time behavior of testing scenarios. They're now
deprecated and replaced by new linker options. This document shows you how to move
from the environment variables to the linker options.
PgoAutoSweep
A function you can add to your app to provide fine-grained .pgc file data capture
control.
pgosweep
A command-line utility that writes all profile data to the .pgc file, closes the .pgc file,
and opens a new .pgc file.
pgomgr
A command-line utility that adds profile data from one or more .pgc files to the .pgd
file.
How to: Merge multiple PGO profiles into a single profile
Examples of pgomgr usage.
See also
Additional MSVC build tools
Environment Variables for Profile￾Guided Optimizations
Article • 08/03/2021
There are three environment variables that affect test scenarios on an image created
with /LTCG:PGI for profile-guided optimizations:
PogoSafeMode specifies whether to use fast mode or safe mode for application
profiling.
VCPROFILE_ALLOC_SCALE adds additional memory for use by the profiler.
VCPROFILE_PATH lets you specify the folder used for .pgc files.
The PogoSafeMode and VCPROFILE_ALLOC_SCALE environment variables are
deprecated starting in Visual Studio 2015. The linker options /GENPROFILE or
/FASTGENPROFILE and /USEPROFILE specify the same linker behavior as these
environment variables.
PogoSafeMode
This environment variable is deprecated. Use the EXACT or NOEXACT arguments to
/GENPROFILE or /FASTGENPROFILE to control this behavior.
Clear or set the PogoSafeMode environment variable to specify whether to use fast
mode or safe mode for application profiling on x86 systems.
Profile-guided optimization (PGO) has two possible modes during the profiling phase:
fast mode and safe mode. When profiling is in fast mode, it uses the INC instruction to
increase data counters. The INC instruction is faster but is not thread-safe. When
profiling is in safe mode, it uses the LOCK INC instruction to increase data counters. The
LOCK INC instruction has the same functionality as the INC instruction has, and is
thread-safe, but it is slower than the INC instruction.
By default, PGO profiling operates in fast mode. PogoSafeMode is only required if you
want to use safe mode.
To run PGO profiling in safe mode, you must either use the environment variable
PogoSafeMode or the linker switch /PogoSafeMode, depending on the system. If you
are performing the profiling on an x64 computer, you must use the linker switch. If you
are performing the profiling on an x86 computer, you may use the linker switch or set
the PogoSafeMode environment variable to any value before you start the optimization
process.
PogoSafeMode syntax
set PogoSafeMode[=value]
Set PogoSafeMode to any value to enable safe mode. Set without a value to clear a
previous value and re-enable fast mode.
VCPROFILE_ALLOC_SCALE
This environment variable is deprecated. Use the MEMMIN and MEMMAX arguments to
/GENPROFILE or /FASTGENPROFILE to control this behavior.
Modify the VCPROFILE_ALLOC_SCALE environment variable to change the amount of
memory allocated to hold the profile data. In rare cases, there will not be enough
memory available to support gathering profile data when running test scenarios. In
those cases, you can increase the amount of memory by setting
VCPROFILE_ALLOC_SCALE. If you receive an error message during a test run that
indicates that you have insufficient memory, assign a larger value to
VCPROFILE_ALLOC_SCALE, until the test runs complete with no out-of-memory errors.
VCPROFILE_ALLOC_SCALE syntax
set VCPROFILE_ALLOC_SCALE[=scale_value]
The scale_value parameter is a scaling factor for the amount of memory you want for
running test scenarios. The default is 1. For example, this command line sets the scale
factor to 2:
set VCPROFILE_ALLOC_SCALE=2
VCPROFILE_PATH
Use the VCPROFILE_PATH environment variable to specify the directory to create .pgc
files. By default, .pgc files are created in the same directory as the binary being profiled.
However, if the absolute path of the binary does not exist, as may be the case when you
run profile scenarios on a different machine from where the binary was built, you can set
VCPROFILE_PATH to a path that exists on the target machine.
VCPROFILE_PATH syntax
set VCPROFILE_PATH[=path]
Set the path parameter to the directory path in which to add .pgc files. For example, this
command line sets the folder to C:\profile:
set VCPROFILE_PATH=c:\profile
See also
Profile-Guided Optimizations
/GENPROFILE and /FASTGENPROFILE
/USEPROFILE
PgoAutoSweep
Article • 08/03/2021
PgoAutoSweep saves the current profile counter information to a file, and then resets the
counters. Use the function during profile-guided optimization training to write all profile
data from the running program to a .pgc file for later use in the optimization build.
Syntax
C++
void PgoAutoSweep(const char* name); // ANSI/MBCS
void PgoAutoSweep(const wchar_t* name); // UNICODE
Parameters
name
An identifying string for the saved .pgc file.
Remarks
You can call PgoAutoSweep from your application to save and reset the profile data at any
point during application execution. In an instrumented build, PgoAutoSweep captures the
current profiling data, saves it in a file, and resets the profile counters. It's the equivalent
of calling the pgosweep command at a specific point in your executable. In an optimized
build, PgoAutoSweep is a no-op.
The saved profile counter data is placed in a file named base_name-name!value.pgc,
where base_name is the base name of the executable, name is the parameter passed to
PgoAutoSweep , and value is a unique value, usually a monotonically increasing number,
to prevent file name collisions.
The .pgc files created by PgoAutoSweep must be merged into a .pgd file to be used to
create an optimized executable. You can use the pgomgr command to perform the
merge.
You can pass the name of the merged .pgd file to the linker during the optimization
build by using the PGD=filename argument to the /USEPROFILE linker option, or by
using the deprecated /PGD linker option. If you merge the .pgc files into a file named
base_name.pgd, you do not need to specify the filename on the command line, because
the linker picks up this file name by default.
The PgoAutoSweep function maintains the thread-safety setting specified when the
instrumented build is created. If you use the default setting or specify the NOEXACT
argument to the /GENPROFILE or /FASTGENPROFILE linker option, calls to PgoAutoSweep
are not thread-safe. The EXACT argument creates a thread-safe and more accurate, but
slower, instrumented executable.
Routine Required header
PgoAutoSweep <pgobootrun.h>
The executable must include the pgobootrun.lib file in the linked libraries. This file is
included in your Visual Studio installation, in the VC libraries directory for each
supported architecture.
The example below uses PgoAutoSweep to create two .pgc files at different points during
execution. The first contains data that describes the runtime behavior until count is
equal to 3, and the second contains the data collected after this point until just before
application termination.
C++
Requirements
Example
// pgoautosweep.cpp
// Compile by using: cl /c /GL /W4 /EHsc /O2 pgoautosweep.cpp
// Link to instrument: link /LTCG /genprofile pgobootrun.lib
pgoautosweep.obj
// Run to generate data: pgoautosweep
// Merge data by using command line pgomgr tool:
// pgomgr /merge pgoautosweep-func1!1.pgc pgoautosweep-func2!1.pgc
pgoautosweep.pgd
// Link to optimize: link /LTCG /useprofile pgobootrun.lib pgoautosweep.obj
#include <iostream>
#include <windows.h>
#include <pgobootrun.h>
void func2(int count)
{
 std::cout << "hello from func2 " << count << std::endl;
In a developer command prompt, compile the code to an object file by using this
command:
cl /c /GL /W4 /EHsc /O2 pgoautosweep.cpp
Then generate an instrumented build for training by using this command:
link /LTCG /genprofile pgobootrun.lib pgoautosweep.obj
Run the instrumented executable to capture the training data. The data output by the
calls to PgoAutoSweep is saved in files named pgoautosweep-func1!1.pgc and
pgoautosweep-func2!1.pgc. The output of the program should look like this as it runs:
Output
 Sleep(2000);
}
void func1(int count)
{
 std::cout << "hello from func1 " << count << std::endl;
 Sleep(2000);
}
int main()
{
 int count = 10;
 while (count--)
 {
 if (count < 3)
 func2(count);
 else
 {
 func1(count);
 if (count == 3)
 {
 PgoAutoSweep("func1");
 }
 }
 }
 PgoAutoSweep("func2");
}
hello from func1 9
hello from func1 8
hello from func1 7
hello from func1 6
hello from func1 5
hello from func1 4
hello from func1 3
hello from func2 2
hello from func2 1
hello from func2 0
Merge the saved data into a profile training database by running the pgomgr
command:
pgoautosweep-func1!1.pgc pgoautosweep-func2!1.pgc
The output of this command looks something like this:
Output
Microsoft (R) Profile Guided Optimization Manager 14.13.26128.0
Copyright (C) Microsoft Corporation. All rights reserved.
Merging pgoautosweep-func1!1.pgc
pgoautosweep-func1!1.pgc: Used 3.8% (22304 / 589824) of total space
reserved. 0.0% of the counts were dropped due to overflow.
Merging pgoautosweep-func2!1.pgc
pgoautosweep-func2!1.pgc: Used 3.8% (22424 / 589824) of total space
reserved. 0.0% of the counts were dropped due to overflow.
Now you can use this training data to generate an optimized build. Use this command
to build the optimized executable:
link /LTCG /useprofile pgobootrun.lib pgoautosweep.obj
Output
Microsoft (R) Incremental Linker Version 14.13.26128.0
Copyright (C) Microsoft Corporation. All rights reserved.
Merging pgoautosweep!1.pgc
pgoautosweep!1.pgc: Used 3.9% (22904 / 589824) of total space reserved. 
0.0% of the counts were dropped due to overflow.
 Reading PGD file 1: pgoautosweep.pgd
Generating code
0 of 0 ( 0.0%) original invalid call sites were matched.
0 new call sites were added.
294 of 294 (100.00%) profiled functions will be compiled for speed
348 of 1239 inline instances were from dead/cold paths
294 of 294 functions (100.0%) were optimized using profile data
16870 of 16870 instructions (100.0%) were optimized using profile data
Finished generating code
See also
Profile-Guided Optimizations
pgosweep
pgomgr
Article • 08/03/2021
Adds profile data from one or more .pgc files to the .pgd file.
Syntax
pgomgr [options] pgcfiles pgdfile
Parameters
options
The following options can be specified to pgomgr:
/help or /? Displays available pgomgr options.
/clear Causes the .pgd file to be cleared of all profile information. You cannot
specify a .pgc file when /clear is specified.
/detail Displays detailed statistics, including flow graph coverage information.
/summary Displays per-function statistics.
/unique When used with /summary, causes decorated function names to display.
The default, when /unique is not used, is for undecorated function names to be
displayed.
/merge[:n] Causes the data in the .pgc file or files to be added to the .pgd file. The
optional parameter, n, lets you specify that the data should be added n times. For
example, if a scenario would commonly be done six times to reflect how often it is
done by customers, you can do it once in a test run and add it to the .pgd file six
times with pgomgr /merge:6.
pgcfiles
One or more .pgc files whose profile data you want to merge into the .pgd file. You can
specify a single .pgc file or multiple .pgc files. If you do not specify any .pgc files,
pgomgr merges all .pgc files whose filenames are the same as the .pgd file.
pgdfile
The .pgd file into which you are merging data from the .pgc file or files.
Remarks
７ Note
You can start this tool only from a Visual Studio developer command prompt. You
cannot start it from a system command prompt or from File Explorer.
Example
This example command clears the myapp.pgd file of profile data:
pgomgr /clear myapp.pgd
This example command adds profile data in myapp1.pgc to the .pgd file three times:
pgomgr /merge:3 myapp1.pgc myapp.pgd
In this example, profile data from all myapp#.pgc files is added to the myapp.pgd file.
pgomgr -merge myapp1.pgd
See also
Profile-Guided Optimizations
PgoAutoSweep
pgosweep
pgosweep
Article • 08/03/2021
Used in profile-guided optimization to write all profile data from a running program to
the PGC file.
Syntax
pgosweep [options] image pgcfile
Parameters
options
(Optional) The valid values for options are:
/? or /help displays the help message.
/reset resets counts to zero after sweep. This behavior is the default.
/pid:n only sweeps the specified PID, where n is the PID number.
/wait waits for the specified PID to terminate before collecting counts.
/onlyzero doesn't save a PGC file, only zero counts.
/pause pauses count collection on the system.
/resume resumes count collection on the system.
/noreset preserves the count in the runtime data structures.
image
The full path of an EXE or DLL file that was created by using the /GENPROFILE,
/FASTGENPROFILE, or /LTCG:PGINSTRUMENT option.
pgcfile
The PGC file where this command writes out the data counts.
Remarks
The pgosweep command works on programs that were built by using the /GENPROFILE
or /FASTGENPROFILE option, or the deprecated /LTCG:PGINSTRUMENT option. It
interrupts a running program and writes the profile data to a new PGC file. By default,
the command resets counts after each write operation. If you specify the /noreset
option, the command will record the values, but not reset them in the running program.
This option gives you duplicate data if you retrieve the profile data later.
An alternative use for pgosweep is to retrieve profile information just for the normal
operation of the application. For example, you could run pgosweep shortly after you start
the application and discard that file. This command would remove profile data
associated with startup costs. Then, you can run pgosweep before ending the application.
Now the collected data has profile information only from the time the user could
interact with the program.
When you name a PGC file (by using the pgcfile parameter) you can use the standard
format, which is appname!n.pgc . The n represents an increasing numeric value for each
file. If you use this format, the compiler automatically finds this data in the /LTCG
/USEPROFILE or /LTCG:PGO phase. If you don't use the standard format, you must use
pgomgr to merge the PGC files.
７ Note
You can start this tool only from a Visual Studio developer command prompt. You
can't start it from a system command prompt or from File Explorer.
For information on how to capture the profile data from within your executable, see
PgoAutoSweep.
Example
In this example command, pgosweep writes the current profile information for myapp.exe
to myapp!1.pgc .
pgosweep myapp.exe myapp!1.pgc
See also
Profile-Guided Optimizations
PgoAutoSweep
How to: Merge Multiple PGO Profiles
into a Single Profile
Article • 08/03/2021
Profile-guided optimization (PGO) is a great tool for creating optimized binaries based
on a scenario that is profiled. But what if you have an application that has several
important, yet distinct scenarios? How do you create a single profile that PGO can use
from several different scenarios? In Visual Studio, the PGO Manager, pgomgr.exe, does
this job for you.
The syntax for merging profiles is:
pgomgr /merge[:num] [.pgc_files] .pgd_files
where num is an optional weight to use for the .pgc files added by this merge. Weights
are commonly used if there are some scenarios that are more important than others or
if there are scenarios that are to be run multiple times.
７ Note
The PGO Manager does not work with stale profile data. To merge a .pgc file into a
.pgd file, the .pgc file must be generated by an executable which was created by
the same link invocation that generated the .pgd file.
Examples
In this example, the PGO Manager adds pgcFile.pgc to pgdFile.pgd six times:
pgomgr /merge:6 pgcFile.pgc pgdFile.pgd
In this example, the PGO Manager adds pgcFile1.pgc and pgcFile2.pgc to pgdFile.pgd,
two times for each .pgc file:
pgomgr /merge:2 pgcFile1.pgc pgcFile2.pgc pgdFile.pgd
If the PGO Manager is run without any .pgc file arguments, it searches the local directory
for all .pgc files that have the same base name as the .pgd file followed by an
exclamation mark (!) and then one or more arbitrary characters. For example, if the local
directory has files test.pgd, test!1.pgc, test2.pgc, and test!hello.pgc, and the following
command is run from the local directory, then pgomgr merges test!1.pgc and
test!hello.pgc into test.pgd.
pgomgr /merge test.pgd
See also
Profile-Guided Optimizations
Use the Microsoft C++ toolset from the
command line
Article • 03/02/2023
You can build C and C++ applications on the command line by using tools that are
included in Visual Studio. The Microsoft C++ (MSVC) compiler toolset is also
downloadable as a standalone package. You don't need to install the Visual Studio IDE if
you don't plan to use it.
７ Note
This article is about how to set up an environment to use the individual compilers,
linkers, librarian, and other basic tools. The native project build system in Visual
Studio, based on MSBuild, doesn't use the environment as described in this article.
For more information on how to use MSBuild from the command line, see MSBuild
on the command line - C++.
Download and install the tools
If you've installed Visual Studio and a C++ workload, you have all the command-line
tools. For information on how to install C++ and Visual Studio, see Install C++ support
in Visual Studio. If you only want the command-line toolset, download the Build Tools
for Visual Studio . When you run the downloaded executable, it updates and runs the
Visual Studio Installer. To install only the tools you need for C++ development, select
the Desktop development with C++ workload. You can select optional libraries and
toolsets to include under Installation details. To build code by using the Visual Studio
2015, 2017, or 2019 toolsets, select the optional MSVC v140, v141, or v142 build tools.
When you're satisfied with your selections, choose Install.
How to use the command-line tools
When you choose one of the C++ workloads in the Visual Studio Installer, it installs the
Visual Studio platform toolset. A platform toolset has all the C and C++ tools for a
specific Visual Studio version. The tools include the C/C++ compilers, linkers,
assemblers, and other build tools, and matching libraries and header files. You can use
all of these tools at the command line. They're also used internally by the Visual Studio
IDE. There are separate x86-hosted and x64-hosted compilers and tools to build code
for x86, x64, ARM, and ARM64 targets. Each set of tools for a particular host and target
build architecture is stored in its own directory.
To work correctly, the tools require several specific environment variables to be set.
These variables are used to add the tools to the path, and to set the locations of include
files, library files, and SDKs. To make it easy to set these environment variables, the
installer creates customized command files, or batch files, during installation. You can
run one of these command files to set a specific host and target build architecture,
Windows SDK version, and platform toolset. For convenience, the installer also creates
shortcuts in your Start menu. The shortcuts open developer command prompt windows
by using these command files for specific combinations of host and target. These
shortcuts ensure all the required environment variables are set and ready to use.
The required environment variables are specific to your installation and to the build
architecture you choose. They also might be changed by product updates or upgrades.
This variability is one reason why we recommend you use an installed command prompt
shortcut or command file, instead of setting the environment variables yourself.
The toolsets, command files, and shortcuts installed depend on your computer
processor and the options you selected during installation. The x86-hosted tools and
cross tools that build x86 and x64 code are always installed. If you have 64-bit Windows,
the x64-hosted tools and cross tools that build x86 and x64 code are also installed. If
you choose the optional C++ Universal Windows Platform tools, then the x86 and x64
tools that build ARM and ARM64 code also get installed. Other workloads may install
these and other tools.
Path and environment variables for command￾line builds
The MSVC command-line tools use the PATH , TMP , INCLUDE , LIB , and LIBPATH
environment variables, and also use other environment variables specific to your
installed tools, platforms, and SDKs. Even a simple Visual Studio installation may set
twenty or more environment variables. This complexity is why we strongly recommend
that you use a developer command prompt shortcut or one of the customized
command files. We don't recommend you set these variables in the Windows
environment yourself.
To see which environment variables are set by a developer command prompt shortcut,
you can use the SET command. Open a plain command prompt window and capture
the output of the SET command for a baseline. Open a developer command prompt
window and capture the output of the SET command for comparison. Use a diff tool
such as the one built into Visual Studio to highlight the environment variables set by the
developer command prompt. For more information about the compiler and linker
environment variables, see CL environment variables.
Developer command prompt shortcuts
The command prompt shortcuts are installed in a version-specific Visual Studio folder in
your Windows Start menu. Here's a list of the base command prompt shortcuts and the
build architectures they support:
Developer Command Prompt - Sets the environment to use 32-bit, x86-native
tools to build 32-bit, x86-native code.
x86 Native Tools Command Prompt - Sets the environment to use 32-bit, x86-
native tools to build 32-bit, x86-native code.
x64 Native Tools Command Prompt - Sets the environment to use 64-bit, x64-
native tools to build 64-bit, x64-native code.
x86_x64 Cross Tools Command Prompt - Sets the environment to use 32-bit, x86-
native tools to build 64-bit, x64-native code.
x64_x86 Cross Tools Command Prompt - Sets the environment to use 64-bit, x64-
native tools to build 32-bit, x86-native code.
The Start menu folder and shortcut names vary depending on the installed version of
Visual Studio. If you set one, they also depend on the installation Nickname. For
example, suppose you installed Visual Studio 2022, and you gave it a nickname of Latest.
The developer command prompt shortcut is named Developer Command Prompt for
VS 2022 (Latest), in a folder named Visual Studio 2022.
７ Note
Several command-line tools or tool options may require Administrator permission.
If you have permission issues when you use them, we recommend that you open
the developer command prompt window by using the Run as Administrator
option. Right-click to open the shortcut menu for the command prompt window,
then choose More, Run as administrator.
To open a developer command prompt window
1. On the desktop, open the Windows Start menu. In Windows 11, choose the All
apps button to open the list of installed apps. In Windows 10, the list is open to
the left. Scroll down the list to find and open the folder (not the app) for your
version of Visual Studio, for example, Visual Studio 2022.
2. In the folder, choose the Developer Command Prompt for your version of Visual
Studio. This shortcut starts a developer command prompt window that uses the
default build architecture of 32-bit, x86-native tools to build 32-bit, x86-native
code. If you prefer a non-default build architecture, choose one of the native or
cross tools command prompts to specify the host and target architecture.
For an even faster way to open a developer command prompt, enter developer
command prompt in the desktop search box. Then choose the result you want.
７ Note
By default, the current working directory in a developer command prompt is the
root of your Visual Studio installation in the Program Files directory. This isn't an
appropriate location for your code and projects. Change the current working
directory to another location before you create a project. The IDE creates projects
in your user directory, typically in %USERPROFILE%\source\repos.
Developer command file locations
If you prefer to set the build environment in an existing command prompt window, you
can use one of the command files created by the installer. We recommend you set the
environment in a new command prompt window. We don't recommend you later switch
environments in the same command window.
The command file location depends on the version of Visual Studio you installed, and on
choices you made during installation. For Visual Studio 2019, the typical installation
location on a 64-bit system is in \Program Files\Microsoft Visual Studio\2022\
<edition> . The <edition> may be Community, Professional, Enterprise, BuildTools, or
another nickname you supplied.
The primary developer command prompt command file, VsDevCmd.bat , is located in the
Common7\Tools subdirectory. When no parameters are specified, it sets the environment
to use the x86-native tools to build 32-bit x86 code.
More command files are available to set up specific build architectures. The command
files available depend on the Visual Studio workloads and options you've installed. In
Visual Studio 2017 and Visual Studio 2019, you'll find them in the VC\Auxiliary\Build
subdirectory.
These command files set default parameters and call VsDevCmd.bat to set up the
specified build architecture environment. A typical installation may include these
command files:
Command File Host and Target architectures
vcvars32.bat Use the 32-bit x86-native tools to build 32-bit x86 code.
vcvars64.bat Use the 64-bit x64-native tools to build 64-bit x64 code.
vcvarsx86_amd64.bat Use the 32-bit x86-native cross tools to build 64-bit x64 code.
vcvarsamd64_x86.bat Use the 64-bit x64-native cross tools to build 32-bit x86 code.
vcvarsx86_arm.bat Use the 32-bit x86-native cross tools to build ARM code.
vcvarsamd64_arm.bat Use the 64-bit x64-native cross tools to build ARM code.
vcvarsx86_arm64.bat Use the 32-bit x86-native cross tools to build ARM64 code.
vcvarsamd64_arm64.bat Use the 64-bit x64-native cross tools to build ARM64 code.
vcvarsall.bat Use parameters to specify the host and target architectures, Windows
SDK, and platform choices. For a list of supported options, call by using
a /help parameter.
The simplest way to specify a particular build architecture in an existing command
window is to use the vcvarsall.bat file. Use vcvarsall.bat to set environment variables
to configure the command line for native 32-bit or 64-bit compilation. Arguments let
Ｕ Caution
The vcvarsall.bat file and other Visual Studio command files can vary from
computer to computer. Do not replace a missing or damaged vcvarsall.bat file by
using a file from another computer. Rerun the Visual Studio installer to replace the
missing file.
The vcvarsall.bat file also varies from version to version. If the current version of
Visual Studio is installed on a computer that also has an earlier version of Visual
Studio, do not run vcvarsall.bat or another Visual Studio command file from
different versions in the same command prompt window.
Use the developer tools in an existing
command window
you specify cross-compilation to x86, x64, ARM, or ARM64 processors. You can target
Microsoft Store, Universal Windows Platform, or Windows Desktop platforms. You can
even specify which Windows SDK to use, and select the platform toolset version.
When used with no arguments, vcvarsall.bat configures the environment variables to
use the current x86-native compiler for 32-bit Windows Desktop targets. You can add
arguments to configure the environment to use any of the native or cross compiler
tools. vcvarsall.bat displays an error message if you specify a configuration that's not
installed, or not available on your computer.
vcvarsall.bat [ architecture ] [ platform_type ] [ winsdk_version ] [ -
vcvars_ver= vcversion ] [ spectre_mode ]
architecture
This optional argument specifies the host and target architecture to use. If architecture
isn't specified, the default build environment is used. These arguments are supported:
architecture Compiler Host computer
architecture
Build output (target)
architecture
x86 x86 32-bit
native
x86, x64 x86
x86_amd64 or
x86_x64
x64 on x86
cross
x86, x64 x64
x86_arm ARM on x86
cross
x86, x64 ARM
x86_arm64 ARM64 on x86
cross
x86, x64 ARM64
amd64 or x64 x64 64-bit
native
x64 x64
amd64_x86 or
x64_x86
x86 on x64
cross
x64 x86
amd64_arm or
x64_arm
ARM on x64
cross
x64 ARM
amd64_arm64 or
x64_arm64
ARM64 on x64
cross
x64 ARM64
vcvarsall syntax
platform_type
This optional argument allows you to specify store or uwp as the platform type. By
default, the environment is set to build desktop or console apps.
winsdk_version
Optionally specifies the version of the Windows SDK to use. By default, the latest
installed Windows SDK is used. To specify the Windows SDK version, you can use a full
Windows SDK number such as 10.0.10240.0 , or specify 8.1 to use the Windows 8.1
SDK.
vcversion
Optionally specifies the Visual Studio compiler toolset to use. By default, the
environment is set to use the current Visual Studio compiler toolset.
Use -vcvars_ver=14.2x.yyyyy to specify a specific version of the Visual Studio 2019
compiler toolset.
Use -vcvars_ver=14.29 to specify the latest version of the Visual Studio 2019 compiler
toolset.
Use -vcvars_ver=14.0 to specify the Visual Studio 2015 compiler toolset.
spectre_mode
Leave this parameter out to use libraries without Spectre mitigations. Use the value
spectre to use libraries with Spectre mitigations.
To set up the build environment in an existing command prompt
window
1. At the command prompt, use the CD command to change to the Visual Studio
installation directory. Then, use CD again to change to the subdirectory that
contains the configuration-specific command files. For Visual Studio 2019 and
Visual Studio 2017, use the VC\Auxiliary\Build subdirectory. For Visual Studio 2015,
use the VC subdirectory.
2. Enter the command for your preferred developer environment. For example, to
build ARM code for UWP on a 64-bit platform, using the latest Windows SDK and
Visual Studio compiler toolset, use this command line:
vcvarsall.bat amd64_arm uwp
Create your own command prompt shortcut
Open the Properties dialog for a developer command prompt shortcut to see the
command target used. For example, the target for the x64 Native Tools Command
Prompt for VS 2019 shortcut is something similar to:
%comspec% /k "C:\Program Files (x86)\Microsoft Visual
Studio\2019\Community\VC\Auxiliary\Build\vcvars64.bat"
The architecture-specific batch files set the architecture parameter and call
vcvarsall.bat . You can pass the same options to these batch files as you would pass to
vcvarsall.bat , or you can just call vcvarsall.bat directly. To specify parameters for
your own command shortcut, add them to the end of the command in double-quotes.
For example, here's a shortcut to build ARM code for UWP on a 64-bit platform, using
the latest Windows SDK. To use an earlier compiler toolset, specify the version number.
Use something like this command target in your shortcut:
%comspec% /k "C:\Program Files (x86)\Microsoft Visual
Studio\2019\Community\VC\Auxiliary\Build\vcvarsall.bat" amd64_arm uwp -
vcvars_ver=14.29
Adjust the path to reflect your Visual Studio installation directory. The vcvarsall.bat file
has additional information about specific version numbers.
Command-line tools
To build a C/C++ project at a command prompt, Visual Studio provides these
command-line tools:
CL
Use the compiler (cl.exe) to compile and link source code files into apps, libraries, and
DLLs.
Link
Use the linker (link.exe) to link compiled object files and libraries into apps and DLLs.
When you build on the command line, the F1 command isn't available for instant help.
Instead, you can use a search engine to get information about warnings, errors, and
messages. You can also download and use the offline help files. To use the search in
Microsoft Learn, enter your query in the search box at the top of any article.
Command-line project management tools
By default, the Visual Studio IDE uses native project build systems based on MSBuild.
You can invoke MSBuild directly to build projects without using the IDE. You can also use
the devenv command to use Visual Studio to build projects and solutions. Visual Studio
also supports build systems based on CMake or NMake.
MSBuild
Use MSBuild (msbuild.exe) and a project file (.vcxproj) to configure a build and invoke
the toolset without loading the Visual Studio IDE. It's equivalent to running the Build
project or Build Solution command in the Visual Studio IDE. MSBuild has advantages
over the IDE when you build at the command line. You don't have to install the full IDE
on all your build servers and build pipelines. You avoid the extra overhead of the IDE.
MSBuild runs in containerized build environments, and supports a binary logger .
DEVENV
Use DEVENV (devenv.exe) combined with a command-line switch such as /Build or
/Clean to execute certain build commands without displaying the Visual Studio IDE.
CMake
CMake (cmake.exe) is a cross-platform, open-source tool for defining build processes
that run on multiple platforms. CMake can configure and control native build tools for
its supported platforms, such as MSBuild and Make. For more information about CMake,
see the CMake documentation .
NMAKE
Use NMAKE (nmake.exe) to build C++ projects by using a traditional makefile.
７ Note
Starting in Visual Studio 2019 version 16.5, MSBuild and DEVENV don't use the
command-line environment to control the toolset and libraries used.
In this section
These articles show how to build apps on the command line, and describe how to
customize the command-line build environment. Some show how to use 64-bit toolsets,
and target x86, x64, ARM, and ARM64 platforms. They also describe use of the
command-line build tools MSBuild and NMAKE.
Walkthrough: Compiling a native C++ program on the command line
Gives an example that shows how to create and compile a C++ program on the
command line.
Walkthrough: Compile a C program on the command line
Describes how to compile a program written in the C programming language.
Walkthrough: Compiling a C++/CLI program on the command line
Describes how to create and compile a C++/CLI program that uses the .NET Framework.
Walkthrough: Compiling a C++/CX program on the command line
Describes how to create and compile a C++/CX program that uses the Windows
Runtime.
NMAKE reference
Provides links to articles that describe the Microsoft Program Maintenance Utility
(NMAKE.EXE).
MSBuild on the command line - C++
Provides links to articles that discuss how to use msbuild.exe from the command line.
Related sections
/MD, /MT, /LD (Use run-time library)
Describes how to use these compiler options to use a Debug or Release run-time library.
C/C++ compiler options
Provides links to articles that discuss the C and C++ compiler options and CL.exe.
MSVC linker options
Provides links to articles that discuss the linker options and LINK.exe.
Additional MSVC build tools
Provides links to the C/C++ build tools that are included in Visual Studio.
See also
Projects and build systems
Walkthrough: Compiling a Native C++
Program on the Command Line
Article • 02/08/2022
Visual Studio includes a command-line C and C++ compiler. You can use it to create
everything from basic console apps to Universal Windows Platform apps, Desktop apps,
device drivers, and .NET components.
In this walkthrough, you create a basic, "Hello, World"-style C++ program by using a
text editor, and then compile it on the command line. If you'd like to try the Visual
Studio IDE instead of using the command line, see Walkthrough: Working with Projects
and Solutions (C++) or Using the Visual Studio IDE for C++ Desktop Development.
In this walkthrough, you can use your own C++ program instead of typing the one
that's shown. Or, you can use a C++ code sample from another help article.
Prerequisites
To complete this walkthrough, you must have installed either Visual Studio and the
optional Desktop development with C++ workload, or the command-line Build Tools
for Visual Studio.
Visual Studio is an integrated development environment (IDE). It supports a full-featured
editor, resource managers, debuggers, and compilers for many languages and
platforms. Versions available include the free Visual Studio Community edition, and all
can support C and C++ development. For information on how to download and install
Visual Studio, see Install C++ support in Visual Studio.
The Build Tools for Visual Studio installs only the command-line compilers, tools, and
libraries you need to build C and C++ programs. It's perfect for build labs or classroom
exercises and installs relatively quickly. To install only the command-line tools, look for
Build Tools for Visual Studio on the Visual Studio Downloads page.
Before you can build a C or C++ program on the command line, verify that the tools are
installed, and you can access them from the command line. Visual C++ has complex
requirements for the command-line environment to find the tools, headers, and libraries
it uses. You can't use Visual C++ in a plain command prompt window without doing
some preparation. Fortunately, Visual C++ installs shortcuts for you to launch a
developer command prompt that has the environment set up for command line builds.
Unfortunately, the names of the developer command prompt shortcuts and where
they're located are different in almost every version of Visual C++ and on different
versions of Windows. Your first walkthrough task is finding the right one to use.
７ Note
A developer command prompt shortcut automatically sets the correct paths for the
compiler and tools, and for any required headers and libraries. You must set these
environment values yourself if you use a regular Command Prompt window. For
more information, see Use the MSVC toolset from the command line. We
recommend you use a developer command prompt shortcut instead of building
your own.
Open a developer command prompt
1. If you have installed Visual Studio 2017 or later on Windows 10 or later, open the
Start menu and choose All apps. Scroll down and open the Visual Studio folder
(not the Visual Studio application). Choose Developer Command Prompt for VS to
open the command prompt window.
If you have installed Microsoft Visual C++ Build Tools 2015 on Windows 10 or
later, open the Start menu and choose All apps. Scroll down and open the Visual
C++ Build Tools folder. Choose Visual C++ 2015 x86 Native Tools Command
Prompt to open the command prompt window.
You can also use the Windows search function to search for "developer command
prompt" and choose one that matches your installed version of Visual Studio. Use
the shortcut to open the command prompt window.
2. Next, verify that the Visual C++ developer command prompt is set up correctly. In
the command prompt window, enter cl and verify that the output looks
something like this:
Output
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
usage: cl [ option... ] filename... [ /link linkoption... ]
There may be differences in the current directory or version numbers. These values
depend on the version of Visual C++ and any updates installed. If the above
output is similar to what you see, then you're ready to build C or C++ programs at
the command line.
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104
when you run the cl command, then either you are not using a developer
command prompt, or something is wrong with your installation of Visual C++.
You must fix this issue before you can continue.
If you can't find the developer command prompt shortcut, or if you get an error
message when you enter cl , then your Visual C++ installation may have a
problem. Try reinstalling the Visual C++ component in Visual Studio, or reinstall
the Microsoft Visual C++ Build Tools. Don't go on to the next section until the cl
command works. For more information about installing and troubleshooting Visual
C++, see Install Visual Studio.
７ Note
Depending on the version of Windows on the computer and the system
security configuration, you might have to right-click to open the shortcut
menu for the developer command prompt shortcut and then choose Run as
administrator to successfully build and run the program that you create by
following this walkthrough.
Create a Visual C++ source file and compile it on the
command line
1. In the developer command prompt window, enter md c:\hello to create a
directory, and then enter cd c:\hello to change to that directory. This directory is
where both your source file and the compiled program get created.
2. Enter notepad hello.cpp in the command prompt window.
Choose Yes when Notepad prompts you to create a new file. This step opens a
blank Notepad window, ready for you to enter your code in a file named hello.cpp.
3. In Notepad, enter the following lines of code:
C++
This code is a simple program that will write one line of text on the screen and
then exit. To minimize errors, copy this code and paste it into Notepad.
4. Save your work! In Notepad, on the File menu, choose Save.
Congratulations, you've created a C++ source file, hello.cpp, that is ready to
compile.
5. Switch back to the developer command prompt window. Enter dir at the
command prompt to list the contents of the c:\hello directory. You should see the
source file hello.cpp in the directory listing, which looks something like:
Output
The dates and other details will differ on your computer.
#include <iostream>
using namespace std;
int main()
{
 cout << "Hello, world, from Visual C++!" << endl;
}
c:\hello>dir
 Volume in drive C has no label.
 Volume Serial Number is CC62-6545
 Directory of c:\hello
05/24/2016 05:36 PM <DIR> .
05/24/2016 05:36 PM <DIR> ..
05/24/2016 05:37 PM 115 hello.cpp
 1 File(s) 115 bytes
 2 Dir(s) 571,343,446,016 bytes free
７ Note
If you don't see your source code file, hello.cpp , make sure the current
working directory in your command prompt is the C:\hello directory you
created. Also make sure that this is the directory where you saved your source
file. And make sure that you saved the source code with a .cpp file name
extension, not a .txt extension. Your source file gets saved in the current
directory as a .cpp file automatically if you open Notepad at the command
prompt by using the notepad hello.cpp command. Notepad's behavior is
different if you open it another way: By default, Notepad appends a .txt
extension to new files when you save them. It also defaults to saving files in
your Documents directory. To save your file with a .cpp extension in Notepad,
choose File > Save As. In the Save As dialog, navigate to your C:\hello folder
in the directory tree view control. Then use the Save as type dropdown
control to select All Files (*.*). Enter hello.cpp in the File name edit control,
and then choose Save to save the file.
6. At the developer command prompt, enter cl /EHsc hello.cpp to compile your
program.
The cl.exe compiler generates an .obj file that contains the compiled code, and
then runs the linker to create an executable program named hello.exe. This name
appears in the lines of output information that the compiler displays. The output of
the compiler should look something like:
Output
c:\hello>cl /EHsc hello.cpp
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
hello.cpp
Microsoft (R) Incremental Linker Version 14.10.25017.0
Copyright (C) Microsoft Corporation. All rights reserved.
/out:hello.exe
hello.obj
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104,
your developer command prompt is not set up correctly. For information on
how to fix this issue, go back to the Open a developer command prompt
section.
７ Note
If you get a different compiler or linker error or warning, review your source
code to correct any errors, then save it and run the compiler again. For
information about specific errors, use the search box to look for the error
number.
7. To run the hello.exe program, at the command prompt, enter hello .
The program displays this text and exits:
Output
Hello, world, from Visual C++!
Congratulations, you've compiled and run a C++ program by using the command￾line tools.
Next steps
This "Hello, World" example is about as simple as a C++ program can get. Real world
programs usually have header files, more source files, and link to libraries.
You can use the steps in this walkthrough to build your own C++ code instead of typing
the sample code shown. These steps also let you build many C++ code sample
programs that you find elsewhere. You can put your source code and build your apps in
any writeable directory. By default, the Visual Studio IDE creates projects in your user
folder, in a source\repos subfolder. Older versions may put projects in a
Documents\Visual Studio <version>\Projects folder.
To compile a program that has additional source code files, enter them all on the
command line, like:
cl /EHsc file1.cpp file2.cpp file3.cpp
The /EHsc command-line option instructs the compiler to enable standard C++
exception handling behavior. Without it, thrown exceptions can result in undestroyed
objects and resource leaks. For more information, see /EH (Exception Handling Model).
When you supply additional source files, the compiler uses the first input file to create
the program name. In this case, it outputs a program called file1.exe. To change the
name to program1.exe, add an /out linker option:
cl /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe
And to catch more programming mistakes automatically, we recommend you compile
by using either the /W3 or /W4 warning level option:
cl /W4 /EHsc file1.cpp file2.cpp file3.cpp /link /out:program1.exe
The compiler, cl.exe, has many more options. You can apply them to build, optimize,
debug, and analyze your code. For a quick list, enter cl /? at the developer command
prompt. You can also compile and link separately and apply linker options in more
complex build scenarios. For more information on compiler and linker options and
usage, see C/C++ Building Reference.
You can use NMAKE and makefiles, MSBuild and project files, or CMake, to configure
and build more complex projects on the command line. For more information on using
these tools, see NMAKE Reference, MSBuild, and CMake projects in Visual Studio.
The C and C++ languages are similar, but not the same. The MSVC compiler uses a
simple rule to determine which language to use when it compiles your code. By default,
the MSVC compiler treats files that end in .c as C source code, and files that end in
.cpp as C++ source code. To force the compiler to treat all files as C++ independent of
file name extension, use the /TP compiler option.
The MSVC compiler includes a C Runtime Library (CRT) that conforms to the ISO C99
standard, with minor exceptions. Portable code generally compiles and runs as expected.
Certain obsolete library functions, and several POSIX function names, are deprecated by
the MSVC compiler. The functions are supported, but the preferred names have
changed. For more information, see Security Features in the CRT and Compiler Warning
(level 3) C4996.
See also
C++ Language Reference
Projects and build systems
MSVC Compiler Options
Walkthrough: Compile a C program on
the command line
Article • 05/10/2022
The Visual Studio build tools include a C compiler that you can use to create everything
from basic console programs to full Windows Desktop applications, mobile apps, and
more. Microsoft C/C++ (MSVC) is a C and C++ compiler that, in its latest versions,
conforms to some of the latest C language standards, including C11 and C17.
This walkthrough shows how to create a basic, "Hello, World"-style C program by using
a text editor, and then compile it on the command line. If you'd rather work in C++ on
the command line, see Walkthrough: Compiling a Native C++ Program on the
Command Line. If you'd like to try the Visual Studio IDE instead of using the command
line, see Walkthrough: Working with Projects and Solutions (C++) or Using the Visual
Studio IDE for C++ Desktop Development.
Prerequisites
To complete this walkthrough, you must have installed either Visual Studio or the Build
Tools for Visual Studio and the optional Desktop development with C++ workload.
Visual Studio is a powerful integrated development environment that supports a full￾featured editor, resource managers, debuggers, and compilers for many languages and
platforms. For information on these features and how to download and install Visual
Studio, including the free Visual Studio Community edition, see Install Visual Studio.
The Build Tools for Visual Studio version of Visual Studio installs only the command-line
toolset, the compilers, tools, and libraries you need to build C and C++ programs. It's
perfect for build labs or classroom exercises and installs relatively quickly. To install only
the command-line toolset, download Build Tools for Visual Studio from the Visual Studio
downloads page and run the installer. In the Visual Studio installer, select the Desktop
development with C++ workload (in older versions of Visual Studio, select the C++
build tools workload), and choose Install.
When you've installed the tools, there's another tool you'll use to build a C or C++
program on the command line. MSVC has complex requirements for the command-line
environment to find the tools, headers, and libraries it uses. You can't use MSVC in a
plain command prompt window without some preparation. You need a developer
command prompt window, which is a regular command prompt window that has all the
required environment variables set. Fortunately, Visual Studio installs shortcuts for you
to launch developer command prompts that have the environment set up for command
line builds. Unfortunately, the names of the developer command prompt shortcuts and
where they're located are different in almost every version of Visual Studio and on
different versions of Windows. Your first walkthrough task is to find the right shortcut to
use.
７ Note
A developer command prompt shortcut automatically sets the correct paths for the
compiler and tools, and for any required headers and libraries. Some of these
values are different for each build configuration. You must set these environment
values yourself if you don't use one of the shortcuts. For more information, see Use
the MSVC toolset from the command line. Because the build environment is
complex, we strongly recommend you use a developer command prompt shortcut
instead of building your own.
These instructions vary depending on which version of Visual Studio you're using. To see
the documentation for your preferred version of Visual Studio, use the Version selector
control. It's found at the top of the table of contents on this page.
Open a developer command prompt in Visual
Studio 2022
If you've installed Visual Studio 2022 on Windows 10 or later, open the Start menu, and
choose All apps. Then, scroll down and open the Visual Studio 2022 folder (not the
Visual Studio 2022 app). Choose Developer Command Prompt for VS 2022 to open the
command prompt window.
If you're using a different version of Windows, look in your Start menu or Start page for
a Visual Studio tools folder that contains a developer command prompt shortcut. You
can also use the Windows search function to search for "developer command prompt"
and choose one that matches your installed version of Visual Studio. Use the shortcut to
open the command prompt window.
Next, verify that the developer command prompt is set up correctly. In the command
prompt window, enter cl (or CL , case doesn't matter for the compiler name, but it does
matter for compiler options). The output should look something like this:
Output
C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise>cl
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
usage: cl [ option... ] filename... [ /link linkoption... ]
There may be differences in the current directory or version numbers, depending on the
version of Visual Studio and any updates installed. If the above output is similar to what
you see, then you're ready to build C or C++ programs at the command line.
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104 when
you run the cl command, then either you are not using a developer command
prompt, or something is wrong with your installation of Visual Studio. You must fix
this issue before you can continue.
If you can't find the developer command prompt shortcut, or if you get an error
message when you enter cl , then your Visual Studio installation may have a problem. If
you're using Visual Studio 2017 or later, try reinstalling the Desktop development with
C++ workload in the Visual Studio installer. For details, see Install C++ support in Visual
Studio. Or, reinstall the Build Tools from the Visual Studio downloads page. Don't go
on to the next section until the cl command works. For more information about
installing and troubleshooting Visual Studio, see Install Visual Studio.
７ Note
Depending on the version of Windows on the computer and the system security
configuration, you might have to right-click to open the shortcut menu for the
developer command prompt shortcut and then choose Run as Administrator to
successfully build and run the program that you create by following this
walkthrough.
Create a C source file and compile it on the
command line
1. In the developer command prompt window, enter cd c:\ to change the current
working directory to the root of your C: drive. Next, enter md c:\hello to create a
directory, and then enter cd c:\hello to change to that directory. This directory
will hold your source file and the compiled program.
2. Enter notepad hello.c at the developer command prompt. In the Notepad alert
dialog that pops up, choose Yes to create a new hello.c file in your working
directory.
3. In Notepad, enter the following lines of code:
C
4. On the Notepad menu bar, choose File > Save to save hello.c in your working
directory.
5. Switch back to the developer command prompt window. Enter dir at the
command prompt to list the contents of the c:\hello directory. You should see
the source file hello.c in the directory listing, which looks something like:
Output
The dates and other details will differ on your computer. If you don't see your
source code file, hello.c , make sure you've changed to the c:\hello directory
you created, and in Notepad, make sure that you saved your source file in this
#include <stdio.h>
int main()
{
 printf("Hello, World! This is a native C program compiled on the
command line.\n");
 return 0;
}
C:\hello>dir
 Volume in drive C has no label.
 Volume Serial Number is CC62-6545
 Directory of C:\hello
10/02/2017 03:46 PM <DIR> .
10/02/2017 03:46 PM <DIR> ..
10/02/2017 03:36 PM 143 hello.c
 1 File(s) 143 bytes
 2 Dir(s) 514,900,566,016 bytes free
directory. Also make sure that you saved the source code with a .c file name
extension, not a .txt extension.
6. To compile your program, enter cl hello.c at the developer command prompt.
You can see the executable program name, hello.exe, in the lines of output
information that the compiler displays:
Output
c:\hello>cl hello.c
Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x86
Copyright (C) Microsoft Corporation. All rights reserved.
hello.c
Microsoft (R) Incremental Linker Version 14.10.25017.0
Copyright (C) Microsoft Corporation. All rights reserved.
/out:hello.exe
hello.obj
７ Note
If you get an error such as "'cl' is not recognized as an internal or external
command, operable program or batch file," error C1034, or error LNK1104,
your developer command prompt is not set up correctly. For information on
how to fix this issue, go back to the Open a developer command prompt
section.
If you get a different compiler or linker error or warning, review your source
code to correct any errors, then save it and run the compiler again. For
information about specific errors, use the search box at the top of this page to
look for the error number.
7. To run your program, enter hello at the command prompt.
The program displays this text and then exits:
Output
Hello, World! This is a native C program compiled on the command line.
Congratulations, you've compiled and run a C program by using the command
line.
Next steps
This "Hello, World" example is about as basic as a C program can get. Real world
programs have header files and more source files, link in libraries, and do useful work.
You can use the steps in this walkthrough to build your own C code instead of typing
the sample code shown. You can also build many C code sample programs that you find
elsewhere. To compile a program that has more source code files, enter them all on the
command line:
cl file1.c file2.c file3.c
The compiler outputs a program called file1.exe . To change the name to
program1.exe , add an /out linker option:
cl file1.c file2.c file3.c /link /out:program1.exe
And to catch more programming mistakes automatically, we recommend you compile
by using either the /W3 or /W4 warning level option:
cl /W4 file1.c file2.c file3.c /link /out:program1.exe
The compiler, cl.exe, has many more options you can apply to build, optimize, debug,
and analyze your code. For a quick list, enter cl /? at the developer command prompt.
You can also compile and link separately and apply linker options in more complex build
scenarios. For more information on compiler and linker options and usage, see C/C++
Building Reference.
You can use NMAKE and makefiles, or MSBuild and project files to configure and build
more complex projects on the command line. For more information on using these
tools, see NMAKE Reference and MSBuild.
The C and C++ languages are similar, but not the same. The Microsoft C/C++ compiler
(MSVC) uses a basic rule to determine which language to use when it compiles your
code. By default, the MSVC compiler treats all files that end in .c as C source code, and
all files that end in .cpp as C++ source code. To force the compiler to treat all files as C
no matter the file name extension, use the /TC compiler option.
By default, MSVC is compatible with the ANSI C89 and ISO C99 standards, but not
strictly conforming. In most cases, portable C code will compile and run as expected.
The compiler provides optional support for the changes in ISO C11/C17. To compile with
C11/C17 support, use the compiler flag /std:c11 or /std:c17 . C11/C17 support requires
Windows SDK 10.0.20201.0 or later. Windows SDK 10.0.22000.0 or later is
recommended. You can download the latest SDK from the Windows SDK page. For more
information, and instructions on how to install and use this SDK for C development, see
Install C11 and C17 support in Visual Studio.
Certain library functions and POSIX function names are deprecated by MSVC. The
functions are supported, but the preferred names have changed. For more information,
see Security Features in the CRT and Compiler Warning (level 3) C4996.
See also
Walkthrough: Creating a Standard C++ Program (C++)
C Language Reference
Projects and build systems
Compatibility
Walkthrough: Compiling a C++/CLI
Program on the Command Line
Article • 02/24/2023
You can create Visual C++ programs that target the Common Language Runtime (CLR)
and use the .NET Framework, and build them on the command line. Visual C++ supports
the C++/CLI programming language, which has additional types and operators to target
the .NET programming model. For general information about the C++/CLI language, see
.NET Programming with C++/CLI (Visual C++).
In this walkthrough, you use a text editor to create a basic C++/CLI program, and then
compile it on the command line. (You can use your own C++/CLI program instead of
typing the one that's shown, or you can use a C++/CLI code sample from another help
article. This technique is useful for building and testing small modules that have no UI
elements.)
Prerequisites
You understand the fundamentals of the C++ language.
Compiling a C++/CLI Program
The following steps show how to compile a C++/CLI console application that uses .NET
Framework classes.
To enable compilation for C++/CLI, you must use the /clr compiler option. The MSVC
compiler generates an .exe file that contains MSIL code—or mixed MSIL and native code
—and links to the required .NET Framework libraries.
To compile a C++/CLI application on the command line
1. Open a Developer Command Prompt window. For specific instructions, see To
open a developer command prompt window.
Administrator credentials may be required to successfully compile the code,
depending on the computer's operating system and configuration. To run the
command prompt window as an administrator, right-click to open the shortcut
menu for the command prompt and then choose More > Run as administrator.
2. Change the current working directory in the command prompt window to a
directory you can write to, such as your Documents directory.
3. At the command prompt, enter notepad basicclr.cpp .
Choose Yes when you're prompted to create a file.
4. In Notepad, enter these lines:
C++
int main()
{
 System::Console::WriteLine("This is a C++/CLI program.");
}
5. On the menu bar, choose File > Save.
You've created a Visual C++ source file that uses a .NET Framework class (Console)
in the System namespace.
6. At the command prompt, enter cl /clr basicclr.cpp . The cl.exe compiler
compiles the source code into an .obj file that contains MSIL, and then runs the
linker to generate an executable program named basicclr.exe.
7. To run the basicclr.exe program, at the command prompt, enter basicclr .
The program displays this text and exits:
Output
This is a C++/CLI program.
See also
C++ Language Reference
Projects and build systems
MSVC Compiler Options
Walkthrough: Compiling a C++/CX
Program on the Command Line
Article • 03/01/2023
７ Note
For new UWP apps and components, we recommend that you use C++/WinRT, a
standard C++17 language projection for Windows Runtime APIs. C++/WinRT is
available in the Windows SDK from version 1803 (10.0.17134.0) onward.
C++/WinRT is implemented entirely in header files, and is designed to provide you
with first-class access to the modern Windows API.
The Microsoft C++ compiler (MSVC) supports C++ component extensions (C++/CX),
which has additional types and operators to target the Windows Runtime programming
model. You can use C++/CX to build apps for Universal Windows Platform (UWP), and
Windows desktop. For more information, see A Tour of C++/CX and Component
Extensions for Runtime Platforms.
In this walkthrough, you use a text editor to create a basic C++/CX program, and then
compile it on the command line. (You can use your own C++/CX program instead of
typing the one that's shown, or you can use a C++/CX code sample from another help
article. This technique is useful for building and testing small modules that have no UI
elements.)
７ Note
You can also use the Visual Studio IDE to compile C++/CX programs. Because the
IDE includes design, debugging, emulation, and deployment support that isn't
available on the command line, we recommend that you use the IDE to build
Universal Windows Platform (UWP) apps. For more information, see Create a UWP
app in C++.
Prerequisites
You understand the fundamentals of the C++ language.
Compiling a C++/CX Program
To enable compilation for C++/CX, you must use the /ZW compiler option. The MSVC
compiler generates an .exe file that targets the Windows Runtime, and links to the
required libraries.
To compile a C++/CX application on the command line
1. Open a Developer Command Prompt window. For specific instructions, see To
open a developer command prompt window.
Administrator credentials may be required to successfully compile the code,
depending on the computer's operating system and configuration. To run the
command prompt window as an administrator, right-click to open the shortcut
menu for the command prompt and then choose More > Run as administrator.
2. Change the current working directory in the command prompt window to a
directory you can write to, such as your Documents directory.
3. At the command prompt, enter notepad basiccx.cpp.
Choose Yes when you're prompted to create a file.
4. In Notepad, enter these lines:
C++
using namespace Platform;
int main(Platform::Array<Platform::String^>^ args)
{
 Platform::Details::Console::WriteLine("This is a C++/CX program.");
}
5. On the menu bar, choose File > Save.
You've created a C++ source file that uses the Windows Runtime Platform
namespace namespace.
6. At the command prompt, enter cl /EHsc /ZW basiccx.cpp /link
/SUBSYSTEM:CONSOLE . The cl.exe compiler compiles the source code into an .obj
file, and then runs the linker to generate an executable program named
basiccx.exe. The /EHsc compiler option specifies the C++ exception-handling
model, and the /link flag specifies a console application.
7. To run the basiccx.exe program, at the command prompt, enter basiccx.
The program displays this text and exits:
Output
This is a C++/CX program.
See also
Projects and build systems
MSVC Compiler Options
MSBuild on the command line - C++
Article • 08/03/2021
In general, we recommend that you use Visual Studio to set project properties and
invoke the MSBuild system. However, you can use the MSBuild tool directly from the
command prompt. The build process is controlled by the information in a project file
(.vcxproj) that you can create and edit. The project file specifies build options based on
build stages, conditions, and events. In addition, you can specify zero or more
command-line options arguments.
msbuild.exe [ project_file ] [ options ]
Use the /target (or /t) and /property (or /p) command-line options to override specific
properties and targets that are specified in the project file.
An essential function of the project file is to specify a target, which is a particular
operation applied to your project, and the inputs and outputs that are required to
perform that operation. A project file can specify one or more targets, which can include
a default target.
Each target consists of a sequence of one or more tasks. Each task is represented by a
.NET Framework class that contains one executable command. For example, the CL task
contains the cl.exe command.
A task parameter is a property of the class task and typically represents a command-line
option of the executable command. For example, the FavorSizeOrSpeed parameter of
the CL task corresponds to the /Os and /Ot compiler options.
Additional task parameters support the MSBuild infrastructure. For example, the
Sources task parameter specifies a set of tasks that can be consumed by other tasks. For
more information about MSBuild tasks, see Task Reference.
Most tasks require inputs and outputs, such as file names, paths, and string, numeric, or
Boolean parameters. For example, a common input is the name of a .cpp source file to
compile. An important input parameter is a string that specifies the build configuration
and platform, for example, "Debug|Win32". Inputs and outputs are specified by one or
more user-defined XML Item elements contained in an ItemGroup element.
A project file can also specify user-defined properties and ItemDefinitionGroup items.
Properties and items form name/value pairs that can be used as variables in the build.
The name component of a pair defines a macro, and the value component declares the
macro value. A property macro is accessed by using $(name) notation, and an item
macro is accessed by using %(name) notation.
Other XML elements in a project file can test macros, and then conditionally set the
value of any macro or control the execution of the build. Macro names and literal strings
can be concatenated to generate constructs such as a path and file name. On the
command line, the /property option sets or overrides a project property. Items cannot
be referenced on the command line.
The MSBuild system can conditionally execute a target before or after another target.
Also, the system can build a target based on whether the files that the target consumes
are newer than the files it emits.
For more information about MSBuild, see:
MSBuild Overview of MSBuild concepts.
MSBuild Reference Reference information about the MSBuild system.
Project File Schema Reference Lists the MSBuild XML Schema elements, together
with their attributes, and parent and child elements. Especially note the ItemGroup,
PropertyGroup, Target, and Task elements.
Command-Line Reference Describes the command-line arguments and options
that you can use with msbuild.exe.
Task Reference Describes MSBuild tasks. Especially note these tasks, which are
specific to Visual C++: BscMake Task, CL Task, CPPClean Task, LIB Task, Link Task,
MIDL Task, MT Task, RC Task, SetEnv Task, VCMessage Task
Term Definition
Walkthrough: Using
MSBuild to Create a C++
Project
Demonstrates how to create a Visual Studio C++ project using
MSBuild.
How to: Use Build Events
in MSBuild Projects
Demonstrates how to specify an action that occurs at a particuler
stage in the build: before the build starts; before the link step starts;
or after the build ends.
How to: Add a Custom
Build Step to MSBuild
Projects
Demonstrates how to add a user-defined stage to the build sequence.
In This Section
Term Definition
How to: Add Custom
Build Tools to MSBuild
Projects
Demonstrates how to associate a build tool with a particular file.
How to: Integrate
Custom Tools into the
Project Properties
Demonstrates how to add options for a custom tool to the project
properties.
How to: Modify the
Target Framework and
Platform Toolset
Demonstrates how to compile a project for multiple frameworks or
toolsets.
Use the MSVC toolset from the command line
See also
Walkthrough: Using MSBuild to Create a
Visual C++ Project
Article • 10/25/2021
This walkthrough demonstrates how to use MSBuild in a command prompt to build a
Visual Studio C++ project. You'll learn how to create an XML-based .vcxproj project file
for a Visual C++ console application. After building the project, you'll learn how to
customize the build process.
） Important
Don't use this approach if you intend to edit the project file later by using the
Visual Studio IDE. If you create a .vcxproj file manually, the Visual Studio IDE
might not be able to edit or load it, especially if the project uses wildcards in
project items. For more information, see .vcxproj and .props file structure and
.vcxproj files and wildcards.
This walkthrough illustrates these tasks:
Creating the C++ source files for your project.
Creating the XML MSBuild project file.
Using MSBuild to build your project.
Using MSBuild to customize your project.
Prerequisites
You need these prerequisites to complete this walkthrough:
A copy of Visual Studio with the Desktop development with C++ workload
installed.
A general understanding of the MSBuild system.
７ Note
Most of the low-level build instructions are contained in the .targets and .props
files that are defined under the default targets folder, stored in the property
In this walkthrough, you'll create a project that has a source file and a header file. The
source file main.cpp contains the main function for the console application. The header
file main.h contains code to include the <iostream> header file. You can create these
C++ files by using Visual Studio or a text editor such as Visual Studio Code.
1. Create a folder for your project.
2. Create a file named main.cpp and add this code to the file:
C++
3. Create a file named main.h and add this code to the file:
C++
$(VCTargetsPath) . It's where you'll find files such as Microsoft.Cpp.Common.props .
The default path for these files is under %VSINSTALLDIR%MSBuild\Microsoft\VC\
<version>\ . The <version> path element is specific to the version of Visual Studio.
It's v160 for Visual Studio 2019. Visual Studio 2017 stored these files under
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\ . Visual Studio 2015 and earlier versions
stored them under %ProgramFiles(x86)%\MSBuild\Microsoft.Cpp\v4.0\<version>\ .
Create the C++ source files
To create the C++ source files for your project
// main.cpp : the application source code.
#include <iostream>
#include "main.h"
int main()
{
 std::cout << "Hello, from MSBuild!\n";
 return 0;
}
// main.h: the application header code.
/* Additional source code to include. */
Creating the XML MSBuild Project File
An MSBuild project file is an XML file that contains a project root element ( <Project> ).
In the example project you'll build, the <Project> element contains seven child
elements:
Three item group tags ( <ItemGroup> ) that specify project configuration and
platform, source file name, and header file name.
Three import tags ( <Import> ) that specify the location of Microsoft Visual C++
settings.
A property group tag ( <PropertyGroup> ) that specifies project settings.
1. Use a text editor to create a project file that is named myproject.vcxproj , and then
add the root <Project> element shown here. (Use ToolsVersion="14.0" if you're
using Visual Studio 2015, ToolsVersion="15.0" if you're using Visual Studio 2017,
or ToolsVersion="16.0" if you're using Visual Studio 2019.)
XML
Insert the elements in the next procedure steps between the root <Project> tags.
2. Add these two <ProjectConfiguration> child elements in an <ItemGroup> element.
The child element specifies debug and release configurations for a 32-bit Windows
operating system:
XML
To create the MSBuild project file
<Project DefaultTargets="Build" ToolsVersion="16.0"
xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
</Project>
<ItemGroup>
 <ProjectConfiguration Include="Debug|Win32">
 <Configuration>Debug</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
 <ProjectConfiguration Include="Release|Win32">
 <Configuration>Release</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
</ItemGroup>
3. Add an <Import> element that specifies the path of the default C++ settings for
this project:
XML
4. Add a property group element ( <PropertyGroup> ) that specifies two project
properties, <ConfigurationType> and <PlatformToolset> . (Use v140 as the
<PlatformToolset> value if you're using Visual Studio 2015, v141 if you're using
Visual Studio 2017, or v142 if you're using Visual Studio 2019.)
XML
5. Add an <Import> element that specifies the path of the current C++ settings for
this project:
XML
6. Add a <ClCompile> child element in an <ItemGroup> element. The child element
specifies the name of the C/C++ source file to compile:
XML
7. Add a <ClInclude> child element in an <ItemGroup> element. The child element
specifies the name of the header file for the C/C++ source file:
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.default.props" />
<PropertyGroup>
 <ConfigurationType>Application</ConfigurationType>
 <PlatformToolset>v142</PlatformToolset>
</PropertyGroup>
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
<ItemGroup>
 <ClCompile Include="main.cpp" />
</ItemGroup>
７ Note
<ClCompile> is a build target and is defined in the default targets folder.
XML
8. Add an <Import> element that specifies the path of the file that defines the target
for this project:
XML
This code shows the complete project file that you created in the previous procedure.
(Use ToolsVersion="15.0" for Visual Studio 2017, or ToolsVersion="14.0" for Visual
Studio 2015.)
XML
<ItemGroup>
 <ClInclude Include="main.h" />
</ItemGroup>
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.Targets" />
Complete Project File
<Project DefaultTargets="Build" ToolsVersion="16.0"
xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
 <ItemGroup>
 <ProjectConfiguration Include="Debug|Win32">
 <Configuration>Debug</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
 <ProjectConfiguration Include="Release|Win32">
 <Configuration>Release</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
 </ItemGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.default.props" />
 <PropertyGroup>
 <ConfigurationType>Application</ConfigurationType>
 <PlatformToolset>v142</PlatformToolset>
 </PropertyGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
 <ItemGroup>
 <ClCompile Include="main.cpp" />
 </ItemGroup>
 <ItemGroup>
 <ClInclude Include="main.h" />
 </ItemGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Targets" />
</Project>
Using MSBuild to Build Your Project
Enter this command at the command prompt to build your console application:
msbuild myproject.vcxproj /p:configuration=debug
MSBuild creates a folder for the output files, and then compiles and links your project to
generate the Myproject.exe program. After the build process finishes, use this
command to run the application from the debug folder:
myproject
The application should display "Hello, from MSBuild!" in the console window.
Customizing Your Project
MSBuild enables you to execute predefined build targets, apply user-defined properties,
and use custom tools, events, and build steps. This section illustrates these tasks:
Using MSBuild with build targets.
Using MSBuild with build properties.
Using MSBuild with the 64-bit compiler and tools.
Using MSBuild with different toolsets.
Adding MSBuild customizations.
Using MSBuild with Build Targets
A build target is a named set of predefined or user-defined commands that can be
executed during the build. Use the target command-line option ( /t ) to specify a build
target. For the myproject example project, the predefined clean target deletes all files
in the debug folder and creates a new log file.
At the command prompt, enter this command to clean myproject :
msbuild myproject.vcxproj /t:clean
Using MSBuild with Build Properties
The property command-line option ( /p ) enables you to override a property in your
project build file. In the myproject example project, the release or debug build
configuration is specified by the Configuration property. The operating system that
you'll use to run the built application is specified by the Platform property.
At the command prompt, enter this command to create a debug build of the myproject
application to run on 32-bit Windows:
msbuild myproject.vcxproj /p:configuration=debug /p:platform=win32
Assume that the myproject example project also defines a configuration for 64-bit
Windows, and another configuration for a custom operating system named myplatform .
At the command prompt, enter this command to create a release build that runs on 64-
bit Windows:
msbuild myproject.vcxproj /p:configuration=release /p:platform=x64
At the command prompt, enter this command to create a release build for myplatform :
msbuild myproject.vcxproj /p:configuration=release /p:platform=myplatform
If you have installed Visual Studio on 64-bit Windows, the 64-bit x64 native and cross
tools are installed by default. You can configure MSBuild to use the 64-bit compiler and
tools to build your application by setting the PreferredToolArchitecture property. This
property doesn't affect the project configuration or platform properties. By default, the
32-bit version of the tools is used. To specify the 64-bit version of the compiler and
tools, add this property group element to the Myproject.vcxproj project file after the
Microsoft.Cpp.default.props file <Import /> element:
XML
At the command prompt, enter this command to use the 64-bit tools to build your
application:
Using MSBuild with the 64-bit Compiler and Tools
<PropertyGroup>
 <PreferredToolArchitecture>x64</PreferredToolArchitecture>
</PropertyGroup>
msbuild myproject.vcxproj /p:PreferredToolArchitecture=x64
If you have the toolsets and libraries for other versions of Visual C++ installed, MSBuild
can build applications for either the current Visual C++ version or for the other installed
versions. For example, if you have installed Visual Studio 2012, to specify the Visual C++
11.0 toolset for Windows XP, add this property group element to the Myproject.vcxproj
project file after the Microsoft.Cpp.props file <Import /> element:
XML
To rebuild your project with the Visual C++ 11.0 Windows XP toolset, enter this
command:
msbuild myproject.vcxproj /p:PlatformToolset=v110_xp /t:rebuild
MSBuild provides various ways to customize your build process. These articles show how
to add custom build steps, tools, and events to your MSBuild project:
How to: Add a Custom Build Step to MSBuild Projects
How to: Add Custom Build Tools to MSBuild Projects
How to: Use Build Events in MSBuild Projects
Using MSBuild with a different toolset
<PropertyGroup>
 <PlatformToolset>v110_xp</PlatformToolset>
</PropertyGroup>
Adding MSBuild customizations
How to: Use Build Events in MSBuild
Projects
Article • 08/03/2021
A build event is a command that MSBuild performs at a particular stage in the build
process. The pre-build event occurs before the build starts; the pre-link event occurs
before the link step starts; and the post-build event occurs after the build successfully
ends. A build event occurs only if the associated build step occurs. For example, the pre￾link event does not occur if the link step does not run.
Each of the three build events is represented in an item definition group by a command
element ( <Command> ) that is executed and a message element ( <Message> ) that is
displayed when MSBuild performs the build event. Each element is optional, and if you
specify the same element multiple times, the last occurrence takes precedence.
An optional use-in-build element ( < build-event UseInBuild> ) can be specified in a
property group to indicate whether the build event is executed. The value of the content
of a use-in-build element is either true or false . By default, a build event is executed
unless its corresponding use-in-build element is set to false .
The following table lists each build event XML element:
XML Element Description
PreBuildEvent This event executes before the build begins.
PreLinkEvent This event executes before the link step begins.
PostBuildEvent This event executes after the build finishes.
The following table lists each use-in-build element:
XML Element Description
PreBuildEventUseInBuild Specifies whether to execute the pre-build event.
PreLinkEventUseInBuild Specifies whether to execute the pre-link event.
PostBuildEventUseInBuild Specifies whether to execute the post-build event.
Example
The following example can be added inside of the Project element of the
myproject.vcxproj file created in Walkthrough: Using MSBuild to Create a C++ Project. A
pre-build event makes a copy of main.cpp; a pre-link event makes a copy of main.obj;
and a post-build event makes a copy of myproject.exe. If the project is built using a
release configuration, the build events are executed. If the project is built using a debug
configuration, the build events are not executed.
XML
MSBuild on the command line - C++
Walkthrough: Using MSBuild to Create a C++ Project
<ItemDefinitionGroup>
 <PreBuildEvent>
 <Command>copy $(ProjectDir)main.cpp
$(ProjectDir)copyOfMain.cpp</Command>
 <Message>Making a copy of main.cpp </Message>
 </PreBuildEvent>
 <PreLinkEvent>
 <Command>copy $(ProjectDir)$(Configuration)\main.obj
$(ProjectDir)$(Configuration)\copyOfMain.obj</Command>
 <Message>Making a copy of main.obj</Message>
 </PreLinkEvent>
 <PostBuildEvent>
 <Command>copy $(ProjectDir)$(Configuration)\$(TargetFileName)
$(ProjectDir)$(Configuration)\copyOfMyproject.exe</Command>
 <Message>Making a copy of myproject.exe</Message>
 </PostBuildEvent>
</ItemDefinitionGroup>
<PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
 <PreBuildEventUseInBuild>true</PreBuildEventUseInBuild>
 <PreLinkEventUseInBuild>true</PreLinkEventUseInBuild>
 <PostBuildEventUseInBuild>true</PostBuildEventUseInBuild>
</PropertyGroup>
<PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
 <PreBuildEventUseInBuild>false</PreBuildEventUseInBuild>
 <PreLinkEventUseInBuild>false</PreLinkEventUseInBuild>
 <PostBuildEventUseInBuild>false</PostBuildEventUseInBuild>
</PropertyGroup>
See also
How to: Add a Custom Build Step to
MSBuild Projects
Article • 08/03/2021
A custom build step is a user-defined step in a build. A custom build step behaves like
any other command tool step, such as the standard compile or link tool step.
Specify a custom build step in the project file (.vcxproj). The step can specify a command
line to execute, any additional input or output files, and a message to display. If MSBuild
determines that your output files are out-of-date with regard to your input files, it
displays the message and executes the command.
To specify the location of the custom build step in the sequence of build targets, use
one or both of the CustomBuildAfterTargets and CustomBuildBeforeTargets XML
elements in the project file. For example, you could specify that the custom build step
runs after the link tool target and before the manifest tool target. The actual set of
available targets depends on your particular build.
Specify the CustomBuildBeforeTargets element to execute the custom build step before
a particular target runs, the CustomBuildAfterTargets element to execute the step after a
particular target runs, or both elements to execute the step between two adjacent
targets. If neither element is specified, your custom build tool executes at its default
location, which is after the Link target.
Custom build steps and custom build tools share the information specified in the
CustomBuildBeforeTargets and CustomBuildAfterTargets XML elements. Therefore,
specify those targets just one time in your project file.
To define what is executed by the custom build step
1. Add a property group to the project file. In this property group, specify the
command, its inputs and outputs, and a message, as shown in the following
example. This example creates a .cab file from the main.cpp file you created in
Walkthrough: Using MSBuild to Create a C++ Project.
<ItemDefinitionGroup>
 <CustomBuildStep>
 <Command>makecab.exe $(ProjectDir)main.cpp
$(TargetName).cab</Command>
 <Outputs>$(TargetName).cab</Outputs>
 <Inputs>$(ProjectDir)main.cpp</Inputs>
 </CustomBuildStep>
</ItemDefinitionGroup>
To define where in the build the custom build step will
execute
1. Add the following property group to the project file. You can specify both targets,
or you can omit one if you just want the custom step to execute before or after a
particular target. This example tells MSBuild to perform the custom step after the
compile step but before the link step.
<PropertyGroup>
 <CustomBuildAfterTargets>ClCompile</CustomBuildAfterTargets>
 <CustomBuildBeforeTargets>Link</CustomBuildBeforeTargets>
</PropertyGroup>
See also
Walkthrough: Using MSBuild to Create a C++ Project
How to: Use Build Events in MSBuild Projects
How to: Add Custom Build Tools to MSBuild Projects
How to: Add custom build tools to
MSBuild projects
Article • 03/22/2022
A custom build tool is a user-defined, command-line tool that's associated with a
particular file.
For a particular file, specify in the project file ( .vcxproj ) the command line to execute,
any other input or output files, and a message to display. If MSBuild determines that
your output files are out of date relative to your input files, it displays the message and
executes the command-line tool.
Specify custom build tools and custom build
steps
To specify when the custom build tool executes, use one or both of the
CustomBuildBeforeTargets and CustomBuildAfterTargets XML elements in the project
file. For example, you might specify that your custom build tool run after the MIDL
compiler and before the C/C++ compiler. Specify the CustomBuildBeforeTargets
element to execute the tool before a particular target runs. Use the
CustomBuildAfterTargets element to execute the tool after a particular target runs. Use
both elements to run the tool between execution of two targets. If neither element is
specified, your custom build tool executes at its default location, which is before the
MIDL target.
Custom build steps and custom build tools share the information specified in the
CustomBuildBeforeTargets and CustomBuildAfterTargets XML elements. Specify those
targets one time in your project file.
To add a custom build tool
1. Add an item group to the project file and add an item for each input file. Specify
the command and its inputs, outputs, and a message as item metadata, as shown
here. This example assumes that a "faq.txt" file exists in the same directory as your
project. The custom build step copies it to the output directory.
XML
1. Add the following property group to the project file. You have to specify at least
one of the targets. You can omit the other if you're only interested in having your
build step execute before (or after) a particular target. This example performs the
custom step after compiling but before linking.
XML
Walkthrough: Using MSBuild to create a C++ project
How to: Use build events in MSBuild projects
How to: Add a custom build step to MSBuild projects
Common macros for MSBuild commands and properties
MSBuild well-known item metadata
<ItemGroup>
 <CustomBuild Include="faq.txt">
 <Message>Copying readme...</Message>
 <Command>copy %(Identity) $(OutDir)%(Identity)</Command>
 <Outputs>$(OutDir)%(Identity)</Outputs>
 </CustomBuild>
</ItemGroup>
To define where in the build the custom build tools
execute
<PropertyGroup>
 <CustomBuildAfterTargets>ClCompile</CustomBuildAfterTargets>
 <CustomBuildBeforeTargets>Link</CustomBuildBeforeTargets>
</PropertyGroup>
See also
How to: Integrate Custom Tools into the
Project Properties
Article • 08/03/2021
You can add custom tool options to the Visual Studio Property Pages window by
creating an XML file.
The Configuration Properties section of the Property Pages window displays setting
groups known as rules. Every rule contains the settings for a tool or a group of features.
For example, the Linker rule contains the settings for the linker tool. The settings in a
rule can be subdivided into categories.
You can create a rule file that contains properties for your custom tool so that the
properties are loaded when Visual Studio starts. For information about how to modify
the file, see Platform Extensibility Part 2 on the Visual Studio Project Team blog.
The folder to place your rule file in depends on the locale and the version of Visual
Studio in use. In a Visual Studio 2019 or later developer command prompt, the rules
folder is %VSINSTALLDIR%MSBuild\Microsoft\VC\<version>\<locale>\ , where the
<version> value is v160 in Visual Studio 2019. The <locale> is an LCID, for example,
1033 for English. In Visual Studio 2017, the rules folder is
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\<locale>\ . In a Visual Studio 2015 or earlier
developer command prompt, the rules folder is
%ProgramFiles(x86)%\MSBuild\Microsoft.Cpp\v4.0\<version>\<locale>\ . You'll use a
different path for each edition of Visual Studio that's installed, and for each language.
For example, the default rules folder path for Visual Studio 2019 Community edition in
English could be C:\Program Files (x86)\Microsoft Visual
Studio\2019\Community\MSBuild\Microsoft\VC\v160\1033\ .
To add or change project properties
1. In the XML editor, create an XML file.
2. Save the file in the default rules folder. Adjust the path for your language and
Visual Studio edition. Every rule in the Property Pages window is represented by
an XML file in this folder. Make sure that the file is uniquely named in the folder.
3. Copy the content of an existing rules file, such as rc.xml , close it without saving
changes, and then paste the content in your new XML file. You can copy any XML
schema file to use as a template. Choose one that's similar to your tool.
4. In the new XML file, modify the content according to your requirements. Make
sure to change the Rule Name and Rule.DisplayName at the top of the file.
5. Save your changes and close the file.
6. The XML files in the rules folder are loaded when Visual Studio starts. To test the
new file, restart Visual Studio.
7. In Solution Explorer, right-click a project and then choose Properties. In the
Property Pages window, verify that there's a new node with the name of your rule.
See also
MSBuild on the command line - C++
How to: Modify the Target Framework
and Platform Toolset
Article • 11/23/2021
You can edit a Visual Studio C++ project file to target different versions of the C++
platform toolset. The Windows SDK and the .NET Framework used are also editable. (The
.NET Framework applies to C++/CLI projects only). A new project uses the default .NET
Framework and toolset of the Visual Studio version that you use to create the project. If
you modify these values in the .vcxproj file, you can use the same code base for every
compilation target.
Platform toolset
The platform toolset consists of the C++ compiler (cl.exe) and linker (link.exe), along
with the C/C++ standard libraries. Visual Studio 2015, Visual Studio 2017, and Visual
Studio 2019 are binary-compatible. It's shown by the major version of the toolset, which
has remained at 14. Projects compiled in Visual Studio 2019 or Visual Studio 2017 are
ABI-backwards-compatible with 2017 and 2015 projects. The minor version has updated
by 1 for each version since Visual Studio 2015:
Visual Studio 2015: v140
Visual Studio 2017: v141
Visual Studio 2019: v142
Visual Studio 2022: v143
These toolsets support the .NET Framework 4.5 and later.
Visual Studio also supports multitargeting for C++ projects. You can use the latest Visual
Studio IDE to edit and build projects created by older versions of Visual Studio. It
doesn't require a project upgrade the projects to use a new version of the toolset. It
does require the older toolset is installed on your computer. For more information, see
How to use native multi-targeting in Visual Studio. For example, in Visual Studio 2015,
you can target .NET Framework 2.0, but you must use an earlier toolset that supports it.
Target framework (C++/CLI project only)
When you change the target Framework, also change the platform toolset to a version
that supports that Framework. For example, to target the .NET Framework 4.5, you must
use a compatible platform toolset. These toolsets include Visual Studio 2015 (v140),
Visual Studio 2013 (v120), or Visual Studio 2012 (v110). You can use the Windows 7.1
SDK to target .NET Framework 2.0, 3.0, 3.5, and 4.
You can extend the target platform further by creating a custom platform toolset. For
more information, see C++ Native Multi-Targeting on the Visual C++ blog.
To change the target Framework
1. In Visual Studio, in Solution Explorer, select your project. On the menu bar, open
the Project menu and choose Unload project. This command unloads the project
(.vcxproj) file for your project.
７ Note
A C++ project can't be loaded while you edit the project file in Visual Studio.
However, you can use another editor such as Notepad to modify the project
file while the project is loaded in Visual Studio. Visual Studio will detect that
the project file has changed and prompt you to reload the project.
2. On the menu bar, select File, Open, File. In the Open File dialog box, navigate to
your project folder, and then open the project (.vcxproj) file.
3. In the project file, locate the entry for the target Framework version. For example, if
your project is designed to use the .NET Framework 4.5, locate
<TargetFrameworkVersion>v4.5</TargetFrameworkVersion> in the <PropertyGroup
Label="Globals"> element of the <Project> element. If the
<TargetFrameworkVersion> element isn't present, your project doesn't use the .NET
Framework and no change is required.
4. Change the value to the Framework version you want, such as v3.5 or v4.6.
5. Save the changes and close the editor.
6. In Solution Explorer, open the shortcut menu for your project and then choose
Reload Project.
7. To verify the change, on the menu bar, select Project > Properties to open your
project Property Pages dialog box. In the dialog box, select the Configuration
Properties > General property page. Verify that .NET Target Framework Version
shows the new Framework version.
To change the platform toolset
1. In Visual Studio, on the menu bar, select Project > Properties to open your project
Property Pages dialog box.
2. In the top of the Property Pages dialog box, open the Configuration drop-down
list and then select All Configurations.
3. In the dialog box, select the Configuration Properties > General property page.
4. In the properties page, select Platform Toolset and then select the toolset you
want from the drop-down list. For example, if you've installed the Visual Studio
2010 toolset, select Visual Studio 2010 (v100) to use it for your project.
5. Choose the OK button to save your changes.
Next Steps
Walkthrough: Working with Projects and Solutions (C++)
See also
MSBuild on the command line - C++
Walkthrough: Create and use a static
library
Article • 10/29/2021
This step-by-step walkthrough shows how to create a static library (.lib file) for use with
C++ apps. Using a static library is a great way to reuse code. Rather than
reimplementing the same routines in every app that requires the functionality, you write
them one time in a static library and then reference it from the apps. Code linked from a
static library becomes part of your app—you don't have to install another file to use the
code.
This walkthrough covers these tasks:
Create a static library project
Add a class to the static library
Create a C++ console app that references the static library
Use the functionality from the static library in the app
Run the app
Prerequisites
An understanding of the fundamentals of the C++ language.
Create a static library project
The instructions for how to create the project vary depending on your version of Visual
Studio. To see the documentation for your preferred version of Visual Studio, use the
Version selector control. It's found at the top of the table of contents on this page.
To create a static library project in Visual Studio
1. On the menu bar, choose File > New > Project to open the Create a New Project
dialog.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Library.
3. From the filtered list of project types, select Windows Desktop Wizard, then
choose Next.
4. In the Configure your new project page, enter MathLibrary in the Project name
box to specify a name for the project. Enter StaticMath in the Solution name box.
Choose the Create button to open the Windows Desktop Project dialog.
5. In the Windows Desktop Project dialog, under Application type, select Static
Library (.lib).
6. Under Additional options, uncheck the Precompiled header check box if it's
checked. Check the Empty project box.
7. Choose OK to create the project.
1. To create a header file for a new class, right-click to open the shortcut menu for
the MathLibrary project in Solution Explorer, and then choose Add > New Item.
2. In the Add New Item dialog box, select Visual C++ > Code. In the center pane,
select Header File (.h). Specify a name for the header file—for example,
MathLibrary.h—and then choose the Add button. A nearly blank header file is
displayed.
3. Add a declaration for a class named Arithmetic to do common mathematical
operations such as addition, subtraction, multiplication, and division. The code
should resemble:
C++
Add a class to the static library
To add a class to the static library
// MathLibrary.h
#pragma once
namespace MathLibrary
{
 class Arithmetic
 {
 public:
 // Returns a + b
 static double Add(double a, double b);
 // Returns a - b
 static double Subtract(double a, double b);
4. To create a source file for the new class, open the shortcut menu for the
MathLibrary project in Solution Explorer, and then choose Add > New Item.
5. In the Add New Item dialog box, in the center pane, select C++ File (.cpp). Specify
a name for the source file—for example, MathLibrary.cpp—and then choose the
Add button. A blank source file is displayed.
6. Use this source file to implement the functionality for class Arithmetic . The code
should resemble:
C++
 // Returns a * b
 static double Multiply(double a, double b);
 // Returns a / b
 static double Divide(double a, double b);
 };
}
// MathLibrary.cpp
// compile with: cl /c /EHsc MathLibrary.cpp
// post-build command: lib MathLibrary.obj
#include "MathLibrary.h"
namespace MathLibrary
{
 double Arithmetic::Add(double a, double b)
 {
 return a + b;
 }
 double Arithmetic::Subtract(double a, double b)
 {
 return a - b;
 }
 double Arithmetic::Multiply(double a, double b)
 {
 return a * b;
 }
 double Arithmetic::Divide(double a, double b)
 {
 return a / b;
 }
}
7. To build the static library, select Build > Build Solution on the menu bar. The build
creates a static library, MathLibrary.lib, that can be used by other programs.
７ Note
When you build on the Visual Studio command line, you must build the
program in two steps. First, run cl /c /EHsc MathLibrary.cpp to compile the
code and create an object file that's named MathLibrary.obj. (The cl
command invokes the compiler, Cl.exe, and the /c option specifies compile
without linking. For more information, see /c (Compile Without Linking).)
Second, run lib MathLibrary.obj to link the code and create the static library
MathLibrary.lib. (The lib command invokes the Library Manager, Lib.exe. For
more information, see LIB Reference.)
Create a C++ console app that references the
static library
To create a C++ console app that references the static
library in Visual Studio
1. In Solution Explorer, right-click on the top node, Solution 'StaticMath', to open
the shortcut menu. Choose Add > New Project to open the Add a New Project
dialog.
2. At the top of the dialog, set the Project type filter to Console.
3. From the filtered list of project types, choose Console App then choose Next. In
the next page, enter MathClient in the Name box to specify a name for the project.
4. Choose the Create button to create the client project.
5. After you create a console app, an empty program is created for you. The name for
the source file is the same as the name that you chose earlier. In the example, it's
named MathClient.cpp .
Use the functionality from the static library in
the app
To use the functionality from the static library in the app
1. Before you can use the math routines in the static library, you must reference it.
Open the shortcut menu for the MathClient project in Solution Explorer, and then
choose Add > Reference.
2. The Add Reference dialog box lists the libraries that you can reference. The
Projects tab lists the projects in the current solution and any libraries they
reference. Open the Projects tab, select the MathLibrary check box, and then
choose the OK button.
3. To reference the MathLibrary.h header file, you must modify the included
directories path. In Solution Explorer, right-click on MathClient to open the
shortcut menu. Choose Properties to open the MathClient Property Pages dialog
box.
4. In the MathClient Property Pages dialog box, set the Configuration drop-down to
All Configurations. Set the Platform drop-down to All Platforms.
5. Select the Configuration Properties > C/C++ > General property page. In the
Additional Include Directories property, specify the path of the MathLibrary
directory, or browse for it.
To browse for the directory path:
a. Open the Additional Include Directories property value drop-down list, and
then choose Edit.
b. In the Additional Include Directories dialog box, double-click in the top of the
text box. Then choose the ellipsis button (...) at the end of the line.
c. In the Select Directory dialog box, navigate up a level, and then select the
MathLibrary directory. Then choose the Select Folder button to save your
selection.
d. In the Additional Include Directories dialog box, choose the OK button.
e. In the Property Pages dialog box, choose the OK button to save your changes
to the project.
6. You can now use the Arithmetic class in this app by including the #include
"MathLibrary.h" header in your code. Replace the contents of MathClient.cpp with
this code:
C++
7. To build the executable, choose Build > Build Solution on the menu bar.
1. Make sure that MathClient is selected as the default project. To select it, right-click
to open the shortcut menu for MathClient in Solution Explorer, and then choose
Set as StartUp Project.
2. To run the project, on the menu bar, choose Debug > Start Without Debugging.
The output should resemble:
Output
// MathClient.cpp
// compile with: cl /EHsc MathClient.cpp /link MathLibrary.lib
#include <iostream>
#include "MathLibrary.h"
int main()
{
 double a = 7.4;
 int b = 99;
 std::cout << "a + b = " <<
 MathLibrary::Arithmetic::Add(a, b) << std::endl;
 std::cout << "a - b = " <<
 MathLibrary::Arithmetic::Subtract(a, b) << std::endl;
 std::cout << "a * b = " <<
 MathLibrary::Arithmetic::Multiply(a, b) << std::endl;
 std::cout << "a / b = " <<
 MathLibrary::Arithmetic::Divide(a, b) << std::endl;
 return 0;
}
Run the app
To run the app
a + b = 106.4
a - b = -91.6
a * b = 732.6
a / b = 0.0747475
See also
Walkthrough: Creating and Using a Dynamic Link Library (C++)
Desktop Applications (Visual C++)
Create C/C++ DLLs in Visual Studio
Article • 08/03/2021
In Windows, a dynamic-link library (DLL) is a kind of executable file that acts as a shared
library of functions and resources. Dynamic linking is an operating system capability. It
enables an executable to call functions or use resources stored in a separate file. These
functions and resources can be compiled and deployed separately from the executables
that use them.
A DLL isn't a stand-alone executable. DLLs run in the context of the applications that call
them. The operating system loads the DLL into an application's memory space. It's done
either when the application is loaded (implicit linking), or on demand at runtime (explicit
linking). DLLs also make it easy to share functions and resources across executables.
Multiple applications can access the contents of a single copy of a DLL in memory at the
same time.
Differences between dynamic linking and static
linking
Static linking copies all the object code in a static library into the executables that use it
when they're built. Dynamic linking includes only the information needed by Windows
at run time to locate and load the DLL that contains a data item or function. When you
create a DLL, you also create an import library that contains this information. When you
build an executable that calls the DLL, the linker uses the exported symbols in the
import library to store this information for the Windows loader. When the loader loads a
DLL, the DLL is mapped into the memory space of your application. If present, a special
function in the DLL, DllMain , is called to do any initialization the DLL requires.
Differences between applications and DLLs
Even though DLLs and applications are both executable modules, they differ in several
ways. The most obvious difference is that you can't run a DLL. From the system's point
of view, there are two fundamental differences between applications and DLLs:
An application can have multiple instances of itself running in the system
simultaneously. A DLL can have only one instance.
An application can be loaded as a process. It can own things such as a stack,
threads of execution, global memory, file handles, and a message queue. A DLL
can't own these things.
Advantages of using DLLs
Dynamic linking to code and resources offers several advantages over static linking:
Dynamic linking saves memory and reduces swapping. Many processes can use a
DLL simultaneously, sharing a single copy of the read-only parts of a DLL in
memory. In contrast, every application that is built by using a statically linked
library has a complete copy of the library code that Windows must load into
memory.
Dynamic linking saves disk space and bandwidth. Many applications can share a
single copy of the DLL on disk. In contrast, each application built by using a static
link library has the library code linked into its executable image. That uses more
disk space, and takes more bandwidth to transfer.
Maintenance, security fixes, and upgrades can be easier. When your applications
use common functions in a DLL, you can implement bug fixes and deploy updates
to the DLL. When DLLs are updated, the applications that use them don't need to
be recompiled or relinked. They can make use of the new DLL as soon as it's
deployed. In contrast, when you make fixes in statically linked object code, you
must relink and redeploy every application that uses it.
You can use DLLs to provide after-market support. For example, a display driver
DLL can be modified to support a display that wasn't available when the
application was shipped.
You can use explicit linking to discover and load DLLs at runtime. For example,
application extensions that add new functionality to your app without rebuilding or
redeploying it.
Dynamic linking makes it easier to support applications written in different
programming languages. Programs written in different programming languages
can call the same DLL function as long as the programs follow the function's
calling convention. The programs and the DLL function must be compatible in the
following ways: The order in which the function expects its arguments to be
pushed onto the stack. Whether the function or the application is responsible for
cleaning up the stack. And, whether any arguments are passed in registers.
Dynamic linking provides a mechanism to extend the Microsoft Foundation Class
library (MFC) classes. You can derive classes from the existing MFC classes and
place them in an MFC extension DLL for use by MFC applications.
Dynamic linking makes creation of international versions of your application easier.
DLLs are a convenient way to supply locale-specific resources, which make it much
easier to create international versions of an application. Instead of shipping many
localized versions of your application, you can place the strings and images for
each language in a separate resource DLL. Then your application can load the
appropriate resources for that locale at runtime.
A potential disadvantage to using DLLs is that the application isn't self-contained. It
depends on the existence of a separate DLL module: one that you must deploy or verify
yourself as part of your installation.
More information on how to create and use
DLLs
The following articles provide detailed information about how to create C/C++ DLLs in
Visual Studio.
Walkthrough: Creating and using a dynamic link library (C++)
Describes how to create and use a DLL using Visual Studio.
Kinds of DLLs
Provides information about the different kinds of DLLs that can be built.
DLL frequently asked questions
Provides answers to frequently asked questions about DLLs.
Link an executable to a DLL
Describes explicit and implicit linking to a DLL.
Initialize a DLL
Discusses DLL initialization code that must execute when your DLL loads.
DLLs and Visual C++ run-time library behavior
Describes the run-time library DLL startup sequence.
LoadLibrary and AfxLoadLibrary
Discusses using LoadLibrary and AfxLoadLibrary to explicitly link to a DLL at runtime.
GetProcAddress
Discusses using GetProcAddress to obtain the address of an exported function in the
DLL.
FreeLibrary and AfxFreeLibrary
Discusses using FreeLibrary and AfxFreeLibrary when the DLL module is no longer
needed.
Dynamic-Link Library Search Order
Describes the search path that the Windows operating system uses to locate a DLL on
the system.
Module states of a regular MFC DLL dynamically linked to MFC
Describes the module states of a regular MFC DLL dynamically linked to MFC.
MFC extension DLLs
Explains DLLs that typically implement reusable classes derived from the existing MFC
classes.
Creating a resource-only DLL
Discusses a resource-only DLL, which contains nothing but resources, such as icons,
bitmaps, strings, and dialog boxes.
Localized resources in MFC Applications: Satellite DLLs
Provides enhanced support for satellite DLLs, a feature that helps in creating
applications localized for multiple languages.
Importing and exporting
Describes importing public symbols into an application or exporting functions from a
DLL
Active technology and DLLs
Allows object servers to be implemented inside a DLL.
Automation in a DLL
Describes what the Automation option in the MFC DLL Wizard supplies.
Naming conventions for MFC DLLs
Discusses how the DLLs and libraries included in MFC follow a structured naming
convention.
Calling DLL functions from Visual Basic applications
Describes how to call DLL functions from Visual Basic applications.
Related Sections
Using MFC as part of a DLL
Describes regular MFC DLLs, which let you use the MFC library as part of a Windows
dynamic-link library.
DLL version of MFC
Describes how you can use the MFCxx.dll and MFCxxD.dll (where x is the MFC version
number) shared dynamic-link libraries with MFC applications and MFC extension DLLs.
Walkthrough: Create and use your own
Dynamic Link Library (C++)
Article • 12/10/2021
This step-by-step walkthrough shows how to use the Visual Studio IDE to create your
own dynamic link library (DLL) written in Microsoft C++ (MSVC). Then it shows how to
use the DLL from another C++ app. DLLs (also known as shared libraries in UNIX-based
operating systems) are one of the most useful kinds of Windows components. You can
use them as a way to share code and resources, and to shrink the size of your apps.
DLLs can even make it easier to service and extend your apps.
In this walkthrough, you'll create a DLL that implements some math functions. Then
you'll create a console app that uses the functions from the DLL. You'll also get an
introduction to some of the programming techniques and conventions used in Windows
DLLs.
This walkthrough covers these tasks:
Create a DLL project in Visual Studio.
Add exported functions and variables to the DLL.
Create a console app project in Visual Studio.
Use the functions and variables imported from the DLL in the console app.
Run the completed app.
Like a statically linked library, a DLL exports variables, functions, and resources by name.
A client app imports the names to use those variables, functions, and resources. Unlike a
statically linked library, Windows connects the imports in your app to the exports in a
DLL at load time or at run time, instead of connecting them at link time. Windows
requires extra information that isn't part of the standard C++ compilation model to
make these connections. The MSVC compiler implements some Microsoft-specific
extensions to C++ to provide this extra information. We explain these extensions as we
go.
This walkthrough creates two Visual Studio solutions; one that builds the DLL, and one
that builds the client app. The DLL uses the C calling convention. It can be called from
apps written in other programming languages, as long as the platform, calling
conventions, and linking conventions match. The client app uses implicit linking, where
Windows links the app to the DLL at load-time. This linking lets the app call the DLL￾supplied functions just like the functions in a statically linked library.
This walkthrough doesn't cover some common situations. The code doesn't show the
use of C++ DLLs by other programming languages. It doesn't show how to create a
resource-only DLL, or how to use explicit linking to load DLLs at run-time rather than at
load-time. Rest assured, you can use MSVC and Visual Studio to do all these things.
Even though the code of the DLL is written in C++, we've used C-style interfaces for the
exported functions. There are two main reasons for this: First, many other languages
support imports of C-style functions. The client app doesn't have to be written in C++.
Second, it avoids some common pitfalls related to exported classes and member
functions. It's easy to make hard-to-diagnose errors when exporting classes, since
everything referred to within a class declaration has to have an instantiation that's also
exported. This restriction applies to DLLs, but not static libraries. If your classes are plain￾old-data style, you shouldn't run into this issue.
For links to more information about DLLs, see Create C/C++ DLLs in Visual Studio. For
more information about implicit linking and explicit linking, see Determine which linking
method to use. For information about creating C++ DLLs for use with programming
languages that use C-language linkage conventions, see Exporting C++ functions for
use in C-language executables. For information about how to create DLLs for use with
.NET languages, see Calling DLL Functions from Visual Basic Applications.
Prerequisites
A computer that runs Microsoft Windows 7 or later versions. We recommend the
latest version of Windows for the best development experience.
A copy of Visual Studio. For information on how to download and install Visual
Studio, see Install Visual Studio. When you run the installer, make sure that the
Desktop development with C++ workload is checked. Don't worry if you didn't
install this workload when you installed Visual Studio. You can run the installer
again and install it now.
An understanding of the basics of using the Visual Studio IDE. If you've used
Windows desktop apps before, you can probably keep up. For an introduction, see
Visual Studio IDE feature tour.
An understanding of enough of the fundamentals of the C++ language to follow
along. Don't worry, we don't do anything too complicated.
Create the DLL project
In this set of tasks, you create a project for your DLL, add code, and build it. To begin,
start the Visual Studio IDE, and sign in if you need to. The instructions vary slightly
depending on which version of Visual Studio you're using. Make sure you have the
correct version selected in the control in the upper left of this page.
To create a DLL project in Visual Studio 2019
1. On the menu bar, choose File > New > Project to open the Create a New Project
dialog box.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Library.
3. From the filtered list of project types, select Dynamic-link Library (DLL), and then
choose Next.
4. In the Configure your new project page, enter MathLibrary in the Project name
box to specify a name for the project. Leave the default Location and Solution
name values. Set Solution to Create new solution. Uncheck Place solution and
project in the same directory if it's checked.
5. Choose the Create button to create the project.
When the solution is created, you can see the generated project and source files in the
Solution Explorer window in Visual Studio.
Right now, this DLL doesn't do very much. Next, you'll create a header file to declare the
functions your DLL exports, and then add the function definitions to the DLL to make it
more useful.
To add a header file to the DLL
1. To create a header file for your functions, on the menu bar, choose Project > Add
New Item.
2. In the Add New Item dialog box, in the left pane, select Visual C++. In the center
pane, select Header File (.h). Specify MathLibrary.h as the name for the header file.
3. Choose the Add button to generate a blank header file, which is displayed in a new
editor window.
4. Replace the contents of the header file with this code:
C++
// MathLibrary.h - Contains declarations of math functions
#pragma once
#ifdef MATHLIBRARY_EXPORTS
#define MATHLIBRARY_API __declspec(dllexport)
#else
#define MATHLIBRARY_API __declspec(dllimport)
#endif
// The Fibonacci recurrence relation describes a sequence F
// where F(n) is { n = 0, a
// { n = 1, b
This header file declares some functions to produce a generalized Fibonacci sequence,
given two initial values. A call to fibonacci_init(1, 1) generates the familiar Fibonacci
number sequence.
Notice the preprocessor statements at the top of the file. The new project template for a
DLL project adds <PROJECTNAME>_EXPORTS to the defined preprocessor macros. In this
example, Visual Studio defines MATHLIBRARY_EXPORTS when your MathLibrary DLL project
is built.
When the MATHLIBRARY_EXPORTS macro is defined, the MATHLIBRARY_API macro sets the
__declspec(dllexport) modifier on the function declarations. This modifier tells the
compiler and linker to export a function or variable from the DLL for use by other
applications. When MATHLIBRARY_EXPORTS is undefined, for example, when the header file
is included by a client application, MATHLIBRARY_API applies the __declspec(dllimport)
modifier to the declarations. This modifier optimizes the import of the function or
variable in an application. For more information, see dllexport, dllimport.
1. In Solution Explorer, right-click on the Source Files node and choose Add > New
Item. Create a new .cpp file called MathLibrary.cpp, in the same way that you
added a new header file in the previous step.
// { n > 1, F(n-2) + F(n-1)
// for some initial integral values a and b.
// If the sequence is initialized F(0) = 1, F(1) = 1,
// then this relation produces the well-known Fibonacci
// sequence: 1, 1, 2, 3, 5, 8, 13, 21, 34, ...
// Initialize a Fibonacci relation sequence
// such that F(0) = a, F(1) = b.
// This function must be called before any other function.
extern "C" MATHLIBRARY_API void fibonacci_init(
 const unsigned long long a, const unsigned long long b);
// Produce the next value in the sequence.
// Returns true on success and updates current value and index;
// false on overflow, leaves current value and index unchanged.
extern "C" MATHLIBRARY_API bool fibonacci_next();
// Get the current value in the sequence.
extern "C" MATHLIBRARY_API unsigned long long fibonacci_current();
// Get the position of the current value in the sequence.
extern "C" MATHLIBRARY_API unsigned fibonacci_index();
To add an implementation to the DLL
2. In the editor window, select the tab for MathLibrary.cpp if it's already open. If not,
in Solution Explorer, double-click MathLibrary.cpp in the Source Files folder of the
MathLibrary project to open it.
3. In the editor, replace the contents of the MathLibrary.cpp file with the following
code:
C++
// MathLibrary.cpp : Defines the exported functions for the DLL.
#include "pch.h" // use stdafx.h in Visual Studio 2017 and earlier
#include <utility>
#include <limits.h>
#include "MathLibrary.h"
// DLL internal state variables:
static unsigned long long previous_; // Previous value, if any
static unsigned long long current_; // Current sequence value
static unsigned index_; // Current seq. position
// Initialize a Fibonacci relation sequence
// such that F(0) = a, F(1) = b.
// This function must be called before any other function.
void fibonacci_init(
 const unsigned long long a,
 const unsigned long long b)
{
 index_ = 0;
 current_ = a;
 previous_ = b; // see special case when initialized
}
// Produce the next value in the sequence.
// Returns true on success, false on overflow.
bool fibonacci_next()
{
 // check to see if we'd overflow result or position
 if ((ULLONG_MAX - previous_ < current_) ||
 (UINT_MAX == index_))
 {
 return false;
 }
 // Special case when index == 0, just return b value
 if (index_ > 0)
 {
 // otherwise, calculate next sequence value
 previous_ += current_;
 }
 std::swap(current_, previous_);
 ++index_;
 return true;
}
To verify that everything works so far, compile the dynamic link library. To compile,
choose Build > Build Solution on the menu bar. The DLL and related compiler output
are placed in a folder called Debug directly below the solution folder. If you create a
Release build, the output is placed in a folder called Release. The output should look
something like this:
Output
Congratulations, you've created a DLL using Visual Studio! Next, you'll create a client
app that uses the functions exported by the DLL.
When you create a DLL, think about how client apps may use it. To call the functions or
access the data exported by a DLL, client source code must have the declarations
available at compile time. At link time, the linker requires information to resolve the
function calls or data accesses. A DLL supplies this information in an import library, a file
that contains information about how to find the functions and data, instead of the actual
code. And at run time, the DLL must be available to the client, in a location that the
operating system can find.
// Get the current value in the sequence.
unsigned long long fibonacci_current()
{
 return current_;
}
// Get the current index position in the sequence.
unsigned fibonacci_index()
{
 return index_;
}
1>------ Build started: Project: MathLibrary, Configuration: Debug Win32 ---
---
1>pch.cpp
1>dllmain.cpp
1>MathLibrary.cpp
1>Generating Code...
1> Creating library
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.lib and object
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.exp
1>MathLibrary.vcxproj ->
C:\Users\username\Source\Repos\MathLibrary\Debug\MathLibrary.dll
========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========
Create a client app that uses the DLL
Whether it's your own or from a third-party, your client app project needs several pieces
of information to use a DLL. It needs to find the headers that declare the DLL exports,
the import libraries for the linker, and the DLL itself. One solution is to copy all of these
files into your client project. For third-party DLLs that are unlikely to change while your
client is in development, this method may be the best way to use them. However, when
you also build the DLL, it's better to avoid duplication. If you make a local copy of DLL
files that are under development, you may accidentally change a header file in one copy
but not the other, or use an out-of-date library.
To avoid out-of-sync code, we recommend you set the include path in your client
project to include the DLL header files directly from your DLL project. Also, set the
library path in your client project to include the DLL import libraries from the DLL
project. And finally, copy the built DLL from the DLL project into your client build output
directory. This step allows your client app to use the same DLL code you build.
To create a client app in Visual Studio
1. On the menu bar, choose File > New > Project to open the Create a new project
dialog box.
2. At the top of the dialog, set Language to C++, set Platform to Windows, and set
Project type to Console.
3. From the filtered list of project types, choose Console App then choose Next.
4. In the Configure your new project page, enter MathClient in the Project name box
to specify a name for the project. Leave the default Location and Solution name
values. Set Solution to Create new solution. Uncheck Place solution and project in
the same directory if it's checked.
5. Choose the Create button to create the client project.
A minimal console application project is created for you. The name for the main source
file is the same as the project name that you entered earlier. In this example, it's named
MathClient.cpp. You can build it, but it doesn't use your DLL yet.
Next, to call the MathLibrary functions in your source code, your project must include
the MathLibrary.h file. You could copy this header file into your client app project, then
add it to the project as an existing item. This method can be a good choice for third￾party libraries. However, if you're working on the code for your DLL and your client at
the same time, the header files could get out of sync. To avoid this issue, set the
Additional Include Directories path in your project to include the path to the original
header.
To add the DLL header to your include path
1. Right-click on the MathClient node in Solution Explorer to open the Property
Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it's not already
selected.
3. In the left pane, select Configuration Properties > C/C++ > General.
4. In the property pane, select the drop-down control next to the Additional Include
Directories edit box, and then choose Edit.
5. Double-click in the top pane of the Additional Include Directories dialog box to
enable an edit control. Or, choose the folder icon to create a new entry.
6. In the edit control, specify the path to the location of the MathLibrary.h header
file. You can choose the ellipsis (...) control to browse to the correct folder.
You can also enter a relative path from your client source files to the folder that
contains the DLL header files. If you followed the directions to put your client
project in a separate solution from the DLL, the relative path should look like this:
..\..\MathLibrary\MathLibrary
If your DLL and client projects are in the same solution, the relative path might
look like this:
..\MathLibrary
When the DLL and client projects are in other folders, adjust the relative path to
match. Or, use the ellipsis control to browse for the folder.
7. After you've entered the path to the header file in the Additional Include
Directories dialog box, choose the OK button. In the Property Pages dialog box,
choose the OK button to save your changes.
You can now include the MathLibrary.h file and use the functions it declares in your
client application. Replace the contents of MathClient.cpp by using this code:
C++
This code can be compiled, but not linked. If you build the client app now, the error list
shows several LNK2019 errors. That's because your project is missing some information:
You haven't specified that your project has a dependency on the MathLibrary.lib library
yet. And, you haven't told the linker how to find the MathLibrary.lib file.
To fix this issue, you could copy the library file directly into your client app project. The
linker would find and use it automatically. However, if both the library and the client app
are under development, that might lead to changes in one copy that aren't shown in the
other. To avoid this issue, you can set the Additional Dependencies property to tell the
build system that your project depends on MathLibrary.lib. And, you can set an
Additional Library Directories path in your project to include the path to the original
library when you link.
1. Right-click on the MathClient node in Solution Explorer and choose Properties to
open the Property Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it's not already
selected. It ensures that any property changes apply to both Debug and Release
builds.
3. In the left pane, select Configuration Properties > Linker > Input. In the property
pane, select the drop-down control next to the Additional Dependencies edit box,
and then choose Edit.
// MathClient.cpp : Client app for MathLibrary DLL.
// #include "pch.h" Uncomment for Visual Studio 2017 and earlier
#include <iostream>
#include "MathLibrary.h"
int main()
{
 // Initialize a Fibonacci relation sequence.
 fibonacci_init(1, 1);
 // Write out the sequence values until overflow.
 do {
 std::cout << fibonacci_index() << ": "
 << fibonacci_current() << std::endl;
 } while (fibonacci_next());
 // Report count of values written before overflow.
 std::cout << fibonacci_index() + 1 <<
 " Fibonacci sequence values fit in an " <<
 "unsigned 64-bit integer." << std::endl;
}
To add the DLL import library to your project
4. In the Additional Dependencies dialog, add MathLibrary.lib to the list in the top
edit control.
5. Choose OK to go back to the Property Pages dialog box.
6. In the left pane, select Configuration Properties > Linker > General. In the
property pane, select the drop-down control next to the Additional Library
Directories edit box, and then choose Edit.
7. Double-click in the top pane of the Additional Library Directories dialog box to
enable an edit control. In the edit control, specify the path to the location of the
MathLibrary.lib file. By default, it's in a folder called Debug directly under the DLL
solution folder. If you create a release build, the file is placed in a folder called
Release. You can use the $(IntDir) macro so that the linker can find your DLL, no
matter which kind of build you create. If you followed the directions to put your
client project in a separate solution from the DLL project, the relative path should
look like this:
..\..\MathLibrary\$(IntDir)
If your DLL and client projects are in other locations, adjust the relative path to
match.
8. Once you've entered the path to the library file in the Additional Library
Directories dialog box, choose the OK button to go back to the Property Pages
dialog box. Choose OK to save the property changes.
Your client app can now compile and link successfully, but it still doesn't have everything
it needs to run. When the operating system loads your app, it looks for the MathLibrary
DLL. If it can't find the DLL in certain system directories, the environment path, or the
local app directory, the load fails. Depending on the operating system, you'll see an
error message like this:
One way to avoid this issue is to copy the DLL to the directory that contains your client
executable as part of the build process. You can add a Post-Build Event to your project,
to add a command that copies the DLL to your build output directory. The command
specified here copies the DLL only if it's missing or has changed. It uses macros to copy
to and from the Debug or Release locations, based on your build configuration.
To copy the DLL in a post-build event
1. Right-click on the MathClient node in Solution Explorer and choose Properties to
open the Property Pages dialog.
2. In the Configuration drop-down box, select All Configurations if it isn't already
selected.
3. In the left pane, select Configuration Properties > Build Events > Post-Build
Event.
4. In the property pane, select the edit control in the Command Line field. If you
followed the directions to put your client project in a separate solution from the
DLL project, then enter this command:
xcopy /y /d "..\..\MathLibrary\$(IntDir)MathLibrary.dll" "$(OutDir)"
If your DLL and client projects are in other directories, change the relative path to
the DLL to match.
5. Choose the OK button to save your changes to the project properties.
Now your client app has everything it needs to build and run. Build the application by
choosing Build > Build Solution on the menu bar. The Output window in Visual Studio
should have something like the following example depending on your version of Visual
Studio:
Output
1>------ Build started: Project: MathClient, Configuration: Debug Win32 ----
--
1>MathClient.cpp
1>MathClient.vcxproj ->
C:\Users\username\Source\Repos\MathClient\Debug\MathClient.exe
1>1 File(s) copied
========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========
Congratulations, you've created an application that calls functions in your DLL. Now run
your application to see what it does. On the menu bar, choose Debug > Start Without
Debugging. Visual Studio opens a command window for the program to run in. The last
part of the output should look like:
Press any key to dismiss the command window.
Now that you've created a DLL and a client application, you can experiment. Try setting
breakpoints in the code of the client app, and run the app in the debugger. See what
happens when you step into a library call. Add other functions to the library, or write
another client app that uses your DLL.
When you deploy your app, you must also deploy the DLLs it uses. The simplest way to
make the DLLs that you build, or that you include from third parties, available is to put
them in the same directory as your app. It's known as app-local deployment. For more
information about deployment, see Deployment in Visual C++.
See also
Calling DLL Functions from Visual Basic Applications
Kinds of DLLs
Article • 08/03/2021
This topic provides information to help you determine the kind of DLL to build.
Different Kinds of DLLs Available
Using Visual Studio, you can build Win32 DLLs in C or C++ that do not use the Microsoft
Foundation Class (MFC) library. You can create a non-MFC DLL project with the Win32
Application Wizard.
The MFC library itself is available, in either static link libraries or in a number of DLLs,
with the MFC DLL Wizard. If your DLL is using MFC, Visual Studio supports three
different DLL development scenarios:
Building a regular MFC DLL that statically links MFC
Building a regular MFC DLL that dynamically links MFC
Building an MFC extension DLL, which always dynamically link MFC
What do you want to know more about?
Non-MFC DLLs: Overview
Regular MFC DLLs statically linked to MFC
Regular MFC DLLs dynamically linked to MFC
MFC extension DLLs: Overview
Which kind of DLL to use
Deciding Which Kind of DLL to Use
If your DLL does not use MFC, use Visual Studio to build a non-MFC Win32 DLL. Linking
your DLL to MFC (either statically or dynamically) takes up significant disk space and
memory. You should not link to MFC unless your DLL actually uses MFC.
If your DLL will be using MFC, and will be used by either MFC or non-MFC applications,
you must build either a regular MFC DLL that dynamically links to MFC or a regular MFC
DLL that statically links to MFC. In most cases, you probably want to use a regular MFC
DLL that dynamically links to MFC because the file size of the DLL will be much smaller
and the savings in memory from using the shared version of MFC can be significant. If
you statically link to MFC, the file size of your DLL will be larger and potentially take up
extra memory because it loads its own private copy of the MFC library code.
Building a DLL that dynamically links to MFC is faster than building a DLL that statically
links to MFC because it is not necessary to link MFC itself. This is especially true in
debug builds where the linker must compact the debug information. By linking with a
DLL that already contains the debug information, there is less debug information to
compact within your DLL.
One disadvantage to dynamically linking to MFC is that you must distribute the shared
DLLs Mfcx0.dll and Msvcrxx.dll (or similar files) with your DLL. The MFC DLLs are freely
redistributable, but you still must install the DLLs in your setup program. In addition, you
must ship the Msvcrxx.dll, which contains the C run-time library that is used both by
your program and the MFC DLLs themselves.
If your DLL will only be used by MFC executables, you have a choice between building a
regular MFC DLL or an MFC extension DLL. If your DLL implements reusable classes
derived from the existing MFC classes or you need to pass MFC-derived objects
between the application and the DLL, you must build an MFC extension DLL.
If your DLL dynamically links to MFC, the MFC DLLs might be redistributed with your
DLL. This architecture is particularly useful for sharing the class library between multiple
executable files to save disk space and minimize memory usage.
What do you want to know more about?
Non-MFC DLLs: Overview
Regular MFC DLLs statically linked to MFC
Regular MFC DLLs dynamically linked to MFC
MFC extension DLLs: Overview
See also
Create C/C++ DLLs in Visual Studio
Non-MFC DLLs: Overview
Article • 08/03/2021
A non-MFC DLL is a DLL that does not use MFC internally, and the exported functions in
the DLL can be called by either MFC or non-MFC executable files. Functions are usually
exported from a non-MFC DLL using the standard C interface.
For more information about non-MFC DLLs, see Dynamic-Link Libraries in the Windows
SDK.
What do you want to do?
Walkthrough: Creating and Using a Dynamic Link Library
Export from a DLL
Link an executable to a DLL
Initialize a DLL
What do you want to know more about?
Regular MFC DLLs statically linked to MFC
Regular MFC DLLs dynamically linked to MFC
MFC extension DLLs: Overview
See also
Kinds of DLLs
Regular MFC DLLs Statically Linked to
MFC
Article • 08/03/2021
A regular MFC DLL statically linked to MFC is a DLL that uses MFC internally, and the
exported functions in the DLL can be called by either MFC or non-MFC executables. As
the name describes, this kind of DLL is built using the static link library version of MFC.
Functions are usually exported from a regular MFC DLL using the standard C interface.
For an example of how to write, build, and use a regular MFC DLL, see the sample
DLLScreenCap .
Note that the term USRDLL is no longer used in the Visual C++ documentation. A
regular MFC DLL that is statically linked to MFC has the same characteristics as the
former USRDLL.
A regular MFC DLL, statically linked to MFC, has the following features:
The client executable can be written in any language that supports the use of DLLs
(C, C++, Pascal, Visual Basic, and so on); it does not have to be an MFC application.
The DLL can link to the same MFC static link libraries used by applications. There is
no longer a separate version of the static link libraries for DLLs.
Before version 4.0 of MFC, USRDLLs provided the same type of functionality as
regular MFC DLLs statically linked to MFC. As of Visual C++ version 4.0, the term
USRDLL is obsolete.
A regular MFC DLL, statically linked to MFC, has the following requirements:
This type of DLL must instantiate a class derived from CWinApp .
This type of DLL uses the DllMain provided by MFC. Place all DLL-specific
initialization code in the InitInstance member function and termination code in
ExitInstance as in a normal MFC application.
Even though the term USRDLL is obsolete, you must still define "_USRDLL" on the
compiler command line. This definition determines which declarations is pulled in
from the MFC header files.
regular MFC DLLs must have a CWinApp -derived class and a single object of that
application class, as does an MFC application. However, the CWinApp object of the DLL
does not have a main message pump, as does the CWinApp object of an application.
Note that the CWinApp::Run mechanism does not apply to a DLL, because the
application owns the main message pump. If the DLL opens modeless dialogs or has a
main frame window of its own, the application's main message pump must call a routine
exported by the DLL that in turn calls the CWinApp::PreTranslateMessage member
function of the DLL's application object.
For an example of this function, see the DLLScreenCap sample.
Symbols are usually exported from a regular MFC DLL using the standard C interface.
The declaration of a function exported from a regular MFC DLL would look something
like this:
extern "C" __declspec(dllexport) MyExportedFunction( );
All memory allocations within a regular MFC DLL should stay within the DLL; the DLL
should not pass to or receive from the calling executable any of the following:
Pointers to MFC objects
Pointers to memory allocated by MFC
If you need to do any of the above or need to pass MFC-derived objects between the
calling executable and the DLL, you must build an MFC extension DLL.
It is safe to pass pointers to memory that were allocated by the C run-time libraries
between an application and a DLL only if you make a copy of the data. You must not
delete or resize these pointers or use them without making a copy of the memory.
A DLL that is statically linked to MFC cannot also dynamically link to the shared MFC
DLLs. A DLL that is statically linked to MFC is dynamically bound to an application just
like any other DLL; applications link to it just like any other DLL.
The standard MFC static link libraries are named according to the convention described
in Naming Conventions for MFC DLLs. However, with MFC version 3.0 and later, it is no
longer necessary to manually specify to the linker the version of the MFC library you
want linked in. Instead, the MFC header files automatically determine the correct version
of the MFC library to link in based on preprocessor defines, such as _DEBUG or
_UNICODE. The MFC header files add /DEFAULTLIB directives instructing the linker to
link in a specific version of the MFC library.
What do you want to do?
Initialize regular MFC DLLs
What do you want to know more about?
Using MFC as Part of a DLL
Using Database, OLE, and Sockets MFC extension DLLs in regular MFC DLLs
Creating an MFC DLL
Regular MFC DLLs Dynamically Linked to MFC
MFC extension DLLs
See also
Kinds of DLLs
Regular MFC DLLs Dynamically Linked
to MFC
Article • 08/03/2021
A regular MFC DLL dynamically linked to MFC is a DLL that uses MFC internally, and the
exported functions in the DLL can be called by either MFC or non-MFC executables. As
the name describes, this kind of DLL is built using the dynamic-link library version of
MFC (also known as the shared version of MFC). Functions are usually exported from a
regular MFC DLL using the standard C interface.
You must add the AFX_MANAGE_STATE macro at the beginning of all the exported
functions in regular MFC DLLs that dynamically link to MFC to set the current module
state to the one for the DLL. This is done by adding the following line of code to the
beginning of functions exported from the DLL:
AFX_MANAGE_STATE(AfxGetStaticModuleState( ))
A regular MFC DLL, dynamically linked to MFC has the following features:
This is a new type of DLL introduced by Visual C++ 4.0.
The client executable can be written in any language that supports the use of DLLs
(C, C++, Pascal, Visual Basic, and so on); it does not have to be an MFC application.
Unlike the statically linked regular MFC DLL, this type of DLL is dynamically linked
to the MFC DLL (also known as the shared MFC DLL).
The MFC import library linked to this type of DLL is the same one used for MFC
extension DLLs or applications using the MFC DLL: MFCxx(D).lib.
A regular MFC DLL, dynamically linked to MFC has the following requirements:
These DLLs are compiled with _AFXDLL defined, just like an executable that is
dynamically linked to the MFC DLL. But _USRDLL is also defined, just like a regular
MFC DLL that is statically linked to MFC.
This type of DLL must instantiate a CWinApp -derived class.
This type of DLL uses the DllMain provided by MFC. Place all DLL-specific
initialization code in the InitInstance member function and termination code in
ExitInstance as in a normal MFC application.
Because this kind of DLL uses the dynamic-link library version of MFC, you must
explicitly set the current module state to the one for the DLL. To do this, use the
AFX_MANAGE_STATE macro at the beginning of every function exported from the DLL.
regular MFC DLLs must have a CWinApp -derived class and a single object of that
application class, as does an MFC application. However, the CWinApp object of the DLL
does not have a main message pump, as does the CWinApp object of an application.
Note that the CWinApp::Run mechanism does not apply to a DLL, because the
application owns the main message pump. If your DLL brings up modeless dialogs or
has a main frame window of its own, your application's main message pump must call a
DLL-exported routine that calls CWinApp::PreTranslateMessage .
Place all DLL-specific initialization in the CWinApp::InitInstance member function as in a
normal MFC application. The CWinApp::ExitInstance member function of your CWinApp
derived class is called from the MFC provided DllMain function before the DLL is
unloaded.
You must distribute the shared DLLs MFCx0.dll and Msvcr*0.dll (or similar files) with your
application.
A DLL that is dynamically linked to MFC cannot also statically link to MFC. Applications
link to regular MFC DLLs dynamically linked to MFC it just like any other DLL.
Symbols are usually exported from a regular MFC DLL using the standard C interface.
The declaration of a function exported from a regular MFC DLL looks something like
this:
extern "C" __declspec(dllexport) MyExportedFunction( );
All memory allocations within a regular MFC DLL should stay within the DLL; the DLL
should not pass to or receive from the calling executable any of the following:
pointers to MFC objects
pointers to memory allocated by MFC
If you need to do any of the above, or if you need to pass MFC-derived objects between
the calling executable and the DLL, then you must build an MFC extension DLL.
It is safe to pass pointers to memory that were allocated by the C run-time libraries
between an application and a DLL only if you make a copy of the data. You must not
delete or resize these pointers or use them without making a copy of the memory.
When building a regular MFC DLL that dynamically links to MFC, you need to use the
macro AFX_MANAGE_STATE to switch the MFC module state correctly. This is done by
adding the following line of code to the beginning of functions exported from the DLL:
AFX_MANAGE_STATE(AfxGetStaticModuleState( ))
The AFX_MANAGE_STATE macro should not be used in regular MFC DLLs that statically
link to MFC or in MFC extension DLLs. For more information, see Managing the State
Data of MFC Modules.
For an example of how to write, build, and use a regular MFC DLL, see the sample
DLLScreenCap . For more information about regular MFC DLLs that dynamically link to
MFC, see the section titled "Converting DLLScreenCap to Dynamically Link with the MFC
DLL" in the abstract for the sample.
What do you want to do?
Initialize regular MFC DLLs
What do you want to know more about?
The module states of a regular MFC DLL dynamically linked to MFC
Managing the state data of MFC modules
Using Database, OLE, and Sockets MFC extension DLLs in regular MFC DLLs
Using MFC as Part of a DLL
See also
Kinds of DLLs
MFC extension DLLs: Overview
Article • 08/03/2021
An MFC extension DLL is a DLL that typically implements reusable classes derived from
existing Microsoft Foundation Class Library classes. MFC extension DLLs are built using
the dynamic-link library version of MFC (also known as the shared version of MFC). Only
MFC executables (either applications or regular MFC DLLs) that are built with the shared
version of MFC can use an MFC extension DLL. With an MFC extension DLL, you can
derive new custom classes from MFC and then offer this extended version of MFC to
applications that call your DLL.
Extension DLLs can also be used for passing MFC-derived objects between the
application and the DLL. The member functions associated with the passed object exist
in the module where the object was created. Because these functions are properly
exported when using the shared DLL version of MFC, you can freely pass MFC or MFC￾derived object pointers between an application and the MFC extension DLLs it loads.
For an example of a DLL that fulfills the basic requirements of an MFC extension DLL,
see the MFC sample DLLHUSK . In particular, look at the Testdll1.cpp and Testdll2.cpp
files.
What do you want to do?
Initialize an MFC extension DLL
What do you want to know more about?
MFC extension DLLs
Using Database, OLE, and Sockets MFC extension DLLs in regular MFC DLLs
Non-MFC DLLs: Overview
Regular MFC DLLs statically linked to MFC
Regular MFC DLLs dynamically linked to MFC
Creating an MFC DLL
See also
Kinds of DLLs
DLL frequently asked questions
FAQ
Can an MFC DLL create multiple
threads?
Except during initialization, an MFC DLL can safely create multiple threads as long as it
uses the Win32 thread local storage (TLS) functions such as TlsAlloc to allocate thread
local storage. However, if an MFC DLL uses __declspec(thread) to allocate thread local
storage, the client application must be implicitly linked to the DLL. If the client
application explicitly links to the DLL, the call to LoadLibrary will not successfully load
the DLL. For more information about thread-local variables in DLLs, see thread.
An MFC DLL that creates a new MFC thread during startup will stop responding when it
is loaded by an application. This includes whenever a thread is created by calling
AfxBeginThread or CWinThread::CreateThread inside:
The InitInstance of a CWinApp -derived object in a regular MFC DLL.
A supplied DllMain or RawDllMain function in a regular MFC DLL.
A supplied DllMain or RawDllMain function in an MFC extension DLL.
Can a multithreaded application access
an MFC DLL in different threads?
Multithreaded applications can access regular MFC DLLs that dynamically link to MFC
and MFC extension DLLs from different threads. An application can access regular MFC
DLLs that statically link to MFC from multiple threads created in the application.
Are there any MFC classes or functions
that cannot be used in an MFC DLL?
Extension DLLs use the CWinApp -derived class of the client application. They must not
have their own CWinApp -derived class.
Regular MFC DLLs must have a CWinApp -derived class and a single object of that
application class, as does an MFC application. Unlike the CWinApp object of an
application, the CWinApp object of the DLL does not have a main message pump.
Note that because the CWinApp::Run mechanism does not apply to a DLL, the
application owns the main message pump. If the DLL opens modeless dialog boxes or
has a main frame window of its own, the application's main message pump must call a
routine exported by the DLL, which in turn calls the CWinApp::PreTranslateMessage
member function of the DLL's application object.
What optimization techniques should I
use to improve the client application's
performance when loading?
If your DLL is a regular MFC DLL that is statically linked to MFC, changing it to a regular
MFC DLL that is dynamically linked to MFC reduces the file size.
If the DLL has a large number of exported functions, use a .def file to export the
functions (instead of using __declspec(dllexport) ) and use the .def file NONAME
attribute on each exported function. The NONAME attribute causes only the ordinal
value and not the function name to be stored in the DLL's export table, which reduces
the file size.
DLLs that are implicitly linked to an application are loaded when the application loads.
To improve the performance when loading, try dividing the DLL into different DLLs. Put
all the functions that the calling application needs immediately after loading into one
DLL and have the calling application implicitly link to that DLL. Put the other functions
that the calling application does not need right away into another DLL and have the
application explicitly link to that DLL. For more information, see Link an executable to a
DLL.
There's a memory leak in my regular
MFC DLL, but my code looks fine. How
can I find the memory leak?
One possible cause of the memory leak is that MFC creates temporary objects that are
used inside message handler functions. In MFC applications, these temporary objects
are automatically cleaned up in the CWinApp::OnIdle() function that is called in between
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
processing messages. However, in MFC dynamic-link libraries (DLLs), the OnIdle()
function is not automatically called. As a result, temporary objects are not automatically
cleaned up. To clean up temporary objects, the DLL must explicitly call OnIdle(1)
periodically.
Create C/C++ DLLs in Visual Studio
See also
 Yes  No
Link an executable to a DLL
Article • 08/03/2021
An executable file links to (or loads) a DLL in one of two ways:
Implicit linking, where the operating system loads the DLL at the same time as the
executable that uses it. The client executable calls the exported functions of the
DLL the same way as if the functions were statically linked and contained within
the executable. Implicit linking is sometimes referred to as static load or load-time
dynamic linking.
Explicit linking, where the operating system loads the DLL on demand at runtime.
An executable that uses a DLL by explicit linking must explicitly load and unload
the DLL. It must also set up a function pointer to access each function it uses from
the DLL. Unlike calls to functions in a statically linked library or an implicitly linked
DLL, the client executable must call the exported functions in an explicitly linked
DLL through function pointers. Explicit linking is sometimes referred to as dynamic
load or run-time dynamic linking.
An executable can use either linking method to link to the same DLL. Furthermore, these
methods aren't mutually exclusive; one executable may implicitly link to a DLL, and
another might attach to it explicitly.
Determine which linking method to use
Whether to use implicit linking or explicit linking is an architectural decision you must
make for your application. There are advantages and disadvantages to each method.
Implicit Linking
Implicit linking occurs when an application's code calls an exported DLL function. When
the source code for the calling executable is compiled or assembled, the DLL function
call generates an external function reference in the object code. To resolve this external
reference, the application must link with the import library (.lib file) provided by the
maker of the DLL.
The import library only contains code to load the DLL and to implement calls to
functions in the DLL. Finding an external function in an import library informs the linker
that the code for that function is in a DLL. To resolve external references to DLLs, the
linker simply adds information to the executable file that tells the system where to find
the DLL code when the process starts up.
When the system starts a program that contains dynamically linked references, it uses
the information in the program's executable file to locate the required DLLs. If it can't
locate the DLL, the system terminates the process, and displays a dialog box that reports
the error. Otherwise, the system maps the DLL modules into the process address space.
If any of the DLLs has an entry-point function for initialization and termination code
such as DllMain , the operating system calls the function. One of the parameters passed
to the entry-point function specifies a code that indicates the DLL is attaching to the
process. If the entry-point function doesn't return TRUE, the system terminates the
process and reports the error.
Finally, the system modifies the executable code of the process to provide starting
addresses for the DLL functions.
Like the rest of a program's code, the loader maps DLL code into the address space of
the process when the process starts up. The operating system loads it into memory only
when needed. As a result, the PRELOAD and LOADONCALL code attributes used by .def files
to control loading in previous versions of Windows no longer have meaning.
Explicit Linking
Most applications use implicit linking because it's the easiest linking method to use.
However, there are times when explicit linking is necessary. Here are some common
reasons to use explicit linking:
The application doesn't know the name of a DLL that it loads until run time. For
example, the application might obtain the name of the DLL and the exported
functions from a configuration file at startup.
A process that uses implicit linking is terminated by the operating system if the
DLL isn't found at process startup. A process that uses explicit linking isn't
terminated in this situation, and can attempt to recover from the error. For
example, the process could notify the user of the error and have the user specify
another path to the DLL.
A process that uses implicit linking is also terminated if any of the DLLs it's linked
to have a DllMain function that fails. A process that uses explicit linking isn't
terminated in this situation.
An application that implicitly links to many DLLs can be slow to start because
Windows loads all the DLLs when the application loads. To improve startup
performance, an application might only use implicit linking for DLLs required
immediately after loading. It might use explicit linking to load other DLLs only
when they're needed.
Explicit linking eliminates the need to link the application by using an import
library. If changes in the DLL cause the export ordinals to change, applications
don't have to relink if they call GetProcAddress using the name of a function and
not an ordinal value. Applications that use implicit linking must still relink to the
changed import library.
Here are two hazards of explicit linking to be aware of:
If the DLL has a DllMain entry point function, the operating system calls the
function in the context of the thread that called LoadLibrary . The entry-point
function isn't called if the DLL is already attached to the process because of a
previous call to LoadLibrary that has had no corresponding call to the
FreeLibrary function. Explicit linking can cause problems if the DLL uses a DllMain
function to initialize each thread of a process, because any threads that already
exist when LoadLibrary (or AfxLoadLibrary ) is called aren't initialized.
If a DLL declares static-extent data as __declspec(thread) , it can cause a
protection fault if explicitly linked. After the DLL is loaded by a call to LoadLibrary ,
it causes a protection fault whenever the code references this data. (Static-extent
data includes both global and local static items.) That's why, when you create a
DLL, you should avoid using thread-local storage. If you can't, then inform your
DLL users about the potential pitfalls of dynamically loading your DLL. For more
information, see Using thread local storage in a dynamic-link library (Windows
SDK).
How to use implicit linking
To use a DLL by implicit linking, client executables must obtain these files from the
provider of the DLL:
One or more header files (.h files) that contain the declarations of the exported
data, functions, and C++ classes in the DLL. The classes, functions, and data
exported by the DLL must all be marked __declspec(dllimport) in the header file.
For more information, see dllexport, dllimport.
An import library to link into your executable. The linker creates the import library
when the DLL is built. For more information, see LIB files as linker input.
The actual DLL file.
To use the data, functions, and classes in a DLL by implicit linking, any client source file
must include the header files that declare them. From a coding perspective, calls to the
exported functions are just like any other function call.
To build the client executable file, you must link with the DLL's import library. If you use
an external makefile or build system, specify the import library together with the other
object files or libraries that you link.
The operating system must be able to locate the DLL file when it loads the calling
executable. That means you must either deploy or verify the existence of the DLL when
you install your application.
To use a DLL by explicit linking, applications must make a function call to explicitly load
the DLL at run time. To explicitly link to a DLL, an application must:
Call LoadLibraryEx or a similar function to load the DLL and obtain a module
handle.
Call GetProcAddress to obtain a function pointer to each exported function that
the application calls. Because applications call the DLL functions through a pointer,
the compiler doesn't generate external references, so there's no need to link with
an import library. However, you must have a typedef or using statement that
defines the call signature of the exported functions that you call.
Call FreeLibrary when done with the DLL.
For example, this sample function calls LoadLibrary to load a DLL named "MyDLL", calls
GetProcAddress to obtain a pointer to a function named "DLLFunc1", calls the function
and saves the result, and then calls FreeLibrary to unload the DLL.
C
How to link explicitly to a DLL
#include "windows.h"
typedef HRESULT (CALLBACK* LPFNDLLFUNC1)(DWORD,UINT*);
HRESULT LoadAndCallSomeFunction(DWORD dwParam1, UINT * puParam2)
{
 HINSTANCE hDLL; // Handle to DLL
 LPFNDLLFUNC1 lpfnDllFunc1; // Function pointer
 HRESULT hrReturnVal;
 hDLL = LoadLibrary("MyDLL");
 if (NULL != hDLL)
Unlike this example, in most cases you should call LoadLibrary and FreeLibrary only
once in your application for a given DLL. It's especially true if you're going to call
multiple functions in the DLL, or call DLL functions repeatedly.
Working with Import Libraries and Export Files
Dynamic-Link Library Search Order
Create C/C++ DLLs in Visual Studio
 {
 lpfnDllFunc1 = (LPFNDLLFUNC1)GetProcAddress(hDLL, "DLLFunc1");
 if (NULL != lpfnDllFunc1)
 {
 // call the function
 hrReturnVal = lpfnDllFunc1(dwParam1, puParam2);
 }
 else
 {
 // report the error
 hrReturnVal = ERROR_DELAY_LOAD_FAILED;
 }
 FreeLibrary(hDLL);
 }
 else
 {
 hrReturnVal = ERROR_DELAY_LOAD_FAILED;
 }
 return hrReturnVal;
}
What do you want to know more about?
See also
DLLs and Visual C++ run-time library
behavior
Article • 03/02/2022
When you build a Dynamic-link Library (DLL) by using Visual Studio, by default, the
linker includes the Visual C++ run-time library (VCRuntime). The VCRuntime contains
code required to initialize and terminate a C/C++ executable. When linked into a DLL,
the VCRuntime code provides an internal DLL entry-point function called
_DllMainCRTStartup that handles Windows OS messages to the DLL to attach to or
detach from a process or thread. The _DllMainCRTStartup function performs essential
tasks such as stack buffer security set up, C run-time library (CRT) initialization and
termination, and calls to constructors and destructors for static and global objects.
_DllMainCRTStartup also calls hook functions for other libraries such as WinRT, MFC, and
ATL to perform their own initialization and termination. Without this initialization, the
CRT and other libraries, as well as your static variables, would be left in an uninitialized
state. The same VCRuntime internal initialization and termination routines are called
whether your DLL uses a statically linked CRT or a dynamically linked CRT DLL.
Default DLL entry point _DllMainCRTStartup
In Windows, all DLLs can contain an optional entry-point function, usually called
DllMain , that is called for both initialization and termination. This gives you an
opportunity to allocate or release additional resources as needed. Windows calls the
entry-point function in four situations: process attach, process detach, thread attach,
and thread detach. When a DLL is loaded into a process address space, either when an
application that uses it is loaded, or when the application requests the DLL at runtime,
the operating system creates a separate copy of the DLL data. This is called process
attach. Thread attach occurs when the process the DLL is loaded in creates a new thread.
Thread detach occurs when the thread terminates, and process detach is when the DLL is
no longer required and is released by an application. The operating system makes a
separate call to the DLL entry point for each of these events, passing a reason argument
for each event type. For example, the OS sends DLL_PROCESS_ATTACH as the reason
argument to signal process attach.
The VCRuntime library provides an entry-point function called _DllMainCRTStartup to
handle default initialization and termination operations. On process attach, the
_DllMainCRTStartup function sets up buffer security checks, initializes the CRT and other
libraries, initializes run-time type information, initializes and calls constructors for static
and non-local data, initializes thread-local storage, increments an internal static counter
for each attach, and then calls a user- or library-supplied DllMain . On process detach,
the function goes through these steps in reverse. It calls DllMain , decrements the
internal counter, calls destructors, calls CRT termination functions and registered atexit
functions, and notifies any other libraries of termination. When the attachment counter
goes to zero, the function returns FALSE to indicate to Windows that the DLL can be
unloaded. The _DllMainCRTStartup function is also called during thread attach and
thread detach. In these cases, the VCRuntime code does no additional initialization or
termination on its own, and just calls DllMain to pass the message along. If DllMain
returns FALSE from process attach, signaling failure, _DllMainCRTStartup calls DllMain
again and passes DLL_PROCESS_DETACH as the reason argument, then goes through the
rest of the termination process.
When building DLLs in Visual Studio, the default entry point _DllMainCRTStartup
supplied by VCRuntime is linked in automatically. You do not need to specify an entry￾point function for your DLL by using the /ENTRY (Entry point symbol) linker option.
７ Note
While it is possible to specify another entry-point function for a DLL by using the
/ENTRY: linker option, we do not recommend it, because your entry-point function
would have to duplicate everything that _DllMainCRTStartup does, in the same
order. The VCRuntime provides functions that allow you to duplicate its behavior.
For example, you can call __security_init_cookie immediately on process attach to
support the /GS (Buffer security check) buffer checking option. You can call the
_CRT_INIT function, passing the same parameters as the entry point function, to
perform the rest of the DLL initialization or termination functions.
Initialize a DLL
Your DLL may have initialization code that must execute when your DLL loads. In order
for you to perform your own DLL initialization and termination functions,
_DllMainCRTStartup calls a function called DllMain that you can provide. Your DllMain
must have the signature required for a DLL entry point. The default entry point function
_DllMainCRTStartup calls DllMain using the same parameters passed by Windows. By
default, if you do not provide a DllMain function, Visual Studio provides one for you
and links it in so that _DllMainCRTStartup always has something to call. This means that
if you do not need to initialize your DLL, there is nothing special you have to do when
building your DLL.
This is the signature used for DllMain :
C++
Some libraries wrap the DllMain function for you. For example, in a regular MFC DLL,
implement the CWinApp object's InitInstance and ExitInstance member functions to
perform initialization and termination required by your DLL. For more details, see the
Initialize regular MFC DLLs section.
To perform your own initialization in ordinary (non-MFC) DLLs that use the VCRuntime￾supplied _DllMainCRTStartup entry point, your DLL source code must contain a function
called DllMain . The following code presents a basic skeleton showing what the
definition of DllMain might look like:
C++
#include <windows.h>
extern "C" BOOL WINAPI DllMain (
 HINSTANCE const instance, // handle to DLL module
 DWORD const reason, // reason for calling function
 LPVOID const reserved); // reserved
２ Warning
There are significant limits on what you can safely do in a DLL entry point. For more
information about specific Windows APIs that are unsafe to call in DllMain , see
General Best Practices. If you need anything but the simplest initialization then do
that in an initialization function for the DLL. You can require applications to call the
initialization function after DllMain has run and before they call any other functions
in the DLL.
Initialize ordinary (non-MFC) DLLs
#include <windows.h>
extern "C" BOOL WINAPI DllMain (
 HINSTANCE const instance, // handle to DLL module
 DWORD const reason, // reason for calling function
 LPVOID const reserved) // reserved
{
 // Perform actions based on the reason for calling.
 switch (reason)
 {
Because regular MFC DLLs have a CWinApp object, they should perform their
initialization and termination tasks in the same location as an MFC application: in the
InitInstance and ExitInstance member functions of the DLL's CWinApp -derived class.
Because MFC provides a DllMain function that is called by _DllMainCRTStartup for
DLL_PROCESS_ATTACH and DLL_PROCESS_DETACH , you should not write your own DllMain
function. The MFC-provided DllMain function calls InitInstance when your DLL is
loaded and it calls ExitInstance before the DLL is unloaded.
A regular MFC DLL can keep track of multiple threads by calling TlsAlloc and TlsGetValue
in its InitInstance function. These functions allow the DLL to track thread-specific data.
 case DLL_PROCESS_ATTACH:
 // Initialize once for each new process.
 // Return FALSE to fail DLL load.
 break;
 case DLL_THREAD_ATTACH:
 // Do thread-specific initialization.
 break;
 case DLL_THREAD_DETACH:
 // Do thread-specific cleanup.
 break;
 case DLL_PROCESS_DETACH:
 // Perform any necessary cleanup.
 break;
 }
 return TRUE; // Successful DLL_PROCESS_ATTACH.
}
７ Note
Older Windows SDK documentation says that the actual name of the DLL entry￾point function must be specified on the linker command-line with the /ENTRY
option. With Visual Studio, you do not need to use the /ENTRY option if the name
of your entry-point function is DllMain . In fact, if you use the /ENTRY option and
name your entry-point function something other than DllMain , the CRT does not
get initialized properly unless your entry-point function makes the same
initialization calls that _DllMainCRTStartup makes.
Initialize regular MFC DLLs
In your regular MFC DLL that dynamically links to MFC, if you are using any MFC OLE,
MFC Database (or DAO), or MFC Sockets support, respectively, the debug MFC
extension DLLs MFCOversionD.dll, MFCDversionD.dll, and MFCNversionD.dll (where
version is the version number) are linked in automatically. You must call one of the
following predefined initialization functions for each of these DLLs that you are using in
your regular MFC DLL's CWinApp::InitInstance .
Type of MFC support Initialization function to call
MFC OLE (MFCOversionD.dll) AfxOleInitModule
MFC Database (MFCDversionD.dll) AfxDbInitModule
MFC Sockets (MFCNversionD.dll) AfxNetInitModule
Because MFC extension DLLs do not have a CWinApp -derived object (as do regular MFC
DLLs), you should add your initialization and termination code to the DllMain function
that the MFC DLL Wizard generates.
The wizard provides the following code for MFC extension DLLs. In the code, PROJNAME is
a placeholder for the name of your project.
C++
Initialize MFC extension DLLs
#include "pch.h" // For Visual Studio 2017 and earlier, use "stdafx.h"
#include <afxdllx.h>
#ifdef _DEBUG
#define new DEBUG_NEW
#undef THIS_FILE
static char THIS_FILE[] = __FILE__;
#endif
static AFX_EXTENSION_MODULE PROJNAMEDLL;
extern "C" int APIENTRY
DllMain(HINSTANCE hInstance, DWORD dwReason, LPVOID lpReserved)
{
 if (dwReason == DLL_PROCESS_ATTACH)
 {
 TRACE0("PROJNAME.DLL Initializing!\n");
 // MFC extension DLL one-time initialization
 AfxInitExtensionModule(PROJNAMEDLL,
 hInstance);
 // Insert this DLL into the resource chain
Creating a new CDynLinkLibrary object during initialization allows the MFC extension
DLL to export CRuntimeClass objects or resources to the client application.
If you are going to use your MFC extension DLL from one or more regular MFC DLLs,
you must export an initialization function that creates a CDynLinkLibrary object. That
function must be called from each of the regular MFC DLLs that use the MFC extension
DLL. An appropriate place to call this initialization function is in the InitInstance
member function of the regular MFC DLL's CWinApp -derived object before using any of
the MFC extension DLL's exported classes or functions.
In the DllMain that the MFC DLL Wizard generates, the call to AfxInitExtensionModule
captures the module's run-time classes ( CRuntimeClass structures) as well as its object
factories ( COleObjectFactory objects) for use when the CDynLinkLibrary object is
created. You should check the return value of AfxInitExtensionModule ; if a zero value is
returned from AfxInitExtensionModule , return zero from your DllMain function.
If your MFC extension DLL will be explicitly linked to an executable (meaning the
executable calls AfxLoadLibrary to link to the DLL), you should add a call to
AfxTermExtensionModule on DLL_PROCESS_DETACH . This function allows MFC to clean up
the MFC extension DLL when each process detaches from the MFC extension DLL (which
happens when the process exits or when the DLL is unloaded as a result of a
AfxFreeLibrary call). If your MFC extension DLL will be linked implicitly to the
application, the call to AfxTermExtensionModule is not necessary.
Applications that explicitly link to MFC extension DLLs must call AfxTermExtensionModule
when freeing the DLL. They should also use AfxLoadLibrary and AfxFreeLibrary
(instead of the Win32 functions LoadLibrary and FreeLibrary ) if the application uses
multiple threads. Using AfxLoadLibrary and AfxFreeLibrary ensures that the startup
and shutdown code that executes when the MFC extension DLL is loaded and unloaded
does not corrupt the global MFC state.
Because the MFCx0.dll is fully initialized by the time DllMain is called, you can allocate
memory and call MFC functions within DllMain (unlike the 16-bit version of MFC).
 new CDynLinkLibrary(Dll3DLL);
 }
 else if (dwReason == DLL_PROCESS_DETACH)
 {
 TRACE0("PROJNAME.DLL Terminating!\n");
 }
 return 1; // ok
}
Extension DLLs can take care of multithreading by handling the DLL_THREAD_ATTACH and
DLL_THREAD_DETACH cases in the DllMain function. These cases are passed to DllMain
when threads attach and detach from the DLL. Calling TlsAlloc when a DLL is attaching
allows the DLL to maintain thread local storage (TLS) indexes for every thread attached
to the DLL.
Note that the header file Afxdllx.h contains special definitions for structures used in MFC
extension DLLs, such as the definition for AFX_EXTENSION_MODULE and CDynLinkLibrary .
You should include this header file in your MFC extension DLL.
７ Note
It is important that you neither define nor undefine any of the _AFX_NO_XXX macros
in pch.h (stdafx.h in Visual Studio 2017 and earlier). These macros exist only for the
purpose of checking whether a particular target platform supports that feature or
not. You can write your program to check these macros (for example, #ifndef
_AFX_NO_OLE_SUPPORT ), but your program should never define or undefine these
macros.
A sample initialization function that handles multithreading is included in Using Thread
Local Storage in a Dynamic-Link Library in the Windows SDK. Note that the sample
contains an entry-point function called LibMain , but you should name this function
DllMain so that it works with the MFC and C run-time libraries.
See also
Create C/C++ DLLs in Visual Studio
DllMain entry point
Dynamic-link Library Best Practices
LoadLibrary and AfxLoadLibrary
Article • 08/03/2021
Processes call LoadLibrary or LoadLibraryEx to explicitly link to a DLL. (MFC apps use
AfxLoadLibrary or AfxLoadLibraryEx.) If the function succeeds, it maps the specified DLL
into the address space of the calling process, and returns a handle to the DLL. The
handle is required in other functions used for explicit linking—for example,
GetProcAddress and FreeLibrary . For more information, see Explicit linking.
LoadLibrary attempts to locate the DLL by using the same search sequence that is used
for implicit linking. LoadLibraryEx gives you more control over the search path order.
For more information, see Dynamic Link Library Search Order. If the system can't find
the DLL or if the entry-point function returns FALSE, LoadLibrary returns NULL. If the
call to LoadLibrary specifies a DLL module that is already mapped into the address
space of the calling process, the function returns a handle of the DLL and increments the
reference count of the module.
If the DLL has an entry-point function, the operating system calls the function in the
context of the thread that called LoadLibrary or LoadLibraryEx . The entry-point
function isn't called if the DLL is already attached to the process. That happens when a
previous call to LoadLibrary or LoadLibraryEx for the DLL hasn't had a corresponding
call to the FreeLibrary function.
For MFC applications that load MFC extension DLLs, we recommend that you use
AfxLoadLibrary or AfxLoadLibraryEx instead of LoadLibrary or LoadLibraryEx . The MFC
functions handle thread synchronization before loading the DLL explicitly. The interfaces
(function prototypes) to AfxLoadLibrary and AfxLoadLibraryEx are the same as
LoadLibrary and LoadLibraryEx .
If Windows can't load the DLL, your process can attempt to recover from the error. For
example, it could notify the user of the error, then ask for another path to the DLL.
） Important
Make sure to specify the full path of any DLLs. The current directory may be
searched first when files are loaded by LoadLibrary . If you don't fully qualify the
path of the file, a file other than the intended one might be loaded. When you
create a DLL, use the /DEPENDENTLOADFLAG linker option to specify a search
order for statically linked DLL dependencies. Within your DLLs, use both complete
paths to explicitly loaded dependencies, and LoadLibraryEx or AfxLoadLibraryEx
call parameters to specify module search order. For more information, see
Dynamic-Link Library Security and Dynamic Link Library Search Order.
What do you want to do?
Link an executable to a DLL
Link an executable to a DLL
What do you want to know more about?
Dynamic-Link Library Search Order
FreeLibrary and AfxFreeLibrary
GetProcAddress
See also
Create C/C++ DLLs in Visual Studio
GetProcAddress
Article • 08/03/2021
Processes explicitly linking to a DLL call GetProcAddress to obtain the address of an
exported function in the DLL. You use the returned function pointer to call the DLL
function. GetProcAddress takes as parameters the DLL module handle (returned by
either LoadLibrary, AfxLoadLibrary , or GetModuleHandle) and takes either the name of
the function you want to call or the function's export ordinal.
Because you are calling the DLL function through a pointer and there is no compile-time
type checking, make sure that the parameters to the function are correct so that you do
not overstep the memory allocated on the stack and cause an access violation. One way
to help provide type-safety is to look at the function prototypes of the exported
functions and create matching typedefs for the function pointers. For example:
typedef UINT (CALLBACK* LPFNDLLFUNC1)(DWORD,UINT);
...
HINSTANCE hDLL; // Handle to DLL
LPFNDLLFUNC1 lpfnDllFunc1; // Function pointer
DWORD dwParam1;
UINT uParam2, uReturnVal;
hDLL = LoadLibrary("MyDLL");
if (hDLL != NULL)
{
 lpfnDllFunc1 = (LPFNDLLFUNC1)GetProcAddress(hDLL,
 "DLLFunc1");
 if (!lpfnDllFunc1)
 {
 // handle the error
 FreeLibrary(hDLL);
 return SOME_ERROR_CODE;
 }
 else
 {
 // call the function
 uReturnVal = lpfnDllFunc1(dwParam1, uParam2);
 }
}
How you specify the function you want when calling GetProcAddress depends on how
the DLL was built.
You can only obtain the export ordinal if the DLL you are linking to is built with a
module definition (.def) file and if the ordinals are listed with the functions in the
EXPORTS section of the DLL's .def file. Calling GetProcAddress with an export ordinal, as
opposed to the function name, is slightly faster if the DLL has many exported functions
because the export ordinals serve as indexes into the DLL's export table. With an export
ordinal, GetProcAddress can locate the function directly as opposed to comparing the
specified name to the function names in the DLL's export table. However, you should
call GetProcAddress with an export ordinal only if you have control over assigning the
ordinals to the exported functions in the .def file.
What do you want to do?
Link an executable to a DLL
Link an executable to a DLL
What do you want to know more about?
LoadLibrary and AfxLoadLibrary
FreeLibrary
Exporting from a DLL Using DEF Files
See also
Create C/C++ DLLs in Visual Studio
FreeLibrary and AfxFreeLibrary
Article • 08/03/2021
Processes that explicitly link to a DLL call the FreeLibrary function when the DLL module
is no longer needed. This function decrements the module's reference count. And, if the
reference count is zero, it's unmapped from the address space of the process.
In an MFC application, use AfxFreeLibrary instead of FreeLibrary to unload an MFC
extension DLL. The interface (function prototype) for AfxFreeLibrary is the same as
FreeLibrary .
What do you want to do?
Link an executable to a DLL
Link an executable to a DLL
What do you want to know more about?
LoadLibrary and AfxLoadLibrary
GetProcAddress
See also
Create C/C++ DLLs in Visual Studio
FreeLibrary
AfxFreeLibrary
Module States of a Regular MFC DLL
Dynamically Linked to MFC
Article • 08/03/2021
The ability to dynamically link a regular MFC DLL to the MFC DLL allows some
configurations that are very complicated. For example, a regular MFC DLL and the
executable that uses it can both dynamically link to the MFC DLL and to any MFC
extension DLLs.
This configuration poses a problem with regard to the MFC global data, such as the
pointer to the current CWinApp object and handle maps.
Before MFC version 4.0, this global data resided in the MFC DLL itself and was shared by
all the modules in the process. Because each process using a Win32 DLL gets its own
copy of the DLL's data, this scheme provided an easy way to track per-process data.
Also, because the AFXDLL model presumed that there would be only one CWinApp
object and only one set of handle maps in the process, these items could be tracked in
the MFC DLL itself.
But with the ability to dynamically link a regular MFC DLL to the MFC DLL, it is now
possible to have two or more CWinApp objects in a process — and also two or more sets
of handle maps. How does MFC keep track of which ones it should be using?
The solution is to give each module (application or regular MFC DLL) its own copy of
this global state information. Thus, a call to AfxGetApp in the regular MFC DLL returns a
pointer to the CWinApp object in the DLL, not the one in the executable. This per-module
copy of the MFC global data is known as a module state and is described in MFC Tech
Note 58.
The MFC common window procedure automatically switches to the correct module
state, so you do not need to worry about it in any message handlers implemented in
your regular MFC DLL. But when your executable calls into the regular MFC DLL, you do
need to explicitly set the current module state to the one for the DLL. To do this, use the
AFX_MANAGE_STATE macro in every function exported from the DLL. This is done by
adding the following line of code to the beginning of functions exported from the DLL:
AFX_MANAGE_STATE(AfxGetStaticModuleState( ))
What do you want to know more about?
Managing the state data of MFC modules
Regular MFC DLLs dynamically linked to MFC
MFC extension DLLs
See also
Create C/C++ DLLs in Visual Studio
MFC extension DLLs
Article • 08/03/2021
An MFC extension DLL is a DLL that typically implements reusable classes derived from
the existing Microsoft Foundation Class Library classes.
An MFC extension DLL has the following features and requirements:
The client executable must be an MFC application compiled with _AFXDLL defined.
An MFC extension DLL can also be used by a regular MFC DLL that is dynamically
linked to MFC.
MFC extension DLLs should be compiled with _AFXEXT defined. This forces _AFXDLL
to be also defined and ensures that the proper declarations is pulled in from the
MFC header files. It also ensures that AFX_EXT_CLASS is defined as
__declspec(dllexport) while building the DLL, which is necessary if you are using
this macro to declare the classes in your MFC extension DLL.
MFC extension DLLs should not instantiate a class derived from CWinApp , but
should rely on the client application (or DLL) to provide this object.
MFC extension DLLs should, however, provide a DllMain function and do any
necessary initialization there.
Extension DLLs are built using the dynamic-link library version of MFC (also known as
the shared version of MFC). Only MFC executables (either applications or regular MFC
DLLs) that are built with the shared version of MFC can use an MFC extension DLL. Both
the client application and the MFC extension DLL must use the same version of
MFCx0.dll. With an MFC extension DLL, you can derive new custom classes from MFC
and then offer this extended version of MFC to applications that call your DLL.
Extension DLLs can also be used for passing MFC-derived objects between the
application and the DLL. The member functions associated with the passed object exist
in the module where the object was created. Because these functions are properly
exported when using the shared DLL version of MFC, you can freely pass MFC or MFC￾derived object pointers between an application and the MFC extension DLLs it loads.
An MFC extension DLL uses a shared version of MFC in the same way an application
uses the shared DLL version of MFC, with a few additional considerations:
It does not have a CWinApp -derived object. It must work with the CWinApp -derived
object of the client application. This means that the client application owns the
main message pump, the idle loop, and so on.
It calls AfxInitExtensionModule in its DllMain function. The return value of this
function should be checked. If a zero value is returned from
AfxInitExtensionModule , return 0 from your DllMain function.
It creates a CDynLinkLibrary object during initialization if the MFC extension DLL
wants to export CRuntimeClass objects or resources to the application.
Before version 4.0 of MFC, this type of DLL was called an AFXDLL. AFXDLL refers to the
_AFXDLL preprocessor symbol that is defined when building the DLL.
The import libraries for the shared version of MFC are named according to the
convention described in Naming conventions for MFC DLLs. Visual Studio supplies
prebuilt versions of the MFC DLLs, plus a number of non-MFC DLLs that you can use and
distribute with your applications. These are documented in Redist.txt, which is installed
to the Program Files\Microsoft Visual Studio folder.
If you are exporting using a .def file, place the following code at the beginning and end
of your header file:
C++
#undef AFX_DATA
#define AFX_DATA AFX_EXT_DATA
// <body of your header file>
#undef AFX_DATA
#define AFX_DATA
These four lines ensure that your code is compiled correctly for an MFC extension DLL.
Leaving out these four lines might cause your DLL to either compile or link incorrectly.
If you need to pass an MFC or MFC-derived object pointer to or from an MFC DLL, the
DLL should be an MFC extension DLL. The member functions associated with the passed
object exist in the module where the object was created. Because these functions are
properly exported when using the shared DLL version of MFC, you can freely pass MFC
or MFC-derived object pointers between an application and the MFC extension DLLs it
loads.
Due to C++ name mangling and export issues, the export list from an MFC extension
DLL might be different between the debug and retail versions of the same DLL and DLLs
for different platforms. The retail MFCx0.dll has about 2,000 exported entry points; the
debug MFCx0D.dll has about 3,000 exported entry points.
Memory Management
MFCx0.dll and all MFC extension DLLs loaded into a client application's address space
use the same memory allocator, resource loading, and other MFC global states as if they
were in the same application. This is significant because the non-MFC DLL libraries and
the regular MFC DLLs do the exact opposite and have each DLL allocating out of its own
memory pool.
If an MFC extension DLL allocates memory, that memory can freely intermix with any
other application-allocated object. Also, if an application that dynamically links to MFC
fails, the protection of the operating system maintains the integrity of any other MFC
application sharing the DLL.
Similarly other global MFC states, like the current executable file to load resources from,
are also shared between the client application and all MFC extension DLLs as well as
MFCx0.dll itself.
Sharing Resources and Classes
Exporting resources is done through a resource list. Each application contains a singly
linked list of CDynLinkLibrary objects. When looking for a resource, most of the
standard MFC implementations that load resources look first at the current resource
module ( AfxGetResourceHandle ) and if the resource is not found walk the list of
CDynLinkLibrary objects attempting to load the requested resource.
Walking the list has the disadvantages that it is slightly slower and requires managing
resource ID ranges. It has the advantage that a client application that links to several
MFC extension DLLs can use any DLL-provided resource without having to specify the
DLL instance handle. AfxFindResourceHandle is an API used for walking the resource list
to look for a given match. It takes the name and type of a resource and returns the
resource handle where it was first found (or NULL).
If you do not want to walk the list and only load resources from a specific place, use the
functions AfxGetResourceHandle and AfxSetResourceHandle to save the old handle and
set the new handle. Be sure to restore the old resource handle before you return to the
client application. For an example of using this approach to explicitly load a menu, see
Testdll2 .cpp in the MFC sample DLLHUSK .
Dynamic creation of MFC objects given an MFC name is similar. The MFC object
deserialization mechanism needs to have all of the CRuntimeClass objects registered so
that it can reconstruct by dynamically creating C++ objects of the required type based
on what was stored earlier.
In the case of the MFC sample DLLHUSK , the list looks something like:
head -> DLLHUSK.EXE - or - DLLHUSK.EXE
 | |
 TESTDLL2.DLL TESTDLL2.DLL
 | |
 TESTDLL1.DLL TESTDLL1.DLL
 | |
 MFCOxxD.DLL |
 | |
 MFCDxxD.DLL |
 | |
 MFCxxD.DLL MFCxx.DLL
where xx is the version number; for example, 42 represents version 4.2.
The MFCxx.dll is usually last on the resource and class list. MFCxx.dll includes all of the
standard MFC resources, including prompt strings for all of the standard command IDs.
Placing it at the end of the list allows DLLs and the client application itself not to have
their own copy of the standard MFC resources, but to rely on the shared resources in
the MFCxx.dll instead.
Merging the resources and class names of all DLLs into the client application's name
space has the disadvantage of requiring you to be careful with what IDs or names you
pick.
The DLLHUSK sample manages the shared resource name space by using multiple
header files.
If your MFC extension DLL needs to maintain extra data for each application, you can
derive a new class from CDynLinkLibrary and create it in DllMain . When running, the
DLL can check the current application's list of CDynLinkLibrary objects to find the one
for that particular MFC extension DLL.
What do you want to do?
Initialize an MFC extension DLL
What do you want to know more about?
Tips on using shared resource files
DLL Version of MFC
Regular MFC DLLs statically linked to MFC
Regular MFC DLLs dynamically linked to MFC
Using Database, OLE, and Sockets MFC extension DLLs in regular MFC DLLs
See also
Create C/C++ DLLs in Visual Studio
Using Database, OLE, and Sockets MFC
extension DLLs in regular MFC DLLs
Article • 08/03/2021
When using an MFC extension DLL from a regular MFC DLL, if the MFC extension DLL
isn't wired into the CDynLinkLibrary object chain of the regular MFC DLL, you might run
into one or more related problems. Because the debug versions of the MFC Database,
OLE, and Sockets support DLLs are implemented as MFC extension DLLs, you might see
similar problems if you're using these MFC features, even if you're not explicitly using
any of your own MFC extension DLLs. Some symptoms are:
When attempting to deserialize an object of a type of class defined in the MFC
extension DLL, the message "Warning: Cannot load CYourClass from archive. Class
not defined." appears in the TRACE debug window and the object fails to serialize.
An exception indicating bad class might be thrown.
Resources stored in the MFC extension DLL fail to load because
AfxFindResourceHandle returns NULL or an incorrect resource handle.
DllGetClassObject , DllCanUnloadNow , and the UpdateRegistry , Revoke , RevokeAll ,
and RegisterAll member functions of COleObjectFactory fail to locate a class
factory defined in the MFC extension DLL.
AfxDoForAllClasses doesn't work for any classes in the MFC extension DLL.
Standard MFC database, sockets, or OLE resources fail to load. For example,
AfxLoadString(AFX_IDP_SQL_CONNECT_FAIL) returns an empty string, even when the
regular MFC DLL is properly using the MFC Database classes.
The solution to these problems is to create and export an initialization function in the
MFC extension DLL that creates a CDynLinkLibrary object. Call this initialization function
exactly once from each regular MFC DLL that uses the MFC extension DLL.
MFC OLE, MFC Database (or DAO), or MFC
Sockets Support
If you're using any MFC OLE, MFC Database (or DAO), or MFC Sockets support in your
regular MFC DLL, respectively, the MFC debug MFC extension DLLs MFCOxxD.dll ,
MFCDxxD.dll , and MFCNxxD.dll (where xx is the version number) are linked automatically.
Call a predefined initialization function for each of the DLLs that you're using:
For database support, add a call to AfxDbInitModule to your regular MFC DLL in its
CWinApp::InitInstance function. Make sure this call occurs before any base-class
call or any added code that accesses the MFCDxxD.dll . This function takes no
parameters and returns void .
For OLE support, add a call to AfxOleInitModule to your regular MFC DLL it its
CWinApp::InitInstance function. The COleControlModule::InitInstance function
calls AfxOleInitModule already, so if you're building an OLE control and use
COleControlModule , you shouldn't add this call to AfxOleInitModule .
For Sockets support, add a call to AfxNetInitModule to your regular MFC DLL in
CWinApp::InitInstance .
Release builds of MFC DLLs and applications don't use separate DLLs for database,
sockets, or OLE support. However, it's safe to call these initialization functions in release
mode.
CDynLinkLibrary Objects
During each operation mentioned at the beginning of this article, MFC needs to search
for a particular value or object. For example, during deserialization, MFC needs to search
through all the currently available run-time classes to match objects in the archive with
their proper run-time class.
As a part of these searches, MFC scans through all the MFC extension DLLs in use by
walking a chain of CDynLinkLibrary objects. CDynLinkLibrary objects attach
automatically to a chain during their construction and are created by each MFC
extension DLL in turn during initialization. Every module (application or regular MFC
DLL) has its own chain of CDynLinkLibrary objects.
For an MFC extension DLL to get wired into a CDynLinkLibrary chain, it must create a
CDynLinkLibrary object in the context of every module that uses the MFC extension DLL.
To use an MFC extension DLL in regular MFC DLLs, the extension DLL must provide an
exported initialization function that creates a CDynLinkLibrary object. Every regular MFC
DLL that uses the MFC extension DLL must call the exported initialization function.
If you'll only use an MFC extension DLL from an MFC application, and never from a
regular MFC DLL, then it's sufficient to create the CDynLinkLibrary object in the MFC
extension DLL DllMain function. It's what the MFC DLL Wizard MFC extension DLL code
does. When loading an MFC extension DLL implicitly, DllMain loads and executes before
the application ever starts. Any CDynLinkLibrary creations are wired into a default chain
that the MFC DLL reserves for an MFC application.
It's a bad idea to have multiple CDynLinkLibrary objects from one MFC extension DLL in
any one chain. It's especially true if the MFC extension DLL may be dynamically
unloaded from memory. Don't call the initialization function more than once from any
one module.
This sample code assumes that the regular MFC DLL implicitly links to the MFC
extension DLL. To link implicitly, link to the import library (LIB file) of the MFC extension
DLL when you build the regular MFC DLL.
The following lines should be in the source of the MFC extension DLL:
C++
Sample Code
// YourExtDLL.cpp:
// standard MFC extension DLL routines
#include "afxdllx.h"
static AFX_EXTENSION_MODULE extensionDLL;
extern "C" int APIENTRY
DllMain(HINSTANCE hInstance, DWORD dwReason, LPVOID lpReserved)
{
 if (dwReason == DLL_PROCESS_ATTACH)
 {
 // MFC extension DLL one-time initialization
 if (!AfxInitExtensionModule(extensionDLL, hInstance))
 return 0;
 }
 return 1; // ok
}
// Exported DLL initialization is run in context of
// application or regular MFC DLL
extern "C" void WINAPI InitYourExtDLL()
{
 // create a new CDynLinkLibrary for this app
 new CDynLinkLibrary(extensionDLL);
 // add other initialization here
}
Be sure to export the InitYourExtDLL function. You can use __declspec(dllexport) , or
export it in the DEF file for your DLL, as shown here:
def
Add a call to the InitInstance member of the CWinApp -derived object in each regular
MFC DLL using the MFC extension DLL:
C++
Initialize an MFC extension DLL
Initialize regular MFC DLLs
// YourExtDLL.Def:
LIBRARY YOUREXTDLL
CODE PRELOAD MOVEABLE DISCARDABLE
DATA PRELOAD SINGLE
EXPORTS
 InitYourExtDLL
// YourRegularDLL.cpp:
class CYourRegularDLL : public CWinApp
{
public:
 virtual BOOL InitInstance(); // Initialization
 virtual int ExitInstance(); // Termination
 // nothing special for the constructor
 CYourRegularDLL(LPCTSTR pszAppName) : CWinApp(pszAppName) { }
};
BOOL CYourRegularDLL::InitInstance()
{
 // any DLL initialization goes here
 TRACE0("YOUR regular MFC DLL initializing\n");
 // wire any MFC extension DLLs into CDynLinkLibrary chain
 InitYourExtDLL();
 return TRUE;
}
What do you want to do?
What do you want to know more about?
MFC extension DLLs
Regular MFC DLLs Statically Linked to MFC
Regular MFC DLLs Dynamically Linked to MFC
Using MFC as Part of a DLL
DLL Version of MFC
See also
MFC extension DLLs
Creating a resource-only DLL
Article • 08/03/2021
A resource-only DLL is a DLL that contains nothing but resources, such as icons,
bitmaps, strings, and dialog boxes. Using a resource-only DLL is a good way to share the
same set of resources among multiple programs. It's also a good way to provide an
application with resources localized for multiple languages. For more information, see
Localized resources in MFC applications: Satellite DLLs.
Create a resource-only DLL
To create a resource-only DLL, you create a new Windows DLL (non-MFC) project, and
add your resources to the project:
1. Select Windows Desktop Wizard in the New Project dialog box and choose Next.
In the Configure your new project page, enter the project and solution names,
and choose Create.
2. In the Windows Desktop Project dialog box, select an Application type of
Dynamic Link Library. Under Additional options, select Empty project. Choose OK
to create your project.
3. Create a new resource script that contains the resources for the DLL (such as a
string or a menu). Save the .rc file.
4. On the Project menu, select Add Existing Item, and then insert the new .rc file
into the project.
5. Specify the /NOENTRY linker option. /NOENTRY prevents the linker from linking a
reference to _main into the DLL; this option is required to create a resource-only
DLL.
6. Build the DLL.
Use a resource-only DLL
The application that uses the resource-only DLL should call LoadLibraryEx or a related
function to explicitly link to the DLL. To access the resources, call the generic functions
FindResource and LoadResource , which work on any kind of resource. Or, call one of the
following resource-specific functions:
FormatMessage
LoadAccelerators
LoadBitmap
LoadCursor
LoadIcon
LoadMenu
LoadString
The application should call FreeLibrary when it's finished using the resources.
See also
Working with Resource Files
Create C/C++ DLLs in Visual Studio
Localized Resources in MFC
Applications: Satellite DLLs
Article • 08/03/2021
MFC version 7.0 and later provides enhanced support for satellite DLLs, a feature that
helps in creating applications localized for multiple languages. A satellite DLL is a
resource-only DLL that contains an application's resources localized for a particular
language. When the application begins executing, MFC automatically loads the localized
resource most appropriate for the environment. For example, you could have an
application with English language resources with two satellite DLLs, one containing a
French translation of your resources and the other containing a German translation.
When the application is run on an English language system, it uses the English
resources. If run on a French system, it uses the French resources; if run on a German
system, it uses the German resources.
To support localized resources in an MFC application, MFC attempts to load a satellite
DLL containing resources localized to a specific language. Satellite DLLs are named
ApplicationNameXXX.dll, where ApplicationName is the name of the .exe or .dll using
MFC, and XXX is the three-letter code for the language of the resources (for example,
'ENU' or 'DEU').
MFC attempts to load the resource DLL for each of the following languages in order,
stopping when it finds one:
1. The current user's default UI language, as returned from the
GetUserDefaultUILanguage() Win32 API.
2. The current user's default UI language, without any specific sublanguage (that is,
ENC [Canadian English] becomes ENU [U.S. English]).
3. The system's default UI language, as returned from the
GetSystemDefaultUILanguage() API. On other platforms, this is the language of the
OS itself.
4. The system's default UI language, without any specific sublanguage.
5. A fake language with the 3-letter code LOC.
If MFC does not find any satellite DLLs, it uses whatever resources are contained in the
application itself.
As an example, suppose that an application LangExample.exe uses MFC and is running
on a multiple user-interface system; the system UI language is ENU [U.S. English] and
the current user's UI language is set to FRC [Canadian French]. MFC looks for the
following DLLs in the following order:
1. LangExampleFRC.dll (user's UI language).
2. LangExampleFRA.dll (user's UI language without the sublanguage, in this example
French (France).
3. LangExampleENU.dll (system's UI language).
4. LangExampleLOC.dll.
If none of these DLLs are found, MFC uses the resources in LangExample.exe.
See also
Create C/C++ DLLs in Visual Studio
TN057: Localization of MFC Components
Importing and Exporting
Article • 08/03/2021
You can import public symbols into an application or export functions from a DLL using
two methods:
Use a module definition (.def) file when building the DLL
Use the keywords __declspec(dllimport) or __declspec(dllexport) in a function
definition in the main application
Using a .def file
A module-definition (.def) file is a text file containing one or more module statements
that describe various attributes of a DLL. If you do not use __declspec(dllimport) or
__declspec(dllexport) to export a DLL's functions, the DLL requires a .def file.
You can use .def files to import into an application or to export from a DLL.
Using __declspec
You do not need to use __declspec(dllimport) for your code to compile correctly, but
doing so allows the compiler to generate better code. The compiler is able to generate
better code because it can determine whether a function exists in a DLL or not, which
allows the compiler to produce code that skips a level of indirection that would normally
be present in a function call that crossed a DLL boundary. However, you must use
__declspec(dllimport) to import variables used in a DLL.
With the proper .def file EXPORTS section, __declspec(dllexport) is not required.
__declspec(dllexport) was added to provide an easy way to export functions from an
.exe or .dll file without using a .def file.
The Win32 Portable Executable format is designed to minimize the number of pages
that must be touched to fix imports. To do this, it places all the import addresses for any
program in one place called the Import Address Table. This allows the loader to modify
only one or two pages when accessing these imports.
What do you want to do?
Import into an Application
Export from a DLL
See also
Create C/C++ DLLs in Visual Studio
Importing into an Application
Article • 08/03/2021
You can import functions into an application using two methods:
Use the keywords __declspec(dllimport) in a function definition in the main
application
Use a module definition (.def) file along with __declspec(dllimport)
What do you want to do?
Import into an Application Using __declspec(dllimport)
Import Function Calls Using __declspec(dllimport)
Import Data Using __declspec(dllimport)
Import Using DEF Files
See also
Importing and Exporting
Import into an application using
__declspec(dllimport)
Article • 08/03/2021
A program that uses public symbols defined by a DLL is said to import them. When you
create header files for applications that use your DLLs to build with, use
__declspec(dllimport) on the declarations of the public symbols. The keyword
__declspec(dllimport) works whether you export with .def files or with the
__declspec(dllexport) keyword.
To make your code more readable, define a macro for __declspec(dllimport) and then
use the macro to declare each imported symbol:
#define DllImport __declspec( dllimport )
DllImport int j;
DllImport void func();
Using __declspec(dllimport) is optional on function declarations, but the compiler
produces more efficient code if you use this keyword. However, you must use
__declspec(dllimport) for the importing executable to access the DLL's public data
symbols and objects. Note that the users of your DLL still need to link with an import
library.
You can use the same header file for both the DLL and the client application. To do this,
use a special preprocessor symbol that indicates whether you are building the DLL or
building the client application. For example:
#ifdef _EXPORTING
 #define CLASS_DECLSPEC __declspec(dllexport)
#else
 #define CLASS_DECLSPEC __declspec(dllimport)
#endif
class CLASS_DECLSPEC CExampleA : public CObject
{ ... class definition ... };
What do you want to do?
Initialize a DLL
What do you want to know more about?
Importing and exporting inline functions
Mutual imports
See also
Importing into an Application
Importing function calls using
__declspec(dllimport)
Article • 08/03/2021
Annotating calls by using the __declspec(dllimport) can make them faster.
__declspec(dllimport) is always required to access exported DLL data.
Import a function from a DLL
The following code example shows how to use __declspec(dllimport) to import
function calls from a DLL into an application. Assume that func1 is a function that's in a
DLL separate from the executable file that contains the main function.
Without __declspec(dllimport) , given this code:
C
int main(void)
{
 func1();
}
the compiler generates code that looks like this:
asm
call func1
and the linker translates the call into something like this:
asm
call 0x4000000 ; The address of 'func1'.
If func1 exists in another DLL, the linker can't resolve this address directly because it has
no way of knowing what the address of func1 is. In 32-bit and 64-bit environments, the
linker generates a thunk at a known address. In a 32-bit environment the thunk looks
like:
asm
0x40000000: jmp DWORD PTR __imp_func1
Here __imp_func1 is the address for the func1 slot in the import address table of the
executable file. All these addresses are known to the linker. The loader only has to
update the executable file's import address table at load time for everything to work
correctly.
That's why using __declspec(dllimport) is better: because the linker doesn't generate a
thunk if it's not required. Thunks make the code larger (on RISC systems, it can be
several instructions) and can degrade your cache performance. If you tell the compiler
the function is in a DLL, it can generate an indirect call for you.
So now this code:
C
__declspec(dllimport) void func1(void);
int main(void)
{
 func1();
}
generates this instruction:
asm
call DWORD PTR __imp_func1
There's no thunk and no jmp instruction, so the code is smaller and faster. You can also
get the same effect without __declspec(dllimport) by using whole program
optimization. For more information, see /GL (Whole Program Optimization).
For function calls within a DLL, you don't want to have to use an indirect call. The linker
already knows the function's address. It takes extra time and space to load and store the
address of the function before an indirect call. A direct call is always faster and smaller.
You only want to use __declspec(dllimport) when calling DLL functions from outside
the DLL itself. Don't use __declspec(dllimport) on functions inside a DLL when building
that DLL.
See also
Importing into an Application
Importing data using
__declspec(dllimport)
Article • 08/03/2021
In the case of data, using __declspec(dllimport) is a convenience item that removes a
layer of indirection. When you import data from a DLL, you still have to go through the
import address table. Before __declspec(dllimport) , this meant you had to remember
to do an extra level of indirection when accessing data exported from the DLL:
C
You would then export the data in your .DEF file:
DEF
and access it outside the DLL:
C
When you mark the data as __declspec(dllimport) , the compiler automatically
generates the indirection code for you. You no longer have to worry about the steps
above. As stated previously, do not use __declspec(dllimport) declaration on the data
when building the DLL. Functions within the DLL do not use the import address table to
access the data object; therefore, you will not have the extra level of indirection present.
// project.h
// Define PROJECT_EXPORTS when building your DLL
#ifdef PROJECT_EXPORTS // If accessing the data from inside the DLL
 ULONG ulDataInDll;
#else // If accessing the data from outside the DLL
 ULONG *ulDataInDll;
#endif
// project.def
LIBRARY project
EXPORTS
 ulDataInDll CONSTANT
if (*ulDataInDll == 0L)
{
 // Do stuff here
}
To export the data automatically from the DLL, use this declaration:
C
// project.h
// Define PROJECT_EXPORTS when building your DLL
#ifdef PROJECT_EXPORTS // If accessing the data from inside the DLL
 __declspec(dllexport) ULONG ulDataInDLL;
#else // If accessing the data from outside the DLL
 __declspec(dllimport) ULONG ulDataInDLL;
#endif
See also
Importing into an Application
Importing Using DEF Files
Article • 08/03/2021
If you choose to use __declspec(dllimport) along with a .def file, you should change
the .def file to use DATA in place of CONSTANT to reduce the likelihood that incorrect
coding will cause a problem:
The following table shows why.
Keyword Emits in the import library Exports
CONSTANT _imp_ulDataInDll , _ulDataInDll _ulDataInDll
DATA _imp_ulDataInDll _ulDataInDll
Using __declspec(dllimport) and CONSTANT lists both the imp version and the
undecorated name in the .lib DLL import library that is created to allow explicit linking.
Using __declspec(dllimport) and DATA lists just the imp version of the name.
If you use CONSTANT, either of the following code constructs can be used to access
ulDataInDll :
-or￾However, if you use DATA in your .def file, only code compiled with the following
definition can access the variable ulDataInDll :
// project.def
LIBRARY project
EXPORTS
 ulDataInDll DATA
__declspec(dllimport) ULONG ulDataInDll; /*prototype*/
if (ulDataInDll == 0L) /*sample code fragment*/
ULONG *ulDataInDll; /*prototype*/
if (*ulDataInDll == 0L) /*sample code fragment*/
__declspec(dllimport) ULONG ulDataInDll;
if (ulDataInDll == 0L) /*sample code fragment*/
Using CONSTANT is more risky because if you forget to use the extra level of indirection,
you could potentially access the import address table's pointer to the variable — not the
variable itself. This type of problem can often manifest as an access violation because
the import address table is currently made read-only by the compiler and linker.
The current MSVC linker issues a warning if it sees CONSTANT in the .def file to account
for this case. The only real reason to use CONSTANT is if you cannot recompile some
object file where the header file did not list __declspec(dllimport) on the prototype.
See also
Importing into an Application
Exporting from a DLL
Article • 08/03/2021
A DLL file has a layout very similar to an .exe file, with one important difference — a DLL
file contains an exports table. The exports table contains the name of every function that
the DLL exports to other executables. These functions are the entry points into the DLL;
only the functions in the exports table can be accessed by other executables. Any other
functions in the DLL are private to the DLL. The exports table of a DLL can be viewed by
using the DUMPBIN tool with the /EXPORTS option.
You can export functions from a DLL using two methods:
Create a module definition (.def) file and use the .def file when building the DLL.
Use this approach if you want to export functions from your DLL by ordinal rather
than by name.
Use the keyword __declspec(dllexport) in the function's definition.
When exporting functions with either method, make sure to use the __stdcall calling
convention.
What do you want to do?
Export from a DLL using .def files
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Export C functions for use in C or C++-language executables
Export functions from a DLL by ordinal rather than by name
Determine which exporting method to use
Link an executable to a DLL
Initialize a DLL
What do you want to know more about?
Importing into an application
Importing and exporting inline functions
Mutual imports
See also
Importing and Exporting
Exporting from a DLL Using DEF Files
Article • 08/03/2021
A module-definition or DEF file (*.def) is a text file containing one or more module
statements that describe various attributes of a DLL. If you are not using the
__declspec(dllexport) keyword to export the DLL's functions, the DLL requires a DEF
file.
A minimal DEF file must contain the following module-definition statements:
The first statement in the file must be the LIBRARY statement. This statement
identifies the DEF file as belonging to a DLL. The LIBRARY statement is followed by
the name of the DLL. The linker places this name in the DLL's import library.
The EXPORTS statement lists the names and, optionally, the ordinal values of the
functions exported by the DLL. You assign the function an ordinal value by
following the function's name with an at sign (@) and a number. When you specify
ordinal values, they must be in the range 1 through N, where N is the number of
functions exported by the DLL. If you want to export functions by ordinal, see
Exporting Functions from a DLL by Ordinal Rather Than by Name as well as this
topic.
For example, a DLL that contains the code to implement a binary search tree might look
like the following:
LIBRARY BTREE
EXPORTS
 Insert @1
 Delete @2
 Member @3
 Min @4
If you use the MFC DLL Wizard to create an MFC DLL, the wizard creates a skeleton DEF
file for you and automatically adds it to your project. Add the names of the functions to
be exported to this file. For non-MFC DLLs, create the DEF file yourself and add it to
your project. Then go to Project > Properties > Linker > Input > Module Definition File
and enter the name of the DEF file. Repeat this step for each configuration and platform,
or do it all at once by selecting Configuration = All Configurations, and Platform = All
Platforms.
If you are exporting functions in a C++ file, you have to either place the decorated
names in the DEF file or define your exported functions with standard C linkage by using
extern "C". If you need to place the decorated names in the DEF file, you can obtain
them by using the DUMPBIN tool or by using the linker /MAP option. Note that the
decorated names produced by the compiler are compiler specific. If you place the
decorated names produced by the Microsoft C++ compiler (MSVC) into a DEF file,
applications that link to your DLL must also be built using the same version of MSVC so
that the decorated names in the calling application match the exported names in the
DLL's DEF file.
７ Note
A DLL built with Visual Studio 2015 can be consumed by applications built with
Visual Studio 2017 or Visual Studio 2019.
If you are building an extension DLL, and exporting using a DEF file, place the following
code at the beginning and end of your header files that contain the exported classes:
#undef AFX_DATA
#define AFX_DATA AFX_EXT_DATA
// <body of your header file>
#undef AFX_DATA
#define AFX_DATA
These lines ensure that MFC variables that are used internally or that are added to your
classes are exported (or imported) from your MFC extension DLL. For example, when
deriving a class using DECLARE_DYNAMIC , the macro expands to add a CRuntimeClass
member variable to your class. Leaving out these four lines might cause your DLL to
compile or link incorrectly or cause an error when the client application links to the DLL.
When building the DLL, the linker uses the DEF file to create an export (.exp) file and an
import library (.lib) file. The linker then uses the export file to build the DLL file.
Executables that implicitly link to the DLL link to the import library when they are built.
Note that MFC itself uses DEF files to export functions and classes from the MFCx0.dll.
What do you want to do?
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Export C functions for use in C or C++-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
.def files
Rules for module-definition statements
Decorated names
Importing and exporting inline functions
Mutual imports
See also
Exporting from a DLL
Exporting from a DLL Using
__declspec(dllexport)
Article • 08/03/2021
You can export data, functions, classes, or class member functions from a DLL using the
__declspec(dllexport) keyword. __declspec(dllexport) adds the export directive to the
object file so you do not need to use a .def file.
This convenience is most apparent when trying to export decorated C++ function
names. Because there is no standard specification for name decoration, the name of an
exported function might change between compiler versions. If you use
__declspec(dllexport) , recompiling the DLL and dependent .exe files is necessary only
to account for any naming convention changes.
Many export directives, such as ordinals, NONAME, and PRIVATE, can be made only in a
.def file, and there is no way to specify these attributes without a .def file. However,
using __declspec(dllexport) in addition to using a .def file does not cause build errors.
To export functions, the __declspec(dllexport) keyword must appear to the left of the
calling-convention keyword, if a keyword is specified. For example:
__declspec(dllexport) void __cdecl Function1(void);
To export all of the public data members and member functions in a class, the keyword
must appear to the left of the class name as follows:
class __declspec(dllexport) CExampleExport : public CObject
{ ... class definition ... };
７ Note
__declspec(dllexport) cannot be applied to a function with the __clrcall calling
convention.
When building your DLL, you typically create a header file that contains the function
prototypes and/or classes you are exporting and add __declspec(dllexport) to the
declarations in the header file. To make your code more readable, define a macro for
__declspec(dllexport) and use the macro with each symbol you are exporting:
#define DllExport __declspec( dllexport )
__declspec(dllexport) stores function names in the DLL's export table. If you want to
optimize the table's size, see Exporting Functions from a DLL by Ordinal Rather Than by
Name.
What do you want to do?
Export from a DLL using .def files
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Export C functions for use in C or C++-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
The __declspec keyword
Importing and exporting inline functions
Mutual imports
See also
Exporting from a DLL
Exporting and Importing Using
AFX_EXT_CLASS
Article • 08/03/2021
MFC extension DLLs use the macro AFX_EXT_CLASS to export classes; the executables
that link to the MFC extension DLL use the macro to import classes. With the
AFX_EXT_CLASS macro, the same header files that are used to build the MFC extension
DLL can be used with the executables that link to the DLL.
In the header file for your DLL, add the AFX_EXT_CLASS keyword to the declaration of
your class as follows:
C++
class AFX_EXT_CLASS CMyClass : public CDocument
{
// <body of class>
};
This macro is defined by MFC as __declspec(dllexport) when the preprocessor symbols
_AFXDLL and _AFXEXT are defined. But the macro is defined as __declspec(dllimport)
when _AFXDLL is defined and _AFXEXT is not defined. When defined, the preprocessor
symbol _AFXDLL indicates that the shared version of MFC is being used by the target
executable (either a DLL or an application). When both _AFXDLL and _AFXEXT are
defined, this indicates that the target executable is an MFC extension DLL.
Because AFX_EXT_CLASS is defined as __declspec(dllexport) when exporting from an
MFC extension DLL, you can export entire classes without placing the decorated names
for all of that class's symbols in the .def file.
Although you can avoid creating a .def file and all of the decorated names for the class
with this method, creating a .def file is more efficient because the names can be
exported by ordinal. To use the .def file method of exporting, place the following code
at the beginning and end of your header file:
C++
#undef AFX_DATA
#define AFX_DATA AFX_EXT_DATA
// <body of your header file>
#undef AFX_DATA
#define AFX_DATA
Sometimes you might want to export individual members of your class. For example, if
you are exporting a CDialog -derived class, you might only need to export the
constructor and the DoModal call. You can use AFX_EXT_CLASS on the individual members
you need to export.
For example:
C++
Because you are no longer exporting all members of the class, you may run into an
additional problem because of the way that MFC macros work. Several of MFC's helper
macros actually declare or define data members. Therefore, these data members must
also be exported from your DLL.
For example, the DECLARE_DYNAMIC macro is defined as follows when building an MFC
extension DLL:
C++
Ｕ Caution
Be careful when exporting inline functions, because they can create the possibility
of version conflicts. An inline function gets expanded into the application code;
therefore, if you later rewrite the function, it does not get updated unless the
application itself is recompiled. Normally, DLL functions can be updated without
rebuilding the applications that use them.
Exporting Individual Members in a Class
class CExampleDialog : public CDialog
{
public:
 AFX_EXT_CLASS CExampleDialog();
 AFX_EXT_CLASS int DoModal();
 ...
 // rest of class definition
 ...
};
#define DECLARE_DYNAMIC(class_name) \
protected: \
 static CRuntimeClass* PASCAL _GetBaseClass(); \
public: \
The line that begins with static AFX_DATA is declaring a static object inside of your class.
To export this class correctly and access the run-time information from a client
executable, you must export this static object. Because the static object is declared with
the modifier AFX_DATA , you only need to define AFX_DATA to be __declspec(dllexport)
when building your DLL and define it as __declspec(dllimport) when building your
client executable. Because AFX_EXT_CLASS is already defined in this way, you just need to
redefine AFX_DATA to be the same as AFX_EXT_CLASS around your class definition.
For example:
C++
Because MFC always uses the AFX_DATA symbol on data items it defines within its
macros, this technique works for all such scenarios. For example, it works for
DECLARE_MESSAGE_MAP .
Export from a DLL using .def files
Export from a DLL using __declspec(dllexport)
Export C++ functions for use in C-language executables
 static AFX_DATA CRuntimeClass class##class_name; \
 virtual CRuntimeClass* GetRuntimeClass() const; \
#undef AFX_DATA
#define AFX_DATA AFX_EXT_CLASS
class CExampleView : public CView
{
 DECLARE_DYNAMIC()
 // ... class definition ...
};
#undef AFX_DATA
#define AFX_DATA
７ Note
If you are exporting the entire class rather than selected members of the class,
static data members are automatically exported.
What do you want to do?
Export C functions for use in C or C++-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
Decorated names
Importing and exporting inline functions
Mutual imports
See also
Exporting from a DLL
Exporting C++ Functions for Use in C￾Language Executables
Article • 08/03/2021
If you have functions in a DLL written in C++ that you want to access from a C-language
module, you should declare these functions with C linkage instead of C++ linkage.
Unless otherwise specified, the C++ compiler uses C++ type-safe naming (also known
as name decoration) and C++ calling conventions, which can be difficult to call from C.
To specify C linkage, specify extern "C" for your function declarations. For example:
extern "C" __declspec( dllexport ) int MyFunc(long parm1);
What do you want to do?
Export from a DLL using .def files
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C functions for use in C or C++-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
Decorated names
Using extern to Specify Linkage
See also
Exporting from a DLL
Export C functions for use in C or C++
language executables
Article • 05/25/2022
If you have functions in a DLL written in C, you can use a preprocessor macro to make
them easy to access from both C language and C++ language code. The __cplusplus
preprocessor macro indicates which language is being compiled. You may use it to
declare the functions with C linkage when called from C++ language code. If you use
this technique and provide header files for your DLL, these functions can be used by C
and C++ users with no change.
The following code shows a header file that both C and C++ client applications can use:
h
Sometimes you may need to link C functions to your C++ executable, but the function
declaration header files haven't used the above technique. You can still call the functions
from C++. In the C++ source file, wrap the #include directive to prevent the compiler
from decorating the C function names:
C++
Export from a DLL using .def files
// MyCFuncs.h
#ifdef __cplusplus
extern "C" { // only need to export C interface if
 // used by C++ source code
#endif
__declspec( dllimport ) void MyCFunc();
__declspec( dllimport ) void AnotherCFunc();
#ifdef __cplusplus
}
#endif
extern "C" {
#include "MyCHeader.h"
}
What do you want to do?
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Determine which exporting method to use
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
Decorated names
Using extern to specify linkage
See also
Exporting from a DLL
Determine Which Exporting Method to
Use
Article • 08/03/2021
You can export functions in either of two ways—a .def file or the __declspec(dllexport)
keyword. To help you decide which way is better for your DLL, consider these questions:
Do you plan to export more functions later?
Is your DLL used only by applications that you can rebuild, or is it used by
applications that you cannot rebuild—for example, applications that are created by
third parties?
Pros and Cons of Using .def Files
Exporting functions in a .def file gives you control over the export ordinals. When you
add an exported function to your DLL, you can assign it a higher ordinal value than any
other exported function. When you do this, applications that use implicit linking do not
have to relink with the import library that contains the new function. This is very
convenient if you are designing a DLL for use by many applications because you can
add new functionality and also ensure that it continues to work correctly with the
applications that already rely on it. For example, the MFC DLLs are built by using .def
files.
Another advantage to using a .def file is that you can use the NONAME attribute to export
a function. This puts only the ordinal in the exports table in the DLL. For DLLs that have a
large number of exported functions, using the NONAME attribute can reduce the size of
the DLL file. For information about how to write a module definition statement, see
Rules for Module-Definition Statements. For information about ordinal export, see
Exporting Functions from a DLL by Ordinal Rather Than by Name.
A disadvantage of using a .def file is that if you are exporting functions in a C++ file, you
either have to put the decorated names in the .def file or define the exported functions
by using extern "C" to avoid the name decoration that's done by the MSVC compiler.
If you put the decorated names in the .def file, you can obtain them by using the
DUMPBIN tool or by using the linker /MAP option. The decorated names that are
produced by the compiler are compiler-specific; therefore, if you put the decorated
names that are produced by the compiler into a .def file, the applications that link to the
DLL must also be built by using the same version of the compiler so that the decorated
names in the calling application match the exported names in the .def file of the DLL.
Pros and Cons of Using __declspec(dllexport)
Using __declspec(dllexport) is convenient because you do not have to worry about
maintaining a .def file and obtaining the decorated names of the exported functions.
However, the usefulness of this way of exporting is limited by the number of linked
applications that you are willing to rebuild. If you rebuild the DLL with new exports, you
also have to rebuild the applications because the decorated names for exported C++
functions might change if you use a different version of the compiler to rebuild it.
What do you want to do?
Export from a DLL using .DEF files
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Export C functions for use in C or C++-language executables
Import into an application using __declspec(dllimport)
Initialize a DLL
What do you want to know more about?
Importing and exporting inline functions
Mutual imports
Decorated names
See also
Exporting from a DLL
Exporting Functions from a DLL by
Ordinal Rather Than by Name
Article • 08/03/2021
The simplest way to export functions from your DLL is to export them by name. This is
what happens when you use __declspec(dllexport) , for example. But you can instead
export functions by ordinal. With this technique, you must use a .def file instead of
__declspec(dllexport) . To specify a function's ordinal value, append its ordinal to the
function name in the .def file. For information about specifying ordinals, see Exporting
from a DLL Using .def Files.
 Tip
If you want to optimize your DLL's file size, use the NONAME attribute on each
exported function. With the NONAME attribute, the ordinals are stored in the DLL's
export table rather than the function names. This can be a considerable savings if
you are exporting many functions.
What do you want to do?
Use a .def file so I can export by ordinal
Use __declspec(dllexport)
See also
Exporting from a DLL
Mutual Imports
Article • 08/03/2021
Exporting or importing to another executable file presents complications when the
imports are mutual (or circular). For example, two DLLs import symbols from each other,
similar to mutually recursive functions.
The problem with mutually importing executable files (usually DLLs) is that neither can
be built without building the other first. Each build process requires, as input, an import
library produced by the other build process.
The solution is to use the LIB utility with the /DEF option, which produces an import
library without building the executable file. Using this utility, you can build all the import
libraries you need, no matter how many DLLs are involved or how complicated the
dependencies are.
The general solution for handling mutual imports is:
1. Take each DLL in turn. (Any order is feasible, although some orders are more
optimal.) If all the needed import libraries exist and are current, run LINK to build
the executable file (DLL). This produces an import library. Otherwise, run LIB to
produce an import library.
Running LIB with the /DEF option produces an additional file with an .EXP
extension. The .EXP file must be used later to build the executable file.
2. After using either LINK or LIB to build all of the import libraries, go back and run
LINK to build any executable files that were not built in the previous step. Note
that the corresponding .exp file must be specified on the LINK line.
If you had run the LIB utility earlier to produce an import library for DLL1, LIB
would have produced the file DLL1.exp as well. You must use DLL1.exp as input to
LINK when building DLL1.dlll.
The following illustration shows a solution for two mutually importing DLLs, DLL1 and
DLL2. Step 1 is to run LIB, with the /DEF option set, on DLL1. Step 1 produces DLL1.lib,
an import library, and DLL1.exp. In step 2, the import library is used to build DLL2, which
in turn produces an import library for DLL2's symbols. Step 3 builds DLL1, by using
DLL1.exp and DLL2.lib as input. Note that an .exp file for DLL2 is not necessary because
LIB was not used to build DLL2's import library.
Linking Two DLLs with Mutual Imports
Limitations of _AFXEXT
You can use the _AFXEXT preprocessor symbol for your MFC extension DLLs as long as
you do not have multiple layers of MFC extension DLLs. If you have MFC extension DLLs
that call or derive from classes in your own MFC extension DLLs, which then derive from
the MFC classes, you must use your own preprocessor symbol to avoid ambiguity.
The problem is that in Win32, you must explicitly declare any data as
__declspec(dllexport) if it is to be exported from a DLL, and __declspec(dllimport) if it
is to be imported from a DLL. When you define _AFXEXT , the MFC headers make sure
that AFX_EXT_CLASS is defined correctly.
When you have multiple layers, one symbol such as AFX_EXT_CLASS is not sufficient,
because an MFC extension DLL might be exporting new classes as well as importing
other classes from another MFC extension DLL. To solve this problem, use a special
preprocessor symbol that indicates that you are building the DLL itself versus using the
DLL. For example, imagine two MFC extension DLLs, A.dll and B.dll. They each export
some classes in A.h and B.h, respectively. B.dll uses the classes from A.dll. The header
files would look something like this:
/* A.H */
#ifdef A_IMPL
 #define CLASS_DECL_A __declspec(dllexport)
#else
 #define CLASS_DECL_A __declspec(dllimport)
#endif
class CLASS_DECL_A CExampleA : public CObject
{ ... class definition ... };
// B.H
#ifdef B_IMPL
 #define CLASS_DECL_B __declspec(dllexport)
#else
 #define CLASS_DECL_B __declspec(dllimport)
#endif
class CLASS_DECL_B CExampleB : public CExampleA
{ ... class definition ... };
...
When A.dll is built, it is built with /D A_IMPL and when B.dll is built, it is built with /D
B_IMPL . By using separate symbols for each DLL, CExampleB is exported and CExampleA is
imported when building B.dll. CExampleA is exported when building A.dll and imported
when used by B.dll (or some other client).
This type of layering cannot be done when using the built-in AFX_EXT_CLASS and
_AFXEXT preprocessor symbols. The technique described above solves this problem in a
manner not unlike the mechanism MFC itself uses when building its Active technologies,
Database, and Network MFC extension DLLs.
Not Exporting the Entire Class
When you are not exporting an entire class, you have to ensure that the necessary data
items created by the MFC macros are exported correctly. This can be done by redefining
AFX_DATA to your specific class's macro. This should be done any time you are not
exporting the entire class.
For example:
/* A.H */
#ifdef A_IMPL
 #define CLASS_DECL_A _declspec(dllexport)
#else
 #define CLASS_DECL_A _declspec(dllimport)
#endif
#undef AFX_DATA
#define AFX_DATA CLASS_DECL_A
class CExampleA : public CObject
{
 DECLARE_DYNAMIC()
 CLASS_DECL_A int SomeFunction();
 //... class definition ...
};
#undef AFX_DATA
#define AFX_DATA
What do you want to do?
Export from a DLL
Export from a DLL using .DEF files
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
What do you want to know more about?
The LIB utility and the /DEF option
See also
Importing and Exporting
Importing and exporting inline
functions
Article • 08/03/2021
Imported functions can be defined as inline. The effect is roughly the same as defining a
standard function inline; calls to the function are expanded into inline code, much like a
macro. This is principally useful as a way of supporting C++ classes in a DLL that might
inline some of their member functions for efficiency.
One feature of an imported inline function is that you can take its address in C++. The
compiler returns the address of the copy of the inline function residing in the DLL.
Another feature of imported inline functions is that you can initialize static local data of
the imported function, unlike global imported data.
Ｕ Caution
You should exercise care when providing imported inline functions because they
can create the possibility of version conflicts. An inline function gets expanded into
the application code; therefore, if you later rewrite the function, it does not get
updated unless the application itself is recompiled. (Normally, DLL functions can be
updated without rebuilding the applications that use them.)
What do you want to do?
Export from a DLL
Export from a DLL using .DEF files
Export from a DLL using __declspec(dllexport)
Export and import using AFX_EXT_CLASS
Export C++ functions for use in C-language executables
Determine which exporting method to use
Import into an application using __declspec(dllimport)
See also
Importing and Exporting
Active Technology and DLLs
Article • 08/03/2021
Active technology allows object servers to be completely implemented inside a DLL. This
type of server is called an in-process server. MFC does not completely support in￾process servers for all the features of visual editing, mainly because Active technology
does not provide a way for a server to hook into the container's main message loop.
MFC requires access to the container application's message loop to handle accelerator
keys and idle-time processing.
If you are writing an Automation server and your server has no user interface, you can
make your server an in-process server and put it completely into a DLL.
What do you want to know more about?
Automation Servers
See also
Create C/C++ DLLs in Visual Studio
Automation in a DLL
Article • 08/03/2021
When you choose the Automation option in the MFC DLL Wizard, the wizard provides
you with the following:
A starter object description language (.ODL) file
An include directive in the STDAFX.h file for Afxole.h
An implementation of the DllGetClassObject function, which calls the
AfxDllGetClassObject function
An implementation of the DllCanUnloadNow function, which calls the
AfxDllCanUnloadNow function
An implementation of the DllRegisterServer function, which calls the
COleObjectFactory::UpdateRegistryAll function
What do you want to know more about?
Automation Servers
See also
Create C/C++ DLLs in Visual Studio
Calling DLL Functions from Visual Basic
Applications
Article • 08/03/2021
For Visual Basic applications (or applications in other languages such as Pascal or
Fortran) to call functions in a C/C++ DLL, the functions must be exported using the
correct calling convention without any name decoration done by the compiler
__stdcall creates the correct calling convention for the function (the called function
cleans up the stack and parameters are passed from right to left) but decorates the
function name differently. So, when __declspec(dllexport) is used on an exported
function in a DLL, the decorated name is exported.
The __stdcall name decoration prefixes the symbol name with an underscore ( _ ) and
appends the symbol with an at sign (@) character followed by the number of bytes in
the argument list (the required stack space). As a result, the function when declared as:
C
int __stdcall func (int a, double b)
is decorated as _func@12 in the output.
The C calling convention ( __cdecl ) decorates the name as _func .
To get the decorated name, use /MAP. Use of __declspec(dllexport) does the
following:
If the function is exported with the C calling convention ( __cdecl ), it strips the
leading underscore ( _ ) when the name is exported.
If the function being exported does not use the C calling convention (for example,
__stdcall ), it exports the decorated name.
Because there is no way to override where the stack cleanup occurs, you must use
__stdcall . To undecorate names with __stdcall , you must specify them by using
aliases in the EXPORTS section of the .def file. This is shown as follows for the following
function declaration:
C
int __stdcall MyFunc (int a, double b);
void __stdcall InitCode (void);
In the .DEF file:
EXPORTS
 MYFUNC=_MyFunc@12
 INITCODE=_InitCode@0
For DLLs to be called by programs written in Visual Basic, the alias technique shown in
this topic is needed in the .def file. If the alias is done in the Visual Basic program, use of
aliasing in the .def file is not necessary. It can be done in the Visual Basic program by
adding an alias clause to the Declare statement.
What do you want to know more about?
Exporting from a DLL
Exporting from a DLL using .DEF files
Exporting from a DLL using __declspec(dllexport)
Exporting C++ functions for use in C-language executables
Determine which exporting method to use
Decorated names
See also
Create C/C++ DLLs in Visual Studio
Building C/C++ Isolated Applications
and Side-by-side Assemblies
Article • 08/03/2021
Visual Studio supports a deployment model for Windows client applications based on
the idea of isolated applications and side-by-side assemblies. By default, Visual Studio
builds all native C/C++ applications as isolated applications that use manifests to
describe their dependencies on Visual C++ libraries.
Building C/C++ programs as isolated applications presents a range of advantages. For
example, an isolated application is unaffected when other C/C++ applications install or
uninstall Visual C++ libraries. Visual C++ libraries used by isolated applications may still
be redistributed in either the application's local folder, or by installation to the native
assembly cache (WinSxS); however, servicing of Visual C++ libraries for already
deployed applications can be simplified by using a publisher configuration file. The
isolated application deployment model makes it easier to ensure that C/C++
applications that are running on a specific computer use the most recent version of
Visual C++ libraries, while still leaving open the possibility for system administrators and
application authors to control explicit version binding of applications to their dependent
DLLs.
This section discusses how you can build your C/C++ application as an isolated
application and ensure that it binds to Visual C++ libraries using a manifest. The
information in this section primarily applies to native, or unmanaged, C++ applications.
For information about deploying native C++ applications built with Visual Studio, see
Redistributing Visual C++ Files.
In This Section
Concepts of Isolated Applications and Side-by-side Assemblies
Building C/C++ Isolated Applications
Building C/C++ Side-by-side Assemblies
How to: Build Registration-Free COM Components
How to: Build Isolated Applications to Consume COM Components
Understanding Manifest Generation for C/C++ Programs
Troubleshooting C/C++ Isolated Applications and Side-by-side Assemblies
Related Sections
Isolated Applications and Side-by-side Assemblies
Deploying Desktop Applications
Concepts of Isolated Applications and
Side-by-side Assemblies
Article • 08/03/2021
An application is considered an isolated application if all of its components are side-by￾side assemblies. A side-by-side assembly is a collection of resources—a group of DLLs,
windows classes, COM servers, type libraries, or interfaces—that are deployed together
and made available for an application to use at run time. Typically, a side-by-side
assembly is one to several DLLs.
Shared or private
A side-by-side assembly can be either shared or private. Shared side-by-side assemblies
may be used by multiple applications that specify, in their manifests, a dependence on
the assembly. Multiple versions of a side-by-side assembly can be shared by different
applications that are running at the same time. A private assembly is an assembly that is
deployed together with an application for the exclusive use of that application. Private
assemblies are installed in the folder that contains the application's executable file or
one of its subfolders.
Manifests and search order
Both isolated applications and side-by-side assemblies are described by manifests. A
manifest is an XML document that can be an external file or can be embedded in an
application or an assembly as a resource. The manifest file of an isolated application is
used to manage the names and versions of shared side-by-side assemblies to which the
application should bind at run time. The manifest of a side-by-side assembly specifies
names, versions, resources, and dependent assemblies of side-by-side assemblies. For a
shared side-by-side assembly, its manifest is installed in the
%WINDIR%\WinSxS\Manifests\ folder. In the case of a private assembly, we recommend
that you include its manifest in the DLL as a resource that has an ID equal to 1. You can
also give the private assembly the same name as that of the DLL. For more information,
see About Private Assemblies.
At execution time, Windows uses assembly information from the application manifest to
search and load the corresponding side-by-side assembly. If an isolated application
specifies an assembly dependency, the operating system first searches for the assembly
among the shared assemblies in the native assembly cache in the %WINDIR%\WinSxS\
folder. If the required assembly is not found, the operating system then searches for a
private assembly in a folder of the application's directory structure. For more
information, see Assembly Searching Sequence.
Changing dependencies
You can change side-by-side assembly dependencies after an application has been
deployed by modifying the Publisher Configuration Files and Application Configuration
Files. A publisher configuration file, also known as a publisher policy file, is an XML file
that globally redirects applications and assemblies from using one version of a side-by￾side assembly to using another version of the same assembly. For example, you could
change a dependency when a bug fix or security fix is deployed for a side-by-side
assembly and you want to redirect all applications to use the fixed version. An
application configuration file is an XML file that redirects a specific application from
using one version of a side-by-side assembly to using another version of the same
assembly. You can use an application configuration file to redirect a particular
application to use a version of a side-by-side assembly that's different from the one
that's defined in the publisher configuration file. For more information, see
Configuration.
Visual C++ libraries
In Visual Studio 2005 and Visual Studio 2008, redistributable libraries such as ATL, MFC,
CRT, Standard C++, OpenMP, and MSDIA were deployed as shared side-by-side
assemblies to the native assembly cache. In the current version, the redistributable
libraries use central deployment. By default, all applications that are built by using Visual
Studio are built with the manifest embedded in the final binary, and the manifest
describes the dependencies of the binary on the Visual C++ libraries. To understand
manifest generation for C++ applications, see Understanding Manifest Generation for
C/C++ Programs. A manifest is not required for applications that are statically linked to
the libraries that they use, or that use local deployment. For more information about
deployment, see Deployment in Visual C++.
See also
Building C/C++ Isolated Applications and Side-by-side Assemblies
Building C/C++ Isolated Applications
Article • 08/03/2021
An isolated application depends only on side-by-side assemblies and binds to its
dependencies using a manifest. It is not required for your application to be fully isolated
in order to run properly on Windows; however, by investing in making your application
fully isolated, you may save time if you need to service your application in the future. For
more information on the advantages of making your application fully isolated, see
Isolated Applications.
When you build your native C/C++ application using Visual Studio, by default the Visual
Studio project system generates a manifest file that describes your application's
dependencies on Visual Studio libraries. If these are the only dependencies your
application has, then it becomes an isolated application as soon as it is rebuilt with
Visual Studio. If your application is using other libraries at runtime, then you may need
to rebuild those libraries as side-by-side assemblies following the steps described in
Building C/C++ Side-by-side Assemblies.
See also
Concepts of Isolated Applications and Side-by-side Assemblies
Building C/C++ Isolated Applications and Side-by-side Assemblies
Building C/C++ Side-by-side Assemblies
Article • 08/03/2021
A side-by-side assembly is a collection of resources—a group of DLLs, windows classes,
COM servers, type libraries, or interfaces—available for an application to use at runtime.
The primary advantage of repackaging DLLs in assemblies is that multiple versions of
assemblies can be used by applications at the same time and it is possible to service
currently installed assemblies in case of an update release.
A C++ application may use one or several DLLs in different parts of the application. At
runtime, the DLLs are loaded into the main process and the required code is executed.
The application relies on the operating system to locate the requested DLLs, understand
what other dependent DLLs have to be loaded and then load them together with the
requested DLL. On Windows operating systems versions earlier than Windows XP,
Windows Server 2003, and Windows Vista, the operating system loader searches for
dependent DLLs in either the application's local folder or another folder specified on the
system path. On Windows XP, Windows Server 2003, and Windows Vista, the operating
system loader can also search for dependent DLLs using a manifest file and search for
side-by-side assemblies that contain these DLLs.
By default, when a DLL is built with Visual Studio, it has an application manifest
embedded as an RT_MANIFEST resource with ID equal to 2. Just as for an executable,
this manifest describes dependencies of this DLL on other assemblies. This assumes that
the DLL is not part of a side-by-side assembly and applications that depend on this DLL
are not going to use an application manifest to load it, but instead rely on the operating
system loader to find this DLL on the system path.
７ Note
It is important for a DLL that uses an application manifest to have the manifest
embedded as a resource with ID equal to 2. If the DLL is dynamically loaded at
runtime (for example, using the LoadLibrary function), the operating system loader
loads dependent assemblies specified in the DLL's manifest. An external application
manifest for DLLs is not checked during a LoadLibrary call. If the manifest is not
embedded, the loader may attempt to load incorrect versions of assemblies or fail
to find to find dependent assemblies.
One or several related DLLs can be repackaged into a side-by-side assembly with a
corresponding assembly manifest, which describes which files form the assembly as well
as the dependence of the assembly on other side-by-side assemblies.
７ Note
If an assembly contains one DLL, it is recommended to embed the assembly
manifest into this DLL as a resource with ID equal to 1, and give the private
assembly the same name as the DLL. For example, if the name of the DLL is
mylibrary.dll, the value of the name attribute used in the <assemblyIdentity>
element of the manifest may also be mylibrary. In some cases, when a library has an
extension other than .dll (for example, an MFC ActiveX Controls project creates an
.ocx library) an external assembly manifest can be created. In this case, the name of
the assembly and its manifest must be different than the name of the DLL (for
example, MyAssembly, MyAssembly.manifest, and mylibrary.ocx). However it is still
recommended to rename such libraries to have the extension.dll and embed the
manifest as a resource to reduce the future maintenance cost of this assembly. For
more information about how the operating system searches for private assemblies,
see Assembly Searching Sequence.
This change may allow deployment of corresponding DLLs as a private assembly in an
application local folder or as a shared assembly in the WinSxS assembly cache. Several
steps have to be followed in order to achieve correct runtime behavior of this new
assembly; they are described in Guidelines for Creating Side-by-side Assemblies. After
an assembly is correctly authored it can deployed as either a shared or private assembly
together with an application that depends on it. When installing side-by-side assemblies
as a shared assembly, you may either follow the guidelines outlined in Installing Win32
Assemblies for Side-by-Side Sharing on Windows XP or use merge modules. When
installing side-by-side assemblies as a private assembly, you may just copy the
corresponding DLL, resources and assembly manifest as part of the installation process
to the application local folder on the target computer, ensuring that this assembly can
be found by the loader at runtime (see Assembly Searching Sequence). Another way is
to use Windows Installer and follow the guidelines outlined in Installing Win32
Assemblies for the Private Use of an Application on Windows XP.
See also
Building C/C++ Isolated Applications
Building C/C++ Isolated Applications and Side-by-side Assemblies
How to: Build Registration-Free COM
Components
Article • 08/03/2021
Registration-free COM components are COM components that have manifests built into
the DLLs.
To build manifests into COM components
1. Open the project property pages for the COM component.
2. Expand the Configuration Properties node, and then expand the Manifest Tool
node.
3. Select the Input and Output property page, and then set the Embed Manifest
property equal to Yes.
4. Click OK.
5. Build the solution.
See also
How to: Build Isolated Applications to Consume COM Components
How to: Build Isolated Applications to
Consume COM Components
Article • 08/03/2021
Isolated applications are applications that have manifests built into the program. You
can create isolated applications to consume COM components.
To add COM references to manifests of isolated
applications
1. Open the project property pages for the isolated application.
2. Expand the Configuration Properties node, and then expand the Manifest Tool
node.
3. Select the Isolated COM property page, and then set the Component File Name
property to the name of the COM component that you want the isolated
application to consume.
4. Click OK.
To build manifests into isolated applications
1. Open the project property pages for the isolated application.
2. Expand the Configuration Properties node, and then expand the Manifest Tool
node.
3. Select the Input and Output property page, and then set the Embed Manifest
property equal to Yes.
4. Click OK.
5. Build the solution.
See also
Isolated Applications
About Side-by-Side Assemblies
Understanding manifest generation for
C/C++ programs
Article • 06/14/2022
A manifest is an XML document that uniquely identifies an assembly. It contains
information used for binding and activation, such as COM classes, interfaces, and type
libraries. A manifest can be an external XML file or a resource embedded inside an
application or an assembly. The manifest of an isolated application is used to manage
the names and versions of shared side-by-side assemblies the application should bind
to at run time. The manifest of a side-by-side assembly specifies its dependencies on
names, versions, resources, and other assemblies.
There are two ways to create a manifest for an isolated application or a side-by-side
assembly. First, the author of the assembly can manually create a manifest file by
following the rules and naming requirements. For more information, see Manifest files
reference. Alternatively, if a program only depends on MSVC assemblies such as CRT,
MFC, ATL or others, then the linker can generate a manifest automatically.
The headers of MSVC libraries contain assembly information, and when the libraries are
included in application code, this assembly information is used by the linker to form a
manifest for the final binary. By default, the linker doesn't embed the manifest file inside
the binary. Having a manifest as an external file may not work for all scenarios. For
example, it's recommended that private assemblies have embedded manifests. In
command line builds such as ones that use NMAKE to build code, you can use the
/MANIFEST:EMBED linker option to embed the manifest. Alternatively, a manifest can be
embedded using the manifest tool. For more information, see Manifest generation at
the command line. When you build in Visual Studio, a manifest can be embedded by
setting a property for the manifest tool in the Project Properties dialog, as described in
the next section.
Manifest generation in Visual Studio
You can tell Visual Studio to generate a manifest file for a particular project in the
project's Property Pages dialog. Under Configuration Properties, select Linker >
Manifest File > Generate Manifest. By default, the project properties of new projects
are set to generate a manifest file. However it's possible to disable generation of the
manifest for a project by using the Generate Manifest property of the project. When
this property is set to Yes, the manifest for the project is generated. Otherwise the linker
ignores assembly information when resolving dependencies of the application code, and
doesn't generate the manifest.
The build system in Visual Studio allows the manifest to be embedded in the final binary
application file, or generated as an external file. This behavior is controlled by the
Embed Manifest option in the Project Properties dialog. To set this property, open the
Manifest Tool node, then select Input and Output. If the manifest isn't embedded, it's
generated as an external file and saved in the same directory as the final binary. If the
manifest is embedded, Visual Studio embeds the final manifests using the following
process:
1. After the source code is compiled to object files, the linker collects dependent
assembly information. While it links the final binary, the linker generates an
intermediate manifest that's used later to generate the final manifest.
2. After the intermediate manifest and linking are finished, the manifest tool merges
a final manifest and saves it as an external file.
3. The project build system then detects whether the manifest generated by the
manifest tool contains different information than the manifest already embedded
in the binary.
4. If the manifest embedded in the binary is different from the manifest generated by
the manifest tool, or the binary doesn't contain an embedded manifest, Visual
Studio invokes the linker one more time to embed the external manifest file inside
the binary as a resource.
5. If the manifest embedded in the binary is the same as the manifest generated by
the manifest tool, the build continues to the next build steps.
The manifest is embedded inside the final binary as a text resource. You can view it by
opening the final binary as a file in Visual Studio. To ensure that the manifest points to
the correct libraries, follow the steps described in Understanding the dependencies of a
Visual C++ application. Or, follow the suggestions described in the Troubleshooting
article.
Manifest generation at the command line
When you build C/C++ applications from the command line using NMAKE or similar
tools, the manifest is generated after the linker has processed all object files and built
the final binary. The linker collects assembly information stored in the object files and
combines this information into a final manifest file. By default, the linker generates a file
named <binary_name>.<extension>.manifest to describe the final binary. The linker can
embed a manifest file inside the binary by specifying the /MANIFEST:EMBED linker
option.
There are several other ways to embed a manifest inside the final binary, such as using
the Manifest tool (mt.exe) or compiling the manifest into a resource file. You must follow
specific rules when you embed a manifest to enable features such as incremental
linking, signing, and Edit and Continue. These rules and other options are discussed in
the next section.
How to embed a manifest inside a C/C++
application
We recommended that you embed the manifest of your application or library inside the
final binary. This approach guarantees correct runtime behavior in most scenarios. By
default, Visual Studio tries to embed the manifest when it builds a project. However, if
you build your application by using NMAKE, you have to make some changes to the
makefile. This section shows how to change the makefiles so that it automatically
embeds the manifest inside the final binary.
Two approaches
There are two ways to embed the manifest inside an application or library.
1. If you aren't doing an incremental build, you can directly embed the manifest
using a command line similar to the following as a post-build step:
Windows Command Prompt
mt.exe -manifest MyApp.exe.manifest -outputresource:MyApp.exe;1
or
Windows Command Prompt
mt.exe -manifest MyLibrary.dll.manifest -outputresource:MyLibrary.dll;2
Use 1 for an EXE and 2 for a DLL.
2. If you're doing an incremental build, use the following steps:
Link the binary to generate the MyApp.exe.manifest file.
Convert the manifest to a resource file.
Relink (incrementally) to embed the manifest resource into the binary.
The following examples show how to change makefiles to incorporate both techniques.
Makefiles (Before)
Consider the NMAKE script for MyApp.exe , a simple application built from one file:
makefile
# build MyApp.exe
!if "$(DEBUG)" == "1"
CPPFLAGS=$(CPPFLAGS) /MDd
LFLAGS=$(LFLAGS) /INCREMENTAL
!else
CPPFLAGS=$(CPPFLAGS) /MD
!endif
MyApp.exe : MyApp.obj
 link $** /out:$@ $(LFLAGS)
MyApp.obj : MyApp.cpp
clean :
 del MyApp.obj MyApp.exe
If this script is run unchanged with Visual Studio, it successfully creates MyApp.exe . It also
creates the external manifest file MyApp.exe.manifest , for use by the operating system to
load dependent assemblies at runtime.
The NMAKE script for MyLibrary.dll looks similar:
makefile
# build MyLibrary.dll
!if "$(DEBUG)" == "1"
CPPFLAGS=$(CPPFLAGS) /MDd
LFLAGS=$(LFLAGS) /DLL /INCREMENTAL
!else
CPPFLAGS=$(CPPFLAGS) /MD
LFLAGS=$(LFLAGS) /DLL
!endif
MyLibrary.dll : MyLibrary.obj
 link $** /out:$@ $(LFLAGS)
To build with embedded manifests, you have to make four small changes to the original
makefiles. For the MyApp.exe makefile:
makefile
For the MyLibrary.dll makefile:
makefile
MyLibrary.obj : MyLibrary.cpp
clean :
 del MyLibrary.obj MyLibrary.dll
Makefiles (After)
# build MyApp.exe
!include makefile.inc
#^^^^^^^^^^^^^^^^^^^^ Change #1. (Add full path if necessary.)
!if "$(DEBUG)" == "1"
CPPFLAGS=$(CPPFLAGS) /MDd
LFLAGS=$(LFLAGS) /INCREMENTAL
!else
CPPFLAGS=$(CPPFLAGS) /MD
!endif
MyApp.exe : MyApp.obj
 link $** /out:$@ $(LFLAGS)
 $(_VC_MANIFEST_EMBED_EXE)
#^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Change #2
MyApp.obj : MyApp.cpp
clean :
 del MyApp.obj MyApp.exe
 $(_VC_MANIFEST_CLEAN)
#^^^^^^^^^^^^^^^^^^^^^^^^ Change #3
!include makefile.target.inc
#^^^^^^^^^^^^^^^^^^^^^^^^^ Change #4. (Add full path if necessary.)
# build MyLibrary.dll
!include makefile.inc
#^^^^^^^^^^^^^^^^^^^^ Change #1. (Add full path if necessary.)
!if "$(DEBUG)" == "1"
CPPFLAGS=$(CPPFLAGS) /MDd
LFLAGS=$(LFLAGS) /DLL /INCREMENTAL
The makefiles now include two files that do the real work, makefile.inc and
makefile.target.inc .
Create makefile.inc and copy the following content into it:
makefile
!else
CPPFLAGS=$(CPPFLAGS) /MD
LFLAGS=$(LFLAGS) /DLL
!endif
MyLibrary.dll : MyLibrary.obj
 link $** /out:$@ $(LFLAGS)
 $(_VC_MANIFEST_EMBED_DLL)
#^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Change #2.
MyLibrary.obj : MyLibrary.cpp
clean :
 del MyLibrary.obj MyLibrary.dll
 $(_VC_MANIFEST_CLEAN)
#^^^^^^^^^^^^^^^^^^^^^^^^ Change #3.
!include makefile.target.inc
#^^^^^^^^^^^^^^^^^^^^^^^^^ Change #4. (Add full path if necessary.)
# makefile.inc -- Include this file into existing makefile at the very top.
# _VC_MANIFEST_INC specifies whether build is incremental (1 - incremental).
# _VC_MANIFEST_BASENAME specifies name of a temporary resource file.
!if "$(DEBUG)" == "1"
CPPFLAGS=$(CPPFLAGS) /MDd
LFLAGS=$(LFLAGS) /INCREMENTAL
_VC_MANIFEST_INC=1
_VC_MANIFEST_BASENAME=__VC90.Debug
!else
CPPFLAGS=$(CPPFLAGS) /MD
_VC_MANIFEST_INC=0
_VC_MANIFEST_BASENAME=__VC90
!endif
####################################################
# Specifying name of temporary resource file used only in incremental
builds:
!if "$(_VC_MANIFEST_INC)" == "1"
Now create makefile.target.inc and copy the following content into it:
makefile
_VC_MANIFEST_AUTO_RES=$(_VC_MANIFEST_BASENAME).auto.res
!else
_VC_MANIFEST_AUTO_RES=
!endif
####################################################
# _VC_MANIFEST_EMBED_EXE - command to embed manifest in EXE:
!if "$(_VC_MANIFEST_INC)" == "1"
#MT_SPECIAL_RETURN=1090650113
#MT_SPECIAL_SWITCH=-notify_resource_update
MT_SPECIAL_RETURN=0
MT_SPECIAL_SWITCH=
_VC_MANIFEST_EMBED_EXE= \
if exist $@.manifest mt.exe -manifest $@.manifest -
out:$(_VC_MANIFEST_BASENAME).auto.manifest $(MT_SPECIAL_SWITCH) & \
if "%ERRORLEVEL%" == "$(MT_SPECIAL_RETURN)" \
rc /r $(_VC_MANIFEST_BASENAME).auto.rc & \
link $** /out:$@ $(LFLAGS)
!else
_VC_MANIFEST_EMBED_EXE= \
if exist $@.manifest mt.exe -manifest $@.manifest -outputresource:$@;1
!endif
####################################################
# _VC_MANIFEST_CLEAN - command to clean resources files generated
temporarily:
!if "$(_VC_MANIFEST_INC)" == "1"
_VC_MANIFEST_CLEAN=-del $(_VC_MANIFEST_BASENAME).auto.res \
 $(_VC_MANIFEST_BASENAME).auto.rc \
 $(_VC_MANIFEST_BASENAME).auto.manifest
!else
_VC_MANIFEST_CLEAN=
!endif
# End of makefile.inc
####################################################
# makefile.target.inc - include this at the very bottom of the existing
makefile
####################################################
# Commands to generate initial empty manifest file and the RC file
# that references it, and for generating the .res file:
$(_VC_MANIFEST_BASENAME).auto.res : $(_VC_MANIFEST_BASENAME).auto.rc
$(_VC_MANIFEST_BASENAME).auto.rc : $(_VC_MANIFEST_BASENAME).auto.manifest
 type <<$@
#include <winuser.h>
1RT_MANIFEST"$(_VC_MANIFEST_BASENAME).auto.manifest"
<< KEEP
$(_VC_MANIFEST_BASENAME).auto.manifest :
 type <<$@
<?xml version='1.0' encoding='UTF-8' standalone='yes'?>
<assembly xmlns='urn:schemas-microsoft-com:asm.v1' manifestVersion='1.0'>
</assembly>
<< KEEP
# end of makefile.target.inc
See also
Building C/C++ isolated applications and side-by-side assemblies
Concepts of isolated applications and side-by-side assemblies
Troubleshooting C/C++ isolated applications and side-by-side assemblies
/INCREMENTAL (Link incrementally)
/MANIFEST (Create side-by-side assembly manifest)
Strong Name assemblies (Assembly signing) (C++/CLI)
Edit and Continue
Troubleshooting C/C++ Isolated
Applications and Side-by-side
Assemblies
Article • 08/03/2021
Loading a C/C++ application can fail if dependent libraries cannot be found. This article
describes some common reasons why a C/C++ application fails to load, and suggests
steps to resolve the problems.
If an application fails to load because it has a manifest that specifies a dependency on a
side-by-side assembly, and the assembly is not installed as a private assembly in the
same folder as the executable nor in the native assembly cache in the
%WINDIR%\WinSxS\ folder, one of the following error messages might be displayed,
depending on the version of Windows on which you try to run the app.
The application failed to initialize properly (0xc0000135).
This application has failed to start because the application configuration is
incorrect. Reinstalling the application may fix this problem.
The system cannot execute the specified program.
If your application has no manifest and depends on a DLL that Windows can't find in the
typical search locations, an error message that resembles this one might be displayed:
This application has failed to start because a required DLL was not found. Re￾installing the application may fix this problem.
If your application is deployed on a computer that doesn't have Visual Studio, and it
crashes with error messages that resemble the previous ones, check these things:
1. Follow the steps that are described in Understanding the Dependencies of a Visual
C++ Application. The dependency walker can show most dependencies for an
application or DLL. If you observe that some DLLs are missing, install them on the
computer on which you are trying to run your application.
2. The operating system loader uses the application manifest to load assemblies that
the application depends on. The manifest can either be embedded in the binary as
a resource, or installed as a separate file in the application folder. To check whether
the manifest is embedded in the binary, open the binary in Visual Studio and look
for RT_MANIFEST in its list of resources. If you can't find an embedded manifest,
look in the application folder for a file that's named something like
<binary_name>.<extension>.manifest.
3. If your application depends on side-by-side assemblies and a manifest is not
present, you have to ensure that the linker generates a manifest for your project.
Check the linker option Generate manifest in the Project Properties dialog box for
the project.
4. If the manifest is embedded in the binary, ensure that the ID of RT_MANIFEST is
correct for this type of the binary. For more information about which resource ID
to use, see Using Side-by-Side Assemblies as a Resource (Windows). If the manifest
is in a separate file, open it in an XML editor or text editor. For more information
about manifests and rules for deployment, see Manifests.
７ Note
If both an embedded manifest and a separate manifest file are present, the
operating system loader uses the embedded manifest and ignores the
separate file. However, on Windows XP, the opposite is true—the separate
manifest file is used and the embedded manifest is ignored.
5. We recommend that you embed a manifest in every DLL because external
manifests are ignored when a DLL is loaded though a LoadLibrary call. For more
information, see Assembly manifests.
6. Check that all assemblies that are enumerated in the manifest are correctly
installed on the computer. Each assembly is specified in the manifest by its name,
version number, and processor architecture. If your application depends on side￾by-side assemblies, check that these assemblies are correctly installed on the
computer so that the operating system loader can find them, as described in
Assembly Searching Sequence. Remember that 64-bit assemblies cannot be loaded
in 32-bit processes and cannot be executed on 32-bit operating systems.
Example
Assume we have an application, appl.exe, that's built by using Visual C++. The
application manifest either is embedded in appl.exe as the binary resource
RT_MANIFEST, which has an ID equal to 1, or is stored as the separate file
appl.exe.manifest. The content of this manifest resembles this:
<assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
 <dependency>
 <dependentAssembly>
 <assemblyIdentity type="win32" name="Fabrikam.SxS.Library"
version="2.0.20121.0" processorArchitecture="x86"
publicKeyToken="1fc8b3b9a1e18e3e"></assemblyIdentity>
 </dependentAssembly>
 </dependency>
</assembly>
To the operating system loader, this manifest says that appl.exe depends on an
assembly named Fabrikam.SxS.Library, version 2.0.20121.0, that's built for a 32-bit x86
processor architecture. The dependent side-by-side assembly can be installed either as a
shared assembly or as a private assembly.
The assembly manifest for a shared assembly is installed in the
%WINDIR%\WinSxS\Manifests\ folder. It identifies the assembly and lists its contents—
that is, the DLLs that are part of the assembly:
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
 <noInheritable/>
 <assemblyIdentity type="win32" name="Fabrikam.SxS.Library"
version="2.0.20121.0" processorArchitecture="x86"
publicKeyToken="1fc8b3b9a1e18e3e"/>
 <file name="Fabrikam.Main.dll"
hash="3ca5156e8212449db6c622c3d10f37d9adb1ab12" hashalg="SHA1"/>
 <file name="Fabrikam.Helper.dll"
hash="92cf8a9bb066aea821d324ca4695c69e55b2d1c2" hashalg="SHA1"/>
</assembly>
Side-by-side assemblies can also use publisher configuration files—also known as policy
files—to globally redirect applications and assemblies to use one version of a side-by￾side assembly instead of another version of the same assembly. You can check the
policies for a shared assembly in the %WINDIR%\WinSxS\Policies\ folder. Here is an
example policy file:
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
 <assemblyIdentity type="win32-policy"
name="policy.2.0.Fabrikam.SxS.Library" version="2.0.20121.0"
processorArchitecture="x86" publicKeyToken="1fc8b3b9a1e18e3e"/>
 <dependency>
 <dependentAssembly>
 <assemblyIdentity type="win32" name="Fabrikam.SxS.Library"
processorArchitecture="x86" publicKeyToken="1fc8b3b9a1e18e3e"/>
 <bindingRedirect oldVersion="2.0.10000.0-2.0.20120.99"
newVersion="2.0.20121.0"/>
 </dependentAssembly>
 </dependency>
</assembly>
This policy file specifies that any application or assembly that asks for version
2.0.10000.0 of this assembly should instead use version 2.0.20121.0, which is the current
version that's installed on the system. If a version of the assembly that's mentioned in
the application manifest is specified in the policy file, the loader looks for a version of
this assembly that's specified in the manifest in the %WINDIR%\WinSxS\ folder, and if
this version is not installed, load fails. And if assembly version 2.0.20121.0 is not
installed, load fails for applications that ask for assembly version 2.0.10000.0.
However, the assembly can also be installed as a private side-by-side assembly in the
installed application folder. If the operating system fails to find the assembly as a shared
assembly, it looks for it as a private assembly, in the following order:
1. Check the application folder for a manifest file that has the name
<assemblyName>.manifest. In this example, the loader tries to find
Fabrikam.SxS.Library.manifest in the folder that contains appl.exe. If it finds the
manifest, the loader loads the assembly from the application folder. If the
assembly is not found, load fails.
2. Try to open the \<assemblyName>\ folder in the folder that contains appl.exe, and
if \<assemblyName>\ exists, try to load a manifest file that has the name
<assemblyName>.manifest from this folder. If the manifest is found, the loader
loads the assembly from the \<assemblyName>\ folder. If the assembly is not
found, load fails.
For more information about how the loader searches for dependent assemblies, see
Assembly Searching Sequence. If the loader fails to find a dependent assembly as a
private assembly, load fails and the message "The system cannot execute the specified
program" is displayed. To resolve this error, make sure that dependent assemblies—and
DLLs that are part of them—are installed on the computer as either private or shared
assemblies.
See also
Concepts of Isolated Applications and Side-by-side Assemblies
Building C/C++ Isolated Applications and Side-by-side Assemblies
Configure C++ projects for 64-bit, x64
targets
Article • 08/03/2021
This section contains topics about targeting 64-bit x64 hardware with the Visual C++
build tools.
In This Section
How to: Configure Visual C++ Projects to Target 64-Bit, x64 Platforms
How to: Enable a 64-bit, x64-hosted MSVC toolset on the command line
Common Visual C++ 64-bit Migration Issues
x64 Software Conventions
Related Sections
.NET Framework 64-bit Applications
align
/clr (Common Language Runtime Compilation)
/favor (Optimize for Architecture Specifics)
Programming Guide for 64-bit Windows
MASM for x64 (ml64.exe)
x64 (amd64) Intrinsics List
See also
Projects and build systems
How to: Configure Visual Studio C++
projects to Target 64-Bit, x64 Platforms
Article • 08/03/2021
You can use the project configurations in the Visual Studio IDE to set up C++
applications to target 64-bit, x64 platforms. You can also migrate Win32 project settings
into a 64-bit project configuration.
To set up C++ applications to target 64-bit platforms
1. Open the C++ project that you want to configure.
2. Open the property pages for that project. For more information, see Set C++
compiler and build properties in Visual Studio.
７ Note
For .NET projects, make sure that the Configuration Properties node, or one
of its child nodes, is selected in the <Projectname> Property Pages dialog
box; otherwise, the Configuration Manager button remains unavailable.
3. Choose the Configuration Manager button to open the Configuration Manager
dialog box.
4. In the Active Solution Platform drop-down list, select the <New...> option to
open the New Solution Platform dialog box.
5. In the Type or select the new platform drop-down list, select a 64-bit target
platform.
７ Note
In the New Solution Platform dialog box, you can use the Copy settings from
option to copy existing project settings into the new 64-bit project
configuration.
6. Choose the OK button. The platform that you selected in the preceding step
appears under Active Solution Platform in the Configuration Manager dialog box.
7. Choose the Close button in the Configuration Manager dialog box, and then
choose the OK button in the <Projectname> Property Pages dialog box.
To copy Win32 project settings into a 64-bit project
configuration
When the New Solution Platform dialog box is open while you set up a project to
target a 64-bit platform, in the Copy settings from drop-down list, select Win32.
These project settings are automatically updated on the project level:
The /MACHINE linker option is set to /MACHINE:X64.
Register Output is turned OFF. For more information, see Linker Property Pages.
Target Environment is set to /env x64. For more information, see MIDL Property
Pages.
Validate Parameters is cleared and reset to the default value. For more
information, see MIDL Property Pages.
If Debug Information Format was set to /ZI in the Win32 project configuration,
then it is set to /Zi in the 64-bit project configuration. For more information, see
/Z7, /Zi, /ZI (Debug Information Format).
７ Note
None of these project properties are changed if they are overridden on the
file level.
See also
Configure C++ projects for 64-bit, x64 targets
Debug 64-Bit Applications
How to: Enable a 64-Bit, x64 hosted
MSVC toolset on the command line
Article • 10/16/2023
Visual Studio includes C++ compilers, linkers, and other tools that you can use to create
platform-specific versions of your apps that can run on 32-bit, 64-bit, or ARM-based
Windows operating systems. Other optional Visual Studio workloads let you use C++
tools to target other platforms, such as iOS, Android, and Linux. The default build
architecture uses 32-bit, x86-hosted tools to build 32-bit, x86-native Windows code.
However, you probably have a 64-bit computer. When Visual Studio is installed on a 64-
bit Windows operating system, additional developer command prompt shortcuts for the
64-bit, x64-hosted native and cross compilers are available. You can take advantage of
the processor and memory space available to 64-bit code by using the 64-bit, x64-
hosted toolset when you build code for x86, x64, or ARM processors.
Use a 64-bit hosted developer command
prompt shortcut
To access these command prompts on Windows, on the Start menu type x64 and then
choose one of the x64 native or cross-tool developer command prompts.
On earlier versions of Windows, choose Start, expand All Programs, and then expand
the folder for your version of Visual Studio (and on older versions of Visual Studio,
Visual Studio Tools). For more information, see Developer command prompt shortcuts.
Use Vcvarsall.bat to set a 64-bit hosted build
architecture
Any of the native or cross compiler tools build configurations can be used on the
command line by running the vcvarsall.bat command file. This command file configures
the path and environment variables that enable a particular build architecture in an
existing command prompt window. For specific instructions, see Developer command
file locations.
Remarks
７ Note
For information about the specific tools that are included with each Visual Studio
edition, see Visual C++ Tools and Features in Visual Studio Editions.
For information about how to use the Visual Studio IDE to create 64-bit
applications, see How to: Configure Visual C++ Projects to Target 64-Bit, x64
Platforms.
When you install a C++ workload in the Visual Studio installer, it always installs 32-bit,
x86-hosted, native and cross compiler tools to build x86 and x64 code. If you include the
Universal Windows Platform workload, it also installs x86-hosted cross compiler tools to
build ARM code. If you install these workloads on a 64-bit, x64 processor, you also get
64-bit native and cross compiler tools to build x86, x64, and ARM code. The 32-bit and
64-bit tools generate identical code, but the 64-bit tools support more memory for
precompiled header symbols and the Whole Program Optimization (/GL and /LTCG)
options. If you run into memory limits when you use the 32-bit tools, try the 64-bit
tools.
See also
Configure C++ projects for 64-bit, x64 targets
Common Visual C++ 64-bit Migration
Issues
Article • 08/03/2021
When you use the Microsoft C++ compiler (MSVC) to create applications to run on a
64-bit Windows operating system, you should be aware of the following issues:
An int and a long are 32-bit values on 64-bit Windows operating systems. For
programs that you plan to compile for 64-bit platforms, you should be careful not
to assign pointers to 32-bit variables. Pointers are 64-bit on 64-bit platforms, and
you will truncate the pointer value if you assign it to a 32-bit variable.
size_t , time_t , and ptrdiff_t are 64-bit values on 64-bit Windows operating
systems.
time_t is a 32-bit value on 32-bit Windows operating systems in Visual Studio
2005 and earlier. time_t is now a 64-bit integer by default. For more information,
see Time Management.
You should be aware of where your code takes an int value and processes it as a
size_t or time_t value. It is possible that the number could grow to be larger
than a 32-bit number and data will be truncated when it is passed back to the int
storage.
The %x (hex int format) printf modifier will not work as expected on a 64-bit
Windows operating system. It will only operate on the first 32 bits of the value that is
passed to it.
Use %I32x to display a 32-bit integral type in hex format.
Use %I64x to display a 64-bit integral type in hex format.
The %p (hex format for a pointer) will work as expected on a 64-bit Windows
operating system.
For more information, see:
MSVC Compiler Options
Migration Tips
See also
Configure C++ projects for 64-bit, x64 targets
Visual C++ Porting and Upgrading Guide
Overview of x64 ABI conventions
Article • 04/22/2022
This topic describes the basic application binary interface (ABI) for x64, the 64-bit
extension to the x86 architecture. It covers topics such as the calling convention, type
layout, stack and register usage, and more.
x64 calling conventions
Two important differences between x86 and x64 are:
64-bit addressing capability
Sixteen 64-bit registers for general use.
Given the expanded register set, x64 uses the __fastcall calling convention and a RISC￾based exception-handling model.
The __fastcall convention uses registers for the first four arguments, and the stack
frame to pass more arguments. For details on the x64 calling convention, including
register usage, stack parameters, return values, and stack unwinding, see x64 calling
convention.
Enable x64 compiler optimization
The following compiler option helps you optimize your application for x64:
/favor (Optimize for Architecture Specifics)
x64 type and storage layout
This section describes the storage of data types for the x64 architecture.
Scalar types
Although it's possible to access data with any alignment, align data on its natural
boundary, or a multiple of its natural boundary, to avoid performance loss. Enums are
constant integers and are treated as 32-bit integers. The following table describes the
type definition and recommended storage for data as it pertains to alignment using the
following alignment values:
Byte - 8 bits
Word - 16 bits
Doubleword - 32 bits
Quadword - 64 bits
Octaword - 128 bits
Scalar type C data type Storage size (in
bytes)
Recommended
alignment
INT8 char 1 Byte
UINT8 unsigned char 1 Byte
INT16 short 2 Word
UINT16 unsigned short 2 Word
INT32 int , long 4 Doubleword
UINT32 unsigned int , unsigned
long
4 Doubleword
INT64 __int64 8 Quadword
UINT64 unsigned __int64 8 Quadword
FP32 (single
precision)
float 4 Doubleword
FP64 (double
precision)
double 8 Quadword
POINTER * 8 Quadword
__m64 struct __m64 8 Quadword
__m128 struct __m128 16 Octaword
Other types, such as arrays, structs, and unions, have stricter alignment requirements
that ensure consistent aggregate and union storage and data retrieval. Here are the
definitions for array, structure, and union:
Array
Contains an ordered group of adjacent data objects. Each object is called an
element. All elements within an array have the same size and data type.
x64 aggregate and union layout
Structure
Contains an ordered group of data objects. Unlike the elements of an array, the
members of a structure can have different data types and sizes.
Union
An object that holds any one of a set of named members. The members of the
named set can be of any type. The storage allocated for a union is equal to the
storage required for the largest member of that union, plus any padding required
for alignment.
The following table shows the strongly recommended alignment for the scalar members
of unions and structures.
Scalar Type C Data Type Required Alignment
INT8 char Byte
UINT8 unsigned char Byte
INT16 short Word
UINT16 unsigned short Word
INT32 int , long Doubleword
UINT32 unsigned int , unsigned long Doubleword
INT64 __int64 Quadword
UINT64 unsigned __int64 Quadword
FP32 (single precision) float Doubleword
FP64 (double precision) double Quadword
POINTER * Quadword
__m64 struct __m64 Quadword
__m128 struct __m128 Octaword
The following aggregate alignment rules apply:
The alignment of an array is the same as the alignment of one of the elements of
the array.
The alignment of the beginning of a structure or a union is the maximum
alignment of any individual member. Each member within the structure or union
must be placed at its proper alignment as defined in the previous table, which may
require implicit internal padding, depending on the previous member.
Structure size must be an integral multiple of its alignment, which may require
padding after the last member. Since structures and unions can be grouped in
arrays, each array element of a structure or union must begin and end at the
proper alignment previously determined.
It's possible to align data in such a way as to be greater than the alignment
requirements as long as the previous rules are maintained.
An individual compiler may adjust the packing of a structure for size reasons. For
example, /Zp (Struct Member Alignment) allows for adjusting the packing of
structures.
The following four examples each declare an aligned structure or union, and the
corresponding figures illustrate the layout of that structure or union in memory. Each
column in a figure represents a byte of memory, and the number in the column
indicates the displacement of that byte. The name in the second row of each figure
corresponds to the name of a variable in the declaration. The shaded columns indicate
padding that is required to achieve the specified alignment.
C
x64 structure alignment examples
Example 1
// Total size = 2 bytes, alignment = 2 bytes (word).
_declspec(align(2)) struct {
 short a; // +0; size = 2 bytes
}
Example 2
C
C
C
// Total size = 24 bytes, alignment = 8 bytes (quadword).
_declspec(align(8)) struct {
 int a; // +0; size = 4 bytes
 double b; // +8; size = 8 bytes
 short c; // +16; size = 2 bytes
}
Example 3
// Total size = 12 bytes, alignment = 4 bytes (doubleword).
_declspec(align(4)) struct {
 char a; // +0; size = 1 byte
 short b; // +2; size = 2 bytes
 char c; // +4; size = 1 byte
 int d; // +8; size = 4 bytes
}
Example 4
// Total size = 8 bytes, alignment = 8 bytes (quadword).
_declspec(align(8)) union {
 char *p; // +0; size = 8 bytes
 short s; // +0; size = 2 bytes
 long l; // +0; size = 4 bytes
}
Bitfields
Structure bit fields are limited to 64 bits and can be of type signed int, unsigned int,
int64, or unsigned int64. Bit fields that cross the type boundary will skip bits to align the
bitfield to the next type alignment. For example, integer bitfields may not cross a 32-bit
boundary.
Conflicts with the x86 compiler
Data types that are larger than 4 bytes aren't automatically aligned on the stack when
you use the x86 compiler to compile an application. Because the architecture for the x86
compiler is a 4 byte aligned stack, anything larger than 4 bytes, for example, a 64-bit
integer, can't be automatically aligned to an 8-byte address.
Working with unaligned data has two implications.
It may take longer to access unaligned locations than it takes to access aligned
locations.
Unaligned locations can't be used in interlocked operations.
If you require more strict alignment, use __declspec(align(N)) on your variable
declarations. This causes the compiler to dynamically align the stack to meet your
specifications. However, dynamically adjusting the stack at run time may cause slower
execution of your application.
x64 register usage
The x64 architecture provides for 16 general-purpose registers (hereafter referred to as
integer registers) as well as 16 XMM/YMM registers available for floating-point use.
Volatile registers are scratch registers presumed by the caller to be destroyed across a
call. Nonvolatile registers are required to retain their values across a function call and
must be saved by the callee if used.
Register volatility and preservation
The following table describes how each register is used across function calls:
Register Status Use
RAX Volatile Return value register
RCX Volatile First integer argument
RDX Volatile Second integer argument
R8 Volatile Third integer argument
R9 Volatile Fourth integer argument
R10:R11 Volatile Must be preserved as needed by caller; used in
syscall/sysret instructions
R12:R15 Nonvolatile Must be preserved by callee
RDI Nonvolatile Must be preserved by callee
RSI Nonvolatile Must be preserved by callee
RBX Nonvolatile Must be preserved by callee
RBP Nonvolatile May be used as a frame pointer; must be preserved
by callee
RSP Nonvolatile Stack pointer
XMM0, YMM0 Volatile First FP argument; first vector-type argument when
__vectorcall is used
XMM1, YMM1 Volatile Second FP argument; second vector-type argument
when __vectorcall is used
XMM2, YMM2 Volatile Third FP argument; third vector-type argument
when __vectorcall is used
XMM3, YMM3 Volatile Fourth FP argument; fourth vector-type argument
when __vectorcall is used
XMM4, YMM4 Volatile Must be preserved as needed by caller; fifth vector￾type argument when __vectorcall is used
XMM5, YMM5 Volatile Must be preserved as needed by caller; sixth
vector-type argument when __vectorcall is used
XMM6:XMM15,
YMM6:YMM15
Nonvolatile (XMM),
Volatile (upper half of
YMM)
Must be preserved by callee. YMM registers must
be preserved as needed by caller.
On function exit and on function entry to C Runtime Library calls and Windows system
calls, the direction flag in the CPU flags register is expected to be cleared.
Stack usage
For details on stack allocation, alignment, function types and stack frames on x64, see
x64 stack usage.
Prolog and epilog
Every function that allocates stack space, calls other functions, saves nonvolatile
registers, or uses exception handling must have a prolog whose address limits are
described in the unwind data associated with the respective function table entry, and
epilogs at each exit to a function. For details on the required prolog and epilog code on
x64, see x64 prolog and epilog.
x64 exception handling
For information on the conventions and data structures used to implement structured
exception handling and C++ exception handling behavior on the x64, see x64 exception
handling.
Intrinsics and inline assembly
One of the constraints for the x64 compiler is no inline assembler support. This means
that functions that can't be written in C or C++ will either have to be written as
subroutines or as intrinsic functions supported by the compiler. Certain functions are
performance sensitive while others aren't. Performance-sensitive functions should be
implemented as intrinsic functions.
The intrinsics supported by the compiler are described in Compiler intrinsics.
x64 image format
The x64 executable image format is PE32+. Executable images (both DLLs and EXEs) are
restricted to a maximum size of 2 gigabytes, so relative addressing with a 32-bit
displacement can be used to address static image data. This data includes the import
address table, string constants, static global data, and so on.
See also
Calling Conventions
x64 calling convention
Article • 05/18/2022
This section describes the standard processes and conventions that one function (the
caller) uses to make calls into another function (the callee) in x64 code.
For more information on the __vectorcall calling convention, see __vectorcall.
Calling convention defaults
The x64 Application Binary Interface (ABI) uses a four-register fast-call calling
convention by default. Space is allocated on the call stack as a shadow store for callees
to save those registers.
There's a strict one-to-one correspondence between a function call's arguments and the
registers used for those arguments. Any argument that doesn't fit in 8 bytes, or isn't 1, 2,
4, or 8 bytes, must be passed by reference. A single argument is never spread across
multiple registers.
The x87 register stack is unused. It may be used by the callee, but consider it volatile
across function calls. All floating point operations are done using the 16 XMM registers.
Integer arguments are passed in registers RCX, RDX, R8, and R9. Floating point
arguments are passed in XMM0L, XMM1L, XMM2L, and XMM3L. 16-byte arguments are
passed by reference. Parameter passing is described in detail in Parameter passing.
These registers, and RAX, R10, R11, XMM4, and XMM5, are considered volatile, or
potentially changed by a callee on return. Register usage is documented in detail in x64
register usage and Caller/callee saved registers.
For prototyped functions, all arguments are converted to the expected callee types
before passing. The caller is responsible for allocating space for the callee's parameters.
The caller must always allocate sufficient space to store four register parameters, even if
the callee doesn't take that many parameters. This convention simplifies support for
unprototyped C-language functions and vararg C/C++ functions. For vararg or
unprototyped functions, any floating point values must be duplicated in the
corresponding general-purpose register. Any parameters beyond the first four must be
stored on the stack after the shadow store before the call. Vararg function details can be
found in Varargs. Unprototyped function information is detailed in Unprototyped
functions.
Alignment
Most structures are aligned to their natural alignment. The primary exceptions are the
stack pointer and malloc or alloca memory, which are 16-byte aligned to aid
performance. Alignment above 16 bytes must be done manually. Since 16 bytes is a
common alignment size for XMM operations, this value should work for most code. For
more information about structure layout and alignment, see x64 type and storage
layout. For information about the stack layout, see x64 stack usage.
Unwindability
Leaf functions are functions that don't change any non-volatile registers. A non-leaf
function may change non-volatile RSP, for example, by calling a function. Or, it could
change RSP by allocating additional stack space for local variables. To recover non￾volatile registers when an exception is handled, non-leaf functions are annotated with
static data. The data describes how to properly unwind the function at an arbitrary
instruction. This data is stored as pdata, or procedure data, which in turn refers to xdata,
the exception handling data. The xdata contains the unwinding information, and can
point to additional pdata or an exception handler function.
Prologs and epilogs are highly restricted so that they can be properly described in xdata.
The stack pointer must remain 16-byte aligned in any region of code that isn't part of an
epilog or prolog, except within leaf functions. Leaf functions can be unwound simply by
simulating a return, so pdata and xdata aren't required. For details about the proper
structure of function prologs and epilogs, see x64 prolog and epilog. For more
information about exception handling, and the exception handling and unwinding of
pdata and xdata, see x64 exception handling.
Parameter passing
By default, the x64 calling convention passes the first four arguments to a function in
registers. The registers used for these arguments depend on the position and type of
the argument. Remaining arguments get pushed on the stack in right-to-left order.
Integer valued arguments in the leftmost four positions are passed in left-to-right order
in RCX, RDX, R8, and R9, respectively. The fifth and higher arguments are passed on the
stack as previously described. All integer arguments in registers are right-justified, so the
callee can ignore the upper bits of the register and access only the portion of the
register necessary.
Any floating-point and double-precision arguments in the first four parameters are
passed in XMM0 - XMM3, depending on position. Floating-point values are only placed
in the integer registers RCX, RDX, R8, and R9 when there are varargs arguments. For
details, see Varargs. Similarly, the XMM0 - XMM3 registers are ignored when the
corresponding argument is an integer or pointer type.
__m128 types, arrays, and strings are never passed by immediate value. Instead, a
pointer is passed to memory allocated by the caller. Structs and unions of size 8, 16, 32,
or 64 bits, and __m64 types, are passed as if they were integers of the same size. Structs
or unions of other sizes are passed as a pointer to memory allocated by the caller. For
these aggregate types passed as a pointer, including __m128 , the caller-allocated
temporary memory must be 16-byte aligned.
Intrinsic functions that don't allocate stack space, and don't call other functions,
sometimes use other volatile registers to pass additional register arguments. This
optimization is made possible by the tight binding between the compiler and the
intrinsic function implementation.
The callee is responsible for dumping the register parameters into their shadow space if
needed.
The following table summarizes how parameters are passed, by type and position from
the left:
Parameter type fifth and
higher
fourth third second leftmost
floating-point stack XMM3 XMM2 XMM1 XMM0
integer stack R9 R8 RDX RCX
Aggregates (8, 16, 32, or 64 bits) and
__m64
stack R9 R8 RDX RCX
Other aggregates, as pointers stack R9 R8 RDX RCX
__m128 , as a pointer stack R9 R8 RDX RCX
C++
Example of argument passing 1 - all integers
func1(int a, int b, int c, int d, int e, int f);
// a in RCX, b in RDX, c in R8, d in R9, f then e pushed on stack
Example of argument passing 2 - all floats
C++
func2(float a, double b, float c, double d, float e, float f);
// a in XMM0, b in XMM1, c in XMM2, d in XMM3, f then e pushed on stack
Example of argument passing 3 - mixed ints and floats
C++
func3(int a, double b, int c, float d, int e, float f);
// a in RCX, b in XMM1, c in R8, d in XMM3, f then e pushed on stack
Example of argument passing 4 - __m64 , __m128 , and
aggregates
C++
func4(__m64 a, __m128 b, struct c, float d, __m128 e, __m128 f);
// a in RCX, ptr to b in RDX, ptr to c in R8, d in XMM3,
// ptr to f pushed on stack, then ptr to e pushed on stack
Varargs
If parameters are passed via varargs (for example, ellipsis arguments), then the normal
register parameter passing convention applies. That convention includes spilling the
fifth and later arguments to the stack. It's the callee's responsibility to dump arguments
that have their address taken. For floating-point values only, both the integer register
and the floating-point register must contain the value, in case the callee expects the
value in the integer registers.
Unprototyped functions
For functions not fully prototyped, the caller passes integer values as integers and
floating-point values as double precision. For floating-point values only, both the
integer register and the floating-point register contain the float value in case the callee
expects the value in the integer registers.
C++
func1();
func2() { // RCX = 2, RDX = XMM1 = 1.0, and R8 = 7
 func1(2, 1.0, 7);
}
Return values
A scalar return value that can fit into 64 bits, including the __m64 type, is returned
through RAX. Non-scalar types including floats, doubles, and vector types such as
__m128, __m128i, __m128d are returned in XMM0. The state of unused bits in the value
returned in RAX or XMM0 is undefined.
User-defined types can be returned by value from global functions and static member
functions. To return a user-defined type by value in RAX, it must have a length of 1, 2, 4,
8, 16, 32, or 64 bits. It must also have no user-defined constructor, destructor, or copy
assignment operator. It can have no private or protected non-static data members, and
no non-static data members of reference type. It can't have base classes or virtual
functions. And, it can only have data members that also meet these requirements. (This
definition is essentially the same as a C++03 POD type. Because the definition has
changed in the C++11 standard, we don't recommend using std::is_pod for this test.)
Otherwise, the caller must allocate memory for the return value and pass a pointer to it
as the first argument. The remaining arguments are then shifted one argument to the
right. The same pointer must be returned by the callee in RAX.
These examples show how parameters and return values are passed for functions with
the specified declarations:
Example of return value 1 - 64-bit result
Output
__int64 func1(int a, float b, int c, int d, int e);
// Caller passes a in RCX, b in XMM1, c in R8, d in R9, e pushed on stack,
// callee returns __int64 result in RAX.
Example of return value 2 - 128-bit result
Output
__m128 func2(float a, double b, int c, __m64 d);
// Caller passes a in XMM0, b in XMM1, c in R8, d in R9,
// callee returns __m128 result in XMM0.
Example of return value 3 - user type result by pointer
Output
struct Struct1 {
 int j, k, l; // Struct1 exceeds 64 bits.
};
Struct1 func3(int a, double b, int c, float d);
// Caller allocates memory for Struct1 returned and passes pointer in RCX,
// a in RDX, b in XMM2, c in R9, d pushed on the stack;
// callee returns pointer to Struct1 result in RAX.
Example of return value 4 - user type result by value
Output
struct Struct2 {
 int j, k; // Struct2 fits in 64 bits, and meets requirements for
return by value.
};
Struct2 func4(int a, double b, int c, float d);
// Caller passes a in RCX, b in XMM1, c in R8, and d in XMM3;
// callee returns Struct2 result by value in RAX.
Caller/callee saved registers
The x64 ABI considers the registers RAX, RCX, RDX, R8, R9, R10, R11, and XMM0-XMM5
volatile. When present, the upper portions of YMM0-YMM15 and ZMM0-ZMM15 are
also volatile. On AVX512VL, the ZMM, YMM, and XMM registers 16-31 are also volatile.
When AMX support is present, the TMM tile registers are volatile. Consider volatile
registers destroyed on function calls unless otherwise safety-provable by analysis such
as whole program optimization.
The x64 ABI considers registers RBX, RBP, RDI, RSI, RSP, R12, R13, R14, R15, and XMM6-
XMM15 nonvolatile. They must be saved and restored by a function that uses them.
Function pointers
Function pointers are simply pointers to the label of the respective function. There's no
table of contents (TOC) requirement for function pointers.
The MMX and floating-point stack registers (MM0-MM7/ST0-ST7) are preserved across
context switches. There's no explicit calling convention for these registers. The use of
these registers is strictly prohibited in kernel mode code.
The register state also includes the x87 FPU control word. The calling convention
dictates this register to be nonvolatile.
The x87 FPU control word register gets set using the following standard values at the
start of program execution:
Register[bits] Setting
FPCSR[0:6] Exception masks all 1's (all exceptions masked)
FPCSR[7] Reserved - 0
FPCSR[8:9] Precision Control - 10B (double precision)
FPCSR[10:11] Rounding control - 0 (round to nearest)
FPCSR[12] Infinity control - 0 (not used)
A callee that modifies any of the fields within FPCSR must restore them before returning
to its caller. Furthermore, a caller that has modified any of these fields must restore
them to their standard values before invoking a callee, unless by agreement the callee
expects the modified values.
There are two exceptions to the rules about the non-volatility of the control flags:
In functions where the documented purpose of the given function is to modify the
nonvolatile FPCSR flags.
When it's provably correct that the violation of these rules results in a program
that behaves the same as a program that doesn't violate the rules, for example,
through whole-program analysis.
The register state also includes MXCSR. The calling convention divides this register into
a volatile portion and a nonvolatile portion. The volatile portion consists of the six status
Floating-point support for older code
FPCSR
MXCSR
flags, in MXCSR[0:5], while the rest of the register, MXCSR[6:15], is considered
nonvolatile.
The nonvolatile portion is set to the following standard values at the start of program
execution:
Register[bits] Setting
MXCSR[6] Denormals are zeros - 0
MXCSR[7:12] Exception masks all 1's (all exceptions masked)
MXCSR[13:14] Rounding control - 0 (round to nearest)
MXCSR[15] Flush to zero for masked underflow - 0 (off)
A callee that modifies any of the nonvolatile fields within MXCSR must restore them
before returning to its caller. Furthermore, a caller that has modified any of these fields
must restore them to their standard values before invoking a callee, unless by
agreement the callee expects the modified values.
There are two exceptions to the rules about the non-volatility of the control flags:
In functions where the documented purpose of the given function is to modify the
nonvolatile MXCSR flags.
When it's provably correct that the violation of these rules results in a program
that behaves the same as a program that doesn't violate the rules, for example,
through whole-program analysis.
Make no assumptions about the MXCSR register's volatile portion state across a
function boundary, unless the function documentation explicitly describes it.
When you include setjmpex.h or setjmp.h, all calls to setjmp or longjmp result in an
unwind that invokes destructors and __finally calls. This behavior differs from x86,
where including setjmp.h results in __finally clauses and destructors not being
invoked.
A call to setjmp preserves the current stack pointer, non-volatile registers, and MXCSR
registers. Calls to longjmp return to the most recent setjmp call site and resets the stack
pointer, non-volatile registers, and MXCSR registers, back to the state as preserved by
the most recent setjmp call.
setjmp/longjmp
See also
x64 software conventions
x64 stack usage
Article • 08/03/2021
All memory beyond the current address of RSP is considered volatile: The OS, or a
debugger, may overwrite this memory during a user debug session, or an interrupt
handler. Thus, RSP must always be set before attempting to read or write values to a
stack frame.
This section discusses the allocation of stack space for local variables and the alloca
intrinsic.
Stack allocation
A function's prolog is responsible for allocating stack space for local variables, saved
registers, stack parameters, and register parameters.
The parameter area is always at the bottom of the stack (even if alloca is used), so that
it will always be adjacent to the return address during any function call. It contains at
least four entries, but always enough space to hold all the parameters needed by any
function that may be called. Note that space is always allocated for the register
parameters, even if the parameters themselves are never homed to the stack; a callee is
guaranteed that space has been allocated for all its parameters. Home addresses are
required for the register arguments so a contiguous area is available in case the called
function needs to take the address of the argument list (va_list) or an individual
argument. This area also provides a convenient place to save register arguments during
thunk execution and as a debugging option (for example, it makes the arguments easy
to find during debugging if they are stored at their home addresses in the prolog code).
Even if the called function has fewer than 4 parameters, these 4 stack locations are
effectively owned by the called function, and may be used by the called function for
other purposes besides saving parameter register values. Thus the caller may not save
information in this region of stack across a function call.
If space is dynamically allocated ( alloca ) in a function, then a nonvolatile register must
be used as a frame pointer to mark the base of the fixed part of the stack and that
register must be saved and initialized in the prolog. Note that when alloca is used, calls
to the same callee from the same caller may have different home addresses for their
register parameters.
The stack will always be maintained 16-byte aligned, except within the prolog (for
example, after the return address is pushed), and except where indicated in Function
Types for a certain class of frame functions.
The following is an example of the stack layout where function A calls a non-leaf
function B. Function A's prolog has already allocated space for all the register and stack
parameters required by B at the bottom of the stack. The call pushes the return address
and B's prolog allocates space for its local variables, nonvolatile registers, and the space
needed for it to call functions. If B uses alloca , the space is allocated between the local
variable/nonvolatile register save area and the parameter stack area.
When the function B calls another function, the return address is pushed just below the
home address for RCX.
Dynamic parameter stack area construction
If a frame pointer is used, the option exists to dynamically create the parameter stack
area. This is not currently done in the x64 compiler.
Function types
There are basically two types of functions. A function that requires a stack frame is called
a frame function. A function that does not require a stack frame is called a leaf function.
A frame function is a function that allocates stack space, calls other functions, saves
nonvolatile registers, or uses exception handling. It also requires a function table entry.
A frame function requires a prolog and an epilog. A frame function can dynamically
allocate stack space and can employ a frame pointer. A frame function has the full
capabilities of this calling standard at its disposal.
If a frame function does not call another function then it is not required to align the
stack (referenced in Section Stack Allocation).
A leaf function is one that does not require a function table entry. It can't make changes
to any nonvolatile registers, including RSP, which means that it can't call any functions
or allocate stack space. It is allowed to leave the stack unaligned while it executes.
malloc alignment
malloc is guaranteed to return memory that's suitably aligned for storing any object that
has a fundamental alignment and that could fit in the amount of memory that's
allocated. A fundamental alignment is an alignment that's less than or equal to the
largest alignment that's supported by the implementation without an alignment
specification. (In Visual C++, this is the alignment that's required for a double , or 8
bytes. In code that targets 64-bit platforms, it's 16 bytes.) For example, a four-byte
allocation would be aligned on a boundary that supports any four-byte or smaller
object.
Visual C++ permits types that have extended alignment, which are also known as over￾aligned types. For example, the SSE types __m128 and __m256 , and types that are
declared by using __declspec(align( n )) where n is greater than 8, have extended
alignment. Memory alignment on a boundary that's suitable for an object that requires
extended alignment is not guaranteed by malloc . To allocate memory for over-aligned
types, use _aligned_malloc and related functions.
alloca
_alloca is required to be 16-byte aligned and additionally required to use a frame
pointer.
The stack that is allocated needs to include space after it for parameters of subsequently
called functions, as discussed in Stack Allocation.
See also
x64 software conventions
align
__declspec
x64 prolog and epilog
Article • 08/03/2021
Every function that allocates stack space, calls other functions, saves nonvolatile
registers, or uses exception handling must have a prolog whose address limits are
described in the unwind data associated with the respective function table entry. For
more information, see x64 exception handling. The prolog saves argument registers in
their home addresses if necessary, pushes nonvolatile registers on the stack, allocates
the fixed part of the stack for locals and temporaries, and optionally establishes a frame
pointer. The associated unwind data must describe the action of the prolog and must
provide the information necessary to undo the effect of the prolog code.
If the fixed allocation in the stack is more than one page (that is, greater than 4096
bytes), then it's possible that the stack allocation could span more than one virtual
memory page and, therefore, the allocation must be checked before it's allocated. A
special routine that's callable from the prolog and which doesn't destroy any of the
argument registers is provided for this purpose.
The preferred method for saving nonvolatile registers is to move them onto the stack
before the fixed stack allocation. If the fixed stack allocation is performed before the
nonvolatile registers are saved, then most probably a 32-bit displacement is required to
address the saved register area. (Reportedly, pushes of registers are as fast as moves
and should remain so for the foreseeable future in spite of the implied dependency
between pushes.) Nonvolatile registers can be saved in any order. However, the first use
of a nonvolatile register in the prolog must be to save it.
Prolog code
The code for a typical prolog might be:
MASM
 mov [RSP + 8], RCX
 push R15
 push R14
 push R13
 sub RSP, fixed-allocation-size
 lea R13, 128[RSP]
 ...
This prolog stores the argument register RCX in its home location, saves nonvolatile
registers R13-R15, allocates the fixed part of the stack frame, and establishes a frame
pointer that points 128 bytes into the fixed allocation area. Using an offset allows more
of the fixed allocation area to be addressed with one-byte offsets.
If the fixed allocation size is greater than or equal to one page of memory, then a helper
function must be called before modifying RSP. This helper, __chkstk , probes the to-be￾allocated stack range to ensure that the stack is extended properly. In that case, the
previous prolog example would instead be:
MASM
 mov [RSP + 8], RCX
 push R15
 push R14
 push R13
 mov RAX, fixed-allocation-size
 call __chkstk
 sub RSP, RAX
 lea R13, 128[RSP]
 ...
The __chkstk helper will not modify any registers other than R10, R11, and the
condition codes. In particular, it will return RAX unchanged and leave all nonvolatile
registers and argument-passing registers unmodified.
Epilog code
Epilog code exists at each exit to a function. Whereas there is normally only one prolog,
there can be many epilogs. Epilog code trims the stack to its fixed allocation size (if
necessary), deallocates the fixed stack allocation, restores nonvolatile registers by
popping their saved values from the stack, and returns.
The epilog code must follow a strict set of rules for the unwind code to reliably unwind
through exceptions and interrupts. These rules reduce the amount of unwind data
required, because no extra data is needed to describe each epilog. Instead, the unwind
code can determine that an epilog is being executed by scanning forward through a
code stream to identify an epilog.
If no frame pointer is used in the function, then the epilog must first deallocate the fixed
part of the stack, the nonvolatile registers are popped, and control is returned to the
calling function. For example,
MASM
 add RSP, fixed-allocation-size
 pop R13
 pop R14
 pop R15
 ret
If a frame pointer is used in the function, then the stack must be trimmed to its fixed
allocation prior to the execution of the epilog. This action is technically not part of the
epilog. For example, the following epilog could be used to undo the prolog previously
used:
MASM
 lea RSP, -128[R13]
 ; epilogue proper starts here
 add RSP, fixed-allocation-size
 pop R13
 pop R14
 pop R15
 ret
In practice, when a frame pointer is used, there is no good reason to adjust RSP in two
steps, so the following epilog would be used instead:
MASM
 lea RSP, fixed-allocation-size - 128[R13]
 pop R13
 pop R14
 pop R15
 ret
These forms are the only legal ones for an epilog. It must consist of either an add
RSP,constant or lea RSP,constant[FPReg] , followed by a series of zero or more 8-byte
register pops and a return or a jmp . (Only a subset of jmp statements are allowable in
the epilog. The subset is exclusively the class of jmp statements with ModRM memory
references where ModRM mod field value is 00. The use of jmp statements in the epilog
with ModRM mod field value 01 or 10 is prohibited. See Table A-15 in the AMD x86-64
Architecture Programmer's Manual Volume 3: General Purpose and System Instructions,
for more info on the allowable ModRM references.) No other code can appear. In
particular, nothing can be scheduled within an epilog, including loading of a return
value.
When a frame pointer is not used, the epilog must use add RSP,constant to deallocate
the fixed part of the stack. It may not use lea RSP,constant[RSP] instead. This restriction
exists so the unwind code has fewer patterns to recognize when searching for epilogs.
Following these rules allows the unwind code to determine that an epilog is currently
being executed and to simulate execution of the remainder of the epilog to allow
recreating the context of the calling function.
See also
x64 Software Conventions
x64 exception handling
Article • 02/08/2022
An overview of structured exception handling and C++ exception handling coding
conventions and behavior on the x64. For general information on exception handling,
see Exception Handling in Visual C++.
Several data structures are required for exception handling and debugging support.
Table-based exception handling requires a table entry for all functions that allocate stack
space or call another function (for example, nonleaf functions). Function table entries
have the format:
Size Value
ULONG Function start address
ULONG Function end address
ULONG Unwind info address
The RUNTIME_FUNCTION structure must be DWORD aligned in memory. All addresses
are image relative, that is, they're 32-bit offsets from the starting address of the image
that contains the function table entry. These entries are sorted, and put in the .pdata
section of a PE32+ image. For dynamically generated functions [JIT compilers], the
runtime to support these functions must either use RtlInstallFunctionTableCallback or
RtlAddFunctionTable to provide this information to the operating system. Failure to do
so will result in unreliable exception handling and debugging of processes.
The unwind data info structure is used to record the effects a function has on the stack
pointer, and where the nonvolatile registers are saved on the stack:
Size Value
Unwind data for exception handling, debugger
support
struct RUNTIME_FUNCTION
struct UNWIND_INFO
Size Value
UBYTE: 3 Version
UBYTE: 5 Flags
UBYTE Size of prolog
UBYTE Count of unwind codes
UBYTE: 4 Frame Register
UBYTE: 4 Frame Register offset (scaled)
USHORT * n Unwind codes array
variable Can either be of form (1) or (2) below
(1) Exception Handler
Size Value
ULONG Address of exception handler
variable Language-specific handler data (optional)
(2) Chained Unwind Info
Size Value
ULONG Function start address
ULONG Function end address
ULONG Unwind info address
The UNWIND_INFO structure must be DWORD aligned in memory. Here's what each
field means:
Version
Version number of the unwind data, currently 1.
Flags
Three flags are currently defined:
Flag Description
Flag Description
UNW_FLAG_EHANDLER The function has an exception handler that should be called when
looking for functions that need to examine exceptions.
UNW_FLAG_UHANDLER The function has a termination handler that should be called when
unwinding an exception.
UNW_FLAG_CHAININFO This unwind info structure is not the primary one for the procedure.
Instead, the chained unwind info entry is the contents of a previous
RUNTIME_FUNCTION entry. For information, see Chained unwind
info structures. If this flag is set, then the UNW_FLAG_EHANDLER and
UNW_FLAG_UHANDLER flags must be cleared. Also, the frame
register and fixed-stack allocation fields must have the same values
as in the primary unwind info.
Size of prolog
Length of the function prolog in bytes.
Count of unwind codes
The number of slots in the unwind codes array. Some unwind codes, for example,
UWOP_SAVE_NONVOL, require more than one slot in the array.
Frame register
If nonzero, then the function uses a frame pointer (FP), and this field is the number
of the nonvolatile register used as the frame pointer, using the same encoding for
the operation info field of UNWIND_CODE nodes.
Frame register offset (scaled)
If the frame register field is nonzero, this field is the scaled offset from RSP that is
applied to the FP register when it's established. The actual FP register is set to RSP
+ 16 * this number, allowing offsets from 0 to 240. This offset permits pointing the
FP register into the middle of the local stack allocation for dynamic stack frames,
allowing better code density through shorter instructions. (That is, more
instructions can use the 8-bit signed offset form.)
Unwind codes array
An array of items that explains the effect of the prolog on the nonvolatile registers
and RSP. See the section on UNWIND_CODE for the meanings of individual items.
For alignment purposes, this array always has an even number of entries, and the
final entry is potentially unused. In that case, the array is one longer than indicated
by the count of unwind codes field.
Address of exception handler
An image-relative pointer to either the function's language-specific exception or
termination handler, if flag UNW_FLAG_CHAININFO is clear and one of the flags
UNW_FLAG_EHANDLER or UNW_FLAG_UHANDLER is set.
Language-specific handler data
The function's language-specific exception handler data. The format of this data is
unspecified and completely determined by the specific exception handler in use.
Chained Unwind Info
If flag UNW_FLAG_CHAININFO is set, then the UNWIND_INFO structure ends with
three UWORDs. These UWORDs represent the RUNTIME_FUNCTION information
for the function of the chained unwind.
The unwind code array is used to record the sequence of operations in the prolog that
affect the nonvolatile registers and RSP. Each code item has this format:
Size Value
UBYTE Offset in prolog
UBYTE: 4 Unwind operation code
UBYTE: 4 Operation info
The array is sorted by descending order of offset in the prolog.
Offset (from the beginning of the prolog) of the end of the instruction that performs this
operation, plus 1 (that is, the offset of the start of the next instruction).
Note: Certain operation codes require an unsigned offset to a value in the local stack
frame. This offset is from the start, that is, the lowest address of the fixed stack
allocation. If the Frame Register field in the UNWIND_INFO is zero, this offset is from
RSP. If the Frame Register field is nonzero, this offset is from where RSP was located
when the FP register was established. It equals the FP register minus the FP register
struct UNWIND_CODE
Offset in prolog
Unwind operation code
offset (16 * the scaled frame register offset in the UNWIND_INFO). If an FP register is
used, then any unwind code taking an offset must only be used after the FP register is
established in the prolog.
For all opcodes except UWOP_SAVE_XMM128 and UWOP_SAVE_XMM128_FAR , the offset is always
a multiple of 8, because all stack values of interest are stored on 8-byte boundaries (the
stack itself is always 16-byte aligned). For operation codes that take a short offset (less
than 512K), the final USHORT in the nodes for this code holds the offset divided by 8.
For operation codes that take a long offset (512K <= offset < 4GB), the final two
USHORT nodes for this code hold the offset (in little-endian format).
For the opcodes UWOP_SAVE_XMM128 and UWOP_SAVE_XMM128_FAR , the offset is always a
multiple of 16, since all 128-bit XMM operations must occur on 16-byte aligned
memory. Therefore, a scale factor of 16 is used for UWOP_SAVE_XMM128 , permitting offsets
of less than 1M.
The unwind operation code is one of these values:
UWOP_PUSH_NONVOL (0) 1 node
Push a nonvolatile integer register, decrementing RSP by 8. The operation info is
the number of the register. Because of the constraints on epilogs,
UWOP_PUSH_NONVOL unwind codes must appear first in the prolog and
correspondingly, last in the unwind code array. This relative ordering applies to all
other unwind codes except UWOP_PUSH_MACHFRAME .
UWOP_ALLOC_LARGE (1) 2 or 3 nodes
Allocate a large-sized area on the stack. There are two forms. If the operation info
equals 0, then the size of the allocation divided by 8 is recorded in the next slot,
allowing an allocation up to 512K - 8. If the operation info equals 1, then the
unscaled size of the allocation is recorded in the next two slots in little-endian
format, allowing allocations up to 4GB - 8.
UWOP_ALLOC_SMALL (2) 1 node
Allocate a small-sized area on the stack. The size of the allocation is the operation
info field * 8 + 8, allowing allocations from 8 to 128 bytes.
The unwind code for a stack allocation should always use the shortest possible
encoding:
Allocation Size Unwind Code
Allocation Size Unwind Code
8 to 128 bytes UWOP_ALLOC_SMALL
136 to 512K-8 bytes UWOP_ALLOC_LARGE , operation info = 0
512K to 4G-8 bytes UWOP_ALLOC_LARGE , operation info = 1
UWOP_SET_FPREG (3) 1 node
Establish the frame pointer register by setting the register to some offset of the
current RSP. The offset is equal to the Frame Register offset (scaled) field in the
UNWIND_INFO * 16, allowing offsets from 0 to 240. The use of an offset permits
establishing a frame pointer that points to the middle of the fixed stack allocation,
helping code density by allowing more accesses to use short instruction forms. The
operation info field is reserved and shouldn't be used.
UWOP_SAVE_NONVOL (4) 2 nodes
Save a nonvolatile integer register on the stack using a MOV instead of a PUSH.
This code is primarily used for shrink-wrapping, where a nonvolatile register is
saved to the stack in a position that was previously allocated. The operation info is
the number of the register. The scaled-by-8 stack offset is recorded in the next
unwind operation code slot, as described in the note above.
UWOP_SAVE_NONVOL_FAR (5) 3 nodes
Save a nonvolatile integer register on the stack with a long offset, using a MOV
instead of a PUSH. This code is primarily used for shrink-wrapping, where a
nonvolatile register is saved to the stack in a position that was previously allocated.
The operation info is the number of the register. The unscaled stack offset is
recorded in the next two unwind operation code slots, as described in the note
above.
UWOP_SAVE_XMM128 (8) 2 nodes
Save all 128 bits of a nonvolatile XMM register on the stack. The operation info is
the number of the register. The scaled-by-16 stack offset is recorded in the next
slot.
UWOP_SAVE_XMM128_FAR (9) 3 nodes
Save all 128 bits of a nonvolatile XMM register on the stack with a long offset. The
operation info is the number of the register. The unscaled stack offset is recorded
in the next two slots.
UWOP_PUSH_MACHFRAME (10) 1 node
Push a machine frame. This unwind code is used to record the effect of a hardware
interrupt or exception. There are two forms. If the operation info equals 0, one of
these frames has been pushed on the stack:
Location Value
RSP+32 SS
RSP+24 Old RSP
RSP+16 EFLAGS
RSP+8 CS
RSP RIP
If the operation info equals 1, then one of these frames has been pushed:
Location Value
RSP+40 SS
RSP+32 Old RSP
RSP+24 EFLAGS
RSP+16 CS
RSP+8 RIP
RSP Error code
This unwind code always appears in a dummy prolog, which is never actually
executed, but instead appears before the real entry point of an interrupt routine,
and exists only to provide a place to simulate the push of a machine frame.
UWOP_PUSH_MACHFRAME records that simulation, which indicates the machine has
conceptually done this operation:
1. Pop RIP return address from top of stack into Temp
2. Push SS
3. Push old RSP
4. Push EFLAGS
5. Push CS
6. Push Temp
7. Push Error Code (if op info equals 1)
The simulated UWOP_PUSH_MACHFRAME operation decrements RSP by 40 (op info
equals 0) or 48 (op info equals 1).
The meaning of the operation info bits depends upon the operation code. To encode a
general-purpose (integer) register, this mapping is used:
Bit Register
0 RAX
1 RCX
2 RDX
3 RBX
4 RSP
5 RBP
6 RSI
7 RDI
8 to 15 R8 to R15
If the UNW_FLAG_CHAININFO flag is set, then an unwind info structure is a secondary
one, and the shared exception-handler/chained-info address field contains the primary
unwind information. This sample code retrieves the primary unwind information,
assuming that unwindInfo is the structure that has the UNW_FLAG_CHAININFO flag set.
C++
Chained info is useful in two situations. First, it can be used for noncontiguous code
segments. By using chained info, you can reduce the size of the required unwind
Operation info
Chained unwind info structures
PRUNTIME_FUNCTION primaryUwindInfo = (PRUNTIME_FUNCTION)&(unwindInfo-
>UnwindCode[( unwindInfo->CountOfCodes + 1 ) & ~1]);
information, because you do not have to duplicate the unwind codes array from the
primary unwind info.
You can also use chained info to group volatile register saves. The compiler may delay
saving some volatile registers until it is outside of the function entry prolog. You can
record them by having primary unwind info for the portion of the function before the
grouped code, and then setting up chained info with a non-zero size of prolog, where
the unwind codes in the chained info reflect saves of the nonvolatile registers. In that
case, the unwind codes are all instances of UWOP_SAVE_NONVOL. A grouping that
saves nonvolatile registers by using a PUSH or modifies the RSP register by using an
additional fixed stack allocation is not supported.
An UNWIND_INFO item that has UNW_FLAG_CHAININFO set can contain a
RUNTIME_FUNCTION entry whose UNWIND_INFO item also has
UNW_FLAG_CHAININFO set, sometimes called multiple shrink-wrapping. Eventually, the
chained unwind info pointers arrive at an UNWIND_INFO item that has
UNW_FLAG_CHAININFO cleared. This item is the primary UNWIND_INFO item, which
points to the actual procedure entry point.
Unwind procedure
The unwind code array is sorted into descending order. When an exception occurs, the
complete context is stored by the operating system in a context record. The exception
dispatch logic is then invoked, which repeatedly executes these steps to find an
exception handler:
1. Use the current RIP stored in the context record to search for a
RUNTIME_FUNCTION table entry that describes the current function (or function
portion, for chained UNWIND_INFO entries).
2. If no function table entry is found, then it's in a leaf function, and RSP directly
addresses the return pointer. The return pointer at [RSP] is stored in the updated
context, the simulated RSP is incremented by 8, and step 1 is repeated.
3. If a function table entry is found, RIP can lie within three regions: a) in an epilog, b)
in the prolog, or c) in code that may be covered by an exception handler.
Case a) If the RIP is within an epilog, then control is leaving the function,
there can be no exception handler associated with this exception for this
function, and the effects of the epilog must be continued to compute the
context of the caller function. To determine if the RIP is within an epilog, the
code stream from RIP onward is examined. If that code stream can be
matched to the trailing portion of a legitimate epilog, then it's in an epilog,
and the remaining portion of the epilog is simulated, with the context record
updated as each instruction is processed. After this processing, step 1 is
repeated.
Case b) If the RIP lies within the prologue, then control hasn't entered the
function, there can be no exception handler associated with this exception for
this function, and the effects of the prolog must be undone to compute the
context of the caller function. The RIP is within the prolog if the distance from
the function start to the RIP is less than or equal to the prolog size encoded
in the unwind info. The effects of the prolog are unwound by scanning
forward through the unwind codes array for the first entry with an offset less
than or equal to the offset of the RIP from the function start, then undoing
the effect of all remaining items in the unwind code array. Step 1 is then
repeated.
Case c) If the RIP isn't within a prolog or epilog, and the function has an
exception handler (UNW_FLAG_EHANDLER is set), then the language-specific
handler is called. The handler scans its data and calls filter functions as
appropriate. The language-specific handler can return that the exception was
handled or that the search is to be continued. It can also initiate an unwind
directly.
4. If the language-specific handler returns a handled status, then execution is
continued using the original context record.
5. If there's no language-specific handler or the handler returns a "continue search"
status, then the context record must be unwound to the state of the caller. It's
done by processing all of the unwind code array elements, undoing the effect of
each. Step 1 is then repeated.
When chained unwind info is involved, these basic steps are still followed. The only
difference is that, while walking the unwind code array to unwind a prolog's effects,
once the end of the array is reached, it's then linked to the parent unwind info and the
entire unwind code array found there is walked. This linking continues until arriving at
an unwind info without the UNW_CHAINED_INFO flag, and then it finishes walking its
unwind code array.
The smallest set of unwind data is 8 bytes. This would represent a function that only
allocated 128 bytes of stack or less, and possibly saved one nonvolatile register. It's also
the size of a chained unwind info structure for a zero-length prolog with no unwind
codes.
Language-specific handler
The relative address of the language-specific handler is present in the UNWIND_INFO
whenever flags UNW_FLAG_EHANDLER or UNW_FLAG_UHANDLER are set. As described
in the previous section, the language-specific handler is called as part of the search for
an exception handler or as part of an unwind. It has this prototype:
C++
typedef EXCEPTION_DISPOSITION (*PEXCEPTION_ROUTINE) (
 IN PEXCEPTION_RECORD ExceptionRecord,
 IN ULONG64 EstablisherFrame,
 IN OUT PCONTEXT ContextRecord,
 IN OUT PDISPATCHER_CONTEXT DispatcherContext
);
ExceptionRecord supplies a pointer to an exception record, which has the standard
Win64 definition.
EstablisherFrame is the address of the base of the fixed stack allocation for this
function.
ContextRecord points to the exception context at the time the exception was raised (in
the exception handler case) or the current "unwind" context (in the termination handler
case).
DispatcherContext points to the dispatcher context for this function. It has this
definition:
C++
typedef struct _DISPATCHER_CONTEXT {
 ULONG64 ControlPc;
 ULONG64 ImageBase;
 PRUNTIME_FUNCTION FunctionEntry;
 ULONG64 EstablisherFrame;
 ULONG64 TargetIp;
 PCONTEXT ContextRecord;
 PEXCEPTION_ROUTINE LanguageHandler;
 PVOID HandlerData;
} DISPATCHER_CONTEXT, *PDISPATCHER_CONTEXT;
ControlPc is the value of RIP within this function. This value is either an exception
address or the address at which control left the establishing function. The RIP is used to
determine if control is within some guarded construct inside this function, for example, a
__try block for __try / __except or __try / __finally .
ImageBase is the image base (load address) of the module containing this function, to
be added to the 32-bit offsets used in the function entry and unwind info to record
relative addresses.
FunctionEntry supplies a pointer to the RUNTIME_FUNCTION function entry holding the
function and unwind info image-base relative addresses for this function.
EstablisherFrame is the address of the base of the fixed stack allocation for this
function.
TargetIp Supplies an optional instruction address that specifies the continuation address
of the unwind. This address is ignored if EstablisherFrame isn't specified.
ContextRecord points to the exception context, for use by the system exception
dispatch/unwind code.
LanguageHandler points to the language-specific language handler routine being
called.
HandlerData points to the language-specific handler data for this function.
In order to write proper assembly routines, there's a set of pseudo-operations that can
be used in parallel with the actual assembly instructions to create the appropriate .pdata
and .xdata. And, there's a set of macros that provide simplified use of the pseudo￾operations for their most common uses.
Pseudo
operation
Description
PROC FRAME
[:ehandler]
Causes MASM to generate a function table entry in .pdata and unwind
information in .xdata for a function's structured exception handling unwind
behavior. If ehandler is present, this proc is entered in the .xdata as the
language-specific handler.
When the FRAME attribute is used, it must be followed by an .ENDPROLOG
directive. If the function is a leaf function (as defined in Function types) the
FRAME attribute is unnecessary, as are the remainder of these pseudo￾operations.
Unwind helpers for MASM
Raw pseudo-operations
Pseudo
operation
Description
.PUSHREG
register
Generates a UWOP_PUSH_NONVOL unwind code entry for the specified register
number using the current offset in the prologue.
Only use it with nonvolatile integer registers. For pushes of volatile registers, use
an .ALLOCSTACK 8, instead
.SETFRAME
register, offset
Fills in the frame register field and offset in the unwind information using the
specified register and offset. The offset must be a multiple of 16 and less than or
equal to 240. This directive also generates a UWOP_SET_FPREG unwind code
entry for the specified register using the current prologue offset.
.ALLOCSTACK
size
Generates a UWOP_ALLOC_SMALL or a UWOP_ALLOC_LARGE with the specified
size for the current offset in the prologue.
The size operand must be a multiple of 8.
.SAVEREG
register, offset
Generates either a UWOP_SAVE_NONVOL or a UWOP_SAVE_NONVOL_FAR
unwind code entry for the specified register and offset using the current
prologue offset. MASM chooses the most efficient encoding.
offset must be positive, and a multiple of 8. offset is relative to the base of the
procedure's frame, which is generally in RSP, or, if using a frame pointer, the
unscaled frame pointer.
.SAVEXMM128
register, offset
Generates either a UWOP_SAVE_XMM128 or a UWOP_SAVE_XMM128_FAR
unwind code entry for the specified XMM register and offset using the current
prologue offset. MASM chooses the most efficient encoding.
offset must be positive, and a multiple of 16. offset is relative to the base of the
procedure's frame, which is generally in RSP, or, if using a frame pointer, the
unscaled frame pointer.
.PUSHFRAME
[code]
Generates a UWOP_PUSH_MACHFRAME unwind code entry. If the optional code
is specified, the unwind code entry is given a modifier of 1. Otherwise the
modifier is 0.
.ENDPROLOG Signals the end of the prologue declarations. Must occur in the first 255 bytes of
the function.
Here's a sample function prolog with proper usage of most of the opcodes:
MASM
sample PROC FRAME
 db 048h; emit a REX prefix, to enable hot-patching
 push rbp
 .pushreg rbp
 sub rsp, 040h
 .allocstack 040h
 lea rbp, [rsp+020h]
 .setframe rbp, 020h
 movdqa [rbp], xmm7
 .savexmm128 xmm7, 020h ;the offset is from the base of the frame
 ;not the scaled offset of the frame
 mov [rbp+018h], rsi
 .savereg rsi, 038h
 mov [rsp+010h], rdi
 .savereg rdi, 010h ; you can still use RSP as the base of the frame
 ; or any other register you choose
 .endprolog
; you can modify the stack pointer outside of the prologue (similar to
alloca)
; because we have a frame pointer.
; if we didn't have a frame pointer, this would be illegal
; if we didn't make this modification,
; there would be no need for a frame pointer
 sub rsp, 060h
; we can unwind from the next AV because of the frame pointer
 mov rax, 0
 mov rax, [rax] ; AV!
; restore the registers that weren't saved with a push
; this isn't part of the official epilog, as described in section 2.5
 movdqa xmm7, [rbp]
 mov rsi, [rbp+018h]
 mov rdi, [rbp-010h]
; Here's the official epilog
 lea rsp, [rbp+020h] ; deallocate both fixed and dynamic portions of the
frame
 pop rbp
 ret
sample ENDP
For more information about the epilog example, see Epilog code in x64 prolog and
epilog.
MASM macros
In order to simplify the use of the Raw pseudo-operations, there's a set of macros,
defined in ksamd64.inc, which can be used to create typical procedure prologues and
epilogues.
Macro Description
alloc_stack(n) Allocates a stack frame of n bytes (using sub rsp, n ), and emits the appropriate
unwind information (.allocstack n)
save_reg reg,
loc
Saves a nonvolatile register reg on the stack at RSP offset loc, and emits the
appropriate unwind information. (.savereg reg, loc)
push_reg reg Pushes a nonvolatile register reg on the stack, and emits the appropriate unwind
information. (.pushreg reg)
rex_push_reg
reg
Saves a nonvolatile register on the stack using a 2-byte push, and emits the
appropriate unwind information (.pushreg reg). Use this macro if the push is the
first instruction in the function, to ensure that the function is hot-patchable.
save_xmm128
reg, loc
Saves a nonvolatile XMM register reg on the stack at RSP offset loc, and emits the
appropriate unwind information (.savexmm128 reg, loc)
set_frame reg,
offset
Sets the frame register reg to be the RSP + offset (using a mov , or an lea ), and
emits the appropriate unwind information (.set_frame reg, offset)
push_eflags Pushes the eflags with a pushfq instruction, and emits the appropriate unwind
information (.alloc_stack 8)
Here's a sample function prolog with proper usage of the macros:
MASM
sampleFrame struct
 Fill dq ?; fill to 8 mod 16
 SavedRdi dq ?; Saved Register RDI
 SavedRsi dq ?; Saved Register RSI
sampleFrame ends
sample2 PROC FRAME
 alloc_stack(sizeof sampleFrame)
 save_reg rdi, sampleFrame.SavedRdi
 save_reg rsi, sampleFrame.SavedRsi
 .end_prolog
; function body
 mov rsi, sampleFrame.SavedRsi[rsp]
 mov rdi, sampleFrame.SavedRdi[rsp]
; Here's the official epilog
 add rsp, (sizeof sampleFrame)
 ret
sample2 ENDP
Here's a C description of the unwind data:
C
Unwind data definitions in C
typedef enum _UNWIND_OP_CODES {
 UWOP_PUSH_NONVOL = 0, /* info == register number */
 UWOP_ALLOC_LARGE, /* no info, alloc size in next 2 slots */
 UWOP_ALLOC_SMALL, /* info == size of allocation / 8 - 1 */
 UWOP_SET_FPREG, /* no info, FP = RSP + UNWIND_INFO.FPRegOffset*16
*/
 UWOP_SAVE_NONVOL, /* info == register number, offset in next slot */
 UWOP_SAVE_NONVOL_FAR, /* info == register number, offset in next 2 slots
*/
 UWOP_SAVE_XMM128 = 8, /* info == XMM reg number, offset in next slot */
 UWOP_SAVE_XMM128_FAR, /* info == XMM reg number, offset in next 2 slots
*/
 UWOP_PUSH_MACHFRAME /* info == 0: no error-code, 1: error-code */
} UNWIND_CODE_OPS;
typedef unsigned char UBYTE;
typedef union _UNWIND_CODE {
 struct {
 UBYTE CodeOffset;
 UBYTE UnwindOp : 4;
 UBYTE OpInfo : 4;
 };
 USHORT FrameOffset;
} UNWIND_CODE, *PUNWIND_CODE;
#define UNW_FLAG_EHANDLER 0x01
#define UNW_FLAG_UHANDLER 0x02
#define UNW_FLAG_CHAININFO 0x04
typedef struct _UNWIND_INFO {
 UBYTE Version : 3;
 UBYTE Flags : 5;
 UBYTE SizeOfProlog;
 UBYTE CountOfCodes;
 UBYTE FrameRegister : 4;
 UBYTE FrameOffset : 4;
 UNWIND_CODE UnwindCode[1];
/* UNWIND_CODE MoreUnwindCode[((CountOfCodes + 1) & ~1) - 1];
* union {
* OPTIONAL ULONG ExceptionHandler;
* OPTIONAL ULONG FunctionEntry;
* };
* OPTIONAL ULONG ExceptionData[]; */
} UNWIND_INFO, *PUNWIND_INFO;
typedef struct _RUNTIME_FUNCTION {
 ULONG BeginAddress;
 ULONG EndAddress;
 ULONG UnwindData;
} RUNTIME_FUNCTION, *PRUNTIME_FUNCTION;
#define GetUnwindCodeEntry(info, index) \
 ((info)->UnwindCode[index])
#define GetLanguageSpecificDataPtr(info) \
 ((PVOID)&GetUnwindCodeEntry((info),((info)->CountOfCodes + 1) & ~1))
#define GetExceptionHandler(base, info) \
 ((PEXCEPTION_HANDLER)((base) + *
(PULONG)GetLanguageSpecificDataPtr(info)))
#define GetChainedFunctionEntry(base, info) \
 ((PRUNTIME_FUNCTION)((base) + *
(PULONG)GetLanguageSpecificDataPtr(info)))
#define GetExceptionDataPtr(info) \
 ((PVOID)((PULONG)GetLanguageSpecificData(info) + 1))
See also
x64 software conventions
Configure C++ projects for ARM
processors
Article • 07/27/2023
This section of the documentation contains information about how to use the MSVC
build tools to target ARM hardware.
In This Section
Overview of ARM ABI conventions
Describes the application binary interface used by Windows on ARM for register usage,
calling conventions and exception handling.
Overview of ARM64 ABI conventions
Describes the application binary interface used by Windows on ARM64 for register
usage, calling conventions and exception handling.
Common MSVC ARM migration issues
Describes C++ code elements that are commonly assumed to be portable across
architectures, but that produce different results for ARM than for x86 and x64.
ARM exception handling
Describes the encoding scheme for stack unwinding during structured exception
handling in Windows on ARM.
ARM64 exception handling
Describes the encoding scheme for stack unwinding during structured exception
handling in Windows on ARM64.
Related Sections
Get started with Arm64EC
Describes how to get started building your app or project using Arm64EC.
How to: Configure projects to target platforms
Describes how to set up your build to target different processor architectures, including
Arm64.
ARM intrinsics
Describes compiler intrinsics for processors that use the ARM architecture.
ARM64 intrinsics
Describes compiler intrinsics for processors that use the ARM64 architecture.
Common Visual C++ ARM Migration
Issues
Article • 06/15/2022
When using the Microsoft C++ compiler (MSVC), the same C++ source code might
produce different results on the ARM architecture than it does on x86 or x64
architectures.
Sources of migration issues
Many issues that you might encounter when you migrate code from the x86 or x64
architectures to the ARM architecture are related to source-code constructs that might
invoke undefined, implementation-defined, or unspecified behavior.
Undefined behavior is behavior that the C++ standard does not define, and that's
caused by an operation that has no reasonable result: for example, converting a
floating-point value to an unsigned integer, or shifting a value by a number of positions
that is negative or exceeds the number of bits in its promoted type.
Implementation-defined behavior is behavior that the C++ standard requires the
compiler vendor to define and document. A program can safely rely on implementation￾defined behavior, even though doing so might not be portable. Examples of
implementation-defined behavior include the sizes of built-in data types and their
alignment requirements. An example of an operation that might be affected by
implementation-defined behavior is accessing the variable arguments list.
Unspecified behavior is behavior that the C++ standard leaves intentionally non￾deterministic. Although the behavior is considered non-deterministic, particular
invocations of unspecified behavior are determined by the compiler implementation.
However, there is no requirement for a compiler vendor to predetermine the result or
guarantee consistent behavior between comparable invocations, and there is no
requirement for documentation. An example of unspecified behavior is the order in
which sub-expressions, which include arguments to a function call, are evaluated.
Other migration issues can be attributed to hardware differences between ARM and x86
or x64 architectures that interact with the C++ standard differently. For example, the
strong memory model of the x86 and x64 architecture gives volatile -qualified
variables some additional properties that have been used to facilitate certain kinds of
inter-thread communication in the past. But the ARM architecture's weak memory
model doesn't support this use, nor does the C++ standard require it.
） Important
Although volatile gains some properties that can be used to implement limited
forms of inter-thread communication on x86 and x64, these additional properties
are not sufficient to implement inter-thread communication in general. The C++
standard recommends that such communication be implemented by using
appropriate synchronization primitives instead.
Because different platforms might express these kinds of behavior differently, porting
software between platforms can be difficult and bug-prone if it depends on the
behavior of a specific platform. Although many of these kinds of behavior can be
observed and might appear stable, relying on them is at least non-portable, and in the
cases of undefined or unspecified behavior, is also an error. Even the behavior that's
cited in this document should not be relied on, and could change in future compilers or
CPU implementations.
Example migration issues
The rest of this document describes how the different behavior of these C++ language
elements can produce different results on different platforms.
Conversion of floating-point to unsigned integer
On the ARM architecture, conversion of a floating-point value to a 32-bit integer
saturates to the nearest value that the integer can represent if the floating-point value is
outside the range that the integer can represent. On the x86 and x64 architectures, the
conversion wraps around if the integer is unsigned, or is set to -2147483648 if the
integer is signed. None of these architectures directly support the conversion of
floating-point values to smaller integer types; instead, the conversions are performed to
32 bits, and the results are truncated to a smaller size.
For the ARM architecture, the combination of saturation and truncation means that
conversion to unsigned types correctly saturates smaller unsigned types when it
saturates a 32-bit integer, but produces a truncated result for values that are larger than
the smaller type can represent but too small to saturate the full 32-bit integer.
Conversion also saturates correctly for 32-bit signed integers, but truncation of
saturated, signed integers results in -1 for positively-saturated values and 0 for
negatively-saturated values. Conversion to a smaller signed integer produces a
truncated result that's unpredictable.
For the x86 and x64 architectures, the combination of wrap-around behavior for
unsigned integer conversions and explicit valuation for signed integer conversions on
overflow, together with truncation, make the results for most shifts unpredictable if they
are too large.
These platforms also differ in how they handle conversion of NaN (Not-a-Number) to
integer types. On ARM, NaN converts to 0x00000000; on x86 and x64, it converts to
0x80000000.
Floating-point conversion can only be relied on if you know that the value is within the
range of the integer type that it's being converted to.
Shift operator (<< >>) behavior
On the ARM architecture, a value can be shifted left or right up to 255 bits before the
pattern begins to repeat. On x86 and x64 architectures, the pattern is repeated at every
multiple of 32 unless the source of the pattern is a 64-bit variable; in that case, the
pattern repeats at every multiple of 64 on x64, and every multiple of 256 on x86, where
a software implementation is employed. For example, for a 32-bit variable that has a
value of 1 shifted left by 32 positions, on ARM the result is 0, on x86 the result is 1, and
on x64 the result is also 1. However, if the source of the value is a 64-bit variable, then
the result on all three platforms is 4294967296, and the value doesn't "wrap around"
until it's shifted 64 positions on x64, or 256 positions on ARM and x86.
Because the result of a shift operation that exceeds the number of bits in the source
type is undefined, the compiler is not required to have consistent behavior in all
situations. For example, if both operands of a shift are known at compile time, the
compiler may optimize the program by using an internal routine to precompute the
result of the shift and then substituting the result in place of the shift operation. If the
shift amount is too large, or negative, the result of the internal routine might be
different than the result of the same shift expression as executed by the CPU.
Variable arguments (varargs) behavior
On the ARM architecture, parameters from the variable arguments list that are passed
on the stack are subject to alignment. For example, a 64-bit parameter is aligned on a
64-bit boundary. On x86 and x64, arguments that are passed on the stack are not
subject to alignment and pack tightly. This difference can cause a variadic function like
printf to read memory addresses that were intended as padding on ARM if the
expected layout of the variable arguments list is not matched exactly, even though it
might work for a subset of some values on the x86 or x64 architectures. Consider this
example:
C
// notice that a 64-bit integer is passed to the function, but '%d' is used
to read it.
// on x86 and x64 this may work for small values because %d will "parse" the
low-32 bits of the argument.
// on ARM the calling convention will align the 64-bit value and the code
will print a random value
printf("%d\n", 1LL);
In this case, the bug can be fixed by making sure that the correct format specification is
used so that the alignment of the argument is considered. This code is correct:
C
// CORRECT: use %I64d for 64-bit integers
printf("%I64d\n", 1LL);
Argument evaluation order
Because ARM, x86, and x64 processors are so different, they can present different
requirements to compiler implementations, and also different opportunities for
optimizations. Because of this, together with other factors like calling-convention and
optimization settings, a compiler might evaluate function arguments in a different order
on different architectures or when the other factors are changed. This can cause the
behavior of an app that relies on a specific evaluation order to change unexpectedly.
This kind of error can occur when arguments to a function have side effects that impact
other arguments to the function in the same call. Usually this kind of dependency is easy
to avoid, but it can sometimes be obscured by dependencies that are difficult to discern,
or by operator overloading. Consider this code example:
C++
handle memory_handle;
memory_handle->acquire(*p);
This appears well-defined, but if -> and * are overloaded operators, then this code is
translated to something that resembles this:
C++
Handle::acquire(operator->(memory_handle), operator*(p));
And if there's a dependency between operator->(memory_handle) and operator*(p) , the
code might rely on a specific evaluation order, even though the original code looks like
there is no possible dependency.
volatile keyword default behavior
The MSVC compiler supports two different interpretations of the volatile storage
qualifier that you can specify by using compiler switches. The /volatile:ms switch selects
the Microsoft extended volatile semantics that guarantee strong ordering, as has been
the traditional case for x86 and x64 because of the strong memory model on those
architectures. The /volatile:iso switch selects the strict C++ standard volatile semantics
that don't guarantee strong ordering.
On the ARM architecture (except ARM64EC), the default is /volatile:iso because ARM
processors have a weakly ordered memory model, and because ARM software doesn't
have a legacy of relying on the extended semantics of /volatile:ms and doesn't usually
have to interface with software that does. However, it's still sometimes convenient or
even required to compile an ARM program to use the extended semantics. For example,
it may be too costly to port a program to use the ISO C++ semantics, or driver software
might have to adhere to the traditional semantics to function correctly. In these cases,
you can use the /volatile:ms switch; however, to recreate the traditional volatile
semantics on ARM targets, the compiler must insert memory barriers around each read
or write of a volatile variable to enforce strong ordering, which can have a negative
impact on performance.
On the x86, x64 and ARM64EC architectures, the default is /volatile:ms because much of
the software that has already been created for these architectures by using MSVC relies
on them. When you compile x86, x64 and ARM64EC programs, you can specify the
/volatile:iso switch to help avoid unnecessary reliance on the traditional volatile
semantics, and to promote portability.
See also
Configure Visual C++ for ARM processors
Overview of ARM32 ABI Conventions
Article • 11/11/2021
The application binary interface (ABI) for code compiled for Windows on ARM
processors is based on the standard ARM EABI. This article highlights key differences
between Windows on ARM and the standard. This document covers the ARM32 ABI. For
information about the ARM64 ABI, see Overview of ARM64 ABI conventions. For more
information about the standard ARM EABI, see Application Binary Interface (ABI) for the
ARM Architecture (external link).
Base Requirements
Windows on ARM always presumes that it's running on an ARMv7 architecture.
Floating-point support in the form of VFPv3-D32 or later must be present in hardware.
The VFP must support both single-precision and double-precision floating-point in
hardware. The Windows runtime doesn't support emulation of floating-point to enable
running on non-VFP hardware.
Advanced SIMD Extensions (NEON) support, including both integer and floating-point
operations, must also be present in hardware. No run-time support for emulation is
provided.
Integer divide support (UDIV/SDIV) is recommended but not required. Platforms that
lack integer divide support may incur a performance penalty because these operations
have to be trapped and possibly patched.
Endianness
Windows on ARM executes in little-endian mode. Both the MSVC compiler and the
Windows runtime always expect little-endian data. The SETEND instruction in the ARM
instruction set architecture (ISA) allows even user-mode code to change the current
endianness. However, doing so is discouraged because it's dangerous for an application.
If an exception is generated in big-endian mode, the behavior is unpredictable. It may
lead to an application fault in user mode, or a bugcheck in kernel mode.
Alignment
Although Windows enables the ARM hardware to handle misaligned integer accesses
transparently, alignment faults still may be generated in some situations. Follow these
rules for alignment:
You don't have to align half-word-sized (16-bit) and word-sized (32-bit) integer
loads and stores. The hardware handles them efficiently and transparently.
Floating-point loads and stores should be aligned. The kernel handles unaligned
loads and stores transparently, but with significant overhead.
Load or store double (LDRD/STRD) and multiple (LDM/STM) operations should be
aligned. The kernel handles most of them transparently, but with significant
overhead.
All uncached memory accesses must be aligned, even for integer accesses.
Unaligned accesses cause an alignment fault.
The instruction set for Windows on ARM is strictly limited to Thumb-2. All code
executed on this platform is expected to start and always remain in Thumb mode. An
attempt to switch into the legacy ARM instruction set may succeed. However, if it does,
any exceptions or interrupts that occur may lead to an application fault in user mode, or
a bugcheck in kernel mode.
A side-effect of this requirement is that all code pointers must have the low bit set.
Then, when they're loaded and branched to via BLX or BX, the processor remains in
Thumb mode. It doesn't try to execute the target code as 32-bit ARM instructions.
The use of integer divide instructions SDIV and UDIV is fully supported, even on
platforms without native hardware to handle them. The extra overhead per SDIV or
UDIV divide on a Cortex-A9 processor is approximately 80 cycles. That's added to the
overall divide time of 20-250 cycles, depending on the inputs.
The ARM processor supports 16 integer registers:
Register Volatile? Role
r0 Volatile Parameter, result, scratch register 1
r1 Volatile Parameter, result, scratch register 2
Instruction Set
SDIV/UDIV instructions
Integer registers
Register Volatile? Role
r2 Volatile Parameter, scratch register 3
r3 Volatile Parameter, scratch register 4
r4 Non-volatile
r5 Non-volatile
r6 Non-volatile
r7 Non-volatile
r8 Non-volatile
r9 Non-volatile
r10 Non-volatile
r11 Non-volatile Frame pointer
r12 Volatile Intra-procedure-call scratch register
r13 (SP) Non-volatile Stack pointer
r14 (LR) Non-volatile Link register
r15 (PC) Non-volatile Program counter
For details about how to use the parameter and return value registers, see the
Parameter Passing section in this article.
Windows uses r11 for fast-walking of the stack frame. For more information, see the
Stack Walking section. Because of this requirement, r11 must always point to the
topmost link in the chain. Don't use r11 for general purposes, because your code won't
generate correct stack walks during analysis.
Windows only supports ARM variants that have VFPv3-D32 coprocessor support. It
means floating-point registers are always present and can be relied on for parameter
passing. And, the full set of 32 registers is available for use. The VFP registers and their
usage are summarized in this table:
Singles Doubles Quads Volatile? Role
s0-s3 d0-d1 q0 Volatile Parameters, result, scratch register
VFP registers
Singles Doubles Quads Volatile? Role
s4-s7 d2-d3 q1 Volatile Parameters, scratch register
s8-s11 d4-d5 q2 Volatile Parameters, scratch register
s12-s15 d6-d7 q3 Volatile Parameters, scratch register
s16-s19 d8-d9 q4 Non-volatile
s20-s23 d10-d11 q5 Non-volatile
s24-s27 d12-d13 q6 Non-volatile
s28-s31 d14-d15 q7 Non-volatile
d16-d31 q8-q15 Volatile
The next table illustrates the floating-point status and control register (FPSCR) bitfields:
Bits Meaning Volatile? Role
31-28 NZCV Volatile Status flags
27 QC Volatile Cumulative saturation
26 AHP Non-volatile Alternative half-precision control
25 DN Non-volatile Default NaN mode control
24 FZ Non-volatile Flush-to-zero mode control
23-22 RMode Non-volatile Rounding mode control
21-20 Stride Non-volatile Vector Stride, must always be 0
18-16 Len Non-volatile Vector Length, must always be 0
15, 12-8 IDE, IXE, and so on Non-volatile Exception trap enable bits, must always be 0
7, 4-0 IDC, IXC, and so on Volatile Cumulative exception flags
Most ARM hardware doesn't support IEEE floating-point exceptions. On processor
variants that do have hardware floating-point exceptions, the Windows kernel silently
catches the exceptions and implicitly disables them in the FPSCR register. This action
ensures normalized behavior across processor variants. Otherwise, code developed on a
Floating-point exceptions
platform that doesn't have exception support could receive unexpected exceptions
when it's running on a platform that does have exception support.
Parameter passing
The Windows on ARM ABI follows the ARM rules for parameter passing for non-variadic
functions. The ABI rules include the VFP and Advanced SIMD extensions. These rules
follow the Procedure Call Standard for the ARM Architecture , combined with the VFP
extensions. By default, the first four integer arguments and up to eight floating-point or
vector arguments are passed in registers. Any further arguments are passed on the
stack. Arguments are assigned to registers or the stack by using this procedure:
Stage A: Initialization
Initialization is performed exactly once, before argument processing begins:
1. The Next Core Register Number (NCRN) is set to r0.
2. The VFP registers are marked as unallocated.
3. The Next Stacked Argument Address (NSAA) is set to the current SP.
4. If a function that returns a result in memory is called, then the address for the
result is placed in r0 and the NCRN is set to r1.
Stage B: Pre-padding and extension of arguments
For each argument in the list, the first matching rule from the following list is applied:
1. If the argument is a composite type whose size cannot be statically determined by
both the caller and the callee, the argument is copied to memory and replaced by
a pointer to the copy.
2. If the argument is a byte or 16-bit half-word, then it is zero-extended or sign￾extended to a 32-bit full word and treated as a 4-byte argument.
3. If the argument is a composite type, its size is rounded up to the nearest multiple
of 4.
Stage C: Assignment of arguments to registers and stack
For each argument in the list, the following rules are applied in turn until the argument
has been allocated:
1. If the argument is a VFP type and there are enough consecutive unallocated VFP
registers of the appropriate type, then the argument is allocated to the lowest￾numbered sequence of such registers.
2. If the argument is a VFP type, all remaining unallocated registers are marked as
unavailable. The NSAA is adjusted upwards until it is correctly aligned for the
argument type and the argument is copied to the stack at the adjusted NSAA. The
NSAA is then incremented by the size of the argument.
3. If the argument requires 8-byte alignment, the NCRN is rounded up to the next
even register number.
4. If the size of the argument in 32-bit words is not more than r4 minus NCRN, the
argument is copied into core registers, starting at the NCRN, with the least
significant bits occupying the lower-numbered registers. The NCRN is incremented
by the number of registers used.
5. If the NCRN is less than r4 and the NSAA is equal to the SP, the argument is split
between core registers and the stack. The first part of the argument is copied into
the core registers, starting at the NCRN, up to and including r3. The rest of the
argument is copied onto the stack, starting at the NSAA. The NCRN is set to r4 and
the NSAA is incremented by the size of the argument minus the amount passed in
registers.
6. If the argument requires 8-byte alignment, the NSAA is rounded up to the next 8-
byte aligned address.
7. The argument is copied into memory at the NSAA. The NSAA is incremented by
the size of the argument.
The VFP registers aren't used for variadic functions, and Stage C rules 1 and 2 are
ignored. It means that a variadic function can begin with an optional push {r0-r3} to
prepend the register arguments to any additional arguments passed by the caller, and
then access the entire argument list directly from the stack.
Integer type values are returned in r0, optionally extended to r1 for 64-bit return values.
VFP/NEON floating-point or SIMD type values are returned in s0, d0, or q0, as
appropriate.
Stack
The stack must always remain 4-byte aligned, and must be 8-byte aligned at any
function boundary. It's required to support the frequent use of interlocked operations
on 64-bit stack variables. The ARM EABI states that the stack is 8-byte aligned at any
public interface. For consistency, the Windows on ARM ABI considers any function
boundary to be a public interface.
Functions that have to use a frame pointer—for example, functions that call alloca or
that change the stack pointer dynamically—must set up the frame pointer in r11 in the
function prologue and leave it unchanged until the epilogue. Functions that don't
require a frame pointer must perform all stack updates in the prologue and leave the
stack pointer unchanged until the epilogue.
Functions that allocate 4 KB or more on the stack must ensure that each page prior to
the final page is touched in order. This order ensures that no code can "leap over" the
guard pages that Windows uses to expand the stack. Typically, the expansion is done by
the __chkstk helper, which is passed the total stack allocation in bytes divided by 4 in
r4, and which returns the final stack allocation amount in bytes back in r4.
Red zone
The 8-byte area immediately below the current stack pointer is reserved for analysis and
dynamic patching. It permits carefully generated code to be inserted, which stores 2
registers at [sp, #-8] and temporarily uses them for arbitrary purposes. The Windows
kernel guarantees that those 8 bytes won't be overwritten if an exception or interrupt
occurs in both user mode and kernel mode.
Kernel stack
The default kernel-mode stack in Windows is three pages (12 KB). Be careful not to
create functions that have large stack buffers in kernel mode. An interrupt could come in
with very little stack headroom and cause a stack panic bugcheck.
C/C++ specifics
Enumerations are 32-bit integer types unless at least one value in the enumeration
requires 64-bit double-word storage. In that case, the enumeration is promoted to a 64-
bit integer type.
wchar_t is defined to be equivalent to unsigned short , to preserve compatibility with
other platforms.
Stack walking
Windows code is compiled with frame pointers enabled (/Oy (Frame-Pointer Omission))
to enable fast stack walking. Generally, the r11 register points to the next link in the
chain, which is an {r11, lr} pair that specifies the pointer to the previous frame on the
stack and the return address. We recommend that your code also enable frame pointers
for improved profiling and tracing.
Exception unwinding
Stack unwinding during exception handling is enabled by the use of unwind codes. The
unwind codes are a sequence of bytes stored in the .xdata section of the executable
image. They describe the operation of the function prologue and epilogue code in an
abstract manner, so that the effects of a function's prologue can be undone in
preparation for unwinding to the caller's stack frame.
The ARM EABI specifies an exception unwinding model that uses unwind codes.
However, this specification isn't sufficient for unwinding in Windows, which must handle
cases where the processor is in the middle of the prologue or epilogue of a function. For
more information about Windows on ARM exception data and unwinding, see ARM
Exception Handling.
We recommend that dynamically generated code be described by using dynamic
function tables specified in calls to RtlAddFunctionTable and associated functions, so
that the generated code can participate in exception handling.
Cycle counter
ARM processors running Windows are required to support a cycle counter, but using the
counter directly may cause problems. To avoid these issues, Windows on ARM uses an
undefined opcode to request a normalized 64-bit cycle-counter value. From C or C++,
use the __rdpmccntr64 intrinsic to emit the appropriate opcode; from assembly, use the
__rdpmccntr64 instruction. Reading the cycle counter takes approximately 60 cycles on a
Cortex-A9.
The counter is a true cycle counter, not a clock; therefore, the counting frequency varies
with the processor frequency. If you want to measure elapsed clock time, use
QueryPerformanceCounter .
See also
Common Visual C++ ARM Migration Issues
ARM Exception Handling
Overview of ARM64 ABI conventions
Article • 08/25/2021
The basic application binary interface (ABI) for Windows when compiled and run on
ARM processors in 64-bit mode (ARMv8 or later architectures), for the most part, follows
ARM's standard AArch64 EABI. This article highlights some of the key assumptions and
changes from what is documented in the EABI. For information about the 32-bit ABI, see
Overview of ARM ABI conventions. For more information about the standard ARM EABI,
see Application Binary Interface (ABI) for the ARM Architecture (external link).
Definitions
With the introduction of 64-bit support, ARM has defined several terms:
AArch32 – the legacy 32-bit instruction set architecture (ISA) defined by ARM,
including Thumb mode execution.
AArch64 – the new 64-bit instruction set architecture (ISA) defined by ARM.
ARMv7 – the specification of the "7th generation" ARM hardware, which only
includes support for AArch32. This version of the ARM hardware is the first version
Windows for ARM supported.
ARMv8 – the specification of the "8th generation" ARM hardware, which includes
support for both AArch32 and AArch64.
Windows also uses these terms:
ARM – refers to the 32-bit ARM architecture (AArch32), sometimes referred to as
WoA (Windows on ARM).
ARM32 – same as ARM, above; used in this document for clarity.
ARM64 – refers to the 64-bit ARM architecture (AArch64). There's no such thing as
WoA64.
Finally, when referring to data types, the following definitions from ARM are referenced:
Short-Vector – A data type directly representable in SIMD, a vector of 8 bytes or 16
bytes worth of elements. It's aligned to its size, either 8 bytes or 16 bytes, where
each element can be 1, 2, 4, or 8 bytes.
HFA (Homogeneous Floating-point Aggregate) – A data type with 2 to 4 identical
floating-point members, either floats or doubles.
HVA (Homogeneous Short-Vector Aggregate) – A data type with 2 to 4 identical
Short-Vector members.
The ARM64 version of Windows presupposes that it's running on an ARMv8 or later
architecture at all times. Both floating-point and NEON support are presumed to be
present in hardware.
The ARMv8 specification describes new optional crypto and CRC helper opcodes for
both AArch32 and AArch64. Support for them is currently optional, but recommended.
To take advantage of these opcodes, apps should first make runtime checks for their
existence.
As with the ARM32 version of Windows, on ARM64 Windows executes in little-endian
mode. Switching endianness is difficult to achieve without kernel mode support in
AArch64, so it's easier to enforce.
Windows running on ARM64 enables the CPU hardware to handle misaligned accesses
transparently. In an improvement from AArch32, this support now also works for all
integer accesses (including multi-word accesses) and for floating-point accesses.
However, accesses to uncached (device) memory still must always be aligned. If code
could possibly read or write misaligned data from uncached memory, it must make sure
to align all accesses.
Default layout alignment for locals:
Size in bytes Alignment in bytes
1 1
2 2
3, 4 4
> 4 8
Default layout alignment for globals and statics:
Size in bytes Alignment in bytes
1 1
Base requirements
Endianness
Alignment
Size in bytes Alignment in bytes
2 - 7 4
8 - 63 8
>= 64 16
The AArch64 architecture supports 32 integer registers:
Register Volatility Role
x0-x8 Volatile Parameter/Result scratch registers
x9-x15 Volatile Scratch registers
x16-x17 Volatile Intra-procedure-call scratch registers
x18 N/A Reserved platform register: in kernel mode, points to KPCR for the current
processor; In user mode, points to TEB
x19-x28 Non￾volatile
Scratch registers
x29/fp Non￾volatile
Frame pointer
x30/lr Both Link Register: Callee function must preserve it for its own return, but
caller's value will be lost.
Each register may be accessed as a full 64-bit value (via x0-x30) or as a 32-bit value (via
w0-w30). 32-bit operations zero-extend their results up to 64 bits.
See the Parameter passing section for details on the use of the parameter registers.
Unlike AArch32, the program counter (PC) and the stack pointer (SP) aren't indexed
registers. They're limited in how they may be accessed. Also note that there's no x31
register. That encoding is used for special purposes.
The frame pointer (x29) is required for compatibility with fast stack walking used by ETW
and other services. It must point to the previous {x29, x30} pair on the stack.
Integer registers
Floating-point/SIMD registers
The AArch64 architecture also supports 32 floating-point/SIMD registers, summarized
below:
Register Volatility Role
v0-v7 Volatile Parameter/Result scratch registers
v8-v15 Both Low 64 bits are Non-Volatile. High 64 bits are Volatile.
v16-v31 Volatile Scratch registers
Each register may be accessed as a full 128-bit value (via v0-v31 or q0-q31). It may be
accessed as a 64-bit value (via d0-d31), as a 32-bit value (via s0-s31), as a 16-bit value
(via h0-h31), or as an 8-bit value (via b0-b31). Accesses smaller than 128 bits only access
the lower bits of the full 128-bit register. They leave the remaining bits untouched
unless otherwise specified. (AArch64 is different from AArch32, where the smaller
registers were packed on top of the larger registers.)
The floating-point control register (FPCR) has certain requirements on the various
bitfields within it:
Bits Meaning Volatility Role
26 AHP Non-Volatile Alternative half-precision control.
25 DN Non-Volatile Default NaN mode control.
24 FZ Non-volatile Flush-to-zero mode control.
23-22 RMode Non-volatile Rounding mode control.
15,12-8 IDE/IXE/etc Non-Volatile Exception trap enable bits, must always be 0.
Like AArch32, the AArch64 specification provides three system-controlled "thread ID"
registers:
Register Role
TPIDR_EL0 Reserved.
TPIDRRO_EL0 Contains CPU number for current processor.
TPIDR_EL1 Points to KPCR structure for current processor.
System registers
Floating-point exceptions
Support for IEEE floating-point exceptions is optional on AArch64 systems. For
processor variants that do have hardware floating-point exceptions, the Windows kernel
silently catches the exceptions and implicitly disables them in the FPCR register. This
trap ensures normalized behavior across processor variants. Otherwise, code developed
on a platform without exception support may find itself taking unexpected exceptions
when running on a platform with support.
Parameter passing
For non-variadic functions, the Windows ABI follows the rules specified by ARM for
parameter passing. These rules are excerpted directly from the Procedure Call Standard
for the AArch64 Architecture:
Stage A – Initialization
This stage is done exactly once, before processing of the arguments begins.
1. The Next General-purpose Register Number (NGRN) is set to zero.
2. The Next SIMD and Floating-point Register Number (NSRN) is set to zero.
3. The next stacked argument address (NSAA) is set to the current stack-pointer value
(SP).
Stage B – Pre-padding and extension of arguments
For each argument in the list, the first matching rule from the following list is applied. If
no rule matches, the argument is used unmodified.
1. If the argument type is a Composite Type whose size can't be statically determined
by both the caller and the callee, the argument is copied to memory and the
argument is replaced by a pointer to the copy. (There are no such types in C/C++
but they exist in other languages or in language extensions).
2. If the argument type is an HFA or an HVA, then the argument is used unmodified.
3. If the argument type is a Composite Type larger than 16 bytes, then the argument
is copied to memory allocated by the caller, and the argument is replaced by a
pointer to the copy.
4. If the argument type is a Composite Type, then the size of the argument is
rounded up to the nearest multiple of 8 bytes.
Stage C – Assignment of arguments to registers and stack
For each argument in the list, the following rules are applied in turn until the argument
has been allocated. When an argument is assigned to a register, any unused bits in the
register have unspecified value. If an argument is assigned to a stack slot, any unused
padding bytes have unspecified value.
1. If the argument is a Half-, Single-, Double- or Quad-precision Floating-point or
Short Vector Type, and the NSRN is less than 8, then the argument is allocated to
the least significant bits of register v[NSRN]. The NSRN is incremented by one. The
argument has now been allocated.
2. If the argument is an HFA or an HVA, and there are sufficient unallocated SIMD and
Floating-point registers (NSRN + number of members ≤ 8), then the argument is
allocated to SIMD and Floating-point Registers, one register per member of the
HFA or HVA. The NSRN is incremented by the number of registers used. The
argument has now been allocated.
3. If the argument is an HFA or an HVA, then the NSRN is set to 8, and the size of the
argument is rounded up to the nearest multiple of 8 bytes.
4. If the argument is an HFA, an HVA, a Quad-precision Floating-point or Short Vector
Type, then the NSAA is rounded up to the larger of 8 or the Natural Alignment of
the argument's type.
5. If the argument is a Half- or Single-precision Floating Point type, then the size of
the argument is set to 8 bytes. The effect is as if the argument had been copied to
the least significant bits of a 64-bit register, and the remaining bits filled with
unspecified values.
6. If the argument is an HFA, an HVA, a Half-, Single-, Double-, or Quad-precision
Floating-point or Short Vector Type, then the argument is copied to memory at the
adjusted NSAA. The NSAA is incremented by the size of the argument. The
argument has now been allocated.
7. If the argument is an Integral or Pointer Type, the size of the argument is less than
or equal to 8 bytes, and the NGRN is less than 8, the argument is copied to the
least significant bits in x[NGRN]. The NGRN is incremented by one. The argument
has now been allocated.
8. If the argument has an alignment of 16, then the NGRN is rounded up to the next
even number.
9. If the argument is an Integral Type, the size of the argument is equal to 16, and the
NGRN is less than 7, the argument is copied to x[NGRN] and x[NGRN+1]. x[NGRN]
shall contain the lower addressed double-word of the memory representation of
the argument. The NGRN is incremented by two. The argument has now been
allocated.
10. If the argument is a Composite Type, and the size in double-words of the
argument is no more than 8 minus NGRN, then the argument is copied into
consecutive general-purpose registers, starting at x[NGRN]. The argument is
passed as though it had been loaded into the registers from a double-word￾aligned address, with an appropriate sequence of LDR instructions that load
consecutive registers from memory. The contents of any unused parts of the
registers are unspecified by this standard. The NGRN is incremented by the
number of registers used. The argument has now been allocated.
11. The NGRN is set to 8.
12. The NSAA is rounded up to the larger of 8 or the Natural Alignment of the
argument's type.
13. If the argument is a composite type, then the argument is copied to memory at the
adjusted NSAA. The NSAA is incremented by the size of the argument. The
argument has now been allocated.
14. If the size of the argument is less than 8 bytes, then the size of the argument is set
to 8 bytes. The effect is as if the argument was copied to the least significant bits
of a 64-bit register, and the remaining bits were filled with unspecified values.
15. The argument is copied to memory at the adjusted NSAA. The NSAA is
incremented by the size of the argument. The argument has now been allocated.
Addendum: Variadic functions
Functions that take a variable number of arguments are handled differently than above,
as follows:
1. All composites are treated alike; no special treatment of HFAs or HVAs.
2. SIMD and Floating-point Registers aren't used.
Effectively, it's the same as following rules C.12–C.15 to allocate arguments to an
imaginary stack, where the first 64 bytes of the stack are loaded into x0-x7, and any
remaining stack arguments are placed normally.
Return values
Integral values are returned in x0.
Floating-point values are returned in s0, d0, or v0, as appropriate.
A type is considered to be an HFA or HVA if all of the following hold:
It's non-empty,
It doesn't have any non-trivial default or copy constructors, destructors, or
assignment operators,
All of its members have the same HFA or HVA type, or are float, double, or neon
types that match the other members' HFA or HVA types.
HVA values with four or fewer elements are returned in s0-s3, d0-d3, or v0-v3, as
appropriate.
Types returned by value are handled differently depending on whether they have certain
properties, and whether the function is a non-static member function. Types which have
all of these properties,
they're aggregate by the C++14 standard definition, that is, they have no user￾provided constructors, no private or protected non-static data members, no base
classes, and no virtual functions, and
they have a trivial copy-assignment operator, and
they have a trivial destructor,
and are returned by non-member functions or static member functions, use the
following return style:
Types that are HFAs with four or fewer elements are returned in s0-s3, d0-d3, or
v0-v3, as appropriate.
Types less than or equal to 8 bytes are returned in x0.
Types less than or equal to 16 bytes are returned in x0 and x1, with x0 containing
the lower-order 8 bytes.
For other aggregate types, the caller shall reserve a block of memory of sufficient
size and alignment to hold the result. The address of the memory block shall be
passed as an additional argument to the function in x8. The callee may modify the
result memory block at any point during the execution of the subroutine. The
callee isn't required to preserve the value stored in x8.
All other types use this convention:
The caller shall reserve a block of memory of sufficient size and alignment to hold
the result. The address of the memory block shall be passed as an additional
argument to the function in x0, or x1 if $this is passed in x0. The callee may modify
the result memory block at any point during the execution of the subroutine. The
callee returns the address of the memory block in x0.
Stack
Following the ABI put forth by ARM, the stack must remain 16-byte aligned at all times.
AArch64 contains a hardware feature that generates stack alignment faults whenever
the SP isn't 16-byte aligned and an SP-relative load or store is done. Windows runs with
this feature enabled at all times.
Functions that allocate 4k or more worth of stack must ensure that each page prior to
the final page is touched in order. This action ensures no code can "leap over" the guard
pages that Windows uses to expand the stack. Typically the touching is done by the
__chkstk helper, which has a custom calling convention that passes the total stack
allocation divided by 16 in x15.
Red zone
The 16-byte area immediately below the current stack pointer is reserved for use by
analysis and dynamic patching scenarios. This area permits carefully generated code to
be inserted which stores two registers at [sp, #-16] and temporarily uses them for
arbitrary purposes. The Windows kernel guarantees that those 16 bytes aren't
overwritten if an exception or interrupt is taken, in both user and kernel mode.
Kernel stack
The default kernel mode stack in Windows is six pages (24k). Pay extra attention to
functions with large stack buffers in kernel mode. An ill-timed interrupt could come in
with little headroom and create a stack panic bug check.
Stack walking
Code within Windows is compiled with frame pointers enabled (/Oy-) to enable fast
stack walking. Generally, x29 (fp) points to the next link in the chain, which is an {fp, lr}
pair, indicating the pointer to the previous frame on the stack and the return address.
Third-party code is encouraged to enable frame pointers as well, to allow for improved
profiling and tracing.
Exception unwinding
Unwinding during exception handling is assisted through the use of unwind codes. The
unwind codes are a sequence of bytes stored in the .xdata section of the executable.
They describe the operation of the prologue and epilogue in an abstract manner, such
that the effects of a function's prologue can be undone in preparation for backing up to
the caller's stack frame. For more information on the unwind codes, see ARM64
exception handling.
The ARM EABI also specifies an exception unwinding model that uses unwind codes.
However, the specification as presented is insufficient for unwinding in Windows, which
must handle cases where the PC is in the middle of a function prologue or epilogue.
Code that is dynamically generated should be described with dynamic function tables
via RtlAddFunctionTable and associated functions, so that the generated code can
participate in exception handling.
Cycle counter
All ARMv8 CPUs are required to support a cycle counter register, a 64-bit register that
Windows configures to be readable at any exception level, including user mode. It can
be accessed via the special PMCCNTR_EL0 register, using the MSR opcode in assembly
code, or the _ReadStatusReg intrinsic in C/C++ code.
The cycle counter here is a true cycle counter, not a wall clock. The counting frequency
will vary with the processor frequency. If you feel you must know the frequency of the
cycle counter, you shouldn't be using the cycle counter. Instead, you want to measure
wall clock time, for which you should use QueryPerformanceCounter .
See also
Common Visual C++ ARM Migration Issues
ARM64 exception handling
Overview of ARM64EC ABI conventions
Article • 10/14/2022
ARM64EC is an application binary interface (ABI) that enables ARM64 binaries to run natively and
interoperably with x64 code. Specifically, the ARM64EC ABI follows x64 software conventions
including calling convention, stack usage, and data alignment, making ARM64EC and x64 code
interoperable. The operating system emulates the x64 portion of the binary. (The EC in ARM64EC
stands for emulation compatible.)
For more information on the x64 and ARM64 ABIs, see Overview of x64 ABI conventions and
Overview of ARM64 ABI conventions.
ARM64EC doesn't solve memory model differences between x64 and ARM based architectures. For
more information, see Common Visual C++ ARM migration issues.
ARM64 - The code stream for ARM64 processes that contains traditional ARM64 code.
ARM64EC - The code stream that utilizes a subset of the ARM64 register set to provide
interoperability with x64 code.
x64 processes may have threads running ARM64EC code. So it's always possible to retrieve an x64
register context, ARM64EC uses a subset of the ARM64 core registers that map 1:1 to emulated
x64 registers. Importantly, ARM64EC never uses registers outside of this subset, except to read the
Thread Environment Block (TEB) address from x18 .
Native ARM64 processes shouldn't regress in performance when some or many functions are
recompiled as ARM64EC. To maintain performance, the ABI follows these principles:
The ARM64EC register subset includes all registers that are part of the ARM64 function
calling convention.
The ARM64EC calling convention directly maps to the ARM64 calling convention.
Special helper routines like __chkstk_arm64ec use custom calling conventions and registers. These
registers are also included in the ARM64EC subset of registers.
ARM64EC register x64 register ARM64EC calling
convention
ARM64 calling
convention
x64 calling
convention
x0 rcx volatile volatile volatile
Definitions
Register mapping
Register mapping for integer registers
ARM64EC register x64 register ARM64EC calling
convention
ARM64 calling
convention
x64 calling
convention
x1 rdx volatile volatile volatile
x2 r8 volatile volatile volatile
x3 r9 volatile volatile volatile
x4 r10 volatile volatile volatile
x5 r11 volatile volatile volatile
x6 mm1 (low 64 bits of x87 R1
register)
volatile volatile volatile
x7 mm2 (low 64 bits of x87 R2
register)
volatile volatile volatile
x8 rax volatile volatile volatile
x9 mm3 (low 64 bits of x87 R3
register)
volatile volatile volatile
x10 mm4 (low 64 bits of x87 R4
register)
volatile volatile volatile
x11 mm5 (low 64 bits of x87 R5
register)
volatile volatile volatile
x12 mm6 (low 64 bits of x87 R6
register)
volatile volatile volatile
x13 N/A disallowed volatile N/A
x14 N/A disallowed volatile N/A
x15 mm7 (low 64 bits of x87 R7
register)
volatile volatile volatile
x16 High 16 bits of each of the
x87 R0 - R3 registers
volatile( xip0 ) volatile( xip0 ) volatile
x17 High 16 bits of each of the
x87 R4 - R7 registers
volatile( xip1 ) volatile( xip1 ) volatile
x18 N/A fixed(TEB) fixed(TEB) volatile
x19 r12 non-volatile non-volatile non-volatile
x20 r13 non-volatile non-volatile non-volatile
x21 r14 non-volatile non-volatile non-volatile
x22 r15 non-volatile non-volatile non-volatile
x23 N/A disallowed non-volatile N/A
ARM64EC register x64 register ARM64EC calling
convention
ARM64 calling
convention
x64 calling
convention
x24 N/A disallowed non-volatile N/A
x25 rsi non-volatile non-volatile non-volatile
x26 rdi non-volatile non-volatile non-volatile
x27 rbx non-volatile non-volatile non-volatile
x28 N/A disallowed disallowed N/A
fp rbp non-volatile non-volatile non-volatile
lr mm0 (low 64 bits of x87 R0
register)
volatile volatile N/A
sp rsp non-volatile non-volatile non-volatile
pc rip instruction pointer instruction
pointer
instruction
pointer
PSTATE subset:
N / Z / C / V / SS
RFLAGS subset:
SF / ZF / CF / OF / TF
volatile volatile volatile
N/A RFLAGS subset: PF / AF N/A N/A volatile
N/A RFLAGS subset: DF N/A N/A non-volatile
 Avoid directly reading, writing or computing mappings between PSTATE and RFLAGS . These bits
may be used in the future and are subject to change.
 The ARM64EC carry flag C is the inverse of the x64 carry flag CF for subtraction operations.
There's no special handling, because the flag is volatile and is therefore trashed when transitioning
between (ARM64EC and x64) functions.
ARM64EC
register
x64 register ARM64EC calling
convention
ARM64 calling
convention
x64 calling convention
v0 - v5 xmm0 - xmm5 volatile volatile volatile
v6 - v7 xmm6 - xmm7 volatile volatile non-volatile
v8 - v15 xmm8 - xmm15 volatile volatile non-volatile
v16 - v31 xmm16 - xmm31 disallowed volatile disallowed (x64 emulator doesn't
support AVX-512)
FPCR MXCSR[15:6] non-volatile non-volatile non-volatile
1, 2
1
2
Register mapping for vector registers
1 1
2
ARM64EC
register
x64 register ARM64EC calling
convention
ARM64 calling
convention
x64 calling convention
FPSR MXCSR[5:0] volatile volatile volatile
 These ARM64 registers are special in that the lower 64 bits are non-volatile but the upper 64 bits
are volatile. From the point of view of an x64 caller, they're effectively volatile because the callee
would trash data.
 Avoid directly reading, writing, or computing mappings of FPCR and FPSR . These bits may be
used in the future and are subject to change.
ARM64EC follows the same struct packing rules used for x64 to ensure interoperability between
ARM64EC code and x64 code. For more information and examples of x64 struct packing, see
Overview of x64 ABI conventions.
ARM64EC code and thunks use emulation helper routines to transition between x64 and ARM64EC
functions.
The following table describes each special ABI routine and the registers the ABI uses. The routines
don't modify the listed preserved registers under the ABI column. No assumptions should be
made about unlisted registers. On-disk, the ABI routine pointers are null. At load time, the loader
updates the pointers to point to the x64 emulator routines.
Name Description ABI
__os_arm64x_dispatch_call_no_redirect Called by an exit thunk
to call an x64 target
(either an x64 function or
an x64 fast-forward
sequence). The routine
pushes the ARM64EC
return address (in the LR
register) followed by the
address of the
instruction that succeeds
a blr x16 instruction
that invokes the x64
emulator. It then runs
the blr x16 instruction
return value in x8 ( rax )
2
1
2
Struct packing
Emulation helper ABI routines
Name Description ABI
__os_arm64x_dispatch_ret Called by an entry thunk
to return to its x64 caller.
It pops the x64 return
address from the stack
and invokes the x64
emulator to jump to it
N/A
__os_arm64x_check_call Called by ARM64EC code
with a pointer to an exit
thunk and the indirect
ARM64EC target address
to execute. The
ARM64EC target is
considered patchable,
and execution always
returns to the caller with
either the same data it
was called with, or with
modified data
Arguments:
x9 : The target address
x10 : The exit thunk address
x11 : The fast forward sequence address
Out:
x9 : If the target function was detoured, it
contains the address of the fast forward
sequence
x10 : The exit thunk address
x11 : If the function was detoured, it contains
the exit thunk address. Otherwise, the target
address jumped to
Preserved registers: x0 - x8 , x15 ( chkstk ). and
q0 - q7
Name Description ABI
__os_arm64x_check_icall Called by ARM64EC
code, with a pointer to
an exit thunk, to handle
a jump to either a target
address that is either x64
or ARM64EC. If the
target is x64 and the x64
code hasn't been
patched, the routine sets
the target address
register. It points to the
ARM64EC version of the
function if one exists.
Otherwise, it sets the
register to point to the
exit thunk that
transitions to the x64
target. Then, it returns to
the calling ARM64EC
code, which then jumps
to the address in the
register. This routine is a
non-optimized version
of
__os_arm64x_check_call ,
where the target address
isn't known at compile
time
Used at a call-site of an
indirect call
Arguments:
x9 : The target address
x10 : The exit thunk address
x11 : The fast forward sequence address
Out:
x9 : If the target function was detoured, it
contains the address of the fast forward
sequence
x10 : The exit thunk address
x11 : If the function was detoured, it contains
the exit thunk address. Otherwise, the target
address jumped to
Preserved registers: x0 - x8 , x15 ( chkstk ), and
q0 - q7
__os_arm64x_check_icall_cfg Same as
__os_arm64x_check_icall
but also checks that the
specified address is a
valid Control Flow Graph
indirect call target
Arguments:
x10 : The address of the exit thunk
x11 : The address of the target function
Out:
x9 : If the target is x64, the address to the
function. Otherwise, undefined
x10 : The address of the exit thunk
x11 : If the target is x64, it contains the address
of the exit thunk. Otherwise, the address of the
function
Preserved registers: x0 - x8 , x15 ( chkstk ), and
q0 - q7
__os_arm64x_get_x64_information Gets the requested part
of the live x64 register
context
_Function_class_(ARM64X_GET_X64_INFORMATION)
NTSTATUS LdrpGetX64Information(_In_ ULONG
Type, _Out_ PVOID Output, _In_ PVOID
ExtraInfo)
Name Description ABI
__os_arm64x_set_x64_information Sets the requested part
of the live x64 register
context
_Function_class_(ARM64X_SET_X64_INFORMATION)
NTSTATUS LdrpSetX64Information(_In_ ULONG
Type,_In_ PVOID Input, _In_ PVOID ExtraInfo)
__os_arm64x_x64_jump Used in signature-less
adjustor and other
thunks that directly
forward ( jmp ) a call to
another function that
can have any signature,
deferring the potential
application of the right
thunk to the real target
Arguments:
x9 : target to jump to
All parameter registers preserved (forwarded)
Thunks are the low-level mechanisms to support ARM64EC and x64 functions calling each other.
There are two types: entry thunks for entering ARM64EC functions and exit thunks for calling x64
functions.
To support x64 callers when a C/C++ function is compiled as ARM64EC, the toolchain generates a
single entry thunk consisting of ARM64EC machine code. Intrinsics have an entry thunk of their
own. All other functions share an entry thunk with all functions that have a matching calling
convention, parameters, and return type. The content of the thunk depends on the calling
convention of the C/C++ function.
In addition to handling parameters and the return address, the thunk bridges the differences in
volatility between ARM64EC and x64 vector registers caused by ARM64EC vector register
mapping:
ARM64EC
register
x64
register
ARM64EC calling convention ARM64 calling
convention
x64 calling
convention
v6 - v15 xmm6 - xmm15 volatile, but saved/restored in the
entry thunk (x64 to ARM64EC)
volatile or partially
volatile upper 64 bits
non-volatile
The entry thunk performs the following actions:
Parameter
number
Stack usage
Thunks
Entry thunk and intrinsic entry thunks: x64 to ARM64EC
function call
Parameter
number
Stack usage
0-4 Stores ARM64EC v6 and v7 into the caller-allocated home space
Since the callee is ARM64EC, which doesn't have the notion of a home space, the stored
values aren't clobbered.
Allocates an extra 128 bytes on the stack and store ARM64EC v8 through v15 .
5-8 x4 = 5th parameter from the stack
x5 = 6th parameter from the stack
x6 = 7th parameter from the stack
x7 = 8th parameter from the stack
If the parameter is SIMD, the v4 - v7 registers are used instead
9+ Allocates AlignUp(NumParams - 8 , 2) * 8 bytes on the stack. *
Copies the 9th and remaining parameters to this area
* Aligning the value to an even number guarantees that the stack remains aligned to 16 bytes
If the function accepts a 32-bit integer parameter, the thunk is permitted to only push 32 bits
instead of the full 64 bits of the parent register.
Next, the thunk uses an ARM64 bl instruction to call the ARM64EC function. After the function
returns, the thunk:
1. Undoes any stack allocations
2. Calls the __os_arm64x_dispatch_ret emulator helper to pop the x64 return address and
resume x64 emulation.
For every call that an ARM64EC C/C++ function makes to potential x64 code, the MSVC toolchain
generates an exit thunk. The content of the thunk depends on the parameters of the x64 callee
and whether the callee is using the standard calling convention or __vectorcall . The compiler
obtains this information from a function declaration for the callee.
First, The thunk pushes the return address that's in the ARM64EC lr register and a dummy 8-byte
value to guarantee that the stack is aligned to 16 bytes. Second, the thunk handles the parameters:
Parameter
number
Stack usage
0-4 Allocates 32 bytes of home space on the stack
Exit thunk: ARM64EC to x64 function call
Parameter
number
Stack usage
5-8 Allocates AlignUp(NumParams - 4, 2) * 8 more bytes higher up on the stack. * 
Copies the 5th and any subsequent parameters from ARM64EC's x4 - x7 to this extra
space
9+ Copies the 9th and remaining parameters to the extra space
* Aligning the value to an even number guarantees that the stack remains aligned to 16 bytes.
Third, the thunk calls the __os_arm64x_dispatch_call_no_redirect emulator helper to invoke the
x64 emulator to run the x64 function. The call must be a blr x16 instruction (conveniently, x16 is
a volatile register). A blr x16 instruction is required because the x64 emulator parses this
instruction as a hint.
The x64 function usually attempts to return to the emulator helper by using an x64 ret
instruction. At this point, the x64 emulator detects that it's in ARM64EC code. It then reads the
preceding 4-byte hint that happens to be the ARM64 blr x16 instruction. Since this hint indicates
that the return address is in this helper, the emulator jumps directly to this address.
The x64 function is permitted to return to the emulator helper using any branch instruction,
including x64 jmp and call . The emulator handles these scenarios as well.
When the helper then returns to the thunk, the thunk:
1. Undoes any stack allocation
2. Pops the ARM64EC lr register
3. Executes an ARM64 ret lr instruction.
An ARM64EC function name has a secondary decoration applied after any language-specific
decoration. For functions with C linkage (whether compiled as C or by using extern "C" ), a # is
prepended to the name. For C++ decorated functions, a $$h tag is inserted into the name.
The ARM64EC toolchain currently doesn't support __vectorcall . The compiler emits an error
when it detects __vectorcall usage with ARM64EC.
ARM64EC function name decoration
foo => #foo
?foo@@YAHXZ => ?foo@@$$hYAHXZ
__vectorcall
See also
Understanding ARM64EC ABI and assembly code
Common Visual C++ ARM migration issues
Decorated names
ARM Exception Handling
Article • 05/25/2022
Windows on ARM uses the same structured exception-handling mechanism for
asynchronous hardware-generated exceptions and synchronous software-generated
exceptions. Language-specific exception handlers are built on top of Windows
structured exception handling by using language helper functions. This document
describes exception handling in Windows on ARM, and the language helpers both the
Microsoft ARM assembler and the MSVC compiler generate.
ARM Exception Handling
Windows on ARM uses unwind codes to control stack unwinding during structured
exception handling (SEH). Unwind codes are a sequence of bytes stored in the .xdata
section of the executable image. These codes describe the operation of function
prologue and epilogue code in an abstract way. The handler uses them to undo the
function prologue's effects when it unwinds to the caller's stack frame.
The ARM EABI (embedded application binary interface) specifies a model for exception
unwinding that uses unwind codes. The model isn't sufficient for SEH unwinding in
Windows. It must handle asynchronous cases where the processor is in the middle of
the prologue or epilogue of a function. Windows also separates unwinding control into
function-level unwinding and language-specific scope unwinding, which is unified in the
ARM EABI. For these reasons, Windows on ARM specifies more details for the unwinding
data and procedure.
Assumptions
Executable images for Windows on ARM use the Portable Executable (PE) format. For
more information, see PE Format. Exception handling information is stored in the
.pdata and .xdata sections of the image.
The exception handling mechanism makes certain assumptions about code that follows
the ABI for Windows on ARM:
When an exception occurs within the body of a function, the handler could undo
the prologue's operations, or do the epilogue's operations in a forward manner.
Both should produce identical results.
Prologues and epilogues tend to mirror each other. This feature can be used to
reduce the size of the metadata needed to describe unwinding.
Functions tend to be relatively small. Several optimizations rely on this observation
for efficient packing of data.
If a condition is placed on an epilogue, it applies equally to each instruction in the
epilogue.
If the prologue saves the stack pointer (SP) in another register, that register must
remain unchanged throughout the function, so the original SP may be recovered
at any time.
Unless the SP is saved in another register, all manipulation of it must occur strictly
within the prologue and epilogue.
To unwind any stack frame, these operations are required:
Adjust r13 (SP) in 4-byte increments.
Pop one or more integer registers.
Pop one or more VFP (virtual floating-point) registers.
Copy an arbitrary register value to r13 (SP).
Load SP from the stack by using a small post-decrement operation.
Parse one of a few well-defined frame types.
.pdata Records
The .pdata records in a PE-format image are an ordered array of fixed-length items that
describe every stack-manipulating function. Leaf functions (functions that don't call
other functions) don't require .pdata records when they don't manipulate the stack.
(That is, they don't require any local storage and don't have to save or restore non￾volatile registers.). Records for these functions can be omitted from the .pdata section
to save space. An unwind operation from one of these functions can just copy the return
address from the Link Register (LR) to the program counter (PC) to move up to the
caller.
Every .pdata record for ARM is 8 bytes long. The general format of a record places the
relative virtual address (RVA) of the function start in the first 32-bit word, followed by a
second word that contains either a pointer to a variable-length .xdata block, or a
packed word that describes a canonical function unwinding sequence, as shown in this
table:
Word
Offset
Bits Purpose
0 0-
31
Function Start RVA is the 32-bit RVA of the start of the function. If the function
contains thumb code, the low bit of this address must be set.
1 0-1 Flag is a 2-bit field that indicates how to interpret the remaining 30 bits of the
second .pdata word. If Flag is 0, then the remaining bits form an Exception
Information RVA (with the low two bits implicitly 0). If Flag is non-zero, then the
remaining bits form a Packed Unwind Data structure.
1 2-
31
Exception Information RVA or Packed Unwind Data.
Exception Information RVA is the address of the variable-length exception
information structure, stored in the .xdata section. This data must be 4-byte
aligned.
Packed Unwind Data is a compressed description of the operations required to
unwind from a function, assuming a canonical form. In this case, no .xdata record
is required.
For functions whose prologues and epilogues follow the canonical form described
below, packed unwind data can be used. It eliminates the need for an .xdata record
and significantly reduces the space required to provide the unwind data. The canonical
prologues and epilogues are designed to meet the common requirements of a simple
function that doesn't require an exception handler, and performs its setup and teardown
operations in a standard order.
This table shows the format of a .pdata record that has packed unwind data:
Word
Offset
Bits Purpose
0 0-
31
Function Start RVA is the 32-bit RVA of the start of the function. If the function
contains thumb code, the low bit of this address must be set.
Packed Unwind Data
Word
Offset
Bits Purpose
1 0-1 Flag is a 2-bit field that has these meanings:
- 00 = packed unwind data not used; remaining bits point to .xdata record.
- 01 = packed unwind data.
- 10 = packed unwind data where the function is assumed to have no prologue.
This is useful for describing function fragments that are discontiguous with the
start of the function.
- 11 = reserved.
1 2-
12
Function Length is an 11-bit field that provides the length of the entire function
in bytes divided by 2. If the function is larger than 4K bytes, a full .xdata record
must be used instead.
1 13-
14
Ret is a 2-bit field that indicates how the function returns:
- 00 = return via pop {pc} (the L flag bit must be set to 1 in this case).
- 01 = return by using a 16-bit branch.
- 10 = return by using a 32-bit branch.
- 11 = no epilogue at all. This is useful for describing a discontiguous function
fragment that may only contain a prologue, but whose epilogue is elsewhere.
1 15 H is a 1-bit flag that indicates whether the function "homes" the integer
parameter registers (r0-r3) by pushing them at the start of the function, and
deallocates the 16 bytes of stack before returning. (0 = doesn't home registers, 1
= homes registers.)
1 16-
18
Reg is a 3-bit field that indicates the index of the last saved non-volatile register. If
the R bit is 0, then only integer registers are being saved, and are assumed to be
in the range of r4-rN, where N is equal to 4 + Reg . If the R bit is 1, then only
floating-point registers are being saved, and are assumed to be in the range of
d8-dN, where N is equal to 8 + Reg . The special combination of R = 1 and Reg =
7 indicates that no registers are saved.
1 19 R is a 1-bit flag that indicates whether the saved non-volatile registers are integer
registers (0) or floating-point registers (1). If R is set to 1 and the Reg field is set
to 7, no non-volatile registers were pushed.
1 20 L is a 1-bit flag that indicates whether the function saves/restores LR, along with
other registers indicated by the Reg field. (0 = doesn't save/restore, 1 = does
save/restore.)
1 21 C is a 1-bit flag that indicates whether the function includes extra instructions to
set up a frame chain for fast stack walking (1) or not (0). If this bit is set, r11 is
implicitly added to the list of integer non-volatile registers saved. (See restrictions
below if the C flag is used.)
Word
Offset
Bits Purpose
1 22-
31
Stack Adjust is a 10-bit field that indicates the number of bytes of stack that are
allocated for this function, divided by 4. However, only values between 0x000-
0x3F3 can be directly encoded. Functions that allocate more than 4044 bytes of
stack must use a full .xdata record. If the Stack Adjust field is 0x3F4 or larger,
then the low 4 bits have special meaning:
- Bits 0-1 indicate the number of words of stack adjustment (1-4) minus 1.
- Bit 2 is set to 1 if the prologue combined this adjustment into its push operation.
- Bit 3 is set to 1 if the epilogue combined this adjustment into its pop operation.
Due to possible redundancies in the encodings above, these restrictions apply:
If the C flag is set to 1:
The L flag must also be set to 1, because frame chaining requires both r11 and
LR.
r11 must not be included in the set of registers described by Reg . That is, if r4-
r11 are pushed, Reg should only describe r4-r10, because the C flag implies r11.
If the Ret field is set to 0, the L flag must be set to 1.
Violating these restrictions causes an unsupported sequence.
For purposes of the discussion below, two pseudo-flags are derived from Stack Adjust :
PF or "prologue folding" indicates that Stack Adjust is 0x3F4 or larger and bit 2 is
set.
EF or "epilogue folding" indicates that Stack Adjust is 0x3F4 or larger and bit 3 is
set.
Prologues for canonical functions may have up to 5 instructions (notice that 3a and 3b
are mutually exclusive):
Instruction Opcode is assumed present if: Size Opcode Unwind Codes
1 H==1 16 push {r0-r3} 04
2 C==1 or L==1 or R==0 or
PF==1
16/32 push
{registers}
80-BF/D0-DF/EC￾ED
3a C==1 and ( R==1 and PF==0) 16 mov r11,sp FB
Instruction Opcode is assumed present if: Size Opcode Unwind Codes
3b C==1 and ( R==0 or PF==1) 32 add r11,sp,#xx FC
4 R==1 and Reg != 7 32 vpush {d8-dE} E0-E7
5 Stack Adjust != 0 and PF==0 16/32 sub sp,sp,#xx 00-7F/E8-EB
Instruction 1 is always present if the H bit is set to 1.
To set up the frame chaining, either instruction 3a or 3b is present if the C bit is set. It is
a 16-bit mov if no registers other than r11 and LR are pushed; otherwise, it is a 32-bit
add .
If a non-folded adjustment is specified, instruction 5 is the explicit stack adjustment.
Instructions 2 and 4 are set based on whether a push is required. This table summarizes
which registers are saved based on the C , L , R , and PF fields. In all cases, N is equal to
Reg + 4, E is equal to Reg + 8, and S is equal to (~Stack Adjust ) & 3.
C L R PF Integer Registers Pushed VFP Registers pushed
0 0 0 0 r4 - r* N * none
0 0 0 1 r* S * - r* N * none
0 0 1 0 none d8 - d* E *
0 0 1 1 r* S * - r3 d8 - d* E *
0 1 0 0 r4 - r* N *, LR none
0 1 0 1 r* S * - r* N *, LR none
0 1 1 0 LR d8 - d* E *
0 1 1 1 r* S * - r3, LR d8 - d* E *
1 0 0 0 (invalid encoding) (invalid encoding)
1 0 0 1 (invalid encoding) (invalid encoding)
1 0 1 0 (invalid encoding) (invalid encoding)
1 0 1 1 (invalid encoding) (invalid encoding)
1 1 0 0 r4 - r* N *, r11, LR none
1 1 0 1 r* S * - r* N *, r11, LR none
C L R PF Integer Registers Pushed VFP Registers pushed
1 1 1 0 r11, LR d8 - d* E *
1 1 1 1 r* S * - r3, r11, LR d8 - d* E *
The epilogues for canonical functions follow a similar form, but in reverse and with some
additional options. The epilogue may be up to 5 instructions long, and its form is strictly
dictated by the form of the prologue.
Instruction Opcode is assumed present if: Size Opcode
6 Stack Adjust !=0 and EF==0 16/32 add sp,sp,#xx
7 R==1 and Reg !=7 32 vpop {d8-dE}
8 C==1 or ( L==1 and ( H==0 or Ret !=0)) or R==0 or
EF==1
16/32 pop {registers}
9a H==1 and ( L==0 or Ret !=0) 16 add sp,sp,#0x10
9b H==1 and L==1 and Ret==0 32 ldr pc,
[sp],#0x14
10a Ret==1 16 bx reg
10b Ret==2 32 b address
Instruction 6 is the explicit stack adjustment if a non-folded adjustment is specified.
Because PF is independent of EF , it is possible to have instruction 5 present without
instruction 6, or vice-versa.
Instructions 7 and 8 use the same logic as the prologue to determine which registers are
restored from the stack, but with these three changes: first, EF is used in place of PF ;
second, if Ret = 0 and H = 0, then LR is replaced with PC in the register list and the
epilogue ends immediately; third, if Ret = 0 and H = 1, then LR is omitted from the
register list and popped by instruction 9b.
If H is set, then either instruction 9a or 9b is present. Instruction 9a is used when Ret is
nonzero, which also implies the presence of either 10a or 10b. If L=1, then LR was
popped as part of instruction 8. Instruction 9b is used when L is 1 and Ret is zero, to
indicate an early end to the epilogue, and to return and adjust the stack at the same
time.
If the epilogue hasn't already ended, then either instruction 10a or 10b is present, to
indicate a 16-bit or 32-bit branch, based on the value of Ret .
When the packed unwind format is insufficient to describe the unwinding of a function,
a variable-length .xdata record must be created. The address of this record is stored in
the second word of the .pdata record. The format of the .xdata is a packed variable￾length set of words that has four sections:
1. A 1 or 2-word header that describes the overall size of the .xdata structure and
provides key function data. The second word is only present if the Epilogue Count
and Code Words fields are both set to 0. The fields are broken out in this table:
Word Bits Purpose
0 0-
17
Function Length is an 18-bit field that indicates the total length of the
function in bytes, divided by 2. If a function is larger than 512 KB, then
multiple .pdata and .xdata records must be used to describe the function.
For details, see the Large Functions section in this document.
0 18-
19
Vers is a 2-bit field that describes the version of the remaining .xdata . Only
version 0 is currently defined; values of 1-3 are reserved.
0 20 X is a 1-bit field that indicates the presence (1) or absence (0) of exception
data.
0 21 E is a 1-bit field that indicates that information that describes a single
epilogue is packed into the header (1) rather than requiring additional scope
words later (0).
0 22 F is a 1-bit field that indicates that this record describes a function fragment
(1) or a full function (0). A fragment implies that there's no prologue and
that all prologue processing should be ignored.
0 23-
27
Epilogue Count is a 5-bit field that has two meanings, depending on the
state of the E bit:
- If E is 0, this field is a count of the total number of epilogue scopes
described in section 2. If more than 31 scopes exist in the function, then this
field and the Code Words field must both be set to 0 to indicate that an
extension word is required.
- If E is 1, this field specifies the index of the first unwind code that
describes the only epilogue.
0 28-
31
Code Words is a 4-bit field that specifies the number of 32-bit words
required to contain all of the unwind codes in section 4. If more than 15
words are required for more than 63 unwind code bytes, this field and the
Epilogue Count field must both be set to 0 to indicate that an extension
word is required.
.xdata Records
Word Bits Purpose
1 0-
15
Extended Epilogue Count is a 16-bit field that provides more space for
encoding an unusually large number of epilogues. The extension word that
contains this field is only present if the Epilogue Count and Code Words fields
in the first header word are both set to 0.
1 16-
23
Extended Code Words is an 8-bit field that provides more space for encoding
an unusually large number of unwind code words. The extension word that
contains this field is only present if the Epilogue Count and Code Words fields
in the first header word are both set to 0.
1 24-
31
Reserved
2. After the exception data (if the E bit in the header was set to 0) is a list of
information about epilogue scopes, which are packed one to a word and stored in
order of increasing starting offset. Each scope contains these fields:
Bits Purpose
0-
17
Epilogue Start Offset is an 18-bit field that describes the offset of the epilogue, in
bytes divided by 2, relative to the start of the function.
18-
19
Res is a 2-bit field reserved for future expansion. Its value must be 0.
20-
23
Condition is a 4-bit field that gives the condition under which the epilogue is
executed. For unconditional epilogues, it should be set to 0xE, which indicates
"always". (An epilogue must be entirely conditional or entirely unconditional, and in
Thumb-2 mode, the epilogue begins with the first instruction after the IT opcode.)
24-
31
Epilogue Start Index is an 8-bit field that indicates the byte index of the first unwind
code that describes this epilogue.
3. After the list of epilogue scopes comes an array of bytes that contain unwind
codes, which are described in detail in the Unwind Codes section in this article. This
array is padded at the end to the nearest full word boundary. The bytes are stored
in little-endian order so that they can be directly fetched in little-endian mode.
4. If the X field in the header is 1, the unwind code bytes are followed by the
exception handler information. This consists of one Exception Handler RVA that
contains the address of the exception handler, followed immediately by the
(variable-length) amount of data required by the exception handler.
The .xdata record is designed so that it is possible to fetch the first 8 bytes and
compute the full size of the record, not including the length of the variable-sized
exception data that follows. This code snippet computes the record size:
C++
Although the prologue and each epilogue has an index into the unwind codes, the table
is shared between them. It's not uncommon that they can all share the same unwind
codes. We recommend that compiler writers optimize for this case, because the largest
index that can be specified is 255, and that limits the total number of unwind codes
possible for a particular function.
The array of unwind codes is a pool of instruction sequences that describe exactly how
to undo the effects of the prologue, in the order in which the operations must be
undone. The unwind codes are a mini instruction set, encoded as a string of bytes. When
execution is complete, the return address to the calling function is in the LR register, and
all non-volatile registers are restored to their values at the time the function was called.
ULONG ComputeXdataSize(PULONG Xdata)
{
 ULONG Size;
 ULONG EpilogueScopes;
 ULONG UnwindWords;
 if ((Xdata[0] >> 23) != 0) {
 Size = 4;
 EpilogueScopes = (Xdata[0] >> 23) & 0x1f;
 UnwindWords = (Xdata[0] >> 28) & 0x0f;
 } else {
 Size = 8;
 EpilogueScopes = Xdata[1] & 0xffff;
 UnwindWords = (Xdata[1] >> 16) & 0xff;
 }
 if (!(Xdata[0] & (1 << 21))) {
 Size += 4 * EpilogueScopes;
 }
 Size += 4 * UnwindWords;
 if (Xdata[0] & (1 << 20)) {
 Size += 4; // Exception handler RVA
 }
 return Size;
}
Unwind Codes
If exceptions were guaranteed to only ever occur within a function body, and never
within a prologue or epilogue, then only one unwind sequence would be necessary.
However, the Windows unwinding model requires an ability to unwind from within a
partially executed prologue or epilogue. To accommodate this requirement, the unwind
codes have been carefully designed to have an unambiguous one-to-one mapping to
each relevant opcode in the prologue and epilogue. This has several implications:
It is possible to compute the length of the prologue and epilogue by counting the
number of unwind codes. This is possible even with variable-length Thumb-2
instructions because there are distinct mappings for 16-bit and 32-bit opcodes.
By counting the number of instructions past the start of an epilogue scope, it is
possible to skip the equivalent number of unwind codes, and execute the rest of a
sequence to complete the partially-executed unwind that the epilogue was
performing.
By counting the number of instructions before the end of the prologue, it is
possible to skip the equivalent number of unwind codes, and execute the rest of
the sequence to undo only those parts of the prologue that have completed
execution.
The following table shows the mapping from unwind codes to opcodes. The most
common codes are just one byte, while less common ones require two, three, or even
four bytes. Each code is stored from most significant byte to least significant byte. The
unwind code structure differs from the encoding described in the ARM EABI, because
these unwind codes are designed to have a one-to-one mapping to the opcodes in the
prologue and epilogue to allow for unwinding of partially executed prologues and
epilogues.
Byte
1
Byte
2
Byte
3
Byte
4
Opsize Explanation
00-
7F
16 add sp,sp,#X
where X is (Code & 0x7F) * 4
80-
BF
00-
FF
32 pop {r0-r12, lr}
where LR is popped if Code & 0x2000 and r0-r12 are
popped if the corresponding bit is set in Code & 0x1FFF
C0-
CF
16 mov sp,rX
where X is Code & 0x0F
Byte
1
Byte
2
Byte
3
Byte
4
Opsize Explanation
D0-
D7
16 pop {r4-rX,lr}
where X is (Code & 0x03) + 4 and LR is popped if Code &
0x04
D8-
DF
32 pop {r4-rX,lr}
where X is (Code & 0x03) + 8 and LR is popped if Code &
0x04
E0-
E7
32 vpop {d8-dX}
where X is (Code & 0x07) + 8
E8-
EB
00-
FF
32 addw sp,sp,#X
where X is (Code & 0x03FF) * 4
EC￾ED
00-
FF
16 pop {r0-r7,lr}
where LR is popped if Code & 0x0100 and r0-r7 are
popped if the corresponding bit is set in Code & 0x00FF
EE 00-
0F
16 Microsoft-specific
EE 10-
FF
16 Available
EF 00-
0F
32 ldr lr,[sp],#X
where X is (Code & 0x000F) * 4
EF 10-
FF
32 Available
F0-
F4
- Available
F5 00-
FF
32 vpop {dS-dE}
where S is (Code & 0x00F0) >> 4 and E is Code & 0x000F
F6 00-
FF
32 vpop {dS-dE}
where S is ((Code & 0x00F0) >> 4) + 16 and E is (Code &
0x000F) + 16
Byte
1
Byte
2
Byte
3
Byte
4
Opsize Explanation
F7 00-
FF
00-
FF
16 add sp,sp,#X
where X is (Code & 0x00FFFF) * 4
F8 00-
FF
00-
FF
00-
FF
16 add sp,sp,#X
where X is (Code & 0x00FFFFFF) * 4
F9 00-
FF
00-
FF
32 add sp,sp,#X
where X is (Code & 0x00FFFF) * 4
FA 00-
FF
00-
FF
00-
FF
32 add sp,sp,#X
where X is (Code & 0x00FFFFFF) * 4
FB 16 nop (16-bit)
FC 32 nop (32-bit)
FD 16 end + 16-bit nop in epilogue
FE 32 end + 32-bit nop in epilogue
FF - end
This shows the range of hexadecimal values for each byte in an unwind code Code,
along with the opcode size Opsize and the corresponding original instruction
interpretation. Empty cells indicate shorter unwind codes. In instructions that have large
values covering multiple bytes, the most significant bits are stored first. The Opsize field
shows the implicit opcode size associated with each Thumb-2 operation. The apparent
duplicate entries in the table with different encodings are used to distinguish between
different opcode sizes.
The unwind codes are designed so that the first byte of the code tells both the total size
in bytes of the code and the size of the corresponding opcode in the instruction stream.
To compute the size of the prologue or epilogue, walk the unwind codes from the start
of the sequence to the end, and use a lookup table or similar method to determine how
long the corresponding opcode is.
Unwind codes 0xFD and 0xFE are equivalent to the regular end code 0xFF, but account
for one extra nop opcode in the epilogue case, either 16-bit or 32-bit. For prologues,
codes 0xFD, 0xFE and 0xFF are exactly equivalent. This accounts for the common
epilogue endings bx lr or b <tailcall-target> , which don't have an equivalent
prologue instruction. This increases the chance that unwind sequences can be shared
between the prologue and the epilogues.
In many cases, it should be possible to use the same set of unwind codes for the
prologue and all epilogues. However, to handle the unwinding of partially executed
prologues and epilogues, you might have to have multiple unwind code sequences that
vary in ordering or behavior. This is why each epilogue has its own index into the
unwind array to show where to begin executing.
Unwinding Partial Prologues and Epilogues
The most common unwinding case is when the exception occurs in the body of the
function, away from the prologue and all epilogues. In this case, the unwinder executes
the codes in the unwind array beginning at index 0 and continues until an end opcode is
detected.
When an exception occurs while a prologue or epilogue is executing, the stack frame is
only partially constructed, and the unwinder must determine exactly what has been
done in order to correctly undo it.
For example, consider this prologue and epilogue sequence:
asm
0000: push {r0-r3} ; 0x04
0002: push {r4-r9, lr} ; 0xdd
0006: mov r7, sp ; 0xc7
...
0140: mov sp, r7 ; 0xc7
0142: pop {r4-r9, lr} ; 0xdd
0146: add sp, sp, #16 ; 0x04
0148: bx lr
Next to each opcode is the appropriate unwind code to describe this operation. The
sequence of unwind codes for the prologue is a mirror image of the unwind codes for
the epilogue, not counting the final instruction. This case is common, and is the reason
the unwind codes for the prologue are always assumed to be stored in reverse order
from the prologue's execution order. This gives us a common set of unwind codes:
asm
0xc7, 0xdd, 0x04, 0xfd
The 0xFD code is a special code for the end of the sequence that means that the
epilogue is one 16-bit instruction longer than the prologue. This makes greater sharing
of unwind codes possible.
In the example, if an exception occurs while the function body between the prologue
and epilogue is executing, unwinding starts with the epilogue case, at offset 0 within the
epilogue code. This corresponds to offset 0x140 in the example. The unwinder executes
the full unwind sequence, because no cleanup has been done. If instead the exception
occurs one instruction after the beginning of the epilogue code, the unwinder can
successfully unwind by skipping the first unwind code. Given a one-to-one mapping
between opcodes and unwind codes, if unwinding from instruction n in the epilogue,
the unwinder should skip the first n unwind codes.
Similar logic works in reverse for the prologue. If unwinding from offset 0 in the
prologue, nothing has to be executed. If unwinding from one instruction in, the unwind
sequence should start one unwind code from the end because prologue unwind codes
are stored in reverse order. In the general case, if unwinding from instruction n in the
prologue, unwinding should start executing at n unwind codes from the end of the list
of codes.
Prologue and epilogue unwind codes don't always match exactly. In that case, the
unwind code array may have to contain several sequences of codes. To determine the
offset to begin processing codes, use this logic:
1. If unwinding from within the body of the function, begin executing unwind codes
at index 0 and continue until an end opcode is reached.
2. If unwinding from within an epilogue, use the epilogue-specific starting index
provided by the epilogue scope. Calculate how many bytes the PC is from the start
of the epilogue. Skip forward through the unwind codes until all of the already￾executed instructions are accounted for. Execute the unwind sequence starting at
that point.
3. If unwinding from within the prologue, start from index 0 in the unwind codes.
Calculate the length of the prologue code from the sequence, and then calculate
how many bytes the PC is from the end of the prologue. Skip forward through the
unwind codes until all of the unexecuted instructions are accounted for. Execute
the unwind sequence starting at that point.
The unwind codes for the prologue must always be the first in the array. they're also the
codes used to unwind in the general case of unwinding from within the body. Any
epilogue-specific code sequences should follow immediately after the prologue code
sequence.
Function Fragments
For code optimization, it may be useful to split a function into discontiguous parts.
When this is done, each function fragment requires its own separate .pdata—and
possibly .xdata—record.
Assuming that the function prologue is at the beginning of the function and can't be
split, there are four function fragment cases:
Prologue only; all epilogues in other fragments.
Prologue and one or more epilogues; more epilogues in other fragments.
No prologue or epilogues; prologue and one or more epilogues in other
fragments.
Epilogues only; prologue and possibly more epilogues in other fragments.
In the first case, only the prologue must be described. This can be done in compact
.pdata form by describing the prologue normally and specifying a Ret value of 3 to
indicate no epilogue. In the full .xdata form, this can be done by providing the
prologue unwind codes at index 0 as usual, and specifying an epilogue count of 0.
The second case is just like a normal function. If there's only one epilogue in the
fragment, and it is at the end of the fragment, then a compact .pdata record can be
used. Otherwise, a full .xdata record must be used. Keep in mind that the offsets
specified for the epilogue start are relative to the start of the fragment, not the original
start of the function.
The third and fourth cases are variants of the first and second cases, respectively, except
they don't contain a prologue. In these situations, it is assumed that there's code before
the start of the epilogue and it is considered part of the body of the function, which
would normally be unwound by undoing the effects of the prologue. These cases must
therefore be encoded with a pseudo-prologue, which describes how to unwind from
within the body, but which is treated as 0-length when determining whether to perform
a partial unwind at the start of the fragment. Alternatively, this pseudo-prologue may be
described by using the same unwind codes as the epilogue because they presumably
perform equivalent operations.
In the third and fourth cases, the presence of a pseudo-prologue is specified either by
setting the Flag field of the compact .pdata record to 2, or by setting the F flag in the
.xdata header to 1. In either case, the check for a partial prologue unwind is ignored,
and all non-epilogue unwinds are considered to be full.
Large Functions
Fragments can be used to describe functions larger than the 512 KB limit imposed by
the bit fields in the .xdata header. To describe a larger function, just break it into
fragments smaller than 512 KB. Each fragment should be adjusted so it doesn't split an
epilogue into multiple pieces.
Only the first fragment of the function contains a prologue. All other fragments are
marked as having no prologue. Depending on the number of epilogues, each fragment
may contain zero or more epilogues. Keep in mind that each epilogue scope in a
fragment specifies its starting offset relative to the start of the fragment, not the start of
the function.
If a fragment has no prologue and no epilogue, it still requires its own .pdata—and
possibly .xdata—record to describe how to unwind from within the body of the
function.
Shrink-wrapping
A more complex special case of function fragments is called shrink-wrapping. It's a
technique for deferring register saves from the start of the function to later in the
function. It optimizes for simple cases that don't require register saving. This case has
two parts: there's an outer region that allocates the stack space but saves a minimal set
of registers, and an inner region that saves and restores other registers.
asm
ShrinkWrappedFunction
 push {r4, lr} ; A: save minimal non-volatiles
 sub sp, sp, #0x100 ; A: allocate all stack space up front
 ... ; A:
 add r0, sp, #0xE4 ; A: prepare to do the inner save
 stm r0, {r5-r11} ; A: save remaining non-volatiles
 ... ; B:
 add r0, sp, #0xE4 ; B: prepare to do the inner restore
 ldm r0, {r5-r11} ; B: restore remaining non-volatiles
 ... ; C:
 pop {r4, pc} ; C:
Shrink-wrapped functions are typically expected to pre-allocate the space for the extra
register saves in the regular prologue, and then save the registers by using str or stm
instead of push . This action keeps all stack-pointer manipulation in the function's
original prologue.
The example shrink-wrapped function must be broken into three regions, which are
marked as A , B , and C in the comments. The first A region covers the start of the
function through the end of the additional non-volatile saves. A .pdata or .xdata
record must be constructed to describe this fragment as having a prologue and no
epilogues.
The middle B region gets its own .pdata or .xdata record that describes a fragment
that has no prologue and no epilogue. However, the unwind codes for this region must
still be present because it's considered a function body. The codes must describe a
composite prologue that represents both the original registers saved in the region A
prologue and the extra registers saved before entering region B , as if they were
produced by one sequence of operations.
The register saves for region B can't be considered as an "inner prologue" because the
composite prologue described for region B must describe both the region A prologue
and the additional registers saved. If fragment B had a prologue, the unwind codes
would also imply the size of that prologue, and there's no way to describe the
composite prologue in a way that maps one-to-one with the opcodes that only save the
additional registers.
The extra register saves must be considered part of region A , because until they're
complete, the composite prologue doesn't accurately describe the state of the stack.
The last C region gets its own .pdata or .xdata record, describing a fragment that has
no prologue but does have an epilogue.
An alternative approach can also work if the stack manipulation done before entering
region B can be reduced to one instruction:
asm
ShrinkWrappedFunction
 push {r4, lr} ; A: save minimal non-volatile registers
 sub sp, sp, #0xE0 ; A: allocate minimal stack space up front
 ... ; A:
 push {r4-r9} ; A: save remaining non-volatiles
 ... ; B:
 pop {r4-r9} ; B: restore remaining non-volatiles
 ... ; C:
 pop {r4, pc} ; C: restore non-volatile registers
The key insight is that on each instruction boundary, the stack is fully consistent with the
unwind codes for the region. If an unwind occurs before the inner push in this example,
it's considered part of region A . Only the region A prologue is unwound. If the unwind
occurs after the inner push, it's considered part of region B , which has no prologue.
However, it has unwind codes that describe both the inner push and the original
prologue from region A . Similar logic holds for the inner pop.
Encoding Optimizations
The richness of the unwind codes, and the ability to make use of compact and expanded
forms of data, provide many opportunities to optimize the encoding to further reduce
space. With aggressive use of these techniques, the net overhead of describing
functions and fragments by using unwind codes can be minimized.
The most important optimization idea: Don't confuse prologue and epilogue boundaries
for unwinding purposes with logical prologue and epilogue boundaries from a compiler
perspective. The unwinding boundaries can be shrunk and made tighter to improve
efficiency. For example, a prologue may contain code after the stack setup to do
verification checks. But once all the stack manipulation is complete, there's no need to
encode further operations, and anything beyond that can be removed from the
unwinding prologue.
This same rule applies to the function length. If there's data (such as a literal pool) that
follows an epilogue in a function, it shouldn't be included as part of the function length.
By shrinking the function to just the code that's part of the function, the chances are
much greater that the epilogue is at the very end and a compact .pdata record can be
used.
In a prologue, once the stack pointer is saved to another register, there's typically no
need to record any further opcodes. To unwind the function, the first thing that's done is
to recover SP from the saved register. Further operations don't have any effect on the
unwind.
Single-instruction epilogues don't have to be encoded at all, either as scopes or as
unwind codes. If an unwind takes place before that instruction is executed, then it's safe
to assume it's from within the body of the function. Just executing the prologue unwind
codes is sufficient. When the unwind takes place after the single instruction is executed,
then by definition it takes place in another region.
Multi-instruction epilogues don't have to encode the first instruction of the epilogue, for
the same reason as the previous point: if the unwind takes place before that instruction
executes, a full prologue unwind is sufficient. If the unwind takes place after that
instruction, then only the later operations have to be considered.
Unwind code reuse should be aggressive. The index each epilogue scope specifies
points to an arbitrary starting point in the array of unwind codes. It doesn't have to
point to the start of a previous sequence; it can point in the middle. The best approach
is to generate the unwind code sequence. Then, scan for an exact byte match in the
already-encoded pool of sequences. Use any perfect match as a starting point for reuse.
After single-instruction epilogues are ignored, if there are no remaining epilogues,
consider using a compact .pdata form; it becomes much more likely in the absence of
an epilogue.
Examples
In these examples, the image base is at 0x00400000.
Example 1: Leaf Function, No Locals
asm
Prologue:
 004535F8: B430 push {r4-r5}
Epilogue:
 00453656: BC30 pop {r4-r5}
 00453658: 4770 bx lr
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x000535F8 (= 0x004535F8-0x00400000)
Word 1
Flag = 1, indicating canonical prologue and epilogue formats
Function Length = 0x31 (= 0x62/2)
Ret = 1, indicating a 16-bit branch return
H = 0, indicating the parameters weren't homed
R = 0 and Reg = 1, indicating push/pop of r4-r5
L = 0, indicating no LR save/restore
C = 0, indicating no frame chaining
Stack Adjust = 0, indicating no stack adjustment
Example 2: Nested Function with Local Allocation
asm
Prologue:
 004533AC: B5F0 push {r4-r7, lr}
 004533AE: B083 sub sp, sp, #0xC
Epilogue:
 00453412: B003 add sp, sp, #0xC
 00453414: BDF0 pop {r4-r7, pc}
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x000533AC (= 0x004533AC -0x00400000)
Word 1
Flag = 1, indicating canonical prologue and epilogue formats
Function Length = 0x35 (= 0x6A/2)
Ret = 0, indicating a pop {pc} return
H = 0, indicating the parameters weren't homed
R = 0 and Reg = 3, indicating push/pop of r4-r7
L = 1, indicating LR was saved/restored
C = 0, indicating no frame chaining
Stack Adjust = 3 (= 0x0C/4)
Example 3: Nested Variadic Function
asm
Prologue:
 00453988: B40F push {r0-r3}
 0045398A: B570 push {r4-r6, lr}
Epilogue:
 004539D4: E8BD 4070 pop {r4-r6}
 004539D8: F85D FB14 ldr pc, [sp], #0x14
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x00053988 (= 0x00453988-0x00400000)
Word 1
Flag = 1, indicating canonical prologue and epilogue formats
Function Length = 0x2A (= 0x54/2)
Ret = 0, indicating a pop {pc}-style return (in this case an ldr pc,[sp],#0x14
return)
H = 1, indicating the parameters were homed
R = 0 and Reg = 2, indicating push/pop of r4-r6
L = 1, indicating LR was saved/restored
C = 0, indicating no frame chaining
Stack Adjust = 0, indicating no stack adjustment
Example 4: Function with Multiple Epilogues
asm
Prologue:
 004592F4: E92D 47F0 stmdb sp!, {r4-r10, lr}
 004592F8: B086 sub sp, sp, #0x18
Epilogues:
 00459316: B006 add sp, sp, #0x18
 00459318: E8BD 87F0 ldm sp!, {r4-r10, pc}
 ...
 0045943E: B006 add sp, sp, #0x18
 00459440: E8BD 87F0 ldm sp!, {r4-r10, pc}
 ...
 004595D4: B006 add sp, sp, #0x18
 004595D6: E8BD 87F0 ldm sp!, {r4-r10, pc}
 ...
 00459606: B006 add sp, sp, #0x18
 00459608: E8BD 87F0 ldm sp!, {r4-r10, pc}
 ...
 00459636: F028 FF0F bl KeBugCheckEx ; end of function
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x000592F4 (= 0x004592F4-0x00400000)
Word 1
Flag = 0, indicating .xdata record present (required for multiple epilogues)
.xdata address - 0x00400000
.xdata (variable, 6 words):
Word 0
Function Length = 0x0001A3 (= 0x000346/2)
Vers = 0, indicating the first version of .xdata
X = 0, indicating no exception data
E = 0, indicating a list of epilogue scopes
F = 0, indicating a full function description, including prologue
Epilogue Count = 0x04, indicating the 4 total epilogue scopes
Code Words = 0x01, indicating one 32-bit word of unwind codes
Words 1-4, describing 4 epilogue scopes at 4 locations. Each scope has a common
set of unwind codes, shared with the prologue, at offset 0x00, and is unconditional,
specifying condition 0x0E (always).
Unwind codes, starting at Word 5: (shared between prologue/epilogue)
Unwind code 0 = 0x06: sp += (6 << 2)
Unwind code 1 = 0xDE: pop {r4-r10, lr}
Unwind code 2 = 0xFF: end
Example 5: Function with Dynamic Stack and Inner
Epilogue
asm
Prologue:
 00485A20: B40F push {r0-r3}
 00485A22: E92D 41F0 stmdb sp!, {r4-r8, lr}
 00485A26: 466E mov r6, sp
 00485A28: 0934 lsrs r4, r6, #4
 00485A2A: 0124 lsls r4, r4, #4
 00485A2C: 46A5 mov sp, r4
 00485A2E: F2AD 2D90 subw sp, sp, #0x290
Epilogue:
 00485BAC: 46B5 mov sp, r6
 00485BAE: E8BD 41F0 ldm sp!, {r4-r8, lr}
 00485BB2: B004 add sp, sp, #0x10
 00485BB4: 4770 bx lr
 ...
 00485E2A: F7FF BE7D b #0x485B28 ; end of function
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x00085A20 (= 0x00485A20-0x00400000)
Word 1
Flag = 0, indicating .xdata record present (needed for multiple epilogues)
.xdata address - 0x00400000
.xdata (variable, 3 words):
Word 0
Function Length = 0x0001A3 (= 0x000346/2)
Vers = 0, indicating the first version of .xdata
X = 0, indicating no exception data
E = 0, indicating a list of epilogue scopes
F = 0, indicating a full function description, including prologue
Epilogue Count = 0x001, indicating the 1 total epilogue scope
Code Words = 0x01, indicating one 32-bit word of unwind codes
Word 1: Epilogue scope at offset 0xC6 (= 0x18C/2), starting unwind code index at
0x00, and with a condition of 0x0E (always)
Unwind codes, starting at Word 2: (shared between prologue/epilogue)
Unwind code 0 = 0xC6: sp = r6
Unwind code 1 = 0xDC: pop {r4-r8, lr}
Unwind code 2 = 0x04: sp += (4 << 2)
Unwind code 3 = 0xFD: end, counts as 16-bit instruction for epilogue
Example 6: Function with Exception Handler
asm
Prologue:
 00488C1C: 0059 A7ED dc.w 0x0059A7ED
 00488C20: 005A 8ED0 dc.w 0x005A8ED0
FunctionStart:
 00488C24: B590 push {r4, r7, lr}
 00488C26: B085 sub sp, sp, #0x14
 00488C28: 466F mov r7, sp
Epilogue:
 00488C6C: 46BD mov sp, r7
 00488C6E: B005 add sp, sp, #0x14
 00488C70: BD90 pop {r4, r7, pc}
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x00088C24 (= 0x00488C24-0x00400000)
Word 1
Flag = 0, indicating .xdata record present (needed for multiple epilogues)
.xdata address - 0x00400000
.xdata (variable, 5 words):
Word 0
Function Length =0x000027 (= 0x00004E/2)
Vers = 0, indicating the first version of .xdata
X = 1, indicating exception data present
E = 1, indicating a single epilogue
F = 0, indicating a full function description, including prologue
Epilogue Count = 0x00, indicating epilogue unwind codes start at offset 0x00
Code Words = 0x02, indicating two 32-bit words of unwind codes
Unwind codes, starting at Word 1:
Unwind code 0 = 0xC7: sp = r7
Unwind code 1 = 0x05: sp += (5 << 2)
Unwind code 2 = 0xED/0x90: pop {r4, r7, lr}
Unwind code 4 = 0xFF: end
Word 3 specifies an exception handler = 0x0019A7ED (= 0x0059A7ED -
0x00400000)
Words 4 and beyond are inlined exception data
Example 7: Funclet
asm
Function:
 00488C72: B500 push {lr}
 00488C74: B081 sub sp, sp, #4
 00488C76: 3F20 subs r7, #0x20
 00488C78: F117 0308 adds r3, r7, #8
 00488C7C: 1D3A adds r2, r7, #4
 00488C7E: 1C39 adds r1, r7, #0
 00488C80: F7FF FFAC bl target
 00488C84: B001 add sp, sp, #4
 00488C86: BD00 pop {pc}
.pdata (fixed, 2 words):
Word 0
Function Start RVA = 0x00088C72 (= 0x00488C72-0x00400000)
Word 1
Flag = 1, indicating canonical prologue and epilogue formats
Function Length = 0x0B (= 0x16/2)
Ret = 0, indicating a pop {pc} return
H = 0, indicating the parameters weren't homed
R = 0 and Reg = 7, indicating no registers were saved/restored
L = 1, indicating LR was saved/restored
C = 0, indicating no frame chaining
Stack Adjust = 1, indicating a 1 × 4 byte stack adjustment
See also
Overview of ARM ABI Conventions
Common Visual C++ ARM Migration Issues
ARM64 exception handling
Article • 03/21/2023
Windows on ARM64 uses the same structured exception handling mechanism for
asynchronous hardware-generated exceptions and synchronous software-generated
exceptions. Language-specific exception handlers are built on top of Windows
structured exception handling by using language helper functions. This document
describes exception handling in Windows on ARM64. It illustrates the language helpers
used by code that's generated by the Microsoft ARM assembler and the MSVC compiler.
Goals and motivation
The exception unwinding data conventions, and this description, are intended to:
Provide enough description to allow unwinding without code probing in all cases.
Analyzing the code requires the code to be paged in. It prevents unwinding in
some circumstances where it's useful (tracing, sampling, debugging).
Analyzing the code is complex; the compiler must be careful to only generate
instructions that the unwinder can decode.
If unwinding can't be fully described by using unwind codes, then in some cases
it must fall back to instruction decoding. Instruction decoding increases the
overall complexity, and ideally should be avoided.
Support unwinding in mid-prolog and mid-epilog.
Unwinding is used in Windows for more than exception handling. It's critical
that code can unwind accurately even when in the middle of a prolog or epilog
code sequence.
Take up a minimal amount of space.
The unwind codes must not aggregate to significantly increase the binary size.
Since the unwind codes are likely to be locked in memory, a small footprint
ensures a minimal overhead for each loaded binary.
Assumptions
These assumptions are made in the exception handling description:
Prologs and epilogs tend to mirror each other. By taking advantage of this
common trait, the size of the metadata needed to describe unwinding can be
greatly reduced. Within the body of the function, it doesn't matter whether the
prolog's operations are undone, or the epilog's operations are done in a forward
manner. Both should produce identical results.
Functions tend on the whole to be relatively small. Several optimizations for space
rely on this fact to achieve the most efficient packing of data.
There's no conditional code in epilogs.
Dedicated frame pointer register: If the sp is saved in another register ( x29 ) in the
prolog, that register remains untouched throughout the function. It means the
original sp may be recovered at any time.
Unless the sp is saved in another register, all manipulation of the stack pointer
occurs strictly within the prolog and epilog.
The stack frame layout is organized as described in the next section.
ARM64 stack frame layout
For frame chained functions, the fp and lr pair can be saved at any position in the
local variable area, depending on optimization considerations. The goal is to maximize
the number of locals that can be reached by a single instruction based on the frame
pointer ( x29 ) or stack pointer ( sp ). However, for alloca functions, it must be chained,
and x29 must point to the bottom of stack. To allow for better register-pair-addressing￾mode coverage, nonvolatile register save areas are positioned at the top of the Local
area stack. Here are examples that illustrate several of the most efficient prolog
sequences. For the sake of clarity and better cache locality, the order of storing callee￾saved registers in all canonical prologs is in "growing up" order. #framesz below
represents the size of entire stack (excluding alloca area). #localsz and #outsz denote
local area size (including the save area for the <x29, lr> pair) and outgoing parameter
size, respectively.
1. Chained, #localsz <= 512
asm
 stp x19,x20,[sp,#-96]! // pre-indexed, save in 1st FP/INT
pair
 stp d8,d9,[sp,#16] // save in FP regs (optional)
 stp x0,x1,[sp,#32] // home params (optional)
 stp x2,x3,[sp,#48]
 stp x4,x5,[sp,#64]
 stp x6,x7,[sp,#82]
 stp x29,lr,[sp,#-localsz]! // save <x29,lr> at bottom of local
area
 mov x29,sp // x29 points to bottom of local
 sub sp,sp,#outsz // (optional for #outsz != 0)
2. Chained, #localsz > 512
asm
 stp x19,x20,[sp,#-96]! // pre-indexed, save in 1st FP/INT
pair
 stp d8,d9,[sp,#16] // save in FP regs (optional)
 stp x0,x1,[sp,#32] // home params (optional)
 stp x2,x3,[sp,#48]
 stp x4,x5,[sp,#64]
 stp x6,x7,[sp,#82]
 sub sp,sp,#(localsz+outsz) // allocate remaining frame
 stp x29,lr,[sp,#outsz] // save <x29,lr> at bottom of local
area
 add x29,sp,#outsz // setup x29 points to bottom of
local area
3. Unchained, leaf functions ( lr unsaved)
asm
 stp x19,x20,[sp,#-80]! // pre-indexed, save in 1st FP/INT
reg-pair
 stp x21,x22,[sp,#16]
 str x23,[sp,#32]
 stp d8,d9,[sp,#40] // save FP regs (optional)
 stp d10,d11,[sp,#56]
 sub sp,sp,#(framesz-80) // allocate the remaining local
area
All locals are accessed based on sp . <x29,lr> points to the previous frame. For
frame size <= 512, the sub sp, ... can be optimized away if the regs saved area
is moved to the bottom of stack. The downside is that it's not consistent with other
layouts above. And, saved regs take part of the range for pair-regs and pre- and
post-indexed offset addressing mode.
4. Unchained, non-leaf functions (saves lr in Int saved area)
asm
 stp x19,x20,[sp,#-80]! // pre-indexed, save in 1st FP/INT
reg-pair
 stp x21,x22,[sp,#16] // ...
 stp x23,lr,[sp,#32] // save last Int reg and lr
 stp d8,d9,[sp,#48] // save FP reg-pair (optional)
 stp d10,d11,[sp,#64] // ...
 sub sp,sp,#(framesz-80) // allocate the remaining local
area
Or, with even number saved Int registers,
asm
 stp x19,x20,[sp,#-80]! // pre-indexed, save in 1st FP/INT
reg-pair
 stp x21,x22,[sp,#16] // ...
 str lr,[sp,#32] // save lr
 stp d8,d9,[sp,#40] // save FP reg-pair (optional)
 stp d10,d11,[sp,#56] // ...
 sub sp,sp,#(framesz-80) // allocate the remaining local
area
Only x19 saved:
asm
 sub sp,sp,#16 // reg save area allocation*
 stp x19,lr,[sp] // save x19, lr
 sub sp,sp,#(framesz-16) // allocate the remaining local
area
* The reg save area allocation isn't folded into the stp because a pre-indexed reg￾lr stp can't be represented with the unwind codes.
All locals are accessed based on sp . <x29> points to the previous frame.
5. Chained, #framesz <= 512, #outsz = 0
asm
 stp x29,lr,[sp,#-framesz]! // pre-indexed, save <x29,lr>
 mov x29,sp // x29 points to bottom of
stack
 stp x19,x20,[sp,#(framesz-32)] // save INT pair
 stp d8,d9,[sp,#(framesz-16)] // save FP pair
Compared to the first prolog example above, this example has an advantage: all
register save instructions are ready to execute after only one stack allocation
instruction. That means there's no anti-dependence on sp that prevents
instruction level parallelism.
6. Chained, frame size > 512 (optional for functions without alloca )
asm
 stp x29,lr,[sp,#-80]! // pre-indexed, save <x29,lr>
 stp x19,x20,[sp,#16] // save in INT regs
 stp x21,x22,[sp,#32] // ...
 stp d8,d9,[sp,#48] // save in FP regs
 stp d10,d11,[sp,#64]
 mov x29,sp // x29 points to top of local
area
 sub sp,sp,#(framesz-80) // allocate the remaining local
area
For optimization purpose, x29 can be put at any position in local area to provide a
better coverage for "reg-pair" and pre-/post-indexed offset addressing mode.
Locals below frame pointers can be accessed based on sp .
7. Chained, frame size > 4K, with or without alloca(),
asm
 stp x29,lr,[sp,#-80]! // pre-indexed, save <x29,lr>
 stp x19,x20,[sp,#16] // save in INT regs
 stp x21,x22,[sp,#32] // ...
 stp d8,d9,[sp,#48] // save in FP regs
 stp d10,d11,[sp,#64]
 mov x29,sp // x29 points to top of local
area
 mov x15,#(framesz/16)
 bl __chkstk
 sub sp,sp,x15,lsl#4 // allocate remaining frame
 // end of prolog
 ...
 sub sp,sp,#alloca // more alloca() in body
 ...
 // beginning of epilog
 mov sp,x29 // sp points to top of local
area
 ldp d10,d11,[sp,#64]
 ...
 ldp x29,lr,[sp],#80 // post-indexed, reload
<x29,lr>
ARM64 exception handling information
.pdata records
The .pdata records are an ordered array of fixed-length items that describe every stack￾manipulating function in a PE binary. The phrase "stack-manipulating" is significant: leaf
functions that don't require any local storage, and don't need to save/restore non￾volatile registers, don't require a .pdata record. These records should be explicitly
omitted to save space. An unwind from one of these functions can get the return
address directly from lr to move up to the caller.
Each .pdata record for ARM64 is 8 bytes in length. The general format of each record
places the 32-bit RVA of the function start in the first word, followed by a second word
that contains either a pointer to a variable-length .xdata block, or a packed word
describing a canonical function unwinding sequence.
The fields are as follows:
Function Start RVA is the 32-bit RVA of the start of the function.
Flag is a 2-bit field that indicates how to interpret the remaining 30 bits of the
second .pdata word. If Flag is 0, then the remaining bits form an Exception
Information RVA (with the two lowest bits implicitly 0). If Flag is non-zero, then the
remaining bits form a Packed Unwind Data structure.
Exception Information RVA is the address of the variable-length exception
information structure, stored in the .xdata section. This data must be 4-byte
aligned.
Packed Unwind Data is a compressed description of the operations needed to
unwind from a function, assuming a canonical form. In this case, no .xdata record
is required.
.xdata records
When the packed unwind format is insufficient to describe the unwinding of a function,
a variable-length .xdata record must be created. The address of this record is stored in
the second word of the .pdata record. The format of the .xdata is a packed variable￾length set of words:
This data is broken into four sections:
1. A 1-word or 2-word header describing the overall size of the structure and
providing key function data. The second word is only present if both the Epilog
Count and Code Words fields are set to 0. The header has these bit fields:
a. Function Length is an 18-bit field. It indicates the total length of the function in
bytes, divided by 4. If a function is larger than 1M, then multiple .pdata and
.xdata records must be used to describe the function. For more information, see
the Large functions section.
b. Vers is a 2-bit field. It describes the version of the remaining .xdata . Currently,
only version 0 is defined, so values of 1-3 aren't permitted.
c. X is a 1-bit field. It indicates the presence (1) or absence (0) of exception data.
d. E is a 1-bit field. It indicates that information describing a single epilog is packed
into the header (1) rather than requiring more scope words later (0).
e. Epilog Count is a 5-bit field that has two meanings, depending on the state of E
bit:
a. If E is 0, it specifies the count of the total number of epilog scopes described in
section 2. If more than 31 scopes exist in the function, then the Code Words
field must be set to 0 to indicate that an extension word is required.
b. If E is 1, then this field specifies the index of the first unwind code that describes
the one and only epilog.
f. Code Words is a 5-bit field that specifies the number of 32-bit words needed to
contain all of the unwind codes in section 3. If more than 31 words (that is, 124
unwind codes) are required, then this field must be 0 to indicate that an extension
word is required.
g. Extended Epilog Count and Extended Code Words are 16-bit and 8-bit fields,
respectively. They provide more space for encoding an unusually large number of
epilogs, or an unusually large number of unwind code words. The extension word
that contains these fields is only present if both the Epilog Count and Code Words
fields in the first header word are 0.
2. If the count of epilogs isn't zero, a list of information about epilog scopes, packed
one to a word, comes after the header and optional extended header. They're
stored in order of increasing starting offset. Each scope contains the following bits:
a. Epilog Start Offset is an 18-bit field that has the offset in bytes, divided by 4, of
the epilog relative to the start of the function.
b. Res is a 4-bit field reserved for future expansion. Its value must be 0.
c. Epilog Start Index is a 10-bit field (2 more bits than Extended Code Words). It
indicates the byte index of the first unwind code that describes this epilog.
3. After the list of epilog scopes comes an array of bytes that contain unwind codes,
described in detail in a later section. This array is padded at the end to the nearest
full word boundary. Unwind codes are written to this array. They start with the one
closest to the body of the function, and move towards the edges of the function.
The bytes for each unwind code are stored in big-endian order so the most
significant byte gets fetched first, which identifies the operation and the length of
the rest of the code.
4. Finally, after the unwind code bytes, if the X bit in the header was set to 1, comes
the exception handler information. It consists of a single Exception Handler RVA
that provides the address of the exception handler itself. It's followed immediately
by a variable-length amount of data required by the exception handler.
The .xdata record is designed so it's possible to fetch the first 8 bytes, and use them to
compute the full size of the record, minus the length of the variable-sized exception
data that follows. The following code snippet computes the record size:
C++
Although the prolog and each epilog has its own index into the unwind codes, the table
is shared between them. It's entirely possible (and not altogether uncommon) that they
can all share the same codes. (For an example, see Example 2 in the Examples section.)
Compiler writers should optimize for this case in particular. It's because the largest index
that can be specified is 255, which limits the total number of unwind codes for a
particular function.
The array of unwind codes is a pool of sequences that describe exactly how to undo the
effects of the prolog. They're stored in the same order the operations need to be
undone. The unwind codes can be thought of as a small instruction set, encoded as a
string of bytes. When execution is complete, the return address to the calling function is
in the lr register. And, all non-volatile registers are restored to their values at the time
the function was called.
If exceptions were guaranteed to only ever occur within a function body, and never
within a prolog or any epilog, then only a single sequence would be necessary. However,
ULONG ComputeXdataSize(PULONG Xdata)
{
 ULONG Size;
 ULONG EpilogScopes;
 ULONG UnwindWords;
 if ((Xdata[0] >> 22) != 0) {
 Size = 4;
 EpilogScopes = (Xdata[0] >> 22) & 0x1f;
 UnwindWords = (Xdata[0] >> 27) & 0x1f;
 } else {
 Size = 8;
 EpilogScopes = Xdata[1] & 0xffff;
 UnwindWords = (Xdata[1] >> 16) & 0xff;
 }
 if (!(Xdata[0] & (1 << 21))) {
 Size += 4 * EpilogScopes;
 }
 Size += 4 * UnwindWords;
 if (Xdata[0] & (1 << 20)) {
 Size += 4; // Exception handler RVA
 }
 return Size;
}
Unwind codes
the Windows unwinding model requires that code can unwind from within a partially
executed prolog or epilog. To meet this requirement, the unwind codes have been
carefully designed so they unambiguously map 1:1 to each relevant opcode in the
prolog and epilog. This design has several implications:
By counting the number of unwind codes, it's possible to compute the length of
the prolog and epilog.
By counting the number of instructions past the start of an epilog scope, it's
possible to skip the equivalent number of unwind codes. We can execute the rest
of a sequence to complete the partially executed unwind done by the epilog.
By counting the number of instructions before the end of the prolog, it's possible
to skip the equivalent number of unwind codes. We can execute the rest of the
sequence to undo only those parts of the prolog that have completed execution.
The unwind codes are encoded according to the table below. All unwind codes are a
single/double byte, except the one that allocates a huge stack ( alloc_l ). There are 22
unwind codes in total. Each unwind code maps exactly one instruction in the
prolog/epilog, to allow for unwinding of partially executed prologs and epilogs.
Unwind code Bits and interpretation
alloc_s 000xxxxx: allocate small stack with size < 512 (2^5 * 16).
save_r19r20_x 001zzzzz: save <x19,x20> pair at [sp-#Z*8]! , pre-indexed offset >= -248
save_fplr 01zzzzzz: save <x29,lr> pair at [sp+#Z*8] , offset <= 504.
save_fplr_x 10zzzzzz: save <x29,lr> pair at [sp-(#Z+1)*8]! , pre-indexed offset >= -512
alloc_m 11000xxx'xxxxxxxx: allocate large stack with size < 32K (2^11 * 16).
save_regp 110010xx'xxzzzzzz: save x(19+#X) pair at [sp+#Z*8] , offset <= 504
save_regp_x 110011xx'xxzzzzzz: save pair x(19+#X) at [sp-(#Z+1)*8]! , pre-indexed offset >=
-512
save_reg 110100xx'xxzzzzzz: save reg x(19+#X) at [sp+#Z*8] , offset <= 504
save_reg_x 1101010x'xxxzzzzz: save reg x(19+#X) at [sp-(#Z+1)*8]! , pre-indexed offset >=
-256
save_lrpair 1101011x'xxzzzzzz: save pair <x(19+2*#X),lr> at [sp+#Z*8] , offset <= 504
save_fregp 1101100x'xxzzzzzz: save pair d(8+#X) at [sp+#Z*8] , offset <= 504
Unwind code Bits and interpretation
save_fregp_x 1101101x'xxzzzzzz: save pair d(8+#X) at [sp-(#Z+1)*8]! , pre-indexed offset >=
-512
save_freg 1101110x'xxzzzzzz: save reg d(8+#X) at [sp+#Z*8] , offset <= 504
save_freg_x 11011110'xxxzzzzz: save reg d(8+#X) at [sp-(#Z+1)*8]! , pre-indexed offset >=
-256
alloc_l 11100000'xxxxxxxx'xxxxxxxx'xxxxxxxx: allocate large stack with size < 256M (2^24
* 16)
set_fp 11100001: set up x29 with mov x29,sp
add_fp 11100010'xxxxxxxx: set up x29 with add x29,sp,#x*8
nop 11100011: no unwind operation is required.
end 11100100: end of unwind code. Implies ret in epilog.
end_c 11100101: end of unwind code in current chained scope.
save_next 11100110: save next non-volatile Int or FP register pair.
11100111: reserved
11101xxx: reserved for custom stack cases below only generated for asm
routines
11101000: Custom stack for MSFT_OP_TRAP_FRAME
11101001: Custom stack for MSFT_OP_MACHINE_FRAME
11101010: Custom stack for MSFT_OP_CONTEXT
11101011: Custom stack for MSFT_OP_EC_CONTEXT
11101100: Custom stack for MSFT_OP_CLEAR_UNWOUND_TO_CALL
11101101: reserved
11101110: reserved
11101111: reserved
11110xxx: reserved
11111000'yyyyyyyy : reserved
11111001'yyyyyyyy'yyyyyyyy : reserved
11111010'yyyyyyyy'yyyyyyyy'yyyyyyyy : reserved
Unwind code Bits and interpretation
11111011'yyyyyyyy'yyyyyyyy'yyyyyyyy'yyyyyyyy : reserved
pac_sign_lr 11111100: sign the return address in lr with pacibsp
11111101: reserved
11111110: reserved
11111111: reserved
In instructions with large values covering multiple bytes, the most significant bits are
stored first. This design makes it possible to find the total size in bytes of the unwind
code by looking up only the first byte of the code. Since each unwind code is exactly
mapped to an instruction in a prolog or epilog, you can compute the size of the prolog
or epilog. Walk from the sequence start to the end, and use a lookup table or similar
device to determine the length of the corresponding opcode.
Post-indexed offset addressing isn't allowed in a prolog. All offset ranges (#Z) match the
encoding of stp / str addressing except save_r19r20_x , in which 248 is sufficient for all
save areas (10 Int registers + 8 FP registers + 8 input registers).
save_next must follow a save for Int or FP volatile register pair: save_regp , save_regp_x ,
save_fregp , save_fregp_x , save_r19r20_x , or another save_next . It saves the next
register pair at the next 16-byte slot in "growing up" order. A save_next refers to the
first FP register pair when it follows the save-next that denotes the last Int register pair.
Since the sizes of regular return and jump instructions are the same, there's no need for
a separated end unwind code in tail-call scenarios.
end_c is designed to handle noncontiguous function fragments for optimization
purposes. An end_c that indicates the end of unwind codes in the current scope must
be followed by another series of unwind codes ending with a real end . The unwind
codes between end_c and end represent the prolog operations in the parent region (a
"phantom" prolog). More details and examples are described in the section below.
For functions whose prologs and epilogs follow the canonical form described below,
packed unwind data can be used. It eliminates the need for an .xdata record entirely,
and significantly reduces the cost of providing unwind data. The canonical prologs and
epilogs are designed to meet the common requirements of a simple function: One that
Packed unwind data
doesn't require an exception handler, and which does its setup and teardown operations
in a standard order.
The format of a .pdata record with packed unwind data looks like this:
The fields are as follows:
Function Start RVA is the 32-bit RVA of the start of the function.
Flag is a 2-bit field as described above, with the following meanings:
00 = packed unwind data not used; remaining bits point to an .xdata record
01 = packed unwind data used with a single prolog and epilog at the beginning
and end of the scope
10 = packed unwind data used for code without any prolog and epilog. Useful
for describing separated function segments
11 = reserved.
Function Length is an 11-bit field providing the length of the entire function in
bytes, divided by 4. If the function is larger than 8k, a full .xdata record must be
used instead.
Frame Size is a 9-bit field indicating the number of bytes of stack that is allocated
for this function, divided by 16. Functions that allocate greater than (8k-16) bytes
of stack must use a full .xdata record. It includes the local variable area, outgoing
parameter area, callee-saved Int and FP area, and home parameter area. It excludes
the dynamic allocation area.
CR is a 2-bit flag indicating whether the function includes extra instructions to set
up a frame chain and return link:
00 = unchained function, <x29,lr> pair isn't saved in stack
01 = unchained function, <lr> is saved in stack
10 = chained function with a pacibsp signed return address
11 = chained function, a store/load pair instruction is used in prolog/epilog
<x29,lr>
H is a 1-bit flag indicating whether the function homes the integer parameter
registers (x0-x7) by storing them at the very start of the function. (0 = doesn't
home registers, 1 = homes registers).
RegI is a 4-bit field indicating the number of non-volatile INT registers (x19-x28)
saved in the canonical stack location.
RegF is a 3-bit field indicating the number of non-volatile FP registers (d8-d15)
saved in the canonical stack location. (RegF=0: no FP register is saved; RegF>0:
RegF+1 FP registers are saved). Packed unwind data can't be used for function that
save only one FP register.
Canonical prologs that fall into categories 1, 2 (without outgoing parameter area), 3 and
4 in section above can be represented by packed unwind format. The epilogs for
canonical functions follow a similar form, except H has no effect, the set_fp instruction
is omitted, and the order of steps and the instructions in each step are reversed in the
epilog. The algorithm for packed .xdata follows these steps, detailed in the following
table:
Step 0: Pre-compute of the size of each area.
Step 1: Sign the return address.
Step 2: Save Int callee-saved registers.
Step 3: This step is specific for type 4 in early sections. lr is saved at the end of Int area.
Step 4: Save FP callee-saved registers.
Step 5: Save input arguments in the home parameter area.
Step 6: Allocate remaining stack, including local area, <x29,lr> pair, and outgoing
parameter area. 6a corresponds to canonical type 1. 6b and 6c are for canonical type 2.
6d and 6e are for both type 3 and type 4.
Step
#
Flag values # of
instructions
Opcode Unwind code
0 #intsz = RegI * 8;
if (CR==01) #intsz += 8; // lr
#fpsz = RegF * 8;
if(RegF) #fpsz += 8;
#savsz=
((#intsz+#fpsz+8*8*H)+0xf)&~0xf)
#locsz = #famsz - #savsz
1 CR == 10 1 pacibsp pac_sign_lr
2 0 < RegI <= 10 RegI / 2 +
RegI % 2
stp x19,x20,[sp,#savsz]!
stp x21,x22,[sp,#16]
...
save_regp_x
save_regp
...
3 CR == 01* 1 str lr,[sp,#(intsz-8)] * save_reg
Step
#
Flag values # of
instructions
Opcode Unwind code
4 0 < RegF <= 7 (RegF + 1) /
2 +
(RegF + 1) %
2)
stp d8,d9,[sp,#intsz] **
stp d10,d11,[sp,#(intsz+16)]
...
str d(8+RegF),[sp,#(intsz+fpsz-
8)]
save_fregp
...
save_freg
5 H == 1 4 stp x0,x1,[sp,#(intsz+fpsz)]
stp x2,x3,[sp,#(intsz+fpsz+16)]
stp x4,x5,[sp,#(intsz+fpsz+32)]
stp x6,x7,[sp,#(intsz+fpsz+48)]
nop
nop
nop
nop
6a (CR == 10 || CR
== 11) &&
#locsz <= 512
2 stp x29,lr,[sp,#-locsz]!
mov x29,sp ***
save_fplr_x
set_fp
6b (CR == 10 || CR
== 11) &&
512 < #locsz <=
4080
3 sub sp,sp,#locsz
stp x29,lr,[sp,0]
add x29,sp,0
alloc_m
save_fplr
set_fp
6c (CR == 10 || CR
== 11) &&
#locsz > 4080
4 sub sp,sp,4080
sub sp,sp,#(locsz-4080)
stp x29,lr,[sp,0]
add x29,sp,0
alloc_m
alloc_s / alloc_m
save_fplr
set_fp
6d (CR == 00 || CR
== 01) &&
#locsz <= 4080
1 sub sp,sp,#locsz alloc_s / alloc_m
6e (CR == 00 || CR
== 01) &&
#locsz > 4080
2 sub sp,sp,4080
sub sp,sp,#(locsz-4080)
alloc_m
alloc_s / alloc_m
* If CR == 01 and RegI is an odd number, Step 2 and the last save_rep in step 1 are
merged into one save_regp .
** If RegI == CR == 0, and RegF != 0, the first stp for the floating-point does the
predecrement.
*** No instruction corresponding to mov x29,sp is present in the epilog. Packed unwind
data can't be used if a function requires restoration of sp from x29 .
Unwinding partial prologs and epilogs
In the most common unwinding situations, the exception or call occurs in the body of
the function, away from the prolog and all epilogs. In these situations, unwinding is
straightforward: the unwinder simply executes the codes in the unwind array. It begins
at index 0 and continues until an end opcode is detected.
It's more difficult to correctly unwind in the case where an exception or interrupt occurs
while executing a prolog or epilog. In these situations, the stack frame is only partially
constructed. The problem is to determine exactly what's been done, to correctly undo it.
For example, take this prolog and epilog sequence:
asm
0000: stp x29,lr,[sp,#-256]! // save_fplr_x 256 (pre-indexed
store)
0004: stp d8,d9,[sp,#224] // save_fregp 0, 224
0008: stp x19,x20,[sp,#240] // save_regp 0, 240
000c: mov x29,sp // set_fp
 ...
0100: mov sp,x29 // set_fp
0104: ldp x19,x20,[sp,#240] // save_regp 0, 240
0108: ldp d8,d9,[sp,224] // save_fregp 0, 224
010c: ldp x29,lr,[sp],#256 // save_fplr_x 256 (post￾indexed load)
0110: ret lr // end
Next to each opcode is the appropriate unwind code describing this operation. You can
see how the series of unwind codes for the prolog is an exact mirror image of the
unwind codes for the epilog (not counting the final instruction of the epilog). It's a
common situation: It's why we always assume the unwind codes for the prolog are
stored in reverse order from the prolog's execution order.
So, for both the prolog and epilog, we're left with a common set of unwind codes:
set_fp , save_regp 0,240 , save_fregp,0,224 , save_fplr_x_256 , end
The epilog case is straightforward, since it's in normal order. Starting at offset 0 within
the epilog (which starts at offset 0x100 in the function), we'd expect the full unwind
sequence to execute, as no cleanup has yet been done. If we find ourselves one
instruction in (at offset 2 in the epilog), we can successfully unwind by skipping the first
unwind code. We can generalize this situation, and assume a 1:1 mapping between
opcodes and unwind codes. Then, to start unwinding from instruction n in the epilog,
we should skip the first n unwind codes, and begin executing from there.
It turns out that a similar logic works for the prolog, except in reverse. If we start
unwinding from offset 0 in the prolog, we want to execute nothing. If we unwind from
offset 2, which is one instruction in, then we want to start executing the unwind
sequence one unwind code from the end. (Remember, the codes are stored in reverse
order.) And here too, we can generalize: if we start unwinding from instruction n in the
prolog, we should start executing n unwind codes from the end of the list of codes.
Prolog and epilog codes don't always match exactly, which is why the unwind array may
need to contain several sequences of codes. To determine the offset of where to begin
processing codes, use the following logic:
1. If unwinding from within the body of the function, begin executing unwind codes
at index 0 and continue until hitting an end opcode.
2. If unwinding from within an epilog, use the epilog-specific starting index provided
with the epilog scope as a starting point. Compute how many bytes the PC in
question is from the start of the epilog. Then advance forward through the unwind
codes, skipping unwind codes until all of the already-executed instructions are
accounted for. Then execute starting at that point.
3. If unwinding from within the prolog, use index 0 as your starting point. Compute
the length of the prolog code from the sequence, and then compute how many
bytes the PC in question is from the end of the prolog. Then advance forward
through the unwind codes, skipping unwind codes until all of the not-yet-executed
instructions are accounted for. Then execute starting at that point.
These rules mean the unwind codes for the prolog must always be the first in the array.
And, they're also the codes used to unwind in the general case of unwinding from within
the body. Any epilog-specific code sequences should follow immediately after.
Function fragments
For code optimization purposes and other reasons, it may be preferable to split a
function into separated fragments (also called regions). When split, each resulting
function fragment requires its own separate .pdata (and possibly .xdata ) record.
For each separated secondary fragment that has its own prolog, it's expected that no
stack adjustment is done in its prolog. All stack space required by a secondary region
must be pre-allocated by its parent region (or called host region). This preallocation
keeps stack pointer manipulation strictly in the function's original prolog.
A typical case of function fragments is "code separation", where the compiler may move
a region of code out of its host function. There are three unusual cases that could result
from code separation.
Example
(region 1: begin)
asm
 stp x29,lr,[sp,#-256]! // save_fplr_x 256 (pre-indexed
store)
 stp x19,x20,[sp,#240] // save_regp 0, 240
 mov x29,sp // set_fp
 ...
(region 1: end)
(region 3: begin)
asm
 ...
(region 3: end)
(region 2: begin)
asm
 ...
 mov sp,x29 // set_fp
 ldp x19,x20,[sp,#240] // save_regp 0, 240
 ldp x29,lr,[sp],#256 // save_fplr_x 256 (post-indexed
load)
 ret lr // end
(region 2: end)
1. Prolog only (region 1: all epilogs are in separated regions):
Only the prolog must be described. This prolog can't be represented in the
compact .pdata format. In the full .xdata case, it can be represented by setting
Epilog Count = 0. See region 1 in the example above.
Unwind codes: set_fp , save_regp 0,240 , save_fplr_x_256 , end .
2. Epilogs only (region 2: prolog is in host region)
It's assumed that by the time control jumps into this region, all prolog codes have
been executed. Partial unwind can happen in epilogs the same way as in a normal
function. This type of region can't be represented by compact .pdata . In a full
.xdata record, it can be encoded with a "phantom" prolog, bracketed by an end_c
and end unwind code pair. The leading end_c indicates the size of prolog is zero.
Epilog start index of the single epilog points to set_fp .
Unwind code for region 2: end_c , set_fp , save_regp 0,240 , save_fplr_x_256 , end .
3. No prologs or epilogs (region 3: prologs and all epilogs are in other fragments):
Compact .pdata format can be applied via setting Flag = 10. With full .xdata
record, Epilog Count = 1. Unwind code is the same as the code for region 2 above,
but Epilog Start Index also points to end_c . Partial unwind will never happen in this
region of code.
Another more complicated case of function fragments is "shrink wrapping." The
compiler may choose to delay saving some callee-saved registers until outside of the
function entry prolog.
(region 1: begin)
asm
 stp x29,lr,[sp,#-256]! // save_fplr_x 256 (pre-indexed
store)
 stp x19,x20,[sp,#240] // save_regp 0, 240
 mov x29,sp // set_fp
 ...
(region 2: begin)
asm
 stp x21,x22,[sp,#224] // save_regp 2, 224
 ...
 ldp x21,x22,[sp,#224] // save_regp 2, 224
(region 2: end)
asm
 ...
 mov sp,x29 // set_fp
 ldp x19,x20,[sp,#240] // save_regp 0, 240
 ldp x29,lr,[sp],#256 // save_fplr_x 256 (post-indexed
load)
 ret lr // end
(region 1: end)
In the prolog of region 1, stack space is pre-allocated. You can see that region 2 will
have the same unwind code even it's moved out of its host function.
Region 1: set_fp , save_regp 0,240 , save_fplr_x_256 , end . Epilog Start Index points to
set_fp as usual.
Region 2: save_regp 2, 224 , end_c , set_fp , save_regp 0,240 , save_fplr_x_256 , end .
Epilog Start Index points to first unwind code save_regp 2, 224 .
Large functions
Fragments can be used to describe functions larger than the 1M limit imposed by the
bit fields in the .xdata header. To describe an unusually large function like this, it needs
to be broken into fragments smaller than 1M. Each fragment should be adjusted so that
it doesn't split an epilog into multiple pieces.
Only the first fragment of the function will contain a prolog; all other fragments are
marked as having no prolog. Depending on the number of epilogs present, each
fragment may contain zero or more epilogs. Keep in mind that each epilog scope in a
fragment specifies its starting offset relative to the start of the fragment, not the start of
the function.
If a fragment has no prolog and no epilog, it still requires its own .pdata (and possibly
.xdata ) record, to describe how to unwind from within the body of the function.
Examples
Example 1: Frame-chained, compact-form
asm
|Foo| PROC
|$LN19|
 str x19,[sp,#-0x10]! // save_reg_x
 sub sp,sp,#0x810 // alloc_m
 stp fp,lr,[sp] // save_fplr
 mov fp,sp // set_fp
 // end of prolog
 ...
|$pdata$Foo|
 DCD imagerel |$LN19|
 DCD 0x416101ed
 ;Flags[SingleProEpi] functionLength[492] RegF[0] RegI[1] H[0]
frameChainReturn[Chained] frameSize[2080]
Example 2: Frame-chained, full-form with mirror Prolog &
Epilog
asm
|Bar| PROC
|$LN19|
 stp x19,x20,[sp,#-0x10]! // save_regp_x
 stp fp,lr,[sp,#-0x90]! // save_fplr_x
 mov fp,sp // set_fp
 // end of prolog
 ...
 // begin of epilog, a mirror sequence of
Prolog
 mov sp,fp
 ldp fp,lr,[sp],#0x90
 ldp x19,x20,[sp],#0x10
 ret lr
|$pdata$Bar|
 DCD imagerel |$LN19|
 DCD imagerel |$unwind$cse2|
|$unwind$Bar|
 DCD 0x1040003d
 DCD 0x1000038
 DCD 0xe42291e1
 DCD 0xe42291e1
 ;Code Words[2], Epilog Count[1], E[0], X[0], Function Length[6660]
 ;Epilog Start Index[0], Epilog Start Offset[56]
 ;set_fp
 ;save_fplr_x
 ;save_r19r20_x
 ;end
Epilog Start Index [0] points to the same sequence of Prolog unwind code.
Example 3: Variadic unchained Function
asm
|Delegate| PROC
|$LN4|
 sub sp,sp,#0x50
 stp x19,lr,[sp]
 stp x0,x1,[sp,#0x10] // save incoming register to home area
 stp x2,x3,[sp,#0x20] // ...
 stp x4,x5,[sp,#0x30]
 stp x6,x7,[sp,#0x40] // end of prolog
 ...
 ldp x19,lr,[sp] // beginning of epilog
 add sp,sp,#0x50
 ret lr
 AREA |.pdata|, PDATA
|$pdata$Delegate|
 DCD imagerel |$LN4|
 DCD imagerel |$unwind$Delegate|
 AREA |.xdata|, DATA
|$unwind$Delegate|
 DCD 0x18400012
 DCD 0x200000f
 DCD 0xe3e3e3e3
 DCD 0xe40500d6
 DCD 0xe40500d6
 ;Code Words[3], Epilog Count[1], E[0], X[0], Function Length[18]
 ;Epilog Start Index[4], Epilog Start Offset[15]
 ;nop // nop for saving in home area
 ;nop // ditto
 ;nop // ditto
 ;nop // ditto
 ;save_lrpair
 ;alloc_s
 ;end
Epilog Start Index [4] points to the middle of Prolog unwind code (partially reuse unwind
array).
See also
Overview of ARM64 ABI conventions
ARM exception handling
Configuring Programs for Windows XP
Article • 02/17/2022
Visual Studio supports multiple platform toolsets. That means it's possible to target
operating systems and runtime libraries that aren't supported by the default toolset. For
example, by switching the platform toolset, you can use the Visual Studio 2017 C++
compiler to create apps that target Windows XP and Windows Server 2003. You can also
use older platform toolsets to maintain binary-compatible legacy code and still take
advantage of the latest features of the Visual Studio IDE.
The toolset supplied in Visual Studio 2019 and later doesn't include support for creating
code for Windows XP. Support for Windows XP development is available by using the
Visual Studio 2017 v141_xp toolset. You can install the v141_xp toolset as an individual
component option in the Visual Studio Installer.
Install the Windows XP platform toolset
To get the v141_xp platform toolset and components to target Windows XP and
Windows Server 2003, run the Visual Studio Installer. When you initially install Visual
Studio, or when you modify an existing installation, make sure the Desktop
development with C++ workload is selected. In the Individual components tab, under
Compilers, build tools, and runtimes, choose C++ Windows XP Support for VS 2017
(v141) tools [Deprecated], and then choose Install or Modify.
Windows XP targeting experience
The Windows XP platform toolset that's included in Visual Studio is a version of the
Windows 7 SDK, but it uses the Visual Studio 2017 C++ compiler. It also configures
project properties to appropriate default values, for example, the specification of a
compatible linker for down-level targeting. Only Windows desktop apps created by
using a Windows XP platform toolset can run on Windows XP and Windows Server
2003. Those apps can also run on more recent Windows operating systems.
To target Windows XP
1. In Solution Explorer, open the shortcut menu for your project, and then choose
Properties.
2. In the Property Pages dialog box for the project, set the Configuration dropdown
to All configurations.
3. Select the Configuration Properties > General property page. Set the Platform
Toolset property to your preferred Windows XP toolset. For example, choose
Visual Studio 2017 - Windows XP (v141_xp) to create code for Windows XP and
Windows Server 2003 by using the Microsoft C++ compiler from Visual Studio
2017.
Along with the Windows XP platform toolset, several libraries include runtime support
for Windows XP and Windows Server 2003:
Universal C Runtime Library (UCRT)
C++ Standard Library
Active Template Library (ATL)
Concurrency Runtime Library (ConcRT)
Parallel Patterns Library (PPL)
Microsoft Foundation Class Library (MFC)
C++ AMP (C++ Accelerated Massive Programming) library.
The minimum supported versions of these operating systems are: Windows XP Service
Pack 3 (SP3) for x86, Windows XP Service Pack 2 (SP2) for x64, and Windows Server 2003
Service Pack 2 (SP2) for both x86 and x64.
These libraries are supported by the platform toolsets installed by Visual Studio,
depending on the target:
Library Default platform
toolset targeting
Windows desktop apps
Default platform
toolset targeting
Store apps
Windows XP platform toolset
targeting Windows XP,
Windows Server 2003
CRT X X X
C++
Standard
Library
X X X
ATL X X X
ConcRT/PPL X X X
MFC X X
C++ AMP X X
C++ runtime support
７ Note
Apps that are written in C++/CLI and target the .NET Framework 4 run on Windows
XP and Windows Server 2003.
Differences between the toolsets
Because of differences in platform and library support, the development experience for
apps that use a Windows XP platform toolset isn't as complete as for apps that use the
default platform toolset.
C++ language features
Only C++ language features implemented in Visual Studio 2017 are supported in
apps that use the v141_xp platform toolset. Only C++ language features
implemented in Visual Studio 2015 are supported in apps that use the v140_xp
platform toolset. Visual Studio uses the corresponding compiler when it builds
using the older platform toolsets. Use the most recent Windows XP platform
toolset to take advantage of the latest C++ language features implemented in that
version of the compiler. For more information about language feature support by
compiler version, see Microsoft C/C++ language conformance.
Remote debugging
Remote debugging on Windows XP or Windows Server 2003 isn't supported by
Remote Tools for Visual Studio. To debug an app locally or remotely on Windows
XP or Windows Server 2003, use a debugger from an older version of Visual Studio.
It's similar to debugging an app on Windows Vista: Vista is a runtime target of the
platform toolset, but not a remote debugging target.
Static analysis
The Windows XP platform toolsets don't support static analysis. The SAL
annotations for the Windows 7 SDK and the runtime libraries are incompatible. You
can still run static analysis on an app that supports Windows XP or Windows Server
2003. Temporarily switch the solution to target the default platform toolset for the
analysis, and then switch back to the Windows XP platform toolset to build the
app.
Debugging of DirectX graphics
The Graphics Debugger doesn't support the Direct3D 9 API. It can't be used to
debug apps that use Direct3D on Windows XP or Windows Server 2003. However,
if the app implements an alternative renderer based on Direct3D 10 or Direct3D 11
APIs, you can use the Graphics Debugger to diagnose problems.
Building HLSL
The Windows XP toolset doesn't compile HLSL source code files by default. To
compile HLSL files, download and install the June 2010 DirectX SDK, and then set
the project's VC directories to include it. For more information, see the "DirectX
SDK Does Not Register Include/Library Paths with Visual Studio 2010" section of
the June 2010 DirectX SDK download page (Archived link).
Windows XP deployment
） Important
Because it lacks support for SHA-256 code signing certificates, runtime library
support for Windows XP is no longer available in the latest Visual C++
Redistributable for Visual Studio 2015, 2017, 2019, and 2022. The last
Redistributable to support Windows XP shipped in Visual Studio 2019 version 16.7.
Use a Redistributable that has a file version starting with 14.27. If your Windows XP
apps are deployed with or updated to a later version of the redistributable, the
apps won't run.
If you're using a version of Visual Studio later than Visual Studio 2019 version 16.7, the
redistributable files won't work on Windows XP. To get a copy of the redistributable files
that support Windows XP, you'll need a Visual Studio account. Use the account you use
to sign in to Visual Studio. Or, you can create an account for free at
my.visualstudio.com . The redistributable file is available in the Downloads section, as
Visual C++ Redistributable for Visual Studio 2019 - Version 16.7 . To download the
files, select the platform and language you need, and then choose the Download button.
You can use central deployment or local deployment to install runtime library support
for your Windows XP app. For more information, see Walkthrough: Deploying a Visual
C++ Application By Using the Visual C++ Redistributable Package.
C++ Code analysis in Visual Studio
Visual Studio provides tools to analyze and improve C++ code quality.
Analyze C and C++ code
ｅ OVERVIEW
Code analysis for C/C++ overview
ｆ QUICKSTART
Code Analysis for C/C++ quick start
ｇ TUTORIAL
Analyze C/C++ code for defects walkthrough
Code analysis reference
ｅ OVERVIEW
C++ Core Guidelines
ｉ REFERENCE
C++ Core Guidelines warnings
C++ code analysis warnings
Use SAL annotations to reduce defects
ｅ OVERVIEW
Understanding SAL
ｂ GET STARTED
SAL examples
ｃ HOW-TO GUIDE
Annotate function parameters and return values
Annotate function behavior
Annotate structs and classes
Annotate locking behavior
Specify when and where annotations apply
ｉ REFERENCE
SAL annotation intrinsics
C/C++ Sanitizers | Instrument code for
runtime bug detection
Use C and C++ sanitizers for defect reporting, analysis, and prevention.
Find bugs using code sanitizers
ｅ OVERVIEW
Learn about AddressSanitizer
ｇ TUTORIAL
AddressSanitizer shadow bytes
AddressSanitizer cloud or distributed testing
Instrument your builds
ｉ REFERENCE
AddressSanitizer build and language reference
AddressSanitizer runtime reference
AddressSanitizer error examples
AddressSanitizer known issues
Debug your results
ｉ REFERENCE
AddressSanitizer debugger integration
C/C++ Building Reference
Article • 08/03/2021
Visual Studio provides two ways of building a C/C++ program. The easiest (and most
common) way is to build within the Visual Studio IDE. The other way is to build from a
command prompt using command-line tools. In either case, you can create and edit
your source files using Visual Studio or a third-party editor of your choice.
In This Section
MSBuild reference for C++ projects
MSVC Compiler Reference
Describes the MSVC compiler, which creates an object file containing machine code,
linker directives, sections, external references, and function/data names.
MSVC linker reference
Describes the linker, which combines code from the object files created by the compiler
and from statically linked libraries, resolves the name references, and creates an
executable file.
Unicode Support in the Compiler and Linker
Additional MSVC Build Tools
Additional command-line tools for C++.
C/C++ Build Errors
Introduces the build errors section in the table of contents.
Related Sections
C/C++ Preprocessor Reference
Discusses the preprocessor, which prepares source files for the compiler by translating
macros, operators, and directives.
Understanding Custom Build Steps and Build Events
Discusses customizing the build process.
Building a C/C++ Program
Provides links to topics describing building your program from the command line or
from the integrated development environment of Visual Studio.
MSVC Compiler Command-Line Syntax
Describes setting compiler options in the development environment or on the
command line.
MSVC Compiler Options
Provides links to topics discussing using compiler options.
MSVC linker reference
Describes setting linker options inside or outside the integrated development
environment.
MSVC Linker Options
Provides links to topics discussing using linker options.
BSCMAKE Reference
Describes the Microsoft Browse Information Maintenance Utility (BSCMAKE.EXE), which
builds a browse information file (.bsc) from .sbr files created during compilation.
LIB Reference
Describes the Microsoft Library Manager (LIB.exe), which creates and manages a library
of Common Object File Format (COFF) object files.
EDITBIN Reference
Describes the Microsoft COFF Binary File Editor (EDITBIN.EXE), which modifies Common
Object File Format (COFF) binary files.
DUMPBIN Reference
Describes the Microsoft COFF Binary File Dumper (DUMPBIN.EXE), which displays
information about Common Object File Format (COFF) binary files.
NMAKE Reference
Describes the Microsoft Program Maintenance Utility (NMAKE.EXE), which is a tool that
builds projects based on commands contained in a description file.
MSBuild reference for C++ projects
Article • 08/03/2021
MSBuild is the native build system for all projects in Visual Studio, including C++
projects. When you build a project in the Visual Studio integrated development
environment (IDE), it invokes the msbuild.exe tool, which in turn consumes the .vcxproj
project file, and various .targets and .props files. In general, we strongly recommend
using the Visual Studio IDE to set project properties and invoke MSBuild. Manually
editing project files can lead to serious problems if not done correctly.
If for some reason you wish to use MSBuild directly from the command line, see Use
MSBuild from the command line. For more information about MSBuild in general, see
MSBuild in the Visual Studio documentation.
In this section
MSBuild internals for C++ projects
Information about how properties and targets are stored and consumed.
Common macros for build commands and properties
Describes macros (compile-time constants) that can be used to define properties such
as paths and product versions.
File types created for C++ projects
Describes the various kinds of files that Visual Studio creates for different project types.
Visual Studio C++ project templates
Describes the MSBuild-based project types that are available for C++.
C++ new item templates
Describes source files and other items you can add to a Visual Studio project.
Precompiled header files How to use precompiled header files and how to create your
own custom precompiled code to speed up build times.
Visual Studio project property reference
Reference documentation for project properties that are set in the Visual Studio IDE.
See also
C/C++ Building Reference
MSBuild internals for C++ projects
Article • 02/14/2022
When you set project properties in the IDE and then save the project, Visual Studio
writes the project settings to your project file. The project file contains settings that are
unique to your project. However, it doesn't contain all the settings required to build
your project. The project file contains Import elements that include a network of
additional support files. The support files contain the remaining properties, targets, and
settings required to build the project.
Most targets and properties in the support files exist solely to implement the build
system. This article discusses useful targets and properties you can specify on the
MSBuild command line. To discover more targets and properties, explore the files in the
support file directories.
Support File Directories
By default, the primary Visual Studio support files are located in the following
directories. This information is version-specific.
Visual Studio 2022 and 2019
%VSINSTALLDIR%MSBuild\Microsoft\VC\<version>\
Contains the primary target files ( .targets ) and property files ( .props ) that are
used by the targets. By default, the $(VCTargetsPath) macro references this
directory. The <version> placeholder refers to the Visual Studio version: v170 for
Visual Studio 2022, v160 for Visual Studio 2019, or v150 for Visual Studio 2017.
%VSINSTALLDIR%MSBuild\Microsoft\VC\<version>\Platforms\<platform>\
Contains platform-specific target and property files that override targets and
properties in its parent directory. This directory also contains a DLL that defines the
tasks that are used by the targets in this directory. The <platform> placeholder
represents the ARM, ARM64, Win32, or x64 subdirectory.
%VSINSTALLDIR%MSBuild\Microsoft\VC\<version>\Platforms\
<platform>\PlatformToolsets\<toolset>\
Contains the directories that enable the build to generate C++ applications by
using the specified <toolset> . The <platform> placeholder represents the ARM,
ARM64, Win32, or x64 subdirectory. The <toolset> placeholder represents the
toolset subdirectory.
Visual Studio 2017
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\
Contains the primary target files ( .targets ) and property files ( .props ) that are
used by the targets. By default, the $(VCTargetsPath) macro references this
directory.
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\Platforms\<platform>\
Contains platform-specific target and property files that override targets and
properties in its parent directory. This directory also contains a DLL that defines the
tasks that are used by the targets in this directory. The <platform> placeholder
represents the ARM, ARM64, Win32, or x64 subdirectory.
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\Platforms\<platform>\PlatformToolsets\
<toolset>\
Contains the directories that enable the build to generate C++ applications by
using the specified <toolset> . The <platform> placeholder represents the ARM,
Win32, or x64 subdirectory. The <toolset> placeholder represents the toolset
subdirectory.
Visual Studio 2015 and earlier
<drive>:\Program Files[ (x86)]\MSBuild\Microsoft.Cpp\v4.0\<version>\
Contains the primary target files ( .targets ) and property files ( .props ) that are
used by the targets. By default, the $(VCTargetsPath) macro references this
directory.
<drive>:\Program Files[ (x86)]\MSBuild\Microsoft.Cpp\v4.0\<version>\Platforms\
<platform>\
Contains platform-specific target and property files that override targets and
properties in its parent directory. This directory also contains a DLL that defines the
tasks that are used by the targets in this directory. The <platform> placeholder
represents the ARM, Win32, or x64 subdirectory.
<drive>:\Program Files[ (x86)]\MSBuild\Microsoft.Cpp\v4.0\<version>\Platforms\
<platform>\PlatformToolsets\<toolset>\
Contains the directories that enable the build to generate C++ applications by
using the specified <toolset> . The <version> placeholder is V110 for Visual Studio
2012, V120 for Visual Studio 2013, and V140 for Visual Studio 2015. The
<platform> placeholder represents the ARM, Win32, or x64 subdirectory. The
<toolset> placeholder represents the toolset subdirectory. For example, it's v140
for building Windows apps by using the Visual Studio 2015 toolset. Or, v120_xp to
build for Windows XP using the Visual Studio 2013 toolset.
<drive>:\Program Files[ (x86)]\MSBuild\Microsoft.Cpp\v4.0\Platforms\
<platform>\PlatformToolsets\<toolset>\
The paths that enable the build to generate either Visual Studio 2008 or Visual
Studio 2010 applications don't include the <version> . In those versions, the
<platform> placeholder represents the Itanium, Win32, or x64 subdirectory. The
<toolset> placeholder represents the v90 or v100 toolset subdirectory.
The support file directories contain files with these extensions:
Extension Description
.targets Contains Target XML elements that specify the tasks that are executed by the target.
May also contain PropertyGroup , ItemGroup , ItemDefinitionGroup , and user-defined
Item elements that are used to assign files and command-line options to task
parameters.
For more information, see Target Element (MSBuild).
.props Contains Property Group and user-defined Property XML elements that specify file
and parameter settings that are used during a build.
May also contain ItemDefinitionGroup and user-defined Item XML elements that
specify additional settings. Items defined in an item definition group resemble
properties, but can't be accessed from the command line. Visual Studio project files
frequently use items instead of properties to represent settings.
For more information, see ItemGroup Element (MSBuild), ItemDefinitionGroup
Element (MSBuild), and Item Element (MSBuild).
Support Files
Extension Description
.xml Contains XML elements that declare and initialize IDE user interface elements. For
example, property sheets, property pages, textbox controls, and listbox controls.
The .xml files directly support the IDE, not MSBuild. However, the values of IDE
properties are assigned to build properties and items.
Most .xml files are in a locale-specific subdirectory. For example, files for the
English-US region are in $(VCTargetsPath)\1033\ .
To use MSBuild effectively, it helps to know which properties and targets are useful and
relevant. Most properties and targets help implement the Visual Studio build system,
and aren't relevant to the user. This section describes user-oriented properties and
targets worth knowing about.
The PlatformToolset property determines which MSVC toolset is used in the build. By
default, the current toolset is used. When this property is set, its value gets
concatenated with literal strings to form the path. It's the directory that contains the
property and target files required to build a project for a particular platform. The
platform toolset must be installed to build by using that platform toolset version.
For example, set the PlatformToolset property to v140 to use Visual Studio 2015 tools
and libraries to build your application:
msbuild myProject.vcxproj /p:PlatformToolset=v140
The PreferredToolArchitecture property determines whether the 32-bit or 64-bit
compiler and tools are used in the build. This property doesn't affect the output
platform architecture or configuration. By default, MSBuild uses the x86 version of the
compiler and tools if this property isn't set.
For example, set the PreferredToolArchitecture property to x64 to use the 64-bit
compiler and tools to build your application:
msbuild myProject.vcxproj /p:PreferredToolArchitecture=x64
User targets and properties
PlatformToolset property
PreferredToolArchitecture property
By default, the platform-specific settings for the current project override the PATH ,
INCLUDE , LIB , LIBPATH , CONFIGURATION , and PLATFORM environment variables. Set the
UseEnv property to true to guarantee that the environment variables don't get
overridden.
msbuild myProject.vcxproj /p:UseEnv=true
There are hundreds of targets in the Visual Studio support files. However, most are
system-oriented targets that the user can ignore. Most system targets are prefixed by an
underscore ( _ ), or have a name that starts with PrepareFor , Compute , Before , After ,
Pre , or Post .
The following table lists several useful user-oriented targets.
Target Description
BscMake Executes the Microsoft Browse Information Maintenance Utility tool,
bscmake.exe .
Build Builds the project.
This target is the default for a project.
ClCompile Executes the MSVC compiler tool, cl.exe .
Clean Deletes temporary and intermediate build files.
Lib Executes the Microsoft 32-Bit Library Manager tool, lib.exe .
Link Executes the MSVC linker tool, link.exe .
ManifestResourceCompile Extracts a list of resources from a manifest and then executes the
Microsoft Windows Resource Compiler tool, rc.exe .
Midl Executes the Microsoft Interface Definition Language (MIDL) compiler
tool, midl.exe .
Rebuild Cleans and then builds your project.
ResourceCompile Executes the Microsoft Windows Resource Compiler tool, rc.exe .
XdcMake Executes the XML Documentation tool, xdcmake.exe .
UseEnv property
Targets
Target Description
Xsd Executes the XML Schema Definition tool, xsd.exe . See note.
MSBuild task reference
BscMake task
CL task
CPPClean task
LIB task
Link task
MIDL task
MT task
RC task
SetEnv task
VCMessage task
XDCMake task
７ Note
In Visual Studio 2017 and later, C++ project support for .xsd files is deprecated.
You can still use Microsoft.VisualC.CppCodeProvider by adding
CppCodeProvider.dll manually to the GAC.
See also
Common macros for MSBuild
commands and properties
Article • 01/12/2024
Depending on your installation options, Visual Studio can make hundreds of macros
available to you in an MSBuild-based .vcxproj Visual Studio project. The macros
correspond to the MSBuild properties that are set by default, or in .props or .targets
files, or in your project settings. You can use these macros anywhere in a project's
Property Pages dialog box where strings are accepted. These macros aren't case￾sensitive.
View the current properties and macros
To display all of the currently available macros, open the project property pages from
the main menu by selecting Project > Properties. In the Property Pages dialog, choose
an entry that has a macro in it. You can recognize a macro by the dollar sign and
parenthesis that surround its name.
For example, in the left pane, select Configuration Properties > VC++ Directories, and
then in the right pane, select Include directories. The value for Include directories is
$(VC_IncludePath);$(WindowsSDK_IncludePath); .
The dollar sign and parenthesis surrounding these two values indicates that they're
macros. The expansion of those two macros sets the include directories to search.
Select Include Directories and a dropdown appears at the end of the row. Select the
dropdown button, then select Edit. In the Include Directories dialog box that appears,
select the Macros>> button.
That expands the dialog to show the current set of properties and macros visible to
Visual Studio, along with the current value for each. For more information, see the
Specifying User-Defined Values section of C++ project property page reference.
This table describes a commonly used subset of the available macros; there are many
more not listed here. Go to the Macros dialog to see all of the properties and their
current values in your project. For details on how MSBuild property definitions are
created and used as macros in .props , .targets , and .vcxproj files, see MSBuild
Properties.
Macro Description
$(Configuration) The name of the current project configuration, for example, "Debug".
$(DevEnvDir) The installation directory of Visual Studio (defined as drive + path);
includes the trailing backslash (\).
$(FrameworkDir) The directory into which the .NET Framework was installed.
$(FrameworkSDKDir) The directory into which you installed the .NET Framework. The .NET
Framework may have been installed as part of Visual Studio or separately.
$(FrameworkVersion) The version of the .NET Framework used by Visual Studio. Combined with
$(FrameworkDir) , the full path to the version of the .NET Framework use
by Visual Studio.
$(FxCopDir) The path to the fxcop.cmd file. The fxcop.cmd file isn't installed in all
Visual Studio editions.
$(IntDir) Path to the directory specified for intermediate files. If it's a relative path,
intermediate files go to this path appended to the project directory. This
path should have a trailing backslash (\). It resolves to the value for the
List of common macros
ﾉ Expand table
Macro Description
Intermediate Directory property. Don't use $(OutDir) to define this
property.
$(OutDir) Path to the output file directory. If it's a relative path, output files go to
this path appended to the project directory. This path should have a
trailing backslash (\). It resolves to the value for the Output Directory
property. Don't use $(IntDir) to define this property.
$(Platform) The name of current project platform, for example, "Win32".
$(PlatformShortName) The short name of current architecture, for example, "x86" or "x64".
$(ProjectDir) The directory of the project (defined as drive + path); includes the trailing
backslash (\).
$(ProjectExt) The file extension of the project. It includes the '.' before the file
extension.
$(ProjectFileName) The file name of the project (defined as base name + file extension).
$(ProjectName) The base name of the project.
$(ProjectPath) The absolute path name of the project (defined as drive + path + base
name + file extension).
$(PublishDir) The output location for the publish target; includes the trailing backslash
(\). Defaults to the $(OutDir)app.publish\ folder.
$(RemoteMachine) Set to the value of the Remote Machine property on the Debug property
page. For more information, see Changing Project Settings for a C/C++
Debug Configuration.
$(RootNameSpace) The namespace, if any, containing the application.
$(SolutionDir) The directory of the solution (defined as drive + path); includes the
trailing backslash (\). Defined only when building a solution in the IDE.
$(SolutionExt) The file extension of the solution. It includes the '.' before the file
extension. Defined only when building a solution in the IDE.
$(SolutionFileName) The file name of the solution (defined as base name + file extension).
Defined only when building a solution in the IDE.
$(SolutionName) The base name of the solution. Defined only when building a solution in
the IDE.
$(SolutionPath) The absolute path name of the solution (defined as drive + path + base
name + file extension). Defined only when building a solution in the IDE.
$(TargetDir) The directory of the primary output file for the build (defined as drive +
Macro Description
path); includes the trailing backslash (\).
$(TargetExt) The file extension of the primary output file for the build. It includes the '.'
before the file extension.
$(TargetFileName) The file name of the primary output file for the build (defined as base
name + file extension).
$(TargetName) The base name of the primary output file for the build.
$(TargetPath) The absolute path name of the primary output file for the build (defined
as drive + path + base name + file extension).
$(VCInstallDir) The directory that contains the C++ content of your Visual Studio
installation. This property contains the version of the targeted Microsoft
C++ (MSVC) toolset, which might be different that the host Visual Studio.
For example, when building with $(PlatformToolset) = v140 ,
$(VCInstallDir) contains the path to the Visual Studio 2015 installation.
$(VSInstallDir) The directory into which you installed Visual Studio. This property
contains the version of the targeted Visual Studio toolset, which might be
different that the host Visual Studio. For example, when building with
$(PlatformToolset) = v110 , $(VSInstallDir) contains the path to the
Visual Studio 2012 installation.
$(WebDeployPath) The relative path from the web deployment root to where the project
outputs belong.
$(WebDeployRoot) The absolute path to the location of <localhost> . For example,
c:\inetpub\wwwroot .
The build system for C++ was changed significantly between Visual Studio 2008 and
Visual Studio 2010. Many macros used in earlier project types changed to new ones.
These macros are no longer used or are replaced by one or more equivalent properties
or item metadata macro ( %(item-name) ) values. The migration tool can update macros
marked "migrated". If a project containing the macro is migrated from Visual Studio
2008 or earlier to Visual Studio 2010, Visual Studio converts the macro to the equivalent
current macro. Later versions of Visual Studio can't convert projects from Visual Studio
2008 and earlier to the new project type. You must convert these projects in two steps;
first convert them to Visual Studio 2010, and then convert the result to your newer
version of Visual Studio. For more information, see Overview of potential upgrade
issues.
Obsolete macros
Macro Description
$(InputDir) (Migrated.) The directory of the input file (defined as drive + path);
includes the trailing backslash (\). If the project is the input, then this
macro is equivalent to $(ProjectDir) .
$(InputExt) (Migrated.) The file extension of the input file. It includes the '.' before the
file extension. If the project is the input, then this macro is equivalent to
$(ProjectExt) . For source files, it's equivalent to %(Extension) .
$(InputFileName) (Migrated.) The file name of the input file (defined as base name + file
extension). If the project is the input, then this macro is equivalent to
$(ProjectFileName) . For source files, it's equivalent to %(Identity) .
$(InputName) (Migrated.) The base name of the input file. If the project is the input,
then this macro is equivalent to $(ProjectName) . For source files, it's
equivalent to %(Filename) .
$(InputPath) (Migrated.) The absolute path name of the input file (defined as drive +
path + base name + file extension). If the project is the input, then this
macro is equivalent to $(ProjectPath) . For source files, it's equivalent to
%(FullPath) .
$(ParentName) Name of the item containing this project item. This macro is the parent
folder name, or project name.
$(SafeInputName) The name of the file as a valid class name, minus file extension. This
property doesn't have an exact equivalent.
$(SafeParentName) The name of the immediate parent in valid name format. For example, a
form is the parent of a .resx file. This property doesn't have an exact
equivalent.
$(SafeRootNamespace) The namespace name where the project wizards should add code. This
namespace name only contains characters that would be permitted in a
valid C++ identifier. This property doesn't have an exact equivalent.
Visual Studio Projects - C++
Visual C++ porting and upgrading guide
Overview of potential upgrade issues
MSBuild well-known item metadata
ﾉ Expand table
See also
File Types Created for Visual Studio C++
Projects
Article • 08/03/2021
Many types of files are associated with Visual Studio projects for classic desktop
applications. The actual files included in your project depend on the project type and
the options you select when using a wizard.
Project and Solution Files
CLR Projects
ATL Program or Control Source and Header Files
MFC Program or Control Source and Header Files
Precompiled Header Files
Resource Files
Help Files (WinHelp)
Hint Files
When you create a Visual Studio project, you might create it in a new solution, or you
might add a project to an existing solution. Non-trivial applications are commonly
developed with multiple projects in a solution.
Projects usually produce either an EXE or a DLL. Projects can be dependent on each
other; during the build process, the Visual Studio environment checks dependencies
both within and between projects. Each project usually has core source code. Depending
on the kind of project, it may have many other files containing various aspects of the
project. The contents of these files are indicated by the file extension. The Visual Studio
development environment uses the file extensions to determine how to handle the file
contents during a build.
The following table shows common files in a Visual Studio project, and identifies them
with their file extension.
File
extension
Type Contents
.asmx Source Deployment file.
File
extension
Type Contents
.asp Source Active Server Page file.
.atp Project Application template project file.
.bmp, .dib,
.gif, .jpg, .jpe,
.png
Resource General image files.
.bsc Compiling The browser code file.
.cpp, .c Source Main source code files for your application.
.cur Resource Cursor bitmap graphic file.
.dbp Project Database project file.
.disco Source The dynamic discovery document file. Handles XML Web service
discovery.
.exe, .dll Project Executable or dynamic-link library files.
.h Source A header (include) file.
.htm, .html,
.xsp, .asp,
.htc, .hta, .xml
Resource Common Web files.
.HxC Project Help project file.
.ico Resource Icon bitmap graphic file.
.idb Compiling The state file, containing dependency information between source
files and class definitions. It can be used by the compiler during
incremental compilation. Use the /Fd compiler option to specify the
name of the .idb file.
.idl Compiling An interface definition language file. For more information, see
Interface Definition (IDL) File in the Windows SDK.
.ilk Linking Incremental link file. For more information, see /INCREMENTAL.
.map Linking A text file containing linker information. Use the /Fm compiler
option to name the map file. For more information, see /MAP.
.mfcribbon￾ms
Resource A resource file that contains the XML code that defines the MFC
buttons, controls, and attributes in the ribbon. For more information,
see Ribbon Designer.
.obj, .o Object files, compiled but not linked.
File
extension
Type Contents
.pch Debug Precompiled header file.
.rc, .rc2 Resource Resource script files to generate resources.
.sbr Compiling Source browser intermediate file. The input file for BSCMAKE.
.sln Solution The solution file.
.suo Solution The solution options file.
.txt Resource A text file, usually the "readme" file.
.vap Project A Visual Studio Analyzer project file.
.vbg Solution A compatible project group file.
.vbp, .vip,
.vbproj
Project The Visual Basic project file.
.vcxitems Project Shared Items project for sharing code files between multiple C++
projects. For more information, see Project and Solution Files.
.vcxproj Project The Visual Studio project file. For more information, see Project and
Solution Files.
.vcxproj.filters Project Used when you use Solution Explorer to add a file to a project. The
filters file defines where in the Solution Explorer tree view to add the
file, based on its file name extension.
.vdproj Project The Visual Studio deployment project file.
.vmx Project The macro project file.
.vup Project The utility project file.
For information on other files associated with Visual Studio, see File Types and File
Extensions in Visual Studio .NET.
Project files are organized into folders in Solution Explorer. Visual Studio creates a folder
for source files, header files, and resource files, but you can reorganize these folders or
create new ones. You can use folders to organize explicitly logical clusters of files within
the hierarchy of a project. For example, you could create folders to contain all your user
interface source files. Or, folders for specifications, documentation, or test suites. All file
folder names should be unique.
When you add an item to a project, you add the item to all configurations for that
project. The item is added whether it's buildable or not. For example, if you have a
project named MyProject, adding an item adds it to both the Debug and Release project
configurations.
See also
Creating and Managing Visual Studio C++ Projects
Visual Studio C++ Project Types
Project and Solution Files
Article • 08/03/2021
The following files are created when you create a project in Visual Studio. They are used
to manage project files in the solution.
Filename Directory
location
Solution
Explorer
location
Description
Solname.sln Projname Not
displayed
in
Solution
Explorer
The solution file. It organizes all elements of a
project or multiple projects into one solution.
Projname.suo Projname Not
displayed
in
Solution
Explorer
The solution options file. It stores your
customizations for the solution so that every
time you open a project or file in the solution,
it has the appearance and behavior you want.
Projname.vcxproj Projname Not
displayed
in
Solution
Explorer
The project file. It stores information specific to
each project. (In earlier versions, this file was
named Projname.vcproj or Projname.dsp.) For
an example of a C++ project file (.vcxproj), see
Project Files.
Projname.vcxitems Projname Not
displayed
in
Solution
Explorer
The Shared Items project file. This project isn't
built. Instead, the project can be referenced by
another C++ project, and its files will become
part of the referencing project's build process.
This can be used to share common code with
cross-platform C++ projects.
Projname.sdf Projname Not
displayed
in
Solution
Explorer
The browsing database file. It supports
browsing and navigation features such as Goto
Definition, Find All References, and Class View.
It is generated by parsing the header files.
Projname.vcxproj.filters Projname Not
displayed
in
Solution
Explorer
The filters file. It specifies where to put a file
that is added to the solution. For example, a .h
file is put in the Header Files node.
Filename Directory
location
Solution
Explorer
location
Description
Projname.vcxproj.user Projname Not
displayed
in
Solution
Explorer
The migration user file. After a project is
migrated from Visual Studio 2008, this file
contains information that was converted from
any .vsprops file.
Projname.idl Projname Source (Project-specific) Contains the Interface
Description Language (IDL) source code for a
control type library. This file is used by Visual
C++ to generate a type library. The generated
library exposes the interface of the control to
other Automation clients. For more
information, see Interface Definition (IDL) File
in the Windows SDK.
Readme.txt Projname Project The read me file. It is generated by the
application wizard and describes the files in a
project.
File Types Created for Visual Studio C++ projects
See also
C++ project templates
Article • 08/03/2021
Visual Studio project templates generate source code files, compiler options, menus,
toolbars, icons, references, and #include statements that are appropriate for the kind of
project you want to create. Visual Studio includes several kinds of C++ project templates
and provides wizards for many of them so that you can customize your projects as you
create them. Immediately after you create a project, you can build it and run the
application; it's good practice to build intermittently as you develop your application.
The project templates included in Visual Studio depend on the product version and the
workloads you've installed. If you've installed the Desktop development with C++
workload, Visual Studio has these C++ project templates.
Project template Description
Windows Console
Application
A project for creating a Windows console application.
Windows Desktop
Application
A project for creating a Windows desktop (Win32) application.
Dynamic-Link Library A project for creating a dynamic-link library (DLL).
Static Library A project for creating a static library (LIB).
Windows Desktop
Wizard
A wizard for creating Windows desktop applications and libraries with
additional options.
７ Note
You can create a C-language project by using C++ project templates. In the
generated project, locate files that have a .cpp file name extension and change it to
.c. Then, on the Project Properties page for the project (not for the solution),
expand Configuration Properties, C/C++ and select Advanced. Change the
Compile As setting to Compile as C Code (/TC).
Project templates
Windows Desktop
Project
template
Description
Empty
Project
An empty project for creating an application, library, or DLL. You must add any
code or resources required.
Makefile
Project
A project that wraps a Windows makefile in a Visual Studio project. (To open a
makefile as-is in Visual Studio, use Open Folder.
Shared
Items
Project
A project used for sharing code files or resource files between multiple projects.
This project type does not produce an executable file.
Project template Description
ATL Project A project that uses the Active Template Library.
Project template Description
Native Unit Test Project A project that contains native C++ unit tests.
If you add the MFC and ATL support component to your Visual Studio installation, these
project templates are added to Visual Studio.
Project
template
Description
MFC Application A project for creating an application that uses the Microsoft Foundation Class
(MFC) Library.
MFC ActiveX
Control
A project for creating an ActiveX control that uses the MFC library.
MFC DLL A project for creating a dynamic-link library that uses the MFC library.
General
ATL
Test
MFC
Windows Universal Apps
If you add the C++ Windows Universal Platform tools component to your Visual Studio
installation, these project templates are added to Visual Studio.
For an overview of Windows Universal apps in C++, see Universal Windows Apps (C++).
Project
template
Description
Blank App A project for a single-page Universal Windows Platform (UWP) app that has
no predefined controls or layout.
DirectX 11 App A project for a Universal Windows Platform app that uses DirectX 11.
DirectX 12 App A project for a Universal Windows Platform app that uses DirectX 12.
DirectX 11 and
XAML App
A project for a Universal Windows Platform app that uses DirectX 11 and
XAML.
Unit Test App A project to create a unit test app for Universal Windows Platform (UWP)
apps.
DLL A project for a native dynamic-link library (DLL) that can be used by a
Universal Windows Platform app or runtime component.
Static Library A project for a native static link library (LIB) that can be used by a Universal
Windows Platform app or runtime component.
Windows
Runtime
Component
A project for a Windows Runtime component that can be used by a Universal
Windows Platform app, regardless of the programming language in which the
app is written.
Windows
Application
Packaging
Project
A project that creates a UWP package that enables a desktop application to be
side-loaded or distributed via the Microsoft Store.
Many of the files generated by a project template contain TODO comments to help you
identify where you can provide your own source code. For more information about how
to add code, see Adding Functionality with Code Wizards and Working with Resource
Files.
TODO Comments
Using Visual C++ Add New Item
Templates
Article • 08/03/2021
You can easily add items that are common to Visual Studio projects by using the Add
New Item command. When you use the Add New Item command, the Add New Item
dialog box appears with a list of item templates, which add the appropriate files to your
project.
The following table is an alphabetical list of Visual Studio Add New Item templates.
Template Description
Assembly
Resource File
(.resx)
Creates a file containing CLR resources.
Bitmap File
(.bmp)
Creates a Win32 bitmap file.
C++ File
(.cpp)
Creates a C++ source file.
Class
Diagram (.cd)
Creates an empty class diagram.
Code
Analysis Rule
Set (.ruleset)
Creates a settings file for configuring Code Analysis.
Configuration
File
(app.config)
Creates an empty configuration file.
Component
Class
Adds a Component Class using CLR features.
Cursor File
(.cur)
Creates a Win32 cursor file.
Discovery
File, Static
(.disco)
Creates a static discovery file, which is an XML document that contains links to
other resources that describe the XML Web service, enables programmatic
discovery of an XML Web service.
Frameset
(.htm)
Adds an HTML file that hosts multiple HTML pages.
Template Description
Header File
(.h)
Creates a C++ header file.
HTML Page
(.htm)
Creates a blank HTML file.
Icon File (.ico) Creates a Win32 icon file.
Installer Class Adds a class that inherits from the Installer using CLR features.
MIDL File
(.idl)
Creates an Interface Definition Language file.
Module￾Definition
File (.def)
Creates a DLL export definition file.
Property
Sheet
(.props)
Creates a property sheet file.
Registration
Script (.rgs)
Creates an ATL registration script file.
Report (.rdlc) Creates a report file.
Resource File
(.rc)
Creates a Win32 resource file.
Resource
Template File
(.rct)
Creates a resource template file.
Ribbon
(.mfcribbon￾ms)
Creates a ribbon file.
Server
Response File
(.srf)
Creates a server response file that is used with ATL Server.
SQL Script
File (.sql)
Creates an SQL script file. Note: This template is not a Professional Edition
feature.
Style Sheet
(.css)
Adds a cascading style sheet used for rich HTML style definitions.
Text File (.txt) Adds a blank text file.
User Control Adds a User Control using CLR features.
Template Description
Windows
Form
Adds a Windows Form using CLR features.
XML File
(.xml)
Adds a blank XML file.
XML Schema
File (.xsd)
Creates a file that is used to define a schema for XML documents.
XSLT File
(.xslt)
Creates a file used to transform XML documents.
Adding Functionality with Code Wizards
See also
Project Resource Files (C++)
Article • 08/03/2021
Resources are interface elements that provide information to the user. Bitmaps, icons,
toolbars, and cursors are all resources. Some resources can perform an action such as
selecting from a menu or entering data in dialog box.
For more information, see Working with Resources.
File name Directory
location
Solution
Explorer
location
Description
Projname.rc Projname Source
Files
The resource script file for the project. The
resource script file contains the following,
depending on the type of project, and the
support selected for the project (for example,
toolbars, dialog boxes, or HTML):
- Default menu definition.
- Accelerator and string tables.
- Default About dialog box.
- Other dialog boxes.
- Icon file (res\Projname.ico).
- Version information.
- Bitmaps.
- Toolbar.
- HTML files.
The resource file includes the file Afxres.rc for
standard Microsoft Foundation Class resources.
Resource.h Projname Header
Files
The resource header file that includes definitions
for the resources used by the project.
Projname.rc2 Projname\res Source
Files
The script file containing additional resources
used by the project. You can include the .rc2 file
under the project's .rc file.
An .rc2 file is useful for including resources used
by several different projects. Instead of having to
create the same resources several times for
different projects, you can put them in an .rc2 file
and include the .rc2 file into the main .rc file.
File name Directory
location
Solution
Explorer
location
Description
Projname.def Projname Source
Files
The module definition file for a DLL project. For a
control, it provides the name and description of
the control, as well as the size of the run-time
heap.
Projname.ico Projname\res Resource
Files
The icon file for the project or control. This icon
appears when the application is minimized. It is
also used in the application's About box. By
default, MFC provides the MFC icon, and ATL
provides the ATL icon.
ProjnameDoc.ico Projname\res Resource
Files
The icon file for an MFC project that includes
support for the document/view architecture.
Toolbar.bmp Projname\res Resource
Files
The bitmap file representing the application or
control in a toolbar or palette. This bitmap is
included in the project's resource file. The initial
toolbar and status bar are constructed in the
CMainFrame class.
ribbon.mfcribbon￾ms
Projname\res Resource
Files
The resource file that contains the XML code that
defines the buttons, controls, and attributes in
the ribbon. For more information, see Ribbon
Designer (MFC).
File Types Created for Visual Studio C++ projects
See also
Files Created for CLR Projects
Article • 08/03/2021
When you use Visual C++ templates to create your projects, several files are created,
depending on which template you use. The following table lists all the files that are
created by project templates for .NET Framework projects.
File name File description
AssemblyInfo.cpp The file that contains information (that is, attributes, files, resources, types,
versioning information, signing information, and so on) for modifying the
project's assembly metadata. For more information see Assembly Concepts.
projname.asmx A text file that references managed classes that encapsulate the functionality
of the XML Web service.
projname.cpp The main source file and entry point into the application that Visual Studio
created for you. Identifies the project .dll file and the project namespace.
Provide your own code in this file.
projname.vsdisco An XML deployment file containing links to other resources that describe the
XML Web service.
projname.h The main include file for the project, which contains all declarations, global
symbols, and #include directives for other header files.
projname.sln The solution file used within the development environment to organize all
elements of your project into a single solution.
projname.suo The solution options file used within the development environment.
projname.vcxproj The project file used within the development environment that stores the
information specific to this project.
ReadMe.txt A file describing each file in your project using the actual filenames created
by the template.
ATL program or control source and
header files
Article • 09/28/2022
The following files are created when you create an ATL project in Visual Studio,
depending on the options you select for the project you create. The file names depend
on the name you choose for your project, which we'll call ProjectName .
All of the files created by the project template are located in the ProjectName and
ProjectNamePS project directories. In Solution Explorer, the ProjectName files are located
in the Generated Files, Header Files, Resource Files, and Source Files folders. The
ProjectNamePS files are in the Generated Files and Source Files folders. Not all files
listed here are generated for every project type. Files in the Generated Files folder are
generated automatically by the MIDL compiler; they shouldn't be edited directly.
File name Description
ProjectName_i.c The generated source file containing the C++ IID and CLSID definitions and
GUID declarations of the items defined in ProjectName.idl . Don't edit this file;
it's regenerated by MIDL during compilation. Link this file with the server and
any clients.
ProjectName_i.h The generated include file containing the C++ interface declarations and GUID
declarations of the items defined in ProjectName.idl . Don't edit this file; it's
regenerated by MIDL during compilation. Include this file in source files for the
server and any clients.
ProjectName.rc The main program resource file.
ProjectName.rgs The main program registration file.
ProjectName.cpp The main program source file. In DLL projects, it contains the implementation
of your DLL's exports for an in-process server. In EXE projects, it contains the
implementation of WinMain for a local server. For a service, this file implements
all the service management functions.
ProjectName.def In DLL projects, the definitions for your DLL's exports.
ProjectName.idl The IDL source for your project. The MIDL tool processes this file to produce
the type library ( .tlb ) and marshaling code.
framework.h Sets preprocessor macros and includes the ATL header files, the targetver.h
version support header, and the Resource.h resource file header.
dllmain.h In DLL projects, the header file for the module class.
File name Description
dllmain.cpp In DLL projects, the source file for the DllMain function.
Resource.h The header file for the resource file.
targetver.h Includes SDKDDKVer.h . To build your application for a previous Windows
platform, include WinSDKVer.h and set the _WIN32_WINNT macro to the platform
you wish to support before including SDKDDKVer.h .
pch.cpp Includes the file pch.h .
pch.h Includes the framework.h header file.
File types created for Visual Studio C++ projects
MFC program or control source and header files
Add ATL support to an existing MFC executable or DLL
CLR projects
See also
MFC Program or Control Source and
Header Files
Article • 08/03/2021
The following files are created when you create an MFC project in Visual Studio,
depending on the options you select for the project you create. For example, your
project contains Projnamedlg.cpp and Projnamedlg.h files only if you create a dialog￾based project or class.
All of these files are located in the Projname directory, and in either the Header Files (.h
files) folder or Source Files (.cpp files) folder in Solution Explorer.
File name Description
Projname.h The main include file for the program or DLL. It contains all global
symbols and #include directives for other header files. It derives the
CPrjnameApp class from CWinApp and declares an InitInstance member
function. For a control, the CPrjnameApp class is derived from
COleControlModule .
Projname.cpp The main program source file. It creates one object of the class
CPrjnameApp , which is derived from CWinApp , and overrides the
InitInstance member function.
For executables, CPrjnameApp::InitInstance does several things. It
registers document templates, which serve as a connection between
documents and views; creates a main frame window; and creates an
empty document (or opens a document if one is specified as a
command-line argument to the application).
For DLLs and ActiveX (formerly OLE) controls,
CProjNameApp::InitInstance registers the control's object factory with
OLE by calling COleObjectFactory::RegisterAll and makes a call to
AfxOLEInit . In addition, the member function
CProjNameApp::ExitInstance is used to unload the control from memory
with a call to AfxOleTerm.
This file also registers and unregisters the control in the Windows
registration database by implementing the DllRegisterServer and
DllUnregisterServer functions.
File name Description
Projnamectrl.h,
Projnamectrl.cpp
Declare and implement the CProjnameCtrl class. CProjnameCtrl is
derived from COleControl , and skeleton implementations of some
member functions are defined that initialize, draw, and serialize (load
and save) the control. Message, event, and dispatch maps are also
defined.
Projnamedlg.cpp,
Projnamedlg.h
Created if you choose a dialog-based application. The files derive and
implement the dialog class, named CProjnameDlg , and include skeleton
member functions to initialize a dialog and perform dialog data
exchange (DDX). Your About dialog class is also placed in these files
instead of in Projname.cpp.
Dlgproxy.cpp,
Dlgproxy.h
In a dialog-based program, the implementation and header file for the
project's Automation proxy class for the main dialog. This is only used if
you have chosen Automation support.
Projnamedoc.cpp,
Projnamedoc.h
Derive and implement the document class, named CProjnameDoc , and
include skeleton member functions to initialize a document, serialize
(save and load) a document, and implement debugging diagnostics.
Projnameset.h/.cpp Created if you create a program that supports a database and contains
the recordset class.
Projnameview.cpp,
Projnameview.h
Derive and implement the view class, named CProjnameView , which is
used to display and print the document data. The CProjnameView class is
derived from one of the following MFC classes:
- CEditView
- CFormView
- CRecordView
- COleDBRecordView
- CTreeView
- CListView
- CRichEditView
- CScrollView
- CView
- CHTMLView
- CHTMLEditView
The project's view class contains skeleton member functions to draw the
view and implement debugging diagnostics. If you have enabled
support for printing, then message-map entries are added for print,
print setup, and print preview command messages. These entries call
the corresponding member functions in the base view class.
File name Description
ProjnamePropPage.h,
ProjnamePropPage.cpp
Declare and implement the CProjnamePropPage class. CProjnamePropPage
is derived from COlePropertyPage and a skeleton member function,
DoDataExchange , is provided to implement data exchange and
validation.
IPframe.cpp, IPframe.h Created if the Mini-Server or Full-Server option is selected in the
application wizard's Automation Options page (step 3 of 6). The files
derive and implement the in-place frame window class, named
CInPlaceFrame, used when the server is in place activated by a
container program.
Mainfrm.cpp,
Mainfrm.h
Derive the CMainFrame class from either CFrameWnd (for SDI
applications) or CMDIFrameWnd (for MDI applications). The
CMainFrame class handles the creation of toolbar buttons and the
status bar, if the corresponding options are selected in the application
wizard's Application Options page (step 4 of 6). For information on
using CMainFrame, see The Frame-Window Classes Created by the
Application Wizard.
Childfrm.cpp,
Childfrm.h
Derive the CChildFrame class from CMDIChildWnd. The CChildFrame
class is used for MDI document frame windows. These files are always
created if you select the MDI option.
File Types Created for Visual Studio C++ projects
ATL Program or Control Source and Header Files
CLR Projects
See also
Help Files (HTML Help)
Article • 08/03/2021
The following files are created when you add the HTML Help type of Help support to
your application by selecting the Context-sensitive help check box and then selecting
HTML Help format in the Advanced Features page of the MFC Application Wizard.
File name Directory location Solution
Explorer
location
Description
Projname.hhp Projname\hlp HTML
Help
files
The help project file. It contains the data
needed to compile the help files into an
.hxs file or a .chm file.
Projname.hhk Projname\hlp HTML
Help
files
Contains an index of the help topics.
Projname.hhc Projname\hlp HTML
Help
files
The contents of the help project.
Makehtmlhelp.bat Projname Source
Files
Used by the system to build the Help
project when the project is compiled.
Afxcore.htm Projname\hlp HTML
Help
Topics
Contains the standard help topics for
standard MFC commands and screen
objects. Add your own help topics to this
file.
Afxprint.htm Projname\hlp HTML
Help
Topics
Contains the help topics for the printing
commands.
*.jpg; *.gif Projname\hlp\Images Resource
Files
Contain images for the different
generated help file topics.
File Types Created for Visual Studio C++ projects
See also
Help Files (WinHelp)
Article • 08/03/2021
The following files are created when you add the WinHelp type of Help support to your
application by selecting the Context-sensitive help check box and then selecting
WinHelp format in the Advanced Features page of the MFC Application Wizard.
File name Directory
location
Solution
Explorer
location
Description
Projname.hpj Projname\hlp Source
Files
The Help project file used by the Help compiler to
create your program or control's Help file.
Projname.rtf Projname\hlp Help Files Contains template topics that you can edit and
information on customizing your .hpj file.
Projname.cnt Projname\hlp Help Files Provides the structure for the Contents window in
Windows Help.
Makehelp.bat Projname Source
Files
Used by the system to build the Help project when
the project is compiled.
Print.rtf Projname\hlp Help Files Created if your project includes printing support
(the default). Describes the printing commands and
dialog boxes.
*.bmp Projname\hlp Resource
Files
Contain images for the different generated help file
topics.
You can add WinHelp support to an MFC ActiveX Control project by selecting Generate
help files in the Application Settings tab of the MFC ActiveX Control Wizard. The
following files are added to your project when you add Help support to an MFC ActiveX
control:
File name Directory
location
Solution
Explorer
location
Description
Projname.hpj Projname\hlp Source files The project file used by the Help compiler to
create your program or control's Help file.
Projname.rtf Projname\hlp Project Contains template topics that you can edit and
information on customizing your .hpj file.
Makehelp.bat Projname Source Files Used by the system to build the Help project
when the project is compiled.
File name Directory
location
Solution
Explorer
location
Description
Bullet.bmp Projname Resource Files Used by standard Help file topics to represent
bulleted lists.
File Types Created for Visual Studio C++ projects
See also
Hint Files
Article • 11/11/2021
A hint file contains macros that would otherwise cause regions of code to be skipped by
the C++ Browsing Database Parser. When you open a Visual Studio C++ project, the
parser analyzes the code in each source file in the project and builds a database with
information about every identifier. The IDE uses that information to support code
browsing features such as the Class View browser and the Navigation Bar.
The C++ Browsing Database Parser is a fuzzy parser that can parse large amounts of
code in a short amount of time. One reason it's fast is because it skips the content of
blocks. For instance, it only records the location and parameters of a function, and
ignores its contents. Certain macros can cause issues for the heuristics used to
determine the start and end of a block. These issues cause regions of code to be
recorded improperly.
These skipped regions can manifest in multiple ways:
Missing types and functions in Class View, Go To and Navigation Bar
Incorrect scopes in the Navigation Bar
Suggestions to Create Declaration/Definition for functions that are already
defined
A hint file contains user-customizable hints, which have the same syntax as C/C++
macro definitions. Visual C++ includes a built-in hint file that is sufficient for most
projects. However, you can create your own hint files to improve the parser specifically
for your project.
） Important
If you modify or add a hint file, you need to take additional steps in order for the
changes to take effect:
In versions before Visual Studio 2017 version 15.6: Delete the .sdf file and/or
VC.db file in the solution for all changes.
In Visual Studio 2017 version 15.6 and later: Close and reopen the solution
after adding new hint files.
Scenario
C++
#define NOEXCEPT noexcept
void Function() NOEXCEPT
{
}
Without a hint file, Function doesn't show up in Class View, Go To or the Navigation
Bar. After adding a hint file with this macro definition, the parser now understands and
replaces the NOEXCEPT macro, which allows it to correctly parse the function:
cpp.hint
#define NOEXCEPT
Disruptive Macros
There are two categories of macros that disrupt the parser:
Macros that encapsulate keywords that adorn a function
C++
#define NOEXCEPT noexcept
#define STDMETHODCALLTYPE __stdcall
For these types of macros, only the macro name is required in the hint file:
cpp.hint
#define NOEXCEPT
#define STDMETHODCALLTYPE
Macros that contain unbalanced brackets
C++
#define BEGIN {
For these types of macros, both the macro name and its contents are required in
the hint file:
cpp.hint
#define BEGIN {
Editor Support
Starting in Visual Studio 2017 version 15.8 there are several features to identify
disruptive macros:
Macros that are inside regions skipped by the parser are highlighted.
There's a Quick Action to create a hint file that includes the highlighted macro, or if
there's an existing hint file, to add the macro to the hint file.
After executing either of the Quick Actions, the parser reparses the files affected by the
hint file.
By default, the problem macro is highlighted as a suggestion. The highlight can be
changed to something more noticeable, such as a red or green squiggle. Use the
Macros in Skipped Browsing Regions option in the Code Squiggles section under Tools
> Options > Text Editor > C/C++ > View.
Display Browsing Database Errors
The Project > Display Browsing Database Errors menu command displays all the
regions that failed to parse in the Error List. The command is meant to streamline
building the initial hint file. However, the parser can't tell if the cause of the error was a
disruptive macro, so you must evaluate each error. Run the Display Browsing Database
Errors command and navigate to each error to load the affected file in the editor. Once
the file is loaded, if any macros are inside the region, they're highlighted. You can invoke
the Quick Actions to add them to a hint file. After a hint file update, the error list is
updated automatically. Alternatively, if you're modifying the hint file manually you can
use the Rescan Solution command to trigger an update.
Architecture
Hint files relate to physical directories, not the logical directories shown in Solution
Explorer. You don't have to add a hint file to your project for the hint file to have an
effect. The parsing system uses hint files only when it parses source files.
Every hint file is named cpp.hint. Many directories can contain a hint file, but only one
hint file can occur in a particular directory.
Your project can be affected by zero or more hint files. If there are no hint files, the
parsing system uses error recovery techniques to ignore indecipherable source code.
Otherwise, the parsing system uses the following strategy to find and gather hints.
Search Order
The parsing system searches directories for hint files in the following order.
The directory that contains the installation package for Visual C++ (vcpackages).
This directory contains a built-in hint file that describes symbols in frequently used
system files, such as windows.h. Consequently, your project automatically inherits
most of the hints that it needs.
The path from the root directory of a source file to the directory that contains the
source file itself. In a typical Visual Studio C++ project, the root directory contains
the solution or project file.
The exception to this rule is if a stop file is in the path to the source file. A stop file
is any file that is named cpp.stop. A stop file provides additional control over the
search order. Instead of starting from the root directory, the parsing system
searches from the directory that contains the stop file to the directory that
contains the source file. In a typical project, you don't need a stop file.
Hint Gathering
A hint file contains zero or more hints. A hint is defined or deleted just like a C/C++
macro. That is, the #define preprocessor directive creates or redefines a hint, and the
#undef directive deletes a hint.
The parsing system opens each hint file in the search order described earlier. It
accumulates each file's hints into a set of effective hints, and then uses the effective hints
to interpret the identifiers in your code.
The parsing system uses these rules to accumulate hints:
If the new hint specifies a name that isn't already defined, the new hint adds the
name to the effective hints.
If the new hint specifies a name that is already defined, the new hint redefines the
existing hint.
If the new hint is an #undef directive that specifies an existing effective hint, the
new hint deletes the existing hint.
The first rule means that effective hints are inherited from previously opened hint files.
The last two rules mean that hints later in the search order can override earlier hints. For
example, you can override any previous hints if you create a hint file in the directory that
contains a source file.
For a depiction of how hints are gathered, see the Example section.
You create and delete hints by using the same syntax as the preprocessor directives to
create and delete macros. In fact, the parsing system uses the C/C++ preprocessor to
evaluate the hints. For more information about the preprocessor directives, see #define
Directive (C/C++) and #undef Directive (C/C++).
The only unusual syntax elements are the @< , @= , and @> replacement strings. These
hint-file specific replacement strings are only used in map macros. A map is a set of
macros that relate data, functions, or events to other data, functions, or event handlers.
For example, MFC uses maps to create message maps, and ATL uses maps to create
object maps. The hint-file specific replacement strings mark the starting, intermediate,
and ending elements of a map. Only the name of a map macro is significant. Therefore,
each replacement string intentionally hides the implementation of the macro.
Hints use this syntax:
Syntax Meaning
Syntax
Syntax Meaning
#define hint￾name
replacement￾string
#define hint￾name (
parameter,
... ) replacement￾string
A preprocessor directive that defines a new hint or redefines an existing hint.
After the directive, the preprocessor replaces each occurrence of hint-name in
source code with replacement-string.
The second syntax form defines a function-like hint. If a function-like hint
occurs in source code, the preprocessor first replaces each occurrence of
parameter in replacement-string with the corresponding argument in source
code, and then replaces hint-name with replacement-string.
@< A hint-file specific replacement-string that indicates the start of a set of map
elements.
@= A hint-file specific replacement-string that indicates an intermediate map
element. A map can have multiple map elements.
@> A hint-file specific replacement-string that indicates the end of a set of map
elements.
#undef hint￾name
The preprocessor directive that deletes an existing hint. The name of the hint is
provided by the hint-name identifier.
// comment A single-line comment.
/* comment */ A multiline comment.
This example shows how hints are accumulated from hint files. Stop files aren't used in
this example.
The illustration shows some of the physical directories in a Visual Studio C++ project.
There are hint files in the vcpackages , Debug , A1 , and A2 directories.
Example
Hint File Directories
Directories and Hint File Contents
This list shows the directories in this project that contain hint files, and the contents of
those hint files. Only some of the many hints in the vcpackages directory hint file are
listed:
vcpackages
cpp.hint
// vcpackages (partial list)
#define _In_
#define _In_opt_
#define _In_z_
#define _In_opt_z_
#define _In_count_(size)
Debug
cpp.hint
// Debug
#undef _In_
#define OBRACE {
#define CBRACE }
#define RAISE_EXCEPTION(x) throw (x)
#define START_NAMESPACE namespace MyProject {
#define END_NAMESPACE }
A1
cpp.hint
// A1
#define START_NAMESPACE namespace A1Namespace {
A2
cpp.hint
// A2
#undef OBRACE
#undef CBRACE
Effective Hints
This table lists the effective hints for the source files in this project:
Source File: A1_A2_B.cpp
Effective hints:
cpp.hint
// vcpackages (partial list)
#define _In_opt_
#define _In_z_
#define _In_opt_z_
#define _In_count_(size)
// Debug...
#define RAISE_EXCEPTION(x) throw (x)
// A1
#define START_NAMESPACE namespace A1Namespace {
// ...Debug
#define END_NAMESPACE }
These notes apply to the preceding list:
The effective hints are from the vcpackages , Debug , A1 , and A2 directories.
The #undef directive in the Debug hint file removed the #define _In_ hint in the
vcpackages directory hint file.
The hint file in the A1 directory redefines START_NAMESPACE .
The #undef hint in the A2 directory removed the hints for OBRACE and CBRACE in
the Debug directory hint file.
See also
File Types Created for Visual Studio C++ projects
#define Directive (C/C++)
#undef Directive (C/C++)
SAL Annotations
Property Page XML rule files
Article • 08/03/2021
The project property pages in the IDE are configured by XML files in the default rules
folder. The XML files describe the names of the rules, the categories, and the individual
properties, their data type, default values, and how to display them. When you set a
property in the IDE, the new value is stored in the project file.
The path to the default rules folder depends on the locale and the version of Visual
Studio in use. In a Visual Studio 2019 or later developer command prompt, the rules
folder is %VSINSTALLDIR%MSBuild\Microsoft\VC\<version>\<locale>\ , where the
<version> value is v160 in Visual Studio 2019. The <locale> is an LCID, for example,
1033 for English. In Visual Studio 2017, the rules folder is
%VSINSTALLDIR%Common7\IDE\VC\VCTargets\<locale>\ . In a Visual Studio 2015 or earlier
developer command prompt, the rules folder is
%ProgramFiles(x86)%\MSBuild\Microsoft.Cpp\v4.0\<version>\<locale>\ . You'll use a
different path for each edition of Visual Studio that's installed, and for each language.
For example, the default rules folder path for Visual Studio 2019 Community edition in
English could be C:\Program Files (x86)\Microsoft Visual
Studio\2019\Community\MSBuild\Microsoft\VC\v160\1033\ .
You only need to understand the internal workings of these files and the Visual Studio
IDE in a couple of scenarios:
You want to create a custom property page, or
You want to customize your project properties without use of the Visual Studio IDE.
Contents of rule files
First, let's open the property pages for a project. Right-click on the project node in
Solution Explorer and choose Properties:
Each node under Configuration Properties is called a rule. A rule sometimes represents
a single tool like the compiler. In general, the term refers to something that has
properties, that executes and that may produce some output. Each rule is populated
from an XML file in the default rules folder. For example, the C/C++ rule that's shown
here is populated by cl.xml .
Each rule has a set of properties, which are organized into categories. Each sub-node
under a rule represents a category. For example, the Optimization node under C/C++
contains all the optimization-related properties of the compiler tool. The properties and
their values get rendered in a grid format on the right pane.
You can open cl.xml in notepad or any XML editor. You'll see a root node called Rule .
It defines the same list of properties that get displayed in the UI, along with additional
metadata.
XML
<?xml version="1.0" encoding="utf-8"?>
<!--Copyright, Microsoft Corporation, All rights reserved.-->
<Rule Name="CL" PageTemplate="tool" DisplayName="C/C++" SwitchPrefix="/"
Order="10" xmlns="http://schemas.microsoft.com/build/2009/properties"
xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml" xmlns:sys="clr￾namespace:System;assembly=mscorlib">
 <Rule.Categories>
 <Category Name="General" DisplayName="General" />
 <Category Name="Optimization" DisplayName="Optimization" />
 <Category Name="Preprocessor" DisplayName="Preprocessor" />
 <Category Name="Code Generation" DisplayName="Code Generation" />
 <Category Name="Language" DisplayName="Language" />
 <Category Name="Precompiled Headers" DisplayName="Precompiled Headers"
/>
There's one XML file for every node under Configuration Properties in the property
pages UI. You can add or remove rules in the UI: it's done by including or removing
locations to corresponding XML files in the project. For example, it's how
Microsoft.CppBuild.targets (found one level higher than the 1033 folder) includes
cl.xml :
XML
If you strip cl.xml of all data, you have this basic framework:
XML
The next section describes each major element and some of the metadata that you can
attach.
A <Rule> element is the root node in the XML file. It can have many attributes:
 <Category Name="Output Files" DisplayName="Output Files" />
 <Category Name="Browse Information" DisplayName="Browse Information" />
 <Category Name="Advanced" DisplayName="Advanced" />
 <Category Name="All Options" DisplayName="All Options" Subtype="Search"
/>
 <Category Name="Command Line" DisplayName="Command Line"
Subtype="CommandLine" />
 </Rule.Categories>
 <!-- . . . -->
</Rule>
<PropertyPageSchema Condition="'$(ConfigurationType)' != 'Utility'"
Include="$(VCTargetsPath)$(LangID)\cl.xml"/>
<?xml version="1.0" encoding="utf-8"?>
<Rule>
 <Rule.DataSource />
 <Rule.Categories>
 <Category />
 <!-- . . . -->
 </Rule.Categories>
 <BoolProperty />
 <EnumProperty />
 <IntProperty />
 <StringProperty />
 <StringListProperty />
</Rule>
Rule attributes
XML
Name : The Name attribute is an ID for the Rule . It needs to be unique among all
the property page XML files for a project.
PageTemplate : The value of this attribute is used by the UI to choose from a
collection of UI templates. The "tool" template renders the properties in a standard
grid format. Other in-built values for this attribute are "debugger" and "generic".
See the Debugging node and General node, respectively, to see the UI format
resulting from specifying these values. The UI for "debugger" page template uses a
drop-down box to switch between the properties of different debuggers. The
"generic" template displays different property categories all in one page, as
opposed to having multiple category sub-nodes under the Rule node. This
attribute is just a suggestion to the UI. The XML file is designed to be UI
independent. A different UI might use this attribute for different purposes.
SwitchPrefix : The prefix used in the command line for the switches. A value of
"/" would result in switches that look like /ZI , /nologo , /W3 , and so on.
Order : A suggestion to a prospective UI client on the relative location of this Rule
compared to all other rules in the system.
xmlns : A standard XML element. You can see three namespaces listed. These
attributes correspond to the namespaces for the XML deserialization classes, XML
schema, and system namespace, respectively.
DisplayName : The name that's shown on the property page UI for the Rule node.
This value is localized. We created DisplayName as a child element of Rule rather
than as an attribute (like Name or SwitchPrefix ) because of internal localization
tool requirements. From an XML perspective, both are equivalent. So, you can just
make it an attribute to reduce clutter or leave it as it is.
DataSource : This important property tells the project system the location to read
and write the property value, and its grouping (explained later). For cl.xml , these
values are:
<Rule Name="CL" PageTemplate="tool" SwitchPrefix="/" Order="10"
 xmlns="http://schemas.microsoft.com/build/2009/properties"
 xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml"
 xmlns:sys="clr-namespace:System;assembly=mscorlib">
 <Rule.DisplayName>
 <sys:String>C/C++</sys:String>
 </Rule.DisplayName>
XML
Persistence="ProjectFile" tells the project system that all properties for the
Rule should be written to the project file or the property sheet file (depending
on which node was used to spawn the property pages). The other possible value
is "UserFile" , which will write the value to the .user file.
ItemType="ClCompile" says that the properties will be stored as ItemDefinition
metadata or item metadata (the latter only if the property pages were spawned
from a file node in solution explorer) of this item type. If this field isn't set, then
the property is written as a common property in a PropertyGroup.
Label="" indicates that when the properties are written as ItemDefinition
metadata, the label of the parent ItemDefinitionGroup will be empty (every
MSBuild element can have a Label). Visual Studio 2017 and later use labeled
groups to navigate the .vcxproj project file. The groups that contain most Rule
properties have an empty string as a label.
HasConfigurationCondition="true" tells the project system to affix a
configuration condition to the value so that it takes effect only for the current
project configuration (the condition could be affixed to the parent group or the
value itself). For example, open the property pages off the project node and set
the value of the property Treat Warnings As Error under Configuration
Properties > C/C++ General to "Yes". The following value is written to the
project file. Notice the configuration condition attached to the parent
ItemDefinitionGroup.
XML
If this value is set in the property page for a specific file, such as stdafx.cpp ,
then the property value should be written under the stdafx.cpp item in the
project file as shown Here. Notice how the configuration condition is directly
attached to the metadata itself:
<DataSource Persistence="ProjectFile" ItemType="ClCompile" Label=""
HasConfigurationCondition="true" />
<ItemDefinitionGroup
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
 <ClCompile>
 <TreatWarningAsError>true</TreatWarningAsError>
 </ClCompile>
</ItemDefinitionGroup>
XML
Another attribute of DataSource not listed here is PersistedName . You can use this
attribute to represent a property in the project file using a different name. By
default, this attribute is set to the property's Name .
An individual property can override the DataSource of its parent Rule . In that case,
the location for that property's value will be different from other properties in the
Rule .
There are other attributes of a Rule , including Description and
SupportsFileBatching , that aren't shown here. The full set of attributes applicable
to a Rule or on any other element can be obtained by browsing the
documentation for these types. Alternately, you can examine the public properties
on the types in the Microsoft.Build.Framework.XamlTypes namespace in the
Microsoft.Build.Framework.dll assembly.
DisplayName , PageTemplate , and Order are UI-related properties that are present in
this otherwise UI-independent data model. These properties are almost certain to
be used by any UI that is used to display the property pages. DisplayName and
Description are two properties that are present on almost all elements in the XML
file. And, these two properties are the only ones that are localized.
A Rule can have multiple Category elements. The order in which the categories are
listed in the XML file is a suggestion to the UI to display the categories in the same
order. For example, the order of the categories under the C/C++ node you see in the UI
is the same as the order in cl.xml . A sample category looks like this:
XML
<ItemGroup>
 <ClCompile Include="stdafx.cpp">
 <TreatWarningAsError
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">true</Trea
tWarningAsError>
 </ClCompile>
</ItemGroup>
Category elements
<Category Name="Optimization">
 <Category.DisplayName>
 <sys:String>Optimization</sys:String>
This snippet shows the Name and DisplayName attributes that have been described
before. Once again, there are other attributes a Category can have that aren't shown in
the example. You can learn about them by reading the documentation or by examining
the assemblies using ildasm.exe .
Most of the rule file consists of Property elements. They contain the list of all properties
in a Rule . Each property can be one of the five possible types shown in the basic
framework: BoolProperty , EnumProperty , IntProperty , StringProperty , and
StringListProperty . You might have only a few of those types in your file. A property
has a number of attributes that allow it to be described in detail. The StringProperty is
described here. The rest are similar.
XML
Most of the attributes in the snippet have been described before. The new ones are
Subtype , Category , and Switch .
Subtype is an attribute available only for StringProperty and StringListProperty
elements. It gives contextual information. For example, the value file indicates
that the property represents a file path. Visual Studio uses such contextual
information to enhance the editing experience. For instance, it may provide a
Windows Explorer window that allows the user to choose the file visually as the
property's editor.
Category : The category under which this property falls. Try to find this property
under the Output Files category in the UI.
 </Category.DisplayName>
</Category>
Property elements
<StringProperty Subtype="file" Name="ObjectFileName" Category="Output Files"
Switch="Fo">
 <StringProperty.DisplayName>
 <sys:String>Object File Name</sys:String>
 </StringProperty.DisplayName>
 <StringProperty.Description>
 <sys:String>Specifies a name to override the default object file name;
can be file or directory name.(/Fo[name])</sys:String>
 </StringProperty.Description>
</StringProperty>
Switch : When a rule represents a tool such as the compiler tool, most Rule
properties get passed as switches to the tool executable at build time. The value of
this attribute indicates which switch literal to use. The <StringProperty> example
specifies that its switch should be Fo . Combined with the SwitchPrefix attribute
on the parent Rule , this property is passed to the executable as /Fo"Debug\" . It's
visible in the command line for C/C++ in the property page UI.
Other property attributes include:
Visible : If you don't want your property to appear in the property pages, but want
it available at build time, set this attribute to false .
ReadOnly : If you want to provide a read-only view of this property's value in the
property pages, set this attribute to true .
IncludeInCommandLine : At build time, a tool might not need some of its properties.
Set this attribute to false to prevent a particular property from being passed.
.vcxproj and .props file structure
Article • 11/15/2022
MSBuild is the default project system in Visual Studio; when you choose File > New
Project in Visual C++ you're creating an MSBuild project whose settings are stored in an
XML project file that has the extension .vcxproj . The project file may also import
.props files and .targets files where settings can be stored.
If you intend to maintain your project properties in the IDE, we recommend you only
create and modify your .vcxproj projects in the IDE, and avoid manual edits to the files.
In most cases, you never need to manually edit the project file. Manual edits may break
the project connections required to modify project settings in the Visual Studio property
pages, and can cause build errors that are difficult to debug and repair. For more
information about using the property pages, see Set C++ compiler and build properties
in Visual Studio.
At scale, managing many individual projects in the IDE becomes tedious and error￾prone. It's hard to maintain consistency or enforce standardization across tens or
hundreds of projects. In these cases, it's worthwhile to edit your project files to use
customized .props or .targets files for common properties across many projects. You
may also use these files when you require customizations that aren't possible in the IDE.
Handy places to insert customizations are the Directory.Build.props and
Directory.Build.targets files, which are automatically imported in all MSBuild-based
projects.
In some cases, customized .props or .targets files alone may not be sufficient for your
project management needs. You may still need to modify .vcxproj project files or
property sheets manually. Manual editing requires a good understanding of MSBuild,
and must follow the guidelines in this article. In order for the IDE to load and update
.vcxproj files automatically, these files have several restrictions that don't apply to
other MSBuild project files. Mistakes can cause the IDE to crash or behave in unexpected
ways.
For manual editing scenarios, this article contains basic information about the structure
of .vcxproj and related files.
Important considerations
If you choose to manually edit a .vcxproj file, be aware of these facts:
The structure of the file must follow a prescribed form, which is described in this
article.
The Visual Studio C++ project system currently doesn't support wildcards or lists
directly in project items. For example, these forms aren't supported:
XML
For more information on wildcard support in projects and possible workarounds,
see .vcxproj files and wildcards.
The Visual Studio C++ project system currently doesn't support macros in project
item paths. For example, this form isn't supported:
XML
"Not supported" means that macros aren't guaranteed to work for all operations in
the IDE. Macros that don't change their value in different configurations should
work, but might not be preserved if an item is moved to a different filter or project.
Macros that change their value for different configurations will cause problems.
The IDE doesn't expect project item paths to be different for different project
configurations.
To add, remove, or modify project properties correctly when you edit them in the
Project Properties dialog, the file must contain separate groups for each project
configuration. The conditions must be in this form:
XML
Each property must be specified in the group with its correct label, as specified in
the property rule file. For more information, see Property page xml rule files.
<ItemGroup>
 <None Include="*.txt"/>
 <ClCompile Include="a.cpp;b.cpp"/>
</ItemGroup>
<ItemGroup>
 <ClCompile Include="$(IntDir)\generated.cpp"/>
</ItemGroup>
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'"
You can inspect the contents of a .vcxproj file by using any text or XML editor. You can
view it in Visual Studio by right-clicking on the project in Solution Explorer, choosing
Unload project and then choosing Edit Foo.vcxproj.
The first thing to notice is that the top-level elements appear in a particular order. For
example:
Most of the property groups and item definition groups occur after the import for
Microsoft.Cpp.Default.props.
All targets are imported at the end of the file.
There are multiple property groups, each with a unique label, and they occur in a
particular order.
The order of elements in the project file is vitally important, because MSBuild is based
on a sequential evaluation model. If your project file, including all the imported .props
and .targets files, consists of multiple definitions of a property, the last definition
overrides the preceding ones. In the following example, the value "xyz" will be set
during compilation because the MSBUild engine encounters it last during its evaluation.
XML
The following snippet shows a minimal .vcxproj file. Any .vcxproj file generated by
Visual Studio will contain these top-level MSBuild elements. And, they'll appear in this
order, although they may contain multiple copies of each such top-level element. Any
Label attributes are arbitrary tags that are only used by Visual Studio as signposts for
editing; they have no other function.
XML
.vcxproj file elements
 <MyProperty>abc</MyProperty>
 <MyProperty>xyz</MyProperty>
<Project DefaultTargets="Build" ToolsVersion="4.0"
xmlns='http://schemas.microsoft.com/developer/msbuild/2003'>
 <ItemGroup Label="ProjectConfigurations" />
 <PropertyGroup Label="Globals" />
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.default.props" />
 <PropertyGroup Label="Configuration" />
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
 <ImportGroup Label="ExtensionSettings" />
 <ImportGroup Label="PropertySheets" />
 <PropertyGroup Label="UserMacros" />
The following sections describe the purpose of each of these elements and why they're
ordered this way:
XML
Project is the root node. It specifies the MSBuild version to use and also the default
target to execute when this file gets passed to MSBuild.exe.
XML
ProjectConfigurations contains the project configuration description. Examples are
Debug|Win32, Release|Win32, Debug|ARM and so on. Many project settings are specific
to a given configuration. For example, you'll probably want to set optimization
properties for a release build but not a debug build.
The ProjectConfigurations item group isn't used at build time. The Visual Studio IDE
requires it to load the project. This item group can be moved to a .props file and
imported into the .vcxproj file. However, in that case, if you need to add or remove
configurations, you must manually edit the .props file; you can't use the IDE.
The following snippet shows a project configuration. In this example, 'Debug|x64' is the
configuration name. The project configuration name must be in the format
$(Configuration)|$(Platform) . A ProjectConfiguration node can have two properties:
 <PropertyGroup />
 <ItemDefinitionGroup />
 <ItemGroup />
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
 <ImportGroup Label="ExtensionTargets" />
</Project>
Project element
<Project DefaultTargets="Build" ToolsVersion="4.0"
xmlns='http://schemas.microsoft.com/developer/msbuild/2003' >
ProjectConfigurations ItemGroup element
<ItemGroup Label="ProjectConfigurations" />
ProjectConfiguration elements
Configuration and Platform . Those properties get set automatically with the values
specified here when the configuration is active.
XML
The IDE expects to find a project configuration for any combination of Configuration
and Platform values used in all ProjectConfiguration items. Often, it means that a
project might have meaningless project configurations to fulfill this requirement. For
instance, if a project has these configurations:
Debug|Win32
Retail|Win32
Special 32-bit Optimization|Win32
then it must also have these configurations, even though "Special 32-bit Optimization"
is meaningless for x64:
Debug|x64
Retail|x64
Special 32-bit Optimization|x64
You can disable the build and deploy commands for any configuration in the Solution
Configuration Manager.
XML
Globals contains project level settings such as ProjectGuid , RootNamespace , and
ApplicationType or ApplicationTypeRevision . The last two often define the target OS. A
project can only target a single OS because currently, references and project items can't
have conditions. These properties are typically not overridden elsewhere in the project
<ProjectConfiguration Include="Debug|x64">
 <Configuration>Debug</Configuration>
 <Platform>x64</Platform>
</ProjectConfiguration>
Globals PropertyGroup element
<PropertyGroup Label="Globals" />
file. This group isn't configuration-dependent, and typically only one Globals group
exists in the project file.
Microsoft.Cpp.default.props Import element
XML
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.default.props" />
The Microsoft.Cpp.default.props property sheet comes with Visual Studio and can't be
modified. It contains the default settings for the project. The defaults might vary
depending on the ApplicationType.
Configuration PropertyGroup elements
XML
<PropertyGroup Label="Configuration" />
A Configuration property group has an attached configuration condition (such as
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" ) and comes in multiple
copies, one per configuration. This property group hosts the properties that are set for a
specific configuration. Configuration properties include PlatformToolset and also control
the inclusion of system property sheets in Microsoft.Cpp.props. For example, if you
define the property <CharacterSet>Unicode</CharacterSet> , then the system property
sheet microsoft.Cpp.unicodesupport.props will be included. If you inspect
Microsoft.Cpp.props, you'll see the line: <Import Condition="'$(CharacterSet)' ==
'Unicode'" Project="$(VCTargetsPath)\microsoft.Cpp.unicodesupport.props" /> .
Microsoft.Cpp.props Import element
XML
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
The Microsoft.Cpp.props property sheet (directly or via imports) defines the default
values for many tool-specific properties. Examples include the compiler's Optimization
and Warning Level properties, the MIDL tool's TypeLibraryName property, and so on. It
also imports various system property sheets based on which configuration properties
are defined in the property group immediately before it.
ExtensionSettings ImportGroup element
XML
<ImportGroup Label="ExtensionSettings" />
The ExtensionSettings group contains imports for the property sheets that are part of
Build Customizations. A Build Customization is defined by up to three files: a .targets
file, a .props file, and an .xml file. This import group contains the imports for the
.props file.
PropertySheets ImportGroup elements
XML
<ImportGroup Label="PropertySheets" />
The PropertySheets group contains the imports for user property sheets. These imports
are the property sheets that you add through the Property Manager view in Visual
Studio. The order in which these imports are listed is important and is reflected in the
Property Manager. The project file normally contains multiple instances of this kind of
import group, one for each project configuration.
UserMacros PropertyGroup element
XML
<PropertyGroup Label="UserMacros" />
UserMacros contains properties you create as variables that are used to customize your
build process. For example, you can define a user macro to define your custom output
path as $(CustomOutputPath) and use it to define other variables. This property group
houses such properties. In Visual Studio, this group isn't populated in the project file
because Visual C++ doesn't support user macros for configurations. User macros are
supported in property sheets.
Per-configuration PropertyGroup elements
XML
There are multiple instances of this property group, one per configuration for all project
configurations. Each property group must have one configuration condition attached. If
any configurations are missing, the Project Properties dialog won't work correctly.
Unlike the property groups listed before, this one doesn't have a label. This group
contains project configuration-level settings. These settings apply to all files that are
part of the specified item group. Build customization item definition metadata is
initialized here.
This PropertyGroup must come after <Import
Project="$(VCTargetsPath)\Microsoft.Cpp.props" /> and there must be no other
PropertyGroup without a Label before it (otherwise Project Properties editing won't
work correctly).
XML
Contains item definitions. These definitions must follow the same conditions rules as the
label-less per-configuration PropertyGroup elements.
XML
ItemGroup elements contain the items (source files, and so on) in the project. Conditions
aren't supported for Project items (that is, item types that are treated as project items by
rules definitions).
The metadata should have configuration conditions for each configuration, even if
they're all the same. For example:
XML
<PropertyGroup />
Per-configuration ItemDefinitionGroup elements
<ItemDefinitionGroup />
ItemGroup elements
<ItemGroup />
<ItemGroup>
 <ClCompile Include="stdafx.cpp">
The Visual Studio C++ project system currently doesn't support wildcards in project
items.
XML
The Visual Studio C++ project system currently doesn't support macros in project items.
XML
References are specified in an ItemGroup, and they have these limitations:
References don't support conditions.
References metadata don't support conditions.
XML
Defines (directly or through imports) C++ targets such as build, clean, and so on.
XML
 <TreatWarningAsError
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">true</TreatWarning
AsError>
 <TreatWarningAsError
Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">true</TreatWarningAs
Error>
 </ClCompile>
</ItemGroup>
<ItemGroup>
 <ClCompile Include="*.cpp"> <!--Error-->
</ItemGroup>
<ItemGroup>
 <ClCompile Include="$(IntDir)\generated.cpp"> <!--not guaranteed to work
in all scenarios-->
</ItemGroup>
Microsoft.Cpp.targets Import element
<Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
ExtensionTargets ImportGroup element
<ImportGroup Label="ExtensionTargets" />
This group contains imports for the Build Customization target files.
Consequences of incorrect ordering
The Visual Studio IDE depends on the project file having the ordering described
previously. For example, when you define a property value in the property pages, the
IDE will generally place the property definition in the property group with the empty
label. This ordering ensures that default values brought in the system property sheets
are overridden by user-defined values. Similarly, the target files are imported at the end
since they consume the properties defined before, and since they generally don't define
properties themselves. Likewise, user property sheets are imported after the system
property sheets (included by Microsoft.Cpp.props ). This order ensures that the user can
override any defaults brought in by the system property sheets.
If a .vcxproj file doesn't follow this layout, the build results may not be what you
expect. For example, if you mistakenly import a system property sheet after the property
sheets defined by the user, the user settings get overridden by the system property
sheets.
Even the IDE design time experience depends on some extent on correct ordering of
elements. For example, if your .vcxproj file doesn't have the PropertySheets import
group, the IDE might be unable to determine where to place a new property sheet that
the user has created in Property Manager. It could result in a user sheet being
overridden by a system sheet. Although the heuristic used by IDE can tolerate minor
inconsistencies in the .vcxproj file layout, we strongly recommend you don't deviate
from the structure shown earlier in this article.
How the IDE uses element labels
In the IDE, when you set the UseOfAtl property in the general property page, it's written
to the Configuration property group in the project file. The TargetName property in the
same property page is written to the label-less per-configuration property group. Visual
Studio looks at the property page's xml file for the information on where to write each
property. For the General property page, assuming you have an English version of Visual
Studio 2019 Enterprise Edition, that file is %ProgramFiles(x86)%\Microsoft Visual
Studio\2019\Enterprise\Common7\IDE\VC\VCTargets\1033\general.xml . The property page
XML rule file defines the static information about a Rule and all its properties. One such
piece of information is the preferred position of a Rule property in the destination file
(the file where its value will be written). The preferred position is specified by the Label
attribute on the project file elements.
The following XML snippet is a minimal layout of a property sheet (.props) file. It's
similar to a .vcxproj file, and the functionality of the .props elements can be inferred
from the earlier discussion.
XML
To make your own property sheet, copy one of the .props files in the VCTargets folder
and modify it for your purposes. For Visual Studio 2019 Enterprise edition, the default
VCTargets path is %ProgramFiles%\Microsoft Visual
Studio\2019\Enterprise\Common7\IDE\VC\VCTargets .
Set C++ compiler and build properties in Visual Studio
Property Page XML Files
.vcxproj files and wildcards
Property Sheet layout
<Project ToolsVersion="4.0"
xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
 <ImportGroup Label="PropertySheets" />
 <PropertyGroup Label="UserMacros" />
 <PropertyGroup />
 <ItemDefinitionGroup />
 <ItemGroup />
</Project>
See also
.vcxproj files and wildcards
Article • 08/03/2021
The Visual Studio IDE doesn't support certain constructs in project items in .vcxproj
files. These unsupported constructs include wildcards, semi-colon delimited lists, or
MSBuild macros that expand to multiple files. The .vcxproj project system for C++
builds is more restrictive than MSBuild. Each project item is required to have its own
MSBuild item. For more information on the .vcxproj file format, see .vcxproj and .props
file structure.
These construct examples aren't supported by the IDE:
XML
If a .vcxproj project file that includes these constructs gets loaded in the IDE, the
project may seem to work at first. However, issues are likely as soon as the project is
modified by Visual Studio and then saved on disk. You may experience random crashes
and undefined behavior.
In Visual Studio 2019 version 16.7, when Visual Studio loads a .vcxproj project file, it
automatically detects unsupported entries in project items. You'll see warnings in the
Output window during solution load.
Visual Studio 2019 version 16.7 also adds read-only project support. Read-only support
allows the IDE to use manually authored projects that don't have the additional
limitations of IDE-editable projects.
If you have a .vcxproj file that uses one or more of the unsupported constructs, you
can make it load without warnings in the IDE by using one of these options:
List all items explicitly
Mark your project as read-only
Move wildcard items to a target body
<ItemGroup>
 <None Include="*.txt">
 <ClCompile Include="a.cpp;b.cpp"/>
 <ClCompile Include="@(SomeItems)" />
</ItemGroup>
List all items explicitly
Currently, there's no way to make wildcard expansion items visible in the Solution
Explorer window in a non-read-only project. Solution Explorer expects projects to list all
items explicitly.
To make .vcxproj projects automatically expand wildcards in Visual Studio 2019 version
16.7 or later, set the ReplaceWildcardsInProjectItems property to true . We recommend
you create a Directory.Build.props file in a root directory, and use this content:
XML
In Visual Studio 2019 version 16.7 and later, you can mark projects as read-only. To mark
your project read-only, add the following property to your .vcxproj file, or to any of the
files it imports:
XML
The <ReadOnlyProject> setting prevents Visual Studio from editing and saving the
project, so you can use any MSBuild constructs in it, including wildcards.
It's important to know that the project cache isn't available if Visual Studio detects
wildcards in project items in the .vcxproj file or any of its imports. Solution load times
in the IDE are much longer if you have lots of projects that use wildcards.
You may want to use wildcards to gather resources, add generated sources, and so on. If
you don't need them listed in the Solution Explorer window, you can use this procedure
instead:
1. Change the name of the item group to add wildcards. For instance, instead of:
<Project>
 <PropertyGroup>
 <ReplaceWildcardsInProjectItems>true</ReplaceWildcardsInProjectItems>
 </PropertyGroup>
</Project>
Mark your project as read-only
<PropertyGroup>
 <ReadOnlyProject>true</ReadOnlyProject>
</PropertyGroup>
Move wildcard items to a target body
XML
change it to:
XML
2. Add this content to your  .vcxproj file. Or, add it to a Directory.Build.targets
file in a root directory, to affect all projects under that root:
XML
This change makes the build see the items as they're defined in the  .vcxproj file.
However, now they aren't visible in the Solution Explorer window, and they won't
cause problems in the IDE.
3. To show correct IntelliSense for  _WildCardClCompile  items when you open those
files in the editor, add the following content:
XML
Effectively, you can use wildcards for any items inside a target body. You can also use
wildcards in an  ItemGroup  that isn't defined as a project item by a
ProjectSchemaDefinition .
<Image Include="*.bmp" />
<ClCompile Include="*.cpp" />
<_WildCardImage Include="*.bmp" />
<_WildCardClCompile Include="*.cpp" />
<Target Name="AddWildCardItems"
 AfterTargets="BuildGenerateSources">
 <ItemGroup>
 <Image Include="@(_WildCardImage)" />
 <ClCompile Include="@(_WildCardClCompile)" />
 </ItemGroup>
</Target>
<PropertyGroup>
 <ComputeCompileInputsTargets>
 AddWildCardItems
 $(ComputeCompileInputsTargets)
 </ComputeCompileInputsTargets>
</PropertyGroup>
７ Note
If you move wildcard includes from a .vcxproj file to an imported file, they won't
be visible in the Solution Explorer window. This change also allows your project to
load in the IDE without modification. However, we don't recommend this approach,
because it disables the project cache.
See also
Set C++ compiler and build properties in Visual Studio
Property Page XML Files
Project Files
Article • 08/03/2021
A C++ project file in Visual Studio is an XML-based file that has the .vcxproj file name
extension and contains information that is required to build a C++ project. Note that
the project file imports various project files that have the ".props" or ".targets"
extension. These files contain additional build information, and might themselves refer
to other ".props" or ".targets" files. The macros in the file path (for example
$(VCTargetsPath) ) are dependent on your Visual Studio installation. For more
information about these macros and ".props" and ".targets" files, see VC++ Directories
Property Page, Set C++ compiler and build properties in Visual Studio and Common
macros for build commands and properties.
The following sample .vcxproj file was produced by choosing Windows Desktop Wizard
in the New Project dialog box. To process a project file use either the msbuild.exe tool
at the command line, or the Build command in the IDE. (This sample cannot be
processed because the required source and header files are not provided.) For more
information about the XML elements in a project file, see Project File Schema Reference.
XML
Example
７ Note
For projects in Visual Studio 2017 and earlier, change pch.h to stdafx.h and
pch.cpp to stdafx.cpp .
<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" ToolsVersion="4.0"
xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
 <ItemGroup Label="ProjectConfigurations">
 <ProjectConfiguration Include="Debug|Win32">
 <Configuration>Debug</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
 <ProjectConfiguration Include="Release|Win32">
 <Configuration>Release</Configuration>
 <Platform>Win32</Platform>
 </ProjectConfiguration>
 </ItemGroup>
 <PropertyGroup Label="Globals">
 <ProjectGuid>{96F21549-A7BF-4695-A1B1-B43625B91A14}</ProjectGuid>
 <Keyword>Win32Proj</Keyword>
 <RootNamespace>SomeProjName</RootNamespace>
 </PropertyGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
 <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'"
Label="Configuration">
 <ConfigurationType>Application</ConfigurationType>
 <CharacterSet>Unicode</CharacterSet>
 </PropertyGroup>
 <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'"
Label="Configuration">
 <ConfigurationType>Application</ConfigurationType>
 <WholeProgramOptimization>true</WholeProgramOptimization>
 <CharacterSet>Unicode</CharacterSet>
 </PropertyGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
 <ImportGroup Label="ExtensionSettings">
 </ImportGroup>
 <ImportGroup Label="PropertySheets"
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
 <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props"
Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')"
Label="LocalAppDataPlatform" />
 </ImportGroup>
 <ImportGroup Label="PropertySheets"
Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
 <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props"
Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')"
Label="LocalAppDataPlatform" />
 </ImportGroup>
 <PropertyGroup Label="UserMacros" />
 <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
 <LinkIncremental>true</LinkIncremental>
 </PropertyGroup>
 <PropertyGroup
Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
 <LinkIncremental>false</LinkIncremental>
 </PropertyGroup>
 <ItemDefinitionGroup
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
 <ClCompile>
 <PrecompiledHeader>Use</PrecompiledHeader>
 <WarningLevel>Level3</WarningLevel>
 <MinimalRebuild>true</MinimalRebuild>
 <DebugInformationFormat>EditAndContinue</DebugInformationFormat>
 <Optimization>Disabled</Optimization>
 <BasicRuntimeChecks>EnableFastChecks</BasicRuntimeChecks>
 <RuntimeLibrary>MultiThreadedDebugDLL</RuntimeLibrary>
 <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%
(PreprocessorDefinitions)</PreprocessorDefinitions>
 </ClCompile>
 <Link>
 <SubSystem>Console</SubSystem>
 <GenerateDebugInformation>true</GenerateDebugInformation>
 </Link>
Visual Studio Projects - C++
Set C++ compiler and build properties in Visual Studio
 </ItemDefinitionGroup>
 <ItemDefinitionGroup
Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
 <ClCompile>
 <WarningLevel>Level3</WarningLevel>
 <PrecompiledHeader>Use</PrecompiledHeader>
 <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
 <Optimization>MaxSpeed</Optimization>
 <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
 <FunctionLevelLinking>true</FunctionLevelLinking>
 <IntrinsicFunctions>true</IntrinsicFunctions>
 <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%
(PreprocessorDefinitions)</PreprocessorDefinitions>
 </ClCompile>
 <Link>
 <SubSystem>Console</SubSystem>
 <GenerateDebugInformation>true</GenerateDebugInformation>
 <EnableCOMDATFolding>true</EnableCOMDATFolding>
 <OptimizeReferences>true</OptimizeReferences>
 </Link>
 </ItemDefinitionGroup>
 <ItemGroup>
 <None Include="ReadMe.txt" />
 </ItemGroup>
 <ItemGroup>
 <ClInclude Include="pch.h" />
 <ClInclude Include="targetver.h" />
 </ItemGroup>
 <ItemGroup>
 <ClCompile Include="SomeProjName.cpp" />
 <ClCompile Include="pch.cpp">
 <PrecompiledHeader
Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">Create</Precompile
dHeader>
 <PrecompiledHeader
Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">Create</Precompi
ledHeader>
 </ClCompile>
 </ItemGroup>
 <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
 <ImportGroup Label="ExtensionTargets">
 </ImportGroup>
</Project>
See also
vcxproj.filters files
Article • 04/10/2023
The filters file ( *.vcxproj.filters ) is an XML file in MSBuild format that is located in the
root project folder. It specifies which file types go into which logical folder in Solution
Explorer. In the following illustration, the .cpp files are under the Source Files node. the
.h files are under the Header Files node, and .ico and .rc files are under Resource
Files. This placement is controlled by the filters file.
Creating a custom filters file
Visual Studio creates this file automatically. For desktop applications, the predefined
logical folders (filters) are: Source Files, Header Files and Resource Files. Other project
types such as UWP might have a different set of default folders. Visual Studio
automatically assigns known file types to each folder. If you want to create a filter with a
custom name or a filter that holds custom file types, you can create your own filters file
in the root folder of the project, or under an existing filter. (References and External
Dependencies are special folders that don't participate in filtering.)
The following example shows the filters file for the example show previously. It has a flat
hierarchy; in other words, there are no nested logical folders. The UniqueIdentifier
node is optional. It enables Visual Studio automation interfaces to find the filter.
Extensions is also optional. When a new file is added to a project, it's added to the
topmost filter with a matching file extension. To add a file to a specific filter, right-click
on the filter and choose Add New Item.
The ItemGroup that contains the ClInclude nodes is created when the project is first
launched. If you're generating your own vcxproj files, make sure that all project items
also have an entry in the filters file. Values in a ClInclude node override the default
filtering based on file extensions. When you use Visual Studio to add a new item to the
project, the IDE adds an individual file entry in the filters file. The filter isn't automatically
reassigned if you change the file's extension.
XML
Example
<?xml version="1.0" encoding="utf-8"?>
<Project ToolsVersion="4.0"
xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
 <ItemGroup>
 <Filter Include="Source Files">
 <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}
</UniqueIdentifier>
 <Extensions>cpp;c;cc;cxx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
 </Filter>
 <Filter Include="Header Files">
 <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}
</UniqueIdentifier>
 <Extensions>h;hh;hpp;hxx;hm;inl;inc;ipp;xsd</Extensions>
 </Filter>
 <Filter Include="Resource Files">
 <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}
</UniqueIdentifier>
 
<Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;ti
f;png;wav;mfcribbon-ms</Extensions>
 </Filter>
 </ItemGroup>
 <ItemGroup>
 <ClInclude Include="MFCApplication1.h">
 <Filter>Header Files</Filter>
 </ClInclude>
 <ClInclude Include="MFCApplication1Dlg.h">
 <Filter>Header Files</Filter>
 </ClInclude>
 <ClInclude Include="stdafx.h">
 <Filter>Header Files</Filter>
To create nested logical folders, declare all nodes in filters ItemGroup as shown below.
Each child node must declare the full logical path to the topmost parent. In the
following example, an empty ParentFilter must be declared because it's referenced in
later nodes.
XML
 </ClInclude>
 <ClInclude Include="targetver.h">
 <Filter>Header Files</Filter>
 </ClInclude>
 <ClInclude Include="Resource.h">
 <Filter>Header Files</Filter>
 </ClInclude>
 </ItemGroup>
 <ItemGroup>
 <ClCompile Include="MFCApplication1.cpp">
 <Filter>Source Files</Filter>
 </ClCompile>
 <ClCompile Include="MFCApplication1Dlg.cpp">
 <Filter>Source Files</Filter>
 </ClCompile>
 <ClCompile Include="stdafx.cpp">
 <Filter>Source Files</Filter>
 </ClCompile>
 </ItemGroup>
 <ItemGroup>
 <ResourceCompile Include="MFCApplication1.rc">
 <Filter>Resource Files</Filter>
 </ResourceCompile>
 </ItemGroup>
 <ItemGroup>
 <None Include="res\MFCApplication1.rc2">
 <Filter>Resource Files</Filter>
 </None>
 </ItemGroup>
 <ItemGroup>
 <Image Include="res\MFCApplication1.ico">
 <Filter>Resource Files</Filter>
 </Image>
 </ItemGroup>
</Project>
 <ItemGroup>
 <Filter Include="ParentFilter">
 </Filter>
 <Filter Include="ParentFilter\Source Files"> <!-- Full path to topmost
parent.--> 
 <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}
</UniqueIdentifier> <!-- Optional-->
 <Extensions>cpp;c;cc;cxx;def;odl;idl;hpj;bat;asm;asmx</Extensions> <!-
- Optional -->
 </Filter>
 <Filter Include="Header Files">
 <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}
</UniqueIdentifier>
 <Extensions>h;hh;hpp;hxx;hm;inl;inc;ipp;xsd</Extensions>
 </Filter>
 </ItemGroup>
Windows C++ project property page
reference
Article • 08/03/2021
In Visual Studio, you specify compiler and linker options, file paths, and other build
settings through the property pages for the project. The properties and property pages
that are available depend on the project type. For example, a makefile project has an
NMake property page, which is not present in an MFC or Win32 console project. To
open the Property Pages, choose Project > Properties from the main menu, or right￾click on the project node in Solution Explorer and choose Properties. Individual files
also have property pages that enable you to set compile and build options for just that
file. The following image shows the property pages for an MFC project.
This section provides a quick reference for the property pages themselves. The options
and settings exposed in the property pages are documented more completely in their
own topics and are linked from the property page topics. For more information about
project properties, see Set C++ compiler and build properties in Visual Studio.
For property pages in Linux projects, see Linux C++ Property Page Reference.
In This Section
General Property Page (Project)
General Property Page (File)
Advanced Property Page
VC++ Directories Property Page
Linker Property Pages
Manifest Tool Property Pages
HLSL Property Pages
Command Line Property Pages
Custom Build Step Property Page: General
Adding references
Managed Resources Property Page
MIDL Property Pages
NMake Property Page
Resources Property Pages
Web References Property Page
XML Data Generator Tool Property Page
XML Document Generator Tool Property Pages
See also
How to: Create and Remove Project Dependencies
How to: Create and Edit Configurations
Linux C++ Property Page Reference
General Property Page (Project)
Article • 10/06/2021
This article applies to Visual Studio projects for Windows. For Linux projects, see Linux
C++ Property page reference. For CMake projects, see CMake projects in Visual Studio.
For Android projects, see General project properties (Android C++). For Android
Makefile projects, see General project properties (Android C++ Makefile). In Visual
Studio 2019, some properties for non-UWP (Windows Runtime or Universal Windows
Platform) projects have moved to the Advanced property page.
To open the Property Pages dialog for a project, select the project (not the solution) in
Solution Explorer. Next, select the Project > Project-name Properties menu from the
menu bar. Or, right-click on the project node in Solution Explorer and select Properties
from the shortcut menu.
In the Property Pages dialog, the Configuration Properties > General property page
displays project properties based on project type. These properties are gathered under
one or two headings, depending on project type:
General
Project Defaults
General
The General property heading includes some combination of these properties:
Target Platform
Specifies the platform that the project runs on. For example, Windows, Android, or iOS.
The value Windows 10 means the project targets the Universal Windows Platform. If
you're targeting other versions of Windows, the version isn't listed and the value in this
field appears as just Windows. This property is a read-only field that's set when you
create a project.
Target Platform Version
Specifies the version of the Windows SDK used to build the project. This property
appears only if the project type supports it. You can select 10.0 to specify the latest
version of the Windows SDK. If your app can take advantage of features in this Windows
SDK version, but can still run on earlier versions without those features, perhaps with
some loss of functionality, then the value of this property and the Target Platform Min.
Version property might be different. If so, your code should check the version of the
platform it's running against at runtime and disable features that aren't available in
older platform versions.
Target Platform Min. Version
Specifies the lowest version of the platform that the project can run on. This property
appears only if the project type supports it. Set this value if your app can take advantage
of features in a newer Windows SDK version, but still runs on earlier versions, perhaps
with some loss of functionality. If set to a lower value, your code should check the
version of the platform it's running against at runtime. Then, disable features that aren't
available in older platform versions.
The C++ project system doesn't enforce this option. It's included for consistency with
other languages, such as C# and JavaScript, and as a guide for anyone who uses your
project. Microsoft C++ won't generate an error if you use a feature that's not available
in the minimum version.
Windows SDK Version
For the Windows target platform, this property specifies the version of the Windows
SDK that your project requires. When the Visual Studio Installer installs a C++ Workload,
it also installs the required parts of the Windows SDK. If you have other Windows SDK
versions on your computer, each version installed appears in the dropdown.
To target Windows 7 or Windows Vista, use the value 8.1, since Windows SDK 8.1 is
backward compatible to those platforms. When you target an earlier version, define the
appropriate value for _WIN32_WINNT in targetver.h . For Windows 7, that's 0x0601. For
more information, see Modifying WINVER and _WIN32_WINNT.
You can install the Windows XP platform toolset included as an optional component in
Visual Studio Installer to build Windows XP and Windows 2003 Server projects. For
information on how to obtain and use this platform toolset, see Configuring programs
for Windows XP. For more information on changing the platform toolset, see How to:
Modify the target framework and platform toolset.
Output Directory
Specifies the directory where build tools such as the linker place all final output files
created during the build process. Typically, this directory holds the output of tools such
as the linker, librarian, or BSCMake. By default, this property is the directory specified by
the macro combination $(SolutionDir)$(Configuration)\ .
To programmatically access this property, see OutputDirectory.
Intermediate Directory
Specifies the directory where tools such as the compiler place all intermediate files
created during the build process. Typically, this directory holds the output of tools such
as the C/C++ compiler, MIDL, and the resource compiler. By default, this property is the
directory specified by the macro $(Configuration)\ .
To programmatically access this property, see IntermediateDirectory.
Target Name
Specifies the file name this project generates. By default, this property is the filename
specified by the macro $(ProjectName) .
Target Extension
Specifies the file extension this project generates, such as .exe or .dll . For some Visual
Studio 2019 project types, this property has moved to the Advanced property page.
Extensions to Delete on Clean
The Build > Clean menu command deletes files from the intermediate directory where a
project's configuration is built. The build system deletes files that have the specified
extensions when you run the Clean command or when you rebuild. The build system
also deletes any known output of the build no matter where it's located. Deleted files
include any intermediate outputs such as .obj files. Use semicolons ( ; ) to separate
extensions. You can specify wildcard characters ( * , ? ) in the extensions.
To programmatically access this property, see DeleteExtensionsOnClean. For some Visual
Studio 2019 project types, this property has moved to the Advanced property page.
Build Log File
Allows you to specify a non-default location for the log file that's created whenever you
build a project. The default location is specified by the macro combination
$(IntDir)$(MSBuildProjectName).log . For some Visual Studio 2019 project types, this
property has moved to the Advanced property page.
You can use project macros to change the directory location. For more information, see
Common macros for build commands and properties.
Platform Toolset
Specifies the toolset used for building the current configuration. This property allows the
project to target a different version of the Visual C++ libraries and compiler. By default,
Visual Studio C++ projects target the latest toolset installed by Visual Studio. You can
choose one of the toolsets installed by several previous versions of Visual Studio
instead. Some older toolsets can create executables that run on Windows XP or Vista.
For more information on how to change the platform toolset, see How to: Modify the
target framework and platform toolset.
Enable Managed Incremental Build
For managed projects, this property enables detection of external visibility when you
generate assemblies. If a change to a managed project isn't visible to other projects,
then dependent projects don't get rebuilt. This option can dramatically improve build
times in solutions that include managed projects. In Visual Studio 2019 projects, this
property has moved to the Advanced property page.
Configuration Type
Specifies the project output and its required tools. In UWP projects, this property
appears under the Project Defaults heading. There are several configuration types from
which to choose, depending on your project type:
Application (.exe)
Displays the linker toolset: The C/C++ Compiler, MIDL, Resource Compiler, Linker,
BSCMake, XML Web Service Proxy Generator, custom build, prebuild, prelink, and
postbuild events.
Dynamic Library (.dll)
Displays the linker toolset, specifies the /DLL linker option, and adds the _WINDLL
preprocessor definition to the CL command line.
Makefile
Displays the makefile toolset (NMake).
Static Library (.lib)
Displays the librarian toolset. It's the same as the linker toolset, except it replaces the
linker with the librarian and omits XML Web Service Proxy Generator.
Utility
Displays the utility toolset (MIDL, custom build, prebuild, and postbuild events).
To programmatically access this property, see ConfigurationType.
C++ Language Standard
Specifies which C++ language standard to use. The default is /std:c++14 . Specify
/std:c++17 to use C++17 features, /std:c++20 to use C++20 features, and
/std:c++latest to use proposed C++23 features or other experimental features. For
more information, see /std (Specify language standard version).
C Language Standard
Specifies which C language standard to use. The default is Legacy MSVC, which
implements C89, some of C99, and Microsoft-specific extensions. Specify /std:c11 to
use C11 features, and /std:c17 to use C17 features. For more information, see /std
(Specify language standard version)
Project Defaults
Use of MFC
Specifies whether the MFC project statically or dynamically links to the MFC DLL. Non￾MFC projects select Use Standard Windows Libraries. In Visual Studio 2019 projects,
this property has moved to the Advanced property page.
To programmatically access this property, see useOfMfc.
Character Set
Specifies whether the _UNICODE or _MBCS preprocessor macro should be set. Also affects
the linker entry point, where appropriate. In Visual Studio 2019 projects, this property
has moved to the Advanced property page.
To programmatically access this property, see CharacterSet.
Common Language Runtime support
Causes the /clr compiler option to be used. In Visual Studio 2019 projects, this property
has moved to the Advanced property page.
To programmatically access this property, see ManagedExtensions.
.NET Target Framework Version
In managed projects, specifies the .NET framework version to target. In Visual Studio
2019 projects, this property has moved to the Advanced property page.
Whole Program Optimization
Specifies the /GL compiler option and /LTCG linker option. By default, this property is
disabled for Debug configurations, and enabled for Release configurations. In Visual
Studio 2019 projects, this property has moved to the Advanced property page.
Windows Store App Support
Specifies whether this project supports Windows Runtime (Universal Windows Platform
or UWP) apps. For more information, see /ZW (Windows Runtime Compilation), and the
Windows Developer UWP documentation.
Windows Desktop Compatible
Enables the output of this Windows Runtime project to also support desktop apps. This
property sets the <DesktopCompatible> value in the project file. The Windows Desktop
Compatible property is available starting in Visual Studio 2019 version 16.9.
See also
C++ project property page reference
General Property Page (File)
Article • 03/03/2022
This topic applies to Windows projects. For non-Windows projects, see Linux C++
Property Page Reference.
When you right-click on a file node Solution Explorer, the General property page under
the Configuration Properties node opens. It contains the following properties:
Excluded From Build
Specifies whether the file should be in the build for the current configuration.
To programmatically access this property, see ExcludedFromBuild.
Content (Applies to UWP apps only.) Specifies whether the file contains content to
be included in the app package.
Item Type
The Item Type specifies the tool that will be used to process the file during the
build process. Files whose extension is known to Visual Studio have a default value
in this property. You can specify a custom tool here if you have a custom file type
or wish to override the default tool for a known file type. For more information, see
Specifying Custom Build Tools. You can also use this property page to specify that
a file is not part of the build process.
The following illustration shows the property page for a .cpp file. The default Item
Type for this kind of file is the C/C++ Compiler (cl.exe) and the property page
exposes various compiler settings that can be applied to this file only.
The following table lists the default Item Types:
File extension Item Type Default Tool File extension Item Type Default Tool
.appx XAML Application
Definition
App packager
.hlsl, .cso HLSL Compiler fxc.exe
.h C/C++ Header C/C++ Preprocessor
n/a Does not
participate in
build
n/a
.xml, .xslt, .xsl Xml XML Editor
.resw, .resjson PRI Resource
(UWP Apps)
MakePri.exe
Media (UWP) App packager
.xsd XML Data
Generator Tool
XML Schema Definition Tool (Xsd.exe) (Requires .NET
workload. Not included with MSVC.)
Manifest Tool mt.exe
.rc Resource Windows Resource Compiler (rc.exe)
.appxmanifest App Package
Manifest
App packager
.obj Object C/C++ Linker (link.exe)
.ttf Font n/a
.txt Text n/a
n/a Custom Build Tool User-defined
n/a Copy file n/a
.packagelayout App Package
Layout
App packager
.resx Compiler
Managed
Resource
Resgen.exe (Resource File Generator)
.natvis C++ Debugger
visualization file
Natvis framework
.jpg, .bmp, .ico,
etc.
Image Resource compiler based on application type.
File extension Item Type Default Tool
.cpp C/C++ Compiler cl.exe
To programmatically access this property, see Tool.
For information on how to access the General property page under the Configuration
Properties node, see Set C++ compiler and build properties in Visual Studio.
C++ project property page reference
See also
Advanced Property Page
Article • 07/26/2023
The Advanced property page is available in Visual Studio 2019 and later. The specific
properties shown depend on the project type. Windows Runtime (Universal Windows
Platform, or UWP) projects don't show this page.
Advanced Properties
Target File Extension
Specifies the file extension to use for the build output. Defaults to .exe for applications,
.lib for static libraries and .dll for DLLs.
Extensions to Delete on Clean
The Build > Clean menu command deletes files from the intermediate directory where a
project's configuration is built. The build system deletes files that have the specified
extensions when you run the Clean command or when you rebuild. The build system
also deletes any known output of the build no matter where it's located. Deleted files
include any intermediate outputs such as .obj files. Use semicolons ( ; ) to separate
extensions. You can specify wildcard characters ( * , ? ) in the extensions.
To programmatically access this property, see DeleteExtensionsOnClean.
Build Log File
Allows you to specify a non-default location for the log file that's created whenever you
build a project. The default location is specified by the macros
$(IntDir)$(MSBuildProjectName).log .
You can use project macros to change the directory location. For more information, see
Common macros for build commands and properties.
Preferred Build Tool Architecture
Specifies whether to use the x86 or x64 build tools.
Use Debug Libraries
Specifies whether to create a Debug or Release build. Despite the name, Use Debug
Libraries is a build system-specific property that is effectively shorthand for "Make a
Debug build" or "Make a Release build". It sets several compiler and linker properties for
Debug or Release builds, including the library settings. You can use it to create Debug or
Release configurations for a new platform or in a new template. We don't recommend
you change this property in an existing configuration. Use the individual compiler and
linker properties instead.
Enable Unity (JUMBO) build
Enables a faster build process that combines many C++ source files into one or more
files before compilation. These combined files are known as unity files. They're unrelated
to the Unity game engine.
Copy Content to OutDir
Copy the items marked as content in the project to the project's output directory
( $(OutDir) ). This setting can simplify deployment. This property is available starting in
Visual Studio 2019 version 16.7.
Copy Project References to OutDir
Copy the executable (DLL and EXE file) project reference items to the project's output
directory ( $(OutDir) ). In C++/CLI (/clr) projects, this property is ignored. Instead, the
Copy Local property on each project reference controls whether it's copied to the
output directory. This setting can simplify local deployment. It's available starting in
Visual Studio 2019 version 16.7.
Copy Project References' Symbols to OutDir
Copy the PDB files for project reference items along with the project reference
executable items to the project's output directory ( $(OutDir) ). This property is always
enabled for C++/CLI projects. This setting can simplify debug deployment. It's available
starting in Visual Studio 2019 version 16.7.
Copy C++ Runtime to OutDir
Copy the runtime DLLs to the project's output directory ( $(OutDir) ). This setting can
simplify local deployment. It's available starting in Visual Studio 2019 version 16.7.
Use of MFC
Specifies whether the MFC project statically or dynamically links to the MFC DLL. Non￾MFC projects select Use Standard Windows Libraries.
To programmatically access this property, see useOfMfc.
Character Set
Specifies whether the _UNICODE or _MBCS preprocessor macro should be set. Also affects
the linker entry point, where appropriate.
To programmatically access this property, see CharacterSet.
Whole Program Optimization
Specifies the /GL compiler option and /LTCG linker option. By default, this property is
disabled for Debug configurations, and enabled for Release configurations.
MSVC Toolset Version
Specifies the full version of the MSVC toolset that's used to build the project. You may
have various update and preview versions of a toolset installed. You can specify which
one to use here.
LLVM Toolset Version
Specifies the full version of the LLVM toolset that's used to build the project. This
property is available when LLVM (clang-cl) is selected as the platform toolset, starting in
Visual Studio 2019 version 16.9. For more information, see Set a custom LLVM toolset
version.
C++/CLI Properties
Common Language Runtime support
Causes the /clr compiler option to be used.
To programmatically access this property, see ManagedExtensions.
.NET Target Framework Version
This property only applies when the Common Language Runtime support property is
set to .NET Framework Runtime Support, that is the project targets .NET Framework,
and it specifies the version of the .NET Framework.
.NET Target Framework
This property only applies when the Common Language Runtime support property is
set to .NET Runtime Support, that is the project targets .NET.
This property specifies the .NET 5+ Target Framework Moniker this project targets, for
example net6.0-windows or net7.0-windows8.0 .
Enable Managed Incremental Build
For managed projects, this option enables detection of external visibility when you
generate assemblies. If a change to a managed project isn't visible to other projects,
dependent projects aren't rebuilt. Managed incremental builds can dramatically improve
build times in solutions that include managed projects.
Enable CLR Support for Individual Files
This option sets a ManagedAssembly build property that enables building only some files
in the project as managed code. You must set Enable CLR Support for Individual Files
to Yes if some but not all of your project files are built as managed code. This property is
only available in projects that use the v143 or later toolset in Visual Studio 2022 and
later versions.
.NET Target Windows Version
This property only applies when the Common Language Runtime support property is
set to .NET Runtime Support, that is the project targets .NET.
This property specifies the minimum Windows version that the project supports. This
value is used by NuGet to determine the compatibility of projects and NuGet package
dependencies. If a project A depends on project B, project A's .NET target Windows
version must be greater or equal to project B's.
C++ Debugging Property Pages
Article • 08/03/2021
These property pages are found under Project > Properties > Configuration Properties
> Debugging. Choose the debugger type in the drop-down control. For more
information about debugging C++ code, see Tutorial: Learn to debug C++ code using
Visual Studio and Debugging Native Code.
Local Windows Debugger Property Page
Command
The debug command to execute.
Command Arguments
The command line arguments to pass to the application.
Working Directory
The application's working directory. By default, the directory containing the project file.
Attach
Specifies whether the debugger should attempt to attach to an existing process when
debugging starts.
Debugger Type
Specifies the debugger type to use. When set to Auto, the debugger type will be
selected based on contents of the exe file.
Choices
Native Only - Native Only
Managed Only - Managed Only
Mixed - Mixed
Auto - Auto
Script - Script
GPU Only (C++ AMP) - GPU Only (C++ AMP)
Environment
Specifies the environment for the program to be debugged, or variables to merge with
existing environment.
Debugging Accelerator Type
The debugging accelerator type to use for debugging the GPU code. (Available when
the GPU debugger is active.)
GPU Default Breakpoint Behavior
Sets how often the GPU debugger breaks.
Choices
Break once per warp - Break once per warp
Break for every thread (like CPU behavior) - Break for every thread (like CPU
behavior)
Merge Environment
Merge specified environment variables with existing environment.
SQL Debugging
Attach the SQL debugger.
Amp Default Accelerator
Override C++ AMP's default accelerator selection. Property does not apply when
debugging managed code.
Remote Windows Debugger Property Page
For more information about remote debugging, see Remote Debugging a Visual C++
Project in Visual Studio.
Remote Command
The debug command to execute.
Remote Command Arguments
The command line arguments to pass to the application.
Working Directory
The application's working directory. By default, the directory containing the project file.
Remote Server Name
Specifies a remote server name.
Connection
Specifies the connection type.
Choices
Remote with Windows authentication - Remote with Windows authentication.
Remote with no authentication - Remote with no authentication.
Debugger Type
Specifies the debugger type to use. When set to Auto, the debugger type will be
selected based on contents of the exe file.
Choices
Native Only - Native Only
Managed Only - Managed Only
Mixed - Mixed
Auto - Auto
Script - Script
GPU Only (C++ AMP) - GPU Only (C++ AMP)
Environment
Specifies the environment for the program to be debugged, or variables to merge with
existing environment.
Debugging Accelerator Type
The debugging accelerator type to use for debugging the GPU code. (Available when
the GPU debugger is active.)
GPU Default Breakpoint Behavior
Sets how often the GPU debugger breaks.
Choices
Break once per warp - Break once per warp
Break for every thread (like CPU behavior) - Break for every thread (like CPU
behavior)
Attach
Specifies whether the debugger should attempt to attach to an existing process when
debugging starts.
SQL Debugging
Attach the SQL debugger.
Deployment Directory
When debugging on a remote machine, if you want the contents of the project output
(except for PDB files) to be copied to the remote machine, specify the path here.
Additional Files to Deploy
When debugging on a remote machine, files and directories specified here (besides the
project output) are copied to the Deployment Directory if one was specified.
Deploy Visual C++ Debug Runtime Libraries
Specifies whether to deploy the debug runtime libraries for the active platform (Win32,
x64, or ARM).
Amp Default Accelerator
Override C++ AMP's default accelerator selection. Property does not apply when
debugging managed code.
Web Browser Debugger Property Page
HTTP URL
Specifies the URL for the project.
Debugger Type
Specifies the debugger type to use. When set to Auto, the debugger type will be
selected based on contents of the exe file.
Choices
Native Only - Native Only
Managed Only - Managed Only
Mixed - Mixed
Auto - Auto
Script - Script
Web Service Debugger Property Page
HTTP URL
Specifies the URL for the project.
Debugger Type
Specifies the debugger type to use. When set to Auto, the debugger type will be
selected based on contents of the exe file.
Choices
Native Only - Native Only
Managed Only - Managed Only
Mixed - Mixed
Auto - Auto
Script - Script
SQL Debugging
Attach the SQL debugger.
VC++ Directories Property Page
(Windows)
Article • 04/10/2023
Use this property page to tell Visual Studio which directories to use when building the
currently selected project. To set directories for multiple projects in a solution, use a
custom property sheet as described in Share or reuse Visual Studio C++ project settings.
For the Linux version of this page, see VC++ Directories (Linux C++).
To access the VC++ Directories property page:
1. If the Solution Explorer window isn't visible, choose View > Solution Explorer on
the main menu.
2. Right-click on a project node (not the top-level solution) and choose Properties to
open the Property Pages dialog box.
3. Select the Configuration Properties > VC++ Directories property page.
VC++ Directories properties apply to a project, not the top-level solution node. If you
don't see VC++ Directories under Configuration Properties, select a C++ project node
in the Solution Explorer window:
The VC++ Directories property page for cross-platform projects looks different. For
information specific to Linux C++ projects, see VC++ Directories (Linux C++).
If you're not familiar with project properties in Visual Studio, you might find it helpful to
first read Set C++ compiler and build properties in Visual Studio.
The default settings for VC++ Directories properties depend on project type. For
desktop projects, they include the C++ tools locations for a particular Platform Toolset
and the Windows SDK location. You can change the Platform Toolset and Windows SDK
version on the Configuration Properties > General page.
To view the values for any of the directories:
1. Select one of the properties in the VC++ Directories page. For example, choose
Library Directories.
2. Choose the down-arrow button at the end of the property value field.
3. In the drop-down menu, choose Edit.
You now see a dialog box like this:
Use this dialog to view the current directories. However, if you want to change or add a
directory, it's better to use Property Manager to create a property sheet or modify the
default user property sheet. For more information, see Share or reuse Visual Studio C++
project settings.
As shown earlier, many of the inherited paths are provided as macros. To examine the
current value of a macro, choose the Macros button in the lower right corner of the
dialog box. Many macros depend on the configuration type. A macro in a debug build
might evaluate to a different path than the same macro in a release build, for example.
For information about examining macros values, see Common macros for build
commands and properties.
You can search for partial or complete matches of a macro in the edit box. The following
screenshot shows all the macros that contain the string "WindowsSDK". It also shows
the current path that each macro evaluates to:
This list is populated as you type. Don't press Enter.
For more information about macros and why you should use them instead of hard￾coded paths whenever possible, see Set C++ compiler and build properties in Visual
Studio.
For information about examining the values of the macros, see Common macros for
build commands and properties. That topic also lists commonly used macros.
You can define your own macros in two ways:
Set environment variables in a developer command prompt. All environment
variables are treated as MSBuild properties/macros.
Define user macros in a .props file. For more information, see Property page
macros.
For more information, see Property inheritance in Visual Studio projects, and these blog
posts: VC++ Directories, Visual Studio 2010 C++ Project Upgrade Guide .
General
You can also specify other directories, as follows.
Executable Directories
Directories in which to search for executable files. Corresponds to the PATH environment
variable.
Include Directories
Directories in which to search for include files that are referenced in the source code.
Corresponds to the INCLUDE environment variable.
External Include Directories
Paths for include files to treat as external or system files during compilation. These files
are skipped in build up-to-date checks. These paths are also used by the External
Includes properties. For more information on how to set these options in the IDE, see
the /external compiler option.
Reference Directories
Directories in which to search for assembly and module (metadata) files that are
referenced in the source code by the #using directive. Corresponds to the LIBPATH
environment variable.
Library Directories
Directories to search for library ( .lib ) files. This search includes run-time libraries.
Corresponds to the LIB environment variable. This setting doesn't apply to .obj files; to
link to an .obj file, on the Configuration Properties > Linker > General property page,
select Additional Library Dependencies and then specify the relative path of the file. For
more information, see Linker property pages.
Library WinRT Directories
Directories to search for WinRT library files for use in Universal Windows Platform (UWP)
apps.
Source Directories
Directories in which to search for source files to use for IntelliSense.
Exclude Directories
Before each compilation, Visual Studio queries the timestamp on all files to determine
whether any have been modified since the previous compilation. If your project has
large stable libraries, you can potentially speed up build times by excluding those
directories from the timestamp check.
Public Project Content
Public Include Directories
One or more directories to automatically add to the include path in projects that
reference this project.
All Header Files are Public
Specifies whether to automatically add public directories or all project header files to the
include path in projects that reference this project.
Public C++ Module Directories
One or more directories that contain C++ module or header unit sources to make
available automatically to projects that reference this project.
All Modules are Public
Specifies whether to make all project modules and header units available automatically
to projects that reference this project.
Sharing the settings
You can share project properties with other users or across multiple computers. For
more information, see Set C++ compiler and build properties in Visual Studio.
C/C++ Property Pages
Article • 06/09/2023
The following property pages are found under Project > Properties > Configuration
Properties > C/C++:
C/C++ General Properties
Additional Include Directories
Specifies one or more directories to add to the include path. Separate directories with
semi-colons (' ; ') if there's more than one. Sets the /I (Additional include directories)
compiler option.
Additional #using Directories
Specifies one or more directories to search to resolve names passed to a #using
directive. Separate directories with semi-colons (' ; ') if there's more than one. Sets the
/AI compiler option.
Additional BMI Directories
Specifies one or more directories to search to resolve names passed to an import
directive. Separate directories with semi-colons (' ; ') if there's more than one. Sets the
/ifcSearchDir[path] compiler option.
Additional Module Dependencies
Specifies one or more modules to use to resolve names passed to an import directive.
Separate directories with semi-colons (' ; ') if there's more than one. Sets the /reference
compiler option.
Additional Header Unit Dependencies
Specifies one or more header units to use to resolve names passed to an import header
directive. Separate directories with semi-colons (' ; ') if there's more than one. Sets the
/headerUnit compiler option.
Scan Sources for Module Dependencies
When set to Yes, the compiler scans all C++ sources, not just module interface and
header unit sources, for module and header units dependencies. The build system builds
the full dependencies graph, which ensures that all imported modules and header units
are built before compiling the files that depend on them. When combined with
Translate Includes to Imports, any header file that's specified in a header-units.json file
in the same directory as the header file is compiled into a header unit.
Files that have the extension .ixx , and files that have their File properties > C/C++ >
Compile As property set to Compile as C++ Header Unit (/exportHeader), are always
scanned.
Translate Includes to Imports
When set to Yes, the compiler treats a #include directive as an import directive if
certain conditions are met: The header file is specified in a header-units.json file in the
same directory, and a compiled header unit (an .ifc file) is available for the header file.
Otherwise, the header file is treated as a normal #include . The header-units.json file is
used to build header units for each #include without symbol duplication. When
combined with Scan Sources for Module Dependencies, the compiler automatically
finds all of the header files that can be compiled into header units. This property sets the
/translateInclude compiler option.
Debug Information Format
Specifies the type of debugging information generated by the compiler. This property
requires compatible linker settings. Sets /Z7, /Zi, /ZI (Debug information format)
compiler options.
Choices
None - Produces no debugging information, so compilation may be faster.
C7 compatible - Select the type of debugging information created for your
program and whether this information is kept in object (.obj) files or in a program
database (PDB).
Program Database - Produces a program database (PDB) that contains type
information and symbolic debugging information for use with the debugger. The
symbolic debugging information includes the names and types of variables and
functions, and line numbers.
Program Database for Edit And Continue - Produces a program database, as
described previously, in a format that supports the Edit and Continue feature.
Support Just My Code Debugging
Adds supporting code for enabling Just My Code debugging in this compilation unit.
Sets /JMC.
Common Language RunTime Support
Use the .NET runtime service. This switch is incompatible with some other switches; see
the documentation on the /clr family of switches for details.
Choices
No Common Language RunTime Support - No Common Language RunTime
Support
Common Language RunTime Support - Creates metadata for your application
that can be consumed by other CLR applications. Also allows your application to
consume types and data in the metadata of other CLR components.
Pure MSIL Common Language RunTime Support - Produces an MSIL-only output
file with no native executable code, although it can contain native types compiled
to MSIL.
Safe MSIL Common Language RunTime Support - Produces an MSIL-only (no
native executable code) and verifiable output file.
Consume Windows Runtime Extension
Consume the Windows Run Time languages extensions. Sets /ZW.
Suppress Startup Banner
Suppresses the display of the sign-on banner when the compiler starts up and display of
informational messages during compiling.
Warning Level
Select how strict you want the compiler to be about code errors. Sets /W0 - /W4.
Choices
Turn Off All Warnings - Level 0 disables all warnings.
Level1 - Level 1 displays severe warnings. Level 1 is the default warning level at the
command line.
Level2 - Level 2 displays all level 1 warnings and warnings less severe than level 1.
Level3 - Level 3 displays all level 2 warnings and all other warnings recommended
for production purposes.
Level4 - Level 4 displays all level 3 warnings plus informational warnings, which in
most cases can be safely ignored.
EnableAllWarnings - Enables all warnings, including the ones disabled by default.
Treat Warnings As Errors
Treats compiler warnings as errors. For a new project, it may be best to use /WX in every
compilation. Resolve all warnings to minimize hard-to-find code defects.
Warning Version
Hide warnings introduced after a specific version of the compiler. Sets
/Wv:xx[.yy[.zzzzz]].
Diagnostics Format
Enables rich diagnostics, with column information and source context in diagnostic
messages.
Choices
Caret - Provides column information in the diagnostic message. And, outputs the
relevant line of source code with a caret that indicates the offending column.
Column Info - Additionally provides the column number within the line where the
diagnostic is issued, where applicable.
Classic - Outputs only the prior, concise diagnostic messages with the line number.
SDL checks
Additional Security Development Lifecycle (SDL) recommended checks; includes
enabling additional secure code generation features and enables extra security-relevant
warnings as errors. Sets /sdl, /sdl-.
Multi-processor Compilation
Enable multi-processor compilation. Sets the /MP compiler option.
Enable Address Sanitizer
Compiles and links the program with AddressSanitizer instrumentation. This property
currently supports x86 and x64 target builds. Sets the /fsanitize compiler option.
C/C++ Optimization Properties
Optimization
Select option for code optimization; choose Custom to use specific optimization
options. Sets /Od, /O1, /O2.
Choices
Custom - Custom optimization.
Disabled - Disable optimization.
Maximum Optimization (Favor Size) - Equivalent to /Os /Oy /Ob2 /Gs /GF /Gy
Maximum Optimization (Favor Speed) - Equivalent to /Oi /Ot /Oy /Ob2 /Gs /GF
/Gy
Optimizations (Favor Speed) - Equivalent to /Oi /Ot /Oy /Ob2
Inline Function Expansion
Select the level of inline function expansion for the build. Sets /Ob.
Choices
Default
Disabled - Disables inline expansion, which is on by default.
Only __inline - Expands only functions marked as inline , __forceinline , or
__inline . Or, in a C++ member function, defined within a class declaration.
Any Suitable - Expands functions marked as inline or __inline and any other
function that the compiler chooses. (Expansion occurs at the compiler's discretion,
often referred to as autoinlining.)
Enable Intrinsic Functions
Enables intrinsic functions. Using intrinsic functions generates faster, but possibly larger,
code. Sets /Oi.
Favor Size Or Speed
Whether to favor code size or code speed; 'Global Optimization' must be turned on. Sets
/Ot, /Os.
Choices
Favor small code - Minimizes the size of EXEs and DLLs by instructing the compiler
to favor size over speed.
Favor fast code - Maximizes the speed of EXEs and DLLs by instructing the
compiler to favor speed over size. (This value is the default.)
Neither - No size and speed optimization.
Omit Frame Pointers
Suppresses creation of frame pointers on the call stack.
Enable Fiber-Safe Optimizations
Enables memory space optimization when using fibers and thread local storage access.
Sets /GT.
Whole Program Optimization
Enables cross-module optimizations by delaying code generation to link time. Requires
the linker option Link Time Code Generation. Sets /GL.
C/C++ Preprocessor Properties
Preprocessor Definitions
Defines preprocessing symbols for your source file.
Undefine Preprocessor Definitions
Specifies one or more preprocessor undefines. Sets /U.
Undefine All Preprocessor Definitions
Undefine all previously defined preprocessor values. Sets /u.
Ignore Standard Include Paths
Prevents the compiler from searching for include files in directories specified in the
INCLUDE environment variables.
Preprocess to a File
Preprocesses C and C++ source files, and writes the preprocessed output to a file. This
option suppresses compilation, and it doesn't produce an .obj file.
Preprocess Suppress Line Numbers
Preprocess without #line directives.
Keep Comments
Suppresses comment strip from source code; requires setting at least one of the
Preprocessing options. Sets /C.
C/C++ Code Generation Properties
Enable String Pooling
The compiler creates only one read-only copy of identical strings in the program image.
It results in smaller programs, an optimization called string pooling. /O1, /O2, and /ZI
automatically set /GF option.
Enable Minimal Rebuild
Enables minimal rebuild, which determines whether to recompile C++ source files that
include changed C++ class definitions, stored in header .h files.
Enable C++ Exceptions
Specifies the model of exception handling to be used by the compiler.
Choices
Yes with SEH Exceptions - The exception-handling model that catches
asynchronous (structured) and synchronous (C++) exceptions. Sets /EHa.
Yes - The exception-handling model that catches C++ exceptions only and tells the
compiler to assume that extern C functions never throw a C++ exception. Sets
/EHsc.
Yes with Extern C functions - The exception-handling model that catches C++
exceptions only and tells the compiler to assume that extern C functions do throw
an exception. Sets /EHs.
No - No exception handling.
Smaller Type Check
Enable checking for conversion to smaller types, incompatible with any optimization
type other than debug. Sets /RTCc.
Basic Runtime Checks
Enable basic runtime error checks, incompatible with any optimization type other than
debug. Sets /RTCs, /RTCu, /RTC1.
Choices
Stack Frames - Enables stack frame run-time error checking.
Uninitialized variables - Reports when a variable is used without having been
initialized.
Both (/RTC1, equiv. to /RTCsu) - Equivalent of /RTCsu .
Default - Default runtime checks.
Runtime Library
Specify runtime library for linking. Sets /MT, /MTd, /MD, /MDd.
Choices
Multi-threaded - Causes your application to use the multithread, static version of
the run-time library.
Multi-threaded Debug - Defines _DEBUG and _MT . This option also causes the
compiler to place the library name LIBCMTD.lib into the .obj file so that the linker
will use LIBCMTD.lib to resolve external symbols.
Multi-threaded DLL - Causes your application to use the multithread- and DLL￾specific version of the run-time library. Defines _MT and _DLL and causes the
compiler to place the library name MSVCRT.lib into the .obj file.
Multi-threaded Debug DLL - Defines _DEBUG , _MT , and _DLL and causes your
application to use the debug multithread- and DLL-specific version of the run-time
library. It also causes the compiler to place the library name MSVCRTD.lib into the
.obj file.
Struct Member Alignment
Specifies 1, 2, 4, or 8-byte boundaries for struct member alignment. Sets /Zp.
Choices
1 Byte - Packs structures on one-byte boundaries. Same as /Zp .
2 Bytes - Packs structures on two-byte boundaries.
4 Bytes - Packs structures on four-byte boundaries.
8 Bytes - Packs structures on eight-byte boundaries (default).
16 Bytes - Packs structures on sixteen-byte boundaries.
Default - Default alignment settings.
Security Check
The Security Check helps detect stack-buffer over-runs, a common attempted attack
upon a program's security.
Choices
Disable Security Check - Disable Security Check. Sets /GS-.
Enable Security Check - Enable Security Check. Sets /GS.
Control Flow Guard
Guard security check helps detect attempts to dispatch to illegal block of code.
Choices
Yes - Enable Security Check with Guard Sets /guard:cf.
No
Enable Function-Level Linking
Allows the compiler to package individual functions in the form of packaged functions
(COMDATs). Required for edit and continue to work. Sets /Gy.
Enable Parallel Code Generation
Allows the compiler to generate parallel code for loops identified using #pragma
loop(hint_parallel[(n)]) when optimization is enabled.
Enable Enhanced Instruction Set
Enable use of instructions found on processors that support enhanced instruction sets.
For example, the SSE, SSE2, AVX, and AVX2 enhancements to IA-32. And, the AVX and
AVX2 enhancements to x64. Currently /arch:SSE and /arch:SSE2 are only available
when building for the x86 architecture. If no option is specified, the compiler uses
instructions found on processors that support SSE2. Use of enhanced instructions can be
disabled with /arch:IA32 . For more information, see /arch (x86), /arch (x64), /arch
(ARM64), and /arch (ARM).
Choices
Streaming SIMD Extensions - Streaming SIMD Extensions. Sets /arch:SSE
Streaming SIMD Extensions 2 - Streaming SIMD Extensions 2. Sets /arch:SSE2
Advanced Vector Extensions - Advanced Vector Extensions. Sets /arch:AVX
Advanced Vector Extensions 2 - Advanced Vector Extensions 2. Sets /arch:AVX2
No Enhanced Instructions - No Enhanced Instructions. Sets /arch:IA32
Not Set - Not Set.
Floating Point Model
Sets the floating point model. Sets /fp:precise, /fp:strict, /fp:fast.
Choices
Precise - Default. Improves the consistency of floating-point tests for equality and
inequality.
Strict - The strictest floating-point model. /fp:strict causes fp_contract to be
OFF and fenv_access to be ON. /fp:except is implied and can be disabled by
explicitly specifying /fp:except- . When used with /fp:except- , /fp:strict
enforces strict floating-point semantics but without respect for exceptional events.
Fast - Creates the fastest code in most cases.
Enable Floating Point Exceptions
Reliable floating-point exception model. Exceptions will be raised immediately after
they're triggered. Sets /fp:except.
Create Hotpatchable Image
When hotpatching is on, the compiler ensures that first instruction of each function is
two bytes, as required for hot patching. Sets /hotpatch.
Spectre Mitigation
Spectre mitigations for CVE 2017-5753. Sets /Qspectre.
Choices
Enabled - Enable Spectre mitigation feature for CVE 2017-5753
Disabled - Not Set.
C/C++ Language Properties
Disable Language Extensions
Suppresses or enables language extensions. Sets /Za.
Treat WChar_t As Built in Type
When specified, the type wchar_t becomes a native type that maps to __wchar_t in the
same way that short maps to __int16 . /Zc:wchar_t is on by default.
Force Conformance in For Loop Scope
Implements standard C++ behavior for the for statement loops with Microsoft
extensions. Sets /Za, /Ze (Disable language extensions. /Zc:forScope is on by default.
Remove unreferenced code and data
When specified, the compiler no longer generates symbol information for unreferenced
code and data.
Enforce type conversion rules
Used to identify an rvalue reference type as the result of a cast operation according to
the C++11 standard.
Enable Run-Time Type Information
Adds code for checking C++ object types at run time (runtime type information, or RTTI).
Sets /GR, /GR-.
Open MP Support
Enables OpenMP 2.0 language extensions. Sets /openmp.
C++ Language Standard
Determines the C++ language standard that the compiler enables. The default value
doesn't set a standard option, so the compiler uses its default C++14 setting. If you
select a specific value, the corresponding /std compiler option is set.md).
Choices
Default (ISO C++14 Standard)
ISO C++14 Standard (/std:c++14)
ISO C++17 Standard (/std:c++17)
ISO C++20 Standard (/std:c++20)
Preview - Features from the Latest C++ Working Draft (/std:c++latest)
C Language Standard
Determines the C language standard that the compiler enables. The default value
doesn't set a standard option, so the compiler uses its default legacy MSVC setting. If
you select a specific value, the corresponding /std compiler option is set.md).
Choices
Default (Legacy MSVC)
ISO C11 Standard (/std:c11)
ISO C17 (2018) Standard (/std:c17)
Conformance mode
Enables or suppresses conformance mode. Sets /permissive-.
Enable Experimental C++ Standard Library Modules
Experimental support for the C++ Modules TS and Standard Library modules.
Build ISO C++23 Standard Library Modules
Starting in Visual Studio 17.6, when this property is enabled and C++ Language
Standard is set to /std:c++latest , Visual C++ projects automatically find and build ISO
C++23 Standard Library modules. This enables you to import std or import std.compat
in your C++ code.
C/C++ Precompiled Headers Properties
Create/Use Precompiled Header
Enables creation or use of a precompiled header during the build. Sets /Yc, /Yu.
Choices
Create - Instructs the compiler to create a precompiled header ( .pch ) file that
represents the state of compilation at a certain point.
Use - Instructs the compiler to use an existing precompiled header ( .pch ) file in
the current compilation.
Not Using Precompiled Headers - Not using precompiled headers.
Precompiled Header File
Specifies header file name to use when creating or using a precompiled header file. Sets
/Yc, /Yu.
Precompiled Header Output File
Specifies the path or name of the generated precompiled header file. Sets /Fp.
C/C++ Output Files Properties
Expand Attributed Source
Create listing file with expanded attributes injected into source file. Sets /Fx.
Assembler Output
Specifies the contents of assembly language output file. Sets /FA, /FAc, /FAs, /FAcs.
Choices
No Listing - No listing.
Assembly-Only Listing - Assembly code; .asm
Assembly With Machine Code - Machine and assembly code; .cod
Assembly With Source Code - Source and assembly code; .asm
Assembly, Machine Code and Source - Assembly, machine code and source code;
.cod
Use Unicode For Assembler Listing
Causes the output file to be created in UTF-8 format.
ASM List Location
Specifies relative path or name for ASM listing file; can be file or directory name. Sets
/Fa.
Object File Name
Specifies a name to override the default object file name; can be file or directory name.
Sets /Fo.
Program Database File Name
Specifies a name for a compiler-generated PDB file; also specifies base name for the
required compiler-generated IDB file; can be file or directory name. Sets /Fd.
Generate XML Documentation Files
Specifies that the compiler should generate XML documentation comment files (.XDC).
Sets /doc.
XML Documentation File Name
Specifies the name of the generated XML documentation files; can be file or directory
name. Sets /doc:<name>.
C/C++ Browse Information Properties
Enable Browse Information
Specifies level of browse information in .bsc file. Sets /FR.
Browse Information File
Specifies optional name for browser information file. Sets /FR<name>.
External Includes
Treat Files Included with Angle Brackets as External
Specifies whether to treat files included with angle brackets as external. Set this property
to Yes to set the /external:anglebrackets compiler option.
External Header Warning Level
Select how strict you want the compiler to be about code errors in external headers. This
property sets the /external:Wn compiler option. If this value is set to Inherit Project
Warning Level or the default, other /external options are ignored.
Template Diagnostics in External Headers
Specifies whether to evaluate the warning level across a template instantiation chain. Set
this property to Yes to set the /external:templates- compiler option.
Disable Code Analysis for External Headers
Disables code analysis for external headers. Sets the /analyze:external- compiler option.
Analysis Ruleset for External Headers
Specifies a code analysis ruleset override for external headers. If not specified, the Code
Analysis setting is used. Sets the /analyze:external:ruleset path compiler option.
C/C++ Advanced Properties
Calling Convention
Select the default calling convention for your application (can be overridden by
function). Sets /Gd, /Gr, /Gz, /Gv.
Choices
__cdecl - Specifies the __cdecl calling convention for all functions except C++
member functions and functions marked __stdcall or __fastcall .
__fastcall - Specifies the __fastcall calling convention for all functions except
C++ member functions and functions marked __cdecl or __stdcall . All
__fastcall functions must have prototypes.
__stdcall - Specifies the __stdcall calling convention for all functions except
C++ member functions and functions marked __cdecl or __fastcall . All
__stdcall functions must have prototypes.
__vectorcall - Specifies the __vectorcall calling convention for all functions
except C++ member functions and functions marked __cdecl , __fastcall , or
__stdcall . All __vectorcall functions must have prototypes.
Compile As
Select compile language option for source files. Sets /TC, /TP, /interface,
/internalPartition, or /exportHeader options.
Choices
Default - Default.
Compile as C Code (/TC) - Compile specified source files as C code. By default,
files with a .c extension are compiled as C.
Compile as C++ Code (/TP) - Compile specified source files as C++ code. By
default, all source files that don't have a .c , .ixx , .cppm , .h , or no extension are
compiled as C++.
Compile as C++ Module Code (/interface) - Compile specified source files as C++
module code. By default, files with a .ixx or .cppm extension are compiled as C++
module code.
Compile as C++ Module Internal Partition (/internalPartition) - Compile specified
source files as C++ module internal partition.
Compile as C++ Header Unit (/exportHeader) - Compile specified source files as
C++ header unit. By default, files with a .h extension or no extension are compiled
as header units.
Disable Specific Warnings
Disable the specified warning numbers. Put the warning numbers in a semi-colon
delimited list. Sets /wd<number>.
Forced Include File
one or more forced include files. Sets /FI<name>.
Forced #using File
Specifies one or more forced #using files. Sets /FU<name>.
Show Includes
Generates a list of include files with compiler output. Sets /showIncludes.
Use Full Paths
Use full paths in diagnostic messages. Sets /FC.
Omit Default Library Name
Doesn't include default library names in .obj files. Sets /Zl.
Internal Compiler Error Reporting
７ Note
This option is deprecated. Starting in Windows Vista, error reporting is controlled
by Windows Error Reporting (WER) settings.
Treat Specific Warnings As Errors
Treats the specific compiler warning as an error where n is a compiler warning.
Additional Options
Additional Options.
Linker Property Pages
Article • 09/22/2022
The following properties are found under Project > Properties > Configuration
Properties > Linker. For more information about the linker, see CL Invokes the Linker
and Linker Options.
General Property Page
Output File
The /OUT option overrides the default name and location of the program that the linker
creates.
Show Progress
Prints Linker Progress Messages
Choices
Not Set - No verbosity.
Display all progress messages - Displays all progress messages.
For Libraries Searched - Displays progress messages indicating just the libraries
searched.
About COMDAT folding during optimized linking - Displays information about
COMDAT folding during optimized linking.
About data removed during optimized linking - Displays information about
functions and data removed during optimized linking.
About Modules incompatible with SEH - Displays information about modules
incompatible with Safe Exception Handling.
About linker activity related to managed code - Display information about linker
activity related to managed code.
Version
The /VERSION option tells the linker to put a version number in the header of the .exe
or .dll file. Use DUMPBIN /HEADERS to see the image version field of the OPTIONAL HEADER
VALUES to see the effect of /VERSION .
Enable Incremental Linking
Enables incremental linking. (/INCREMENTAL, /INCREMENTAL:NO)
Suppress Startup Banner
The /NOLOGO option prevents display of the copyright message and version number.
Ignore Import Library
This property tells the linker not to link any .lib output generated from this build into
any dependent project. It allows the project system to handle .dll files that don't
produce a .lib file when built. If a project depends on another project that produces a
DLL, the project system automatically links the .lib file produced by that child project.
This property may be unnecessary in projects that produce COM DLLs or resource-only
DLLs, because these DLLs don't have any meaningful exports. If a DLL has no exports,
the linker doesn't generate a .lib file. If no export .lib file is present, and the project
system tells the linker to link with the missing DLL, the link fails. Use the Ignore Import
Library property to resolve this problem. When set to Yes, the project system ignores
the presence or absence of the .lib file, and causes any project that depends on this
project to not link with the nonexistent .lib file.
To programmatically access this property, see IgnoreImportLibrary.
Register Output
Runs regsvr32.exe /s $(TargetPath) on the build output, which is valid only on .dll
projects. For .exe projects, this property is ignored. To register an .exe output, set a
postbuild event on the configuration to do the custom registration that is always
required for registered .exe files.
To programmatically access this property, see RegisterOutput.
Per-user Redirection
Registration in Visual Studio has traditionally been done in HKEY_CLASSES_ROOT (HKCR).
With Windows Vista and later operating systems, to access HKCR you must run Visual
Studio in elevated mode. Developers don't always want to run in elevated mode but still
must work with registration. Per-user redirection allows you to register without having
to run in elevated mode.
Per-user redirection forces any writes to HKCR to be redirected to HKEY_CURRENT_USER
(HKCU). If per-user redirection is turned off, it can cause Project Build Error PRJ0050
when the program tries to write to HKCR.
Additional Library Directories
Allows the user to override the environment's library path. (/LIBPATH:folder)
Link Library Dependencies
Specifies whether to link the .lib files that are produced by dependent projects.
Typically, you want to link in the .lib files, but it may not be the case for certain DLLs.
You can also specify a .obj file by providing the file name and relative path, for
example, ..\..\MyLibProject\MyObjFile.obj . If the source code for the .obj file has a
#include for a precompiled header, for example, pch.h , then the pch.obj file is located
in the same folder as MyObjFile.obj . You must also add pch.obj as an additional
dependency.
Use Library Dependency Inputs
Specifies whether to use the inputs to the librarian tool, rather than the library file itself,
when linking in library outputs of project dependencies. In a large project, when a
dependent project produces a .lib file, incremental linking is disabled. If there are
many dependent projects that produce .lib files, building the application can take a
long time. When this property is set to Yes, the project system links in the .obj files for
.lib files produced by dependent projects, enabling incremental linking.
For information about how to access the General linker property page, see Set compiler
and build properties.
Link Status
Specifies whether the linker should display a progress indicator showing what
percentage of the link is complete. The default is to not display this status information.
(/LTCG:STATUS|LTCG:NOSTATUS)
Prevent DLL Binding
/ALLOWBIND:NO sets a bit in a DLL's header that indicates to Bind.exe that binding the
image isn't allowed. You may not want a DLL to be bound if it has been digitally signed
(binding invalidates the signature).
Treat Linker Warning As Errors
/WX causes no output file to be generated if the linker generates a warning.
Force File Output
The /FORCE option tells the linker to create an .exe file or DLL even if a symbol is
referenced but not defined ( UNRESOLVED ), or is defined multiple times ( MULTIPLE ). It may
create an invalid .exe file.
Choices
Enabled - /FORCE with no arguments implies both /FORCE:MULTIPLE and
/FORCE:UNRESOLVED .
Multiply Defined Symbol Only - Use /FORCE:MULTIPLE to create an output file,
even if LINK finds more than one definition for a symbol.
Undefined Symbol Only - Use /FORCE:UNRESOLVED to create an output file whether
or not LINK finds an undefined symbol. /FORCE:UNRESOLVED is ignored if the entry
point symbol is unresolved.
Create Hot Patchable Image
Prepares an image for hot patching.
Choices
Enabled - Prepares an image for hot patching.
X86 Image Only - Prepares an X86 image for hot patching.
X64 Image Only - Prepares an X64 image for hot patching.
Itanium Image Only - Prepares an Itanium image for hot patching.
Specify Section Attributes
The /SECTION option changes the attributes of a section, overriding the attributes set
when the .obj file for the section was compiled.
Input Property Page
Additional Dependencies
Specifies extra dependency items to add to the link command line, for example
kernel32.lib .
Ignore All Default Libraries
The /NODEFAULTLIB option tells the linker to remove one or more default libraries from
the list of libraries it searches when resolving external references.
Ignore Specific Default Libraries
Specifies one or more names of default libraries to ignore. Separate multiple libraries
with semi-colons. (/NODEFAULTLIB:[name, name, ...])
Module Definition File
The /DEF option passes a module-definition file ( .def ) to the linker. Only one .def file
can be specified to LINK.
Add Module to Assembly
The /ASSEMBLYMODULE option allows you to add a module reference to an assembly.
Type information in the module won't be available to the assembly program that added
the module reference. However, type information in the module will be available to any
program that references the assembly.
Embed Managed Resource File
/ASSEMBLYRESOURCE embeds a resource file in the output file.
Force Symbol References
The /INCLUDE option tells the linker to add a specified symbol to the symbol table.
Delay Loaded DLLs
The /DELAYLOAD option causes delayed loading of DLLs. The dll name specifies a DLL to
delay load.
Assembly Link Resource
The /ASSEMBLYLINKRESOURCE option creates a link to a .NET Framework resource in
the output file. The linker doesn't place the resource file in the output file.
Manifest File Property Page
Generate Manifest
/MANIFEST specifies that the linker should create a side-by-side manifest file.
Manifest File
/MANIFESTFILE lets you change the default name of the manifest file. The default name
of the manifest file is the file name with .manifest appended.
Additional Manifest Dependencies
/MANIFESTDEPENDENCY lets you specify attributes that will be placed in the
dependency section of the manifest file.
Allow Isolation
Specifies behavior for manifest lookup. (/ALLOWISOLATION:NO)
Enable User Account Control (UAC)
Specifies whether or not User Account Control is enabled. (/MANIFESTUAC,
/MANIFESTUAC:NO)
UAC Execution Level
Specifies the requested execution level for the application when running with User
Account Control. (/MANIFESTUAC:level=[value])
Choices
asInvoker - UAC Execution Level: as invoker.
highestAvailable - UAC Execution Level: highest available.
requireAdministrator - UAC Execution Level: require administrator.
UAC Bypass UI Protection
Specifies whether or not to bypass user interface protection levels for other windows on
the desktop. Set this property to 'Yes' only for accessibility applications.
(/MANIFESTUAC:uiAccess=[true | false])
Debugging Property Page
Generate Debug Info
This option enables creation of debugging information for the .exe file or the DLL.
Choices
No - Produces no debugging information.
Generate Debug Information - Create a complete Program Database (PDB) ideal
for distribution to Microsoft Symbol Server.
Generate Debug Information optimized for faster links - Produces a program
database (PDB) ideal for a fast edit-link-debug cycle.
Generate Debug Information optimized for sharing and publishing - Produces a
program database (PDB) ideal for a shared edit-link-debug cycle.
Generate Program Database File
By default, when /DEBUG is specified, the linker creates a program database (PDB) which
holds debugging information. The default file name for the PDB has the base name of
the program and the extension .pdb .
Strip Private Symbols
The /PDBSTRIPPED option creates a second program database (PDB) file when you build
your program image with any of the compiler or linker options that generate a PDB file
( /DEBUG , /Z7 , /Zd , or /Zi ).
Generate Map File
The /MAP option tells the linker to create a mapfile.
Map File Name
A user-specified name for the mapfile. It replaces the default name.
Map Exports
The /MAPINFO option tells the linker to include the specified information in a mapfile,
which is created if you specify the /MAP option. EXPORTS tells the linker to include
exported functions.
Debuggable Assembly
/ASSEMBLYDEBUG emits the DebuggableAttribute attribute with debug information
tracking and disables JIT optimizations.
System Property Page
SubSystem
The /SUBSYSTEM option tells the operating system how to run the .exe file. The choice
of subsystem affects the entry point symbol (or entry point function) that the linker will
choose.
Choices
Not Set - No subsystem set.
Console - Win32 character-mode application. Console applications are given a
console by the operating system. If main or wmain is defined, CONSOLE is the
default.
Windows - Application doesn't require a console, probably because it creates its
own windows for interaction with the user. If WinMain or wWinMain is defined,
WINDOWS is the default.
Native - Device drivers for Windows NT. If /DRIVER:WDM is specified, NATIVE is the
default.
EFI Application - EFI Application.
EFI Boot Service Driver - EFI Boot Service Driver.
EFI ROM - EFI ROM.
EFI Runtime - EFI Runtime.
POSIX - Application that runs with the POSIX subsystem in Windows NT.
Minimum Required Version
Specify the minimum required version of the subsystem. The arguments are decimal
numbers in the range 0 through 65535.
Heap Reserve Size
Specifies total heap allocation size in virtual memory. Default is 1 MB. (/HEAP:reserve)
Heap Commit Size
Specifies total heap allocation size in physical memory. Default is 4 KB.
( [/HEAP:reserve,commit ](heap-set-heap-size.md))
Stack Reserve Size
Specifies the total stack allocation size in virtual memory. Default is 1 MB.
(/STACK:reserve)
Stack Commit Size
Specifies the total stack allocation size in physical memory. Default is 4 KB.
(/STACK:reserve,commit)
Enable Large Addresses
The /LARGEADDRESSAWARE option tells the linker that the application can handle
addresses larger than 2 gigabytes. By default, /LARGEADDRESSAWARE:NO is enabled if
/LARGEADDRESSAWARE isn't otherwise specified on the linker line.
Terminal Server
The /TSAWARE option sets a flag in the IMAGE_OPTIONAL_HEADER DllCharacteristics field
in the program image's optional header. When this flag is set, Terminal Server won't
make certain changes to the application.
Swap Run From CD
The /SWAPRUN option tells the operating system to first copy the linker output to a
swap file, and then run the image from there. This option is a Windows NT 4.0 (and
later) feature. When CD is specified, the operating system will copy the image on a
removable disk to a page file, and then load it.
Swap Run From Network
The /SWAPRUN option tells the operating system to first copy the linker output to a
swap file, and then run the image from there. This option is a Windows NT 4.0 (and
later) feature. If NET is specified, the operating system will first copy the binary image
from the network to a swap file and load it from there. This option is useful for running
applications over the network.
Driver
Use the /DRIVER linker option to build a Windows NT kernel mode driver.
Choices
Not Set - Default driver setting.
Driver - Driver
UP Only - /DRIVER:UPONLY causes the linker to add the IMAGE_FILE_UP_SYSTEM_ONLY
bit to the characteristics in the output header to specify that it's a uniprocessor
(UP) driver. The operating system will refuse to load a UP driver on a
multiprocessor (MP) system.
WDM - /DRIVER:WDM causes the linker to set the
IMAGE_DLLCHARACTERISTICS_WDM_DRIVER bit in the optional header's
DllCharacteristics field.
Optimization Property Page
References
/OPT:REF eliminates functions and/or data that's never referenced while /OPT:NOREF
keeps functions and/or data that's never referenced.
Enable COMDAT Folding
Use /OPT:ICF[=iterations] to perform identical COMDAT folding.
Function Order
The /ORDER option tells LINK to optimize your program by placing certain COMDATs
into the image in a predetermined order. LINK places the functions in the specified
order within each section in the image.
Profile Guided Database
Specify the .pgd file for profile guided optimizations. (/PGD)
Link Time Code Generation
Specifies link-time code generation. (/LTCG)
Choices
Default - Default LTCG setting.
Use Fast Link Time Code Generation - Use Link Time Code Generation with
/FASTGENPROFILE.
Use Link Time Code Generation - Use Link Time Code Generation.
Profile Guided Optimization - Instrument - Use profile guided optimization with
:PGINSTRUMENT .
Profile Guided Optimization - Optimization - Specifies that the linker should use
the profile data created after running the instrumented binary to create an
optimized image.
Profile Guided Optimization - Update - Allows and tracks list of input files to be
added or modified from what was specified in the :PGINSTRUMENT phase.
Embedded IDL Property Page
MIDL Commands
Specify MIDL command line options. (/MIDL:@responsefile)
Ignore Embedded IDL
The /IGNOREIDL option specifies that any IDL attributes in source code shouldn't be
processed into an .idl file.
Merged IDL Base File Name
The /IDLOUT option specifies the name and extension of the .idl file.
Type Library
The /TLBOUT option specifies the name and extension of the .tlb file.
TypeLib Resource ID
Allows you to specify the resource ID of the linker-generated type library. (/TLBID:id)
Windows Metadata Property Page
Generate Windows Metadata
Enables or disables generation of Windows Metadata.
Choices
Yes - Enable generation of Windows Metadata files.
No - Disable the generation of Windows Metadata files.
Windows Metadata File
The /WINMDFILE option switch.
Windows Metadata Key File
Specify a key or key pair to sign the Windows Metadata. (/WINMDKEYFILE:filename)
Windows Metadata Key Container
Specify a key container to sign the Windows Metadata. (/WINMDKEYCONTAINER:name)
Windows Metadata Delay Sign
Partially sign the Windows Metadata. Use /WINMDDELAYSIGN if you only want to place
the public key in the Windows Metadata. The default is /WINMDDELAYSIGN:NO .
Advanced Property Page
Entry Point
The [/ENTRY ](entry-entry-point-symbol.md) option specifies an entry point function as
the starting address for an .exe file or DLL.
No Entry Point
The /NOENTRY option is required for creating a resource-only DLL. Use this option to
prevent LINK from linking a reference to _main into the DLL.
Set Checksum
The /RELEASE option sets the Checksum in the header of an .exe file.
Base Address
Sets a base address for the program. (/BASE:{address[,size] | @filename,key})
Randomized Base Address
Randomized Base Address. (/DYNAMICBASE[:NO])
Fixed Base Address
Creates a program that can be loaded only at its preferred base address. (/FIXED[:NO])
Data Execution Prevention (DEP)
Marks an executable as having been tested to be compatible with Windows Data
Execution Prevention feature. (/NXCOMPAT[:NO])
Turn Off Assembly Generation
The /NOASSEMBLY option tells the linker to create an image for the current output file
without a .NET Framework assembly.
Unload delay loaded DLL
The UNLOAD qualifier tells the delay-load helper function to support explicit unloading of
the DLL. (/DELAY:UNLOAD)
Nobind delay loaded DLL
The NOBIND qualifier tells the linker not to include a bindable Import Address Table (IAT)
in the final image. The default is to create the bindable IAT for delay-loaded DLLs.
(/DELAY:NOBIND)
Import Library
Overrides the default import library name. (/IMPLIB:filename)
Merge Sections
The /MERGE option combines the first section with the second section, and gives the
resulting section the second section name. For example, /merge:.rdata=.text merges
the .rdata section with the .text section, and names the combined section .text .
Target Machine
The /MACHINE option specifies the target platform for the program.
Choices
Not Set
MachineARM
MachineARM64
MachineEBC
MachineIA64
MachineMIPS
MachineMIPS16
MachineMIPSFPU
MachineMIPSFPU16
MachineSH4
MachineTHUMB
MachineX64
MachineX86
Profile
Produces an output file that can be used with the Performance Tools profiler. Requires
the Generate Debug Info property be set to GenerateDebugInformation (/DEBUG).
(/PROFILE)
CLR Thread Attribute
Explicitly specify the threading attribute for the entry point of your CLR program.
Choices
MTA threading attribute - Applies the MTAThreadAttribute attribute to the entry
point of your program.
STA threading attribute - Applies the STAThreadAttribute attribute to the entry
point of your program.
Default threading attribute - Same as not specifying /CLRTHREADATTRIBUTE. Lets
the Common Language Runtime (CLR) set the default threading attribute.
CLR Image Type
Sets the type (IJW, pure, or safe) of a CLR image.
Choices
Force IJW image
Force Pure IL Image
Force Safe IL Image
Default image type
Key File
Specify key or key pair to sign an assembly. (/KEYFILE:filename)
Key Container
Specify a key container to sign an assembly. (/KEYCONTAINER:name)
Delay Sign
Partially sign an assembly. Use /DELAYSIGN if you only want to place the public key in
the assembly. The default is /DELAYSIGN:NO .
CLR Unmanaged Code Check
/CLRUNMANAGEDCODECHECK specifies whether the linker will apply
SuppressUnmanagedCodeSecurityAttribute to linker-generated P/Invoke calls from
managed code into native DLLs.
Error Reporting
Allows you to provide internal compiler error (ICE) information directly to the Visual
Studio C++ team.
Choices
PromptImmediately - Prompt immediately.
Queue For Next Login - Queue for next sign-in.
Send Error Report - Send error report.
No Error Report - No error report.
SectionAlignment
The /ALIGN option specifies the alignment of each section within the linear address
space of the program. The number argument is in bytes and must be a power of two.
Preserve Last Error Code for PInvoke Calls
/CLRSUPPORTLASTERROR, which is on by default, preserves the last error code of
functions called through the P/Invoke mechanism, which allows you to call native
functions in DLLS, from code compiled with /clr .
Choices
Enabled - Enable /CLRSupportLastError .
Disabled - Disable /CLRSupportLastError .
System DLLs Only - Enable /CLRSupportLastError for system DLLs only.
Image Has Safe Exception Handlers
When /SAFESEH is specified, the linker will only produce an image if it can also produce
a table of the image's safe exception handlers. This table specifies for the operating
system which exception handlers are valid for the image.
Command line property pages
Article • 09/22/2022
Most property page folders that correspond with a command-line tool contain a
Command Line property page. For information on how to access the Command Line
property pages, see Set compiler and build properties.
Command Line property page
All Options
The All Options display-only control shows the tool command line created by the
properties set in the folder.
Additional Options
This property's edit control lets you specify other command-line options that are valid
for the tool but that don't have a corresponding property.
The options that you enter in the edit box are passed through to the tool for the folder
after the options listed in All Options. No verification or validity checks are done on the
options you enter, and there's no dependency checking.
See also
Windows C++ project property page reference
Linux C++ property page reference
Linker property pages
Manifest tool property pages
MIDL property pages
NMake property page
XML document generator tool property pages
NMake Property Page
Article • 02/07/2023
The NMake property page lets you specify build settings for Makefile projects. (NMAKE
is the Microsoft implementation of Make .)
For more information about Makefile projects, see Creating a Makefile Project. For non￾Windows Makefile projects, see Makefile Project Properties (Linux C++), General Project
Properties (Android C++ Makefile) or NMake Properties (Android C++).
The property page contains the following properties:
General
Build Command Line
Specifies the command to be run when Build is clicked on the Build menu.
Rebuild All Command Line
Specifies the command to be run when Rebuild All is clicked on the Build menu.
Clean Command Line
Specifies the command to be run when Clean is clicked on the Build menu.
Output
Specifies the name of the file that will contain the output for the command line. By
default, this file name is based on the project name.
IntelliSense
Preprocessor Definitions
Specifies any preprocessor definitions that the source files use. The default value is
determined by the current platform and configuration.
Include Search Path
Specifies the directories where the compiler searches for include files.
Forced Includes
Specifies files that the preprocessor automatically processes even if they aren't
included in the project files.
Assembly Search Path
Specifies the directories where the .NET Framework searches when it resolves .NET
assemblies.
Forced Using Assemblies
Specifies assemblies that the .NET Framework automatically processes.
Additional Options
Specifies any extra compiler switches for IntelliSense to use when it parses C++
files.
For information about how to access this property page, see Set C++ compiler and build
properties in Visual Studio.
For information about how to programmatically access members of this object, see
VCNMakeTool.
See also
C++ project property page reference
Manifest Tool Property Pages
Article • 09/22/2022
Use these pages to specify general options for Mt.exe. These pages are found under
Project > Properties > Configuration Properties > Manifest Tool.
General Property Page
Suppress Startup Banner
Yes ( /nologo ) specifies that standard Microsoft copyright data will be concealed when
the manifest tool is started. Use this option to suppress unwanted output in log files
when you run mt.exe , either as part of a build process or from a build environment.
Verbose Output
Yes ( /verbose ) specifies that more build information will be displayed during manifest
generation.
Assembly Identity
Uses the /identity option to specify an identity string, which holds the attributes for
the <assemblyIdentity> element. An identity string begins with the value for the name
attribute, and is followed by attribute = value pairs. The attributes in an identity string
are delimited by a comma.
Here's an example identity string:
Microsoft.Windows.Common-Controls, processorArchitecture=x86, version=6.0.0.0,
type=win32, publicKeyToken=6595b64144ccf1df
Input and Output Property Page
Additional Manifest Files
Uses the /manifest option to specify the full paths of more manifest files that the
manifest tool will process or merge. Full paths are delimited by a semicolon. ( /manifest
[manifest1] [manifest2] ... )
Input Resource Manifests
Uses the /inputresource option to specify the full path of a resource of type
RT_MANIFEST , to input into the manifest tool. The path can be followed by the specified
resource ID. For example:
dll_with_manifest.dll;#1
Embed Manifest
Yes specifies that the project system will embed the application manifest file into
the assembly.
No specifies that the project system will create the application manifest file as a
stand-alone file.
Output Manifest File
Specifies the name of the output manifest file. This property is optional when only one
manifest file is operated upon by the manifest tool. ( /out:[file];#[resource ID] )
Manifest Resource File
Specifies the output resources file used to embed the manifest into the project output.
Generate Catalog Files
Uses the /makecdfs option to specify that the manifest tool will generate catalog
definition files ( .cdf files), which are used to make catalogs. ( /makecdfs )
Generate Manifest From ManagedAssembly
Generates a manifest from a managed assembly. ( /managedassemblyname:[file] )
Suppress Dependency Element
Used with /managedassemblyname . Suppresses the generation of dependency elements in
the final manifest. ( /nodependency )
Generate Category Tags
Used with /managedassemblyname . /category causes the category tags to be generated.
( /category )
DPI Awareness
Specifies whether the application is DPI-aware. By default, the setting is Yes for MFC
projects and No otherwise because only MFC projects have built in DPI awareness. You
can override the setting to Yes if you add code to handle different DPI settings. Your
application might appear fuzzy or small if it isn't DPI-aware, but you set a DPI-aware
option.
Choices
None
High DPI Aware
Per Monitor High DPI Aware
Isolated COM Property Page
For more information about isolated COM, see Isolated applications and How to: Build
isolated applications to consume COM components.
Type Library File
Specifies the type library to use for regfree COM manifest support. ( /tlb:[file] )
Registrar Script File
Specifies the registrar script file to use for regfree COM manifest support. ( /rgs:[file] )
Component File Name
Specifies the file name of the component that is built from the .tlb or .rgs specified.
( /dll:[file] )
Replacements File
Specifies the file that contains values for replaceable strings in the RGS file.
( /replacements:[file] )
Advanced Property Page
Update File Hashes
Computes the hash of files specified in the file elements, and then updates the hash
attribute with this value. ( /hashupdate:[path] )
Update File Hashes Search Path
Specifies the search path to use when updating the file hashes.
Additional Options
Allows you to specify more options.
See also
C++ project property page reference
Resources property page
Article • 09/22/2022
For native Windows desktop programs, the build invokes the Resource Compiler (rc.exe)
to add images, string tables, and .res files to the binary. The properties exposed in this
property page are passed to the Resource Compiler, not to the C++ compiler or the
linker. For more information on the properties listed here and how they map to RC
command-line options, see Using RC (The RC Command Line). For information on how
to access the Resources property pages, see Set C++ compiler and build properties in
Visual Studio. To programmatically access these properties, see
VCResourceCompilerTool.
Properties for .NET resources in C++/CLI applications are exposed in the Managed
Resources Property Page.
Preprocessor Definitions
Specifies one or more defines for the resource compiler. (/d[macro])
Undefine Preprocessor Definitions
Undefine a symbol. (/u)
Culture
Lists the culture (such as US English or Italian) used in the resources. (/l [num])
Additional Include Directories
Specifies one or more directories to add to the include path; use semi-colon delimiter if
more than one. (/I[path])
Ignore Standard Include Paths
Prevents the resource compiler from searching for include files in directories specified in
the INCLUDE environment variables. (/X)
Show Progress
Send progress messages to output window. (/v)
Suppress Startup Banner
Suppress the display of the startup banner and information message (/nologo)
Resource File Name
Specifies the name of the resource file (/fo[file])
Null Terminate Strings
Append null's to all strings in the string tables. (/n)
See also
C++ project property page reference
Managed Resources Property Page
Article • 08/03/2021
The Managed Resources property page exposes the following properties for the
managed resource compiler resgen.exe when using .NET resources in C++/CLI
programs:
Resource Logical Name
Specifies the logical name of the generated intermediate .resources file. The logical
name is the name used to load the resource. If no logical name is specified, the
resource (.resx) file name is used as the logical name.
Output File Name
Specifies the name of the final output file that the resource (.resx) file contributes
to.
Default Localized Resources
Specifies whether the given .resx file contributes to the default resources or to a
satellite .dll.
For information on how to access the Managed Resources property page, see Set C++
compiler and build properties in Visual Studio.
See also
Using RC (The RC Command Line)
C++ project property page reference
/ASSEMBLYRESOURCE (Embed a Managed Resource)
MIDL Property Pages
Article • 09/22/2022
The MIDL property pages are available as an item property on an .IDL file in a C++
project that uses COM. Use them to configure the MIDL Compiler. For information on
how to programmatically access MIDL options for C++ projects, see VCMidlTool object.
See also General MIDL Command-line Syntax.
General Property Page
Preprocessor Definitions
Specifies one or more defines, including MIDL macros (/D)[macros]).
Additional Include Directories
Specifies one or more directories to add to the include path (/I[path]).
Additional Metadata Directories
Specify the directory containing the Windows.Foundation.WinMD file (/metadata_dir
[path]).
Enable Windows Runtime
Enable Windows Runtime semantics to create Windows metadata file (/winrt).
Ignore Standard Include Path
Ignore the current and the INCLUDE directories (/no_def_idir).
MkTypLib Compatible
Forces compatibility with mktyplib.exe version 2.03 (/mktyplib203).
Warning Level
Selects the strictness of the MIDL code errors (/W).
Choices
1
1
2
3
4
Treat Warnings as Errors
Enables MIDL to treat all warnings as errors (/WX).
Suppress Startup Banner
Suppress the display of the startup banner and information message (/nologo).
C Compiler Char Type
Specifies the default character type of the C compiler that will be used to compile the
generated code. (/char signed|unsigned|ascii7).
Choices
Signed - Signed
Unsigned - Unsigned
Ascii - Ascii
Target Environment
Specifies which environment to target (/env arm32|win32|ia64|x64).
Choices
Not Set - Win32
Microsoft Windows 32-bit - Win32
Microsoft Windows 64-bit on Itanium - IA64
Microsoft Windows ARM - ARM
Microsoft Windows ARM64 - ARM64
Microsoft Windows 64-bit on x64 - X64
Generate Stubless Proxies
Generate fully interpreted stubs with extensions and stubless proxies for object
interfaces (/Oicf, /Oif ).
Suppress Compiler Warnings
Suppress compiler warning messages (/no_warn).
Application Configuration Mode
Allow selected ACF attributes in the IDL file (/app_config).
Locale ID
Specifies the LCID for input files, file names and directory paths (/lcid DECIMAL).
Multi-Processor Compilation
Run multiple instances at the same time.
Output Property Page
Output Directory
Specifies the output directory (/out [directory]).
Metadata File
Specifies the name of the generated metadata file (/winmd filename).
Header File
Specifies the name of the generated header file (/h filename).
DllData File
Specifies the name of the DLLDATA file (/dlldata filename).
IID File
Specifies the name for the Interface Identifier file (/iid filename).
Proxy File
Specifies the name of the proxy file (/proxy filename).
Generate Type Library
Specify not to generate a type library ([/notlb] for no).
Type Library
Specifies the name of the type library file (/tlb filename).
Generate Client Stub Files
Generate client stub file only (/client [stub|none]).
Choices
Stub - Stub
None - None
Generate Server Stub Files
Generate server stub file only (/server [stub|none]).
Choices
Stub - Stub
None - None
Client Stub File
Specify the client stub file (/cstub [file]).
Server Stub File
Specify the server stub file (/sstub [file]).
Type Library Format
Specifies the type library file format ([/oldtlb|/newtlb]).
Choices
NewFormat - New Format
OldFormat - Old Format
Advanced Property Page
C Preprocess Options
Specifies switches to pass to C compiler preprocessor (/cpp_opt switches).
Undefine Preprocessor Definitions
Specifies one or more undefines, including MIDL macros (/U [macros]).
Enable Error Checking
Select error checking option ([/error all|none]).
Choices
EnableCustom - All
All - All
None - None
Check Allocations
Check for out of memory errors (/error allocation).
Check Bounds
Check size vs transmission length specification (/error bounds_check).
Check Enum Range
Check enum values to be in allowable range (/error enum).
Check Reference Pointers
Check ref pointers to be non-null (/error ref).
Check Stub Data
Emit additional check for server side stub data validity (/error stub_data).
Prepend with 'ABI' namespace
Prepend the 'ABI' namespace to all types. (/ns_prefix).
Validate Parameters
Generate additional information to validate parameters (/robust | /no_robust).
Struct Member Alignment
Specifies the packing level of structures in the target system (/ZpN).
Choices
Not Set - Not Set
1 Byte - Zp1
2 Byte - Zp2
4 Byte - Zp4
8 Byte - Zp8
Redirect Output
Redirects output from screen to a file (/o file).
Minimum Target System
Set the minimum target system (/target STRING).
Web References Property Page
Article • 08/03/2021
The Web References property page specifies how the XML Web service proxy class will
be generated. An XML Web service proxy class will be generated if you add a web
reference to your project.
The Web References property page contains the following properties:
Output file
The name of the file to contain the XML Web service proxy class.
Suppress Startup Banner
Do not display the banner for the Web Services Description Language Tool
(Wsdl.exe).
Namespace
Specifies the name of the generated web proxy.
Additional References
Specifies the additional DLLs referenced by the proxy DLL.
For information on how to access the Web Reference property page, see Set C++
compiler and build properties in Visual Studio.
See also
C++ project property page reference
XML Data Generator Tool Property Page
Article • 08/03/2021
The XML Data Generator Tool property page becomes available when you add a
dataset to a project.
The XML Data Generator Tool property page contains the following properties:
Output File
Specifies the output file name to use.
Suppress Startup Banner
Suppresses the display of the startup banner and information messages.
Generated Proxy Language
Determines whether or not to emit managed code.
For information on how to access the XML Data Generator Tool property page, see Set
C++ compiler and build properties in Visual Studio.
For information on how to programmatically access members of this object, see
VCXMLDataGeneratorTool
See also
C++ project property page reference
XML Document Generator Tool Property
Pages
Article • 03/03/2022
The XML Document Generator Tool property page exposes the functionality of
xdcmake.exe , or XDCMake. XDCMake merges .xdc files into an .xml file when your
source code contains documentation comments and /doc (Process Documentation
Comments) (C/C++) is specified. For more information on adding documentation
comments to source code, see Recommended tags for documentation comments.
７ Note
XDCMake options in the development environment (property pages) differ from
the options when xdcmake.exe is used at the command line. For information on
using xdcmake.exe at the command line, see XDCMake reference.
UIElement List
Suppress Startup Banner
Suppress copyright message.
Additional Document Files
Additional directories in which you want the project system to look for .xdc files.
XDCMake always looks for .xdc files generated by the project. Multiple directories
can be specified.
Output Document File
The name and directory location of the .xml output file. For more information on
using macros to specify directory locations, see Common macros for build
commands and properties.
Document Library Dependencies
If your project has a dependency on a .lib project in the solution, you can
process .xdc files from the .lib project into the .xml files for the current project.
See also
C++ project property page reference
Custom Build Step Property Page:
General
Article • 08/03/2021
For each project configuration and target platform combination in your project, you can
specify a custom step to execute when the project is built.
For the Linux version of this page, see Custom Build Step Properties (Linux C++).
General page
Command Line
The command to be executed by the custom build step.
Description
A message that's displayed when the custom build step runs.
Outputs
The output file that the custom build step generates. This setting is required so
that incremental builds work correctly.
Additional Dependencies
A semicolon-delimited list of any additional input files to use for the custom build
step.
Execute After and Execute Before
These options define when the custom build step is run in the build process,
relative to the listed targets. The most commonly listed targets are
BuildGenerateSources , BuildCompile , and BuildLink , because they represent the
major steps in the build process. Other often-listed targets are Midl , CLCompile ,
and Link .
Treat Output As Content
This option is only meaningful for Universal Windows Platform or Windows Phone
apps, which include all content files in the .appx package.
To specify a custom build step
1. On the menu bar, choose Project > Properties to open the Property Pages dialog
box. For more information, see Set C++ compiler and build properties in Visual
Studio.
2. Select the Configuration Properties > Custom Build Step > General page.
3. Modify the settings.
See also
C++ project property page reference
HLSL Compiler Property Pages
Article • 08/03/2021
You can use the HLSL compiler (fxc.exe) property pages to configure how individual
HLSL shader files are built. You can also specify command-line arguments to the HLSL
compiler by using the Additional Options property of the Command Line property
page; this includes arguments that can't be configured by using other properties of the
HLSL property pages. For information about the HLSL compiler, see Effect-Compiler Tool
HLSL General Property Page
Additional Include Directories
Specifies one or more directories to add to the include path; separate with semi-colons
if more than one. (/I[path])
Entrypoint Name
Specifies the name of the entry point for the shader (/E[name])
Disable Optimizations
Yes (/Od) to disable optimizations; otherwise, No. By default, the value is Yes (/Od) for
Debug configurations and No for Release configurations.
The /Od command-line argument to the HLSL compiler implicitly applies the /Gfp
command-line argument, but output may not be identical to output that is produced by
passing both the /Od and /Gfp command-line arguments explicitly.
Enable Debugging Information
Yes (/Zi) to enable debugging information; otherwise, No. By default, the value is Yes
(/Zi) for Debug configurations and No for Release configurations.
Shader Type
Specifies the kind of shader. Different kinds of shaders implement different parts of the
graphics pipeline. Certain kinds of shaders are available only in more recent shader
models (which are specified by the Shader Model property)—for example, compute
shaders were introduced in shader model 5.
This property corresponds to the [type] portion of the /T [type]_[model] command-line
argument to the HLSL compiler. The Shader Models property specifies the [model]
portion of the argument.
Choices
Effect
Vertex Shader
Pixel Shader
Geometry Shader
Hull Shader
Domain Shader
Compute Shader
Library
Generate Root Signature Object
Shader Model
Specifies the shader model. Different shader models have different capabilities. In
general, more recent shader models offer expanded capabilities but require more
modern graphics hardware to run the shader code. Certain kinds of shaders (which are
specified by the Shader Type property) are available only in more recent shader models
—for example, compute shaders were introduced in shader model 5.
This property corresponds to the [model] portion of the /T [type]_[model] command￾line argument to the HLSL compiler. The Shader Type property specifies the [type]
portion of the argument.
All Resources Bound
Compiler will assume that all resources that a shader may reference are bound and are
in good state for the duration of shader execution (/all_resources_bound). Available for
Shader Model 5.1 and above.
Enable Unbounded Descriptor Tables
Inform the compiler that a shader may contain a declaration of a resource array with
unbounded range (/enable_unbounded_descriptor_tables). Available for Shader Model
5.1 and above.
Set Root Signature
Attach root signature to shader bytecode (/setrootsignature). Available for Shader
Model 5.0 and above.
Preprocessor Definitions
Adds one or more preprocessor symbol definitions to apply to the HLSL source code
file. Use semi-colons to separate the symbol definitions.
This property corresponds to the /D [definitions] command-line argument to the HLSL
compiler.
Compile a Direct2D custom pixel shader effect
Compile a Direct2D custom effect that contains pixel shaders. Do not use for a vertex or
compute custom effect.
Multi Processor Compilation
Run multiple instances at the same time.
Advanced Property Page
Suppress Startup Banner
Suppresses the display of the startup banner and information message. (/nologo)
Treat Warnings As Errors
Treats all compiler warnings as errors. For a new project, it may be best to use /WX in all
compilations; resolving all warnings will ensure the fewest possible hard-to-find code
defects.
Output Files Property Page
Header Variable Name
Specifies a name for the variable name in the header file (/Vn [name])
Header File Name
Specifies a name for header file containing object code. (/Fh [name])
Object File Name
Specifies a name for object file. (/Fo [name])
Assembler Output
Specifies the contents of assembly language output file. (/Fc, /Fx)
Choices
No Listing - No listing.
Assembly-Only Listing - Assembly code file
Assembly Code and Hex - Assembly code and hex listing file
Assembler Output File
Specifies file name for assembly code listing file
See also
C++ project property page reference
Command Line Property Pages
Compiling Shaders
Compiling a C/C++ project
Article • 03/03/2022
C and C++ compiler options can be set either in the Visual Studio IDE or on the
command line.
In Visual Studio
You can set compiler options for each project in its Visual Studio Property Pages dialog
box. In the left pane, select Configuration Properties, C/C++ and then choose the
compiler option category. The topic for each compiler option describes how it can be
set and where it is found in the development environment. For more information and a
complete list of options, see MSVC compiler options.
From the command line
You can set compiler (CL.exe) options:
On the command line
In command files
In the CL environment variable
Options specified in the CL environment variable are used every time you invoke CL. If a
command file is named in the CL environment variable or on the command line, the
options specified in the command file are used. Unlike either the command line or the
CL environment variable, a command file allows you to use multiple lines of options and
filenames.
Compiler options are processed "left to right," and when a conflict is detected, the last
(rightmost) option wins. The CL environment variable is processed before the command
line, so in any conflicts between CL and the command line, the command line takes
precedence.
Additional Compiler Topics
MSVC Compiler Options
Precompiled Header Files
CL Invokes the Linker
For information on choosing the compiler host and target architecture, see Configure
C++ projects for 64-bit, x64 targets.
See also
C/C++ Building Reference
Compiler Command-Line Syntax
Article • 03/03/2022
The CL command line uses the following syntax:
The following table describes input to the CL command.
Entry Meaning
option One or more CL options. Note that all options apply to all specified source files.
Options are specified by either a forward slash (/) or a dash (-). If an option takes an
argument, the option's description documents whether a space is allowed between
the option and the arguments. Option names (except for the /HELP option) are case
sensitive. For more information, see Order of CL Options.
file The name of one or more source files, .obj files, or libraries. CL compiles source files
and passes the names of the .obj files and libraries to the linker. For more
information, see CL Filename Syntax.
lib One or more library names. CL passes these names to the linker.
command￾file
A file that contains multiple options and filenames. For more information, see CL
Command Files.
link-opt One or more MSVC Linker Options. CL passes these options to the linker.
You can specify any number of options, filenames, and library names, as long as the
number of characters on the command line does not exceed 1024, the limit dictated by
the operating system.
For information about the return value of cl.exe, see Return Value of cl.exe .
CL [option...] file... [option | file]... [lib...] [@command-file] [/link
link-opt...]
７ Note
The command-line input limit of 1024 characters is not guaranteed to remain the
same in future releases of Windows.
See also
MSVC Compiler Options
CL Filename Syntax
Article • 08/03/2021
CL accepts files with names that follow FAT, HPFS, or NTFS naming conventions. Any
filename can include a full or partial path. A full path includes a drive name and one or
more directory names. CL accepts filenames separated either by backslashes (\) or
forward slashes (/). Filenames that contain spaces must be surrounded by double quote
characters. A partial path omits the drive name, which CL assumes to be the current
drive. If you don't specify a path, CL assumes the file is in the current directory.
The filename extension determines how files are processed. C and C++ files, which have
the extension .c, .cxx, or .cpp, are compiled. Other files, including .obj files, libraries (.lib),
and module-definition (.def) files, are passed to the linker without being processed.
See also
MSVC Compiler Command-Line Syntax
Order of CL Options
Article • 08/03/2021
Options can appear anywhere on the CL command line, except for the /link option,
which must occur last. The compiler begins with options specified in the CL environment
variable and then reads the command line from left to right — processing command
files in the order it encounters them. Each option applies to all files on the command
line. If CL encounters conflicting options, it uses the rightmost option.
See also
MSVC Compiler Command-Line Syntax
Return Value of cl.exe
Article • 11/11/2021
cl.exe returns zero for success (no errors) and non-zero otherwise.
The return value of cl.exe can be useful if you are compiling from a script, powershell,
.cmd, or .bat file. We recommend that you capture the output of the compiler in case
there are errors or warnings, so that you can resolve them.
There are too many possible error exit codes for cl.exe to list them all. You can look up
an error code in the winerror.h or ntstatus.h files included in the Windows Software
Development Kit in the %ProgramFiles(x86)%\Windows Kits\version\Include\shared\
directory. Error codes returned in decimal must be converted to hexadecimal for search.
For example, an error code of -1073741620 converted to hexadecimal is 0xC00000CC.
This error is found in ntstatus.h, where the corresponding message is "The specified
share name cannot be found on the remote server." For a downloadable list of Windows
error codes, see [MS-ERREF] Windows Error Codes.
You can also use the error lookup utility in Visual Studio to find out what a compiler
error message means. In a Visual Studio command shell, enter errlook.exe to start the
utility; or in the Visual Studio IDE, on the menu bar, choose Tools, Error Lookup. Enter
the error value to find the descriptive text associated with the error. For more
information see ERRLOOK Reference.
The following is a sample .bat file that uses the return value of cl.exe.
Windows Command Prompt
Remarks
echo off
cl /W4 t.cpp
@if ERRORLEVEL == 0 (
 goto good
)
@if ERRORLEVEL != 0 (
 goto bad
)
:good
 echo "clean compile"
 echo %ERRORLEVEL%
 goto end
MSVC Compiler Command-Line Syntax
:bad
 echo "error or warning"
 echo %ERRORLEVEL%
 goto end
:end
See also
CL environment variables
Article • 08/03/2021
The CL tool uses the following environment variables:
CL and _CL_, if defined. The CL tool prepends the options and arguments defined
in the CL environment variable to the command-line arguments, and appends the
options and arguments defined in _CL_, before processing.
INCLUDE, which must point to the \include subdirectory of your Visual Studio
installation.
LIBPATH, which specifies directories to search for metadata files referenced with
#using. For more information on LIBPATH, see #using.
You can set the CL or _CL_ environment variable using the following syntax:
SET CL=[ [option] ... [file] ...] [/link link-opt ...] 
SET _CL_=[ [option] ... [file] ...] [/link link-opt ...]
For details on the arguments to the CL and _CL_ environment variables, see MSVC
Compiler Command-Line Syntax.
You can use these environment variables to define the files and options you use most
often. Then use the command line to give more files and options to CL for specific
purposes. The CL and _CL_ environment variables are limited to 1024 characters (the
command-line input limit).
You can't use the /D option to define a symbol that uses an equal sign (=). Instead, you
can use the number sign (#) for an equal sign. In this way, you can use the CL or _CL_
environment variables to define preprocessor constants with explicit values—for
example, /DDEBUG#1 to define DEBUG=1 .
For more information, see Use the MSVC toolset from the command line.
Examples
The following command is an example of setting the CL environment variable:
SET CL=/Zp2 /Ox /I\INCLUDE\MYINCLS \LIB\BINMODE.OBJ
When the CL environment variable is set, if you enter CL INPUT.C at the command line,
the effective command becomes:
CL /Zp2 /Ox /I\INCLUDE\MYINCLS \LIB\BINMODE.OBJ INPUT.C
The following example causes a plain CL command to compile the source files FILE1.c
and FILE2.c, and then link the object files FILE1.obj, FILE2.obj, and FILE3.obj:
SET CL=FILE1.C FILE2.C 
SET _CL_=FILE3.OBJ 
CL
These environment variables make the call to CL have the same effect as the following
command line:
CL FILE1.C FILE2.C FILE3.OBJ
See also
Setting Compiler Options
MSVC Compiler Options
CL Command Files
Article • 08/03/2021
A command file is a text file that contains compiler options and filenames. It supplies
options you would otherwise type on the command line, or specify using the CL
environment variable. CL accepts a compiler command file as an argument, either in the
CL environment variable, or on the command line. Unlike either the command line or
the CL environment variable, you can use multiple lines of options and filenames in a
command file.
Options and filenames in a command file are processed when a command filename
appears within the CL environment variable or on the command line. However, if the
/link option appears in the command file, all options on the rest of the line are passed
to the linker. Options in later lines in the command file, and options on the command
line after the command file invocation, are still accepted as compiler options. For more
information on how the order of options affects their interpretation, see Order of CL
Options.
A command file must not contain the CL command. Each option must begin and end on
the same line; you can't use the backslash ( \ ) to combine an option across two lines.
A command file is specified by an at sign ( @ ) followed by a filename. The filename can
specify an absolute or relative path.
For example, if the following command is in a file named RESP:
Windows Command Prompt
/Ot /link LIBC.LIB
and you specify the following CL command:
Windows Command Prompt
CL /Ob2 @RESP MYAPP.C
the command to CL is as follows:
Windows Command Prompt
CL /Ob2 /Ot MYAPP.C /link LIBC.LIB
Here you can see how the command line and the command-file commands are
effectively combined.
See also
MSVC compiler command-line syntax
MSVC compiler options
CL Invokes the Linker
Article • 08/03/2021
CL automatically invokes the linker after compiling unless the /c option is used. CL
passes to the linker the names of .obj files created during compiling and the names of
any other files specified on the command line. The linker uses the options listed in the
LINK environment variable. You can use the /link option to specify linker options on the
CL command line. Options that follow the /link option override those in the LINK
environment variable. The options in the following table suppress linking.
Option Description
/c Compile without linking
/E, /EP, /P Preprocess without compiling or linking
/Zg Generate function prototypes
/Zs Check syntax
For further details about linking, see MSVC Linker Options.
Assume that you are compiling three C source files: MAIN.c, MOD1.c, and MOD2.c. Each
file includes a call to a function defined in a different file:
MAIN.c calls the function func1 in MOD1.c and the function func2 in MOD2.c.
MOD1.c calls the standard library functions printf_s and scanf_s .
MOD2.c calls graphics functions named myline and mycircle , which are defined in
a library named MYGRAPH.lib.
To build this program, compile with the following command line:
CL first compiles the C source files and creates the object files MAIN.obj, MOD1.obj, and
MOD2.obj. The compiler places the name of the standard library in each .obj file. For
more details, see Use Run-Time Library.
Example
CL MAIN.c MOD1.C MOD2.C MYGRAPH.lib
CL passes the names of the .obj files, along with the name MYGRAPH.lib, to the linker.
The linker resolves the external references as follows:
1. In MAIN.obj, the reference to func1 is resolved using the definition in MOD1.obj;
the reference to func2 is resolved using the definition in MOD2.obj.
2. In MOD1.obj, the references to printf_s and scanf_s are resolved using the
definitions in the library that the linker finds named within MOD1.obj.
3. In MOD2.obj, the references to myline and mycircle are resolved using the
definitions in MYGRAPH.lib.
See also
MSVC Compiler Options
Setting Compiler Options
Compiler Options
Article • 08/03/2021
cl.exe is a tool that controls the Microsoft C++ (MSVC) C and C++ compilers and linker.
cl.exe can be run only on operating systems that support Microsoft Visual Studio for
Windows.
７ Note
You can start this tool only from a Visual Studio developer command prompt. You
cannot start it from a system command prompt or from File Explorer. For more
information, see Use the MSVC toolset from the command line.
The compilers produce Common Object File Format (COFF) object (.obj) files. The linker
produces executable (.exe) files or dynamic-link libraries (DLLs).
All compiler options are case-sensitive. You may use either a forward slash ( / ) or a dash
( - ) to specify a compiler option.
To compile without linking, use the /c option.
Find a compiler option
To find a particular compiler option, see one of the following lists:
Compiler Options Listed Alphabetically
Compiler Options Listed by Category
Specify compiler options
The topic for each compiler option discusses how it can be set in the development
environment. For information on specifying options outside the development
environment, see:
MSVC Compiler Command-Line Syntax
CL Command Files
CL Environment Variables
Related build tools
MSVC Linker Options also affect how your program is built.
See also
C/C++ Building Reference
CL Invokes the Linker
Compiler options listed by category
Article • 11/13/2023
This article contains a categorical list of compiler options. For an alphabetical list, see
Compiler options listed alphabetically.
Option Purpose
/favor:
<blend|AMD64|INTEL64|ATOM>
Produces code that is optimized for a specified
architecture, or for a range of architectures.
/O1 Creates small code.
/O2 Creates fast code.
/Ob<n> Controls inline expansion.
/Od Disables optimization.
/Og Deprecated. Uses global optimizations.
/Oi[-] Generates intrinsic functions.
/Os Favors small code.
/Ot Favors fast code.
/Ox A subset of /O2 that doesn't include /GF or /Gy.
/Oy Omits frame pointer. (x86 only)
Option Purpose
/arch:
<IA32|SSE|SSE2|AVX|AVX2|AVX512>
Minimum CPU architecture requirements. IA32, SSE, and
SSE2 are x86 only.
/clr Produces an output file to run on the common language
runtime.
/clr:implicitKeepAlive- Turn off implicit emission of System::GC::KeepAlive(this) .
/clr:initialAppDomain Enable initial AppDomain behavior of Visual C++ 2002.
Optimization
Code generation
Option Purpose
/clr:netcore Produce assemblies targeting .NET Core runtime.
/clr:noAssembly Don't produce an assembly.
/clr:nostdimport Don't import any required assemblies implicitly.
/clr:nostdlib Ignore the system .NET framework directory when
searching for assemblies.
/clr:pure Produce an IL-only output file (no native executable code).
/clr:safe Produce an IL-only verifiable output file.
/EHa Enable C++ exception handling (with SEH exceptions).
/EHc extern "C" defaults to nothrow .
/EHr Always generate noexcept runtime termination checks.
/EHs Enable C++ exception handling (no SEH exceptions).
/fp:contract Consider floating-point contractions when generating
code.
/fp:except[-] Consider floating-point exceptions when generating code.
/fp:fast "fast" floating-point model; results are less predictable.
/fp:precise "precise" floating-point model; results are predictable.
/fp:strict "strict" floating-point model (implies /fp:except ).
/fpcvt:BC Backward-compatible floating-point to unsigned integer
conversions.
/fpcvt:IA Intel native floating-point to unsigned integer conversion
behavior.
/fsanitize Enables compilation of sanitizer instrumentation such as
AddressSanitizer.
/fsanitize-coverage Enables compilation of code coverage instrumentation for
libraries such as LibFuzzer.
/GA Optimizes for Windows applications.
/Gd Uses the __cdecl calling convention. (x86 only)
/Ge Deprecated. Activates stack probes.
/GF Enables string pooling.
Option Purpose
/Gh Calls hook function _penter .
/GH Calls hook function _pexit .
/GL[-] Enables whole program optimization.
/Gm[-] Deprecated. Enables minimal rebuild.
/Gr Uses the __fastcall calling convention. (x86 only)
/GR[-] Enables run-time type information (RTTI).
/GS[-] Checks buffer security.
/Gs[n] Controls stack probes.
/GT Supports fiber safety for data allocated by using static
thread-local storage.
/Gu[-] Ensure distinct functions have distinct addresses.
/guard:cf[-] Adds control flow guard security checks.
/guard:ehcont[-] Enables EH continuation metadata.
/Gv Uses the __vectorcall calling convention. (x86 and x64
only)
/Gw[-] Enables whole-program global data optimization.
/GX[-] Deprecated. Enables synchronous exception handling. Use
/EH instead.
/Gy[-] Enables function-level linking.
/Gz Uses the __stdcall calling convention. (x86 only)
/GZ Deprecated. Enables fast checks. (Same as /RTC1)
/homeparams Forces parameters passed in registers to be written to
their locations on the stack upon function entry. This
compiler option is only for the x64 compilers (native and
cross compile).
/hotpatch Creates a hotpatchable image.
/jumptablerdata Put switch case statement jump tables in the .rdata
section.
/Qfast_transcendentals Generates fast transcendentals.
Option Purpose
/QIfist Deprecated. Suppresses the call of the helper function
_ftol when a conversion from a floating-point type to an
integral type is required. (x86 only)
/Qimprecise_fwaits Removes fwait commands inside try blocks.
/QIntel-jcc-erratum Mitigates the performance impact of the Intel JCC erratum
microcode update.
/Qpar Enables automatic parallelization of loops.
/Qpar-report:n Enables reporting levels for automatic parallelization.
/Qsafe_fp_loads Uses integer move instructions for floating-point values
and disables certain floating point load optimizations.
/Qspectre[-] Enable mitigations for CVE 2017-5753, for a class of
Spectre attacks.
/Qspectre-load Generate serializing instructions for every load instruction.
/Qspectre-load-cf Generate serializing instructions for every control flow
instruction that loads memory.
/Qvec-report:n Enables reporting levels for automatic vectorization.
/RTC1 Enable fast runtime checks (equivalent to /RTCsu ).
/RTCc Convert to smaller type checks at run-time.
/RTCs Enable stack frame runtime checks.
/RTCu Enables uninitialized local usage checks.
/volatile:iso Acquire/release semantics not guaranteed on volatile
accesses.
/volatile:ms Acquire/release semantics guaranteed on volatile
accesses.
Option Purpose
/doc Processes documentation comments to an XML file.
/FA Configures an assembly listing file.
Output files
Option Purpose
/Fa Creates an assembly listing file.
/Fd Renames program database file.
/Fe Renames the executable file.
/Fi Specifies the preprocessed output file name.
/Fm Creates a mapfile.
/Fo Creates an object file.
/Fp Specifies a precompiled header file name.
/FR, /Fr Name generated .sbr browser files. /Fr is deprecated.
/Ft<dir> Location of the header files generated for #import .
Option Purpose
/AI<dir> Specifies a directory to search to resolve file references passed to the
#using directive.
/C Preserves comments during preprocessing.
/D<name>{=|#}
<text>
Defines constants and macros.
/E Copies preprocessor output to standard output.
/EP Copies preprocessor output to standard output.
/FI<file> Preprocesses the specified include file.
/FU<file> Forces the use of a file name, as if it had been passed to the #using
directive.
/Fx Merges injected code with the source file.
/I<dir> Searches a directory for include files.
/P Writes preprocessor output to a file.
/PD Print all macro definitions.
/PH Generate #pragma file_hash when preprocessing.
Preprocessor
Option Purpose
/U<name> Removes a predefined macro.
/u Removes all predefined macros.
/X Ignores the standard include directory.
Option Purpose
/exportHeader Create the header units files ( .ifc ) specified by the input
arguments.
/headerUnit Specify where to find the header unit file ( .ifc ) for the
specified header.
/headerName Build a header unit from the specified header.
/ifcOutput Specify the output file name or directory for built .ifc files.
/interface Treat the input file as a module interface unit.
/internalPartition Treat the input file as an internal partition unit.
/reference Use named module IFC.
/scanDependencies List module and header unit dependencies in C++ Standard
JSON form.
/sourceDependencies List all source-level dependencies.
/sourceDependencies:directives List module and header unit dependencies.
/translateInclude Treat #include as import .
Option Purpose
/await Enable coroutines (resumable functions) extensions.
/await:strict Enable standard C++20 coroutine support with earlier language
versions.
/constexpr:backtrace<N> Show N constexpr evaluations in diagnostics (default: 10).
Header units/modules
Language
Option Purpose
/constexpr:depth<N> Recursion depth limit for constexpr evaluation (default: 512).
/constexpr:steps<N> Terminate constexpr evaluation after N steps (default: 100000)
/openmp Enables #pragma omp in source code.
/openmp:experimental Enable OpenMP 2.0 language extensions plus select OpenMP 3.0+
language extensions.
/openmp:llvm OpenMP language extensions using LLVM runtime.
/permissive[-] Set standard-conformance mode.
/std:c++14 C++14 standard ISO/IEC 14882:2014 (default).
/std:c++17 C++17 standard ISO/IEC 14882:2017.
/std:c++20 C++20 standard ISO/IEC 14882:2020.
/std:c++latest The latest draft C++ standard preview features.
/std:c11 C11 standard ISO/IEC 9899:2011.
/std:c17 C17 standard ISO/IEC 9899:2018.
/std:clatest The latest draft C standard preview features.
/vd{0|1|2} Suppresses or enables hidden vtordisp class members.
/vmb Uses best base for pointers to members.
/vmg Uses full generality for pointers to members.
/vmm Declares multiple inheritance.
/vms Declares single inheritance.
/vmv Declares virtual inheritance.
/Z7 Generates C 7.0-compatible debugging information.
/Za Disables some C89 language extensions in C code.
/Zc:__cplusplus[-] Enable the __cplusplus macro to report the supported standard (off
by default).
/Zc:__STDC__ Enable the __STDC__ macro to report the C standard is supported (off
by default).
/Zc:alignedNew[-] Enable C++17 over-aligned dynamic allocation (on by default in
C++17).
Option Purpose
/Zc:auto[-] Enforce the new Standard C++ meaning for auto (on by default).
/Zc:char8_t[-] Enable or disable C++20 native u8 literal support as const char8_t
(off by default, except under /std:c++20 ).
/Zc:enumTypes[-] Enable Standard C++ rules for inferred enum base types (Off b y
default, not implied by /permissive- ).
/Zc:externC[-] Enforce Standard C++ rules for extern "C" functions (implied by
/permissive- ).
/Zc:externConstexpr[-] Enable external linkage for constexpr variables (off by default).
/Zc:forScope[-] Enforce Standard C++ for scoping rules (on by default).
/Zc:gotoScope Enforce Standard C++ goto rules around local variable initialization
(implied by /permissive- ).
/Zc:hiddenFriend[-] Enforce Standard C++ hidden friend rules (implied by /permissive- )
/Zc:implicitNoexcept[-] Enable implicit noexcept on required functions (on by default).
/Zc:inline[-] Remove unreferenced functions or data if they're COMDAT or have
internal linkage only (off by default).
/Zc:lambda[-] Enable new lambda processor for conformance-mode syntactic
checks in generic lambdas.
/Zc:noexceptTypes[-] Enforce C++17 noexcept rules (on by default in C++17 or later).
/Zc:nrvo[-] Enable optional copy and move elisions (on by default under /O2 ,
/permissive- , or /std:c++20 or later).
/Zc:preprocessor[-] Use the new conforming preprocessor (off by default, except in
C11/C17).
/Zc:referenceBinding[-] A UDT temporary won't bind to a non-const lvalue reference (off by
default).
/Zc:rvalueCast[-] Enforce Standard C++ explicit type conversion rules (off by default).
/Zc:sizedDealloc[-] Enable C++14 global sized deallocation functions (on by default).
/Zc:strictStrings[-] Disable string-literal to char* or wchar_t* conversion (off by default).
/Zc:templateScope[-] Enforce Standard C++ template parameter shadowing rules (off by
default).
/Zc:ternary[-] Enforce conditional operator rules on operand types (off by default).
Option Purpose
/Zc:threadSafeInit[-] Enable thread-safe local static initialization (on by default).
/Zc:throwingNew[-] Assume operator new throws on failure (off by default).
/Zc:tlsGuards[-] Generate runtime checks for TLS variable initialization (on by default).
/Zc:trigraphs Enable trigraphs (obsolete, off by default).
/Zc:twoPhase[-] Use nonconforming template parsing behavior (conforming by
default).
/Zc:wchar_t[-] wchar_t is a native type, not a typedef (on by default).
/Zc:zeroSizeArrayNew[-] Call member new / delete for 0-size arrays of objects (on by default).
/Ze Deprecated. Enables C89 language extensions.
/Zf Improves PDB generation time in parallel builds.
/ZH:
[MD5|SHA1|SHA_256]
Specifies MD5, SHA-1, or SHA-256 for checksums in debug info.
/ZI Includes debug information in a program database compatible with
Edit and Continue. (x86 only)
/Zi Generates complete debugging information.
/Zl Removes the default library name from the .obj file.
/Zo[-] Generate richer debugging information for optimized code.
/Zp[n] Packs structure members.
/Zs Checks syntax only.
/ZW Produces an output file to run on the Windows Runtime.
Option Purpose
/F Sets stack size.
/LD Creates a dynamic-link library.
/LDd Creates a debug dynamic-link library.
/link Passes the specified option to LINK.
Linking
Option Purpose
/LN Creates an MSIL .netmodule .
/MD Compiles to create a multithreaded DLL, by using MSVCRT.lib.
/MDd Compiles to create a debug multithreaded DLL, by using MSVCRTD.lib.
/MT Compiles to create a multithreaded executable file, by using LIBCMT.lib.
/MTd Compiles to create a debug multithreaded executable file, by using LIBCMTD.lib.
Option Purpose
/? Lists the compiler options.
@ Specifies a response file.
/analyze Enables code analysis.
/bigobj Increases the number of addressable sections in an .obj file.
/c Compiles without linking.
/cgthreads Specifies number of cl.exe threads to use for optimization and code
generation.
/errorReport Deprecated. Windows Error Reporting (WER) settings control error reporting.
/execution-charset Set execution character set.
/fastfail Enable fast-fail mode.
/FC Displays the full path of source code files passed to cl.exe in diagnostic text.
/FS Forces writes to the PDB file to be serialized through MSPDBSRV.EXE.
/H Deprecated. Restricts the length of external (public) names.
/HELP Lists the compiler options.
/J Changes the default char type.
/JMC Supports native C++ Just My Code debugging.
/kernel The compiler and linker create a binary that can be executed in the Windows
kernel.
/MP Builds multiple source files concurrently.
Miscellaneous
Option Purpose
/nologo Suppresses display of sign-on banner.
/presetPadding Zero initialize padding for stack based class types.
/showIncludes Displays a list of all include files during compilation.
/source-charset Set source character set.
/Tc Specifies a C source file.
/TC Specifies all source files are C.
/Tp Specifies a C++ source file.
/TP Specifies all source files are C++.
/utf-8 Set source and execution character sets to UTF-8.
/V Deprecated. Sets the version string.
/validate-charset Validate UTF-8 files for only compatible characters.
/volatileMetadata Generate metadata on volatile memory accesses.
/Yc Create .PCH file.
/Yd Deprecated. Places complete debugging information in all object files. Use
/Zi instead.
/Yl Injects a PCH reference when creating a debug library.
/Yu Uses a precompiled header file during build.
/Y- Ignores all other precompiled-header compiler options in the current build.
/Zm Specifies the precompiled header memory allocation limit.
Option Purpose
/diagnostics:caret[-] Diagnostics format: prints column and the indicated line of
source.
/diagnostics:classic Use legacy diagnostics format.
/diagnostics Diagnostics format: prints column information.
/external:anglebrackets Treat all headers included via <> as external.
Diagnostics
Option Purpose
/external:env:<var> Specify an environment variable with locations of external
headers.
/external:I <path> Specify location of external headers.
/external:templates[-] Evaluate warning level across template instantiation chain.
/external:W<n> Set warning level for external headers.
/options:strict Unrecognized compiler options are errors.
/sdl Enable more security features and warnings.
/w Disable all warnings.
/W0, /W1, /W2, /W3, /W4 Set output warning level.
/w1<n>, /w2<n>, /w3<n>,
/w4<n>
Set warning level for the specified warning.
/Wall Enable all warnings, including warnings that are disabled by
default.
/wd<n> Disable the specified warning.
/we<n> Treat the specified warning as an error.
/WL Enable one-line diagnostics for error and warning messages when
compiling C++ source code from the command line.
/wo<n> Display the specified warning only once.
/Wv:xx[.yy[.zzzzz]] Disable warnings introduced after the specified version of the
compiler.
/WX Treat warnings as errors.
Experimental options may only be supported by certain versions of the compiler. They
may also behave differently in different compiler versions. Often the best, or only,
documentation for experimental options is in the Microsoft C++ Team Blog .
Option Purpose
/experimental:log Enables experimental structured SARIF output.
/experimental:module Enables experimental module support.
Experimental options
Option Purpose
/clr:noAssembly Deprecated. Use /LN (Create MSIL Module) instead.
/errorReport Deprecated. Error reporting is controlled by Windows Error
Reporting (WER) settings.
/experimental:preprocessor Deprecated. Enables experimental conforming preprocessor
support. Use /Zc:preprocessor
/Fr Deprecated. Creates a browse information file without local
variables.
/Ge Deprecated. Activates stack probes. On by default.
/Gm Deprecated. Enables minimal rebuild.
/GX Deprecated. Enables synchronous exception handling. Use /EH
instead.
/GZ Deprecated. Enables fast checks. Use /RTC1 instead.
/H Deprecated. Restricts the length of external (public) names.
/Og Deprecated. Uses global optimizations.
/QIfist Deprecated. Once used to specify how to convert from a floating￾point type to an integral type.
/V Deprecated. Sets the .obj file version string.
/Wp64 Obsolete. Detects 64-bit portability problems.
/Yd Deprecated. Places complete debugging information in all object
files. Use /Zi instead.
/Zc:forScope- Deprecated. Disables conformance in for loop scope.
/Ze Deprecated. Enables language extensions.
/Zg Removed in Visual Studio 2015. Generates function prototypes.
C/C++ building reference
MSVC compiler options
MSVC compiler command-line syntax
Deprecated and removed compiler options
See also
Compiler options listed alphabetically
Article • 11/13/2023
This table contains an alphabetical list of compiler options. For a list of compiler options
by category, see the Compiler options listed by category article.
Option Purpose
@ Specifies a response file.
/? Lists the compiler options.
/AI<dir> Specifies a directory to search to resolve file references
passed to the #using directive.
/analyze Enables code analysis.
/arch:
<IA32|SSE|SSE2|AVX|AVX2|AVX512>
Minimum CPU architecture requirements. IA32, SSE, and
SSE2 are x86 only.
/arm64EC Generate code compatible with the arm64EC ABI.
/await Enable coroutines (resumable functions) extensions.
/await:strict Enable standard C++20 coroutine support with earlier
language versions.
/bigobj Increases the number of addressable sections in an .obj
file.
/C Preserves comments during preprocessing.
/c Compiles without linking.
/cgthreads Specifies number of cl.exe threads to use for optimization
and code generation.
/clr Produces an output file to run on the common language
runtime.
/clr:implicitKeepAlive- Turn off implicit emission of System::GC::KeepAlive(this) .
/clr:initialAppDomain Enable initial AppDomain behavior of Visual C++ 2002.
/clr:netcore Produce assemblies targeting .NET Core runtime.
Compiler options
Option Purpose
/clr:noAssembly Don't produce an assembly.
/clr:nostdimport Don't import any required assemblies implicitly.
/clr:nostdlib Ignore the system .NET framework directory when
searching for assemblies.
/clr:pure Produce an IL-only output file (no native executable code).
/clr:safe Produce an IL-only verifiable output file.
/constexpr:backtrace<N> Show N constexpr evaluations in diagnostics (default: 10).
/constexpr:depth<N> Recursion depth limit for constexpr evaluation (default:
512).
/constexpr:steps<N> Terminate constexpr evaluation after N steps (default:
100000)
/D<name>{=|#}<text> Defines constants and macros.
/diagnostics Diagnostics format: prints column information.
/diagnostics:caret[-] Diagnostics format: prints column and the indicated line of
source.
/diagnostics:classic Use legacy diagnostics format.
/doc Processes documentation comments to an XML file.
/E Copies preprocessor output to standard output.
/EHa Enable C++ exception handling (with SEH exceptions).
/EHc extern "C" defaults to nothrow .
/EHr Always generate noexcept runtime termination checks.
/EHs Enable C++ exception handling (no SEH exceptions).
/EP Copies preprocessor output to standard output.
/errorReport Deprecated. Windows Error Reporting (WER) settings
control error reporting.
/execution-charset Set execution character set.
/experimental:log Enables experimental structured SARIF output.
/experimental:module Enables experimental module support.
Option Purpose
/exportHeader Create the header units files ( .ifc ) specified by the input
arguments.
/external:anglebrackets Treat all headers included via <> as external.
/external:env:<var> Specify an environment variable with locations of external
headers.
/external:I <path> Specify location of external headers.
/external:templates[-] Evaluate warning level across template instantiation chain.
/external:W<n> Set warning level for external headers.
/F Sets stack size.
/FA Configures an assembly listing file.
/Fa Creates an assembly listing file.
/fastfail Enable fast-fail mode.
/favor:
<blend|AMD64|INTEL64|ATOM>
Produces code that is optimized for a specified
architecture, or for a range of architectures.
/FC Displays the full path of source code files passed to cl.exe
in diagnostic text.
/Fd Renames program database file.
/Fe Renames the executable file.
/FI<file> Preprocesses the specified include file.
/Fi Specifies the preprocessed output file name.
/Fm Creates a mapfile.
/Fo Creates an object file.
/Fp Specifies a precompiled header file name.
/fp:contract Consider floating-point contractions when generating
code.
/fp:except[-] Consider floating-point exceptions when generating code.
/fp:fast "fast" floating-point model; results are less predictable.
/fp:precise "precise" floating-point model; results are predictable.
Option Purpose
/fp:strict "strict" floating-point model (implies /fp:except ).
/fpcvt:BC Backward-compatible floating-point to unsigned integer
conversions.
/fpcvt:IA Intel native floating-point to unsigned integer conversion
behavior.
/FR, /Fr Name generated .sbr browser files. /Fr is deprecated.
/FS Forces writes to the PDB file to be serialized through
MSPDBSRV.EXE.
/fsanitize Enables compilation of sanitizer instrumentation such as
AddressSanitizer.
/fsanitize-coverage Enables compilation of code coverage instrumentation for
libraries such as LibFuzzer.
/Ft<dir> Location of the header files generated for #import .
/FU<file> Forces the use of a file name, as if it had been passed to
the #using directive.
/Fx Merges injected code with the source file.
/GA Optimizes for Windows applications.
/Gd Uses the __cdecl calling convention. (x86 only)
/Ge Deprecated. Activates stack probes.
/GF Enables string pooling.
/GH Calls hook function _pexit .
/Gh Calls hook function _penter .
/GL[-] Enables whole program optimization.
/Gm[-] Deprecated. Enables minimal rebuild.
/GR[-] Enables run-time type information (RTTI).
/Gr Uses the __fastcall calling convention. (x86 only)
/GS[-] Checks buffer security.
/Gs[n] Controls stack probes.
Option Purpose
/GT Supports fiber safety for data allocated by using static
thread-local storage.
/Gu[-] Ensure distinct functions have distinct addresses.
/guard:cf[-] Adds control flow guard security checks.
/guard:ehcont[-] Enables EH continuation metadata.
/Gv Uses the __vectorcall calling convention. (x86 and x64
only)
/Gw[-] Enables whole-program global data optimization.
/GX[-] Deprecated. Enables synchronous exception handling. Use
/EH instead.
/Gy[-] Enables function-level linking.
/GZ Deprecated. Enables fast checks. (Same as /RTC1)
/Gz Uses the __stdcall calling convention. (x86 only)
/H Deprecated. Restricts the length of external (public)
names.
/headerName Build a header unit from the specified header.
/headerUnit Specify where to find the header unit file ( .ifc ) for the
specified header.
/HELP Lists the compiler options.
/homeparams Forces parameters passed in registers to be written to
their locations on the stack upon function entry. This
compiler option is only for the x64 compilers (native and
cross compile).
/hotpatch Creates a hotpatchable image.
/I<dir> Searches a directory for include files.
/ifcOutput Specify output file name or directory for built .ifc files.
/interface Treat the input file as a module interface unit.
/internalPartition Treat the input file as an internal partition unit.
/J Changes the default char type.
Option Purpose
/jumptablerdata Put switch case statement jump tables in the .rdata
section.
/JMC Supports native C++ Just My Code debugging.
/kernel The compiler and linker create a binary that can be
executed in the Windows kernel.
/LD Creates a dynamic-link library.
/LDd Creates a debug dynamic-link library.
/link Passes the specified option to LINK.
/LN Creates an MSIL .netmodule .
/MD Compiles to create a multithreaded DLL, by using
MSVCRT.lib.
/MDd Compiles to create a debug multithreaded DLL, by using
MSVCRTD.lib.
/MP Builds multiple source files concurrently.
/MT Compiles to create a multithreaded executable file, by
using LIBCMT.lib.
/MTd Compiles to create a debug multithreaded executable file,
by using LIBCMTD.lib.
/nologo Suppresses display of sign-on banner.
/O1 Creates small code.
/O2 Creates fast code.
/Ob<n> Controls inline expansion.
/Od Disables optimization.
/Og Deprecated. Uses global optimizations.
/Oi[-] Generates intrinsic functions.
/openmp Enables #pragma omp in source code.
/openmp:experimental Enable OpenMP 2.0 language extensions plus select
OpenMP 3.0+ language extensions.
/openmp:llvm OpenMP language extensions using LLVM runtime.
Option Purpose
/options:strict Unrecognized compiler options are errors.
/Os Favors small code.
/Ot Favors fast code.
/Ox A subset of /O2 that doesn't include /GF or /Gy.
/Oy Omits frame pointer. (x86 only)
/P Writes preprocessor output to a file.
/PD Print all macro definitions.
/permissive[-] Set standard-conformance mode.
/PH Generate #pragma file_hash when preprocessing.
/presetPadding Zero initialize padding for stack based class types.
/Qfast_transcendentals Generates fast transcendentals.
/QIfist Deprecated. Suppresses the call of the helper function
_ftol when a conversion from a floating-point type to an
integral type is required. (x86 only)
/Qimprecise_fwaits Removes fwait commands inside try blocks.
/QIntel-jcc-erratum Mitigates the performance impact of the Intel JCC erratum
microcode update.
/Qpar-report:<n> Enables reporting levels for automatic parallelization.
/Qpar Enables automatic parallelization of loops.
/Qsafe_fp_loads Uses integer move instructions for floating-point values
and disables certain floating point load optimizations.
/Qspectre[-] Enable mitigations for CVE 2017-5753, for a class of
Spectre attacks.
/Qspectre-load Generate serializing instructions for every load instruction.
/Qspectre-load-cf Generate serializing instructions for every control flow
instruction that loads memory.
/Qvec-report:<n> Enables reporting levels for automatic vectorization.
/reference Use named module IFC.
/RTC1 Enable fast runtime checks (equivalent to /RTCsu ).
Option Purpose
/RTCc Convert to smaller type checks at run-time.
/RTCs Enable stack frame runtime checks.
/RTCu Enables uninitialized local usage checks.
/scanDependencies List module dependencies in C++ Standard JSON form.
/sdl Enable more security features and warnings.
/showIncludes Displays a list of all include files during compilation.
/source-charset Set source character set.
/sourceDependencies List all source-level dependencies.
/sourceDependencies:directives List module and header unit dependencies.
/std:c++14 C++14 standard ISO/IEC 14882:2014 (default).
/std:c++17 C++17 standard ISO/IEC 14882:2017.
/std:c++20 C++20 standard ISO/IEC 14882:2020.
/std:c++latest The latest draft C++ standard preview features.
/std:c11 C11 standard ISO/IEC 9899:2011.
/std:c17 C17 standard ISO/IEC 9899:2018.
/std:clatest The latest draft C standard preview features.
/TC Specifies all source files are C.
/Tc Specifies a C source file.
/TP Specifies all source files are C++.
/Tp Specifies a C++ source file.
/translateInclude Treat #include as import .
/U<name> Removes a predefined macro.
/u Removes all predefined macros.
/utf-8 Set source and execution character sets to UTF-8.
/V Deprecated. Sets the version string.
/validate-charset Validate UTF-8 files for only compatible characters.
Option Purpose
/vd{0|1|2} Suppresses or enables hidden vtordisp class members.
/vmb Uses best base for pointers to members.
/vmg Uses full generality for pointers to members.
/vmm Declares multiple inheritance.
/vms Declares single inheritance.
/vmv Declares virtual inheritance.
/volatile:iso Acquire/release semantics not guaranteed on volatile
accesses.
/volatile:ms Acquire/release semantics guaranteed on volatile
accesses.
/volatileMetadata Generate metadata on volatile memory accesses.
/w Disable all warnings.
/W0, /W1, /W2, /W3, /W4 Set output warning level.
/w1<n>, /w2<n>, /w3<n>, /w4<n> Set warning level for the specified warning.
/Wall Enable all warnings, including warnings that are disabled
by default.
/wd<n> Disable the specified warning.
/we<n> Treat the specified warning as an error.
/WL Enable one-line diagnostics for error and warning
messages when compiling C++ source code from the
command line.
/wo<n> Display the specified warning only once.
/Wv:xx[.yy[.zzzzz]] Disable warnings introduced after the specified version of
the compiler.
/WX Treat warnings as errors.
/X Ignores the standard include directory.
/Y- Ignores all other precompiled-header compiler options in
the current build.
/Yc Create .PCH file.
Option Purpose
/Yd Deprecated. Places complete debugging information in all
object files. Use /Zi instead.
/Yl Injects a PCH reference when creating a debug library.
/Yu Uses a precompiled header file during build.
/Z7 Generates C 7.0-compatible debugging information.
/Za Disables some C89 language extensions in C code.
/Zc:__cplusplus[-] Enable the __cplusplus macro to report the supported
standard (off by default).
/Zc:__STDC__ Enable the __STDC__ macro to report the C standard is
supported (off by default).
/Zc:alignedNew[-] Enable C++17 over-aligned dynamic allocation (on by
default in C++17).
/Zc:auto[-] Enforce the new Standard C++ meaning for auto (on by
default).
/Zc:char8_t[-] Enable or disable C++20 native u8 literal support as const
char8_t (off by default, except under /std:c++20 ).
/Zc:enumTypes[-] Enable Standard C++ rules for enum type deduction (off by
default).
/Zc:externC[-] Enforce Standard C++ rules for extern "C" functions
(implied by /permissive- ).
/Zc:externConstexpr[-] Enable external linkage for constexpr variables (off by
default).
/Zc:forScope[-] Enforce Standard C++ for scoping rules (on by default).
/Zc:gotoScope Enforce Standard C++ goto rules around local variable
initialization (implied by /permissive- ).
/Zc:hiddenFriend[-] Enforce Standard C++ hidden friend rules (implied by
/permissive- )
/Zc:implicitNoexcept[-] Enable implicit noexcept on required functions (on by
default).
/Zc:inline[-] Remove unreferenced functions or data if they're COMDAT
or have internal linkage only (off by default).
Option Purpose
/Zc:lambda[-] Enable new lambda processor for conformance-mode
syntactic checks in generic lambdas.
/Zc:noexceptTypes[-] Enforce C++17 noexcept rules (on by default in C++17 or
later).
/Zc:nrvo[-] Enable optional copy and move elisions (on by default
under /O2 , /permissive- , or /std:c++20 or later).
/Zc:preprocessor[-] Use the new conforming preprocessor (off by default,
except in C11/C17).
/Zc:referenceBinding[-] A UDT temporary won't bind to a non-const lvalue
reference (off by default).
/Zc:rvalueCast[-] Enforce Standard C++ explicit type conversion rules (off
by default).
/Zc:sizedDealloc[-] Enable C++14 global sized deallocation functions (on by
default).
/Zc:strictStrings[-] Disable string-literal to char* or wchar_t* conversion (off
by default).
/Zc:templateScope[-] Enforce Standard C++ template parameter shadowing
rules (off by default).
/Zc:ternary[-] Enforce conditional operator rules on operand types (off
by default).
/Zc:threadSafeInit[-] Enable thread-safe local static initialization (on by default).
/Zc:throwingNew[-] Assume operator new throws on failure (off by default).
/Zc:tlsGuards[-] Generate runtime checks for TLS variable initialization (on
by default).
/Zc:trigraphs Enable trigraphs (obsolete, off by default).
/Zc:twoPhase[-] Use nonconforming template parsing behavior
(conforming by default).
/Zc:wchar_t[-] wchar_t is a native type, not a typedef (on by default).
/Zc:zeroSizeArrayNew[-] Call member new / delete for zero-size arrays of objects
(on by default).
/Ze Deprecated. Enables C89 language extensions.
/Zf Improves PDB generation time in parallel builds.
Option Purpose
/ZH:[MD5|SHA1|SHA_256] Specifies MD5, SHA-1, or SHA-256 for checksums in
debug info.
/ZI Includes debug information in a program database
compatible with Edit and Continue. (x86 only)
/Zi Generates complete debugging information.
/Zl Removes the default library name from the .obj file.
/Zm Specifies the precompiled header memory allocation limit.
/Zo[-] Generate richer debugging information for optimized
code.
/Zp[n] Packs structure members.
/Zs Checks syntax only.
/ZW Produces an output file to run on the Windows Runtime.
MSVC compiler options
MSVC compiler command-line syntax
See also
@ (Specify a Compiler Response File)
Article • 08/03/2021
Specifies a compiler response file.
Syntax
@response_file
Arguments
response_file
A text file containing compiler commands.
Remarks
A response file can contain any commands that you would specify on the command line.
This can be useful if your command-line arguments exceed 127 characters.
It is not possible to specify the @ option from within a response file. That is, a response
file cannot embed another response file.
From the command line you can specify as many response file options (for example,
@respfile.1 @respfile.2 ) as you want.
To set this compiler option in the Visual Studio
development environment
A response file cannot be specified from within the development environment and
must be specified at the command line.
To set this compiler option programmatically
This compiler option cannot be changed programmatically.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/AI (Specify Metadata Directories)
Article • 08/03/2021
Specifies a directory that the compiler will search to resolve file references passed to the
#using directive.
Syntax
/AIdirectory
Arguments
directory
The directory or path for the compiler to search.
Remarks
Only one directory can be passed to an /AI invocation. Specify one /AI option for each
path you want the compiler to search. For example, to add both C:\Project\Meta and
C:\Common\Meta to the compiler search path for #using directives, add
/AI"C:\Project\Meta" /AI"C:\Common\Meta" to the compiler command line or add each
directory to the Additional #using Directories property in Visual Studio.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Additional #using Directories property.
To set this compiler option programmatically
See AdditionalUsingDirectories.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
#using Directive
/analyze (Code analysis)
Article • 02/18/2022
Enables code analysis and control options.
Syntax
General analysis options:
/analyze [ - ]
/analyze:only
/analyze:quiet
/analyze:max_paths number
/analyze:stacksize number
/analyze:WX￾Analysis plugin options:
/analyze:plugin plugin_dll
External file analysis options:
/analyze:external-
/analyze:external:ruleset ruleset_files
Analysis log options:
/analyze:autolog [ - ]
/analyze:autolog:ext extension
/analyze:log log_path
Log file format options:
/analyze:log:format:sarif
/analyze:log:format:xml
Log file content options:
/analyze:sarif:analyzedfiles [ - ]
/analyze:sarif:configuration [ - ]
/analyze:log:compilerwarnings
/analyze:log:includesuppressed
Ruleset options:
/analyze:projectdirectory project_directory
/analyze:rulesetdirectory ruleset_directories
/analyze:ruleset ruleset_files
Arguments
General analysis options
/analyze [ - ]
Turns on code analysis. Use /analyze- to explicitly turn off analysis. /analyze- is the
default behavior.
By default, analysis output goes to the console or the Visual Studio Output window like
other error messages. Code analysis also creates a log file named
filename.nativecodeanalysis.xml , where filename is the name of the analyzed source
file.
/analyze:only
By default, the compiler compiles the code to generate object files before code analysis
runs. The /analyze:only option makes the compiler skip the code generation pass, and
does code analysis directly. Compiler errors still prevent code analysis from running.
However, the compiler won't report other warnings that it might find during the code
generation pass. If the program isn't free of code-generation warnings, analysis results
might be unreliable. We recommend you use this option only if the code passes code￾generation syntax checks without errors or warnings.
/analyze:quiet
Turns off analysis output to the console or Visual Studio Output window.
/analyze:max_paths number
The number parameter specifies the maximum number of code paths to analyze.
Analysis defaults to 256 paths. Larger values cause more thorough checking, but the
analysis might take longer.
/analyze:stacksize number
The number parameter specifies the size in bytes of the stack frame that generates
warning C6262. The default stack frame size is 16KB.
/analyze:WX￾Tells the compiler not to treat code analysis warnings as errors even when the /WX
option is used. For more information, see /WX (Warning level).
Analysis plugin options
/analyze:plugin plugin_dll
Enables the specified code analysis plug-in DLL for code analysis.
Space between /analyze:plugin and the plugin_dll file path is optional if the path
doesn't require double-quotes ( " ). For example, you can write /analyze:plugin
EspxEngine.dll . However, if the path is enclosed in double-quotes, you can't have a
space between /analyze:plugin and the file path. Here's an example:
/analyze:plugin"c:\path\to\EspxEngine.dll" .
The code analysis engine uses plug-ins to help find specific categories of defects. The
code analysis engine comes with some built-in plug-ins that detect various defects. To
use another plug-in with the code analysis engine, specify it by using the
/analyze:plugin option.
Some plug-ins, like EspXEngine.dll , which ships with Visual Studio, employ extensions
that can do further analysis. Visual Studio includes these extensions for EspXEngine:
ConcurrencyCheck.dll , CppCoreCheck.dll , EnumIndex.dll , HResultCheck.dll , and
VariantClear.dll . They check for defects for concurrency issues, CppCoreGuidelines
violations, inappropriate uses of enum values as indexes, HRESULT values, or VARIANT
values, respectively.
When you build on the command line, you can use the Esp.Extensions environment
variable to specify EspXEngine extensions. For example:
Windows Command Prompt
set Esp.Extensions=ConcurrencyCheck.dll;CppCoreCheck.dll;
Use a semicolon ( ; ) to delimit the extensions, as shown in the example. A trailing
semicolon isn't needed. You can use an absolute file path for an extension, or specify a
relative path from the directory that contains EspXEngine.dll .
The EspXEngine.dll plug-in uses ConcurrencyCheck.dll to implement concurrency￾related code analysis checks. These checks raise warnings in the C261XX range, such as
C26100 through C26167.
If you're building in a developer command prompt window, first set the Esp.Extensions
environment variable to specify the ConcurrencyCheck.dll extension:
Windows Command Prompt
set Esp.Extensions=ConcurrencyCheck.dll
Then, use compiler option /analyze:plugin EspXEngine.dll to use the EspXEngine plug￾in.
External file analysis options
Starting in Visual Studio 2019 version 16.10, you can specify different analysis rules and
behavior for external headers. Use the /external:I , /external:env , or
/external:anglebrackets options to specify directories as "external" directories. Any files
that are included by using #include from an external directory or its subdirectories are
considered as external headers. For more information, see /external (External headers
diagnostics).
Code analysis provides these options to control analysis of external files:
/analyze:external￾Skips analysis of external header files. By default, code analysis analyzes external header
files just like other files. When the /analyze:external- option is set, code analysis skips
any files specified as external, except templates from external files. Templates defined in
external headers are treated as non-external by using the /external:templates- option.
The /external:Wn option doesn't affect code analysis. For example, code analysis
analyzes external files and reports defects even when /external:W0 is specified.
/analyze:external:ruleset ruleset_files
The ruleset_files parameter specifies one or more semicolon-delimited ruleset files to
use for analysis of external files. For information on rulesets, refer to "Options for
rulesets" section.
There's an environment variable ( CAExcludePath ) that provides similar but simpler
capability to skip analysis of files under the directories specified in the environment
variable. If a directory is specified in both /external:* option and in the CAExcludePath
environment variable, it's considered as excluded, and /analyze:external* options
won't apply to that directory.
Analysis log options
/analyze:autolog [ - ]
This flag used to be required to enable creation of analysis log file for each of the source
files being analyzed. Log files are now created by default, so this flag is mostly
redundant. When used, it changes the default log extension to *.pftlog instead of
.xml . Use /analyze:autolog- to disable logging to files.
/analyze:autolog:ext extension
Overrides the default extension of the analysis log files, and uses extension instead. If
you use the .sarif extension, the log file uses the SARIF format instead of the default
XML format.
/analyze:log log_path
Specifies a log file path log_path instead of the automatically generated log file path.
When the log_path path has a trailing backslash and refers to an existing directory,
code analysis creates all log files in the specified directory. Otherwise, log_path specifies
a file path. A file path instructs the compiler to combine logs for all analyzed source files
into the specified log file. If the file path has a .sarif extension, the log file uses the
SARIF format instead of the default XML format. You can override this behavior by using
the /analyze:log:format:* option.
Log file format options
Starting in Visual Studio 2019 version 16.9, you can specify different log format options
for code analysis.
/analyze:log:format:xml
Forces the use of XML log format irrelevant of the file extension used.
/analyze:log:format:sarif
Forces the use of SARIF log format irrelevant of the file extension used.
Log file content options
Starting in Visual Studio 2019 version 16.9, you can specify different log content options
for code analysis.
/analyze:sarif:analyzedfiles [ - ]
Adds file artifacts entries to the SARIF log file for analyzed files that don't issue
warnings. This option is disabled by default. Artifacts for the source file and for files that
emitted results are always included.
/analyze:sarif:configuration [ - ]
Adds rule configuration entries to determine how the user overrode the default rule
configuration (disabled by default).
/analyze:log:compilerwarnings
Adds both any defects the analysis engine finds, and all compiler warnings, to the
analysis log file. By default, compiler warnings aren't included in the analysis log file. For
more information on compiler warnings during code analysis, see the /analyze:only
option.
/analyze:log:includesuppressed
Adds both suppressed warnings and unsuppressed warnings to the analysis log file. By
default, suppressed warnings aren't included in the analysis log file. If ruleset files are
specified for analysis, the warnings disabled by the ruleset files aren't included in the log
even when /analyze:log:includesuppressed is specified.
Ruleset options
/analyze:projectdirectory project_directory
Specifies the current project directory. If the ruleset (or an item it includes) is a file name,
the compiler first looks for the file under the specified project_directory . If not found,
it next searches the ruleset_directories specified by /analyze:rulesetdirectory , if any.
If the ruleset (or an item it includes) is a relative path, the compiler first looks for the file
under the project directory. If the ruleset isn't found, then it looks in the current working
directory. This option is available starting in Visual Studio 2019 version 16.9.
/analyze:rulesetdirectory ruleset_directories
Specifies a semicolon-separated list of ruleset search paths. If the ruleset (or an item it
includes) is a file name, then the compiler first looks for the file under the
project_directory specified by /analyze:projectdirectory , if any, followed by the
specified ruleset_directories . This option is available starting in Visual Studio 2019
version 16.9.
/analyze:ruleset ruleset_files
Specifies one or more ruleset files to use for analysis. This option can make analysis
more efficient; the analysis engine tries to exclude checkers that have no active rules
specified in the ruleset files before running. Otherwise, the engine runs all checkers
enabled.
The ruleset files that ship with Visual Studio are found in %VSINSTALLDIR%\Team
Tools\Static Analysis Tools\Rule Sets .
The following example custom ruleset tells the analysis engine to check for C6001 and
C26494, and report them as warnings.
You can place this file anywhere as long as you specify the full path in the argument, or
under the directories specified in the /analyze:projectdirectory or
/analyze:rulesetdirectory options.
XML
By default, the file extension for ruleset files is *.ruleset . Visual Studio uses the default
extension when browsing for ruleset files. However, you can use any extension.
For more information about rulesets, see Use rule sets to specify the C++ rules to run.
For more information, see Code analysis for C/C++ overview and Code analysis for
C/C++ warnings.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Code Analysis > General property page.
3. Modify one or more of the Code Analysis properties.
<?xml version="1.0" encoding="utf-8"?>
<RuleSet Name="New Rule Set" Description="New rules to apply."
ToolsVersion="15.0">
 <Rules AnalyzerId="Microsoft.Analyzers.NativeCodeAnalysis"
RuleNamespace="Microsoft.Rules.Native">
 <Rule Id="C6001" Action="Warning" />
 <Rule Id="C26494" Action="Warning" />
 </Rules>
</RuleSet>
Remarks
To set this compiler option in the Visual Studio
development environment
4. Choose OK or Apply to save your changes.
To set external file analysis options in Visual Studio 2019 version 16.10 and later:
1. Open the project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > External Includes property page.
3. Set properties:
Disable Code Analysis for External Headers sets the /analyze:external￾option.
Analysis Ruleset for External Headers sets the /analyze:external:ruleset
path option.
4. Choose OK or Apply to save your changes.
To set this compiler option programmatically
1. See EnablePREfast.
See also
MSVC compiler options
MSVC compiler command-line syntax
/arch (Minimum CPU Architecture)
Article • 07/01/2022
The architecture options specify the architecture for code generation. Select the base
hardware architecture you're working with to see /arch options for that target platform.
/arch (x86)
/arch (x64)
/arch (ARM)
/arch (ARM64)
See also
MSVC compiler options
MSVC compiler command-line syntax
/arch (x86)
Article • 10/16/2024
Specifies the architecture for code generation on x86. For more information on /arch
for other target architectures, see /arch (ARM64), /arch (x64), and /arch (ARM).
Syntax
/arch: [ IA32 | SSE | SSE2 | AVX | AVX2 | AVX512 | AVX10.1 ]
Arguments
/arch:IA32
Specifies no enhanced instructions and also specifies x87 for floating-point calculations.
/arch:SSE
Enables Intel Streaming SIMD Extensions.
/arch:SSE2
Enables Intel Streaming SIMD Extensions 2. The default instruction set is SSE2 if no
/arch option is specified.
/arch:AVX
Enables Intel Advanced Vector Extensions.
/arch:AVX2
Enables Intel Advanced Vector Extensions 2.
/arch:AVX512
Enables Intel Advanced Vector Extensions 512.
/arch:AVX10.1
Enables Intel Advanced Vector Extensions 10 version 1.
Remarks
The /arch option enables or disables the use of certain instruction set extensions,
particularly for vector calculation, available in processors from Intel and AMD. In general,
more recently introduced processors may support extensions beyond the ones
supported by older processors. You should consult the documentation for a particular
processor or test for instruction set extension support using __cpuid before executing
code using an instruction set extension.
/arch only affects code generation for native functions. When you use /clr to compile,
/arch has no effect on code generation for managed functions.
The /arch options refer to instruction set extensions with the following characteristics:
IA32 is the legacy 32-bit x86 instruction set without any vector operations and
using x87 for floating-point calculations.
SSE allows calculation with vectors of up to four single-precision floating-point
values. Corresponding scalar floating-point instructions were added as well.
SSE2 allows calculation with 128-bit vectors of single-precision, double-precision
and 1, 2, 4, or 8-byte integer values. Double-precision scalar instructions were also
added.
AVX introduced an alternative instruction encoding for vector and floating-point
scalar instructions. It allows vectors of either 128 bits or 256 bits, and zero-extends
all vector results to the full vector size. (For legacy compatibility, SSE-style vector
instructions preserve all bits beyond bit 127.) Most floating-point operations are
extended to 256 bits.
AVX2 extends most integer operations to 256-bit vectors, and enables use of Fused
Multiply-Add (FMA) instructions.
AVX512 introduced another instruction encoding form that allows 512-bit vectors,
masking, embedded rounding/broadcast, and new instructions. The default vector
length for AVX512 is 512 bits and can be changed to 256 bits using the /vlen flag.
AVX10.1 adds more instructions on top of AVX-512 . The default vector length for
AVX10.1 is 256 bits and can be changed to 512 bits using the /vlen flag.
The optimizer chooses when and how to use vector instructions depending on which
/arch is specified. Scalar floating-point computations are usually performed with SSE or
AVX instructions when available. Some calling conventions specify passing floating-point
arguments on the x87 stack, and as a result, your code may use a mixture of both x87
and SSE/AVX instructions for floating-point computations. Integer vector instructions
can also be used for some 64-bit integer operations when available.
In addition to the vector and floating-point scalar instructions, each /arch option may
also enable the use of other non-vector instructions that are associated with that option.
An example is the CMOVcc instruction family that first appeared on the Intel Pentium
Pro processors. Because SSE instructions were introduced with the subsequent Intel
Pentium III processor, CMOVcc instructions may be generated except when /arch:IA32
is specified.
Floating-point operations are normally rounded to double-precision (64-bit) in x87
code, but you can use _controlfp to modify the FP control word, including setting the
precision control to extended precision (80-bit) or single-precision (32-bit). For more
information, see _control87, _controlfp, __control87_2. SSE and AVX have separate
single-precision and double-precision instructions for each operation, so there's no
equivalent for SSE/AVX code. It can change how results are rounded when the result of a
floating-point operation is used directly in further calculation instead of assigning it to a
user variable. Consider the following operations:
C++
With explicit assignment:
C++
/arch and /QIfist can't be used together. The /QIfist option changes the rounding
behavior of floating-point to integer conversion. The default behavior is to truncate
(round toward zero), whereas the /QIfist option specifies use of the floating-point
environment rounding mode. Because the option changes the behavior of all floating￾point to integer conversions, /QIfist is deprecated. When compiling for SSE or AVX,
you can round a floating-point value to an integer using the floating-point environment
rounding mode by using an intrinsic function sequence:
C++
r = f1 * f2 + d; // Different results are possible on SSE/SSE2.
t = f1 * f2; // Do f1 * f2, round to the type of t.
r = t + d; // This should produce the same overall result
 // whether x87 stack is used or SSE/SSE2 is used.
int convert_float_to_int(float x) {
 return _mm_cvtss_si32(_mm_set_ss(x));
}
int convert_double_to_int(double x) {
 return _mm_cvtsd_si32(_mm_set_sd(x));
}
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
The _M_IX86_FP , __AVX__ , __AVX2__ , __AVX512F__ , __AVX512CD__ , __AVX512BW__ ,
__AVX512DQ__ , __AVX512VL__ , and __AVX10_VER__ macros indicate which, if any, /arch
compiler option was used. For more information, see Predefined macros. The
/arch:AVX2 option, and __AVX2__ macro were introduced in Visual Studio 2013 Update
2, version 12.0.34567.1. Limited support for /arch:AVX512 was added in Visual Studio
2017, and expanded in Visual Studio 2019. Support for /arch:AVX10.1 was added in
Visual Studio 2022.
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable Enhanced Instruction Set property.
See EnableEnhancedInstructionSet.
/arch (Minimum CPU Architecture)
MSVC compiler options
MSVC compiler command-line syntax
To set the /arch compiler option in Visual Studio
To set this compiler option programmatically
See also
 Yes  No
/arch (x64)
Article • 10/16/2024
Specifies the architecture for code generation on x64. For more information on /arch
for other target architectures, see /arch (x86), /arch (ARM64), and /arch (ARM).
Syntax
/arch: [ SSE2 | SSE4.2 | AVX | AVX2 | AVX512 | AVX10.1 ]
Arguments
/arch:SSE2
Enables Intel Streaming SIMD Extensions 2. The default instruction set is SSE2 if no
/arch option is specified.
/arch:SSE4.2
Enables Intel Streaming SIMD Extensions 4.2.
/arch:AVX
Enables Intel Advanced Vector Extensions.
/arch:AVX2
Enables Intel Advanced Vector Extensions 2.
/arch:AVX512
Enables Intel Advanced Vector Extensions 512.
/arch:AVX10.1
Enables Intel Advanced Vector Extensions 10 version 1.
Remarks
The /arch option enables the use of certain instruction set extensions, particularly for
vector calculation, available in processors from Intel and AMD. In general, more recently
introduced processors may support extensions beyond the ones supported by older
processors, although you should consult the documentation for a particular processor or
test for instruction set extension support using __cpuid before executing code using an
instruction set extension.
/arch only affects code generation for native functions. When you use /clr to compile,
/arch has no effect on code generation for managed functions.
The processor extensions have the following characteristics:
The default mode uses SSE2 instructions for scalar floating-point and vector
calculations. These instructions allow calculation with 128-bit vectors of single￾precision, double-precision and 1, 2, 4 or 8-byte integer values, as well as single￾precision and double-precision scalar floating-point values.
SSE4.2 uses the full set of SSE instructions for floating-point scalar, vector, and
integer vector calculations.
AVX introduced an alternative instruction encoding for vector and floating-point
scalar instructions. It allows vectors of either 128 bits or 256 bits, and zero-extends
all vector results to the full vector size. (For legacy compatibility, SSE-style vector
instructions preserve all bits beyond bit 127.) Most floating-point operations are
extended to 256 bits.
AVX2 extends most integer operations to 256-bit vectors and enables use of Fused
Multiply-Add (FMA) instructions.
AVX-512 introduced another instruction encoding form that allows 512-bit vectors,
masking, embedded rounding/broadcast, and new instructions. The default vector
length for AVX-512 is 512 bits and can be changed to 256 bits using the /vlen flag.
AVX10.1 adds more instructions on top of AVX-512 . The default vector length for
AVX10.1 is 256 bits and can be changed to 512 bits using the /vlen flag.
Each /arch option may also enable the use of other non-vector instructions that are
associated with that option. An example is the use of certain BMI instructions when
/arch:AVX2 is specified.
The __AVX__ preprocessor symbol is defined when the /arch:AVX , /arch:AVX2 ,
/arch:AVX512 , or /arch:AVX10.1 compiler option is specified. The __AVX2__ preprocessor
symbol is defined when the /arch:AVX2 , /arch:AVX512 , or /arch:AVX10.1 compiler
option is specified. The __AVX512F__ , __AVX512CD__ , __AVX512BW__ , __AVX512DQ__ , and
__AVX512VL__ preprocessor symbols are defined when the /arch:AVX512 , or
/arch:AVX10.1 compiler option is specified. The __AVX10_VER__ preprocessor symbol is
defined when the /arch:AVX10.1 compiler option is specified. It indicates the AVX10
version the compiler is targeting. For more information, see Predefined macros. The
/arch:AVX2 option was introduced in Visual Studio 2013 Update 2, version 12.0.34567.1.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Limited support for /arch:AVX512 was added in Visual Studio 2017, and expanded in
Visual Studio 2019. Support for /arch:AVX10.1 was added in Visual Studio 2022.
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable Enhanced Instruction Set property.
See EnableEnhancedInstructionSet.
/arch (Minimum CPU Architecture)
MSVC compiler options
MSVC compiler command-line syntax
To set the /arch compiler option in Visual Studio
To set this compiler option programmatically
See also
 Yes  No
/arch (ARM)
Article • 07/01/2022
Specifies the architecture for code generation on ARM. For more information on /arch
for other target architectures, see /arch (ARM64), /arch (x64), and /arch (x86)
Syntax
/arch: [ ARMv7VE | VFPv4 ]
Arguments
/arch:ARMv7VE
Enables the use of ARMv7VE Virtualization Extensions instructions.
/arch:VFPv4
Enables the use of ARM VFPv4 instructions. If this option isn't specified, VFPv3 is the
default.
Remarks
The _M_ARM_FP macro (for ARM only) indicates which, if any, /arch compiler option was
used. For more information, see Predefined macros.
When you use /clr to compile, /arch has no effect on code generation for managed
functions. /arch only affects code generation for native functions.
To set the /arch:ARMv7VE or /arch:VFPv4 compiler option
in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /arch:ARMv7VE or /arch:VFPv4 .
To set this compiler option programmatically
See EnableEnhancedInstructionSet.
See also
/arch (Minimum CPU architecture)
MSVC compiler options
MSVC compiler command-line syntax
/arch (ARM64)
Article • 06/13/2024
Specifies the Arm A-Profile architecture extension for code generation on ARM64. For
more information about /arch for other target architectures, see /arch (x86), /arch (x64),
and /arch (ARM).
/arch:
<armv8.0|armv8.1|armv8.2|armv8.3|armv8.4|armv8.5|armv8.6|armv8.7|armv8.8|armv8.
9> [+feature]
/arch:<armv9.0|armv9.1|armv9.2|armv9.3|armv9.4> [+feature]
/arch:armv8.x
Specifies the Armv8-A architecture, where x is a required extension value from 0 to 9 .
By default, the compiler uses the /arch:armv8.0 behavior if no architecture is specified.
/arch:armv9.x
Specifies the Armv9-A architecture, where x is a required extension value from 0 to 4 .
By default, the compiler uses the /arch:armv8.0 behavior if no architecture is specified.
You can specify an ARM64 extension from Armv8.0-A through Armv8.9-A, and Armv9.0-
A through Armv9.4-A. Optionally, enable one or more architecture features by
appending a feature argument to the option . For example, to target Armv8.0-A and
enable feature FEAT_LSE , append feature argument lse so that the option becomes
/arch:armv8.0+lse . For more information about available features and their
requirements, see /feature (ARM64) .
Syntax
Arguments
1
2
Remarks
3
3
７ Note
Depending on your version of Visual Studio, the compiler may not yet generate
instructions from all feature sets required by the extension level you specify. For
example, /arch:armv8.1 allows the *Interlocked* intrinsic functions to use the
The _M_ARM64 macro is defined by default when compiling for an ARM64 target. For
more information, see Predefined macros\
The __ARM_ARCH macro is defined for /arch:ARMv8.0 and higher. It indicates the ARM
architecture extension level that the compiler is targeting. For more information, see
Predefined macros.
C++
/arch only affects code generation for native functions. When you use /clr to compile,
/arch has no effect on code generation for managed functions.
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /arch:armv8.0 or replace armv8.0 with a
different ARM64 extension. Choose OK to save your changes.
See AdditionalOptions.
 Armv8-A architecture extension armv8.9 is available starting in Visual Studio 2022
version 17.10.
 Armv9-A architecture extensions are available starting in Visual Studio 2022 version
17.10.
 Architecture feature enablement is available starting in Visual Studio 2022 version
17.10.
appropriate atomic instruction introduced with the Armv8.1-A extension feature
FEAT_LSE , but compiler support requires Visual Studio 2022 version 17.2 or later.
#if __ARM_ARCH >= 802
 // code that requires ARMv8.2...
#endif
To set the /arch compiler option in Visual Studio
To set this compiler option programmatically
1
2
3
See also
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
/arch (Minimum CPU architecture)
Predefined macros
MSVC compiler options
MSVC compiler command-line syntax
 Yes  No
/await (Enable coroutine support)
Article • 08/03/2021
Use the /await compiler option to enable compiler support for coroutines.
Syntax
/await
/await:strict
Remarks
The /await compiler option enables compiler support for C++ coroutines and the
keywords co_await , co_yield , and co_return . This option is off by default. For
information about support for coroutines in Visual Studio, see the Visual Studio Team
Blog . For more information about the coroutines standard proposal, see N4628
Working Draft, Technical Specification for C++ Extensions for Coroutines .
The /await option is available beginning in Visual Studio 2015.
Starting in Visual Studio 2019 version 16.10, the /await:strict option can be used in
place of /await . The option provides C++20-compatible coroutine support in projects
that build in C++14 or C++17 mode. In /await:strict mode, library support is
provided in <coroutine> and in the std namespace.
The /await:strict option disables language extensions present in /await that weren't
adopted into the C++20 standard. Use of such features results in a compiler error. The
option also implements coroutine behaviors such as promise parameter preview. These
behaviors aren't available under /await because of binary compatibility issues in older
versions of Visual Studio.
７ Note
Coroutine state objects obtained from coroutine_handle<T>::address() aren't
compatible between /await and /await:strict modes. Use of
coroutine_handle<T>::from_address() on an address obtained from a coroutine
handle created by code compiled in an incompatible mode results in undefined
behavior.
To set this compiler option in the Visual Studio
development environment
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /await or /await:strict compiler option in the Additional Options box.
Choose OK or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/bigobj (Increase Number of Sections in
.Obj file)
Article • 08/03/2021
/bigobj increases the number of sections that an object file can contain.
Syntax
/bigobj
Remarks
By default, an object file can hold up to 65,279 (almost 2^16) addressable sections. This
limit applies no matter which target platform is specified. /bigobj increases that address
capacity to 4,294,967,296 (2^32).
Most modules never generate an .obj file that contains more than 65,279 sections.
However, machine-generated code, or code that makes heavy use of template libraries,
may require .obj files that can hold more sections. /bigobj is enabled by default on
Universal Windows Platform (UWP) projects because the machine-generated XAML
code includes a large number of headers. If you disable this option on a UWP app
project, your code may generate compiler error C1128.
For information on the PE-COFF object file format, see PE Format in the Windows
documentation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /bigobj compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/C (Preserve Comments During
Preprocessing)
Article • 08/03/2021
Preserves comments during preprocessing.
Syntax
/C
Remarks
This compiler option requires the /E, /P, or /EP option.
The following code sample will display the source code comment.
C++
// C_compiler_option.cpp
// compile with: /E /C /c
int i; // a variable
This sample will produce the following output.
#line 1 "C_compiler_option.cpp"
int i; // a variable
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Modify the Keep Comments property.
To set this compiler option programmatically
See KeepComments.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/E (Preprocess to stdout)
/P (Preprocess to a File)
/EP (Preprocess to stdout Without #line Directives)
/c (Compile Without Linking)
Article • 08/03/2021
Prevents the automatic call to LINK.
Syntax
/c
Remarks
Compiling with /c creates .obj files only. You must call LINK explicitly with the proper
files and options to perform the linking phase of the build.
Any internal project created in the development environment uses the /c option by
default.
To set this compiler option in the Visual Studio
development environment
This option is not available from within the development environment.
To set this compiler option programmatically
To set this compiler option programmatically, see CompileOnly.
Example
The following command line creates the object files FIRST.obj and SECOND.obj.
THIRD.obj is ignored.
CL /c FIRST.C SECOND.C THIRD.OBJ
To create an executable file, you must invoke LINK:
LINK firsti.obj second.obj third.obj /OUT:filename.exe
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/cgthreads (Code generation threads)
Article • 08/03/2021
Sets number of cl.exe threads to use for optimization and code generation.
Syntax
/cgthreads1
/cgthreads2
/cgthreads3
/cgthreads4
/cgthreads5
/cgthreads6
/cgthreads7
/cgthreads8
Arguments
cgthreadsN
The maximum number of threads for cl.exe to use, where N is a number in the range 1
to 8.
Remarks
The cgthreads option specifies the maximum number of threads cl.exe uses in parallel
for the optimization and code generation phases of compilation. Notice that there can
be no space between cgthreads and the number argument. By default, cl.exe uses four
threads, as if /cgthreads4 were specified. If more processor cores are available, a larger
number value can improve build times. This option is especially useful when it's
combined with /GL (Whole Program Optimization).
Multiple levels of parallelism can be specified for a build. The msbuild.exe switch
/maxcpucount specifies the number of MSBuild processes that can be run in parallel. The
/MP (Build with Multiple Processes) compiler flag specifies the number of cl.exe
processes that simultaneously compile the source files. The cgthreads option specifies
the number of threads used by each cl.exe process. The processor can only run as many
threads at the same time as there are processor cores. It's not useful to specify larger
values for all of these options at the same time, and it can be counterproductive. For
more information about how to build projects in parallel, see Building Multiple Projects
in Parallel.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include cgthreadsN , where N is a value
from 1 to 8, and then select OK.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/clr (Common Language Runtime
Compilation)
Article • 10/29/2021
Enables applications and components to use features from the common language
runtime (CLR) and enables C++/CLI compilation.
Syntax
/clr [ : options]
Arguments
options
One or more of the following comma-separated arguments.
none
With no options, /clr creates metadata for the component. The metadata can be
consumed by other CLR applications, and enables the component to consume
types and data in the metadata of other CLR components. For more information,
see Mixed (Native and Managed) Assemblies.
netcore
Available starting in Visual Studio 2019 version 16.4, /clr:netcore creates
metadata and code for the component using the latest cross-platform .NET
framework, also known as .NET Core. The metadata can be consumed by other
.NET Core applications. And, the option enables the component to consume types
and data in the metadata of other .NET Core components.
nostdlib
Instructs the compiler to ignore the default \clr directory. The compiler produces
errors if you include multiple versions of a DLL, such as System.dll. This option lets
you specify the specific framework to use during compilation.
pure
/clr:pure is deprecated. The option is removed in Visual Studio 2017 and later.
We recommend that you port code that must be pure MSIL to C#.
safe
/clr:safe is deprecated. The option is removed in Visual Studio 2017 and later.
We recommend that you port code that must be safe MSIL to C#.
noAssembly
/clr:noAssembly is deprecated. Use /LN (Create MSIL Module) instead.
Tells the compiler not to insert an assembly manifest into the output file. By
default, the noAssembly option isn't in effect.
A managed program that doesn't have assembly metadata in the manifest is
known as a module. The noAssembly option can be used only to produce a module.
If you compile by using /c and /clr:noAssembly , then specify the /NOASSEMBLY
option in the linker phase to create a module.
Before Visual Studio 2005, /clr:noAssembly required /LD . /LD is now implied
when you specify /clr:noAssembly .
initialAppDomain
initialAppDomain is obsolete. Enables a C++/CLI application to run on version 1 of
the CLR. An application that's compiled by using initialAppDomain shouldn't be
used by an application that uses ASP.NET because it's not supported in version 1
of the CLR.
Remarks
Managed code is code that can be inspected and managed by the CLR. Managed code
can access managed objects. For more information, see /clr Restrictions.
For information about how to develop applications that define and consume managed
types in C++, see Component Extensions for Runtime Platforms.
An application compiled by using /clr may or may not contain managed data.
To enable debugging on a managed application, see /ASSEMBLYDEBUG (Add
DebuggableAttribute).
Only CLR types are instantiated on the garbage-collected heap. For more information,
see Classes and Structs. To compile a function to native code, use the unmanaged
pragma. For more information, see managed, unmanaged.
By default, /clr isn't in effect. When /clr is in effect, /MD is also in effect. For more
information, see /MD, /MT, /LD (Use Run-Time Library). /MD ensures that the
dynamically linked, multithreaded versions of the runtime routines are selected from the
standard header files. Multithreading is required for managed programming because
the CLR garbage collector runs finalizers in an auxiliary thread.
If you compile by using /c , you can specify the CLR type of the resulting output file by
using the /CLRIMAGETYPE linker option.
/clr implies /EHa , and no other /EH options are supported for /clr . For more
information, see /EH (Exception Handling Model).
For information about how to determine the CLR image type of a file, see /CLRHEADER.
All modules passed to a given invocation of the linker must be compiled by using the
same run-time library compiler option ( /MD or /LD ).
Use the /ASSEMBLYRESOURCE linker option to embed a resource in an assembly.
/DELAYSIGN, /KEYCONTAINER, and /KEYFILE linker options also let you customize how
an assembly is created.
When /clr is used, the _MANAGED symbol is defined to be 1. For more information, see
Predefined macros.
The global variables in a native object file are initialized first (during DllMain if the
executable is a DLL), and then the global variables in the managed section are initialized
(before any managed code is run). #pragma init_seg only affects the order of
initialization in the managed and unmanaged categories.
Metadata and Unnamed Classes
Unnamed classes appear in metadata under names such as $UnnamedClass$<crc-of￾current-file-name>$<index>$ , where <index> is a sequential count of the unnamed
classes in the compilation. For example, the following code sample generates an
unnamed class in metadata.
C++
// clr_unnamed_class.cpp
// compile by using: /clr /LD
class {} x;
Use ildasm.exe to view metadata.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Set the Configuration dropdown to All configurations, and set the Platform
dropdown to All Platforms.
3. Select the Configuration Properties > C/C++ > General page.
4. Modify the Common Language Runtime Support property. Choose OK to save
your changes.
７ Note
In the Visual Studio IDE, the /clr compiler option can be individually set on the
Configuration Properties > C/C++ > General page of the Property Pages dialog.
However, we recommend you use a CLR template to create your project. It sets all
of the properties required for successful creation of a CLR component. Another way
to set these properties is to use the Common Language Runtime Support property
on the Configuration Properties > Advanced page of the Property Pages dialog.
This property sets all the other CLR-related tool options at once.
To set this compiler option programmatically
See CompileAsManaged.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/clr Restrictions
Article • 03/02/2022
Note the following restrictions on the use of /clr :
In a structured exception handler, there are restrictions on using _alloca when
compiling with /clr . For more information, see _alloca.
The use of run-time error checks isn't valid with /clr . For more information, see
How to: Use native run-time checks.
When /clr is used to compile a program that only uses standard C++ syntax, the
following guidelines apply to the use of inline assembly:
Inline assembly code that assumes knowledge of the native stack layout, calling
conventions outside of the current function, or other low-level information
about the computer may fail if that knowledge is applied to the stack frame for
a managed function. Functions containing inline assembly code are generated
as unmanaged functions, as if they were placed in a separate module that was
compiled without /clr .
Inline assembly code in functions that pass copy-constructed function
parameters isn't supported.
The vprintf Functions can't be called from a program compiled with /clr .
The naked __declspec modifier is ignored under /clr .
The translator function set by _set_se_translator will affect only catches in
unmanaged code. For more information, see Exception handling.
The comparison of function pointers isn't permitted under /clr .
The use of functions that aren't fully prototyped isn't permitted under /clr .
The following compiler options aren't supported with /clr :
/EHsc and /EHs ( /clr implies /EHa (see /EH (Exception Handling Model))
/fp:strict and /fp:except (see /fp (Specify Floating-Point Behavior))
/Zd
/Gm
/MT
/RTC
/ZI
The combination of the _STATIC_CPPLIB preprocessor definition
( /D_STATIC_CPPLIB ) and the /clr compiler option isn't supported. It's because the
definition would cause your application to link with the static, multithreaded C++
Standard Library, which isn't supported. For more information, see /MD, /MT, /LD
(Use Run-Time Library).
When you use /Zi with /clr , there are performance implications. For more
information, see /Zi.
Passing a wide character to a .NET Framework output routine without also
specifying /Zc:wchar_t or without casting the character to _wchar_t will cause the
output to appear as an unsigned short int . For example:
C++
Console::WriteLine(L' ') // Will output 32.
Console::WriteLine((__wchar_t)L' ') // Will output a space.
/GS is ignored when compiling with /clr , unless a function is under #pragma
unmanaged or if the function must be compiled as native code, in which case the
compiler will generate warning C4793, which is off by default.
See /ENTRY for function signature requirements of a managed application.
Applications compiled with /openmp and /clr can only be run in a single
appdomain process. For more information, see /openmp (Enable OpenMP 2.0
Support).
Functions that take a variable number of arguments (varargs) will be generated as
native functions. Any managed data types in the variable argument position will be
marshaled to native types. Any System.String types are actually wide-character
strings, but they're marshaled to single-byte character strings. So if a printf
specifier is %S ( wchar_t* ), it will marshal to a %s string instead.
When using the va_arg macro, you may get unexpected results when compiling
with /clr:pure . For more information, see va_arg, va_copy, va_end, va_start. The
/clr:pure and /clr:safe compiler options are deprecated in Visual Studio 2015
and unsupported in Visual Studio 2017 and later. Code that must be "pure" or
"safe" should be ported to C#.
You shouldn't call any functions that walk the stack to get parameter information
(function arguments) from managed code. The P/Invoke layer causes that
information to be further down the stack. For example, don't compile proxy/stub
with /clr .
Functions will be compiled to managed code whenever possible, but not all C++
constructs can be translated to managed code. This determination is made on a
function-by-function basis. If any part of a function can't be converted to managed
code, the entire function will be converted to native code instead. The following
cases prevent the compiler from generating managed code.
Compiler-generated thunks or helper functions. Native thunks are generated for
any function call through a function pointer, including virtual function calls.
Functions that call setjmp or longjmp .
Functions that use certain intrinsic routines to directly manipulate machine
resources. For example, the use of __enable and __disable , _ReturnAddress
and _AddressOfReturnAddress , or multimedia intrinsics will all result in native
code.
Functions that follow the #pragma unmanaged directive. (The inverse, #pragma
managed , is also supported.)
A function that contains references to aligned types, that is, types declared
using __declspec(align(...)) .
See also
/clr (Common Language Runtime compilation)
/constexpr (Control constexpr
evaluation)
Article • 08/03/2021
Use the /constexpr compiler options to control parameters for constexpr evaluation at
compile time.
Syntax
/constexpr:depthN
/constexpr:backtraceN
/constexpr:stepsN
Arguments
depthN Limit the depth of recursive constexpr function invocation to N levels. The
default is 512.
backtraceN Show up to N constexpr evaluations in diagnostics. The default is 10.
stepsN Terminate constexpr evaluation after N steps. The default is 100,000.
Remarks
The /constexpr compiler options control compile-time evaluation of constexpr
expressions. Evaluation steps, recursion levels, and backtrace depth are controlled to
prevent the compiler from spending too much time on constexpr evaluation. For more
information on the constexpr language element, see constexpr (C++).
The /constexpr options are available beginning in Visual Studio 2015.
To set this compiler option in the Visual Studio
development environment
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter any /constexpr compiler options in the Additional Options box. Choose OK
or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/D (Preprocessor Definitions)
Article • 08/03/2021
Defines a preprocessing symbol for a source file.
Syntax
/D [ ]name[ = | # [{ string | number }] ]
/D [ ] "name[ = | # [{ string | number }] ] "
Remarks
You can use this symbol together with #if or #ifdef to compile source code
conditionally. The symbol definition remains in effect until it's redefined in the code, or
is undefined in the code by an #undef directive.
/D has the same effect as a #define directive at the beginning of a source code file. The
difference is that /D strips quotation marks on the command line, and a #define
directive keeps them. You can have whitespace between the /D and the symbol. There
can't be whitespace between the symbol and the equals sign, or between the equals
sign and any value assigned.
By default, the value associated with a symbol is 1. For example, /D name is equivalent to
/D name=1 . In the example at the end of this article, the definition of TEST is shown to
print 1 .
Compiling by using /D name= causes the symbol name to have no associated value.
Although the symbol can still be used to conditionally compile code, it otherwise
evaluates to nothing. In the example, if you compile by using /DTEST= , an error occurs.
This behavior resembles the use of #define with or without a value.
The /D option doesn't support function-like macro definitions. To insert definitions that
can't be defined on the command line, consider the /FI (Name forced include file)
compiler option.
You can use /D multiple times on the command line to define more symbols. If the
same symbol is defined more than once, the last definition is used.
This command defines the symbol DEBUG in TEST.c:
Windows Command Prompt
CL /DDEBUG TEST.C
This command removes all occurrences of the keyword __far in TEST.c:
Windows Command Prompt
CL /D __far= TEST.C
The CL environment variable can't be set to a string that contains the equal sign. To use
/D together with the CL environment variable, you must specify the number sign ( # )
instead of the equal sign:
Windows Command Prompt
SET CL=/DTEST#0
When you define a preprocessing symbol at the command prompt, consider both
compiler parsing rules and shell parsing rules. For example, to define a percent-sign
preprocessing symbol ( % ) in your program, specify two percent-sign characters ( %% ) at
the command prompt. If you specify only one, a parsing error is emitted.
Windows Command Prompt
CL /DTEST=%% TEST.C
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Open the drop-down menu of the Preprocessor Definitions property and choose
Edit.
4. In the Preprocessor Definitions dialog box, add, modify, or delete one or more
definitions, one per line. Choose OK to save your changes.
You don't need to include the '/D' option prefix on the definitions you specify here.
In the property page, definitions are separated by semicolons ( ; ).
To set this compiler option programmatically
See PreprocessorDefinitions.
Example
C++
// cpp_D_compiler_option.cpp
// compile with: cl /EHsc /DTEST cpp_D_compiler_option.cpp
#include <stdio.h>
int main( )
{
#ifdef TEST
 printf_s("TEST defined %d\n", TEST);
#else
 printf_s("TEST not defined\n");
#endif
}
Output
TEST defined 1
See also
MSVC compiler options
MSVC compiler command-line syntax
/FI (Name forced include file)
/U, /u (Undefine Symbols)
#undef Directive (C/C++)
#define Directive (C/C++)
/diagnostics (Compiler diagnostic
options)
Article • 08/03/2021
Use the /diagnostics compiler option to specify the display of error and warning
location information.
Syntax
/diagnostics:{caret|classic|column}
Remarks
This option is supported in Visual Studio 2017 and later.
The /diagnostics compiler option controls the display of error and warning information.
The /diagnostics:classic option is the default, which reports only the line number where
the issue was found.
The /diagnostics:column option also includes the column where the issue was found.
This can help you identify the specific language construct or character that is causing
the issue.
The /diagnostics:caret option includes the column where the issue was found and
places a caret (^) under the location in the line of code where the issue was detected.
Note that in some cases, the compiler does not detect an issue where it occurred. For
example, a missing semicolon may not be detected until other, unexpected symbols
have been encountered. The column is reported and the caret is placed where the
compiler detected that something was wrong, which is not always where you need to
make your correction.
The /diagnostics option is available starting in Visual Studio 2017.
To set this compiler option in the Visual Studio
development environment
1. Open your project's Property Pages dialog box.
2. Under Configuration Properties, expand the C/C++ folder and choose the
General property page.
3. Use the dropdown control in the Diagnostics Format field to select a diagnostics
display option. Choose OK or Apply to save your changes.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/doc (Process Documentation
Comments) (C/C++)
Article • 08/03/2021
Causes the compiler to process documentation comments in source code files and to
create an .xdc file for each source code file that has documentation comments.
Syntax
/doc[name]
Arguments
name
The name of the .xdc file that the compiler will create. Only valid when one .cpp file is
passed in the compilation.
Remarks
The .xdc files are processed into an .xml file with xdcmake.exe. For more information, see
XDCMake Reference.
You can add documentation comments to your source code files. For more information,
see Recommended Tags for Documentation Comments.
To use the generated .xml file with IntelliSense, make the file name of the .xml file the
same as the assembly that you want to support and put the .xml file is in the same
directory as the assembly. When the assembly is referenced in the Visual Studio project,
the .xml file is also found. For more information, see Using IntelliSense and Supplying
XML Code Comments.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Output Files property page.
3. Modify the Generate XML Documentation Files property.
To set this linker option programmatically
See GenerateXMLDocumentationFiles.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/E (Preprocess to stdout)
Article • 08/03/2021
Preprocesses C and C++ source files and copies the preprocessed files to the standard
output device.
Syntax
/E
Remarks
In this process, all preprocessor directives are carried out, macro expansions are
performed, and comments are removed. To preserve comments in the preprocessed
output, use the /C (Preserve Comments During Preprocessing) compiler option as well.
/E adds #line directives to the output at the beginning and end of each included file
and around lines removed by preprocessor directives for conditional compilation. These
directives renumber the lines of the preprocessed file. As a result, errors generated
during later stages of processing refer to the line numbers of the original source file
rather than lines in the preprocessed file.
The /E option suppresses compilation. You must resubmit the preprocessed file for
compilation. /E also suppresses the output files from the /FA, /Fa, and /Fm options. For
more information, see /FA, /Fa (Listing File) and /Fm (Name Mapfile).
To suppress #line directives, use the /EP (Preprocess to stdout Without #line Directives)
option instead.
To send the preprocessed output to a file instead of to stdout , use the /P (Preprocess to
a File) option instead.
To suppress #line directives and send the preprocessed output to a file, use /P and /EP
together.
You cannot use precompiled headers with the /E option.
Note that when preprocessing to a separate file, spaces are not emitted after tokens.
This can result in an illegal program or have unintended side effects. The following
program compiles successfully:
#define m(x) x
m(int)main( )
{
 return 0;
}
However, if you compile with:
cl -E test.cpp > test2.cpp
int main in test2.cpp will incorrectly be intmain .
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See GeneratePreprocessedFile.
Example
The following command line preprocesses ADD.C , preserves comments, adds #line
directives, and displays the result on the standard output device:
CL /E /C ADD.C
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/EH (Exception handling model)
Article • 08/03/2021
Specifies the exception handling model support generated by the compiler. Arguments
specify whether to apply catch(...) syntax to both structured and standard C++
exceptions, whether extern "C" code is assumed to throw exceptions, and whether to
optimize away certain noexcept checks.
Syntax
/EHa [ - ]
/EHs [ - ]
/EHc [ - ]
/EHr [ - ]
Arguments
a
Enables standard C++ stack unwinding. Catches both structured (asynchronous) and
standard C++ (synchronous) exceptions when you use catch(...) syntax. /EHa
overrides both /EHs and /EHc arguments.
s
Enables standard C++ stack unwinding. Catches only standard C++ exceptions when
you use catch(...) syntax. Unless /EHc is also specified, the compiler assumes that
functions declared as extern "C" may throw a C++ exception.
c
When used with /EHs , the compiler assumes that functions declared as extern "C" never
throw a C++ exception. It has no effect when used with /EHa (that is, /EHca is
equivalent to /EHa ). /EHc is ignored if /EHs or /EHa aren't specified.
r
Tells the compiler to always generate runtime termination checks for all noexcept
functions. By default, runtime checks for noexcept may be optimized away if the
compiler determines the function calls only non-throwing functions. This option gives
strict C++ conformance at the cost of some extra code. /EHr is ignored if /EHs or /EHa
aren't specified.
-
Clears the previous option argument. For example, /EHsc- is interpreted as /EHs /EHc- ,
and is equivalent to /EHs .
/EH arguments may be specified separately or combined, in any order. If more than one
instance of the same argument is specified, the last one overrides any earlier ones. For
example, /EHr- /EHc /EHs is the same as /EHscr- , and /EHscr- /EHr has the same
effect as /EHscr .
Remarks
Default exception handling behavior
The compiler always generates code that supports asynchronous structured exception
handling (SEH). By default (that is, if no /EHsc , /EHs , or /EHa option is specified), the
compiler supports SEH handlers in the native C++ catch(...) clause. However, it also
generates code that only partially supports C++ exceptions. The default exception
unwinding code doesn't destroy automatic C++ objects outside of try blocks that go
out of scope because of an exception. Resource leaks and undefined behavior may
result when a C++ exception is thrown.
Standard C++ exception handling
Full compiler support for the Standard C++ exception handling model that safely
unwinds stack objects requires /EHsc (recommended), /EHs , or /EHa .
If you use /EHs or /EHsc , then your catch(...) clauses don't catch asynchronous
structured exceptions. Any access violations and managed System.Exception exceptions
go uncaught. And, objects in scope when an asynchronous exception occurs aren't
destroyed, even if the code handles the asynchronous exception. This behavior is an
argument for leaving structured exceptions unhandled. Instead, consider these
exceptions fatal.
When you use /EHs or /EHsc , the compiler assumes that exceptions can only occur at a
throw statement or at a function call. This assumption allows the compiler to eliminate
code for tracking the lifetime of many unwindable objects, which can significantly
reduce code size. If you use /EHa , your executable image may be larger and slower,
because the compiler doesn't optimize try blocks as aggressively. It also leaves in
exception filters that automatically clean up local objects, even if the compiler doesn't
see any code that can throw a C++ exception.
Structured and standard C++ exception handling
The /EHa compiler option enables safe stack unwinding for both asynchronous
exceptions and C++ exceptions. It supports handling of both standard C++ and
structured exceptions by using the native C++ catch(...) clause. To implement SEH
without specifying /EHa , you may use the __try , __except , and __finally syntax. For
more information, see Structured exception handling.
） Important
Specifying /EHa and trying to handle all exceptions by using catch(...) can be
dangerous. In most cases, asynchronous exceptions are unrecoverable and should
be considered fatal. Catching them and proceeding can cause process corruption
and lead to bugs that are hard to find and fix.
Even though Windows and Visual C++ support SEH, we strongly recommend that
you use ISO-standard C++ exception handling ( /EHsc or /EHs ). It makes your code
more portable and flexible. There may still be times you have to use SEH in legacy
code or for particular kinds of programs. It's required in code compiled to support
the common language runtime (/clr), for example. For more information, see
Structured exception handling.
We recommend that you never link object files compiled using /EHa to ones
compiled using /EHs or /EHsc in the same executable module. If you have to
handle an asynchronous exception by using /EHa anywhere in your module, use
/EHa to compile all the code in the module. You can use structured exception
handling syntax in the same module as code that's compiled by using /EHs .
However, you can't mix the SEH syntax with C++ try , throw , and catch in the
same function.
Use /EHa if you want to catch an exception that's raised by something other than a
throw . This example generates and catches a structured exception:
C++
// compiler_options_EHA.cpp
// compile with: /EHa
#include <iostream>
#include <excpt.h>
using namespace std;
void fail()
{
The /clr option implies /EHa (that is, /clr /EHa is redundant). The compiler generates
an error if /EHs or /EHsc is used after /clr . Optimizations don't affect this behavior.
When an exception is caught, the compiler invokes the class destructors for any objects
that are in the same scope as the exception. If an exception isn't caught, those
destructors aren't run.
For information about exception handling restrictions under /clr , see
_set_se_translator.
The /EHr option forces runtime termination checks in all functions that have a noexcept
attribute. By default, runtime checks may be optimized away if the compiler back-end
determines that a function only calls non-throwing functions. Non-throwing functions
are any functions that have an attribute that specifies no exceptions may be thrown.
They include functions marked noexcept , throw() , __declspec(nothrow) , and, when
 // generates SE and attempts to catch it using catch(...)
 try
 {
 int i = 0, j = 1;
 j /= i; // This will throw a SE (divide by zero).
 printf("%d", j);
 }
 catch(...)
 {
 // catch block will only be executed under /EHa
 cout << "Caught an exception in catch(...)." << endl;
 }
}
int main()
{
 __try
 {
 fail();
 }
 // __except will only catch an exception here
 __except(EXCEPTION_EXECUTE_HANDLER)
 {
 // if the exception was not caught by the catch(...) inside fail()
 cout << "An exception was caught in __except." << endl;
 }
}
Exception handling under /clr
Runtime exception checks
/EHc is specified, extern "C" functions. Non-throwing functions also include any that
the compiler has determined are non-throwing by inspection. You can explicitly set the
default behavior by using /EHr- .
A non-throwing attribute isn't a guarantee that exceptions can't be thrown by a
function. Unlike the behavior of a noexcept function, the MSVC compiler considers an
exception thrown by a function declared using throw() , __declspec(nothrow) , or extern
"C" as undefined behavior. Functions that use these three declaration attributes don't
enforce runtime termination checks for exceptions. You can use the /EHr option to help
you identify this undefined behavior, by forcing the compiler to generate runtime
checks for unhandled exceptions that escape a noexcept function.
Set the option in Visual Studio or
programmatically
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select Configuration Properties > C/C++ > Code Generation.
3. Modify the Enable C++ Exceptions property.
Or, set Enable C++ Exceptions to No, and then on the Command Line property
page, in the Additional Options box, add the compiler option.
To set this compiler option programmatically
See ExceptionHandling.
See also
MSVC Compiler options
MSVC Compiler command-line syntax
Errors and exception handling
Exception specifications (throw)
Structured Exception Handling (C/C++)
/EP (Preprocess to stdout Without #line
Directives)
Article • 08/03/2021
Preprocesses C and C++ source files and copies the preprocessed files to the standard
output device.
Syntax
/EP
Remarks
In the process, all preprocessor directives are carried out, macro expansions are
performed, and comments are removed. To preserve comments in the preprocessed
output, use the /C (Preserve Comments During Preprocessing) option with /EP.
The /EP option suppresses compilation. You must resubmit the preprocessed file for
compilation. /EP also suppresses the output files from the /FA, /Fa, and /Fm options. For
more information, see /FA, /Fa (Listing File) and /Fm (Name Mapfile).
Errors generated during later stages of processing refer to the line numbers of the
preprocessed file rather than the original source file. If you want line numbers to refer to
the original source file, use /E (Preprocess to stdout) instead. The /E option adds #line
directives to the output for this purpose.
To send the preprocessed output, with #line directives, to a file, use the /P (Preprocess
to a File) option instead.
To send the preprocessed output to stdout, with #line directives, use /P and /EP
together.
You cannot use precompiled headers with the /EP option.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Modify the Generate Preprocessed File property.
To set this compiler option programmatically
See GeneratePreprocessedFile.
Example
The following command line preprocesses file ADD.C , preserves comments, and displays
the result on the standard output device:
CL /EP /C ADD.C
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/errorReport (Report Internal Compiler
Errors)
Article • 08/03/2021
７ Note
The /errorReport option is deprecated. Starting in Windows Vista, error reporting is
controlled by Windows Error Reporting (WER) settings.
Syntax
/errorReport:[none | prompt | queue | send ]
Remarks
An internal compiler error (ICE) results when the compiler can't process a source code
file. When an ICE occurs, the compiler doesn't produce an output file, or any useful
diagnostic that you can use to fix your code.
The /errorReport arguments are overridden by the Windows Error Reporting service
settings. The compiler automatically sends reports of internal errors to Microsoft, if
reporting is enabled by Windows Error Reporting. No report is sent if disabled by
Windows Error Reporting.
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Error Reporting property.
To set this compiler option programmatically
See ErrorReporting.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/execution-charset (Set execution
character set)
Article • 02/01/2022
This option lets you specify the execution character set for your executable.
Syntax
/execution-charset: [ IANA_name | .CPID ]
Arguments
IANA_name
The IANA-defined character set name.
.CPID
The code page identifier, preceded by a . character.
Remarks
You can use the /execution-charset option to specify an execution character set. The
execution character set is the encoding used for the text of your program that is input
to the compilation phase after all preprocessing steps. This character set is used for the
internal representation of any string or character literals in the compiled code. Set this
option to specify the extended execution character set to use when your source files
include characters that are not representable in the basic execution character set. You
can use either the IANA or ISO character set name, or a dot ( . ) followed by 3-5 decimal
digits that specify the code page identifier of the character set to use. For a list of
supported code page identifiers and character set names, see Code Page Identifiers.
By default, Visual Studio detects a byte-order mark to determine if the source file is in
an encoded Unicode format, for example, UTF-16 or UTF-8. If no byte-order mark is
found, it assumes that the source file is encoded in the current user code page, unless
you used the /source-charset or /utf-8 option to specify a character set name or code
page. Visual Studio allows you to save your C++ source code in any of several character
encodings. For information about source and execution character sets, see Character
sets in the language documentation.
If you want to set both the source character set and the execution character set to UTF-
8, you can use the /utf-8* compiler option as a shortcut. It's equivalent to /source￾charset:utf-8 /execution-charset:utf-8 on the command line. Any of these options
also enables the /validate-charset option by default.
To set this compiler option in the Visual Studio
development environment
1. Open the Property Pages dialog box for your project. For more information, see
Set C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional Options, add the /execution-charset option, and specify your
preferred encoding.
4. Choose OK to save your changes.
See also
MSVC compiler options
MSVC compiler command-line syntax
/source-charset (Set source character set)
/utf-8 (Set source and execution character sets to UTF-8)
/validate-charset (Validate for compatible characters)
/experimental:log (Structured SARIF
diagnostics)
Article • 11/13/2023
Output SARIF diagnostics to the specified file. For more information, see Structured
SARIF Diagnostics.
Syntax
/experimental:log filename
Arguments
filename
Where to output SARIF diagnostics. The .sarif suffix is added to filename to produce
the final filename at which to store the resulting SARIF diagnostics. The space between
/experimental:log and filename is optional. Paths that include spaces must be enclosed
in double quotes. filename may name a relative or absolute path.
Remarks
This option is available starting in Visual Studio 2022 version 17.8.
Diagnostics are also output as text to the console as usual.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the specific project Configuration and Platform for which you want to
change the property. You can also choose "All Configurations" and "All
Platforms".
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional Options property, and then choose OK.
Example
The following command produces SARIF information for the entire compilation in the
diags.sarif file in the current directory:
Windows Command Prompt
CL /experimental:logdiags main.cpp other.cpp
See also
Structured SARIF Diagnostics
/experimental:module (Enable
experimental module support)
Article • 02/14/2025
Enables compiler support for Microsoft's experimental form of C++ Standard modules.
This option is obsolete in Visual Studio 2019 version 16.11 and later.
/experimental:module [ - ]
This switch was for the time before the new, standardized, way of consuming the C++
Standard Library as modules described in Import the C++ standard library using
modules was available. Although you can use this switch to use the older experimental
named modules, we recommend that you use the new, standardized, way of consuming
the C++ Standard Library as modules described in Import the C++ standard library
using modules.
This compiler became available starting in Visual Studio 2015 Update 1. Ensure that C++
Modules for v143 build tools (x64/x86 - experimental) in selected the VS Installer. It's
available in the Individual components tab of the installer. Search for experimental to
see the option. For more information, see Install C and C++ support in Visual Studio.
Version Status
Visual Studio 2015
Update 1
/experimental:module introduced.
Visual Studio 2019
version 16.10
C++20 modules support is feature complete.
Visual Studio 2019
16.11 and earlier
Enable experimental modules support using /experimental:module along
with /std:c++latest.
Visual Studio 2019
version 16.11 and
later
Modules support is enabled automatically with /std:c++20 or later, or
/std:c++latest . Use /experimental:module- to disable experimental
module support.
Syntax
Remarks
ﾉ Expand table
The experimental library consists of the following named modules:
std.regex provides the content of header <regex>
std.filesystem provides the content of header <filesystem>
std.memory provides the content of header <memory>
std.threading provides the contents of headers <atomic> , <condition_variable> ,
<future> , <mutex> , <shared_mutex> , and <thread>
std.core provides everything else in the C++ Standard Library
To consume these modules, add an import declaration to the top of the source code file.
For example:
C++
import std.core;
import std.regex;
To consume the experimental Microsoft Standard Library modules, compile your
program with the /EHsc and /MD options.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Set the Configuration drop-down to All Configurations.
3. Select the Configuration Properties > C/C++ > Language property page.
4. Modify the Enable C++ Modules (experimental) property, and then choose OK.
For more information about how to use and create modules, see Overview of modules
in C++.
See also
/headerUnit (Use header unit IFC)
/exportHeader (Create header units)
/reference (Use named module IFC)
/translateInclude (Translate include directives into import directives)
/Zc (Conformance)
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
/experimental:preprocessor (Enable
preprocessor conformance mode)
Article • 08/03/2021
This option is obsolete starting in Visual Studio 2019 version 16.5, replaced by the
/Zc:preprocessor compiler option. /experimental:preprocessor enables an experimental,
token-based preprocessor that more closely conforms to C++11 standards, including
C99 preprocessor features. For more information, see MSVC new preprocessor overview.
Syntax
/experimental:preprocessor [ - ]
Remarks
Use the /experimental:preprocessor compiler option to enable the experimental
conforming preprocessor. You can use /experimental:preprocessor- option to explicitly
specify the traditional preprocessor.
The /experimental:preprocessor option is available starting in Visual Studio 2017
version 15.8. Starting in Visual Studio 2019 version 16.5, the new preprocessor is
complete, and available under the /Zc:preprocessor compiler option.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /experimental:preprocessor
and then choose OK.
See also
/Zc (Conformance)
/external (External headers diagnostics)
Article • 06/30/2022
The /external compiler options let you specify compiler diagnostic behavior for certain
header files. "External" headers are the natural complement of "Just my code": Header
files such as system files or third-party library files that you can't or don't intend to
change. Since you aren't going to change these files, you may decide it isn't useful to
see diagnostic messages from the compiler about them. The /external compiler
options give you control over these warnings.
The /external compiler options are available starting in Visual Studio 2017 version 15.6.
In versions of Visual Studio before Visual Studio 2019 version 16.10, the /external
options require you also set the /experimental:external compiler option.
Syntax
Use external header options (Not required in 16.10 and later):
/experimental:external
Specify external headers:
/external:anglebrackets
/external:env: var
/external:I path
Specify diagnostics behavior:
/external:W0
/external:W1
/external:W2
/external:W3
/external:W4
/external:templates￾Arguments
/experimental:external
Enables the external headers options. This option isn't required in Visual Studio 2019
version 16.10 and later.
/external:anglebrackets
Treats all headers included by #include <header> , where the header file is enclosed in
angle brackets ( < > ), as external headers.
/external:I path
Defines a root directory that contains external headers. All recursive subdirectories of
path are considered external, but only the path value is added to the list of directories
the compiler searches for include files. The space between /external:I and path is
optional. Directories that include spaces must be enclosed in double quotes. A directory
may be an absolute path or a relative path.
/external:env: var
Specifies the name of an environment variable var that holds a semicolon-separated list
of external header directories. It's useful for build systems that rely on environment
variables such as INCLUDE , which you use to specify the list of external include files. Or,
CAExcludePath , for files that shouldn't be analyzed by /analyze . For example, you can
specify /external:env:INCLUDE to make every directory in INCLUDE an external header
directory at once. It's the same as using /external:I to specify the individual directories,
but much less verbose. There should be no space between var and /external:env: .
/external:Wn
This option sets the default warning level to n (a value from 0 to 4) for external headers.
For example, /external:W0 effectively turns off warnings for external headers. If this
option isn't specified, the compiler issues command line warning D9007 for other
/external options. Those options are ignored, because they would have no effect.
The /external:Wn option has an effect similar to wrapping an included header in a
#pragma warning directive:
C++
#pragma warning (push, 0)
// the global warning level is now 0 here
#include <external_header>
#pragma warning (pop)
/external:templates￾Allows warnings from external headers when they occur in a template that's instantiated
in your code.
By default, the /Wn warning level you specify for your build applies to all files. The
options to specify external headers only define a set of files to which you can apply a
different default warning level. So, if you specify external headers, also use /external:Wn
to specify an external warning level to change compiler behavior.
All the existing mechanisms to enable, disable, and suppress warnings still work in both
external and non-external files. For example, a warning pragma can still override the
default warning level you set for external headers.
This sample program has two source files, program.cpp and header_file.h . The
header_file.h file is in an include_dir subdirectory of the directory containing the
program.cpp file:
Source file include_dir/header_file.h :
C++
Source file program.cpp :
C++
Remarks
Example: Set external warning level
// External header: include_dir/header_file.h
template <typename T>
struct sample_struct
{
 static const T value = -7; // W4: warning C4245: 'initializing':
 // conversion from 'int' to 'unsigned int', signed/unsigned mismatch
};
// User code: program.cpp
#include <header_file.h>
int main()
{
 return sample_struct<unsigned int>().value;
}
You can build the sample by using this command line:
Windows Command Prompt
cl /EHsc /I include_dir /W4 program.cpp
As expected, this sample generates a warning:
Output
program.cpp
include_dir\header_file.h(6): warning C4245: 'initializing': conversion from
'int' to 'const T', signed/unsigned mismatch
 with
 [
 T=unsigned int
 ]
program.cpp(6): note: see reference to class template instantiation
'sample_struct<unsigned int>' being compiled
To treat the header file as an external file and suppress the warning, you can use this
command line instead*:
Windows Command Prompt
cl /EHsc /I include_dir /external:anglebrackets /external:W0 /W4 program.cpp
This command line suppresses the warning inside header_file.h while preserving
warnings inside program.cpp .
Warnings across the internal and external boundary
Setting a low warning level for external headers can hide some actionable warnings. In
particular, it can turn off warnings emitted on template instantiations in user code.
These warnings might indicate a problem in your code that only happens in
instantiations for particular types. (For example, if you forgot to apply a type trait
removing const or & .) To avoid silencing warnings inside templates defined in external
headers, you can use the /external:templates- option. The compiler considers both the
effective warning level in the file that defines the template, and the warning level where
template instantiation occurs. Warnings emitted inside an external template appear if
the template is instantiated within non-external code. For example, this command line
re-enables warnings from template sources in the sample code*:
Windows Command Prompt
The C4245 warning appears again in the output, even though the template code is
inside an external header.
All the existing mechanisms to enable, disable, and suppress warnings still work in
external headers. When a warning appears because you use the /external:templates￾option, you can still suppress the warning at the point of instantiation. For example, to
explicitly suppress the warning in the sample that reappears because of
/external:templates- , use a warning pragma directive:
C++
Library writers can use the same mechanisms to enforce certain warnings, or all the
warnings at certain level, if they feel those warnings should never be silenced by
/external:Wn . For example, this version of the header file forces warning C4245 to
report an error:
C++
cl /EHsc /I include_dir /external:anglebrackets /external:W0
/external:templates- /W4 program.cpp
Enable, disable, or suppress warnings
int main()
{
 #pragma warning( suppress : 4245)
 return sample_struct<unsigned int>().value;
}
// External header: include_dir/header_file.h
#pragma warning( push, 4 )
#pragma warning( error : 4245 )
template <typename T>
struct sample_struct
{
 static const T value = -7; // W4: warning C4245: 'initializing':
conversion from 'int'
 // to 'unsigned int', signed/unsigned
mismatch
};
#pragma warning( pop )
With this change to the library header, the author of the library ensures that the global
warning level in this header is 4, no matter what gets specified in /external:Wn . Now all
level 4 and above warnings are reported. The library author can also force certain
warnings to be errors, disabled, suppressed, or emitted only once in the header. The
/external options don't override that deliberate choice.
system_header pragma
#pragma system_header is an intrusive marker that allows library writers to mark certain
headers as external. A file containing #pragma system_header is considered external from
the point of the pragma to the end of the file, as if it were specified as external on the
command line. The compiler emits any diagnostics after the pragma at the warning level
specified by /external:Wn . For more information, see system_header pragma.
Limitations
Some warnings emitted by the compiler's back-end code generation aren't affected by
the /external options. These warnings usually start with C47XX, though not all C47XX
warnings are back-end warnings. You can still disable these warnings individually by
using /wd47XX . Code analysis warnings are also unaffected, since they don't have
warning levels.
To set this compiler option in the Visual Studio
development environment
In Visual Studio 2019 version 16.10 and later:
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > VC++ Directories property page.
3. Set the External Include Directories property to specify the IDE equivalent of the
/external:I path option for each semicolon-delimited path.
4. Select the Configuration Properties > C/C++ > External Includes property page.
5. Set properties:
Set Treat Files Included with Angle Brackets as External to Yes to set the
/external:anglebrackets option.
External Header Warning Level allows you to set the /external:Wn option. If
this value is set to Inherit Project Warning Level or the default, other
/external options are ignored.
Set Template Diagnostics in External Headers to Yes to set the
/external:templates- option.
6. Choose OK or Apply to save your changes.
In versions of Visual Studio before Visual Studio 2019 version 16.10:
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /experimental:external option and other /external compiler options in
the Additional Options box.
4. Choose OK or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
* Add the /experimental:external option to enable the external headers options in
versions of Visual Studio before Visual Studio 2019 version 16.10.
See also
MSVC compiler options
MSVC compiler command-line syntax
/F (Set Stack Size)
Article • 08/03/2021
Sets the program stack size in bytes.
Syntax
/F number
Arguments
number
The stack size in bytes.
Remarks
Without this option, the stack size defaults to 1 MB. The number argument can be in
decimal or C-language notation. The argument can range from 1 to the maximum stack
size accepted by the linker. The linker rounds up the specified value to the nearest
multiple of 4 bytes. The space between /F and number is optional.
You may need to increase the stack size if your program gets stack-overflow messages
at runtime.
You can also set the stack size by:
Using the /STACK linker option. For more information, see /STACK (Stack
allocations).
Using EDITBIN on the EXE file. For more information, see EDITBIN reference.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
Output-File (/F) Options
Article • 08/03/2021
The output-file options create or rename output files. They affect all C or C++ source
files specified in the CL environment variable, on the command line, or in any command
file.
/FA, /Fa (Listing File)
Specifying the Pathname
/Fd (Name PDB File)
/Fe (Name EXE File)
/FI (Name Forced Include File)
/Fm (Name Mapfile)
/Fo (Name Object File)
/Fp (Name .pch File)
/FR, /Fr (Create .sbr File)
/FU (Name Forced #using File)
/Fx (Merge Injected Code)
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/FA , /Fa (Listing file)
Article • 08/03/2021
Creates a listing file containing assembler code.
Syntax
/FA [ c ][ s ][ u ]
/Fa pathname
Remarks
The /FA compiler option generates an assembler listing file for each translation unit in
the compilation, which generally corresponds to a C or C++ source file. By default, only
assembler is included in the listing file, which is encoded as ANSI. The optional c , s ,
and u arguments to /FA control whether machine code or source code are output
together with the assembler listing, and whether the listing is encoded as UTF-8.
By default, each listing file gets the same base name as the source file, and has an .asm
extension. When machine code is included by using the c option, the listing file has a
.cod extension. You can change the name and extension of the listing file and the
directory where it's created by using the /Fa option.
/FA arguments
none
Only assembler language is included in the listing.
c
Optional. Includes machine code in the listing.
s
Optional. Includes source code in the listing.
u
Optional. Encodes the listing file in UTF-8 format, and includes a byte order marker. By
default, the file is encoded as ANSI. Use u to create a listing file that displays correctly
on any system, or if you're using Unicode source code files as input to the compiler.
If both s and u are specified, and if a source code file uses a Unicode encoding other
than UTF-8, then the code lines in the .asm file may not display correctly.
/Fa argument
none
One source.asm file is created for each source code file in the compilation.
filename
The compiler places a listing file named filename.asm in the current directory. This
argument form is only valid when compiling a single source code file.
filename.extension
The compiler places a listing file named filename.extension in the current directory. This
argument form is only valid when compiling a single source code file.
directory\
The compiler creates one source_file.asm file for each source code file in the compilation.
It's placed in the specified directory. The trailing backslash is required. Only paths on the
current disk are allowed.
directory\filename
A listing file named filename.asm is placed in the specified directory. This argument form
is only valid when compiling a single source code file.
directory\filename.extension
A listing file named filename.extension is placed in the specified directory. This argument
form is only valid when compiling a single source code file.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Output Files property page.
3. Modify the Assembler Output property to set the /FAc and /FAs options for
assembler, machine, and source code. Modify the Use Unicode For Assembler
Listing property to set the /FAu option for ANSI or UTF-8 output. Modify the ASM
List Location to set the /Fa option for listing file name and location.
Setting both Assembler Output and Use Unicode For Assembler Listing properties can
cause Command-Line Warning D9025. To combine these options in the IDE, use the
Additional Options field in the Command Line property page instead.
To set this compiler option programmatically
See AssemblerListingLocation or AssemblerOutput. To specify /FAu, see
AdditionalOptions.
Example
The following command line produces a combined source and machine-code listing
called HELLO.cod :
Windows Command Prompt
CL /FAcs HELLO.CPP
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
Specifying the Pathname
Article • 08/03/2021
Each output-file option accepts a pathname argument that can specify a location and a
name for the output file. The argument can include a drive name, directory, and file
name. No space is allowed between the option and the argument.
If pathname includes a file name without an extension, the compiler gives the output a
default extension. If pathname includes a directory but no file name, the compiler
creates a file with a default name in the specified directory. The default name is based
on the base name of the source file and a default extension based on the type of the
output file. If you leave off pathname entirely, the compiler creates a file with a default
name in a default directory.
Alternatively, the pathname argument can be a device name (AUX, CON, PRN, or NUL)
rather than a file name. Do not use a space between the option and the device name or
a colon as part of the device name.
Device name Represents
AUX Auxiliary device
CON Console
PRN Printer
NUL Null device (no file created)
The following command line sends a mapfile to the printer:
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Example
CL /FmPRN HELLO.CPP
See also
/FD (IDE Minimal Rebuild)
Article • 08/03/2021
/FD is only exposed to users in the Command Line property page of a C++ project's
Property Pages dialog box. It's available if and only if the deprecated and off-by-default
/Gm (Enable Minimal Rebuild) option isn't selected. /FD has no effect other than from
the development environment. /FD isn't exposed in the output of cl /? .
If you don't enable the deprecated /Gm option in the development environment, /FD is
used. /FD ensures the .idb file has sufficient dependency information. /FD is only used
by the development environment, and it shouldn't be used from the command line or a
build script.
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Fd (Program Database File Name)
Article • 08/03/2021
Specifies a file name for the program database (PDB) file created by /Z7, /Zi, /ZI (Debug
Information Format).
Syntax
/Fdpathname
Remarks
Without /Fd, the PDB file name defaults to VCx0.pdb, where x is the major version of
Visual C++ in use.
If you specify a path name that does not include a file name (the path ends in
backslash), the compiler creates a .pdb file named VCx0.pdb in the specified directory.
If you specify a file name that does not include an extension, the compiler uses .pdb as
the extension.
This option also names the state (.idb) file used for minimal rebuild and incremental
compilation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Output Files property page.
3. Modify the Program Database File Name property.
To set this compiler option programmatically
See ProgramDataBaseFileName.
Example
This command line creates a .pdb file named PROG.pdb and an .idb file named
PROG.idb:
CL /DDEBUG /Zi /FdPROG.PDB PROG.CPP
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
/Fe (Name EXE File)
Article • 11/11/2021
Specifies a name and a directory for the .exe file or DLL created by the compiler.
Syntax
/Fe[pathname]
/Fe: pathname
Arguments
pathname
The relative or absolute path and base file name, or relative or absolute path to a
directory, or base file name to use for the generated executable.
Remarks
The /Fe option allows you to specify the output directory, output executable name, or
both, for the generated executable file. If pathname ends in a path separator ( \ ), it is
assumed to specify only the output directory. Otherwise, the last component of
pathname is used as the output file base name, and the rest of pathname specifies the
output directory. If pathname does not have any path separators, it's assumed to specify
the output file name in the current directory. The pathname must be enclosed in double
quotes (") if it contains any characters that can't be in a short path, such as spaces,
extended characters, or path components more than eight characters long.
When the /Fe option is not specified, or when a file base name is not specified in
pathname, the compiler gives the output file a default name using the base name of the
first source or object file specified on the command line and the extension .exe or .dll.
If you specify the /c (Compile Without Linking) option, /Fe has no effect.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Output File property. Choose OK to save your changes.
To set this compiler option programmatically
See OutputFile.
Examples
The following command line compiles and links all C source files in the current directory.
The resulting executable file is named PROCESS.exe and is created in the directory
"C:\Users\User Name\repos\My Project\bin".
CL /Fe"C:\Users\User Name\repos\My Project\bin\PROCESS" *.C
The following command line creates an executable file in C:\BIN with the same base
name as the first source file in the current directory:
CL /FeC:\BIN\ *.C
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
/Fi (Preprocess output file name)
Article • 08/03/2021
Specifies the name of the output file to which the /P (Preprocess to a File) compiler
option writes preprocessed output.
Syntax
/Fi pathname
Parameters
pathname
The relative or absolute path and filename of the output file produced by the /P
compiler option. Or, the directory path for the .i output files when more than one
input file is specified. Don't put a space between the /Fi option and pathname .
Remarks
Use the /Fi compiler option in combination with the /P compiler option. If /P isn't
specified, /Fi causes command line warning D9007.
If you specify only a directory path (a path that ends in a backslash \ ) for the pathname
parameter, the base name of the source file is used as the base name of the
preprocessed output file. The pathname parameter doesn't require a particular file name
extension. However, an extension of ".i" is used if you don't specify a file name
extension.
Example
The following command line preprocesses PROGRAM.cpp , preserves comments, adds #line
directives, and writes the result to the MYPROCESS.i file:
Windows Command Prompt
CL /P /FiMYPROCESS.I PROGRAM.CPP
This command line preprocesses main.cpp and helper.cpp into main.i and helper.i in
a subdirectory named preprocessed :
Windows Command Prompt
CL /P /Fi".\\preprocessed\\" main.cpp helper.cpp
To set this compiler option in the Visual Studio
development environment
1. Open the source file or the project's Property Pages dialog box. For details, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Set the Preprocess to a File property to Yes.
4. Select the Configuration Properties > C/C++ > Command Line property page.
5. Enter the /Fi compiler option and pathname in the Additional Options box. Only
specify a directory path, not a filename, when setting this property for a project.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
/P (Preprocess to a file)
Specifying the pathname
/FI (Name Forced Include File)
Article • 08/03/2021
Causes the preprocessor to process the specified header file.
Syntax
/FI[ ]pathname
Remarks
This option has the same effect as specifying the file with double quotation marks in an
#include directive on the first line of every source file specified on the command line, in
the CL environment variable, or in a command file. If you use multiple /FI options, files
are included in the order they are processed by CL.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Forced Include File property.
To set this compiler option programmatically
See ForcedIncludeFiles.
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
/Fm (Name Mapfile)
Article • 08/03/2021
Tells the linker to produce a mapfile containing a list of segments in the order in which
they appear in the corresponding .exe file or DLL.
Syntax
/Fmpathname
Remarks
By default, the map file is given the base name of the corresponding C or C++ source
file with a .MAP extension.
Specifying /Fm has the same effect as if you had specified the /MAP (Generate Mapfile)
linker option.
If you specify /c (Compile Without Linking) to suppress linking, /Fm has no effect.
Global symbols in a map file usually have one or more leading underscores. It's because
the compiler adds a leading underscore to variable names. Many global symbols that
appear in the map file are used internally by the compiler and the standard libraries.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
/Fo (Object File Name)
Article • 01/30/2024
Specifies an object ( .obj ) file name or directory to be used instead of the default.
Syntax
/Fo"pathname"
/Fo:[ ]"pathname"
Remarks
You can use the /Fo compiler option to set an output directory for all the object files
generated by the CL compiler command. Or, you can use it to rename a single object
file. Don't put a space between the /Fo option and the pathname argument.
By default, the object files generated by the compiler are placed in the current directory.
They're given the base name of the source file and a .obj extension.
To use the /Fo option to rename an object file, specify the output filename as the
pathname argument. When you rename an object file, you can use any name and
extension you want, but the recommended convention is to use an .obj extension. The
compiler generates command line error D8036 if you specify a filename to /Fo when
you've specified more than one source file to compile.
To use the /Fo option to set an output directory for all object files created by the CL
command, specify the directory as the pathname argument. A directory is indicated by a
trailing slash or backslash in the pathname argument. Use an escaped backslash (a
double backslash), if you're using a quoted path. The directory path can be absolute, or
relative to the source directory. The specified directory must exist, or the compiler
reports error D8003. The directory isn't created automatically.
Example
This command line demonstrates the format that allows for an optional space between
the /Fo option and the pathname argument. It creates an object file named test.obj in
the current directory.
Windows Command Prompt
CL /Fo: "test" /EHsc /c sample1.cpp
The following command line creates object files named sample1.obj and sample2.obj in
an existing directory, D:\intermediate\ . It uses escaped backslash characters as path
segment separators in a quoted path:
Windows Command Prompt
CL /Fo"D:\\intermediate\\" /EHsc /c sample1.cpp sample2.cpp
This command line creates object files named sample1.obj and sample2.obj in an
existing directory, output\ , relative to the source directory.
Windows Command Prompt
CL /Fooutput\ /EHsc /c sample1.cpp sample2.cpp
Set the option in Visual Studio or
programmatically
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Output Files property page.
3. Modify the Object File Name property to set the output directory. In the IDE, the
object files must have an extension of .obj .
To set this compiler option programmatically
See ObjectFile.
See also
Output-file (/F) options
MSVC compiler options
MSVC compiler command-line syntax
Specifying the pathname
/Fp (Name .pch file)
Article • 12/06/2021
Provides a path name for a precompiled header instead of using the default path name.
Syntax
/Fppathname
Remarks
Use the /Fp option with /Yc (Create Precompiled Header File) or /Yu (Use Precompiled
Header File) to specify the path and file name for the precompiled header (PCH) file. By
default, the /Yc option creates a PCH file name by using the base name of the source file
and a pch extension.
If you don't specify an extension as part of the pathname, an extension of pch is
assumed. When you specify a directory name by use of a slash (/) at the end of
pathname, the default file name is vcversion0.pch, where version is the major version of
the Visual Studio toolset. This directory must exist, or error C1083 is generated.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Precompiled Headers property
page.
3. Modify the Precompiled Header Output File property.
To set this compiler option programmatically
See AdditionalOptions.
Examples
To create a separate named version of the precompiled header file for the debug build
of your program, you can specify a command such as:
CMD
CL /DDEBUG /Zi /Yc /FpDPROG.PCH PROG.CPP
The following command specifies the use of a precompiled header file named
MYPCH.pch. The compiler precompiles the source code in PROG.cpp through the end of
MYAPP.h, and puts the precompiled code in MYPCH.pch. It then uses the content of
MYPCH.pch and compiles the rest of PROG.cpp to create an .obj file. The output of this
example is a file named PROG.exe.
CMD
CL /YuMYAPP.H /FpMYPCH.PCH PROG.CPP
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Specifying the Pathname
/FR , /Fr (Name SBR file)
Article • 08/31/2022
Creates .sbr (source browser) files, used by Code maps, BSCMAKE, and some third￾party code browsing tools.
Syntax
/FR [ pathname [ \filename ]]
/Fr [ pathname [ \filename ]]
Arguments
pathname
The optional destination directory for the generated .sbr files. If this value isn't
specified, the files are created in the default output directory. For more information, see
Specifying the pathname.
filename
An optional filename for the generated .sbr file. If this value isn't specified, the
compiler uses the base name of the source file with a .sbr extension. For more
information, see Specifying the pathname.
Remarks
/FR creates an .sbr file with complete symbolic information.
/Fr creates an .sbr file without information on local variables. /Fr is deprecated; use
/FR instead. For more information, see the Deprecated and removed compiler options
section in Compiler options listed by category.
The Visual Studio Code Maps feature requires the .sbr files generated by /FR .
The Microsoft Browse Information File Maintenance Utility (BSCMAKE) uses .sbr files to
create a .bsc file, used to display browse information in some third-party tools. For
more information, see BSCMAKE reference.
７ Note
Although BSCMAKE is still installed with Visual Studio, it's no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server SDF file in the solution folder. If you use BSCMAKE,
don't change the .sbr extension. BSCMAKE requires the intermediate files to have
that extension.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Browse Information property
page.
3. Modify the Browse Information File or Enable Browse Information property.
To set this compiler option programmatically
See BrowseInformation and BrowseInformationFile.
See also
Output-File (/F) options
MSVC compiler options
MSVC compiler command-line syntax
Specifying the pathname
/FU (Name Forced #using File)
Article • 08/03/2021
A compiler option that you can use as an alternative to passing a file name to #using
Directive in source code.
Syntax
/FU file
Arguments
file
Specifies the metadata file to reference in this compilation.
Remarks
The /FU switch takes just one file name. To specify multiple files, use /FU with each one.
If you are using C++/CLI and are referencing metadata to use the Friend Assemblies
feature, you can't use /FU. You must reference the metadata in code by using #using—
together with the [as friend] attribute. Friend assemblies are not supported in Visual
C++ component extensions C++/CX.
For information about how to create an assembly or module for the common language
runtime (CLR), see /clr (Common Language Runtime Compilation). For information
about how to build in C++/CX, see Building apps and libraries.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Force #using property.
To set this compiler option programmatically
See ForcedUsingFiles.
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Fx (Merge Injected Code)
Article • 08/03/2021
Produces a copy of each source file with injected code merged into the source.
Syntax
/Fx
Remarks
To distinguish a merged source file from an original source file, /Fx adds an .mrg
extension between the file name and file extension. For example, a file named
MyCode.cpp containing attributed code and built with /Fx creates a file named
MyCode.mrg.cpp containing the following code:
//+++ Start Injected Code
[no_injected_text(true)]; // Suppress injected text, it has
 // already been injected
#pragma warning(disable: 4543) // Suppress warnings about skipping
 // injected text
#pragma warning(disable: 4199) // Suppress warnings from attribute
 // providers
//--- End Injected Code
In an .mrg file, code that was injected because of an attribute will be delimited as
follows:
//+++ Start Injected Code
...
//--- End Injected Code
The no_injected_text attribute is embedded in an .mrg file, which allows for the
compilation of the .mrg file without text being reinjected.
You should be aware that the .mrg source file is intended to be a representation of the
source code injected by the compiler. The .mrg file may not compile or run exactly as
the original source file.
Macros are not expanded in the .mrg file.
If your program includes a header file that uses injected code, /Fx generates an .mrg.h
file for that header. /Fx does not merge include files that do not use injected code.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Output Files property page.
3. Modify the Expand Attributed Source property.
To set this compiler option programmatically
See ExpandAttributedSource.
See also
Output-File (/F) Options
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/favor (Optimize for Architecture
Specifics)
Article • 08/03/2021
/favor: option produces the code that is optimized for a specific architecture or for the
specifics of micro-architectures in the AMD and the Intel architectures.
Syntax
/favor:{blend | ATOM | AMD64 | INTEL64}
Remarks
/favor:blend
(x86 and x64) produces the code that is optimized for the specifics of micro￾architectures in the AMD and the Intel architectures. While /favor:blend may not give
the best performance possible on a specific processor, it is designed to give the best
performance across a broad range of x86 and x64 processors. By default, /favor:blend is
in effect.
/favor:ATOM
(x86 and x64) produces the code that is optimized for the specifics of the Intel Atom
processor and Intel Centrino Atom Processor Technology. Code that is generated by
using /favor:ATOM may also produce Intel SSSE3, SSE3, SSE2, and SSE instructions for
Intel processors.
/favor:AMD64
(x64 only) optimizes the generated code for the AMD Opteron, and Athlon processors
that support 64-bit extensions. The optimized code can run on all x64 compatible
platforms. Code that is generated by using /favor:AMD64 might cause worse
performance on Intel processors that support Intel64.
/favor:INTEL64
(x64 only) optimizes the generated code for Intel processors that support Intel64, which
typically yields better performance for that platform. The resulting code can run on any
x64 platform. Code that is generated with /favor:INTEL64 might cause worse
performance on AMD Opteron, and Athlon processors that support 64-bit extensions.
７ Note
Intel64 architecture was previously known as Extended Memory 64 Technology, and
the corresponding compiler option was /favor:EM64T.
For information about how to program for the x64 architecture, see x64 Software
Conventions.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/FC (Full path of source code file in
diagnostics)
Article • 10/29/2021
Causes the compiler to display the full path of source code files passed to the compiler
in diagnostics.
/FC
Consider the following code sample, where the source file is located in
C:\test\compiler_option_FC.cpp :
C++
Without /FC , the compiler output looks similar to this diagnostic text:
compiler_option_FC.cpp(5): error C2143: syntax error: missing ';' before '}'
With /FC , the compiler output looks similar to this diagnostic text:
C:\test\compiler_option_FC.cpp(5): error C2143: syntax error: missing ';' before '}'
/FC is also needed if you want to see the full path of a file name when using the
__FILE__ macro. For more information about __FILE__ , see Predefined macros.
The /FC option is implied by /ZI . For more information about /ZI , see /Z7, /Zi, /ZI
(Debug information format).
In Visual Studio 2017 and earlier versions, /FC outputs full paths in lower case. Starting
in Visual Studio 2019, /FC uses the same casing as the file system for full paths.
Syntax
Remarks
// compiler_option_FC.cpp
int main( ) {
 int i // C2143
}
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Use Full Paths property.
To set this compiler option programmatically
See UseFullPaths.
See also
MSVC compiler options
MSVC compiler command-line syntax
/feature (ARM64)
Article • 08/14/2024
Enable one or more Arm A-Profile architecture features for an ARM64 extension as
specified by /arch (ARM64). For more information about /arch (ARM64), see /arch
(ARM64).
/feature:<arg1> [ +arg2 ]
To enable one or more features the targeted ARM64 extension supports, specify one or
more of the following feature arguments:
Feature
argument
Feature
identifier
Optional
from
Enabled by
default
Description Supported in
version
lse FEAT_LSE Armv8.0 Armv8.1 Large System
Extensions.
Visual Studio
2022 17.10
rcpc FEAT_LRCPC Armv8.2 Armv8.3 Load-Acquire RCpc
instructions.
Visual Studio
2022 17.10
rcpc2 FEAT_LRCPC2 Armv8.2 Armv8.4 Load-Acquire RCpc
instructions v2.
Visual Studio
2022 17.11
Example usage: to enable FEAT_LSE , specify /feature:lse .
If there are conflicting feature arguments specified by /feature , the right-most feature
is enabled. Enabling a feature the targeted ARM64 extension doesn't support may cause
unexpected behavior, especially if a CPU doesn't implement the feature.
Use either /feature or only /arch (ARM64) to specify features. For example, to enable
FEAT_LSE when targeting Armv8.0-A, use both /feature:lse and /arch:armv8.0 , or
Syntax
Arguments
ﾉ Expand table
Remarks
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
specify /arch:armv8.0+lse . /feature is a way to specify features without specifying
them in /arch (ARM64).
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /feature:lse or replace lse with the feature
to enable. Choose OK to save your changes.
See AdditionalOptions.
/arch (Minimum CPU architecture)
MSVC compiler options
MSVC compiler command-line syntax
To set the /feature compiler option in Visual Studio
To set this compiler option programmatically
See also
 Yes  No
/fp (Specify floating-point behavior)
Article • 11/22/2021
Specifies how the compiler treats floating-point expressions, optimizations, and
exceptions. The /fp options specify whether the generated code allows floating-point
environment changes to the rounding mode, exception masks, and subnormal behavior,
and whether floating-point status checks return current, accurate results. It controls
whether the compiler generates code that maintains source operation and expression
order, and conforms to the standard for NaN propagation. Or, if it instead generates
more efficient code that may reorder or combine operations and use simplifying
algebraic transformations that aren't allowed by the IEEE-754 standard.
Syntax
/fp:contract
/fp:except [ - ]
/fp:fast
/fp:precise
/fp:strict
Arguments
/fp:contract
The /fp:contract option allows the compiler to generate floating-point contractions
when you specify the /fp:precise and /fp:except options. A contraction is a machine
instruction that combines floating-point operations, such as Fused-Multiply-Add (FMA).
FMA, defined as a basic operation by IEEE-754, doesn't round the intermediate product
before the addition, so the result can differ from separate multiplication and addition
operations. Since it's implemented as a single instruction, it can be faster than separate
instructions. The speed comes at a cost of bitwise exact results, and an inability to
examine the intermediate value.
By default, the /fp:fast option enables /fp:contract . The /fp:contract option isn't
compatible with /fp:strict .
The /fp:contract option is new in Visual Studio 2022.
/fp:precise
By default, the compiler uses /fp:precise behavior.
Under /fp:precise , the compiler preserves the source expression ordering and
rounding properties of floating-point code when it generates and optimizes object code
for the target machine. The compiler rounds to source code precision at four specific
points during expression evaluation: at assignments, typecasts, when floating-point
arguments get passed to a function call, and when a function call returns a floating￾point value. Intermediate computations may be performed at machine precision.
Typecasts can be used to explicitly round intermediate computations.
The compiler doesn't perform algebraic transformations on floating-point expressions,
such as reassociation or distribution, unless it can guarantee the transformation
produces a bitwise identical result. Expressions that involve special values (NaN,
+infinity, -infinity, -0.0) are processed according to IEEE-754 specifications. For example,
x != x evaluates to true if x is NaN. Floating-point contractions aren't generated by
default under /fp:precise . This behavior is new in Visual Studio 2022. Previous compiler
versions could generate contractions by default under /fp:precise .
The compiler generates code intended to run in the default floating-point environment.
It also assumes the floating-point environment isn't accessed or modified at runtime.
That is, it assumes the code: leaves floating-point exceptions masked, doesn't read or
write floating-point status registers, and doesn't change rounding modes.
If your floating-point code doesn't depend on the order of operations and expressions
in your floating-point statements (for example, if you don't care whether a * b + a * c
is computed as (b + c) * a or 2 * a as a + a ), consider the /fp:fast option, which can
produce faster, more efficient code. If your code both depends on the order of
operations and expressions, and accesses or alters the floating-point environment (for
example, to change rounding modes or to trap floating-point exceptions), use /fp:strict.
/fp:strict
/fp:strict has behavior similar to /fp:precise , that is, the compiler preserves the
source ordering and rounding properties of floating-point code when it generates and
optimizes object code for the target machine, and observes the standard when handling
special values. The program may also safely access or modify the floating-point
environment at runtime.
Under /fp:strict , the compiler generates code that allows the program to safely
unmask floating-point exceptions, read or write floating-point status registers, or
change rounding modes. It rounds to source code precision at four specific points
during expression evaluation: at assignments, typecasts, when floating-point arguments
get passed to a function call, and when a function call returns a floating-point value.
Intermediate computations may be performed at machine precision. Typecasts can be
used to explicitly round intermediate computations. The compiler doesn't make any
algebraic transformations on floating-point expressions, such as reassociation or
distribution, unless it can guarantee the transformation produces a bitwise identical
result. Expressions that involve special values (NaN, +infinity, -infinity, -0.0) are
processed according to IEEE-754 specifications. For example, x != x evaluates to true if
x is NaN. Floating-point contractions aren't generated under /fp:strict .
/fp:strict is computationally more expensive than /fp:precise because the compiler
must insert extra instructions to trap exceptions and allow programs to access or modify
the floating-point environment at runtime. If your code doesn't use this capability, but
requires source code ordering and rounding, or relies on special values, use
/fp:precise . Otherwise, consider using /fp:fast , which can produce faster and smaller
code.
/fp:fast
The /fp:fast option allows the compiler to reorder, combine, or simplify floating-point
operations to optimize floating-point code for speed and space. The compiler may omit
rounding at assignment statements, typecasts, or function calls. It may reorder
operations or make algebraic transforms, for example, by use of associative and
distributive laws. It may reorder code even if such transformations result in observably
different rounding behavior. Because of this enhanced optimization, the result of some
floating-point computations may differ from the ones produced by other /fp options.
Special values (NaN, +infinity, -infinity, -0.0) may not be propagated or behave strictly
according to the IEEE-754 standard. Floating-point contractions may be generated
under /fp:fast . The compiler is still bound by the underlying architecture under
/fp:fast , and more optimizations may be available through use of the /arch option.
Under /fp:fast , the compiler generates code intended to run in the default floating￾point environment and assumes the floating-point environment isn't accessed or
modified at runtime. That is, it assumes the code: leaves floating-point exceptions
masked, doesn't read or write floating-point status registers, and doesn't change
rounding modes.
/fp:fast is intended for programs that don't require strict source code ordering and
rounding of floating-point expressions, and don't rely on the standard rules for handling
special values such as NaN . If your floating-point code requires preservation of source
code ordering and rounding, or relies on standard behavior of special values, use
/fp:precise. If your code accesses or modifies the floating-point environment to change
rounding modes, unmask floating-point exceptions, or check floating-point status, use
/fp:strict.
The /fp:except option generates code to ensures that any unmasked floating-point
exceptions are raised at the exact point at which they occur, and that no other floating￾point exceptions are raised. By default, the /fp:strict option enables /fp:except , and
/fp:precise doesn't. The /fp:except option isn't compatible with /fp:fast . The option
can be explicitly disabled by use of /fp:except- .
By itself, /fp:except doesn't enable any floating-point exceptions. However, it's required
for programs to enable floating-point exceptions. For more information on how to
enable floating-point exceptions, see _controlfp.
Multiple /fp options can be specified in the same compiler command line. Only one of
/fp:strict , /fp:fast , and /fp:precise options can be in effect at a time. If you specify
more than one of these options on the command line, the later option takes precedence
and the compiler generates a warning. The /fp:strict and /fp:except options aren't
compatible with /clr .
The /Za (ANSI compatibility) option isn't compatible with /fp .
The compiler provides three pragma directives to override the floating-point behavior
specified on the command line: float_control, fenv_access, and fp_contract. You can use
these directives to control floating-point behavior at function-level, not within a
function. These directives don't correspond directly to the /fp options. This table shows
how the /fp options and pragma directives map to each other. For more information,
see the documentation for the individual options and pragma directives.
Option float_control(precise,
*)
float_control(except,
*)
fenv_access(*) fp_contract(*)
/fp:except
Remarks
Using compiler directives to control floating-point
behavior
Option float_control(precise,
*)
float_control(except,
*)
fenv_access(*) fp_contract(*)
/fp:fast off off off on
/fp:precise on off off off *
/fp:strict on on on off
* In versions of Visual Studio before Visual Studio 2022, the /fp:precise behavior
defaulted to fp_contract(on) .
When a process is initialized, the default floating point environment is set. This
environment masks all floating point exceptions, sets the rounding mode to round to
nearest ( FE_TONEAREST ), preserves subnormal (denormal) values, uses the default
precision of significand (mantissa) for float , double , and long double values, and
where supported, sets the infinity control to the default affine mode.
The Microsoft Visual C++ runtime provides several functions to access and modify the
floating-point environment. These include _controlfp, _clearfp, and _statusfp and their
variants. To ensure correct program behavior when your code accesses or modifies the
floating-point environment, fenv_access must be enabled, either by the /fp:strict
option or by use of the fenv_access pragma, for these functions to have any effect.
When fenv_access isn't enabled, access or modification of the floating-point
environment may result in unexpected program behavior:
Code may not honor requested changes to the floating-point environment,
The floating-point status registers may not report expected or current results,
Unexpected floating-point exceptions may occur or expected floating-point
exceptions may not occur.
When your code accesses or modifies the floating-point environment, you must be
careful when you combine code where fenv_access is enabled with code that doesn't
have fenv_access enabled. In code where fenv_access isn't enabled, the compiler
assumes the platform default floating-point environment is in effect. It also assumes the
floating-point status isn't accessed or modified. We recommend you save and restore
The default floating point environment
Floating-point environment access and modification
the local floating-point environment to its default state before control is transferred to a
function that doesn't have fenv_access enabled. This example demonstrates how the
float_control pragma can be set and restored:
C++
Under both /fp:precise and /fp:fast , the compiler generates code intended to run in
the default floating-point environment. It assumes that the environment isn't accessed
or modified at runtime. That is, the compiler assumes the code never unmasks floating￾point exceptions, reads or writes floating-point status registers, or changes rounding
modes. However, some programs need to alter the floating-point environment. For
example, this sample computes error bounds of a floating-point multiplication by
altering floating-point rounding modes:
C++
#pragma float_control(precise, on, push)
// Code that uses /fp:strict mode
#pragma float_control(pop)
Floating-point rounding modes
// fp_error_bounds.cpp
#include <iostream>
#include <limits>
using namespace std;
int main(void)
{
 float a = std::<float>::max();
 float b = -1.1;
 float cLower = 0.0;
 float cUpper = 0.0;
 unsigned int control_word = 0;
 int err = 0;
 // compute lower error bound.
 // set rounding mode to -infinity.
 err = _controlfp_s(&control_word, _RC_DOWN, _MCW_RC);
 if (err)
 {
 cout << "_controlfp_s(&control_word, _RC_DOWN, _MCW_RC) failed with
error:" << err << endl;
 } 
 cLower = a * b;
 // compute upper error bound.
 // set rounding mode to +infinity.
Since the compiler assumes the default floating point environment under /fp:fast and
/fp:precise , it's free to ignore the calls to _controlfp_s . For example, when compiled
by using both /O2 and /fp:precise for the x86 architecture, the bounds aren't
computed, and the sample program outputs:
Output
When compiled by using both /O2 and /fp:strict for the x86 architecture, the sample
program outputs:
Output
Under /fp:precise and /fp:strict , expressions that involve special values (NaN,
+infinity, -infinity, -0.0) behave according to the IEEE-754 specifications. Under
/fp:fast , the behavior of these special values may be inconsistent with IEEE-754.
 err = _controlfp_s(&control_word, _RC_UP, _MCW_RC);
 if (err)
 {
 cout << "_controlfp_s(&control_word, _RC_UP, _MCW_RC) failed with
error:" << err << endl;
 }
 cUpper = a * b;
 // restore default rounding mode.
 err = _controlfp_s(&control_word, _CW_DEFAULT, _MCW_RC);
 if (err)
 {
 cout << "_controlfp_s(&control_word, _CW_DEFAULT, _MCW_RC) failed
with error:" << err << endl;
 }
 // display error bounds.
 cout << "cLower = " << cLower << endl;
 cout << "cUpper = " << cUpper << endl;
 return 0;
}
cLower = -inf
cUpper = -inf
cLower = -inf
cUpper = -3.40282e+38
Floating-point special values
This sample demonstrates the different behavior of special values under /fp:precise ,
/fp:strict , and /fp:fast :
C++
When compiled by using /O2 /fp:precise or /O2 /fp:strict for x86 architecture, the
outputs are consistent with the IEEE-754 specification:
Output
When compiled by using /O2 /fp:fast ** for x86 architecture, the outputs aren't
consistent with IEEE-754:
Output
// fp_special_values.cpp
#include <stdio.h>
#include <cmath>
float gf0 = -0.0;
int main()
{
 float f1 = INFINITY;
 float f2 = NAN;
 float f3 = -INFINITY;
 bool a, b;
 float c, d, e;
 a = (f1 == f1);
 b = (f2 == f2);
 c = (f1 - f1);
 d = (f2 - f2);
 e = (gf0 / f3);
 printf("INFINITY == INFINITY : %d\n", a);
 printf("NAN == NAN : %d\n", b);
 printf("INFINITY - INFINITY : %f\n", c);
 printf("NAN - NAN : %f\n", d);
 printf("std::signbit(-0.0/-INFINITY): %d\n", std::signbit(e));
 return 0;
}
INFINITY == INFINITY : 1
NAN == NAN : 0
INFINITY - INFINITY : -nan(ind)
NAN - NAN : nan
std::signbit(-0.0/-INFINITY): 0
INFINITY == INFINITY : 1
NAN == NAN : 1
Under /fp:precise and /fp:strict , the compiler doesn't do any mathematical
transformation unless the transformation is guaranteed to produce a bitwise identical
result. The compiler may make such transformations under /fp:fast . For example, the
expression a * b + a * c in the sample function algebraic_transformation may be
compiled into a * (b + c) under /fp:fast . Such transformations aren't done under
/fp:precise or /fp:strict , and the compiler generates a * b + a * c .
C++
Under /fp:precise and /fp:strict , the compiler rounds to source code precision at
four specific points during expression evaluation: at assignments, typecasts, when
floating-point arguments get passed to a function call, and when a function call returns
a floating-point value. Typecasts can be used to explicitly round intermediate
computations. Under /fp:fast , the compiler doesn't generate explicit casts at these
points to guarantee source code precision. This sample demonstrates the behavior
under different /fp options:
C++
When compiled by using /O2 /fp:precise or /O2 /fp:strict , you can see that explicit
type casts are inserted at both the typecast and at the function return point in the
generated code for the x64 architecture:
asm
INFINITY - INFINITY : 0.000000
NAN - NAN : 0.000000
std::signbit(-0.0/-INFINITY): 0
Floating-point algebraic transformations
float algebraic_transformation (float a, float b, float c)
{
 return a * b + a * c;
}
Floating-point explicit casting points
float casting(float a, float b)
{
 return 5.0*((double)(a+b));
}
 addss xmm0, xmm1
 cvtss2sd xmm0, xmm0
 mulsd xmm0, QWORD PTR __real@4014000000000000
 cvtsd2ss xmm0, xmm0
 ret 0
Under /O2 /fp:fast the generated code is simplified, because all type casts are
optimized away:
asm
 addss xmm0, xmm1
 mulss xmm0, DWORD PTR __real@40a00000
 ret 0
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Floating Point Model property.
To set this compiler option programmatically
See floatingPointModel.
See also
MSVC compiler options
MSVC compiler command-line syntax
/fpcvt (Floating-point to integer
conversion compatibility)
Article • 12/01/2021
Specifies how the compiler treats floating-point conversions to integer types.
Syntax
/fpcvt:IA
/fpcvt:BC
Arguments
/fpcvt:IA
The /fpcvt:IA option tells the compiler to convert floating point values to integers so
the results are compatible with the Intel AVX-512 conversion instructions. This behavior
is the usual behavior in Visual Studio 2019 for x86 targets.
/fpcvt:BC
The /fpcvt:BC option tells the compiler to convert floating point values to unsigned
integers so the results are compatible with the Visual Studio 2017 and earlier compilers.
This behavior is the default in Visual Studio 2022.
Remarks
In Visual Studio 2019 version 16.8 and later versions, the /fpcvt compiler option can be
used to control the results of floating-point to integer conversions. The /fpcvt:BC
option specifies the default behavior of Visual Studio 2022, which is the same as the
behavior of Visual Studio 2017 and earlier versions. The /fpcvt:IA option specifies
behavior compatible with Intel Architecture (IA) AVX-512 conversion instruction
behavior. This option can be used with either 32-bit x86 or 64-bit x64 targets, and it
applies whether /arch:AVX512 is specified or not.
For Visual Studio 2019, the default behavior for x64 targets is consistent with /fpcvt:BC
unless /arch:AVX512 is specified. Usually, the behavior for x86 targets is consistent with
/fpcvt:IA , except under /arch:IA32 , /arch:SSE , or sometimes where the result of a
function call is directly converted to an unsigned integer. Use of /fpcvt overrides the
default, so all conversions are handled consistently on either target. The behavior of
conversions for ARM and ARM64 targets isn't consistent with either /fpcvt:BC or
/fpcvt:IA .
Standard C++ specifies that if a truncated floating-point value is exactly representable in
an integer type, it must have that value when converted to that type. Otherwise, any
behavior at all is allowed. Both /fpcvt options conform with Standard C++. The only
difference is in what values are returned for invalid source values.
The /fpcvt:IA option causes any invalid conversion to return a single sentinel value,
which is the destination value farthest from zero. For conversion to signed types, the
sentinel is the minimum value for that type. Unsigned types use the maximum value.
Floating-point operations may return a Not-a-Number (NaN) value to indicate an invalid
operation. That indicator isn't an option for conversion to integer types, which don't
have NaN values. The sentinel is used as a proxy for a NaN value, although it can also be
the result of a valid conversion.
The /fpcvt:BC option also makes conversion to signed types return the minimum
possible value when the source is invalid. However, conversion to unsigned integer
types is based on conversion to long long . To convert a value to unsigned int , the
compiler first converts it to type long long . The compiler then truncates the result to 32
bits. To convert a value to unsigned long long , valid source values that are too high for
a long long are handled as a special case. All other values are first converted to long
long and then recast to unsigned long long .
The /fpcvt options are new in Visual Studio 2019 version 16.8. If you specify more than
one /fpcvt option on the command line, the later option takes precedence and the
compiler generates a warning.
Intrinsic functions for conversions
You can specify the behavior of a specific conversion independently of the /fpcvt
option, which applies globally. The compiler provides intrinsic sentinel conversion
functions for conversions compatible with /fpcvt:IA . For more information, see Sentinel
conversion functions. The compiler also provides saturation conversion functions
compatible with conversions on ARM or ARM64 target architectures. For more
information, see Saturation conversion functions.
The compiler also supports intrinsic conversion functions that execute as quickly as
possible for valid conversions. These functions may generate any value or throw an
exception for an invalid conversion. The results depend on the target platform, compiler
options, and context. They're useful for handling values that have already been range￾checked, or values generated in a way that can't cause an invalid conversion. For more
information, see Fast conversion functions.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to add /fpcvt:IA or /fpcvt:BC . Choose
OK to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
Fast conversion functions
Saturation conversion functions
Sentinel conversion functions
/FS (Force Synchronous PDB Writes)
Article • 08/03/2021
Forces writes to the program database (PDB) file—created by /Zi or /ZI—to be serialized
through MSPDBSRV.EXE.
Syntax
/FS
Remarks
By default, when /Zi or /ZI is specified, the compiler locks PDB files to write type
information and symbolic debugging information. This can significantly reduce the time
it takes the compiler to generate type information when the number of types is large. If
another process temporarily locks the PDB file—for example, an anti-virus program—
writes by the compiler may fail and a fatal error may occur. This problem can also
happen when multiple copies of cl.exe access the same PDB file—for example, if your
solution has independent projects that use the same intermediate directories or output
directories and parallel builds are enabled. The /FS compiler option prevents the
compiler from locking the PDB file and forces writes to go through MSPDBSRV.EXE,
which serializes access. This may make builds significantly longer, and it doesn't prevent
all errors that may occur when multiple instances of cl.exe access the PDB file at the
same time. We recommend that you change your solution so that independent projects
write to separate intermediate and output locations, or that you make one of the
projects dependent on the other to force serialized project builds.
The /MP option enables /FS by default.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /FS and then choose OK.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/fsanitize (Enable sanitizers)
Article • 02/20/2025
Use the /fsanitize compiler options to enable sanitizers.
Syntax
/fsanitize=address
/fsanitize=kernel-address
/fsanitize=fuzzer
/fsanitize-address-use-after-return
/fno-sanitize-address-vcasan-lib /fsanitize-address-asan-compat-lib /fno￾sanitize-address-asan-compat-lib
Remarks
The /fsanitize=address compiler option enables AddressSanitizer, a powerful compiler
and runtime technology to uncover hard-to-find bugs. Support for the
/fsanitize=address option is available starting in Visual Studio 2019 version 16.9.
The /fsanitize=kernel-address compiler option enables Kernel AddressSanitizer
(KASan). KASan is the kernel-mode variant of AddressSanitizer, available starting in
Visual Studio 2022 version 17.11. KASan is only supported on Windows 11 24H2 or
Windows Server 2025 and higher, and requires building using a Windows SDK
10.0.26100.2161 and higher. Building with KASan also implies the /fsanitize-address￾asan-compat-lib compiler option.
The /fsanitize=fuzzer compiler option enables experimental support for LibFuzzer .
LibFuzzer is a coverage-guided fuzzing library that can be used to find bugs and crashes
caused by user-provided input. We recommended you use /fsanitize=address with
LibFuzzer. This option is useful for fuzzing tools such as OneFuzz. For more information,
see the OneFuzz documentation and OneFuzz GitHub project . Support for the
/fsanitize=fuzzer option is available starting in Visual Studio 2022 version 17.0.
The /fsanitize option doesn't allow comma-separated syntax, for example:
/fsanitize=address,fuzzer . These options must be specified individually.
The /fsanitize-address-use-after-return , /fno-sanitize-address-vcasan-lib ,
/fsanitize-address-asan-compat-lib , and /fno-sanitize-address-asan-compat-lib
compiler options, and the /INFERASANLIBS (Use inferred sanitizer libs) and
/INFERASANLIBS:NO linker options offer support for advanced users. For more
information, see AddressSanitizer build and language reference.
To set the /fsanitize=address compiler option in the
Visual Studio development environment
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Enable Address Sanitizer property. To enable it, choose Yes
(/fsanitize=address).
4. Choose OK or Apply to save your changes.
To set the /fsanitize=fuzzer compiler option in the
Visual Studio development environment
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Enable Fuzzer property. To enable it, choose Yes (/fsanitize=fuzzer).
4. Choose OK or Apply to save your changes.
To set the advanced compiler options
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to set /fsanitize-address-use-after-return
or /fno-sanitize-address-vcasan-lib.
4. Choose OK or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
MSVC compiler options
MSVC compiler command-line syntax
/INFERASANLIBS (Use inferred sanitizer libs)
/fsanitize-coverage (Configure sanitizer coverage)
AddressSanitizer overview
AddressSanitizer known issues
AddressSanitizer build and language reference
See also
 Yes  No
/fsanitize-coverage (Configure sanitizer
coverage)
Article • 11/04/2021
The /fsanitize-coverage compiler options instruct the compiler to add various kinds of
instrumentation points where user-defined functions are called. These options are useful
for fuzzing scenarios that use /fsanitize=fuzzer , like OneFuzz. For more information,
see the OneFuzz documentation and OneFuzz GitHub project .
Syntax
/fsanitize-coverage=edge
/fsanitize-coverage=inline-8bit-counters
/fsanitize-coverage=trace-cmp
/fsanitize-coverage=trace-div
/fno-sanitize-coverage=edge
/fno-sanitize-coverage=inline-8bit-counters
/fno-sanitize-coverage=trace-cmp
/fno-sanitize-coverage=trace-div
Remarks
The experimental /fsanitize-coverage compiler options offer code coverage support
and various options to modify which compiler-provided instrumentation is generated.
All these options are automatically set when the /fsanitize=fuzzer option is specified.
The /fsanitize=fuzzer option requires the same instrumentation points and callbacks
mentioned in these options.
The /fsanitize-coverage options don't allow comma-separated syntax, for example:
/fsanitize-coverage=edge,inline-8bit-counters,trace-cmp,trace-div . Specify these
options individually.
The /fsanitize-coverage options are available beginning in Visual Studio 2022 version
17.0.
Code coverage
The /fsanitize-coverage=edge compiler option enables code coverage instrumentation
along all non-redundant edges. Use /fno-sanitize-coverage=edge to disable this option
if it's already provided or implied by another option.
Inline counters
The /fsanitize-coverage=inline-8bit-counters compiler option instructs the compiler
to add an inline counter increment on every relevant edge. This option also adds a call
to extern "C" void __sanitizer_cov_8bit_counters_init(uint8_t *start, uint8_t
*stop) that you must implement. The arguments correspond to the start and end of an
array that contains all the 8-bit counters created. Use /fno-sanitize-coverage=inline-
8bit-counters to disable this option if it's already provided or implied by another
option.
Trace comparisons
The /fsanitize-coverage=trace-cmp compiler option instructs the compiler to insert calls
to the following functions:
C
// Before each comparison instruction of the stated size.
void __sanitizer_cov_trace_cmp1(uint8_t Arg1, uint8_t Arg2);
void __sanitizer_cov_trace_cmp2(uint16_t Arg1, uint16_t Arg2);
void __sanitizer_cov_trace_cmp4(uint32_t Arg1, uint32_t Arg2);
void __sanitizer_cov_trace_cmp8(uint64_t Arg1, uint64_t Arg2);
// Before each comparison instruction of the stated size, if one of the
operands (Arg1) is constant.
void __sanitizer_cov_trace_const_cmp1(uint8_t Arg1, uint8_t Arg2);
void __sanitizer_cov_trace_const_cmp2(uint16_t Arg1, uint16_t Arg2);
void __sanitizer_cov_trace_const_cmp4(uint32_t Arg1, uint32_t Arg2);
void __sanitizer_cov_trace_const_cmp8(uint64_t Arg1, uint64_t Arg2);
Use /fno-sanitize-coverage=trace-cmp to disable this option if it's already provided or
implied by another option.
Trace divisions
The /fsanitize-coverage=trace-div compiler option instructs the compiler to insert calls
to the following functions:
C
// Before a division instruction of the stated size.
void __sanitizer_cov_trace_div4(uint32_t Val);
void __sanitizer_cov_trace_div8(uint64_t Val);
Use /fno-sanitize-coverage=trace-div to disable this option if it's already provided or
implied by another option.
To set the advanced compiler options
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to set /fsanitize-coverage options.
4. Choose OK or Apply to save your changes.
See also
MSVC compiler options
MSVC compiler command-line syntax
/fsanitize (Enable Sanitizers)
AddressSanitizer build and language reference
/GA (Optimize for Windows Application)
Article • 08/03/2021
Results in more efficient code for an .exe file for accessing thread-local storage (TLS)
variables.
Syntax
/GA
Remarks
/GA speeds access to data declared with __declspec(thread) in a Windows-based
program. When this option is set, the __tls_index macro is assumed to be 0.
Using /GA for a DLL can result in bad code generation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Gd, /Gr, /Gv, /Gz (Calling Convention)
Article • 08/03/2021
These options determine the order in which function arguments are pushed onto the
stack, whether the caller function or called function removes the arguments from the
stack at the end of the call, and the name-decorating convention that the compiler uses
to identify individual functions.
Syntax
/Gd
/Gr
/Gv
/Gz
Remarks
/Gd , the default setting, specifies the __cdecl calling convention for all functions except
C++ member functions and functions that are marked __stdcall, __fastcall, or
__vectorcall.
/Gr specifies the __fastcall calling convention for all functions except C++ member
functions, functions named main , and functions that are marked __cdecl , __stdcall , or
__vectorcall . All __fastcall functions must have prototypes. This calling convention is
only available in compilers that target x86, and is ignored by compilers that target other
architectures.
/Gz specifies the __stdcall calling convention for all functions except C++ member
functions, functions named main , and functions that are marked __cdecl , __fastcall ,
or __vectorcall . All __stdcall functions must have prototypes. This calling convention
is only available in compilers that target x86, and is ignored by compilers that target
other architectures.
/Gv specifies the __vectorcall calling convention for all functions except C++ member
functions, functions named main , functions with a vararg variable argument list, or
functions that are marked with a conflicting __cdecl , __stdcall , or __fastcall
attribute. This calling convention is only available on x86 and x64 architectures that
support /arch:SSE2 and above, and is ignored by compilers that target the ARM
architecture.
Functions that take a variable number of arguments must be marked __cdecl .
/Gd , /Gr , /Gv and /Gz are not compatible with /clr:safe or /clr:pure. The /clr:pure and
/clr:safe compiler options are deprecated in Visual Studio 2015 and unsupported in
Visual Studio 2017 and later.
７ Note
By default for x86 processors, C++ member functions use __thiscall.
For all processors, a member function that is explicitly marked as __cdecl , __fastcall ,
__vectorcall , or __stdcall uses the specified calling convention if it is not ignored on
that architecture. A member function that takes a variable number of arguments always
uses the __cdecl calling convention.
These compiler options have no effect on the name decoration of C++ methods and
functions. Unless declared as extern "C" , C++ methods and functions use a different
name-decorating scheme. For more information, see Decorated Names.
For more information about calling conventions, see Calling Conventions.
__cdecl Specifics
On x86 processors, all function arguments are passed on the stack from right to left. On
ARM and x64 architectures, some arguments are passed by register and the rest are
passed on the stack from right to left. The calling routine pops the arguments from the
stack.
For C, the __cdecl naming convention uses the function name preceded by an
underscore ( _ ); no case translation is performed. Unless declared as extern "C" , C++
functions use a different name-decorating scheme. For more information, see Decorated
Names.
__fastcall Specifics
Some of a __fastcall function's arguments are passed in registers (for x86 processors,
ECX, and EDX), and the rest are pushed onto the stack from right to left. The called
routine pops these arguments from the stack before it returns. Typically, /Gr decreases
execution time.
７ Note
Be careful when you use the __fastcall calling convention for any function that's
written in inline assembly language. Your use of registers could conflict with the
compiler's use.
For C, the __fastcall naming convention uses the function name preceded by an at
sign (@) followed by the size of the function's arguments in bytes. No case translation is
done. The compiler uses this template for the naming convention:
@function_name@number
When you use the __fastcall naming convention, use the standard include files.
Otherwise, you will get unresolved external references.
__stdcall Specifics
A __stdcall function's arguments are pushed onto the stack from right to left, and the
called function pops these arguments from the stack before it returns.
For C, the __stdcall naming convention uses the function name preceded by an
underscore (_) and followed by an at sign (@) and the size of the function's arguments
in bytes. No case translation is performed. The compiler uses this template for the
naming convention:
_functionname@number
__vectorcall Specifics
A __vectorcall function's integer arguments are passed by value, using up to two (on
x86) or four (on x64) integer registers, and up to six XMM registers for floating-point
and vector values, and the rest are passed on the stack from right to left. The called
function cleans off the stack before it returns. Vector and floating-point return values are
returned in XMM0.
For C, the __vectorcall naming convention uses the function name followed by two at
signs (@@) and the size of the function's arguments in bytes. No case translation is
performed. The compiler uses this template for the naming convention:
functionname@@number
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Calling Convention property.
To set this compiler option programmatically
See CallingConvention.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Ge (Enable Stack Probes)
Article • 08/03/2021
Activates stack probes for every function call that requires storage for local variables.
Syntax
/Ge
Remarks
This mechanism is useful if you rewrite the functionality of the stack probe. It is
recommended that you use /Gh (Enable _penter Hook Function) instead of rewriting the
stack probe.
/Gs (Control Stack Checking Calls) has the same effect.
/Ge is deprecated; beginning in Visual Studio 2005, the compiler automatically
generates stack checking. For a list of deprecated compiler options, see Deprecated and
Removed Compiler Options in Compiler Options Listed by Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GF (Eliminate Duplicate Strings)
Article • 08/03/2021
Enables the compiler to create a single copy of identical strings in the program image
and in memory during execution. This is an optimization called string pooling that can
create smaller programs.
Syntax
/GF
Remarks
If you use /GF, the operating system does not swap the string portion of memory and
can read the strings back from the image file.
/GF pools strings as read-only. If you try to modify strings under /GF, an application
error occurs.
String pooling allows what were intended as multiple pointers to multiple buffers to be
multiple pointers to a single buffer. In the following code, s and t are initialized with
the same string. String pooling causes them to point to the same memory:
char *s = "This is a character buffer";
char *t = "This is a character buffer";
７ Note
The /ZI option, used for Edit and Continue, automatically sets the /GF option.
７ Note
The /GF compiler option creates an addressable section for each unique string. And
by default, an object file can contain up to 65,536 addressable sections. If your
program contains more than 65,536 strings, use the /bigobj compiler option to
create more sections.
/GF is in effect when /O1 or /O2 is used.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable String Pooling property.
To set this compiler option programmatically
See StringPooling.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GH (Enable _pexit hook function)
Article • 08/03/2021
Calls the _pexit function at the end of every method or function.
Syntax
/GH
Remarks
The _pexit function isn't part of any library. It's up to you to provide a definition for
_pexit .
Unless you plan to explicitly call _pexit , you don't need to provide a prototype. The
function must push the content of all registers on entry and pop the unchanged content
on exit. It must appear as if it had the following prototype:
C++
void __declspec(naked) __cdecl _pexit( void );
This declaration isn't available for 64-bit projects.
_pexit is similar to _penter ; see /Gh (Enable _penter Hook Function) for an example of
how to write a _penter function.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Gh (Enable _penter hook function)
/Gh (Enable _penter hook function)
Article • 06/30/2022
Causes a call to the _penter function at the start of every method or function.
Syntax
/Gh
Remarks
The _penter function isn't part of any library. It's up to you to provide a definition for
_penter .
Unless you plan to explicitly call _penter , you don't need to provide a prototype. The
function must push the content of all registers on entry and pop the unchanged content
on exit. It must appear as if it had the following prototype:
C++
void __declspec(naked) __cdecl _penter( void );
This declaration isn't available for 64-bit projects.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
Example
The following code, when compiled with /Gh, shows how _penter is called twice; once
when entering function main and once when entering function x . The example consists
of two source files, which you compile separately.
Source file local_penter.cpp :
C++
// local_penter.cpp
// compile with: cl /EHsc /c local_penter.cpp
// processor: x86
#include <stdio.h>
extern "C" void __declspec(naked) __cdecl _penter( void ) {
 _asm {
 push eax
 push ebx
 push ecx
 push edx
 push ebp
 push edi
 push esi
 }
 printf_s("\nIn a function!");
 _asm {
 pop esi
 pop edi
 pop ebp
 pop edx
 pop ecx
 pop ebx
 pop eax
 ret
 }
}
Source file Gh_compiler_option.cpp :
C++
// Gh_compiler_option.cpp
// compile with: cl /EHsc /Gh Gh_compiler_option.cpp local_penter.obj
// processor: x86
#include <stdio.h>
void x() {}
int main() {
 x();
}
When run, the local _penter function is called on entry to main and x :
Output
In a function!
In a function!
See also
MSVC compiler options
MSVC compiler command-line syntax
/GH (Enable _pexit hook function)
/GL (Whole program optimization)
Article • 08/03/2021
Enables whole program optimization.
Syntax
/GL [ - ]
Remarks
Whole program optimization allows the compiler to perform optimizations with
information on all modules in the program. Without whole program optimization,
optimizations are performed on a per-module (compiland) basis.
Whole program optimization is off by default and must be explicitly enabled. However,
it's also possible to explicitly disable it with /GL- .
With information on all modules, the compiler can:
Optimize the use of registers across function boundaries.
Do a better job of tracking modifications to global data, allowing a reduction in the
number of loads and stores.
Track the possible set of items modified by a pointer dereference, reducing the
required loads and stores.
Inline a function in a module even when the function is defined in another module.
.obj files produced with /GL aren't usable by linker utilities such as EDITBIN and
DUMPBIN.
If you compile your program with /GL and /c, you should use the /LTCG linker option to
create the output file.
/ZI can't be used with /GL
The format of files produced with /GL in the current version often isn't readable by later
versions of Visual Studio and the MSVC toolset. Unless you're willing to ship copies of
the .lib file for all versions of Visual Studio you expect your users to use, now and in
the future, don't ship a .lib file made up of .obj files produced by /GL . For more
information, see Restrictions on binary compatibility.
.obj files produced by /GL and precompiled header files shouldn't be used to build a
.lib file unless the .lib file is linked on the same machine that produced the /GL .obj
file. Information from the .obj file's precompiled header file is needed at link time.
For more information on the optimizations available with and the limitations of whole
program optimization, see /LTCG. /GL also makes profile guided optimization available.
When compiling for profile guided optimizations and if you want function ordering from
your profile guided optimizations, you must compile with /Gy or a compiler option that
implies /Gy.
To set this linker option in the Visual Studio development
environment
For more information on how to specify /GL in the development environment, see
/LTCG (Link-time code generation) .
To set this linker option programmatically
See WholeProgramOptimization.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Gm (Enable Minimal Rebuild)
Article • 08/03/2021
Deprecated. Enables minimal rebuild, which determines whether C++ source files that
include changed C++ class definitions (stored in header (.h) files) need to be
recompiled.
Syntax
/Gm
Remarks
/Gm is deprecated. It may not trigger a build for certain kinds of header file changes.
You may safely remove this option from your projects. To improve build times, we
recommend you use precompiled headers and incremental and parallel build options
instead. For a list of deprecated compiler options, see the Deprecated and Removed
Compiler Options section in Compiler Options Listed by Category.
The compiler stores dependency information between source files and class definitions
in the project's .idb file during the first compile. (Dependency information tells which
source file is dependent on which class definition, and which .h file the definition is
located in.) Subsequent compiles use the information stored in the .idb file to determine
whether a source file needs to be compiled, even if it includes a modified .h file.
７ Note
Minimal rebuild relies on class definitions not changing between include files. Class
definitions must be global for a project (there should be only one definition of a
given class), because the dependency information in the .idb file is created for the
entire project. If you have more than one definition for a class in your project,
disable minimal rebuild.
Because the incremental linker does not support the Windows metadata included in .obj
files by using the /ZW (Windows Runtime Compilation) option, the /Gm option is
incompatible with /ZW.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable Minimal Rebuild property.
To set this compiler option programmatically
See MinimalRebuild.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GR (Enable Run-Time Type
Information)
Article • 08/03/2021
Adds code to check object types at run time.
Syntax
/GR[-]
Remarks
When /GR is on, the compiler defines the _CPPRTTI preprocessor macro. By default, /GR
is on. /GR- disables run-time type information.
Use /GR if the compiler cannot statically resolve an object type in your code. You usually
need the /GR option when your code uses dynamic_cast Operator or typeid. However,
/GR increases the size of the .rdata sections of your image. If your code does not use
dynamic_cast or typeid , /GR- may produce a smaller image.
For more information about run-time type checking, see Run-Time Type Information in
the C++ Language Reference.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language property page.
3. Modify the Enable Run-Time Type Info property.
To set this compiler option programmatically
See RuntimeTypeInfo.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GS (Buffer Security Check)
Article • 08/03/2021
Detects some buffer overruns that overwrite a function's return address, exception
handler address, or certain types of parameters. Causing a buffer overrun is a technique
used by hackers to exploit code that does not enforce buffer size restrictions.
Syntax
/GS[-]
Remarks
/GS is on by default. If you expect your application to have no security exposure, use
/GS-. For more information about suppressing buffer overrun detection, see safebuffers.
Security Checks
On functions that the compiler recognizes as subject to buffer overrun problems, the
compiler allocates space on the stack before the return address. On function entry, the
allocated space is loaded with a security cookie that is computed once at module load.
On function exit, and during frame unwinding on 64-bit operating systems, a helper
function is called to make sure that the value of the cookie is still the same. A different
value indicates that an overwrite of the stack may have occurred. If a different value is
detected, the process is terminated.
GS Buffers
A buffer overrun security check is performed on a GS buffer. A GS buffer can be one of
these:
An array that is larger than 4 bytes, has more than two elements, and has an
element type that is not a pointer type.
A data structure whose size is more than 8 bytes and contains no pointers.
A buffer allocated by using the _alloca function.
Any class or structure that contains a GS buffer.
For example, the following statements declare GS buffers.
C++
char buffer[20];
int buffer[20];
struct { int a; int b; int c; int d; } myStruct;
struct { int a; char buf[20]; };
However, the following statements do not declare GS buffers. The first two declarations
contain elements of pointer type. The third and fourth statements declare arrays whose
size is too small. The fifth statement declares a structure whose size on an x86 platform
is not more than 8 bytes.
C++
char *pBuf[20];
void *pv[20];
char buf[4];
int buf[2];
struct { int a; int b; };
Initialize the Security Cookie
The /GS compiler option requires that the security cookie be initialized before any
function that uses the cookie is run. The security cookie must be initialized immediately
on entry to an EXE or DLL. This is done automatically if you use the default VCRuntime
entry points: mainCRTStartup, wmainCRTStartup, WinMainCRTStartup,
wWinMainCRTStartup, or _DllMainCRTStartup. If you use an alternate entry point, you
must manually initialize the security cookie by calling __security_init_cookie.
What Is Protected
The /GS compiler option protects the following items:
The return address of a function call.
The address of an exception handler for a function.
Vulnerable function parameters.
On all platforms, /GS attempts to detect buffer overruns into the return address. Buffer
overruns are more easily exploited on platforms such as x86 and x64, which use calling
conventions that store the return address of a function call on the stack.
On x86, if a function uses an exception handler, the compiler injects a security cookie to
protect the address of the exception handler. The cookie is checked during frame
unwinding.
/GS protects vulnerable parameters that are passed into a function. A vulnerable
parameter is a pointer, a C++ reference, a C-structure (C++ POD type) that contains a
pointer, or a GS buffer.
A vulnerable parameter is allocated before the cookie and local variables. A buffer
overrun can overwrite these parameters. And code in the function that uses these
parameters could cause an attack before the function returns and the security check is
performed. To minimize this danger, the compiler makes a copy of the vulnerable
parameters during the function prolog and puts them below the storage area for any
buffers.
The compiler does not make copies of vulnerable parameters in the following situations:
Functions that do not contain a GS buffer.
Optimizations (/O options) are not enabled.
Functions that have a variable argument list (...).
Functions that are marked with naked.
Functions that contain inline assembly code in the first statement.
A parameter is used only in ways that are less likely to be exploitable in the event
of a buffer overrun.
What Is Not Protected
The /GS compiler option does not protect against all buffer overrun security attacks. For
example, if you have a buffer and a vtable in an object, a buffer overrun could corrupt
the vtable.
Even if you use /GS, always try to write secure code that has no buffer overruns.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Buffer Security Check property.
See BufferSecurityCheck.
This sample overruns a buffer. This causes the application to fail at runtime.
C
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
To set this compiler option programmatically
Example
// compile with: /c /W1
#include <cstring>
#include <stdlib.h>
#pragma warning(disable : 4996) // for strcpy use
// Vulnerable function
void vulnerable(const char *str) {
 char buffer[10];
 strcpy(buffer, str); // overrun buffer !!!
 // use a secure CRT function to help prevent buffer overruns
 // truncate string to fit a 10 byte buffer
 // strncpy_s(buffer, _countof(buffer), str, _TRUNCATE);
}
int main() {
 // declare buffer that is bigger than expected
 char large_buffer[] = "This string is longer than 10 characters!!";
 vulnerable(large_buffer);
}
See also
/Gs (Control stack checking calls)
Article • 02/17/2023
Controls the threshold for stack probes.
Syntax
/Gs [ size ]
Arguments
size
(Optional) The number of bytes that local variables can occupy before a stack probe is
initiated. No whitespace is allowed between /Gs and size .
Remarks
A stack probe is a sequence of code that the compiler inserts at the beginning of a
function call. When initiated, a stack probe reaches benignly into memory by the
amount of space required to store the function's local variables. This probe causes the
operating system to transparently page in more stack memory if necessary, before the
rest of the function runs.
By default, the compiler generates code that initiates a stack probe when a function
requires more than one page of stack space. This default is equivalent to a compiler
option of /Gs4096 for x86, x64, ARM, and ARM64 platforms. This value allows an
application and the Windows memory manager to increase the amount of memory
committed to the program stack dynamically at run time.
７ Note
The default value of /Gs4096 allows the program stack of applications for Windows
to grow correctly at run time. We recommend that you do not change the default
value unless you know exactly why you have to change it.
Some programs—for example, virtual device drivers—don't require this default stack￾growth mechanism. In such cases, the stack probes aren't necessary and you can stop
the compiler from generating them by setting size to a value that is larger than any
function requires for local variable storage.
/Gs0 initiates stack probes for every function call that requires storage for local
variables. This value can have a negative impact on performance.
For x64 targets, if you specify the /Gs option without a size argument, it's the same as
/Gs0 . If the size argument is 1 through 9, the compiler emits warning D9014, and the
effect is the same as specifying /Gs0 .
For x86, ARM, and ARM64 targets, the /Gs option without a size argument is the same
as /Gs4096 . If the size argument is 1 through 9, the compiler emits warning D9014, and
the effect is the same as specifying /Gs4096 .
For all targets, a size argument between 10 and 2147483647 sets the threshold at the
specified value. A size of 2147483648 or greater causes fatal error C1049.
You can turn stack probes on or off by using the check_stack directive. /Gs and the
check_stack pragma have no effect on standard C library routines; they affect only the
functions you compile.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /Gs compiler option and an optional size in Additional Options. Choose
OK or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/guard (Enable Control Flow Guard)
Article • 02/25/2025
Enable compiler generation of Control Flow Guard security checks.
Syntax
/guard:cf
/guard:cf￾Remarks
The /guard:cf option causes the compiler to analyze control flow for indirect call
targets at compile time, and inserts code at runtime to verify the targets. By default,
/guard:cf is off and must be explicitly enabled. To explicitly disable this option, use
/guard:cf- .
Visual Studio 2017 and later: This option adds guards for switch statements that
generate jump tables.
When the /guard:cf Control Flow Guard (CFG) option is specified, the compiler and
linker insert extra runtime security checks to detect attempts to compromise your code.
During compiling and linking, all indirect calls in your code are analyzed to find every
location that the code can reach when it runs correctly. This information is stored in
extra structures in the headers of your binaries. The compiler also injects a check before
every indirect call in your code that ensures the target is one of the verified locations. If
the check fails at runtime on a CFG-aware operating system, the operating system closes
the program.
A common attack on software takes advantage of bugs in handling extreme or
unexpected inputs. Carefully crafted input to the application may overwrite a location
that contains a pointer to executable code. This technique can be used to redirect
control flow to code controlled by the attacker. The CFG runtime checks don't fix the
data corruption bugs in your executable. They instead make it more difficult for an
attacker to use them to execute arbitrary code. CFG is a mitigation tool that prevents
calls to locations other than function entry points in your code. It's similar to how Data
Execution Prevention (DEP), /GS stack checks, and /DYNAMICBASE and
/HIGHENTROPYVA address space layout randomization (ASLR) lower the chances that
your code becomes an exploit vector.
To use the CFG exploit mitigation technique, pass /guard:cf to the compiler and
/GUARD:CF to the linker.
To disable the CFG exploit mitigation technique, pass /guard:cf- to the compiler
/GUARD:NO to the linker.
If you build using a single cl command, the compiler passes the option to the linker. If
you compile and link separately, set the option for both the compiler and linker
commands. The /DYNAMICBASE linker option is also required.
To verify that your binary has CFG data, use the dumpbin /headers /loadconfig
command. CFG-enabled binaries have Guard in the list of EXE or DLL characteristics, and
Guard Flags include CF Instrumented and FID table present .
The /guard:cf option is incompatible with /ZI (Edit and Continue debug information) or
/clr (Common Language Runtime Compilation).
Code compiled by using /guard:cf can be linked to libraries and object files that aren't
compiled by using the option. Only this code, when also linked by using the /guard:cf
option and run on a CFG-aware operating system, has CFG protection. Because code
compiled without the option won't stop an attack, we recommend that you use the
option on all the code you compile. There's a small runtime cost for CFG checks, but the
compiler analysis attempts to optimize away the checks on indirect jumps that can be
proven to be safe.
To set this compiler option in the Visual Studio
development environment
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select the Control Flow Guard property.
4. In the dropdown control, choose Yes to enable Control Flow Guard, or No to
disable it.
See also
MSVC compiler options
MSVC compiler command-line syntax
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
/guard:ehcont (Enable EH Continuation
Metadata)
Article • 08/03/2021
Enables generation of EH Continuation (EHCONT) metadata by the compiler.
Syntax
/guard:ehcont [ - ]
Remarks
The /guard:ehcont option causes the compiler to generate a sorted list of the relative
virtual addresses (RVA) of all the valid exception handling continuation targets for a
binary. It's used during runtime for NtContinue and SetThreadContext instruction
pointer validation. By default, /guard:ehcont is off and must be explicitly enabled. To
explicitly disable this option, use /guard:ehcont- .
The /guard:ehcont option is available in Visual Studio 2019 version 16.7 and later. The
feature is supported for 64-bit processes on a 64-bit OS.
Control-flow Enforcement Technology (CET) is a hardware-based security feature that
protects against Return-Oriented Programming (ROP)-based attacks. It maintains a
"shadow stack" for every call stack to enforce control-flow integrity.
When shadow stacks are available to prevent ROP attacks, attackers move on to use
other exploit techniques. One technique they may use is to corrupt the instruction
pointer value inside the CONTEXT structure. This structure gets passed into system calls
that redirect the execution of a thread, such as NtContinue , RtlRestoreContext, and
SetThreadContext. The CONTEXT structure is stored in memory. Corrupting the
instruction pointer it contains can cause the system calls to transfer execution to an
attacker-controlled address. Currently, NTContinue can be called with any continuation
point. That's why it's essential to validate the instruction pointer when shadow stacks are
enabled.
RtlRestoreContext and NtContinue are used during Structured Exception Handling
(SEH) exception unwinding to unwind to the target frame that contains the __except
block. The instruction pointer of the __except block isn't expected to be on the shadow
stack, because it would fail instruction pointer validation. The /guard:ehcont compiler
switch generates an "EH Continuation Table". It contains a sorted list of the RVAs of all
valid exception handling continuation targets in the binary. NtContinue first checks the
shadow stack for the user-supplied instruction pointer, and if the instruction pointer
isn't found there, it proceeds to check the EH Continuation Table from the binary that
contains the instruction pointer. If the containing binary wasn't compiled with the table,
then for compatibility with legacy binaries, NtContinue is allowed to continue. It's
important to distinguish between legacy binaries that have no EHCONT data, and
binaries containing EHCONT data but no table entries. The former allow all addresses
inside the binary as valid continuation targets. The latter don't allow any address inside
the binary as a valid continuation target.
The /guard:ehcont option must be passed to both the compiler and linker to generate
EH continuation target RVAs for a binary. If your binary is built by using a single cl
command, the compiler passes the option to the linker. The compiler also passes the
/guard:cf option to the linker. If you compile and link separately, these options must be
set on both the compiler and linker commands.
You can link code compiled by using /guard:ehcont to libraries and object files
compiled without it. The linker returns a fatal error in any of these scenarios:
A code section has "local unwind". For more information, see Abnormal
termination in try-finally Statement.
An EH (xdata) section contains pointers to a code section, and they aren't for SEH.
The pointers are for SEH, but the object file wasn't compiled using function-level
linking (/Gy) to produce COMDATs.
The linker returns a fatal error, because it can't generate metadata in these scenarios.
That means throwing an exception is likely to cause a crash at runtime.
For SEH section info found in COMDATs, but not compiled using /guard:ehcont , the
linker emits warning LNK4291. In this case, the linker generates correct but conservative
metadata for the section. To ignore this warning, use /IGNORE (Ignore Specific
Warnings).
If the linker is unable to generate metadata, it emits one of the following errors:
LNK2046: module contains _local_unwind but was not compiled with
/guard:ehcont
LNK2047: module contains C++ EH or complex EH metadata but was not compiled
with /guard:ehcont.
To check if a binary contains EHCONT data, look for the following elements when
dumping the binary's load config:
Windows Command Prompt
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select the Enable EH Continuation Metadata property.
4. In the dropdown control, choose Yes (/guard:ehcont) to enable EH continuation
metadata, or No (/guard:ehcont-) to disable it.
/guard (Enable Control Flow Guard)
MSVC Compiler Options
e:\>link /dump /loadconfig CETTest.exe
...
 10417500 Guard Flags
...
 EH Continuation table present // EHCONT guard
flag present
...
 0000000180018640 Guard EH continuation table
 37 Guard EH continuation count // May be 0 if no
exception handling is used in the binary. Still counts has having EHCONT
data.
...
 Guard EH Continuation Table // List of RVAs
 Address
 --------
 0000000180002CF5
 0000000180002F03
 0000000180002F0A
...
To set this compiler option in the Visual Studio
development environment
See also
MSVC Compiler Command-Line Syntax
/GT (Support fiber-safe thread-local
storage)
Article • 08/03/2021
Supports fiber safety for data allocated using static thread-local storage, that is, data
allocated with __declspec(thread) .
Syntax
/GT
Remarks
Data declared with __declspec(thread) is referenced through a thread-local storage
(TLS) array. The TLS array is an array of addresses that the system maintains for each
thread. Each address in this array gives the location of thread-local storage data.
A fiber is a lightweight object that consists of a stack and a register context and can be
scheduled on various threads. A fiber can run on any thread. Because a fiber may get
swapped out and restarted later on a different thread, the compiler mustn't cache the
address of the TLS array, or optimize it as a common subexpression across a function
call. /GT prevents such optimizations.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Enable Fiber-safe Optimizations property.
To set this compiler option programmatically
See EnableFiberSafeOptimizations.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Gw (Optimize Global Data)
Article • 08/03/2021
Package global data in COMDAT sections for optimization.
Syntax
/Gw[-]
Remarks
The /Gw option causes the compiler to package global data in individual COMDAT
sections. By default, /Gw is off and must be explicitly enabled. To explicitly disable it, use
/Gw-. When both /Gw and /GL are enabled, the linker uses whole-program optimization
to compare COMDAT sections across multiple object files in order to exclude
unreferenced global data or to merge identical read-only global data. This can
significantly reduce the size of the resulting binary executable.
When you compile and link separately, you can use the /OPT:REF linker option to
exclude from the executable the unreferenced global data in object files compiled with
the /Gw option.
You can also use the /OPT:ICF and /LTCG linker options together to merge in the
executable any identical read-only global data across multiple object files compiled with
the /Gw option.
For more information, see Introducing /Gw Compiler Switch on the C++ Team Blog.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Gw and then choose OK.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GX (Enable Exception Handling)
Article • 08/03/2021
Deprecated. Enables synchronous exception handling using the assumption that
functions declared by using extern "C" never throw an exception.
Syntax
/GX
Remarks
/GX is deprecated. Use the equivalent /EHsc option instead. For a list of deprecated
compiler options, see the Deprecated and Removed Compiler Options section in
Compiler Options Listed by Category.
By default, /EHsc, the equivalent of /GX, is in effect when you compile by using the
Visual Studio development environment. When using the command line tools, no
exception handling is specified. This is the equivalent of /GX-.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/EH (Exception Handling Model)
/Gy (Enable Function-Level Linking)
Article • 08/03/2021
Allows the compiler to package individual functions in the form of packaged functions
(COMDATs).
Syntax
/Gy[-]
Remarks
The linker requires that functions be packaged separately as COMDATs to exclude or
order individual functions in a DLL or .exe file.
You can use the linker option /OPT (Optimizations) to exclude unreferenced packaged
functions from the .exe file.
You can use the linker option /ORDER (Put Functions in Order) to include packaged
functions in a specified order in the .exe file.
Inline functions are always packaged if they are instantiated as calls (which occurs, for
example, if inlining is off or you take a function address). In addition, C++ member
functions defined in the class declaration are automatically packaged; other functions
are not, and selecting this option is required to compile them as packaged functions.
７ Note
The /ZI option, used for Edit and Continue, automatically sets the /Gy option.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable Function-Level Linking property.
To set this compiler option programmatically
See EnableFunctionLevelLinking.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/GZ (Enable Stack Frame Run-Time Error
Checking)
Article • 08/03/2021
Performs the same operations as the /RTC (Run-Time Error Checks) option. Deprecated.
Syntax
/GZ
Remarks
/GZ is only for use in a nonoptimized (/Od (Disable (Debug))) build.
/GZ is deprecated since Visual Studio 2005; use /RTC (Run-Time Error Checks) instead.
For a list of deprecated compiler options, see Deprecated and Removed Compiler
Options in Compiler Options Listed by Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/H (Restrict Length of External Names)
Article • 08/03/2021
Deprecated. Restricts the length of external names.
Syntax
/Hnumber
Arguments
number
Specifies the maximum length of external names allowed in a program.
Remarks
By default, the length of external (public) names is 2,047 characters. This is true for C
and C++ programs. Using /H can only decrease the maximum allowable length of
identifiers, not increase it. A space between /H and number is optional.
If a program contains external names longer than number, the extra characters are
ignored. If you compile a program without /H and if an identifier contains more than
2,047 characters, the compiler will generate Fatal Error C1064.
The limit on length includes any compiler-created leading underscore (_) or at sign (@).
These characters are part of the identifier and take a significant location.
The compiler adds a leading underscore (_) to names modified by the __cdecl
(default) and __stdcall calling conventions, and a leading at sign (@) to names
modified by the __fastcall calling convention.
The compiler appends argument size information to names modified by the
__fastcall and __stdcall calling conventions, and adds type information to C++
names.
You may find /H useful:
When you create mixed-language or portable programs.
When you use tools that impose limits on the length of external identifiers.
When you want to restrict the amount of space that symbols use in a debug build.
The following example shows how using /H can actually introduce errors if identifier
lengths are limited too much:
C++
// compiler_option_H.cpp
// compile with: /H5
// processor: x86
// LNK2005 expected
void func1(void);
void func2(void);
int main() { func1(); }
void func1(void) {}
void func2(void) {}
You must also be careful when using the /H option because of predefined compiler
identifiers. If the maximum identifier length is too small, certain predefined identifiers
will be unresolved as well as certain library function calls. For example, if the printf
function is used and the option /H5 is specified at compile time, the symbol _prin will
be created in order to reference printf , and this will not be found in the library.
Use of /H is incompatible with /GL (Whole Program Optimization).
The /H option is deprecated since Visual Studio 2005; the maximum length limits have
been increased and /H is no longer needed. For a list of deprecated compiler options,
see Deprecated and Removed Compiler Options in Compiler Options Listed by
Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/headerName (Build a header unit from
the specified header)
Article • 11/18/2022
Build the specified header file into a header unit ( .ifc file).
Syntax
/headerName:quote header-filename
/headerName:angle header-filename
Arguments
header-filename
The name of a header file that the compiler should compile into a header unit ( .ifc
file).
Remarks
The /headerName:quote and /headerName:angle compiler options are available starting in
Visual Studio 2019 version 16.10.
The /headerName compiler options, in all their forms, require the /std:c++20 or later
compiler option (such as /std:c++latest ).
If you specify a /headerName option, you must also specify /exportHeader.
/headerName:quote looks up header-filename using the same rules as #include
"header-filename" and builds it as a header unit ( .ifc file).
/headerName:angle looks up header-filename using the same rules as #include
<header-filename> and builds it as a header unit ( .ifc file).
For more information about the path searching rules for included files in quotes or
angle brackets, see #include directive.
Examples
Given a project that references a header file it defines called m.h , the compiler option to
compile it into a header unit looks similar to this example:
Bash
cl /std:c++latest /exportHeader /headerName:quote m.h /Fom.h.obj
The /headerName:quote and /headerName:angle options act like a flag and don't need an
argument. The following examples are valid:
Bash
cl /std:c++latest /exportHeader /headerName:angle /MP /Fo.\ vector iostream
algorithm
cl /std:c++latest /exportHeader /headerName:quote /MP /Fo.\ my-utilities.h
a/b/my-core.h
You can specify multiple /headerName options on the same command line. Every
argument after a /headerName option is processed with the specified include file lookup
rules for quotes or angle brackets until the next /headerName option. The following
example processes all the headers as the previous two command line examples in the
same way as before. It looks up the headers using the lookup rules applied as if they
had been specified as: #include <vector> , #include <iostream> , #include <algorithm> ,
#include "my-utilties.h" , and #include "a/b/my-core.h" :
Bash
cl /std:c++latest /exportHeader /headerName:angle /MP /Fo.\ vector iostream
algorithm /headerName:quote my-utilities.h a/b/my-core.h
To set this compiler option in the Visual Studio
development environment
７ Note
You normally shouldn't set this option in the Visual Studio development
environment. It's set by the build system.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Set the Configuration drop-down to All Configurations. Set the Platform drop￾down to All Platforms.
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional Options property to add the /headerName:quote or
/headerName:angle options and the header filenames the options apply to. Then,
choose OK or Apply to save your changes.
See also
/exportHeader (Create header units)
/headerUnit (Use header unit IFC)
/reference (Use named module IFC)
/translateInclude (Translate include directives into import directives)
/headerUnit (Use header unit IFC)
Article • 05/28/2024
Imports a header unit. Tells the compiler where to find the .ifc file (the binary
representation of the header unit) for the specified header.
Syntax
/headerUnit header-filename =ifc-filename
/headerUnit:quote header-filename =ifc-filename
/headerUnit:angle header-filename =ifc-filename
Arguments
header-filename
During import header-name; the compiler resolves header-name to a file on disk. Use
header-filename to specify that file. Once matched, the compiler opens the
corresponding IFC named by ifc-filename for import.
ifc-filename
The name of a file that contains compiled header unit information. To import more than
one header unit, add a separate /headerUnit option for each file.
Remarks
The /headerUnit compiler option requires /std:c++20 or later.
The /headerUnit compiler option is available in Visual Studio 2019 version 16.10 or later.
When the compiler comes across import "file"; or import <file>; this compiler
option helps the compiler find the compiled header unit ( .ifc ) for the specified header
file. The path to this file can be expressed in these ways:
/headerUnit looks up the compiled header unit in the current directory, or at the
location specified by ifc-filename .
/headerUnit:quote looks up the compiled header unit file using the same rules as
#include "file" .
/headerUnit:angle looks up the compiled header unit file using the same rules as
#include <file> .
The compiler can't map a single header-name to multiple .ifc files. You can map
multiple header-name arguments to a single .ifc . The contents of the .ifc are
imported as if it was only the header specified by header-name .
The compiler implicitly enables the new preprocessor when this option is used. If any
form of /headerUnit is specified on the command line, then /Zc:preprocessor is added
to the command line by the compiler. To opt out of the implicit /Zc:preprocessor ,
specify: /Zc:preprocessor￾If you disable the new preprocessor, but a file you compile imports a header unit, the
compiler will report an error.
Given a project that references two header files and their header units as listed in this
table:
Header file IFC file
C:\utils\util.h C:\util.h.ifc
C:\app\app.h C:\app\app.h.ifc
The compiler options to reference the header units for these particular header files
would look like this:
CMD
You normally shouldn't set this in the Visual Studio development environment. It's set by
the build system.
Examples
ﾉ Expand table
cl ... /std:c++latest /headerUnit C:\utils\util.h=C:\util.h.ifc
/headerUnit:quote app.h=app.h.ifc
To set this compiler option in the Visual Studio
development environment
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
/exportHeader (Create header units)
/headerName (Create a header unit from the specified header)
/reference (Use named module IFC)
/translateInclude (Translate include directives into import directives)
See also
 Yes  No
/HELP (Compiler Command-Line Help)
Article • 08/03/2021
Displays a listing of compiler options to standard output.
Syntax
/HELP
/help
/?
Remarks
To set this compiler option in the Visual Studio
development environment
This compiler option should only be accessed from the command line.
To set this compiler option programmatically
This compiler option cannot be changed programmatically.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/homeparams (Copy Register
Parameters to Stack)
Article • 08/03/2021
Forces parameters passed in registers to also be written to their locations on the stack
upon function entry.
Syntax
/homeparams
Remarks
This compiler option is only available in the native and cross-compilers that target x64.
The x64 calling convention requires stack space to be allocated for all parameters, even
for parameters passed in registers. For more information, see Parameter Passing. By
default, the register parameters aren't copied into the stack space allocated for them in
release builds. This makes it difficult to debug an optimized release build of your
program.
For release builds, you can use the /homeparams option to force the compiler to copy
register parameters to the stack, to ensure that you can debug your application.
/homeparams does imply a performance disadvantage, because it requires an extra
cycle to load the register parameters onto the stack.
In debug builds, the stack is always populated with parameters passed in registers.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/hotpatch (Create Hotpatchable Image)
Article • 12/09/2021
Prepares an image for hot patching.
Syntax
/hotpatch
Remarks
When /hotpatch is used in a compilation, the compiler ensures that the first instruction
of each function is at least two bytes, and no jump within the function goes to the first
instruction. These conditions are required for hot patching.
To complete the preparation for making an image hotpatchable, after you use /hotpatch
to compile, you must use /FUNCTIONPADMIN (Create Hotpatchable Image) to link.
When you compile and link an image by using one invocation of cl.exe, /hotpatch
implies /functionpadmin.
Because instructions are always two bytes or larger on the ARM architecture, and
because x64 compilation is always treated as if /hotpatch has been specified, you don't
have to specify /hotpatch when you compile for these targets; however, you must still
link by using /functionpadmin to create hotpatchable images for them. The /hotpatch
compiler option only affects x86 compilation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add the compiler option to the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/I (Additional include directories)
Article • 08/03/2021
Adds a directory to the list of directories searched for include files.
Syntax
/I directory
Arguments
directory
The directory to add to the list of directories searched for include files. The space
between /I and directory is optional. Directories that include spaces must be enclosed
in double quotes. A directory may be an absolute path or a relative path.
Remarks
To add more than one directory, use this option more than once. Directories are
searched only until the specified include file is found.
You can use this option on the same command line as the (/X (Ignore standard include
paths)) option.
A #include directive can be specified in double-quote (or local-first) form, for example,
#include "local.h" . Or, it can be specified in angle-bracket (or include-path-first) form,
for example, #include <iostream> .
The compiler searches directories in the following order:
1. If the #include directive is specified using double-quote form, it first searches local
directories. The search begins in the same directory as the file that contains the
#include directive. If it fails to find the file, it searches next in the directories of the
currently opened include files, in the reverse order in which they were opened. The
search begins in the directory of the parent include file and continues upward
through the directories of any grandparent include files.
2. If the #include directive is specified in angle-bracket form, or if the local directory
search has failed, it searches directories specified by using the /I option, in the
order they're specified on the command line.
3. Directories specified in the INCLUDE environment variable.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Additional Include Directories property. You can specify more than
one directory at a time in this property. Directories must be separated by a
semicolon ( ; ).
To set this compiler option programmatically
See AdditionalIncludeDirectories.
Example
The following command looks for the include files requested by main.c in the following
order: First, if specified by using double-quotes, local files are searched. Next, search
continues in the \include directory, then in the \my\include directory, and finally in the
directories assigned to the INCLUDE environment variable, in left to right order.
Windows Command Prompt
CL /I \include /I\my\include main.c
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/ifcOutput
Article • 11/22/2022
This switch tells the compiler where to output built .ifc files. If the destination is a
directory, then the compiler generates the name of each .ifc file based on the interface
name or the header unit name.
Syntax
/ifcOutput filename
/ifcOutput directory\
Remarks
By default, the compiler derives the name for each generated .ifc file from the module
interface name. For example, given a module name MyModule , the generated .ifc will
be named MyModule.ifc , unless you override the name with the /ifcOutput switch.
Use this switch to specify an alternative .ifc filename or directory. If you want to use
the default built .ifc filenames, but specify a directory where they should be built,
ensure that you add a trailing backslash ( \ ) to the directory name.
When you're building multiple .ifc files, only use the directory form of the /ifcOutput
switch. If you provide multiple /ifcOutput switches, the compiler only uses the last one.
If you build with the /MP (Build with multiple processes) switch, we recommend that you
use the directory form of the /ifcOutput switch if you have multiple input module files.
In the following example, the .ifc file for module m defined in m.ixx is built as
c:\example\m.ifc .
Bash
cl ... /c /std:c++latest m.ixx /ifcOutput c:\example\
In the following example, the built .ifc file for module m defined in m.ixx * is built as
c:\example\MyModule.ifc :
Bash
cl ... /c /std:c++latest m.ixx /ifcOutput c:\example\MyModule.ifc
To set this compiler option in the Visual Studio
development environment
1. To apply the /ifcOutput option to one file in the IDE, select the file in Solution
Explorer. Right-click to open the context menu and select Properties to open the
Property Pages dialog.
2. Set the Configuration dropdown to All Configurations. Set the Platform
dropdown to All Platforms.
3. Open the Configuration Properties > C/C++ > Output Files property page.
4. Use the dropdown control to modify the Module Output File Name property to a
directory name (ending in \ ) or an alternate file name. Or you can specify a
directory + file name, for example, c:\example\mymodule.ifc . Choose OK or Apply
to save your changes.
Alternatively, you can specify the /ifcOutput switch with a right-click on the project
name in the Solution Explorer > Configuration Properties > C/C++ > Command Line.
See also
Overview of modules in C++
Using C++ Modules in MSVC from the Command Line
/ifcMap
Article • 10/17/2023
This switch tells the compiler where to find the IFC reference map file, which maps
references to named modules and header units to their corresponding IFC ( .ifc ) files.
Syntax
/ifcMap filename
Remarks
The *filename* argument specifies the IFC reference map file. It can be relative to the
compiler's working directory, or an absolute path.
You can provide multiple /ifcMap arguments to the compiler.
The IFC reference map file format is a subset of the TOML file format. The IFC
reference map file can contain a mix of [[module]] and [[header-unit]] references.
Syntax errors or unrecognized table names result in compiler error C7696 (TOML parse
error).
Map named modules
The format of the IFC reference map file for named modules is:
# Using literal strings
[[module]]
name = 'M'
ifc = 'C:\modules\M.ifc'
# Using basic strings
[[module]]
name = "N"
ifc = "C:\\modules\\N.ifc"
This IFC reference map file maps the named modules 'M' and 'N' to their respective
IFC files. The equivalent `/reference' is:
Windows Command Prompt
/reference M=C:\modules\M.ifc /reference N=C:\modules\N.ifc
For more information about what types of module names are valid for the name field,
see /reference remarks.
Map header units
The format of the IFC reference map file for header units is:
# Using literal strings
[[header-unit]]
name = ['quote', 'my-utility.h']
ifc = 'C:\header-units\my-utility.h.ifc'
[[header-unit]]
name = ['angle', 'vector']
ifc = 'C:\header-units\vector.ifc'
# Using basic strings
[[header-unit]]
name = ["quote", "my-engine.h"]
ifc = "C:\\header-units\\my-engine.h.ifc"
[[header-unit]]
name = ["angle", "algorithm"]
ifc = "C:\\header-units\\algorithm.ifc"
This IFC reference map file maps "my-utility.h" to C:\header-units\my-utility.h.ifc ,
and <vector> to C:\header-units\vector.ifc , and so on. The equivalent /headerUnit is:
Windows Command Prompt
/headerUnit:quote my-utility=C:\header-units\my-utility.h.ifc
/headerUnit:angle vector=C:\header-units\vector.ifc /headerUnit:quote my￾engine.h=C:\header-units\my-engine.h.ifc /headerUnit:angle
algorithm=C:\header-units\algorithm.ifc
When [[header-unit]] is specified in an IFC reference map file, the compiler implicitly
enables /Zc:preprocessor, just as it's implicitly enabled when /headerUnit is used. For
more information about the behavior of the angle and quote lookup methods, see
/headerUnit remarks.
See also
Overview of modules in C++
Walkthrough: Build and import header units in Visual C++ projects
Using C++ Modules in MSVC from the Command Line
/interface
Article • 11/18/2022
This switch instructs the compiler to treat the input file on the command line as a
module interface unit.
Syntax
/interface filename
Remarks
Use this switch when a module interface has a different extension than .ixx .
In the following example, the module interface has a .cppm extension instead of .ixx ,
so the /interface switch is used to compile it as a module interface:
Bash
cl /c /std:c++latest /interface /TP my-module.cppm
The compiler derives the name for the generated .ifc file from the module interface
name. For example, given a module name MyModule defined in my-module.cppm , the
generated .ifc will be named MyModule.ifc .
This switch must be used in with the /TP (Specify source file type) compiler flag.
/interface is available in Visual Studio 2019 version 16.10, or later.
/interface requires /std:c++20 or later.
To set this compiler option in the Visual Studio
development environment
You normally shouldn't set this option in the Visual Studio development environment
unless you use a different extension for your module interface files. By default, the build
system applies this option to files that have a .ixx * extension.
1. To apply the /interface option to a file explicitly in the IDE, select the file in
Solution Explorer. Right-click to open the context menu and select Properties to
open the Property Pages dialog.
2. Set the Configuration dropdown to All Configurations. Set the Platform
dropdown to All Platforms.
3. Open the Configuration Properties > C/C++ > Advanced property page.
4. Use the dropdown control to modify the Compile As property to Compile as C++
Module Code (/interface). Choose OK or Apply to save your changes.
See also
Overview of modules in C++
Using C++ Modules in MSVC from the Command Line
/internalPartition
Article • 11/18/2022
Use the /internalPartition compiler option to treat the input file as an internal
partition unit, which is a module partition implementation unit that doesn't contribute to
the external interface of the module.
Syntax
/internalPartition filename
Remarks
The following example demonstrates how to use the /internalPartition option:
Source file m-internals.cpp :
C++
// m-internals.cpp
module m:internals;
void internalFunc() {} // cannot have `export` since this is an internal
partition
Source file m.ixx :
C++
// m.ixx
export module m;
import :internals; // Cannot export this partition.
export
void wrapper() { internalFunc(); }
To compile this interface:
Bash
cl /std:c++latest /internalPartition /c m-internals.cpp
This option can't be used with the /interface compiler option.
/internalPartition is available in Visual Studio 2019 version 16.10, or later.
/internalPartition requires /std:c++20 or later.
To set this compiler option in the Visual Studio
development environment
You normally shouldn't set this option in the Visual Studio development environment
unless you use a different extension for your partition files. By default, the build system
applies this option to files that have a .ixx * extension.
1. To apply the /internalPartition option to a file explicitly in the IDE, select the file
in Solution Explorer. Right-click to open the context menu and select Properties
to open the Property Pages dialog.
2. Set the Configuration dropdown to All Configurations. Set the Platform
dropdown to All Platforms.
3. Open the Configuration Properties > C/C++ > Advanced property page.
4. Use the dropdown control to modify the Compile As property to Compile as C++
Module Internal Partition (/internalPartition). Choose OK or Apply to save your
changes.
See also
Overview of modules in C++
Using C++ Modules in MSVC from the Command Line
C++ Modules conformance improvements with MSVC in Visual Studio 2019 16.5
/J (Default char Type Is unsigned)
Article • 08/03/2021
Changes the default char type from signed char to unsigned char , and the char type
is zero-extended when it is widened to an int type.
Syntax
/J
Remarks
If a char value is explicitly declared as signed , the /J option does not affect it, and the
value is sign-extended when it is widened to an int type.
The /J option defines _CHAR_UNSIGNED , which is used with #ifndef in the LIMITS.h file to
define the range of the default char type.
ANSI C and C++ do not require a specific implementation of the char type. This option
is useful when you are working with character data that will eventually be translated into
a language other than English.
７ Note
If you use this compiler option with ATL/MFC, an error might be generated.
Although you could disable this error by defining _ATL_ALLOW_CHAR_UNSIGNED , this
workaround is not supported and may not always work.
To set this compiler option in the Visual Studio
development environment
1. Open your project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional Options, enter the /J compiler option.
To set this compiler option programmatically
See DefaultCharIsUnsigned.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Set C++ compiler and build properties in Visual Studio
/JMC (Just My Code debugging)
Article • 03/02/2022
Specifies compiler support for native Just My Code debugging in the Visual Studio
debugger. This option supports the user settings that allow Visual Studio to step over
system, framework, library, and other non-user calls, and to collapse those calls in the
call stack window. The /JMC compiler option is available starting in Visual Studio 2017
version 15.8.
Syntax
/JMC [ - ]
Remarks
The Visual Studio Just My Code settings specify whether the Visual Studio debugger
steps over system, framework, library, and other non-user calls. The /JMC compiler
option enables support for Just My Code debugging in your native C++ code. When
/JMC is enabled, the compiler inserts calls to a helper function,
__CheckForDebuggerJustMyCode , in the function prolog. The helper function provides
hooks that support Visual Studio debugger Just My Code step operations. To enable Just
My Code in the Visual Studio debugger, on the menu bar, choose Tools > Options, and
then set the option in Debugging > General > Enable Just My Code.
The /JMC option requires that your code links to the C Runtime Library (CRT), which
provides the __CheckForDebuggerJustMyCode helper function. If your project doesn't link
to the CRT, you may see linker error LNK2019: unresolved external symbol
__CheckForDebuggerJustMyCode. To resolve this error, either link to the CRT, or disable
the /JMC option.
When the /JMC option is enabled, the PDB file is annotated with extra line number
information. In versions before Visual Studio 2019 version 16.8, this information may
appear in code coverage reports as occurring at line 15732480 (0xF00F00) or 16707566
(0xFEEFEE). These fictitious line numbers are used as markers to delineate user code
from non-user code. To include non-user code in code coverage reports without these
unexpected line numbers, build your code with the /JMC- option.
By default, the /JMC compiler option is off. However, starting in Visual Studio 2017
version 15.8 this option is enabled in most Visual Studio project templates. To explicitly
disable this option, use the /JMC- option on the command line. In Visual Studio, open
the project Property Pages dialog box, and change the Support Just My Code
Debugging property in the Configuration Properties > C/C++ > General property
page to No.
For more information, see C++ Just My Code in Specify whether to debug only user
code using Just My Code in Visual Studio, and the Visual C++ Team Blog post
Announcing C++ Just My Code Stepping in Visual Studio .
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Support Just My Code Debugging property.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/jumptablerdata (put switch case jump
tables in .rdata )
Article • 07/11/2023
Puts the generated switch case jump tables in the .rdata section instead of alongside
code in the .text section.
Syntax
C++
/jumptablerdata
Remarks
Putting jump tables generated for switch case statements in the .rdata section prevents
the jump table from being loaded into both the instruction cache (iCache) and data
cache (dCache), potentially increasing performance. The .rdata section is where const
initialized data is stored.
） Important
This flag only applies to x64 code. This flag was introduced in Visual Studio 17.7.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /jumptablerdata and then
choose OK.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/kernel (Create kernel mode binary)
Article • 08/03/2021
Creates a binary that can be executed in the Windows kernel. The code in the current
project gets compiled and linked by using a simplified set of C++ language features
that are specific to code that runs in kernel mode.
/kernel
Specifying the /kernel option tells the compiler and linker to arbitrate which language
features are permissible in kernel mode and to make sure that you have sufficient
expressive power to avoid runtime instability that is unique to kernel mode C++. It's
done by prohibiting the use of C++ language features that are disruptive in kernel
mode. The compiler produces warnings for C++ language features that are potentially
disruptive but can't be disabled.
The /kernel option applies to both the compiler and linker phases of a build and is set
at the project level. Pass the /kernel switch to indicate to the compiler that the resulting
binary, after linking, should be loaded into the Windows kernel. The compiler will narrow
the spectrum of C++ language features to a subset that is compatible with the kernel.
The following table lists changes in compiler behavior when /kernel is specified.
Behavior
type
/kernel behavior
C++
exception
handling
Disabled. All instances of the throw and try keywords emit a compiler error (except
for the exception specification throw() ). No /EH options are compatible with
/kernel , except for /EH- .
RTTI Disabled. All instances of the dynamic_cast and typeid keywords emit a compiler
error, unless dynamic_cast is used statically.
new and
delete
You must explicitly define the new() or delete() operator. The compiler and runtime
don't supply a default definition.
Syntax
Remarks
Custom calling conventions, the /GS build option, and all optimizations are permitted
when you use the /kernel option. Inlining is largely not affected by /kernel , with the
same semantics honored by the compiler. If you want to make sure that the
__forceinline inlining qualifier is honored, you must make sure that warning C4714 is
enabled so that you know when a particular __forceinline function isn't inlined.
There's no #pragma equivalent to control this option.
When the compiler is passed the /kernel switch, it predefines a preprocessor macro
that's named _KERNEL_MODE and has the value 1. You can use this macro to conditionally
compile code based on whether the execution environment is in user mode or kernel
mode. For example, the following code specifies that the MyNonPagedClass class should
be in a non-pageable memory segment when it's compiled for kernel mode execution.
C++
Some of the following combinations of target architecture and the /arch option
produce an error when they're used with /kernel :
/arch:SSE , /arch:SSE2 , /arch:AVX , /arch:AVX2 , and /arch:AVX512 aren't supported
on x86. Only /arch:IA32 is supported with /kernel on x86.
/arch:AVX , /arch:AVX2 , and /arch:AVX512 aren't supported with /kernel on x64.
Building with /kernel also passes /kernel to the linker. Here's how the option affects
linker behavior:
Incremental linking is disabled. If you add /incremental to the command line, the
linker emits this fatal error:
fatal error LNK1295: '/INCREMENTAL' not compatible with '/KERNEL'
specification; link without '/INCREMENTAL'
#ifdef _KERNEL_MODE
#define NONPAGESECTION __declspec(code_seg("$kerneltext$"))
#else
#define NONPAGESECTION
#endif
class NONPAGESECTION MyNonPagedClass
{
 // ...
};
The linker inspects each object file (or any included archive member from static
libraries) to see whether it could have been compiled by using the /kernel option
but wasn't. If any instances meet this criterion, the linker still successfully links but
might issue a warning, as shown in the following table.
Command /kernel
obj
non- /kernel obj, MASM obj, or
cvtres obj
Mix of /kernel and
non- /kernel objs
link
/kernel
Yes Yes Yes with warning LNK4257
link Yes Yes Yes
LNK4257 linking object not compiled with /KERNEL; image may not run
The /kernel option and the /driver option operate independently. They have no effect
on each other.
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /kernel . Choose OK or Apply to save your
changes.
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
To set the /kernel compiler option in Visual Studio
See also
/link (Pass Options to Linker)
Article • 08/03/2021
Passes one or more linker options to the linker.
Syntax
/link linker-options
Arguments
linker-options
The linker option or options to be passed to the linker.
Remarks
The /link option and its linker options must appear after any file names and CL options.
A space is required between /link and any linker options. For more information, see
MSVC linker reference.
Example
This sample command line compiles hello.cpp and links it to the existing object file
there.obj. It then passes an additional /VERSION command to the linker:
cl /W4 /EHsc hello.cpp there.obj /link /VERSION:3.14
To set this compiler option in the Visual Studio
development environment
The IDE normally sends separate commands to compile and link your code. You can set
linker options in your project property pages.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker folder.
3. Modify one or more properties. Choose OK to save your changes.
To set this compiler option programmatically
This compiler option can't be changed programmatically.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/LN (Create MSIL Module)
Article • 08/03/2021
Specifies that an assembly manifest should not be inserted into the output file.
Syntax
/LN
Remarks
By default, /LN is not in effect (an assembly manifest is inserted into the output file).
When /LN is used, one of the /clr (Common Language Runtime Compilation) options
must also be used.
A managed program that does not have an assembly metadata in the manifest is called
a module. If you compile with /c (Compile Without Linking) and /LN, specify
/NOASSEMBLY (Create a MSIL Module) in the linker phase to create the output file.
You may want to create modules if you want to take a component-based approach to
building assemblies. That is, you can author types and compile them into modules.
Then, you can generate an assembly from one or more modules. For more information
on creating assemblies from modules, see .netmodule Files as Linker Input or Al.exe
(Assembly Linker).
The default file extension for a module is .netmodule.
In releases before Visual Studio 2005, a module was created with /clr:noAssembly.
The MSVC linker accepts .netmodule files as input and the output file produced by the
linker will be an assembly or .netmodule with no run-time dependence on any of the
.netmodules that were input to the linker. For more information, see .netmodule Files as
Linker Input.
To set this compiler option in the Visual Studio
development environment
Specify /NOASSEMBLY (Create a MSIL Module) in the linker phase to create the
output file.
To set this compiler option programmatically
This compiler option cannot be changed programmatically.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/MD, /MT, /LD (Use runtime library)
Article • 01/14/2025
Indicates whether a multithreaded module is a DLL and specifies retail or debug versions
of the runtime library.
Option Description
/MD Use the multithread-specific and DLL-specific version of the runtime library. Defines _MT
and _DLL . The linker uses the MSVCRT.lib import library to resolve runtime symbols.
/MDd Use the debug multithread-specific and DLL-specific version of the runtime library.
Defines _DEBUG , _MT , and _DLL . The linker uses the MSVCRTD.lib import library to
resolve runtime symbols.
/MT Use the multithread, static version of the runtime library. Defines _MT . The linker uses
LIBCMT.lib to resolve runtime symbols.
/MTd Use the debug multithread, static version of the runtime library. Defines _DEBUG and
_MT . The linker uses LIBCMTD.lib to resolve runtime symbols.
/LD Create a DLL.
Passes the /DLL option to the linker. The linker looks for, but does not require, a
DllMain function. If you don't write a DllMain function, the linker inserts a DllMain
function that returns TRUE.
Links the DLL startup code.
Creates an import library ( .lib ), if an export ( .exp ) file is not specified on the
command line. You link the import library to applications that call your DLL.
Syntax
/MD[d]
/MT[d]
/LD[d]
Remarks
ﾉ Expand table
Feedback
Was this page helpful?
Option Description
Interprets /Fe (Name EXE File) as naming a DLL rather than an .exe file. By default, the
program name becomes basename.dll instead of basename.exe.
Implies /MT unless you explicitly specify /MD.
/LDd Create a debug DLL. Defines _MT and _DEBUG .
For more information about C runtime libraries and which libraries are used when you
compile with /clr (Common Language Runtime Compilation), see CRT Library Features.
All modules passed to a given invocation of the linker must have been compiled with
the same runtime library compiler option (/MD, /MT, /LD).
For more information about how to use the debug versions of the runtime libraries, see
C runtime Library Reference.
For more about DLLs, see Create C/C++ DLLs in Visual Studio.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Runtime Library property.
See RuntimeLibrary.
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
The Great C Runtime (CRT) Refactoring
To set this compiler option in the Visual Studio
development environment
To set this compiler option programmatically
See also
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
/exportHeader (Create header units)
Article • 11/18/2022
Tells the compiler to create the header units specified by the input arguments. The
compiler generates header units as IFC ( .ifc ) files.
Syntax
/exportHeader /headerName:angle header-name
/exportHeader /headerName:quote header-name
/exportHeader full path to header file
Arguments
The argument to /exportHeader is a /headerName command-line option that specifies
the name, header-name , of the header file to export.
Remarks
/exportHeader is available starting in Visual Studio 2019 version 16.10.
The /exportHeader compiler option requires you enable the /std:c++20 or later compiler
option (such as /std:c++latest ).
One /exportHeader compiler option can specify as many header-name arguments as
your build requires. You don't need to specify them separately.
The compiler implicitly enables the new preprocessor when this option is used. That is,
/Zc:preprocessor is added to the command line by the compiler if any form of
/exportHeader is used on the command line. To opt out of the implicit
/Zc:preprocessor , use: /Zc:preprocessor￾By default, the compiler doesn't produce an object file when a header unit is compiled.
To produce an object file, specify the /Fo compiler option. For more information, see
/Fo (Object File Name).
You may find it helpful to use the complementary option /showResolvedHeader . The
/showResolvedHeader option prints an absolute path to the file the header-name
argument resolves to.
/exportHeader can handle multiple inputs at once, even under /MP . We recommended
you use /ifcOutput <directory> to create a separate .ifc file for each compilation.
Examples
To build a header unit such as <vector> might look like:
Windows Command Prompt
cl . . . /std:c++latest /exportHeader /headerName:angle vector
Building a local project header such as "utils/util.h" might look like:
Windows Command Prompt
cl . . . /std:c++latest /exportHeader /headerName:quote util/util.h
To set this compiler option in the Visual Studio
development environment
You normally shouldn't set this option in the Visual Studio development environment
unless you use a different extension for your header files. By default, the build system
applies this option to compiled files that have a .h extension, or no extension.
1. To apply the /exportHeader option to a file explicitly in the IDE, select the file in
Solution Explorer. Right-click to open the context menu and select Properties to
open the Property Pages dialog.
2. Set the Configuration dropdown to All Configurations. Set the Platform
dropdown to All Platforms.
3. Open the Configuration Properties > C/C++ > Advanced property page.
4. Use the dropdown control to modify the Compile As property to Compile as C++
Header Unit (/exportHeader). Choose OK or Apply to save your changes.
See also
/headerName (Build a header unit from the specified header)
/headerUnit (Use header unit IFC)
/reference (Use named module IFC)
/translateInclude (Translate include directives into import directives)
/reference (Use named module IFC)
Article • 02/18/2022
Tells the compiler to use an existing IFC ( .ifc ) for the current compilation.
Syntax
/reference module-name=filename
/reference filename
Arguments
filename
The name of a file that contains IFC data, which is prebuilt module information. To
import more than one module, include a separate /reference option for each file.
module-name
A valid name of an exported primary module interface unit name or full module
partition name.
Remarks
In most cases, you won't need to specify this switch because the project system
discovers module dependencies within a solution automatically.
The /reference compiler option requires you enable the /std:c++20 or later compiler
option (such as /std:c++latest ). The /reference option is available starting in Visual
Studio 2019 version 16.10.
If the /reference argument is a filename without a module-name , the file gets opened at
runtime to verify the filename argument names a specific import. It can result in slower
runtime performance in scenarios that have many /reference arguments.
The module-name must be a valid primary module interface unit name or full module
partition name. Examples of primary module interface names include:
M
M.N.O
MyModule
my_module
Examples of full module partition names include:
M:P
M.N.O:P.Q
MyModule:Algorithms
my_module:algorithms
If a module reference is created using a module-name , other modules on the command
line don't get searched if the compiler encounters an import of that name. For example,
given this command line:
Windows Command Prompt
In the case above, if the compiler sees import m; then m.ifc doesn't get searched.
Given three modules as listed in this table:
Module IFC file
M m.ifc
M:Part1 m-part1.ifc
Core.Networking Networking.ifc
The reference options using a filename argument would be like this:
Windows Command Prompt
The reference options using module-name=filename would be like this:
Windows Command Prompt
cl ... /std:c++latest /reference m.ifc /reference m=n.ifc
Examples
cl ... /std:c++latest /reference m.ifc /reference m-part.ifc /reference
Networking.ifc
cl ... /std:c++latest /reference m=m.ifc /reference M:Part1=m-part.ifc
/reference Core.Networking=Networking.ifc
See also
/scanDependencies (List module dependencies in standard form)
/sourceDependencies:directives (List module and header unit dependencies)
/headerUnit (Use header unit IFC)
/exportHeader (Create header units)
/MP (Build with multiple processes)
Article • 06/16/2022
The /MP option can reduce the total time to compile the source files on the command
line. The /MP option causes the compiler to create one or more copies of itself, each in a
separate process. Then these instances simultaneously compile the source files. In some
cases, the total time to build the source files can be reduced significantly.
Syntax
/MP [ processMax ]
Arguments
processMax
(Optional) The maximum number of processes that the compiler can create.
The processMax argument must range from 1 through 65536. Otherwise, the compiler
issues warning message D9014, ignores the processMax argument, and assumes the
maximum number of processes is 1.
If you omit the processMax argument, the compiler retrieves the number of effective
processors on your computer from the operating system, and creates a process for each
processor.
Remarks
The /MP compiler option can significantly reduce build time when you compile many
files. To improve build time, the compiler creates up to processMax copies of itself, and
then uses those copies to compile your source files at the same time. The /MP option
applies to compilations, but not to linking or link-time code generation. By default the
/MP option is off.
The improvement in build time depends on the number of processors on a computer,
the number of files to compile, and the availability of system resources, such as I/O
capacity. Experiment with the /MP option to determine the best setting to build a
particular project. For advice to help you make that decision, see Guidelines.
The /MP option is incompatible with some compiler options and language features. If
you use an incompatible compiler option with the /MP option, the compiler issues
warning D9030 and ignores the /MP option. If you use an incompatible language
feature, the compiler issues error C2813 then ends or continues depending on the
current compiler warning level option.
The following table lists compiler options and language features that are incompatible
with the /MP option:
Option or Language
Feature
Description
#import preprocessor
directive
Converts the types in a type library into C++ classes, and then writes
those classes to a header file.
/E, /EP Copies preprocessor output to the standard output ( stdout ).
/Gm Deprecated. Enables an incremental rebuild.
/showIncludes Writes a list of include files to the standard error ( stderr ).
/Yc Writes a precompiled header file.
If you specify an option or language feature that is incompatible with the /MP option,
you'll receive a diagnostic message. The following table lists the messages and the
behavior of the compiler:
Diagnostic
Message
Description Compiler Behavior
C2813 The #import directive isn't
compatible with the /MP option.
The compilation ends unless a compiler
warning level option specifies otherwise.
Incompatible options and language features
７ Note
Most options are incompatible because if they were permitted, the concurrently
executing compilers would write their output at the same time to the console or to
a particular file. As a result, the output would intermix and be garbled. In some
cases, the combination of options would make the performance worse.
Diagnostic messages
Diagnostic
Message
Description Compiler Behavior
D9014 An invalid value is specified for
the processMax argument.
The compiler ignores the invalid value and
assumes a value of 1.
D9030 The specified option is
incompatible with /MP .
The compiler ignores the /MP option.
Use total build time to measure performance. You can measure the build time with a
physical clock, or you can use software that calculates the difference between when the
build starts and stops. If your computer has multiple processors, a physical clock might
yield more accurate results than a software time measurement.
A computer can have one or more virtual processors, which are also known as effective
processors, for each of its physical processors. Each physical processor can have one or
more cores, and if the operating system enables hyperthreading for a core, each core
appears to be two virtual processors.
For example, a computer has one effective processor if it has one physical processor
that has one core, and hyperthreading is disabled. In contrast, a computer has eight
effective processors if it has two physical processors, each of which has two cores, and
all the cores have hyperthreading enabled. That is, (8 effective processors) = (2 physical
processors) x (2 cores per physical processor) x (2 effective processors per core because
of hyperthreading).
If you omit the processMax argument in the /MP option, the compiler obtains the
number of effective processors from the operating system, and then creates one process
per effective processor. However, the compiler can't guarantee which process executes
on a particular processor; the operating system makes that decision.
The compiler calculates the number of processes that it will use to compile the source
files. That value is the lesser of the number of source files that you specify on the
Guidelines
Measure performance
Effective processors
Number of processes
command line, and the number of processes that you explicitly or implicitly specify with
the /MP option. You can explicitly set the maximum number of processes if you provide
the processMax argument of the /MP option. Or you can use the default, which is equal
to the number of effective processors in a computer, if you omit the processMax
argument.
For example, suppose you specify the following command line:
cl /MP7 a.cpp b.cpp c.cpp d.cpp e.cpp
In this case, the compiler uses five processes because that is the lesser of five source
files and a maximum of seven processes. Alternatively, suppose your computer has two
effective processors and you specify the following command line:
cl /MP a.cpp b.cpp c.cpp
In this case, the operating system reports two processors, so the compiler uses two
processes in its calculation. As a result, the compiler uses two processes to execute the
build because that's the lesser of two processes and three source files.
Source files and build order
The source files might not be compiled in the same order in which they appear on the
command line. Although the compiler creates a set of processes that contain copies of
the compiler, the operating system schedules when each process executes. The /MP
option can't guarantee that the source files will be compiled in a particular order.
A source file is compiled when a process is available to compile it. If there are more files
than processes, the first set of files is compiled by the available processes. The
remaining files are processed when a process finishes handling a previous file and is
available to work on one of the remaining files.
Don't specify the same source file multiple times on a command line. Multiple
specifications could occur, for example, if a tool automatically creates a makefile that's
based on dependency information in a project. If you don't specify the /MP option, the
compiler processes the list of files sequentially and recompiles each occurrence of the
file. However, if you specify the /MP option, different compiler instances might compile
the same file at the same time. The different instances may try to write to the same
output file at the same time. One compiler instance acquires exclusive write access to
the output file and succeed, and the other compiler instances fail with a file access error.
Using type libraries ( #import )
The compiler doesn't support the use of the #import directive with the /MP switch. If
possible, follow these steps to work around this problem:
Move all the #import directives in your various source files to one or more files,
and then compile those files without the /MP option. The result is a set of
generated header files.
In your remaining source files, insert #include directives that specify the generated
headers, and then compile your remaining source files by using the /MP option.
Visual Studio Project settings
The MSBuild tool
Visual Studio uses the MSBuild tool ( msbuild.exe ) to build solutions and projects. The
/maxcpucount:number (or /m:number ) command-line option of the MSBuild tool can build
multiple projects at the same time. And the /MP compiler option can build multiple
compilation units at the same time. If it's appropriate for your application, improve your
solution's build time by using either or both /MP and /maxcpucount .
The build time of your solution partly depends on the number of processes that perform
the build. The number argument of the /maxcpucount MSBuild option specifies the
maximum number of projects to build at the same time. Similarly, the processMax
argument of the /MP compiler option specifies the maximum number of compilation
units to build at the same time. If the /maxcpucount option specifies P projects and the
/MP option specifies C processes, a maximum of P x C processes execute at the same
time.
The guideline for deciding whether to use MSBuild or /MP technology is as follows:
If there are many projects with few files in each project, use the MSBuild tool with
the /maxcpucount option.
If there are few projects with many files in each project, use the /MP option.
If the number of projects and files per project is balanced, use both MSBuild and
/MP . Initially set the /maxcpucount option to the number of projects to build and
the /MP option to the number of processors on your computer. Measure
performance and then adjust your settings to yield the best results. Repeat that
cycle until you're satisfied with the total build time.
See also
#import directive
MSBuild command-line reference
/Zf (Faster PDB generation)
/nologo (Suppress Startup Banner)
(C/C++)
Article • 08/03/2021
Suppresses the display of the copyright banner when the compiler starts up and display
of informational messages during compiling.
Syntax
/nologo
Remarks
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Suppress Startup Banner property.
To set this compiler option programmatically
See SuppressStartupBanner.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/O options (Optimize code)
Article • 08/03/2021
The /O options control various optimizations that help you create code for maximum
speed or minimum size.
/O1 sets a combination of optimizations that generate minimum size code.
/O2 sets a combination of optimizations that optimizes code for maximum speed.
/Ob controls inline function expansion.
/Od disables optimization, to speed compilation and simplify debugging.
/Og (deprecated) enables global optimizations.
/Oi generates intrinsic functions for appropriate function calls.
/Os tells the compiler to favor optimizations for size over optimizations for speed.
/Ot (a default setting) tells the compiler to favor optimizations for speed over
optimizations for size.
/Ox is a combination option that selects several of the optimizations with an
emphasis on speed. /Ox is a strict subset of the /O2 optimizations.
/Oy suppresses the creation of frame pointers on the call stack for quicker function
calls.
Remarks
You can combine multiple /O options into a single option statement. For example, /Odi
is the same as /Od /Oi . Certain options are mutually exclusive and cause a compiler
error if used together. For more information, see the individual /O options.
See also
MSVC compiler options
MSVC compiler command-line syntax
/O1 , /O2 (Minimize Size, Maximize
Speed)
Article • 08/03/2021
Selects a predefined set of options that affect the size and speed of generated code.
/O1
/O2
The /O1 and /O2 compiler options are a quick way to set several specific optimization
options at once. The /O1 option sets the individual optimization options that create the
smallest code in the majority of cases. The /O2 option sets the options that create the
fastest code in the majority of cases. The /O2 option is the default for release builds.
This table shows the specific options that are set by /O1 and /O2 :
Option Equivalent to
/O1 (Minimize Size) /Og /Os /Oy /Ob2 /GF /Gy
/O2 (Maximize Speed) /Og /Oi /Ot /Oy /Ob2 /GF /Gy
/O1 and /O2 are mutually exclusive.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
Syntax
Remarks
７ Note
x86-specific
These options imply the use of the Frame-Pointer Omission (/Oy) option.
To set this compiler option in the Visual Studio
development environment
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Optimization property.
To set this compiler option programmatically
See Optimization.
See also
/O options (Optimize code)
MSVC compiler options
MSVC compiler command-line syntax
/EH (Exception handling model)
/Ob (Inline Function Expansion)
Article • 08/03/2021
Controls inline expansion of functions. By default, when optimizing, expansion occurs at
the compiler's discretion on all functions, often referred to as auto-inlining.
Syntax
/Ob{0|1|2|3}
Arguments
0
The default value under /Od. Disables inline expansions.
1
Allows expansion only of functions marked inline, __inline, or __forceinline, or in a C++
member function defined in a class declaration.
2
The default value under /O1 and /O2. Allows the compiler to expand any function not
explicitly marked for no inlining.
3
This option specifies more aggressive inlining than /Ob2, but has the same restrictions.
The /Ob3 option is available starting in Visual Studio 2019.
Remarks
The compiler treats the inline expansion options and keywords as suggestions. There's
no guarantee that any function will be expanded inline. You can disable inline
expansions, but you can't force the compiler to inline a particular function, even when
using the __forceinline keyword.
To exclude functions from consideration as candidates for inline expansion, you can use
__declspec(noinline), or a region marked by #pragma auto_inline(off) and #pragma
auto_inline(on) directives. For information on another way to provide inlining hints to
the compiler, see the #pragma intrinsic directive.
７ Note
Information that is gathered from profiling test runs overrides optimizations that
would otherwise be in effect because you specified /Ob, /Os, or /Ot. For more
information, see Profile-Guided Optimizations.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Inline Function Expansion property.
The /Ob3 option isn't available in the Inline Function Expansion property. To set /Ob3:
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter /Ob3 in Additional Options.
To set this compiler option programmatically
See InlineFunctionExpansion.
See also
/O Options (Optimize Code)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Od (Disable (Debug))
Article • 08/03/2021
Turns off all optimizations in the program and speeds compilation.
Syntax
/Od
Remarks
This option is the default. Because /Od suppresses code movement, it simplifies the
debugging process. For more information about compiler options for debugging, see
/Z7, /Zi, /ZI (Debug Information Format).
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Optimization property.
To set this compiler option programmatically
See Optimization.
See also
/O Options (Optimize Code)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Z7, /Zi, /ZI (Debug Information Format)
/Og (Global Optimizations)
Article • 10/20/2021
Deprecated. Provides local and global optimizations, automatic-register allocation, and
loop optimization. We recommend you use either /O1 (Minimize Size) or /O2 (Maximize
Speed) instead.
Syntax
/Og
Remarks
/Og is deprecated. These optimizations are now enabled by default when any
optimizations are enabled. For more information on optimizations, see /O1, /O2
(Minimize Size, Maximize Speed), or /Ox (Enable Most Speed Optimizations).
The following optimizations are available under /Og :
Local and global common subexpression elimination
In this optimization, the value of a common subexpression is calculated once. In
the following example, if the values of b and c don't change between the three
expressions, the compiler can assign the calculation of b + c to a temporary
variable, and use that variable for b + c :
C
a = b + c;
d = b + c;
e = b + c;
For local common subexpression optimization, the compiler examines short
sections of code for common subexpressions. For global common subexpression
optimization, the compiler searches entire functions for common subexpressions.
Automatic register allocation
This optimization allows the compiler to store frequently used variables and
subexpressions in registers. The register keyword is ignored by default, and
causes a diagnostic under /std:c++17 or later.
Loop optimization
This optimization removes invariant subexpressions from the body of a loop. An
optimal loop contains only expressions whose values change through each
execution of the loop. In the following example, the expression x + y doesn't
change in the loop body:
C
i = -100;
while( i < 0 ) {
 i += x + y;
}
After optimization, x + y is calculated once rather than every time the loop is
executed:
C
i = -100;
t = x + y;
while( i < 0 ) {
 i += t;
}
Loop optimization is much more effective when the compiler can assume no
aliasing, which you set with __restrict, noalias, or restrict.
７ Note
You can enable or disable global optimization on a function-by-function basis
using the optimize pragma together with the g option.
For related information, see /Oi (Generate intrinsic functions) and /Ox (Enable most
speed optimizations).
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Command-Line Syntax
/Oi (Generate Intrinsic Functions)
Article • 08/03/2021
Replaces some function calls with intrinsic or otherwise special forms of the function
that help your application run faster.
Syntax
/Oi[-]
Remarks
Programs that use intrinsic functions are faster because they do not have the overhead
of function calls, but may be larger because of the additional code created.
See intrinsic for more information on which functions have intrinsic forms.
/Oi is only a request to the compiler to replace some function calls with intrinsics; the
compiler may call the function (and not replace the function call with an intrinsic) if it
will result in better performance.
x86 Specific
The intrinsic floating-point functions do not perform any special checks on input values
and so work in restricted ranges of input, and have different exception handling and
boundary conditions than the library routines with the same name. Using the true
intrinsic forms implies loss of IEEE exception handling, and loss of _matherr and errno
functionality; the latter implies loss of ANSI conformance. However, the intrinsic forms
can considerably speed up floating-point-intensive programs, and for many programs,
the conformance issues are of little practical value.
You can use the Za compiler option to override generation of true intrinsic floating￾point options. In this case, the functions are generated as library routines that pass
arguments directly to the floating-point chip instead of pushing them onto the program
stack.
END x86 Specific
You also use intrinsic to create intrinsic functions, or function (C/C++) to explicitly force
a function call.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Enable Intrinsic Functions property.
To set this compiler option programmatically
See EnableIntrinsicFunctions.
See also
/O Options (Optimize Code)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Compiler Intrinsics
/Os , /Ot (Favor Small Code, Favor Fast
Code)
Article • 04/19/2022
The /Os and /Ot compiler options specify whether to favor size ( /Os ) or speed ( /Ot )
when optimizing code.
Syntax
/Os
/Ot
Remarks
/Os (Favor Small Code) minimizes the size of EXEs and DLLs by instructing the compiler
to favor size over speed. The compiler can reduce many C and C++ constructs to
functionally similar sequences of machine code. Occasionally these differences offer
tradeoffs of size versus speed. The /Os and /Ot options allow you to specify a
preference for one over the other:
/Ot (Favor Fast Code) maximizes the speed of EXEs and DLLs by instructing the compiler
to favor speed over size. /Ot is the default when optimizations are enabled. The
compiler can reduce many C and C++ constructs to functionally similar sequences of
machine code. Occasionally, these differences offer tradeoffs of size versus speed. The
/Ot option is implied by the /O2 (Maximize speed) option. The /O2 option combines
several options to produce faster code.
７ Note
Information that's gathered from profiling test runs overrides any optimizations
that would otherwise be in effect if you specify /Ob , /Os , or /Ot . For more
information, see Profile-Guided Optimizations.
x86-specific example
The following example code demonstrates the difference between the /Os (Favor small
code) option and the /Ot (Favor fast code) option:
C
As shown in the fragment of machine code below, when differ.c is compiled for size
( /Os ), the compiler implements the multiply expression in the return statement explicitly
as a multiply to produce a short but slower sequence of code:
asm
Alternately, when differ.c is compiled for speed ( /Ot ), the compiler implements the
multiply expression in the return statement as a series of shift and LEA instructions to
produce a fast but longer sequence of code:
asm
７ Note
This example describes the expected behavior when using /Os or /Ot . However,
compiler behavior from release to release may result in different optimizations for
the code below.
/* differ.c
 This program implements a multiplication operator
 Compile with /Os to implement multiply explicitly as multiply.
 Compile with /Ot to implement as a series of shift and LEA instructions.
*/
int differ(int x)
{
 return x * 71;
}
mov eax, DWORD PTR _x$[ebp]
imul eax, 71 ; 00000047H
mov eax, DWORD PTR _x$[ebp]
mov ecx, eax
shl eax, 3
lea eax, DWORD PTR [eax+eax*8]
sub eax, ecx
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Favor Size or Speed property.
To set this compiler option programmatically
See FavorSizeOrSpeed.
See also
/O options (Optimize code)
MSVC compiler options
MSVC compiler command-line syntax
/Ox (Enable Most Speed Optimizations)
Article • 08/03/2021
The /Ox compiler option enables a combination of optimizations that favor speed. In
some versions of the Visual Studio IDE and the compiler help message, it's called full
optimization, but the /Ox compiler option enables only a subset of the speed
optimization options enabled by /O2 .
Syntax
/Ox
Remarks
The /Ox compiler option enables the /O compiler options that favor speed. The /Ox
compiler option doesn't include the additional /GF (Eliminate Duplicate Strings) and /Gy
(Enable Function-Level Linking) options enabled by /O1 or /O2 (Minimize Size, Maximize
Speed). The additional options applied by /O1 and /O2 can cause pointers to strings or
to functions to share a target address, which can affect debugging and strict language
conformance. The /Ox option is an easy way to enable most optimizations without
including /GF and /Gy . For more information, see the descriptions of the /GF and /Gy
options.
The /Ox compiler option is the same as using the following options in combination:
/Ob (Inline Function Expansion), where the option parameter is 2 ( /Ob2 )
/Oi (Generate Intrinsic Functions)
/Ot (Favor Fast Code)
/Oy (Frame-Pointer Omission)
/Ox is mutually exclusive from:
/O1 (Minimize Size)
/O2 (Maximize Speed)
/Od (Disable (Debug))
You can cancel the bias toward speed of the /Ox compiler option if you specify /Oxs ,
which combines the /Ox compiler option with /Os (Favor Small Code). The combined
options favor smaller code size. The /Oxs option is exactly the same as specifying /Ox
/Os when the options appear in that order.
To apply all available file-level optimizations for release builds, we recommend you
specify /O2 (Maximize Speed) instead of /Ox , and /O1 (Minimize Size) instead of /Oxs .
For even more optimization in release builds, also consider the /GL (Whole Program
Optimization) compiler option and /LTCG (Link-time Code Generation) linker option.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Optimization property.
To set this compiler option programmatically
See Optimization.
See also
/O Options (Optimize Code)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Oy (Frame-Pointer Omission)
Article • 08/03/2021
Suppresses creation of frame pointers on the call stack.
Syntax
/Oy[-]
Remarks
This option speeds function calls, because no frame pointers need to be set up and
removed. It also frees one more register for general usage.
/Oy enables frame-pointer omission and /Oy- disables omission. In x64 compilers, /Oy
and /Oy- are not available.
If your code requires frame-based addressing, you can specify the /Oy- option after the
/Ox option or use optimize with the "y" and off arguments to gain maximum
optimization with frame-based addressing. The compiler detects most situations where
frame-based addressing is required (for instance, with the _alloca and setjmp functions
and with structured exception handling).
The /Ox (Enable Most Speed Optimizations) and /O1, /O2 (Minimize Size, Maximize
Speed) options imply /Oy. Specifying /Oy- after the /Ox, /O1, or /O2 option disables
/Oy, whether it is explicit or implied.
The /Oy compiler option makes using the debugger more difficult because the compiler
suppresses frame pointer information. If you specify a debug compiler option (/Z7, /Zi,
/ZI), we recommend that you specify the /Oy- option after any other optimization
compiler options.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Optimization property page.
3. Modify the Omit Frame Pointers property. This property adds or removes only the
/Oy option. If you want to add the /Oy- option, select the Command Line property
page and modify Additional options.
To set this compiler option programmatically
See OmitFramePointers.
See also
/O Options (Optimize Code)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/openmp (Enable OpenMP Support)
Article • 07/05/2023
Causes the compiler to process #pragma omp directives in support of OpenMP.
Syntax
/openmp
/openmp:experimental
/openmp:llvm
Remarks
#pragma omp is used to specify Directives and Clauses. If /openmp isn't specified in a
compilation, the compiler ignores OpenMP clauses and directives. OpenMP Function
calls are processed by the compiler even if /openmp isn't specified.
The C++ compiler currently supports the OpenMP 2.0 standard. Visual Studio 2019 also
now offers SIMD functionality. To use SIMD, compile using the /openmp:experimental
option. This option enables both the usual OpenMP features, and OpenMP SIMD
features not available when using the /openmp switch.
Starting in Visual Studio 2019 version 16.9, you can use the experimental /openmp:llvm
option instead of /openmp to target the LLVM OpenMP runtime. Support currently isn't
available for production code, since the required libomp DLLs aren't redistributable. The
option supports the same OpenMP 2.0 directives as /openmp . And, it supports all the
SIMD directives supported by the /openmp:experimental option. It also supports
unsigned integer indices in parallel for loops according to the OpenMP 3.0 standard. For
more information, see Improved OpenMP Support for C++ in Visual Studio .
The /openmp:llvm option supports the x64 architecture. Starting with Visual Studio 2019
version 16.10, it also supports the x86 and ARM64 architectures. This option isn't
compatible with /clr or /ZW .
Applications compiled by using both /openmp and /clr can only be run in a single
application domain process. Multiple application domains aren't supported. That is,
when the module constructor ( .cctor ) is run, it detects if the process is compiled using
/openmp , and if the app is loaded into a non-default runtime. For more information, see
appdomain, /clr (Common Language Runtime Compilation), and Initialization of Mixed
Assemblies.
If you attempt to load an app compiled using both /openmp and /clr into a non-default
application domain, a TypeInitializationException exception is thrown outside the
debugger, and a OpenMPWithMultipleAppdomainsException exception is thrown in the
debugger.
These exceptions can also be raised in the following situations:
If your application is compiled using /clr but not /openmp , and is loaded into a
non-default application domain, where the process includes an app compiled
using /openmp .
If you pass your /clr app to a utility, such as regasm.exe, which loads its target
assemblies into a non-default application domain.
The common language runtime's code access security doesn't work in OpenMP regions.
If you apply a CLR code access security attribute outside a parallel region, it won't be in
effect in the parallel region.
Microsoft doesn't recommend that you write /openmp apps that allow partially trusted
callers. Don't use AllowPartiallyTrustedCallersAttribute, or any CLR code access security
attributes.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Expand the Configuration Properties > C/C++ > Language property page.
3. Modify the OpenMP Support property.
To set this compiler option programmatically
See OpenMP.
Example
The following sample shows some of the effects of thread pool startup versus using the
thread pool after it has started. Assuming an x64, single core, dual processor, the thread
pool takes about 16 ms to start up. After that, there's little extra cost for the thread pool.
When you compile using /openmp , the second call to test2 never runs any longer than if
you compile using /openmp- , as there's no thread pool startup. At a million iterations,
the /openmp version is faster than the /openmp- version for the second call to test2. At
25 iterations, both /openmp- and /openmp versions register less than the clock
granularity.
If you have only one loop in your application and it runs in less than 15 ms (adjusted for
the approximate overhead on your machine), /openmp may not be appropriate. If it's
higher, you may want to consider using /openmp .
C++
// cpp_compiler_options_openmp.cpp
#include <omp.h>
#include <stdio.h>
#include <stdlib.h>
#include <windows.h>
volatile DWORD dwStart;
volatile int global = 0;
double test2(int num_steps) {
 int i;
 global++;
 double x, pi, sum = 0.0, step;
 step = 1.0 / (double) num_steps;
 #pragma omp parallel for reduction(+:sum) private(x)
 for (i = 1; i <= num_steps; i++) {
 x = (i - 0.5) * step;
 sum = sum + 4.0 / (1.0 + x*x);
 }
 pi = step * sum;
 return pi;
}
int main(int argc, char* argv[]) {
 double d;
 int n = 1000000;
 if (argc > 1)
 n = atoi(argv[1]);
 dwStart = GetTickCount();
 d = test2(n);
 printf_s("For %d steps, pi = %.15f, %d milliseconds\n", n, d,
GetTickCount() - dwStart);
 dwStart = GetTickCount();
 d = test2(n);
 printf_s("For %d steps, pi = %.15f, %d milliseconds\n", n, d,
GetTickCount() - dwStart);
}
See also
MSVC compiler options
MSVC compiler command-line syntax
OpenMP in MSVC
/options:strict (Unrecognized
compiler options are errors)
Article • 01/10/2022
The /options:strict compiler option tells the compiler to return an error code if a
compiler option isn't recognized.
Syntax
/options:strict
Remarks
The /options:strict compiler option causes the compiler driver cl.exe to exit with an
error code after all command-line options are parsed if another command-line option or
argument isn't recognized. The compiler emits error D8043 for any command-line
option or argument that isn't recognized.
The /options:strict option is available starting in Visual Studio 2022 version 17.0. In
earlier versions of the compiler, or if /options:strict isn't specified, the compiler
doesn't exit on an unrecognized option. It emits warning D9002, ignores the
unrecognized option, and continues processing.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /options:strict to the Additional options: pane.
See also
/Zc (Conformance)
/P (Preprocess to a File)
Article • 08/03/2021
Preprocesses C and C++ source files and writes the preprocessed output to a file.
Syntax
/P
Remarks
The file has the same base name as the source file and an .i extension. In the process, all
preprocessor directives are carried out, macro expansions are performed, and comments
are removed. To preserve comments in the preprocessed output, use the /C (Preserve
Comments During Preprocessing) option along with /P.
/P adds #line directives to the output, at the beginning and end of each included file
and around lines removed by preprocessor directives for conditional compilation. These
directives renumber the lines of the preprocessed file. As a result, errors generated
during later stages of processing refer to the line numbers of the original source file
rather than lines in the preprocessed file. To suppress the generation of #line directives,
use /EP (Preprocess to stdout Without #line Directives) as well as /P.
The /P option suppresses compilation. It does not produce an .obj file, even if you use
/Fo (Object File Name). You must resubmit the preprocessed file for compilation. /P also
suppresses the output files from the /FA, /Fa, and /Fm options. For more information,
see /FA, /Fa (Listing File) and /Fm (Name Mapfile).
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Modify the Generate Preprocessed File property.
To set this compiler option programmatically
See GeneratePreprocessedFile.
Example
The following command line preprocesses ADD.C , preserves comments, adds #line
directives, and writes the result to a file, ADD.I :
CL /P /C ADD.C
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Fi (Preprocess Output File Name)
/permissive- (Standards conformance)
Article • 10/12/2023
Specify standards conformance mode to the compiler. Use this option to help you
identify and fix conformance issues in your code, to make it both more correct and more
portable.
Syntax
/permissive-
/permissive
Remarks
The /permissive- option is supported in Visual Studio 2017 and later. /permissive is
supported in Visual Studio 2019 version 16.8 and later.
You can use the /permissive- compiler option to specify standards-conforming
compiler behavior. This option disables permissive behaviors, and sets the /Zc compiler
options for strict conformance. In the IDE, this option also makes the IntelliSense engine
underline non-conforming code.
The /permissive- option uses the conformance support in the current compiler version
to determine which language constructs are non-conforming. The option doesn't
determine if your code conforms to a specific version of the C++ standard. To enable all
implemented compiler support for the latest draft standard, use the /std:c++latest
option. To restrict the compiler support to the currently implemented C++20 standard,
use the /std:c++20 option. To restrict the compiler support to the currently
implemented C++17 standard, use the /std:c++17 option. To restrict the compiler
support to more closely match the C++14 standard, use the /std:c++14 option, which is
the default.
The /permissive- option is implicitly set by the /std:c++latest option starting in Visual
Studio 2019 version 16.8, and in version 16.11 by the /std:c++20 option. /permissive￾is required for C++20 Modules support. Perhaps your code doesn't need modules
support but requires other features enabled under /std:c++20 or /std:c++latest . You
can explicitly enable Microsoft extension support by using the /permissive option
without the trailing dash. The /permissive option must come after any option that sets
/permissive- implicitly.
By default, the /permissive- option is set in new projects created by Visual Studio 2017
version 15.5 and later versions. It's not set by default in earlier versions. When the
option is set, the compiler generates diagnostic errors or warnings when non-standard
language constructs are detected in your code. These constructs include some common
bugs in pre-C++11 code.
The /permissive- option is compatible with almost all of the header files from the latest
Windows Kits, such as the Software Development Kit (SDK) or Windows Driver Kit
(WDK), starting in the Windows Fall Creators SDK (10.0.16299.0). Older versions of the
SDK may fail to compile under /permissive- for various source code conformance
reasons. The compiler and SDKs ship on different release timelines, so there are some
remaining issues. For specific header file issues, see Windows header issues below.
The /permissive- option sets the /Zc:referenceBinding, /Zc:strictStrings, and
/Zc:rvalueCast options to conforming behavior. These options default to non￾conforming behavior. You can pass specific /Zc options after /permissive- on the
command line to override this behavior.
In versions of the compiler beginning in Visual Studio 2017 version 15.3, the
/permissive- option sets the /Zc:ternary option. The compiler also implements more of
the requirements for two-phase name look-up. When the /permissive- option is set,
the compiler parses function and class template definitions, and identifies dependent
and non-dependent names used in the templates. In this release, only name
dependency analysis is performed.
As of Visual Studio 2022 Update 17.6, the /permissive- option sets the /Zc:lambda and
/Zc:externConstexpr options. In prior versions, /permissive- didn't set either one.
Environment-specific extensions and language areas that the standard leaves up to the
implementation aren't affected by /permissive- . For example, the Microsoft-specific
__declspec , calling convention and structured exception handling keywords, and
compiler-specific pragma directives or attributes aren't flagged by the compiler in
/permissive- mode.
The MSVC compiler in earlier versions of Visual Studio 2017 doesn't support all C++11,
C++14, or C++17 standards-conforming code. Depending on the version of Visual
Studio, the /permissive- option may not detect issues in some aspects of two-phase
name lookup, binding a non-const reference to a temporary, treating copy init as direct
init, allowing multiple user-defined conversions in initialization, or alternative tokens for
logical operators, and other non-supported conformance areas. For more information
about conformance issues in Visual C++, see Nonstandard Behavior. To get the most
out of /permissive- , update Visual Studio to the latest version.
Here are some examples of code that is detected as non-conforming when you use
/permissive- , along with suggested ways to fix the issues.
C++
C++
How to fix your code
Use default as an identifier in native code
void func(int default); // Error C2321: 'default' is a keyword, and
 // cannot be used in this context
Look up members in dependent base
template <typename T>
struct B
{
 void f() {}
 template <typename U>
 struct S { void operator()(){ return; } };
};
template <typename T>
struct D : public B<T> // B is a dependent base because its type
 // depends on the type of T.
{
 // One possible fix for non-template members and function
 // template members is a using statement:
 // using B<T>::f;
 // If it's a type, don't forget the 'typename' keyword.
 void g()
 {
 f(); // error C3861: 'f': identifier not found
 // Another fix is to change the call to 'this->f();'
 }
 void h()
 {
 S<int> s; // C2065 or C3878
 // Since template S is dependent, the type must be qualified
 // with the `typename` keyword.
 // To fix, replace the declaration of s with:
 // typename B<T>::template S<int> s;
 // Or, use this:
 // typename D::template S<int> s;
 s();
C++
C++
A declaration outside a class can make a hidden friend visible:
C++
 }
};
void h() {
 D<int> d;
 d.g();
 d.h();
}
Use of qualified names in member declarations
struct A {
 void A::f() { } // error C4596: illegal qualified name in member
 // declaration.
 // Remove redundant 'A::' to fix.
};
Initialize multiple union members in a member initializer
union U
{
 U()
 : i(1), j(1) // error C3442: Initializing multiple members of
 // union: 'U::i' and 'U::j'.
 // Remove all but one of the initializations to fix.
 {}
 int i;
 int j;
};
Hidden friend name lookup rules
// Example 1
struct S {
 friend void f(S *);
};
// Uncomment this declaration to make the hidden friend visible:
// void f(S *); // This declaration makes the hidden friend visible
Use of literal nullptr can prevent argument dependent lookup:
C++
You can enable the hidden friend name lookup rules independently of /permissive by
using /Zc:hiddenFriend. If you want legacy behavior for hidden friend name lookup, but
otherwise want /permissive- behavior, use the /Zc:hiddenFriend- option.
C++
C++
using type = void (*)(S *);
type p = &f; // error C2065: 'f': undeclared identifier.
// Example 2
struct S {
 friend void f(S *);
};
void g() {
 // Using nullptr instead of S prevents argument dependent lookup in S
 f(nullptr); // error C3861: 'f': identifier not found
 S *p = nullptr;
 f(p); // Hidden friend now found via argument-dependent lookup.
}
Use scoped enums in array bounds
enum class Color {
 Red, Green, Blue
};
int data[Color::Blue]; // error C3411: 'Color' is not valid as the size
 // of an array as it is not an integer type.
 // Cast to type size_t or int to fix.
Use for each in native code
void func() {
 int array[] = {1, 2, 30, 40};
 for each (int i in array) // error C4496: nonstandard extension
 // 'for each' used: replace with
 // ranged-for statement:
 // for (int i: array)
 {
 // ...
Microsoft-specific ATL attributes can cause issues under /permissive- :
C++
You can fix the issue by using the __declspec form instead:
C++
A more complex example:
C++
Resolution requires extra build steps. In this case, create an IDL file:
C++
 }
}
Use of ATL attributes
// Example 1
[uuid("594382D9-44B0-461A-8DE3-E06A3E73C5EB")]
class A {};
// Fix for example 1
class __declspec(uuid("594382D9-44B0-461A-8DE3-E06A3E73C5EB")) B {};
// Example 2
[emitidl];
[module(name="Foo")];
[object, local, uuid("9e66a290-4365-11d2-a997-00c04fa37ddb")]
__interface ICustom {
 HRESULT Custom([in] longl, [out, retval] long*pLong);
 [local] HRESULT CustomLocal([in] longl, [out, retval] long*pLong);
};
[coclass, appobject, uuid("9e66a294-4365-11d2-a997-00c04fa37ddb")]
class CFoo : public ICustom
{};
// Fix for example 2
// First, create the *.idl file. The vc140.idl generated file can be
// used to automatically obtain a *.idl file for the interfaces with
// annotation. Second, add a midl step to your build system to make
// sure that the C++ interface definitions are outputted.
In versions of the compiler before Visual Studio 2017 version 15.3, the compiler
accepted arguments to the conditional operator (or ternary operator) ?: that are
considered ambiguous by the Standard. In /permissive- mode, the compiler now issues
one or more diagnostics in cases that compiled without diagnostics in earlier versions.
Common errors that may result from this change include:
error C2593: 'operator ?' is ambiguous
error C2679: binary '?': no operator found which takes a right-hand operand of
type 'B' (or there is no acceptable conversion)
error C2678: binary '?': no operator found which takes a left-hand operand of
type 'A' (or there is no acceptable conversion)
// Last, adjust your existing code to use ATL directly as shown in
// the atl implementation section.
-- IDL FILE--
import "docobj.idl";
[object, local, uuid(9e66a290-4365-11d2-a997-00c04fa37ddb)]
interface ICustom : IUnknown {
 HRESULT Custom([in] longl, [out,retval] long*pLong);
 [local] HRESULT CustomLocal([in] longl, [out,retval] long*pLong);
};
[ version(1.0), uuid(29079a2c-5f3f-3325-99a1-3ec9c40988bb) ]
library Foo {
 importlib("stdole2.tlb");
 importlib("olepro32.dll");
 [version(1.0), appobject, uuid(9e66a294-4365-11d2-a997-00c04fa37ddb)]
 coclass CFoo { interface ICustom; };
}
-- ATL IMPLEMENTATION--
#include <idl.header.h>
#include <atlbase.h>
class ATL_NO_VTABLE CFooImpl : public ICustom,
 public ATL::CComObjectRootEx<CComMultiThreadModel>
{
 public:BEGIN_COM_MAP(CFooImpl)
 COM_INTERFACE_ENTRY(ICustom)
 END_COM_MAP()
};
Ambiguous conditional operator arguments
error C2446: ':': no conversion from 'B' to 'A'
A typical code pattern that can cause this issue is when some class C provides both a
non-explicit constructor from another type T and a non-explicit conversion operator to
type T . The conversion of the second argument to the third argument's type is a valid
conversion. So is the conversion of the third argument to the second argument's type.
Since both are valid, it's ambiguous according to the standard.
C++
There's an important exception to this common pattern when T represents one of the
null-terminated string types (for example, const char * , const char16_t * , and so on)
and the actual argument to ?: is a string literal of corresponding type. C++17 has
changed semantics from C++14. As a result, the code in example 2 is accepted under
/std:c++14 and rejected under /std:c++17 or later when /Zc:ternary or /permissive￾is used.
C++
// Example 1: class that provides conversion to and initialization from some
type T
struct A
{
 A(int);
 operator int() const;
};
extern bool cond;
A a(42);
// Accepted when /Zc:ternary or /permissive- is not used:
auto x = cond ? 7 : a; // A: permissive behavior prefers A(7) over (int)a
// Accepted always:
auto y = cond ? 7 : int(a);
auto z = cond ? A(7) : a;
// Example 2: exception from the above
struct MyString
{
 MyString(const char* s = "") noexcept; // from char*
 operator const char* () const noexcept; // to char*
};
extern bool cond;
MyString s;
// Using /std:c++14, /permissive- or /Zc:ternary behavior
// is to prefer MyString("A") over (const char*)s
// but under /std:c++17 this line causes error C2445:
auto x = cond ? "A" : s;
// You can use a static_cast to resolve the ambiguity:
auto y = cond ? "A" : static_cast<const char*>(s);
You may also see errors in conditional operators with one argument of type void . This
case may be common in ASSERT-like macros.
C++
// Example 3: void arguments
void myassert(const char* text, const char* file, int line);
// Accepted when /Zc:ternary or /permissive- is not used:
#define ASSERT_A(ex) (void)((ex) ? 1 : myassert(#ex, __FILE__, __LINE__))
// Accepted always:
#define ASSERT_B(ex) (void)((ex) ? void() : myassert(#ex, __FILE__,
__LINE__))
You may also see errors in template metaprogramming, where conditional operator
result types may change under /Zc:ternary and /permissive- . One way to resolve this
issue is to use std::remove_reference on the resulting type.
C++
// Example 4: different result types
extern bool cond;
extern int count;
char a = 'A';
const char b = 'B';
decltype(auto) x = cond ? a : b; // char without, const char& with
/Zc:ternary
const char (&z)[2] = count > 3 ? "A" : "B"; // const char* without
/Zc:ternary
Two-phase name look-up
When the /permissive- option is set, the compiler parses function and class template
definitions, identifying dependent and non-dependent names used in templates as
required for two-phase name look-up. In Visual Studio 2017 version 15.3, name
dependency analysis is performed. In particular, non-dependent names that aren't
declared in the context of a template definition cause a diagnostic message as required
by the ISO C++ standards. In Visual Studio 2017 version 15.7, binding of non-dependent
names that require argument-dependent look-up in the definition context is also done.
C++
If you want legacy behavior for two-phase lookup, but otherwise want /permissive￾behavior, add the /Zc:twoPhase- option.
The /permissive- option is too strict for versions of the Windows Kits before Windows
Fall Creators Update SDK (10.0.16299.0), or the Windows Driver Kit (WDK) version 1709.
We recommend you update to the latest versions of the Windows Kits to use
/permissive- in your Windows or device driver code.
Certain header files in the Windows April 2018 Update SDK (10.0.17134.0), the Windows
Fall Creators Update SDK (10.0.16299.0), or the Windows Driver Kit (WDK) 1709, still
have issues that make them incompatible with use of /permissive- . To work around
these issues, we recommend you restrict the use of these headers to only those source
code files that require them, and remove the /permissive- option when you compile
those specific source code files.
These WinRT WRL headers released in the Windows April 2018 Update SDK
(10.0.17134.0) aren't clean with /permissive- . To work around these issues, either don't
use /permissive- , or use /permissive- with /Zc:twoPhase- when you work with these
headers:
Issues in winrt/wrl/async.h
// dependent base
struct B {
 void g() {}
};
template<typename T>
struct D : T {
 void f() {
 // The call to g was incorrectly allowed in VS2017:
 g(); // Now under /permissive-: C3861
 // Possible fixes:
 // this->g();
 // T::g();
 }
};
int main()
{
 D<B> d;
 d.f();
}
Windows header issues
Output
C:\Program Files (x86)\Windows
Kits\10\Include\10.0.17134.0\winrt\wrl\async.h(483): error C3861:
'TraceDelegateAssigned': identifier not found
C:\Program Files (x86)\Windows
Kits\10\Include\10.0.17134.0\winrt\wrl\async.h(491): error C3861:
'CheckValidStateForDelegateCall': identifier not found
C:\Program Files (x86)\Windows
Kits\10\Include\10.0.17134.0\winrt\wrl\async.h(509): error C3861:
'TraceProgressNotificationStart': identifier not found
C:\Program Files (x86)\Windows
Kits\10\Include\10.0.17134.0\winrt\wrl\async.h(513): error C3861:
'TraceProgressNotificationComplete': identifier not found
Issue in winrt/wrl/implements.h
Output
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\winrt\wrl\implements.h(2086): error C2039:
'SetStrongReference': is not a member of
'Microsoft::WRL::Details::WeakReferenceImpl'
These User Mode headers released in the Windows April 2018 Update SDK
(10.0.17134.0) aren't clean with /permissive- . To work around these issues, don't use
/permissive- when working with these headers:
Issues in um/Tune.h
Output
C:\ProgramFiles(x86)\Windows
Kits\10\include\10.0.17134.0\um\tune.h(139): error C3861: 'Release':
identifier not found
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\tune.h(559): error C3861: 'Release':
identifier not found
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\tune.h(1240): error C3861: 'Release':
identifier not found
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\tune.h(1240): note: 'Release': function
declaration must be available as none of the arguments depend on a
template parameter
Issue in um/spddkhlp.h
Output
Issues in um/refptrco.h
Output
These issues are specific to User Mode headers in the Windows Fall Creators Update
SDK (10.0.16299.0):
Issue in um/Query.h
When you use the /permissive- compiler switch, the tagRESTRICTION structure
doesn't compile because of the case(RTOr) member or .
C++
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\spddkhlp.h(759): error C3861: 'pNode':
identifier not found
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\refptrco.h(179): error C2760: syntax
error: unexpected token 'identifier', expected 'type specifier'
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\refptrco.h(342): error C2760: syntax
error: unexpected token 'identifier', expected 'type specifier'
C:\Program Files (x86)\Windows
Kits\10\include\10.0.17134.0\um\refptrco.h(395): error C2760: syntax
error: unexpected token 'identifier', expected 'type specifier'
struct tagRESTRICTION
{
 ULONG rt;
 ULONG weight;
 /* [switch_is][switch_type] */ union _URes
 {
 /* [case()] */ NODERESTRICTION ar;
 /* [case()] */ NODERESTRICTION or; // error C2059: syntax
error: '||'
 /* [case()] */ NODERESTRICTION pxr;
 /* [case()] */ VECTORRESTRICTION vr;
 /* [case()] */ NOTRESTRICTION nr;
 /* [case()] */ CONTENTRESTRICTION cr;
 /* [case()] */ NATLANGUAGERESTRICTION nlr;
 /* [case()] */ PROPERTYRESTRICTION pr;
 /* [default] */ /* Empty union arm */
 } res;
};
To address this issue, compile files that include Query.h without the /permissive￾option.
Issue in um/cellularapi_oem.h
When you use the /permissive- compiler switch, the forward declaration of enum
UICCDATASTOREACCESSMODE causes a warning:
C++
The forward declaration of an unscoped enum is a Microsoft extension. To address
this issue, compile files that include cellularapi_oem.h without the /permissive￾option, or use the /wd option to silence warning C4471.
Issue in um/omscript.h
In C++03, a conversion from a string literal to BSTR (which is a typedef to wchar_t
* ) is deprecated but allowed. In C++11, the conversion is no longer allowed.
C++
To address this issue, compile files that include omscript.h without the
/permissive- option, or use /Zc:strictStrings- instead.
In Visual Studio 2017 version 15.5 and later versions, use this procedure:
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Language property page.
3. Change the Conformance mode property value to Yes (/permissive-). Choose OK
or Apply to save your changes.
typedef enum UICCDATASTOREACCESSMODE UICCDATASTOREACCESSMODE; // C4471
virtual /* [id] */ HRESULT STDMETHODCALLTYPE setExpression(
 /* [in] */ __RPC__in BSTR propname,
 /* [in] */ __RPC__in BSTR expression,
 /* [in][defaultvalue] */ __RPC__in BSTR language = L"") = 0; //
C2440
To set this compiler option in the Visual Studio
development environment
In versions before Visual Studio 2017 version 15.5, use this procedure:
1. Open your project's Property Pages dialog box.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /permissive- compiler option in the Additional Options box. Choose OK
or Apply to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Q Options (Low-Level Operations)
Article • 08/03/2021
You can use the /Q compiler options to perform the following low-level compiler
operations:
/Qfast_transcendentals (Force Fast Transcendentals): Generates fast
transcendentals.
/QIfist (Suppress _ftol): Suppresses _ftol when a conversion from a floating-point
type to an integer type is required (x86 only).
/Qimprecise_fwaits (Remove fwaits Inside Try Blocks): Removes fwait commands
inside try blocks.
/QIntel-jcc-erratum: Mitigates the performance impact caused by the Intel Jump
Conditional Code (JCC) erratum microcode update.
/Qpar (Auto-Parallelizer): Enables automatic parallelization of loops that are
marked with the #pragma loop() directive.
/Qpar-report (Auto-Parallelizer Reporting Level): Enables reporting levels for
automatic parallelization.
/Qsafe_fp_loads: Suppresses optimizations for floating-point register loads and for
moves between memory and MMX registers.
/Qspectre: Generates instructions to mitigate certain Spectre security
vulnerabilities.
/Qspectre-load: Generates instructions to mitigate Spectre security vulnerabilities
based on loads.
/Qspectre-load-cf: Generates instructions to mitigate Spectre security
vulnerabilities based on control flow instructions which load.
/Qvec-report (Auto-Vectorizer Reporting Level): Enables reporting levels for
automatic vectorization.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Qfast_transcendentals (Force fast
transcendentals)
Article • 03/03/2022
Generates inline code for transcendental functions.
Syntax
/Qfast_transcendentals
Remarks
This compiler option forces transcendental functions to be converted to inline code to
improve execution speed. This option has an effect only when paired with /fp:except or
/fp:precise . Generating inline code for transcendental functions is already the default
behavior under /fp:fast .
This option is incompatible with /fp:strict . For more information about floating point
compiler options, see /fp (Specify Floating-Point Behavior).
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Type the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q Options (Low-level operations)
MSVC compiler options
MSVC compiler command-line syntax
/QIfist (Suppress _ftol)
Article • 08/03/2021
Deprecated. Suppresses the call of the helper function _ftol when a conversion from a
floating-point type to an integral type is required.
Syntax
/QIfist
Remarks
７ Note
/QIfist is only available in the compiler targeting x86; this compiler option is not
available in the compilers targeting x64 orARM.
In addition to converting from a floating-point type to integral type, the _ftol function
ensures the rounding mode of the floating-point unit (FPU) is toward zero (truncate), by
setting bits 10 and 11 of the control word. This guarantees that converting from a
floating-point type to an integral type occurs as described by the ANSI C standard (the
fractional portion of the number is discarded). When using /QIfist, this guarantee no
longer applies. The rounding mode will be one of four as documented in Intel reference
manuals:
Round toward nearest (even number if equidistant)
Round toward negative infinity
Round toward positive infinity
Round toward zero
You can use the _control87, _controlfp, __control87_2 C Run-Time function to modify the
rounding behavior of the FPU. The default rounding mode of the FPU is "Round toward
nearest." Using /QIfist can improve the performance of your application, but not
without risk. You should thoroughly test the portions of your code that are sensitive to
rounding modes before relying upon code built with /QIfist in production
environments.
/arch (x86) and /QIfist can not be used on the same compiland.
７ Note
/QIfist is not in effect by default because the rounding bits also affect floating
point to floating point rounding (which occurs after every calculation), so when you
set the flags for C-style (toward zero) rounding, your floating point calculations
might be different. /QIfist should not be used if your code depends upon the
expected behavior of truncating the fractional portion of the floating-point
number. If you are unsure, do not use /QIfist.
The /QIfist option is deprecated starting in Visual Studio 2005. The compiler has made
significant improvements in float to int conversion speed. For a list of deprecated
compiler options, see Deprecated and Removed Compiler Options in Compiler Options
Listed by Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Type the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q Options (Low-Level Operations)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Qimprecise_fwaits (Remove fwaits
Inside Try Blocks)
Article • 08/03/2021
Removes the fwait commands internal to try blocks when you use the /fp:except
compiler option.
Syntax
/Qimprecise_fwaits
Remarks
This option has no effect if /fp:except isn't also specified. If you specify the /fp:except
option, the compiler will insert a fwait instruction around each line of code in a try
block. In this way, the compiler can identify the specific line of code that produces an
exception. /Qimprecise_fwaits removes internal fwait instructions, leaving only the
waits around the try block. It improves performance, but the compiler can only show
which try block causes an exception, not which line.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q Options (Low-Level Operations)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/QIntel-jcc-erratum
Article • 08/03/2021
Specifies that the compiler generates instructions to mitigate the performance impact
caused by the Intel Jump Conditional Code (JCC) erratum microcode update in certain
Intel processors.
Syntax
/QIntel-jcc-erratum
Remarks
Under /QIntel-jcc-erratum, the compiler detects jump and macro-fused jump
instructions that cross or end on a 32-byte boundary. It aligns these instructions to the
boundary. This change mitigates the performance impact of microcode updates that
prevent the JCC erratum in certain Intel processors. For more information about the
erratum, see Mitigations for Jump Conditional Code Erratum on the Intel website.
The /QIntel-jcc-erratum option is available in Visual Studio 2019 version 16.5 and later.
This option is only available in compilers that target x86 and x64. The option isn't
available in compilers that target ARM processors.
The /QIntel-jcc-erratum option is off by default, and works only in optimized builds.
This option can increase code size.
/QIntel-jcc-erratum is incompatible with /clr.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select a value for the Enable Intel JCC Erratum Mitigation property. Choose OK to
apply the change.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q options (Low-level operations)
MSVC compiler options
MSVC compiler command-line syntax
/Qpar (Auto-parallelizer)
Article • 02/23/2022
Enables the Auto-parallelizer feature of the compiler to automatically parallelize loops in
your code.
Syntax
/Qpar
Remarks
When the compiler automatically parallelizes loops in code, it spreads computation
across multiple processor cores. The compiler parallelizes a loop only if it determines
that it's legal to do so and that parallelization would improve performance.
The #pragma loop() directives are available to help the optimizer parallelize specific
loops. For more information, see loop.
For information about how to enable output messages for the auto-parallelizer, see
/Qpar-report (Auto-parallelizer reporting level).
To set the /Qpar compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Enable Parallel Code Generation property. Choose OK or Apply to
save your changes.
To set the /Qpar compiler option programmatically
Use the code example in AdditionalOptions.
See also
/Q options (Low-level operations)
/Qpar-report (Auto-parallelizer reporting level)
MSVC compiler options
MSVC compiler command-line syntax
#pragma loop()
Native code vectorization in Visual Studio
/Qpar-report (Auto-Parallelizer
Reporting Level)
Article • 08/03/2021
Enables the reporting feature of the compiler's Auto-Parallelizer and specifies the level
of informational messages for output during compilation.
Syntax
/Qpar-report:{1}{2}
Remarks
/Qpar-report:1
Outputs an informational message for loops that are parallelized.
/Qpar-report:2
Outputs an informational message for loops that are parallelized and also for loops that
are not parallelized, together with a reason code.
Messages are reported to stdout. If no informational messages are reported, then either
the code contains no loops, or the reporting level was not set to report loops that are
not parallelized. For more information about reason codes and messages, see Vectorizer
and Parallelizer Messages.
To set the /Qpar-report compiler option in Visual Studio
1. In Solution Explorer, open the shortcut menu for the project and then choose
Properties.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional Options box, enter /Qpar-report:1 or /Qpar-report:2 .
To set the /Qpar-report compiler option
programmatically
Use the code example in AdditionalOptions.
See also
/Q Options (Low-Level Operations)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Native code vectorization in Visual Studio
/Qsafe_fp_loads
Article • 08/03/2021
Requires integer move instructions for floating-point values and disables certain
floating-point load optimizations.
Syntax
/Qsafe_fp_loads
Remarks
/Qsafe_fp_loads is only available in the compilers that target x86; it is not available in
the compilers that target x64 or ARM.
/Qsafe_fp_loads forces the compiler to use integer move instructions instead of
floating-point move instructions to move data between memory and MMX registers.
This option also disables register load optimization for floating-point values that can be
loaded in multiple control paths when the value may cause an exception on load—for
example, a NaN value.
This option is overridden by /fp:except. /Qsafe_fp_loads specifies a subset of the
compiler behavior that's specified by /fp:except.
/Qsafe_fp_loads is incompatible with /clr and /fp:fast. For more information about
floating point compiler options, see /fp (Specify Floating-Point Behavior).
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box. Choose OK to apply the
change.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q Options (Low-Level Operations)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Qspectre
Article • 11/04/2021
Specifies compiler generation of instructions to mitigate certain Spectre variant 1
security vulnerabilities.
Syntax
/Qspectre
Remarks
The /Qspectre option causes the compiler to insert instructions to mitigate certain
Spectre security vulnerabilities . These vulnerabilities are called speculative execution
side-channel attacks. They affect many operating systems and modern processors,
including processors from Intel, AMD, and ARM.
The /Qspectre option is available starting in Visual Studio 2017 version 15.5.5 and all
later versions. It's available in Visual Studio 2015 Update 3 through KB 4338871 .
The /Qspectre option is off by default.
In its initial release, the /Qspectre option only worked on optimized code. Starting in
Visual Studio 2017 version 15.7, the /Qspectre option is supported at all optimization
levels.
Several Microsoft C++ libraries are also available in versions with Spectre mitigation.
The Spectre-mitigated libraries for Visual Studio can be downloaded in the Visual Studio
Installer. They're found in the Individual Components tab under Compilers, build tools,
and runtimes, and have "Libs for Spectre" in the name. Both DLL and static runtime
libraries with mitigation enabled are available for a subset of the Visual C++ runtimes:
VC++ start-up code, vcruntime140, msvcp140, concrt140, and vcamp140. The DLLs are
supported for application-local deployment only. The contents of the Visual C++
Runtime Libraries Redistributable haven't been modified.
You can also install Spectre-mitigated libraries for MFC and ATL. They're found in the
Individual Components tab under SDKs, libraries, and frameworks.
７ Note
There are no versions of Spectre-mitigated libraries for Universal Windows (UWP)
apps or components. App-local deployment of such libraries isn't possible.
Applicability
If your code operates on data that crosses a trust boundary, then we recommend you
use the /Qspectre option to rebuild and redeploy your code to mitigate this issue as
soon as possible. An example of such code is code that loads untrusted input that can
affect execution. For example, code that makes remote procedure calls, parses untrusted
input or files, or uses other local inter-process communication (IPC) interfaces. Standard
sandboxing techniques may not be sufficient. Investigate your sandboxes carefully
before you decide your code doesn't cross a trust boundary.
Availability
The /Qspectre option is available starting in Visual Studio 2017 version 15.5.5, and in all
updates to Microsoft C/C++ compilers (MSVC) made on or after January 23, 2018. Use
the Visual Studio Installer to update the compiler, and to install the Spectre-mitigated
libraries as individual components. The /Qspectre option is also available in Visual
Studio 2015 Update 3 through a patch. For more information, see KB 4338871 .
All versions of Visual Studio 2017 version 15.5, and all Previews of Visual Studio 2017
version 15.6. include an undocumented option, / d2guardspecload . It's equivalent to the
initial behavior of /Qspectre . You can use /d2guardspecload to apply the same
mitigations to your code in these versions of the compiler. We recommend you update
your build to use /Qspectre in compilers that support the option. The /Qspectre option
may also support new mitigations in later versions of the compiler.
Effect
The /Qspectre option outputs code to mitigate Specter variant 1, Bounds Check Bypass,
CVE-2017-5753 . It works by insertion of instructions that act as a speculative code
execution barrier. The specific instructions used to mitigate processor speculation
depend upon the processor and its micro-architecture, and may change in future
versions of the compiler.
When you enable the /Qspectre option, the compiler attempts to identify instances
where speculative execution may bypass bounds checks. That's where it inserts the
barrier instructions. It's important to be aware of the limits to the analysis that a
compiler can do to identify instances of variant 1. As such, there's no guarantee that all
possible instances of variant 1 are instrumented under /Qspectre .
Performance impact
The effect of /Qspectre on performance appeared to be negligible in several sizable
code bases. However, there are no guarantees that performance of your code under
/Qspectre remains unaffected. You should benchmark your code to determine the effect
of the option on performance. If you know that the mitigation isn't required in a
performance-critical block or loop, you can selectively disable the mitigation by use of a
__declspec(spectre(nomitigation)) directive. This directive isn't available in compilers that
only support the /d2guardspecload option.
Required libraries
The /Qspectre compiler option mitigates issues in your own code. For greater
protection, we strongly recommend you also use libraries built to provide Spectre
mitigations. Several of the Microsoft runtime libraries are available with Spectre
mitigations.
These libraries are optional components that must be installed by using the Visual
Studio Installer:
MSVC version version_numbers Libs for Spectre [(x86 and x64) | (ARM) | (ARM64)]
Visual C++ ATL for [(x86/x64) | ARM | ARM64] with Spectre Mitigations
Visual C++ MFC for [x86/x64 | ARM | ARM64] with Spectre Mitigations
The default MSBuild-based project system in the Visual Studio IDE lets you specify a
Spectre Mitigation property for your projects. This property sets the /Qspectre compiler
option and changes the library paths to link the Spectre-mitigated runtime libraries. If
these libraries aren't installed when you build your code, the build system reports
warning MSB8040. If your MFC or ATL code fails to build, and the linker reports an error
such as "fatal error LNK1104: cannot open file 'oldnames.lib'", these missing libraries
may be the cause.
There are several ways to specify the Spectre-mitigated libraries to the build command
line. You can specify the path to the Spectre-mitigated libraries by using the /LIBPATH
linker option to make them the default libraries. You can use the /NODEFAULTLIB linker
option and explicitly link the Spectre-mitigated libraries. Or, you can set the LIBPATH
environment variable to include the path to the Spectre-mitigated libraries for your
target platform. One way to set this path in the environment is to use a developer
command prompt set up by using the spectre_mode option. For more information, see
Use the developer tools in an existing command window.
Additional information
For more information, see the official Microsoft Security Advisory ADV180002, Guidance
to mitigate speculative execution side-channel vulnerabilities . Guidance is also
available from Intel, Speculative Execution Side Channel Mitigations , and ARM, Cache
Speculation Side-channels .
For a Windows-specific overview of Spectre and Meltdown mitigations, see
Understanding the performance impact of Spectre and Meltdown mitigations on
Windows Systems .
For an overview of Spectre vulnerabilities addressed by the MSVC mitigations, see
Spectre mitigations in MSVC on the C++ Team Blog.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select a new value for the Spectre Mitigation property. Choose OK to apply the
change.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Q options (Low-level operations)
MSVC compiler options
MSVC compiler command-line syntax
/Qspectre-jmp
Article • 12/01/2023
Causes the compiler to generate an int3 instruction (software interrupt) after
unconditional direct branches. This option extends the /Qspectre flag and mitigates
speculative execution side-channel attacks on unconditional direct branches.
Syntax
/Qspectre-jmp
Remarks
/Qspectre-jmp causes the compiler to detect executable instructions following
unconditional direct branches. An int3 is inserted following unconditional direct
branches to ensure that no instructions are speculatively executed beyond the branch.
For example, the compiler mitigates jmp addr by adding an int3 instruction following
the jmp instruction as shown here:
asm
jmp addr
int3
/Qspectre-jmp is off by default. It's supported for all optimization levels.
Set this compiler option programmatically
To set this option programmatically, see VCCLCompilerTool.AdditionalOptions property.
See also
/Qspectre
/Qspectre-jmp
/Qspectre-load
/Qspectre-load-cf
/Q options (Low-Level Operations)
MSVC compiler options
MSVC compiler command-line syntax
/Qspectre-load
Article • 12/01/2023
Specifies compiler generation of serializing instructions for every load instruction. This
option extends the /Qspectre flag, mitigating against any possible speculative
execution side-channel attacks based on loads.
/Qspectre-load
/Qspectre-load causes the compiler to detect loads from memory, and insert serializing
instructions after them. Control flow instructions that load memory, including RET and
CALL , are split into a load and a control flow transfer. The load is followed by an LFENCE
to ensure the load is protected. There are cases where the compiler can't split control
flow instructions, such as the jmp instruction, so it uses an alternate mitigation
technique. For example, the compiler mitigates jmp [rax] by adding instructions to load
the target nondestructively before inserting an LFENCE, as shown here:
asm
Because /Qspectre-load stops speculation of all loads, the performance impact is high.
The mitigation isn't appropriate everywhere. If there are performance critical blocks of
code that don't require protection, you can disable these mitigations by using
__declspec(spectre(nomitigation)) . For more information, see __declspec spectre.
The /Qspectre-load option is off by default, and supports all optimization levels.
The /Qspectre-load option is available in Visual Studio 2019 version 16.5 and later. This
option is only available in compilers that target x86 and x64 processors. It's not available
in compilers that target ARM processors.
Syntax
Remarks
 xor rbx, [rax]
 xor rbx, [rax] ; force a load of [rax]
 lfence ; followed by an LFENCE
 jmp [rax]
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select a new value for the Spectre Mitigation property. Choose OK to apply the
change.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Qspectre
/Qspectre-jmp
/Qspectre-load-cf
/Q options (Low-Level Operations)
MSVC compiler options
MSVC compiler command-line syntax
/Qspectre-load-cf
Article • 12/01/2023
Specifies compiler generation of serializing instructions for every control-flow
instruction that contains a load. This option performs a subset of the mitigations done
by the /Qspectre-load option.
/Qspectre-load-cf
/Qspectre-load-cf causes the compiler to detect JMP , RET , and CALL control-flow
instructions that load from memory, and to insert serializing instructions after the load.
Where possible, these instructions are split into a load and a control flow transfer. The
load is followed by an LFENCE to ensure the load is protected. There are cases where the
compiler can't split instructions, such as the JMP instruction, so it uses an alternate
mitigation technique. For example, the compiler mitigates jmp [rax] by adding
instructions to load the target nondestructively before inserting an LFENCE, as shown
here:
asm
Because /Qspectre-load-cf stops speculation of all loads in control-flow instructions, the
performance impact is high. The mitigation isn't appropriate everywhere. If there are
performance critical blocks of code that don't require protection, you can disable these
mitigations by using __declspec(spectre(nomitigation)) .
The /Qspectre-load-cf option is off by default, and supports all optimization levels.
The /Qspectre-load-cf option is available in Visual Studio 2019 version 16.5 and later.
This option is only available in compilers that target x86 and x64 processors. It's not
available in compilers that target ARM processors.
Syntax
Remarks
 xor rbx, [rax]
 xor rbx, [rax] ; force a load of [rax]
 lfence ; followed by an LFENCE
 jmp [rax]
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Select a new value for the Spectre Mitigation property. Choose OK to apply the
change.
To set this compiler option programmatically
See AdditionalOptions.
See also
/Qspectre
/Qspectre-jmp
/Qspectre-load
/Q options (Low-level operations)
MSVC compiler options
MSVC compiler command-line syntax
/Qvec-report (Auto-Vectorizer
Reporting Level)
Article • 08/03/2021
Enables the reporting feature of the compiler Auto-Vectorizer and specifies the level of
informational messages for output during compilation.
Syntax
/Qvec-report:{1}{2}
Remarks
/Qvec-report:1
Outputs an informational message for loops that are vectorized.
/Qvec-report:2
Outputs an informational message for loops that are vectorized and for loops that are
not vectorized, together with a reason code.
For information about reason codes and messages, see Vectorizer and Parallelizer
Messages.
To set the /Qvec-report compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. In the Additional Options box, enter /Qvec-report:1 or /Qvec-report:2 .
To set the /Qvec-report compiler option
programmatically
Use the code example in AdditionalOptions.
See also
/Q Options (Low-Level Operations)
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Native code vectorization in Visual Studio
/RTC (Run-time error checks)
Article • 08/03/2021
Used to enable and disable the run-time error checks feature, in conjunction with the
runtime_checks pragma.
/RTC1
/RTCc
/RTCs
/RTCu
/RTC1
Equivalent to /RTCsu .
/RTCc
Reports when a value is assigned to a smaller data type and results in a data loss. For
example, it reports if a short type value of 0x0101 is assigned to a variable of type
char .
This option can report situations in which you intend to truncate. For example, when you
want the first 8 bits of an int returned as a char . Because /RTCc causes a run-time
error if an assignment causes any information loss, first mask off the information you
need to avoid the run-time error. For example:
C
Syntax
Arguments
#include <crtdbg.h>
char get8bits(unsigned value, int position) {
 _ASSERT(position < 32);
 return (char)(value >> position);
 // Try the following line instead:
 // return (char)((value >> position) & 0xff);
}
int main() {
 get8bits(12341235,3);
}
Because /RTCc rejects code that conforms to the standard, it's not supported by the
C++ Standard Library. Code that uses /RTCc and the C++ Standard Library may cause
compiler error C1189. You can define _ALLOW_RTCc_IN_STL to silence the warning and use
the /RTCc option.
/RTCs
Enables stack frame run-time error checking, as follows:
Initialization of local variables to a nonzero value. This option helps identify bugs
that don't appear when running in debug mode. There's a greater chance that
stack variables still have a zero value in a debug build compared to a release build.
That's because of compiler optimizations of stack variables in a release build. Once
a program has used an area of its stack, it's never reset to 0 by the compiler. That
means any uninitialized stack variables that happen to use the same stack area
later can return values left over from the earlier use of this stack memory.
Detection of overruns and underruns of local variables such as arrays. /RTCs
doesn't detect overruns when accessing memory that results from compiler
padding within a structure. Padding could occur by using align, /Zp (Struct
Member Alignment), or pack, or if you order structure elements in such a way as to
require the compiler to add padding.
Stack pointer verification, which detects stack pointer corruption. Stack pointer
corruption can be caused by a calling convention mismatch. For example, using a
function pointer, you call a function in a DLL that is exported as __stdcall but you
declare the pointer to the function as __cdecl.
/RTCu
Reports when a variable is used without having been initialized. For example, an
instruction that generates warning C4701 may also generate a run-time error under
/RTCu . Any instruction that generates Compiler Warning (level 1 and level 4) C4700 will
generate a run-time error under /RTCu .
However, consider the following code fragment:
C++
int a, *b, c;
if ( 1 )
b = &a;
c = a; // No run-time error with /RTCu
If a variable could have been initialized, it's not reported at run time by /RTCu . For
example, after a variable is aliased through a pointer, the compiler doesn't track the
variable and report uninitialized uses. In effect, you can initialize a variable by taking its
address. The & operator works like an assignment operator in this situation.
Remarks
Run-time error checks are a way for you to find problems in your running code; for
more information, see How to: Use native run-time checks.
You can specify more than one /RTC option on the command line. The option
arguments may be combined; for example, /RTCcu is the same as /RTCc /RTCu .
If you compile your program at the command line using any of the /RTC compiler
options, any pragma optimize instructions in your code silently fail. That's because run￾time error checks aren't valid in a release (optimized) build.
Use /RTC for development builds; Don't use /RTC for a release build. /RTC can't be used
with compiler optimizations (/O Options (Optimize Code)). A program image built with
/RTC is slightly larger and slightly slower than an image built with /Od (up to 5 percent
slower than an /Od build).
The __MSVC_RUNTIME_CHECKS preprocessor directive will be defined when you use any
/RTC option or /GZ.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify one or both of the following properties: Basic Runtime Checks or Smaller
Type Check.
To set this compiler option programmatically
See BasicRuntimeChecks and SmallerTypeCheck properties.
See also
MSVC compiler options
MSVC compiler command-line syntax
How to: Use native run-time checks
/scanDependencies (List module
dependencies in standard form)
Article • 03/02/2023
This compiler option generates a JSON file that lists module and header-unit
dependencies according to C++ Standard proposal P1689R5 Format for describing
dependencies of source files .
Syntax
/scanDependencies-
/scanDependencies filename
/scanDependencies directory
Arguments
-
If the single dash is provided, then the compiler emits the source dependencies JSON to
stdout , or to where compiler output is redirected.
filename
The compiler writes the source dependency output to the specified filename, which may
include a relative or absolute path. The file is created if it doesn't exist.
directory
If the argument is a directory, the compiler generates source dependency files in the
specified directory. The directory must exist, or the argument is treated as a filename .
The output file name is based on the full name of the input file, with an appended
.module.json extension. For example, if the file provided to the compiler is main.cpp ,
the generated output filename is main.cpp.module.json .
Remarks
The /scanDependencies compiler option identifies which dependencies, modules, and
header units must be compiled before you can compile the project that uses them. For
instance, it lists import <library>; or import "library"; as a header unit dependency,
and import name; as a module dependency. The intent is to provide this information in
a common format consumable by build tools such as CMake. To report module and
header unit dependencies, you must also compile by using /std:c++20 or later.
This command-line option is similar to /sourceDependencies:directives and
/sourceDependencies, but differs in the following ways:
The output uses the P1689R5 schema, instead of the Microsoft-specific schema
generated by /sourceDependencies:directives .
Unlike /sourceDependencies , the compiler doesn't produce compiled output.
Instead, the files are scanned for module directives. No compiled code, modules,
or header units are produced.
The output JSON file doesn't list imported modules and imported header units
( .ifc files) because this option only scans the project files. There are no built
modules or header units to list.
Only directly imported modules or header units are listed. It doesn't list the
dependencies of the imported modules or header units themselves.
Textually included header files such as #include <file> or #include "file" aren't
listed as dependencies unless translated to a header unit by using the
/translateInclude option.
/scanDependencies is meant to be used before .ifc files are built.
/scanDependencies is available starting in Visual Studio 2022 version 17.2. It's not
enabled by default.
When you specify the /MP (Build with multiple processes) compiler option, we
recommend that you use /scanDependencies with a directory argument. If you provide a
single filename argument, two instances of the compiler may attempt to open the
output file simultaneously and cause an error. Use of /MP with /scanDependencies- to
send output to stdout could cause interleaved results.
When a non-fatal compiler error occurs, the dependency information still gets written to
the output file.
All file paths appear as absolute paths in the output.
For details on the format and schema used in the output JSON file, see P1689R5
section 6.
Examples
Consider the following sample code:
C++
You can use this command line to report dependencies in app.cpp :
cl /std:c++latest /scanDependencies output.json app.cpp
The compiler produces a JSON file, output.json , with content similar to:
JSON
//app.cpp:
#include <vector>
import other.module;
import std.core;
import "t.h";
import <iostream>;
int main() {}
{
 "version": 1,
 "revision": 0,
 "rules": [
 {
 "primary-output": "app.obj",
 "outputs": [
 "C:\\Users\\username\\source\\repos\\app\\app"
 ],
 "requires": [
 {
 "logical-name": "other.module"
 },
 {
 "logical-name": "std.core"
 },
 {
 "logical-name": "t.h",
 "source-path":
"C:\\Users\\username\\source\\repos\\app\\app\\t.h",
 "lookup-method": "include-quote",
 "unique-on-source-path": true
 },
 {
 "logical-name": "iostream",
 "source-path": "C:\\Program
Files\\...\\include\\iostream",
 "lookup-method": "include-angle",
 "unique-on-source-path": true
 }
 ]
 }
 ]
}
We've used ... to abbreviate the reported paths. The report contains the absolute
paths. The paths reported depend on where the compiler finds the dependencies. If the
results are unexpected, you may want to check your project's include path settings.
No .ifc files are listed in the output because they weren't built. Unlike
/sourceDependencies , the compiler doesn't produce compiled output when
/scanDependencies is specified, so no compiled modules or header units are produced
to import.
To set this compiler option in Visual Studio
You normally shouldn't set the /scanDependencies option in the Visual Studio
development environment. The compiler doesn't generate object files when you set this
option, which makes the link step fail and report an error.
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to add /scanDependencies- or
/scanDependencies "pathname" , where "pathname" refers to a directory for output.
4. Choose OK to save your changes.
To report module and header unit dependencies, you must also set the Configuration
Properties > General > C++ Language Standard property to ISO C++20 Standard or
later.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/sourceDependencies:directives
/sourceDependencies
/std (Specify language standard version)
/translateInclude
/sdl (Enable Additional Security Checks)
Article • 08/03/2021
Enables recommended Security Development Lifecycle (SDL) checks. These checks
change security-relevant warnings into errors, and set additional secure code￾generation features.
/sdl [ - ]
/sdl enables a superset of the baseline security checks provided by /GS and overrides
/GS- . By default, /sdl is off. /sdl- disables the additional security checks.
/sdl enables these warnings as errors:
Warning
enabled by
/sdl
Equivalent
command-line
switch
Description
C4146 /we4146 A unary minus operator was applied to an unsigned type,
resulting in an unsigned result.
C4308 /we4308 A negative integral constant converted to unsigned type,
resulting in a possibly meaningless result.
C4532 /we4532 Use of continue , break , or goto keywords in a
__finally / finally block has undefined behavior during
abnormal termination.
C4533 /we4533 Code initializing a variable will not be executed.
C4700 /we4700 Use of an uninitialized local variable.
C4703 /we4703 Use of a potentially uninitialized local pointer variable.
C4789 /we4789 Buffer overrun when specific C run-time (CRT) functions are
used.
C4995 /we4995 Use of a function marked with pragma deprecated.
Syntax
Remarks
Compile-time Checks
Warning
enabled by
/sdl
Equivalent
command-line
switch
Description
C4996 /we4996 Use of a function marked as deprecated.
When /sdl is enabled, the compiler generates code that does these checks at run time:
Enables the strict mode of /GS run-time buffer overrun detection, equivalent to
compiling with #pragma strict_gs_check(push, on) .
Does limited pointer sanitization. In expressions that don't involve dereferences
and in types that have no user-defined destructor, pointer references are set to a
non-valid address after a call to delete . This sanitization helps to prevent the
reuse of stale pointer references.
Initializes class member pointers. Automatically initializes class members of pointer
type to nullptr on object instantiation (before the constructor runs). It helps
prevent the use of uninitialized pointers that the constructor doesn't explicitly
initialize. The compiler-generated member pointer initialization is called as long as:
The object isn't allocated using a custom (user defined) operator new
The object isn't allocated as part of an array (for example new A[x] )
The class isn't managed or imported
The class has a user-defined default constructor.
To be initialized by the compiler-generated class initialization function, a member
must be a pointer, and not a property or constant.
For more information, see Warnings, /sdl, and improving uninitialized variable
detection .
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
Runtime checks
To set this compiler option in the Visual Studio
development environment
3. Set the SDL checks property by using the property drop-down control. Choose OK
or Apply to save your changes.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/showIncludes (List include files)
Article • 05/25/2022
Causes the compiler to output a list of the include files. The option also displays nested
include files, that is, the files included by the files that you include.
Syntax
/showIncludes
Remarks
When the compiler comes to an include file during compilation, a message is output, as
in this example:
Windows Command Prompt
Note: including file: d:\MyDir\include\stdio.h
Nested include files are indicated by an indentation, one space for each level of nesting,
as in this example:
Windows Command Prompt
Note: including file: d:\temp\1.h
Note: including file: d:\temp\2.h
In this case, 2.h was included from within 1.h , causing the indentation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Show Includes property.
To set this compiler option programmatically
See ShowIncludes.
See also
MSVC compiler options
MSVC compiler command-line syntax
/source-charset (Set source character
set)
Article • 02/01/2022
This option lets you specify the source character set for your executable.
Syntax
/source-charset: [ IANA_name | .CPID ]
Arguments
IANA_name
The IANA-defined character set name.
.CPID
The code page identifier as a decimal number, preceded by a . character.
Remarks
You can use the /source-charset option to specify an extended source character set to
use when your source files include characters that are not represented in the basic
source character set. The source character set is the encoding used to interpret the
source text of your program. It's converted into the internal representation used as input
to the preprocessing phases before compilation. The internal representation is then
converted to the execution character set to store string and character values in the
executable. You can use either the IANA or ISO character set name, or a dot ( . ) followed
by 3-5 decimal digits that specify the code page identifier of the character set to use.
For a list of supported code page identifiers and character set names, see Code Page
Identifiers.
By default, Visual Studio detects a byte-order mark to determine if the source file is in
an encoded Unicode format, for example, UTF-16 or UTF-8. If no byte-order mark is
found, it assumes that the source file is encoded in the current user code page, unless
you use the /source-charset or /utf-8 option to specify a character set name or code
page. Visual Studio allows you to save your C++ source code in any of several character
encodings. For more information about source and execution character sets, see
Character sets in the language documentation.
The source character set you supply must map the 7-bit ASCII characters to the same
code points in your character set, or many compilation errors are likely to follow. Your
source character set must also have a mapping to the extended Unicode character set of
UTF-8. Characters that have no equivalent in UTF-8 are represented by an
implementation-specific substitute. The Microsoft compiler uses a question mark for
these characters.
If you want to set both the source character set and the execution character set to UTF-
8, you can use the /utf-8 compiler option as a shortcut. It's equivalent to /source￾charset:utf-8 /execution-charset:utf-8 on the command line. Any of these options
also enables the /validate-charset option by default.
To set this compiler option in the Visual Studio
development environment
1. Open the Property Pages dialog box for your project. For details, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional Options, add the /source-charset option, and specify your preferred
encoding.
4. Choose OK to save your changes.
See also
MSVC compiler options
MSVC compiler command-line syntax
/execution-charset (Set execution character set)
/utf-8 (Set source and execution character sets to UTF-8)
/validate-charset (Validate for compatible characters)
/sourceDependencies (List all source￾level dependencies)
Article • 02/23/2024
This command-line switch generates a JSON file that details the source-level
dependencies consumed during compilation. The JSON file contains a list of the source
dependencies, which include:
Header files. Both directly included and the list of headers included by those
headers.
The PCH used (if /Yu is specified).
Names of imported modules
File paths and names of both directly imported header units and of the modules
and header units they import in turn.
This option provides information necessary to build modules and header units in the
proper dependency order.
Syntax
/sourceDependencies-
/sourceDependencies filename
/sourceDependencies directory
Arguments
-
If the single dash is provided, then the compiler will emit the source dependencies JSON
to stdout , or to where compiler output is redirected.
filename
The compiler writes the source dependency output to the specified filename, which may
include a relative or absolute path. The file is created if it doesn't exist.
directory
If the argument is a directory, the compiler generates source dependency files in the
specified directory. The directory must exist, or the argument is treated as a filename .
The output file name is based on the full name of the input file, with an appended .json
extension. For example, if the file provided to the compiler is main.cpp , the generated
output filename is main.cpp.json .
The /sourceDependencies compiler option is available starting in Visual Studio 2019
version 16.7. It's not enabled by default.
When you specify the /MP (Build with multiple processes) compiler option, we
recommend you use /sourceDependencies with a directory argument. If you provide a
single filename argument, two instances of the compiler may attempt to open the
output file simultaneously and cause an error. Use of /MP with /sourceDependencies- to
send output to stdout could cause interleaved results.
When a non-fatal compiler error occurs, the dependency information still gets written to
the output file.
All file paths appear as absolute paths in the output.
Given the following sample code:
C++
You can use /sourceDependencies with the rest of your compiler options:
cl ... /sourceDependencies output.json ... main.cpp
where ... represents your other compiler options. This command line produces a JSON
file output.json with content like:
JSON
Remarks
Examples
// ModuleE.ixx:
export module ModuleE;
import ModuleC;
import ModuleD;
import <iostream>;
{
 "Version": "1.2",
 "Data": {
We've used ... to abbreviate the reported paths. The report contains the absolute
paths. The paths reported depend on where the compiler finds the dependencies. If the
results are unexpected, you may want to check your project's include path settings.
ProvidedModule lists exported module or module partition names.
You normally shouldn't set this option yourself in the Visual Studio development
environment. It's set by the build system.
MSVC compiler options
MSVC compiler command-line syntax
 "Source": "F:\\Sample\\myproject\\modulee.ixx",
 "ProvidedModule": "ModuleE",
 "Includes": [],
 "ImportedModules": [
 {
 "Name": "ModuleC",
 "BMI": 
"F:\\Sample\\Outputs\\Intermediate\\MyProject\\x64\\Debug\\ModuleC.ixx.ifc"
 },
 {
 "Name": "ModuleB",
 "BMI": 
"F:\\Sample\\Outputs\\Intermediate\\ModuleB\\x64\\Debug\\ModuleB.ixx.ifc"
 },
 {
 "Name": "ModuleD",
 "BMI": 
"F:\\Sample\\Outputs\\Intermediate\\MyProject\\x64\\Debug\\ModuleD.cppm.ifc"
 }
 ],
 "ImportedHeaderUnits": [
 {
 "Header": "f:\\visual studio 16
main\\vc\\tools\\msvc\\14.29.30030\\include\\iostream",
 "BMI": 
"F:\\Sample\\Outputs\\Intermediate\\HeaderUnits\\x64\\Debug\\iostream_W4L4JY
GFJ3GL8OG9.ifc"
 }
 ]
 }
}
To set this compiler option in the Visual Studio
development environment
See also
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
/scanDependencies
/sourceDependencies:directives
 Yes  No
/sourceDependencies:directives (List
module and header unit dependencies)
Article • 05/20/2022
This command-line option scans source files and their #include statements to generate
a JSON file that lists module export and imports. This information can be used by a build
system to determine the build order of modules and header units.
This option differs from /sourceDependencies in the following ways:
The compiler doesn't produce compiled output. No compiled code, modules, or
header units are produced. Instead, the files are scanned for module directives.
The JSON format is different from what /sourceDependencies produces. The
/sourceDependencies option is intended to be used with other build tools, such as
CMake.
The output JSON file doesn't list imported modules and imported header units
( .ifc files) because this option does a scan of the project files, not a compilation.
So there are no built modules or header units to list.
Only directly imported modules or header units are listed. It doesn't list the
dependencies of the imported modules or header units themselves.
Header file dependencies aren't listed. That is, #include <file> or #include
"file" dependencies aren't listed.
/sourceDependencies:directives is meant to be used before .ifc files are built.
/sourceDependencies causes the compiler to report all of the files, such as
#includes , .pch files, .ifc files, and so on, that were used for a particular
translation unit, whereas /sourceDependencies:directives [file1] scans the
specified source file and reports all import and export statements.
/sourceDependencies can be used with /sourceDependencies:directives .
Syntax
/sourceDependencies:directives-
/sourceDependencies:directives filename
/sourceDependencies:directives directory
Arguments
-
If the single dash is provided, then the compiler will emit the source dependencies JSON
to stdout , or to where compiler output is redirected.
filename
The compiler writes the source dependency output to the specified filename, which may
include a relative or absolute path. The file is created if it doesn't exist.
directory
If the argument is a directory, the compiler generates source dependency files in the
specified directory. The directory must exist, or the argument is treated as a filename .
The output file name is based on the full name of the input file, with an appended .json
extension. For example, if the file provided to the compiler is main.cpp , the generated
output filename is main.cpp.json .
Remarks
/sourceDependencies:directives is available starting in Visual Studio 2019 version 16.10.
When you specify the /MP (Build with multiple processes) compiler option, we
recommend that you use /sourceDependencies:directives with a directory argument.
This option makes the compiler output a separate *.module.json file for each source
file. If you provide a single filename argument, two instances of the compiler may
attempt to open the output file simultaneously and cause an error. Use of /MP with
/sourceDependencies:directives- to send output to stdout could cause interleaved
results.
When a non-fatal compiler error occurs, the dependency information still gets written to
the output file.
All file paths appear as absolute paths in the output.
This switch can be used with /translateInclude.
Examples
Given the following sample code:
C++
//main.cpp:
#include <vector>
This following command line:
cl /std:c++latest /translateInclude /sourceDependencies:directives output.json
main.cpp
produces a JSON file output.json similar to:
JSON
For brevity, the previous example uses ... to abbreviate the reported paths. The report
contains the absolute paths. The paths reported depend on where the compiler finds
the dependencies. If the results are unexpected, you might want to check your project's
include path settings.
ProvidedModule lists exported module or module partition names.
No .ifc files are listed in the output because they weren't built. Unlike
/sourceDependencies , the compiler doesn't produce compiled output when
/sourceDependencies:directives is specified, so no compiled modules or header units
are produced.
import m;
import std.core;
import <utility>;
import "t.h";
int main() {}
{
 "Version":"1.1",
 "Data":{
 "Source":"C:\\a\\b\\main.cpp",
 "ProvidedModule":"",
 "ImportedModules":[
 "m",
 "std.core"
 ],
 "ImportedHeaderUnits":[
 "C:\\...\\utility",
 "C:\\a\\b\\t.h"
 ]
 }
}
To set this compiler option in Visual Studio
You normally shouldn't set this option yourself in the Visual Studio development
environment. It's set by the build system.
See also
/translateInclude
C++ header-units.json reference
MSVC compiler options
MSVC compiler command-line syntax
/scanDependencies (List module dependencies in standard form)
/sourceDependencies (List all source-level dependencies)
/std (Specify Language Standard
Version)
Article • 01/30/2025
Enable supported C and C++ language features from the specified version of the C or
C++ language standard.
Syntax
/std:c++14
/std:c++17
/std:c++20
/std:c++23preview
/std:c++latest
/std:c11
/std:c17
/std:clatest
Remarks
The /std options are available in Visual Studio 2017 and later. They're used to control
the version-specific ISO C or C++ programming language standard features enabled
during compilation of your code. The options allow you to disable support for certain
new language and library features: ones that may break your existing code that
conforms to a particular version of the language standard.
The Microsoft C++ compiler in Visual Studio 2017 and later versions doesn't support
C++ standards modes earlier than C++14 ( /std:c++14 ). Such support isn't planned. As
an imperfect workaround, it's possible to use older Visual C++ compiler toolsets that
didn't implement features from later standards. For more information on how to install
and use older compiler toolsets in Visual Studio, see Use native multi-targeting in Visual
Studio to build old projects.
C++ standards support
Detect whether the /std option is in effect during a C++ compilation with the
_MSVC_LANG preprocessor macro. For more information, see Preprocessor Macros.
） Important
Because some existing code depends on the value of the macro __cplusplus being
199711L , the MSVC compiler doesn't change the value of this macro unless you
explicitly opt in by setting /Zc:__cplusplus. Specify /Zc:__cplusplus and the /std
option to set __cplusplus to the appropriate value.
/std:c++14
Enables C++14 standard-specific features implemented by the MSVC compiler. This
option is the default for code compiled as C++. It's available starting in Visual Studio
2015 Update 3.
This option disables compiler and standard library support for features that are changed
or new in more recent versions of the language standard. However, it doesn't disable
some C++17 features already implemented in previous releases of the MSVC compiler.
For more information, see Microsoft C/C++ language conformance. The tables indicate
which C++17 features are enabled when you specify /std:c++14 .
The following features remain enabled when the /std:c++14 option is specified to avoid
breaking changes for users who took dependencies on features available in or before
Visual Studio 2015 Update 2:
Rules for auto with braced-init-lists
typename in template template-parameters
Removing trigraphs
Attributes for namespaces and enumerators
u8 character literals
/std:c++17
Enables C++17 standard-specific features and behavior. It enables the full set of C++17
features implemented by the MSVC compiler. This option disables compiler and
standard library support for features that are new or changed after C++17. It specifically
disables post-C++17 changes in the C++ Standard and versions of the Working Draft. It
doesn't disable retroactive defect updates of the C++ Standard. This option is available
starting in Visual Studio 2017 version 15.3.
Depending on the MSVC compiler version or update level, C++17 features may not be
fully implemented or fully conforming when you specify the /std:c++17 option. For an
overview of C++ language conformance in Visual C++ by release version, see Microsoft
C/C++ language conformance.
/std:c++20
Enables C++20 standard-specific features and behavior.
Enables the standard conformance mode provided by /permissive- unless explicitly
overridden with /permissive .
/std:c++23preview
Enables preview C++23 standard-specific features and behavior. Available starting in
Visual Studio 2022 version 17.13 Preview 4. Preview features may change and may not
be ABI compatible across releases.
This switch will be removed when the /std:c++23 switch is implemented--at which point
C++23 features will be fully implemented and ABI stable. If in project properties C/C++
> Language you specify Preview - ISO C++ 23 Standard (/std:c++preview), it will
automatically change to mean /std:c++23 once the new switch is implemented.
This switch differs from /std:c++latest in that it only enables features that are part of
the C++23 standard. It doesn't enable experimental or in-progress features.
/std:c++latest
Enables all currently implemented compiler and standard library features proposed in
the next ISO C++ working draft, as well as some in-progress and experimental features.
This option is available starting with Visual Studio 2015 Update 3.
Depending on the MSVC compiler version or update level, features from published C++
standards or proposed features in the current C++ working draft, may not be fully
implemented or fully conforming when you specify the /std:c++latest option. We
recommend you use the latest version of Visual Studio for maximum standards
conformance. For an overview of C++ language and library conformance in Visual C++
by release version, see Microsoft C/C++ language conformance.
Since Visual Studio 2019 version 16.8, the /std:c++latest option has enabled the
standard conformance mode provided by /permissive- unless explicitly overridden with
/permissive .
For a list of supported language and library features, see What's New for C++ in Visual
Studio.
The /std:c++latest option doesn't enable features guarded by the /experimental
switch, but may be required to enable them.
７ Note
The compiler and library features enabled by /std:c++latest may appear in a
future C++ standard. Features that haven't been approved are subject to breaking
changes or removal without notice and are provided on an as-is basis.
C standards support
You can invoke the Microsoft C compiler by using the /TC or /Tc compiler option. It's
used by default for code that has a .c file extension, unless overridden by a /TP or /Tp
option. The default C compiler (that is, the compiler when /std:c11 or /std:c17 isn't
specified) implements ANSI C89, but includes several Microsoft extensions, some of
which are part of ISO C99. Some Microsoft extensions to C89 can be disabled by using
the /Za compiler option, but others remain in effect. It isn't possible to specify strict C89
conformance. The compiler doesn't implement several required features of C99, so it
isn't possible to specify C99 conformance, either.
/std:c11
Enables ISO C11 conformance. It's available starting in Visual Studio 2019 version 16.8.
/std:c17
Enables ISO C17 conformance. It's available starting in Visual Studio 2019 version 16.8.
Because the new preprocessor is needed to support these standards, the /std:c11 and
/std:c17 compiler options set the /Zc:preprocessor option automatically. If you want to
use the traditional (legacy) preprocessor for C11 or C17, you must set the
/Zc:preprocessor- compiler option explicitly. Setting the /Zc:preprocessor- option may
lead to unexpected behavior, and isn't recommended.
７ Note
At the time of release and through Visual Studio 2019 version 16.10, the Windows
SDK and UCRT libraries installed by Visual Studio don't yet support C11 and C17
code. An updated version of the Windows SDK and UCRT is required. For more
information and installation instructions, see Install C11 and C17 support in Visual
Studio.
When you specify /std:c11 or /std:c17 , MSVC supports all the features of C11 and C17
required by the standards. The /std:c11 and /std:c17 compiler options enable support
for these functionalities:
_Pragma
restrict
_Noreturn and <stdnoreturn.h>
_Alignas, _Alignof and <stdalign.h>
_Generic and <tgmath.h>
_Static_assert
The IDE uses C settings for IntelliSense and code highlighting when your source files
have a .c file extension, or when you specify the /TC or /Tc compiler option. Currently,
IntelliSense in C highlights keywords _Alignas , _Alignof , _Noreturn , and
_Static_assert , but not the equivalent macros defined in the standard headers:
alignas , alignof , noreturn , and static_assert .
Since C17 is largely a bug-fix release of ISO C11, MSVC support for C11 already includes
all the relevant defect reports. There are no differences between the C11 and C17
versions except for the __STDC_VERSION__ macro. It expands to 201112L for C11, and
201710L for C17.
The compiler doesn't support most optional features of ISO C11. Several of these
optional features of C11 were required features of C99 that MSVC hasn't implemented
for architectural reasons. You can use the feature test macros such as __STDC_NO_VLA__
to detect compiler support levels for individual features. For more information about C￾specific predefined macros, see Predefined macros.
There's no conforming multithreading, atomic, or complex number support.
aligned_alloc support is missing, because of the Windows heap implementation.
The alternative is to use _aligned_malloc.
Defect report 400 support is currently unimplemented for realloc because this
change would break the ABI.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Variable length array (VLA) support isn't planned. VLAs provide attack vectors
comparable to gets, which is deprecated and planned for removal.
The /std:clatest option behaves like the /std:c++latest switch for the C++ compiler.
The switch enables all currently implemented compiler and standard library features
proposed in the next draft C standard, as well as some in-progress and experimental
features.
For more information, see the C Standard library features section of Microsoft C/C++
language conformance.
1. Open the project's Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language property page.
3. In C++ Language Standard (or for C, C Language Standard), choose the language
standard to support from the dropdown control, then choose OK or Apply to save
your changes.
/Zc:__cplusplus[-]
MSVC compiler options
MSVC compiler command-line syntax
/std:clatest
To set this compiler option in the Visual Studio
development environment
See also
 Yes  No
/Tc, /Tp, /TC, /TP (Specify Source File
Type)
Article • 08/03/2021
The /Tc option specifies that its filename argument is a C source file, even if it does not
have a .c extension. The /Tp option specifies that its filename argument is a C++ source
file, even if it doesn't have a .cpp or .cxx extension. A space between the option and the
filename is optional. Each option specifies one file; to specify additional files, repeat the
option.
/TC and /TP are global variants of /Tc and /Tp. They specify to the compiler to treat all
files named on the command line as C source files (/TC) or C++ source files (/TP),
without regard to location on the command line in relation to the option. These global
options can be overridden on a single file by means of /Tc or /Tp.
Syntax
/Tc filename
/Tp filename
/TC
/TP
Arguments
filename
A C or C++ source file.
Remarks
By default, CL assumes that files with the .c extension are C source files and files with the
.cpp or the .cxx extension are C++ source files.
When either the TC or Tc option is specified, any specification of the /Zc:wchar_t
(wchar_t Is Native Type) option is ignored.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Compile As property. Choose OK or Apply to apply your changes.
To set this compiler option programmatically
See CompileAs.
Examples
This CL command line specifies that MAIN.c, TEST.prg, and COLLATE.prg are all C source
files. CL will not recognize PRINT.prg.
CL MAIN.C /TcTEST.PRG /TcCOLLATE.PRG PRINT.PRG
This CL command line specifies that TEST1.c, TEST2.cxx, TEST3.huh, and TEST4.o are
compiled as C++ files, and TEST5.z is compiled as a C file.
CL TEST1.C TEST2.CXX TEST3.HUH TEST4.O /Tc TEST5.Z /TP
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/translateInclude
Article • 02/18/2022
This switch instructs the compiler to treat #include as import for header files that have
been built into header unit ( .ifc ) files and that are specified on the command line with
/headerUnit.
When used with /scanDependencies or /sourceDependencies-directives, the compiler
lists as imported header units in the generated dependency file those headers that are
both included in the source and have a corresponding entry in a header-units.json file.
This dependency info is used by the build system to generate compiled header unit
.ifc files. Once the header units are built, they're treated by the compiler as an import
instead of an #include .
The header-units.json file is only consulted when /translateInclude is specified. For
more information about the format and purpose of the header-units.json file, see
header-units.json.
If an #include file isn't listed in the header-units.json file, it's treated as a normal
#include .
For an example of how this switch is used, see Walkthrough: Build and import header
units in Microsoft Visual C++.
Syntax
/translateInclude
Remarks
/translateInclude is available in Visual Studio 2019 version 16.10, or later.
/translateInclude requires /std:c++20 or later.
To set this compiler option in Visual Studio
To enable /translateInclude , in the project properties dialog, set Translate Includes to
Imports:
1. In the left-hand pane of the project property pages, select Configuration
Properties > C/C++ > General.
2. Change the Translate Includes to Imports dropdown to Yes.
3. Choose OK or Apply to save your changes.
See also
/headerUnit (Use header unit IFC).
/exportHeader (Create header units)
/reference (Use named module IFC)
/scanDependencies
/sourceDependencies-directives
Walkthrough: Build and import header units in Microsoft Visual C++
/U, /u (Undefine symbols)
Article • 08/03/2021
The /U compiler option undefines the specified preprocessor symbol. The /u compiler
option undefines the Microsoft-specific symbols that the compiler defines.
/U [ ]symbol
/u
symbol
The preprocessor symbol to undefine.
Neither of the /U and /u options can undefine a symbol created by using the #define
directive.
The /U option can undefine a symbol that was previously defined by using the /D
option.
By default, the compiler may define a large number of Microsoft-specific symbols. Here
are a few common ones:
Symbol Function
_CHAR_UNSIGNED Default char type is unsigned. Defined when the /J option is specified.
_CPPRTTI Defined for code compiled with the /GR option.
_CPPUNWIND Defined for code compiled with the /EHsc option.
_DLL Defined when the /MD option is specified.
_M_IX86 By default, defined to 600 for x86 targets.
_MSC_VER Defined as a unique integer value for each compiler version. For more
information, see Predefined macros.
Syntax
Arguments
Remarks
Symbol Function
_WIN32 Defined for WIN32 applications. Always defined.
_MT Defined when the /MD or /MT option is specified.
For a complete list of Microsoft-specific predefined macros, see Predefined macros.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Undefine Preprocessor Definitions or Undefine All Preprocessor
Definitions properties.
See UndefineAllPreprocessorDefinitions or UndefinePreprocessorDefinitions.
MSVC compiler options
MSVC compiler command-line syntax
/J (Default char type is unsigned)
/GR (Enable run-time type information)
/EH (Exception handling model)
/MD , /MT , /LD (Use run-time library)
To set this compiler option in the Visual Studio
development environment
To set this compiler option programmatically
See also
/utf-8 (Set source and execution
character sets to UTF-8)
Article • 02/01/2022
Specifies both the source character set and the execution character set as UTF-8.
Syntax
/utf-8
Remarks
You can use the /utf-8 option to specify both the source and execution character sets
as encoded by using UTF-8. It's equivalent to specifying /source-charset:utf-8
/execution-charset:utf-8 on the command line. Any of these options also enables the
/validate-charset option by default. For a list of supported code page identifiers and
character set names, see Code Page Identifiers.
By default, Visual Studio detects a byte-order mark to determine if the source file is in
an encoded Unicode format, for example, UTF-16 or UTF-8. If no byte-order mark is
found, it assumes that the source file is encoded in the current user code page, unless
you've specified a code page by using /utf-8 or the /source-charset option. Visual
Studio allows you to save your C++ source code in any of several character encodings.
For information about source and execution character sets, see Character sets in the
language documentation.
Set the option in Visual Studio or
programmatically
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional Options, add the /utf-8 option to specify your preferred encoding.
4. Choose OK to save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/execution-charset (Set execution character set)
/source-charset (Set source character set)
/validate-charset (Validate for compatible characters)
/V (Version Number)
Article • 08/03/2021
Deprecated. Embeds a text string in the .obj file.
Syntax
/Vstring
Arguments
string
A string specifying the version number or copyright notice to be embedded in an .obj
file.
Remarks
The stringcan label an .obj file with a version number or a copyright notice. Any space or
tab characters must be enclosed in double quotation marks (") if they are a part of the
string. A backslash (\) must precede any double quotation marks if they are a part of the
string. A space between /V and string is optional.
You can also use comment (C/C++) with the compiler comment-type argument to place
the name and version number of the compiler in the .obj file.
The /V option is deprecated beginning in Visual Studio 2005; /V was primarily used to
support building virtual device drivers (VxDs), and building VxDs is no longer supported
by the Visual C++ toolset. For a list of deprecated compiler options, see Deprecated
and Removed Compiler Options in Compiler Options Listed by Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/validate-charset (Validate for
compatible characters)
Article • 02/01/2022
This compiler option validates that the source file text contains only characters
representable as UTF-8.
Syntax
validate-charset [ - ]
Remarks
You can use the /validate-charset option to validate that the source code contains
only characters that can be represented in both the source character set and the
execution character set. This check is enabled automatically when you specify /source￾charset , /execution-charset , or /utf-8 compiler options. To explicitly disable this
check, specify the /validate-charset- option.
By default, Visual Studio detects a byte-order mark to determine if the source file is in
an encoded Unicode format, for example, UTF-16 or UTF-8. If no byte-order mark is
found, it assumes that the source file is encoded in the current user code page, unless
you have specified a code page by using /utf-8 or the /source-charset option. Visual
Studio allows you to save your C++ source code in any of several character encodings.
For information about source and execution character sets, see Character sets in the
language documentation. For a list of supported code page identifiers and character set
names, see Code Page Identifiers.
Visual Studio uses UTF-8 as the internal character encoding during conversion between
the source character set and the execution character set. If a character in the source file
can't be represented in the execution character set, the UTF-8 conversion substitutes a
question mark ( ? ) character. If a substitution occurs, the /validate-charset option
causes the compiler to report a warning.
To set this compiler option in the Visual Studio
development environment
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional Options, add the /validate-charset or /validate-charset- option.
4. Choose OK to save your changes.
See also
MSVC compiler options
MSVC compiler command-line syntax
/execution-charset (Set execution character set)
/source-charset (Set source character set)
/utf-8 (Set source and execution character sets to UTF-8)
/vd (Disable Construction
Displacements)
Article • 08/03/2021
Syntax
/vdn
Arguments
0
Suppresses the vtordisp constructor/destructor displacement member. Choose this
option only if you are certain that all class constructors and destructors call virtual
functions virtually.
1
Enables the creation of hidden vtordisp constructor/destructor displacement members.
This choice is the default.
2
Allows you to use dynamic_cast Operator on an object being constructed. For example,
a dynamic_cast from a virtual base class to a derived class.
/vd2 adds a vtordisp field when you have a virtual base with virtual functions. /vd1
should be sufficient. The most common case where /vd2 is necessary is when the only
virtual function in your virtual base is a destructor.
Remarks
These options apply only to C++ code that uses virtual bases.
Visual C++ implements C++ construction displacement support in situations where
virtual inheritance is used. Construction displacements solve the problem created when
a virtual function, declared in a virtual base and overridden in a derived class, is called
from a constructor during construction of a further derived class.
The problem is that the virtual function may be passed an incorrect this pointer as a
result of discrepancies between the displacements to the virtual bases of a class and the
displacements to its derived classes. The solution provides a single construction
displacement adjustment, called a vtordisp field, for each virtual base of a class.
By default, vtordisp fields are introduced whenever the code defines user-defined
constructors and destructors and also overrides virtual functions of virtual bases.
These options affect entire source files. Use vtordisp to suppress and then re-enable
vtordisp fields on a class-by-class basis.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/vlen
Article • 10/16/2024
Specifies the vector length for code generation on x86 and x64. For more information
about /arch for x86 and x64, see /arch (x86) and /arch (x64).
Syntax
/vlen= [ 256 | 512 ]
/vlen
Arguments
/vlen=256
Specify a vector length of 256 bits for auto-vectorization and other optimizations.
/vlen=512
Specify a vector length of 512 bits for auto-vectorization and other optimizations.
/vlen
Specify the default vector length for the selected /arch setting.
Remarks
If a specific /vlen value isn't specified, the default vector length depends on the /arch
flag setting. The /vlen flag can override the default vector length specified by
/arch:AVX512 or /arch:AVX10.1 flag. For example:
/arch:AVX512 /vlen=256 overrides the default vector length of 512 bits specified by
/arch:AVX512 to be 256 bits.
/arch:AVX10.1 /vlen=512 overrides the default vector length of 256 bits specified
by /arch:AVX10.1 to be 512 bits.
When the specified /vlen value is incompatible with specified /arch flag, a warning is
generated and default vector length for the /arch setting is used. For example:
/arch:AVX2 /vlen=512 generates a warning because AVX2 doesn't support 512-bit
vectors. Vector length of 256 bits is used in this case.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /vlen=256 or /vlen=512 . Choose OK to save
your changes.
/arch (Minimum CPU Architecture)
MSVC compiler options
MSVC compiler command-line syntax
To set the /vlen=256 or /vlen=512 compiler option in
Visual Studio
See also
 Yes  No
/vmb , /vmg (Representation method)
Article • 08/03/2021
Select the method that the compiler uses to represent pointers to class members.
Syntax
/vmb
/vmg
Options
/vmb is the compiler's default behavior. Its behavior is the same as #pragma
pointers_to_members(best_case) . It doesn't require or ensure complete types. For
complete types, it uses the best representation among single, multiple, or virtual
inheritance based the inheritance of the class type. For incomplete types, it uses the
largest, most general representation.
/vmg lets you specify compiler behavior in combination with /vmm, /vms, /vmv (General
purpose representation) to declare a pointer to a member of a class before defining the
class. This need can arise if you define members in two different classes that reference
each other. For such mutually referencing classes, one class must be referenced before
it's defined.
Remarks
You can also use #pragma pointers_to_members or Inheritance keywords in your code
to specify a pointer representation.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/vmm , /vms , /vmv (General Purpose
Representation)
Article • 08/06/2021
Used when /vmg is selected as the representation method. These options indicate the
inheritance model of the not-yet-encountered class definition.
Syntax
/vmm
/vms
/vmv
Options
/vmm
Specifies the most general representation of a pointer to a member of a class as one
that uses multiple inheritance.
The corresponding inheritance keyword and argument to #pragma
pointers_to_members is multiple_inheritance .
This representation is larger than the one required for single inheritance.
If you use /vmm and declare a pointer to member of a class that has a virtual inheritance
model, the compiler generates an error.
/vms
Specifies the most general representation of a pointer to a member of a class as one
that uses either no inheritance or single inheritance.The corresponding inheritance
keyword and argument to #pragma pointers_to_members is single_inheritance .
This option generates the smallest possible representation of a pointer to a member of
a class.
If you use /vms and declare a pointer to member of a class that has a multiple or virtual
inheritance model, the compiler generates an error.
/vmv
Specifies the most general representation of a pointer to a member of a class as one
that uses virtual inheritance. This pointer representation never causes an error and is the
default.
The corresponding inheritance keyword and argument to #pragma
pointers_to_members is virtual_inheritance .
This option requires a larger pointer and more code to interpret the pointer than the
other options.
Remarks
In Visual Studio 2019 and earlier versions, Microsoft uses different representations (of
different sizes) for pointer-to-member types. Pointers to members of classes that have
no inheritance or single inheritance have the smallest representation. Pointers to
members of classes that have multiple inheritance are larger. Pointers to members of
classes that have virtual inheritance are the largest. When no representation model is
specified to the compiler, it defaults to using the largest, most general representation.
When you specify one of these inheritance-model options, that model gets used for all
pointers to class members, no matter their inheritance type or whether you declare the
pointer before or after the class. If you always use single-inheritance classes, you can
reduce code size by compiling with /vms . However, if you want to use the most general
case (at the expense of the largest data representation), compile with /vmv .
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
/vmb, /vmg (Representation method)
MSVC compiler options
MSVC compiler command-line syntax
/volatile (volatile Keyword
Interpretation)
Article • 06/15/2022
Specifies how the volatile keyword is to be interpreted.
Syntax
/volatile:{iso|ms}
Arguments
/volatile:iso
Selects strict volatile semantics as defined by the ISO-standard C++ language.
Acquire/release semantics are not guaranteed on volatile accesses. If the compiler
targets ARM (except ARM64EC), this is the default interpretation of volatile .
/volatile:ms
Selects Microsoft extended volatile semantics, which add memory ordering
guarantees beyond the ISO-standard C++ language. Acquire/release semantics are
guaranteed on volatile accesses. However, this option also forces the compiler to
generate hardware memory barriers, which might add significant overhead on ARM and
other weak memory-ordering architectures. If the compiler targets ARM64EC or any
non-ARM platform, this is default interpretation of volatile .
Remarks
We strongly recommend that you use /volatile:iso along with explicit synchronization
primitives and compiler intrinsics when you are dealing with memory that is shared
across threads. For more information, see volatile.
If you port existing code or change this option in the middle of a project, it may be
helpful to enable warning C4746 to identify code locations that are affected by the
difference in semantics.
There is no #pragma equivalent to control this option.
To set the /volatile compiler option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In the Additional options box, add /volatile:iso or /volatile:ms and then choose
OK or Apply to save your changes.
See also
volatile
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/volatileMetadata (Generate metadata
on volatile memory accesses)
Article • 05/31/2024
Generate metadata for volatile memory accesses to improve performance when running
x64 code on ARM64.
Syntax
C++
/volatileMetadata[-]
Arguments
-
Turns off /volatileMetadata . This may result in worse performance when your code runs
in emulation mode on ARM64 because the emulator pessimistically assumes that every
load/store needs a barrier.
Remarks
Starting with Visual Studio 2019 16.10, /volatileMetadata is on by default when
generating x64 code. It improves the emulation performance of x64 code on ARM64 by
generating metadata that identifies volatile memory addresses. An emulator can use this
metadata to improve performance by not using acquire/release semantics on those
accesses it knows aren't volatile. Without this metadata, the emulator assumes that all
addresses are volatile and uses acquire and release semantics.
One side effect of /volatileMetadata is you may see npad macros used in the generated
code. This macro expands to a specified number of NOP instructions that create an
address to associate with a memory barrier. That address is then recorded in the
metadata to indicate that acquire/release semantics should be used to access it.
/volatileMetadata is ignored when targeting x86.
/volatileMetadata can be disabled by using /volatileMetadata- .
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Visual Studio 2019 version 16.10 or later.
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Requirements
See also
 Yes  No
/w, /W0, /W1, /W2, /W3, /W4, /w1, /w2,
/w3, /w4, /Wall, /wd, /we, /wo, /Wv,
/WX (Warning level)
Article • 02/18/2022
Specifies how the compiler generates warnings for a given compilation.
/w
/W0
/W1
/W2
/W3
/W4
/Wall
/Wv[:version]
/WX
/w1warning
/w2warning
/w3warning
/w4warning
/wdwarning
/wewarning
/wowarning
The warning options specify which compiler warnings to display and the warning
behavior for the entire compilation.
The warning options and related arguments are described in the following tables:
Option Description
/w Suppresses all compiler warnings.
Syntax
Remarks
Option Description
/W0
/W1
/W2
/W3
/W4
Specifies the level of warnings to be generated by the compiler. Valid warning
levels range from 0 to 4:
/W0 suppresses all warnings. It's equivalent to /w.
/W1 displays level 1 (severe) warnings. /W1 is the default setting in the command￾line compiler.
/W2 displays level 1 and level 2 (significant) warnings.
/W3 displays level 1, level 2, and level 3 (production quality) warnings. /W3 is the
default setting in the IDE.
/W4 displays level 1, level 2, and level 3 warnings, and all level 4 (informational)
warnings that aren't off by default. We recommend that you use this option to
provide lint-like warnings. For a new project, it may be best to use /W4 in all
compilations. This option helps ensure the fewest possible hard-to-find code
defects.
/Wall Displays all warnings displayed by /W4 and all other warnings that /W4 doesn't
include—for example, warnings that are off by default. For more information, see
Compiler warnings that are off by default.
/Wv[:version] Displays only warnings introduced in the version compiler version and earlier. You
can use this option to suppress new warnings in code when you migrate to a
newer version of the compiler. It lets you maintain your existing build process
while you fix them. The optional parameter version takes the form
nn[.mm[.bbbbb]], where nn is the major version number, mm is the optional minor
version number, and bbbbb is the optional build number of the compiler. For
example, use /Wv:17 to display only warnings introduced in Visual Studio 2012
(major version 17) or earlier. That is, it displays warnings from any version of the
compiler that has a major version number of 17 or less. It suppresses warnings
introduced in Visual Studio 2013 (major version 18) and later. By default, /Wv uses
the current compiler version number, and no warnings are suppressed. For
information about which warnings are suppressed by compiler version, see
Compiler warnings by compiler version.
/WX Treats all compiler warnings as errors. For a new project, it may be best to use
/WX in all compilations; resolving all warnings ensures the fewest possible hard￾to-find code defects.
The linker also has a /WX option. For more information, see /WX (Treat linker
warnings as errors).
The following options are mutually exclusive with each other. The last option that's
specified from this group is the one applied:
Option Description
Option Description
/w1nnnn
/w2nnnn
/w3nnnn
/w4nnnn
Sets the warning level for the warning number specified by nnnn. These options let
you change the compiler behavior for that warning when a specific warning level is
set. You can use these options in combination with other warning options to enforce
your own coding standards for warnings, rather than the default ones provided by
Visual Studio.
For example, /w34326 causes C4326 to be generated as a level 3 warning instead of
level 1. If you compile by using both the /w34326 option and the /W2 option,
warning C4326 isn't generated.
/wdnnnn Suppresses the compiler warning that is specified by nnnn.
For example, /wd4326 suppresses compiler warning C4326.
/wennnn Treats the compiler warning that is specified by nnnn as an error.
For example, /we4326 causes warning number C4326 to be treated as an error by the
compiler.
/wonnnn Reports the compiler warning that is specified by nnnn only once.
For example, /wo4326 causes warning C4326 to be reported only once, the first time
it's encountered by the compiler.
If you use any warning options when you create a precompiled header, it keeps those
settings. Using the precompiled header puts those same warning options in effect again.
To override the precompiled header warning options, set another warning option on the
command line.
You can use a #pragma warning directive to control the level of warning that's reported
at compile time in specific source files.
Warning pragma directives in source code are unaffected by the /w option.
The build errors documentation describes the warnings and warning levels, and
indicates why certain statements may not compile as you intend.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
To set the compiler options in the Visual Studio
development environment
2. To set the /W0, /W1, /W2, /W3, /W4, /Wall, /Wv, /WX, or /WX- options, select
Configuration Properties > C/C++ > General.
To set the /W0, /W1, /W2, /W3, /W4, or /Wall options, modify the Warning
Level property.
To set the /WX or /WX- options, modify the Treat Warnings as Errors
property.
To set the version for the /Wv option, enter the compiler version number in
the Warning Version property.
3. To set the /wd or /we options, select the Configuration Properties > C/C++ >
Advanced property page.
To set the /wd option, select the Disable Specific Warnings property
dropdown control and then choose Edit. In the edit box in the Disable
Specific Warnings dialog, enter the warning number. To enter more than one
warning, separate the values by using a semicolon (;). For example, to disable
both C4001 and C4010, enter 4001;4010. Choose OK to save your changes
and return to the Property Pages dialog.
To set the /we option, Select the Treat Specific Warnings As Errors property
dropdown control and then choose Edit. In the edit box in the Treat Specific
Warnings As Errors dialog, enter the warning number. To enter more than
one warning, separate the values by using a semicolon (;). For example, to
treat both C4001 and C4010 as errors, enter 4001;4010. Choose OK to save
your changes and return to the Property Pages dialog.
4. To set the /wo option, select the Configuration Properties > C/C++ > Command
Line property page. Enter the compiler option in the Additional Options box.
5. Choose OK to save your changes.
To set the compiler option programmatically
See WarningLevel, WarnAsError, DisableSpecificWarnings, and AdditionalOptions.
See also
MSVC compiler options
MSVC compiler command-line syntax
/WL (Enable One-Line Diagnostics)
Article • 08/03/2021
Appends additional information to an error or warning message.
Error and warning messages from the C++ compiler can be followed by additional
information that appears, by default, on a new line. When you compile from the
command line, the extra line of information can be appended to the error or warning
message. It's useful if you capture your build output to a log file and then process that
log to find all errors and warnings. A semicolon will separate the error or warning
message from the additional line.
Not all error and warning messages have an extra line of information. The following
code will generate an error that has another line of information. It lets you test the effect
when you use /WL.
C++
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
Syntax
/WL
Remarks
// compiler_option_WL.cpp
// compile with: /WL
#include <queue>
int main() {
 std::queue<int> q;
 q.fromthecontinuum(); // C2039
}
To set this compiler option in the Visual Studio
development environment
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Wp64 (Detect 64-Bit Portability Issues)
Article • 08/03/2021
This compiler option is obsolete. In versions of Visual Studio before Visual Studio 2013,
this detects 64-bit portability problems on types that are also marked with the __w64
keyword.
Syntax
/Wp64
Remarks
By default, in versions of Visual Studio before Visual Studio 2013, the /Wp64 compiler
option is off in the MSVC compiler that builds 32-bit x86 code, and on in the MSVC
compiler that builds 64-bit, x64 code.
） Important
The /Wp64 compiler option and __w64 keyword are deprecated in Visual Studio
2010 and Visual Studio 2012, and not supported starting in Visual Studio 2013. If
you convert a project that uses this switch, the switch will not be migrated during
conversion. To use this option in Visual Studio 2010 or Visual Studio 2012, you must
type the compiler switch under Additional Options in the Command Line section
of the project properties. If you use the /Wp64 compiler option on the command
line, the compiler issues Command-Line Warning D9002. Instead of using this
option and keyword to detect 64-bit portability issues, use a MSVC compiler that
targets a 64-bit platform and specify the /W4 option. For more information, see
Configure C++ projects for 64-bit, x64 targets.
Variables of the following types are tested on a 32-bit operating system as if they were
being used on a 64-bit operating system:
int
long
pointer
If you regularly compile your application by using a compiler that builds 64-bit, x64
code, you can just disable /Wp64 in your 32-bit compilations because the 64-bit
compiler will detect all issues. For more information about how to target a Windows 64-
bit operating system, see Configure C++ projects for 64-bit, x64 targets.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options box to include /Wp64.
To set this compiler option programmatically
See Detect64BitPortabilityProblems.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Configure C++ projects for 64-bit, x64 targets
/X (Ignore standard include paths)
Article • 08/03/2021
Prevents the compiler from searching for include files in directories specified in the PATH
and INCLUDE environment variables.
Syntax
/X
Remarks
You can use this option with the /I (Additional include directories) option to specify an
alternate path to the standard include files.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Modify the Ignore Standard Include Path property.
To set this compiler option programmatically
See IgnoreStandardIncludePath.
Example
In the following command, /X tells the compiler to ignore locations specified by the
PATH and INCLUDE environment variables, and /I specifies the directory to look in for
include files:
Windows Command Prompt
CL /X /I \ALT\INCLUDE MAIN.C
See also
MSVC compiler options
MSVC compiler command-line syntax
/Y (precompiled headers)
Article • 08/03/2021
The following compiler options affect the generation and use of precompiled headers:
/Y- (Ignore precompiled header options)
/Yc (Create precompiled header file)
/Yd (Place Debug Information in Object file)
/Yl (Inject PCH reference for debug library)
/Yu (Use precompiled header file)
For details on working with precompiled headers, see precompiled header files.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Y- (Ignore Precompiled Header
Options)
Article • 08/03/2021
Causes all other /Y compiler options to be ignored (and cannot itself be overridden).
Syntax
/Y￾Remarks
For more information on precompiled headers, see:
/Y (Precompiled Headers)
Precompiled Header Files
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Yc (Create Precompiled Header File)
Article • 08/03/2021
Instructs the compiler to create a precompiled header (.pch) file that represents the state
of compilation at a certain point.
Syntax
/Yc
/Ycfilename
Arguments
filename
Specifies a header (.h) file. When this argument is used, the compiler compiles all code
up to and including the .h file.
Remarks
When /Yc is specified without an argument, the compiler compiles all code up to the
end of the base source file, or to the point in the base file where a hdrstop directive
occurs. The resulting .pch file has the same base name as your base source file unless
you specify a different file name using the hdrstop pragma or the /Fp option.
The precompiled code is saved in a file with a name created from the base name of the
file specified with the /Yc option and a .pch extension. You can also use the /Fp (Name
.Pch File) option to specify a name for the precompiled header file.
If you use /Ycfilename, the compiler compiles all code up to and including the specified
file for subsequent use with the /Yu (Use Precompiled Header File) option.
If the options /Ycfilename and /Yufilename occur on the same command line and both
reference, or imply, the same file name, /Ycfilename takes precedence. This feature
simplifies the writing of makefiles.
For more information on precompiled headers, see:
/Y (Precompiled Headers)
Precompiled Header Files
To set this compiler option in the Visual Studio
development environment
1. Select a .cpp file. The .cpp file must #include the .h file that contains precompiled
header information. The project's /Yc setting can be overridden at the file level.
2. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
3. Open the Configuration Properties, C/C++, Precompiled Headers property page.
4. Modify the Precompiled Header property.
5. To set the filename, modify the Precompiled Header File property.
To set this compiler option programmatically
See PrecompiledHeaderThrough and UsePrecompiledHeader.
Example
Consider the following code:
C++
// prog.cpp
// compile with: cl /c /Ycmyapp.h prog.cpp
#include <afxwin.h> // Include header for class library
#include "resource.h" // Include resource definitions
#include "myapp.h" // Include information specific to this app
// ...
When this code is compiled with the command CL /YcMYAPP.H PROG.CPP , the compiler
saves all the preprocessing for AFXWIN.h, RESOURCE.h, and MYAPP.h in a precompiled
header file called MYAPP.pch.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Precompiled Header Files
/Yd (Place Debug Information in Object
File)
Article • 08/03/2021
Paces complete debugging information in all object files created from a precompiled
header (.pch) file when used with the /Yc and /Z7 options. Deprecated.
Syntax
/Yd
Remarks
/Yd is deprecated; Visual C++ now supports multiple objects writing to a single .pdb file,
use /Zi instead. For a list of deprecated compiler options, see Deprecated and Removed
Compiler Options in Compiler Options Listed by Category.
Unless you need to distribute a library containing debugging information, use the /Zi
option rather than /Z7 and /Yd.
Storing complete debugging information in every .obj file is necessary only to distribute
libraries that contain debugging information. It slows compilation and requires
considerable disk space. When /Yc and /Z7 are used without /Yd, the compiler stores
common debugging information in the first .obj file created from the .pch file. The
compiler does not insert this information into .obj files subsequently created from the
.pch file; it inserts cross-references to the information. No matter how many .obj files
use the .pch file, only one .obj file contains the common debugging information.
Although this default behavior results in faster build times and reduces disk-space
demands, it is undesirable if a small change requires rebuilding the .obj file containing
the common debugging information. In this case, the compiler must rebuild all .obj files
containing cross-references to the original .obj file. Also, if a common .pch file is used by
different projects, reliance on cross-references to a single .obj file is difficult.
For more information on precompiled headers, see:
/Y (Precompiled Headers)
Precompiled Header Files
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
Examples
Suppose you have two base files, F.cpp and G.cpp, each containing these #include
statements:
#include "windows.h"
#include "etc.h"
The following command creates the precompiled header file ETC.pch and the object file
F.obj:
CL /YcETC.H /Z7 F.CPP
The object file F.obj includes type and symbol information for WINDOWS.h and ETC.h
(and any other header files they include). Now you can use the precompiled header
ETC.pch to compile the source file G.cpp:
CL /YuETC.H /Z7 G.CPP
The object file G.obj does not include the debugging information for the precompiled
header but simply references that information in the F.obj file. Note that you must link
with the F.obj file.
If your precompiled header was not compiled with /Z7, you can still use it in later
compilations using /Z7. However, the debugging information is placed in the current
object file, and local symbols for functions and types defined in the precompiled header
are not available to the debugger.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Yl (Inject PCH Reference for Debug
Library)
Article • 08/03/2021
The /Yl option generates a unique symbol in a precompiled header file, and a reference
to this symbol is injected in all object files that use the precompiled header.
Syntax
/Yl
/Ylname
/Yl￾Arguments
name
An optional name used as part of the unique symbol.
-
A dash (-) explicitly disables the /Yl compiler option.
Remarks
The /Yl compiler option creates a unique symbol definition in a precompiled header file
created by using the /Yc option. References to this symbol are automatically injected in
all files that include the precompiled header by using the /Yu compiler option. The /Yl
option is enabled by default when /Yc is used to create a precompiled header file.
The /Ylname option is used to create an identifiable symbol in the precompiled header
file. The compiler uses the name argument as part of the decorated symbol name it
creates, similar to __@@_PchSym_@00@...@name , where the ellipsis (...) represents a unique
compiler-generated character string. If the name argument is omitted, the compiler
generates a symbol name automatically. Normally, you do not need to know the name
of the symbol. However, when your project uses more than one precompiled header file,
the /Ylname option may be useful to determine which object files use which
precompiled header. You can use name as a search string to find the symbol reference
in a dump file.
/Yl- disables the default behavior and does not put an identifying symbol in the
precompiled header file. Compiled files that include this precompiled header do not get
a common symbol reference.
When /Yc is not specified, any /Yl option has no effect, but if specified it must match any
/Yl option passed when /Yc is specified.
If you use /Yl-, /Yc and /Z7 options to build a precompiled header file, the debugging
information is stored in the object file for the source file used to create the precompiled
header, rather than a separate .pdb file. If this object file is then made part of a library,
LNK1211 errors or LNK4206 warnings can occur in builds that use this library and the
precompiled header file, if the source file used to create the precompiled header file
does not define any symbols itself. The linker may exclude the object file from the link,
along with the associated debugging information, when nothing in the object file is
referenced in the library client. To solve this problem, specify /Yl (or remove the /Yl￾option) when you use /Yc to create the precompiled header file. This ensures that the
object file from the library that contains the debugging information gets linked in your
build.
For more information on precompiled headers, see:
/Y (Precompiled Headers)
Precompiled Header Files
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add the /Ylname compiler option in the Additional Options box. Choose OK to
save your changes.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Yu (Use precompiled header file)
Article • 08/03/2021
Instructs the compiler to use an existing precompiled header ( .pch ) file in the current
compilation.
Syntax
/Yu [filename]
Arguments
filename
The name of a header file, which is included in the source file using a #include
preprocessor directive.
Remarks
The name of the include file must be the same for both the /Yc option that creates the
precompiled header and for any later /Yu option that indicates use of the precompiled
header.
For /Yc , filename specifies the point at which precompilation stops; the compiler
precompiles all code though filename and names the resulting precompiled header
using the base name of the include file and an extension of .pch .
The .pch file must have been created using /Yc .
The compiler treats all code occurring before the .h file as precompiled. It skips to just
beyond the #include directive associated with the .h file, uses the code contained in
the .pch file, and then compiles all code after filename.
On the command line, no space is allowed between /Yu and filename.
When you specify the /Yu option without a file name, your source program must
contain a #pragma hdrstop pragma that specifies the file name of the precompiled
header, .pch file. In this case, the compiler will use the precompiled header ( .pch file)
named by /Fp (Name .pch file). The compiler skips to the location of that pragma and
restores the compiled state from the specified precompiled header file. Then it compiles
only the code that follows the pragma. If #pragma hdrstop doesn't specify a file name,
the compiler looks for a file with a name derived from the base name of the source file
with a .pch extension. You can also use the /Fp option to specify a different .pch file.
If you specify the /Yu option without a file name and fail to specify a hdrstop pragma,
an error message is generated and the compilation is unsuccessful.
If the /Yc filename and /Yu filename options occur on the same command line and both
reference the same file name, /Yc filename takes precedence, precompiling all code up
to and including the named file. This feature simplifies the writing of makefiles.
Because .pch files contain information about the machine environment and memory
address information about the program, you should only use a .pch file on the machine
where it was created.
For more information on precompiled headers, see:
/Y (Precompiled headers)
Precompiled header files
To set this compiler option in the Visual Studio
development environment
1. Specify /Yc (Create precompiled header file) on a .cpp file in your project.
2. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
3. Select the Configuration Properties > C/C++ > Precompiled Headers property
page.
4. Modify the Precompiled Header property, the Create/Use PCH Through File
property, or the Create/Use Precompiled Header property.
To set this compiler option programmatically
See PrecompiledHeaderThrough and UsePrecompiledHeader.
Example
If the following code:
C++
#include <afxwin.h> // Include header for class library
#include "resource.h" // Include resource definitions
#include "myapp.h" // Include information specific to this app
...
is compiled by using the command line CL /YuMYAPP.H PROG.CPP , the compiler doesn't
process the three include statements. Instead, it uses precompiled code from MYAPP.pch ,
which saves the time involved in preprocessing all three of the files (and any files they
might include).
You can use the /Fp (Name .pch file) option with the /Yu option to specify the name of
the .pch file if the name is different from either the filename argument to /Yc or the
base name of the source file, as in the following example:
Windows Command Prompt
CL /YuMYAPP.H /FpMYPCH.pch PROG.CPP
This command specifies a precompiled header file named MYPCH.pch . The compiler uses
its contents to restore the precompiled state of all header files up to and including
MYAPP.h . The compiler then compiles the code that occurs after the #include
"MYAPP.h" * directive.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Z7 , /Zi , /ZI (Debug Information
Format)
Article • 12/10/2021
The /Z7 , /Zi , and /ZI compiler options specify the type of debugging information
created for your program, and whether this information is kept in object files or in a
program database (PDB) file.
Syntax
/Z7
/Zi
/ZI
Remarks
When you specify a debug option, the compiler produces symbol names for functions
and variables, type information, and line locations for use by the debugger. This
symbolic debugging information can be included either in the object files ( .obj files)
produced by the compiler, or in a separate PDB file (a .pdb file) for the executable. The
debug information format options are described in the following sections.
None
By default, if no debug information format option is specified, the compiler produces no
debugging information, so compilation is faster.
/Z7
The /Z7 option produces object files that also contain full symbolic debugging
information for use with the debugger. These object files and any libraries built from
them can be substantially larger than files that have no debugging information. The
symbolic debugging information includes the names and types of variables, functions,
and line numbers. No PDB file is produced by the compiler. However, a PDB file can still
be generated from these object files or libraries if the linker is passed the /DEBUG option.
For distributors of debug versions of third-party libraries, there's an advantage to not
having a PDB file. However, the object files for any precompiled headers are necessary
during the library link phase, and for debugging. If there's only type information (and no
code) in the .pch object file, you must also use the /Yl (Inject PCH Reference for Debug
Library) option, which is enabled by default, when you build the library.
The deprecated /Gm (Enable Minimal Rebuild) option is unavailable when /Z7 is
specified.
/Zi
The /Zi option produces a separate PDB file that contains all the symbolic debugging
information for use with the debugger. The debugging information isn't included in the
object files or executable, which makes them much smaller.
Use of /Zi doesn't affect optimizations. However, /Zi does imply /debug . For more
information, see /DEBUG (Generate Debug Info).
When you specify both /Zi and /clr , the DebuggableAttribute attribute isn't placed in
the assembly metadata. If you want it, you must specify it in the source code. This
attribute can affect the runtime performance of the application. For more information
about how the Debuggable attribute affects performance and how you can modify the
performance impact, see Making an image easier to debug.
The compiler names the PDB file <project>.pdb , where <project> is the name of your
project. If you compile a file outside of a project, the compiler creates a PDB file named
VC<x>.pdb , where <x> is a concatenation of the major and minor version number of the
compiler version in use. The compiler embeds the name of the PDB and an identifying
timestamped signature in each object file created using this option. This name and
signature point the debugger to the location of symbolic and line-number information.
The name and signature in the PDB file must match the executable for symbols to be
loaded in the debugger. The WinDBG debugger can load mismatched symbols by using
the .symopt+0x40 command. Visual Studio doesn't have a similar option to load
mismatched symbols.
If you create a library from objects that were compiled using /Zi , the associated PDB
file must be available when the library is linked to a program. That means, if you
distribute the library, you must also distribute the PDB file. To create a library that
contains debugging information without using PDB files, you must select the /Z7
option. If you use the precompiled headers options, debugging information for both the
precompiled header and the rest of the source code is placed in the PDB file.
/ZI
The /ZI option is similar to /Zi , but it produces a PDB file in a format that supports the
Edit and Continue feature. To use Edit and Continue debugging features, you must use
this option. The Edit and Continue feature is useful for developer productivity, but can
cause issues in code size, performance, and compiler conformance. Because most
optimizations are incompatible with Edit and Continue, using /ZI disables any #pragma
optimize statements in your code. The /ZI option is also incompatible with use of the
__LINE__ predefined macro; code compiled with /ZI can't use __LINE__ as a non-type
template argument, although __LINE__ can be used in macro expansions.
The /ZI option forces both the /Gy (Enable Function-Level Linking) and /FC (Full Path of
Source Code File in Diagnostics) options to be used in your compilation.
/ZI is incompatible with /clr (Common Language Runtime Compilation).
７ Note
The /ZI option is only available in the compilers targeting x86 and x64 processors.
This compiler option is not available in the compilers targeting ARM processors.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > General property page.
3. Modify the Debug Information Format property. Choose OK to save your changes.
To set this compiler option programmatically
See DebugInformationFormat.
See also
MSVC compiler options
MSVC compiler command-line syntax
/Za, /Ze (Disable Language Extensions)
Article • 08/03/2021
The /Za compiler option disables and emits errors for Microsoft extensions to C that
aren't compatible with ANSI C89/ISO C90. The deprecated /Ze compiler option enables
Microsoft extensions. Microsoft extensions are enabled by default.
Syntax
/Za
/Ze
Remarks
７ Note
The use of /Za when code is compiled as C++ is not recommended. The /Ze option
is deprecated because its behavior is on by default. For a list of deprecated
compiler options, see Deprecated and removed compiler options.
The Microsoft C/C++ compiler supports compilation of C code in two ways:
The compiler uses C compilation mode by default when a source file has a .c
extension, or when the /Tc or /TC option is specified. The C compiler is an C89/C90
compiler that, by default, enables Microsoft extensions to the C language. For
more information about specific extensions, see Microsoft Extensions to C and
C++. When both C compilation and the /Za option are specified, the C compiler
conforms strictly to the C89/C90 standard. The compiler treats Microsoft extended
keywords as simple identifiers, disables the other Microsoft extensions, and
automatically defines the __STDC__ predefined macro for C programs.
The compiler can compile C code in C++ compilation mode. This behavior is the
default for source files that don't have a .c extension, and when the /Tp or /TP
option is specified. In C++ compilation mode, the compiler supports those parts of
the ISO C99 and C11 standards that have been incorporated into the C++
standard. Almost all C code is also valid C++ code. A small number of C keywords
and code constructs aren't valid C++ code, or are interpreted differently in C++.
The compiler behaves according to the C++ standard in these cases. In C++
compilation mode, the /Za option may cause unexpected behavior and isn't
recommended.
Other compiler options can affect how the compiler ensures standards conformance. For
ways to specify specific standard C and C++ behavior settings, see the /Zc compiler
option. For additional C++ standard conformance settings, see the /permissive- and
/std compiler options.
For more information about conformance issues with Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language property page.
3. Modify the Disable Language Extensions property.
To set this compiler option programmatically
See DisableLanguageExtensions.
See also
Compiler Options
/Zc (Conformance)
/permissive- (Standards conformance)
/std (Specify Language Standard Version)
Microsoft extensions to C and C++
Article • 03/22/2022
Microsoft Visual C++ (MSVC) extends the C and C++ language standards in several
ways, detailed in this article.
The MSVC C++ compiler defaults to support for ISO C++14 with some ISO C++17
features and some Microsoft-specific language extensions. For more information on
supported features, see Microsoft C/C++ language conformance by Visual Studio
version. You can use the /std compiler option to enable full support for ISO C++17 and
ISO C++20 language features. For more information, see /std (Specify language
standard version).
Where specified, some MSVC C++ language extensions can be disabled by use of the
/Za compiler option. In Visual Studio 2017 and later versions, the /permissive￾compiler option disables Microsoft-specific C++ language extensions. The /permissive￾compiler option is implicitly enabled by the /std:c++20 and /std:c++latest compiler
options.
By default, when MSVC compiles code as C, it implements ANSI C89 with Microsoft￾specific language extensions. Some of these MSVC extensions are standardized in ISO
C99 and later. Most MSVC C extensions can be disabled by use of the /Za compiler
option, as detailed later in this article. You can use the /std compiler option to enable
support for ISO C11 and C17. For more information, see /std (Specify language standard
version).
The standard C runtime library is implemented by the Universal C runtime library (UCRT)
in Windows. The UCRT also implements many POSIX and Microsoft-specific library
extensions. The UCRT supports the ISO C11 and C17 C runtime library standards, with
certain implementation-specific caveats. It doesn't support the full ISO C99 standard C
runtime library. For more information, see compatibility in the Universal C runtime
library documentation.
Keywords
MSVC adds several Microsoft-specific keywords to C and C++. In the list in Keywords,
the keywords that have two leading underscores are MSVC extensions.
Casts
Both the C++ compiler and C compiler support these kinds of non-standard casts:
The C compiler supports non-standard casts to produce l-values. For example:
C
char *p;
(( int * ) p )++;
// In C with /W4, both by default and under /Ze:
// warning C4213: nonstandard extension used: cast on l-value
// Under /TP or /Za:
// error C2105: '++' needs l-value
７ Note
This extension is available in the C language only. You can use the following C
standard form in C++ code to modify a pointer as if it's a pointer to a
different type.
The preceding example could be rewritten as follows to conform to the C standard.
C
p = ( char * )(( int * )p + 1 );
Both the C and C++ compilers support non-standard casts of a function pointer to
a data pointer. For example:
C
int ( * pfunc ) ();
int *pdata;
pdata = ( int * ) pfunc;
/* No diagnostic at any level, whether compiled with default options or
under /Za */
Variable-length argument lists
Both C and C++ compilers support a function declarator that specifies a variable
number of arguments, followed by a function definition that provides a type instead:
C++
void myfunc( int x, ... );
void myfunc( int x, char * c )
{ }
// In C with /W4, either by default or under /Ze:
// warning C4212: nonstandard extension used: function declaration used
ellipsis
// In C with /W4, under /Za:
// warning C4028: formal parameter 2 different from declaration
// In C++, no diagnostic by default or under /Za.
Single-line comments
The C compiler supports single-line comments, which are introduced by using two
forward slash ( // ) characters:
C
// This is a single-line comment.
Single-line comments are a C99 feature. They're unaffected by /Za and cause no
diagnostic at any level.
Scope
The C compiler supports the following scope-related features.
Redefinitions of extern items as static :
C
extern int clip();
static int clip() {}
// In C and C++ with /W4, either by default or under /Ze:
// warning C4211: nonstandard extension used: redefined extern to
static
// In C and C++ under /Za:
// error C2375: 'clip': redefinition; different linkage
Use of benign typedef redefinitions within the same scope:
C
typedef int INT;
typedef int INT; // No diagnostic at any level in C or C++
Function declarators have file scope:
C
Use of block-scope variables that are initialized by using non-constant expressions:
C
The C compiler supports the following data declaration and definition features.
Mixed character and string constants in an initializer:
C
void func1()
{
 extern double func2( double );
 // In C at /W4: warning C4210: nonstandard extension used:
function given file scope
}
int main( void )
{
 func2( 4 ); // /Ze passes 4 as type double
} // /Za passes 4 as type int
int clip( int );
int bar( int );
int main( void )
{
 int array[2] = { clip( 2 ), bar( 4 ) };
}
int clip( int x )
{
 return x;
}
int bar( int x )
{
 return x;
}
Data declarations and definitions
char arr[6] = {'a', 'b', "cde"};
// In C with /W4, either by default or under /Ze:
// warning C4207: nonstandard extension used: extended initializer
form
// Under /Za:
// error C2078: too many initializers
Bit fields that have base types other than unsigned int or signed int .
Declarators that don't have a type:
C
Unsized arrays as the last field in structures and unions:
C
Unnamed (anonymous) structures:
C
x;
// By default or under /Ze, /Za, /std:c11, and /std:c17, when /W4 is
specified:
// warning C4431: missing type specifier - int assumed. Note: C no
longer supports default-int
// warning C4218: nonstandard extension used: must specify at least
a storage class or a type
*/
int main( void )
{
 x = 1;
}
struct zero
{
 char *c;
 int zarray[];
 // In C with /W4, either by default, under /Ze, /std:c11, and
/std:c17:
 // warning C4200: nonstandard extension used: zero-sized array
in struct/union
 // Under /Za:
 // error C2133: 'zarray': unknown size
};
struct
{
 int i;
 char *s;
};
// By default or under /Ze, /std:c11, and /std:c17, when /W4 is
specified:
// warning C4094: untagged 'struct' declared no symbols
// Under /Za:
// error C2059: syntax error: 'empty declaration'
Unnamed (anonymous) unions:
C
Both the x86 C++ compiler and C compiler support inline generation of the atan ,
atan2 , cos , exp , log , log10 , sin , sqrt , and tan functions when /Oi is specified. These
intrinsics don't conform to the standard, because they don't set the errno variable.
Under /Ze , you have to include iso646.h if you want to use text forms of the following
operators:
Operator Text form
&& and
&= and_eq
& bitand
| bitor
~ compl
! not
!= not_eq
|| or
|= or_eq
union
{
 int i;
 float fl;
};
// By default or under /Ze, /std:c11, and /std:c17, when /W4 is
specified:
// warning C4094: untagged 'union' declared no symbols
// Under /Za:
// error C2059: syntax error: 'empty declaration'
Intrinsic floating-point functions
ISO646.H not enabled
Operator Text form
^ xor
^= xor_eq
These text forms are available as C++ keywords under /Za or when /permissive- is
specified or implied.
/Za, /Ze (Disable language extensions)
MSVC compiler options
MSVC compiler command-line syntax
See also
/Zc (Conformance)
Article • 08/30/2023
Use the /Zc compiler options to specify standard or Microsoft-specific compiler
behavior.
/Zc: option{,option ...}
You may set multiple /Zc options separated by commas in a single /Zc compiler
option. If a /Zc option is enabled and disabled in the same command, the option that
appears last is used.
When Visual Studio has implemented an extension to C or C++ that is incompatible
with the standard, you can use a /Zc conformance option to specify standard￾conforming or Microsoft-specific behavior. For some options, the Microsoft-specific
behavior is the default, to prevent large-scale breaking changes to existing code. In
other cases, the default is the standard behavior, where improvements in security,
performance, or compatibility outweigh the costs of breaking changes. The default
setting of each conformance option may change in newer versions of Visual Studio. For
more information about each conformance option, see the article for the specific option.
The /permissive- compiler option implicitly sets the conformance options that aren't set
by default to their conforming settings.
Here are the /Zc compiler options:
Option Behavior
/Zc:__cplusplus[-] Enable the __cplusplus macro to report the supported standard. Off
by default.
/Zc:__STDC__ Enable the __STDC__ macro to report the C standard is supported. Off
by default.
/Zc:alignedNew[-] Enable C++17 over-aligned dynamic allocation. Off by default unless
/std:c++17 or later is specified.
/Zc:auto[-] Enforce the new Standard C++ meaning for auto . On by default.
Syntax
Remarks
Option Behavior
/Zc:char8_t[-] Enable or disable C++20 native u8 literal support as const char8_t .
Off by default unless /std:c++20 or later is specified.
/Zc:enumTypes[-] Enable Standard C++ rules for enum type deduction. Off by default.
/Zc:externC[-] Enforce Standard C++ rules for extern "C" functions. Off by default
unless /permissive- is specified.
/Zc:externConstexpr[-] Enable external linkage for constexpr variables. Off by default.
/Zc:forScope[-] Enforce Standard C++ for scoping rules. On by default.
/Zc:gotoScope[-] Enforce Standard C++ goto rules around local variable initialization.
Off by default unless /permissive- is specified.
/Zc:hiddenFriend[-] Enforce Standard C++ hidden friend rules. Off by default unless
/permissive- is specified.
/Zc:implicitNoexcept[-] Enable implicit noexcept on required functions. On by default.
/Zc:inline[-] Remove unreferenced functions or data if they're COMDAT or have
internal linkage only. Off by default.
/Zc:lambda[-] Enable new lambda processor for conformance-mode syntactic checks
in generic lambdas. Off by default unless /std:c++20 or later is
specified.
/Zc:noexceptTypes[-] Enforce C++17 noexcept rules. Off by default unless /std:c++17 or
later is specified.
/Zc:nrvo[-] Enable optional copy and move elisions. Off by default unless /O2 ,
/permissive- , or /std:c++20 or later is specified.
/Zc:preprocessor[-] Use the new conforming preprocessor. Off by default unless /std:c11
or later is specified.
/Zc:referenceBinding[-] A UDT temporary won't bind to a nonconst lvalue reference. Off by
default unless /permissive- is specified.
/Zc:rvalueCast[-] Enforce Standard C++ explicit type conversion rules. Off by default
unless /permissive- is specified.
/Zc:sizedDealloc[-] Enable C++14 global sized deallocation functions. On by default.
/Zc:strictStrings[-] Disable string-literal to char* or wchar_t* conversion. Off by default
unless /permissive- is specified.
/Zc:static_assert[-] strict handling of static_assert . Off by default unless /permissive- is
specified.
Option Behavior
/Zc:templateScope[-] Enforce Standard C++ template parameter shadowing rules. Off by
default.
/Zc:ternary[-] Enforce conditional operator rules on operand types. Off by default
unless /permissive- is specified.
/Zc:threadSafeInit[-] Enable thread-safe local static initialization. On by default.
/Zc:throwingNew[-] Assume operator new throws on failure. Off by default.
/Zc:tlsGuards[-] Generate runtime checks for TLS variable initialization. On by default.
/Zc:trigraphs[-] Enable trigraphs (obsolete, off by default).
/Zc:twoPhase- Use nonconforming template parsing behavior (only applicable when
/permissive- is specified, which defaults to conforming).
/Zc:wchar_t[-] wchar_t is a native type, not a typedef. On by default.
/Zc:zeroSizeArrayNew[-] Call member new / delete for 0-size arrays of objects. On by default.
For more information about conformance issues in MSVC, see Nonstandard behavior.
MSVC compiler options
MSVC compiler command-line syntax
See also
/Zc:__cplusplus (Enable updated
__cplusplus macro)
Article • 08/13/2021
The /Zc:__cplusplus compiler option enables the __cplusplus preprocessor macro to
report an updated value for recent C++ language standards support. By default, Visual
Studio always returns the value 199711L for the __cplusplus preprocessor macro.
/Zc:__cplusplus [ - ]
The __cplusplus preprocessor macro is commonly used to report support for a
particular version of the C++ standard. Because a lot of existing code appears to
depend on the value of this macro matching 199711L , the compiler doesn't change the
value of the macro unless you explicitly opt in by using the /Zc:__cplusplus compiler
option. The /Zc:__cplusplus option is available starting in Visual Studio 2017 version
15.7, and is off by default. In earlier versions of Visual Studio, and by default, or if
/Zc:__cplusplus- is specified, Visual Studio returns the value 199711L for the
__cplusplus preprocessor macro. The /permissive- option doesn't enable
/Zc:__cplusplus .
When the /Zc:__cplusplus option is enabled, the value reported by the __cplusplus
macro depends on the /std version option setting. This table shows the possible values
for the macro:
/Zc:__cplusplus option /std option __cplusplus value
Zc:__cplusplus /std:c++14 (default) 201402L
Zc:__cplusplus /std:c++17 201703L
Zc:__cplusplus /std:c++20 202002L
Zc:__cplusplus /std:c++latest see text
Zc:__cplusplus- (disabled) Any value 199711L
Syntax
Remarks
/Zc:__cplusplus option /std option __cplusplus value
Not specified Any value 199711L
The compiler doesn't support standards options for C++98, C++03, or C++11. The
/std:c++20 option is available starting in Visual Studio 2019 version 16.11. The value of
__cplusplus with the /std:c++latest option depends on the version of Visual Studio.
It's always at least one higher than the highest supported __cplusplus standard value
supported by your version of Visual Studio.
For finer-grained detection of changes to the compiler toolset, use the _MSC_VER
predefined macro. The value of this built-in macro is incremented for every toolset
update in Visual Studio 2017 and later versions. The _MSVC_LANG predefined macro
reports the standard version whether the /Zc:__cplusplus option is enabled or disabled.
When /Zc:__cplusplus is enabled, __cplusplus has the same value as _MSVC_LANG .
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:__cplusplus or /Zc:__cplusplus- to the Additional options: pane.
/Zc (Conformance)
/std (Specify language standard version)
Predefined macros
To set this compiler option in Visual Studio
See also
/Zc:__STDC__ (Enable __STDC__ macro)
Article • 11/08/2022
The /Zc:__STDC__ compiler option defines the built-in __STDC__ preprocessor macro as
1 in C code.
/Zc:__STDC__
The /Zc:__STDC__ compiler option implements Standard C conforming behavior for the
__STDC__ preprocessor macro, setting it to 1 when compiling C11 and C17 code.
The /Zc:__STDC__ option is new in Visual Studio 2022 version 17.2. This option is off by
default, but can be enabled explicitly when /std:c11 or /std:c17 is specified. There's no
negative version of the option.
This option is a source breaking change. Due to the behavior of the UCRT, which doesn't
expose POSIX functions when __STDC__ is 1 , it isn't possible to define this macro for C
by default without introducing breaking changes to the stable language versions.
C
Syntax
Remarks
Example
// test__STDC__.c
#include <io.h>
#include <fcntl.h>
#include <stdio.h>
int main() {
#if __STDC__
 int f = _open("file.txt", _O_RDONLY);
 _close(f);
#else
 int f = open("file.txt", O_RDONLY);
 close(f);
#endif
}
/* Command line behavior
C:\Temp>cl /EHsc /W4 /Zc:__STDC__ test__STDC__.c && test__STDC__
*/
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:__STDC__ . Choose OK or Apply to save your
changes.
See also
/Zc (Conformance)
/std (Specify language standard version)
/Zc:alignedNew (C++17 over-aligned
allocation)
Article • 08/17/2021
Enable support for C++17 over-aligned new , dynamic memory allocation aligned on
boundaries greater than the default for the maximum-sized standard aligned type,
max_align_t .
Syntax
/Zc:alignedNew [ - ]
Remarks
The MSVC compiler and library support C++17 standard over-aligned dynamic memory
allocation. When the /Zc:alignedNew option is specified, a dynamic allocation such as
new Example; respects the alignment of Example even when it's greater than
max_align_t , the largest alignment required for any fundamental type. When the
alignment of the allocated type is no more than the alignment guaranteed by the
original operator new , available as the value of the predefined macro
__STDCPP_DEFAULT_NEW_ALIGNMENT__ , the statement new Example; results in a call to
::operator new(size_t) as it did in C++14. When the alignment is greater than
__STDCPP_DEFAULT_NEW_ALIGNMENT__ , the implementation instead obtains the memory by
using ::operator new(size_t, align_val_t) . Similarly, deletion of over-aligned types
invokes ::operator delete(void*, align_val_t) or the sized delete signature
::operator delete(void*, size_t, align_val_t) .
The /Zc:alignedNew option is only available when /std:c++17 or later is enabled. Under
/std:c++17 or later, /Zc:alignedNew is enabled by default to conform to the C++
standard. If the only reason you implement operator new and delete is to support over￾aligned allocations, you may no longer need this code in C++17 or later modes. To turn
off this option and revert to the C++14 behavior of new and delete when you use
/std::c++17 or later, specify /Zc:alignedNew- . If you implement operator new and
delete but you're not ready to implement the over-aligned operator new and delete
overloads that have the align_val_t parameter, use the /Zc:alignedNew- option to
prevent the compiler and Standard Library from generating calls to the over-aligned
overloads. The /permissive- option doesn't change the default setting of
/Zc:alignedNew .
Support for /Zc:alignedNew is available starting in Visual Studio 2017 version 15.5.
This sample shows how operator new and operator delete behave when the
/Zc:alignedNew option is set.
C++
Example
// alignedNew.cpp
// Compile by using: cl /EHsc /std:c++17 /W4 alignedNew.cpp
#include <iostream>
#include <malloc.h>
#include <new>
// "old" unaligned overloads
void* operator new(std::size_t size) {
 auto ptr = malloc(size);
 std::cout << "unaligned new(" << size << ") = " << ptr << '\n';
 return ptr ? ptr : throw std::bad_alloc{};
}
void operator delete(void* ptr, std::size_t size) {
 std::cout << "unaligned sized delete(" << ptr << ", " << size << ")\n";
 free(ptr);
}
void operator delete(void* ptr) {
 std::cout << "unaligned unsized delete(" << ptr << ")\n";
 free(ptr);
}
// "new" over-aligned overloads
void* operator new(std::size_t size, std::align_val_t align) {
 auto ptr = _aligned_malloc(size, static_cast<std::size_t>(align));
 std::cout << "aligned new(" << size << ", " <<
 static_cast<std::size_t>(align) << ") = " << ptr << '\n';
 return ptr ? ptr : throw std::bad_alloc{};
}
void operator delete(void* ptr, std::size_t size, std::align_val_t align) {
 std::cout << "aligned sized delete(" << ptr << ", " << size <<
 ", " << static_cast<std::size_t>(align) << ")\n";
 _aligned_free(ptr);
}
void operator delete(void* ptr, std::align_val_t align) {
 std::cout << "aligned unsized delete(" << ptr <<
This output is typical for 32-bit builds. The pointer values vary based on where your
application runs in memory.
Output
For information about conformance issues in Visual C++, see Nonstandard Behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:alignedNew or
/Zc:alignedNew- and then choose OK.
/Zc (Conformance)
 ", " << static_cast<std::size_t>(align) << ")\n";
 _aligned_free(ptr);
}
struct alignas(256) OverAligned {}; // warning C4324, structure is padded
int main() {
 delete new int;
 delete new OverAligned;
}
unaligned new(4) = 009FD0D0
unaligned sized delete(009FD0D0, 4)
aligned new(256, 256) = 009FE800
aligned sized delete(009FE800, 256, 256)
To set this compiler option in the Visual Studio
development environment
See also
/Zc:auto (Deduce Variable Type)
Article • 08/03/2021
The /Zc:auto compiler option tells the compiler how to use the auto keyword to declare
variables. If you specify the default option, /Zc:auto , the compiler deduces the type of
the declared variable from its initialization expression. If you specify /Zc:auto- , the
compiler allocates the variable to the automatic storage class.
Syntax
/Zc:auto [ - ]
Remarks
The C++ standard defines an original and a revised meaning for the auto keyword.
Before Visual Studio 2010, the keyword declares a variable in the automatic storage
class; that is, a variable that has a local lifetime. Starting with Visual Studio 2010, the
keyword deduces the type of a variable from the declaration's initialization expression.
Use the /Zc:auto compiler option to tell the compiler to use the revised meaning of the
auto keyword. The /Zc:auto option is on by default. The /permissive- option does not
change the default setting of /Zc:auto .
The compiler issues an appropriate diagnostic message if your use of the auto keyword
contradicts the current /Zc:auto compiler option. For more information, see auto
Keyword. For more information about conformance issues with Visual C++, see
Nonstandard Behavior.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:auto or /Zc:auto- to the Additional options: pane.
See also
/Zc (Conformance)
auto Keyword
/Zc:char8_t (Enable C++20 char8_t
type)
Article • 09/02/2021
The /Zc:char8_t compiler option enables C++20 conforming char8_t type support.
char8_t is a character type that's used to represent UTF-8 code units.
Syntax
/Zc:char8_t [ - ]
Remarks
The /Zc:char8_t compiler option enables the char8_t type keyword as specified in the
C++20 standard. It causes the compiler to generate u8 prefixed character or string
literals as const char8_t or const char8_t[N] types, respectively, instead of as const
char or const char[N] types. In C++17, arrays of char may be initialized using u8 string
literals. In C++20, this initialization is ill-formed, and causes compiler error C2440. This
behavior can be a source-breaking change. You can revert the compiler to C++14 or
C++17 behavior explicitly by specifying /Zc:char8_t- .
The /Zc:char8_t option is available starting in Visual Studio 2019 version 16.1. It's
enabled automatically when you specify /std:c++20 or later (such as /std:c++latest ).
Otherwise, it's off by default.
Example
C++
const char* s = u8"Hello"; // Compiles in C++17, Error C2440 in C++20
const char8_t* s = u8"Hello"; // Compiles in C++20 or with /Zc:char8_t
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:char8_t or /Zc:char8_t- to the Additional options: pane.
See also
/Zc (Conformance)
/std (Specify language standard version)
/Zc:checkGwOdr (Enforce Standard C++
ODR violations under /Gw )
Article • 09/04/2023
This switch enforces C++ standards conformance when using /Gw (Optimize global
data). When using /Gw , certain One Definition Rule (ODR) violations are ignored. This
flag ensures that the appropriate errors are raised.
Syntax
/Zc:checkGwOdr [ - ]
Remarks
This switch is off by default.
To see an example of ODR violations that are ignored when using /Gw , see Standards
conformance improvements to /Gw .
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:checkGwOdr or
/Zc:checkGwOdr- and then choose OK.
See also
/Zc (Conformance)
One Definition Rule (ODR)
Standards conformance improvements to /Gw
/Zc:enumTypes (Enable enum type
deduction)
Article • 11/08/2022
The /Zc:enumTypes compiler option enables C++ conforming enum underlying type and
enumerator type deduction.
Syntax
/Zc:enumTypes [ - ]
Remarks
The /Zc:enumTypes compiler option implements Standard C++ conforming behavior for
deduction of enumeration base types and the types of enumerators.
The /Zc:enumTypes option is new in Visual Studio 2022 version 17.4. This option is off by
default, and isn't enabled by /permissive- . To explicitly disable the option, use
/Zc:enumTypes- .
When enabled, the /Zc:enumTypes option is a potential source and binary breaking
change. Some enumeration types change size when the conforming /Zc:enumTypes
option is enabled. Certain Windows SDK headers include such enumeration definitions.
The C++ Standard requires that the underlying type of an enumeration is large enough
to hold all enumerators declared in it. Sufficiently large enumerators can set the
underlying type of the enum to unsigned int , long long , or unsigned long long .
Previously, such enumeration types always had an underlying type of int in the
Microsoft compiler, regardless of enumerator values.
The C++ Standard also specifies that, within an enumeration definition that has no fixed
underlying type, the types of enumerators are determined by their initializers. Or, for the
enumerators with no initializer, by the type of the previous enumerator (accounting for
overflow). Previously, such enumerators were always given the deduced type of the
enumeration, with a placeholder for the underlying type (typically int ).
In versions of Visual Studio before Visual Studio 2022 version 17.4, the C++ compiler
didn't correctly determine the underlying type of an unscoped enumeration with no
fixed base type. The compiler also didn't correctly model the types of enumerators. It
could assume an incorrect type in enumerations without a fixed underlying type before
the closing brace of the enumeration. Under /Zc:enumTypes , the compiler correctly
implements the standard behavior.
C++
C++
Example: Underlying type of unscoped enum with no fixed
type
enum Unsigned
{
 A = 0xFFFFFFFF // Value 'A' does not fit in 'int'.
};
// Previously, this static_assert failed. It passes with /Zc:enumTypes.
static_assert(std::is_same_v<std::underlying_type_t<Unsigned>, unsigned
int>);
template <typename T>
void f(T x)
{
}
int main()
{
 // Previously called f<int>, now calls f<unsigned int>.
 f(+A);
}
// Previously, this enum would have an underlying type of `int`,
// but Standard C++ requires this to have a 64-bit underlying type.
// The /Zc:enumTypes option changes the size of this enum from 4 to 8,
// which could impact binary compatibility with code compiled with an
// earlier compiler version, or without the switch.
enum Changed
{
 X = -1,
 Y = 0xFFFFFFFF
};
Example: Enumerators within an enum definition with no
fixed underlying type
enum Enum {
 A = 'A',
 B = sizeof(A)
};
static_assert(B == 1); // previously failed, now succeeds under
/Zc:enumTypes
In this example the enumerator A should have type char prior to the closing brace of
the enumeration, so B should be initialized using sizeof(char) . Before the
/Zc:enumTypes fix, A had enumeration type Enum with a deduced underlying type int ,
and B was initialized using sizeof(Enum) , or 4.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:enumTypes or /Zc:enumTypes- . Choose OK or Apply
to save your changes.
See also
/Zc (Conformance)
/std (Specify language standard version)
/Zc:externC (Use Standard C++ extern
"C" rules)
Article • 12/03/2021
The /Zc:externC compiler option tells the compiler to conform to the C++ standard and
enforce consistent parameter declarations for functions declared as extern "C" .
Syntax
/Zc:externC
/Zc:externC￾Remarks
The /Zc:externC compiler option checks the definitions of functions declared by using
extern "C" .
The /Zc:externC option is available starting in Visual Studio 2019 version 16.3. It's off
when the /permissive- option isn't set. In earlier versions of Visual Studio, and by default
or if /Zc:externC- is specified, Visual Studio is permissive about matching declarations
of extern "C" functions. The /permissive- option enables /Zc:externC , so it's on by
default in projects that use /std:c++20 or /std:c++latest . The /Zc:externC option must
come after a /permissive- option on the command line.
Mismatched extern "C" declarations can cause compiler errors C2116 and C2733. In
C++ code, an error can occur if you declare an extern "C" function more than once and
use different parameter types, even if the types have the same definitions. The
/Zc:externC- option relaxes this check, and doesn't produce these errors.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:externC or /Zc:externC- to the Additional options: pane.
See also
/Zc (Conformance)
/Zc:externConstexpr (Enable extern
constexpr variables)
Article • 10/13/2023
The /Zc:externConstexpr compiler option tells the compiler to conform to the C++
standard and allow external linkage for constexpr variables. By default, Visual Studio
always gives a constexpr variable internal linkage, even if you specify the extern
keyword.
Syntax
/Zc:externConstexpr [ - ]
Remarks
The /Zc:externConstexpr compiler option causes the compiler to apply external linkage
to variables declared by using extern constexpr .
In earlier versions of Visual Studio, by default or if /Zc:externConstexpr- is specified,
Visual Studio applies internal linkage to constexpr variables even if the extern keyword
is used. The /Zc:externConstexpr option is available starting in Visual Studio 2017
Update 15.6. and is off by default.
As of Visual Studio 2022 Update 17.6, the /permissive- option enables both
/Zc:externConstexpr and /Zc:lambda. In prior versions, /permissive- didn't enable
either one.
If a header file contains a variable declared extern constexpr , it must be marked
__declspec(selectany) in order to merge the duplicate declarations into a single instance
in the linked binary. Otherwise you may see linker errors, for example, LNK2005, for
violations of the one-definition rule.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:externConstexpr or /Zc:externConstexpr- to the Additional options:
pane.
See also
auto Keyword
permissive
/Zc (Conformance)
/Zc:forScope (Force Conformance in for
Loop Scope)
Article • 08/03/2021
Used to implement standard C++ behavior for for loops with Microsoft extensions (/Ze).
/Zc:forScope[-]
Standard behavior is to let a for loop's initializer go out of scope after the for loop.
Under /Zc:forScope- and /Ze, the for loop's initializer remains in scope until the local
scope ends.
The /Zc:forScope option is on by default. /Zc:forScope is not affected when the
/permissive- option is specified.
The /Zc:forScope- option is deprecated and will be removed in a future release. Use of
/Zc:forScope- generates deprecation warning D9035.
The following code compiles under /Ze but not under /Za:
C++
If you use /Zc:forScope-, warning C4288 (off by default) is generated if a variable is in
scope because of a declaration that was made in a previous scope. To demonstrate this,
remove the // characters in the example code to declare int i .
Syntax
Remarks
// zc_forScope.cpp
// compile by using: cl /Zc:forScope- /Za zc_forScope.cpp
// C2065, D9035 expected
int main() {
 // Compile by using cl /Zc:forScope- zc_forScope.cpp
 // to compile this non-standard code as-is.
 // Uncomment the following line to resolve C2065 for /Za.
 // int i;
 for (int i = 0; i < 1; i++)
 ;
 i = 20; // i has already gone out of scope under /Za
}
You can modify the run-time behavior of /Zc:forScope by using the conform pragma.
If you use /Zc:forScope- in a project that has an existing .pch file, a warning is
generated, /Zc:forScope- is ignored, and compilation continues by using the existing
.pch files. If you want a new .pch file generated, use /Yc (Create Precompiled Header
File).
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language property page.
3. Modify the Force Conformance in For Loop Scope property.
To set this compiler option programmatically
See ForceConformanceInForLoopScope.
See also
/Zc (Conformance)
/Za, /Ze (Disable Language Extensions)
/Zc:gotoScope (Enforce conformance in
goto scope)
Article • 11/15/2022
The /Zc:gotoScope compiler option enables checks for Standard C++ behavior around
goto statements that jump over the initialization of local variables.
Syntax
/Zc:gotoScope [ - ]
Remarks
The /Zc:gotoScope compiler option enforces C++ Standard behavior around goto
statements that jump over the initialization of one or more local variables. The compiler
emits error C2362 in all such cases when /Zc:gotoScope is specified. The /Zc:gotoScope￾relaxes this check, but the compiler still emits an error if a goto skips initialization of a
local variable that has a non-trivial destructor.
The intent of the /Zc:gotoScope- option is to help ease the migration of older code
bases to more conformant code. You may use it to suppress certain errors until you've
updated the non-conforming code.
The /Zc:gotoScope compiler option is new in Visual Studio 2022 version 17.4. The option
is off by default. It's enabled automatically by the /permissive- option (or an option
that implies /permissive- , such as /std:c++20 or /std:c++latest ). To enable the error
check explicitly, add /Zc:gotoScope to the compiler command line. To explicitly disable
the check, use the /Zc:gotoScope- option. The /Zc:gotoScope- must appear after the
/permissive- option or any option that implies /permissive- .
Example
This sample generates an error message when compiled using /Zc:gotoScope :
C++
int g(int*);
bool failed(int);
If the code is compiled with /Zc:gotoScope- , the compiler doesn't emit the error.
Even when /Zc:gotoScope- is specified, the compiler still emits an error if the local
variable has a non-trivial destructor. For example:
C++
int f() {
 int v1;
 auto result = g(&v1);
 if (failed(result))
 goto OnError;
 int v2 = v1 + 2;
 return v2;
OnError:
 return -1;
}
/* Output:
t.cpp(9): error C2362: initialization of 'v2' is skipped by 'goto OnError'
*/
int g(int*);
bool failed(int);
class S {
public:
 S(int);
 ~S();
 int mf() const;
};
int f()
{
 int v1;
 auto result = g(&v1);
 if (failed(result))
 goto OnError;
 S s(v1);
 return s.mf();
OnError:
 return -1;
}
/* Output:
t.cpp(17): error C2362: initialization of 's' is skipped by 'goto OnError'
*/
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:gotoScope or /Zc:gotoScope- . Choose OK or Apply
to save your changes.
See also
/Zc (Conformance)
/permissive-
/std (Specify language standard version)
/Zc:hiddenFriend (Enforce Standard
C++ hidden friend rules)
Article • 08/03/2021
Specifies the compiler conforms to the C++ standard treatment of hidden friend
functions or function templates.
Syntax
/Zc:hiddenFriend [ - ]
Remarks
The /Zc:hiddenFriend option enables a subset of the /permissive- option behavior. It
tells the compiler to conform to the standard for hidden friends. The compiler only
includes hidden friends in argument-dependent lookup (ADL) for explicit instances or
template parameters of the enclosing class type. The restriction allows you to use
hidden friends to keep operations on a type from applying to implicit conversions. This
option can improve build speed in code that can't otherwise use /permissive-.
A hidden friend is a friend function or function template declared only within a class or
class template definition. By default, the Microsoft C++ compiler doesn't remove hidden
friend declarations as candidates for overload resolution everywhere it should. This
legacy behavior can slow the compiler down by including the hidden friend functions as
possible candidates in more contexts.
Standard C++ hidden friend behavior is enabled by default under /permissive- . To
specify legacy hidden friend behavior when the /permissive- option is specified, use
/Zc:hiddenFriend- . Use of C++20 Modules requires standard hidden friend behavior.
The /Zc:hiddenFriend option is available starting in Visual Studio 2019 version 16.4.
For examples of compiler behavior when you specify /Zc:hiddenFriend , see Hidden
friend name lookup rules.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:hiddenFriend or
/Zc:hiddenFriend- and then choose OK.
See also
/Zc (Conformance)
/permissive-
/Zc:implicitNoexcept (Implicit Exception
Specifiers)
Article • 08/03/2021
When the /Zc:implicitNoexcept option is specified, the compiler adds an implicit
noexcept exception specifier to compiler-defined special member functions and to user￾defined destructors and deallocators. By default, /Zc:implicitNoexcept is enabled to
conform to the ISO C++11 standard. Turning this option off disables implicit noexcept
on user-defined destructors and dealloacators and compiler-defined special member
functions.
Syntax
/Zc:implicitNoexcept[-]
Remarks
/Zc:implicitNoexcept tells the compiler to follow section 15.4 of the ISO C++11
standard. It implicitly adds a noexcept exception specifier to each implicitly-declared or
explicitly defaulted special member function—the default constructor, copy constructor,
move constructor, destructor, copy assignment operator, or move assignment operator
—and each user-defined destructor or deallocator function. A user-defined deallocator
has an implicit noexcept(true) exception specifier. For user-defined destructors, the
implicit exception specifier is noexcept(true) unless a contained member class or base
class has a destructor that is not noexcept(true) . For compiler-generated special
member functions, if any function directly invoked by this function is effectively
noexcept(false) , the implicit exception specifier is noexcept(false) . Otherwise, the
implicit exception specifier is noexcept(true) .
The compiler does not generate an implicit exception specifier for functions declared by
using explicit noexcept or throw specifiers or a __declspec(nothrow) attribute.
By default, /Zc:implicitNoexcept is enabled. The /permissive- option does not affect
/Zc:implicitNoexcept.
If the option is disabled by specifying /Zc:implicitNoexcept-, no implicit exception
specifiers are generated by the compiler. This behavior is the same as Visual Studio
2013, where destructors and deallocators that did not have exception specifiers could
have throw statements. By default, and when /Zc:implicitNoexcept is specified, if a
throw statement is encountered at run time in a function with an implicit
noexcept(true) specifier, it causes an immediate invocation of std::terminate , and
normal unwinding behavior for exception handlers is not guaranteed. To help identify
this situation, the compiler generates Compiler Warning (level 1) C4297. If the throw is
intentional, we recommend you change your function declaration to have an explicit
noexcept(false) specifier instead of using /Zc:implicitNoexcept-.
This sample shows how a user-defined destructor that has no explicit exception specifier
behaves when the /Zc:implicitNoexcept option is set or disabled. To show the behavior
when set, compile by using cl /EHsc /W4 implicitNoexcept.cpp . To show the behavior
when disabled, compile by using cl /EHsc /W4 /Zc:implicitNoexcept￾implicitNoexcept.cpp .
C++
// implicitNoexcept.cpp
// Compile by using: cl /EHsc /W4 implicitNoexcept.cpp
// Compile by using: cl /EHsc /W4 /Zc:implicitNoexcept- implicitNoexcept.cpp
#include <iostream>
#include <cstdlib> // for std::exit, EXIT_FAILURE, EXIT_SUCCESS
#include <exception> // for std::set_terminate
void my_terminate()
{
 std::cout << "Unexpected throw caused std::terminate" << std::endl;
 std::cout << "Exit returning EXIT_FAILURE" << std::endl;
 std::exit(EXIT_FAILURE);
}
struct A {
 // Explicit noexcept overrides implicit exception specification
 ~A() noexcept(false) {
 throw 1;
 }
};
struct B : public A {
 // Compiler-generated ~B() definition inherits noexcept(false)
 ~B() = default;
};
struct C {
 // By default, the compiler generates an implicit noexcept(true)
 // specifier for this user-defined destructor. To enable it to
 // throw an exception, use an explicit noexcept(false) specifier,
 // or compile by using /Zc:implicitNoexcept-
 ~C() {
When compiled by using the default setting /Zc:implicitNoexcept, the sample generates
this output:
Output
When compiled by using the setting /Zc:implicitNoexcept-, the sample generates this
output:
 throw 1; // C4297, calls std::terminate() at run time
 }
};
struct D : public C {
 // This destructor gets the implicit specifier of its base.
 ~D() = default;
};
int main()
{
 std::set_terminate(my_terminate);
 try
 {
 {
 B b;
 }
 }
 catch (...)
 {
 // exception should reach here in all cases
 std::cout << "~B Exception caught" << std::endl;
 }
 try
 {
 {
 D d;
 }
 }
 catch (...)
 {
 // exception should not reach here if /Zc:implicitNoexcept
 std::cout << "~D Exception caught" << std::endl;
 }
 std::cout << "Exit returning EXIT_SUCCESS" << std::endl;
 return EXIT_SUCCESS;
}
~B Exception caught
Unexpected throw caused std::terminate
Exit returning EXIT_FAILURE
Output
~B Exception caught
~D Exception caught
Exit returning EXIT_SUCCESS
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:implicitNoexcept or
/Zc:implicitNoexcept- and then choose OK.
See also
/Zc (Conformance)
noexcept
Exception Specifications (throw)
terminate
/Zc:inline (Remove unreferenced
COMDAT)
Article • 06/30/2022
Removes unreferenced data or functions that are COMDATs, or that only have internal
linkage. Under /Zc:inline , the compiler specifies that translation units with inline data
or functions must also include their definitions.
Syntax
/Zc:inline [ - ]
Remarks
When /Zc:inline is specified, the compiler doesn't emit symbol information for
unreferenced COMDAT functions or data. Or, for data or functions that have internal
linkage only. This optimization simplifies some of the work the linker does in release
builds, or when you specify the /OPT:REF linker option. This compiler optimization can
significantly reduce .obj file size and improve linker speeds. The compiler option isn't
enabled when you disable optimizations (/Od). Or, when you specify /GL (Whole
Program Optimization).
By default, this option is off ( /Zc:inline- ) in command-line builds. The /permissive￾option doesn't enable /Zc:inline . In MSBuild projects, the option is set by the
Configuration Properties > C/C++ > Language > Remove unreferenced code and
data property, which is set to Yes by default.
If /Zc:inline is specified, the compiler enforces the C++11 requirement that all
functions declared inline must have a definition available in the same translation unit if
they're used. When the option isn't specified, the Microsoft compiler allows non￾conformant code that invokes functions declared inline even if no definition is visible.
For more information, see the C++11 standard, in section 3.2 and section 7.1.2. This
compiler option was introduced in Visual Studio 2013 Update 2.
To use the /Zc:inline option, update non-conforming code.
This example shows how the non-conforming use of an inline function declaration
without a definition still compiles and links when the default /Zc:inline- option is used:
Source file example.h :
C++
Source file example.cpp :
C++
Source file zcinline.cpp :
C++
When /Zc:inline is enabled, the same code causes a LNK2019 error, because the
compiler doesn't emit a non-inlined code body for Example::inline_call in
// example.h
// Compile by using: cl /W4 /EHsc /O2 zcinline.cpp example.cpp
#pragma once
class Example {
public:
 inline void inline_call(); // declared but not defined inline
 void normal_call();
 Example() {};
};
// example.cpp
// Compile by using: cl /W4 /EHsc /O2 zcinline.cpp example.cpp
#include <stdio.h>
#include "example.h"
void Example::inline_call() {
 printf("inline_call was called.\n");
}
void Example::normal_call() {
 printf("normal_call was called.\n");
 inline_call(); // with /Zc:inline-, inline_call forced into .obj file
}
// zcinline.cpp
// Compile by using: cl /W4 /EHsc /O2 zcinline.cpp example.cpp
#include "example.h"
int main() {
 Example example;
 example.inline_call(); // normal call when definition unavailable
}
example.obj . The missing code causes the non-inlined call in main to reference an
undefined external symbol.
To resolve this error, you can remove the inline keyword from the declaration of
Example::inline_call , or move the definition of Example::inline_call into the header
file, or move the implementation of Example into main.cpp . The next example moves the
definition into the header file, where it's visible to any caller that includes the header.
Source file example2.h :
C++
Source file example2.cpp :
C++
Source file zcinline2.h :
C++
// example2.h
// Compile by using: cl /W4 /EHsc /O2 zcinline2.cpp example2.cpp
#pragma once
#include <stdio.h>
class Example2 {
public:
 inline void inline_call() {
 printf("inline_call was called.\n");
 }
 void normal_call();
 Example2() {};
};
// example2.cpp
// Compile by using: cl /W4 /EHsc /O2 zcinline2.cpp example2.cpp
#include "example2.h"
void Example2::normal_call() {
 printf("normal_call was called.\n");
 inline_call();
}
// zcinline2.cpp
// Compile by using: cl /W4 /EHsc /O2 zcinline2.cpp example2.cpp
#include "example2.h"
int main() {
 Example2 example2;
 example2.inline_call(); // normal call when definition unavailable
}
For more information about conformance issues in Visual C++, see Nonstandard
behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language property page.
3. Modify the Remove unreferenced code and data property, and then choose OK.
See also
/Zc (Conformance)
/Zc:lambda (Enable updated lambda
processor)
Article • 02/19/2025
The /Zc:lambda compiler option enables conforming lambda grammar and processing
support.
/Zc:lambda [ - ]
The /Zc:lambda compiler option enables the conforming lambda processor. It parses
and implements lambda code according to the C++ standard. This option is off by
default, which uses the legacy lambda processor. Use this option to enable
conformance-mode syntax checks of generic lambdas when you use the default
/std:c++14 or the /std:c++17 compiler options.
/Zc:lambda is automatically enabled by the /std:c++20, /std:c++latest, /permissive-, and
/experimental:module options. You can disable it explicitly by using /Zc:lambda- .
The /Zc:lambda option is available starting in Visual Studio 2019 version 16.8. It's
available as /experimental:newLambdaProcessor starting in Visual Studio 2019 version
16.3, but this spelling is now deprecated.
The legacy lambda processor has limitations when it parses and compiles lambdas. For
example, this conforming code compiles correctly under /Zc:lambda , but reports errors
under /Zc:lambda- :
C++
Syntax
Remarks
void f1()
{
 constexpr auto c_value = 1;
 auto func = []()
 {
 return c_value; // error C3493: 'c_value' cannot be implicitly
captured
 // because no default capture mode has been
specified
Feedback
The legacy lambda processor compiles this code without warnings, but the new lambda
processor produces error C2760:
C++
This example shows the correct syntax, now enforced by the compiler under /Zc:lambda :
C++
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:lambda or /Zc:lambda- to the Additional options: pane.
/Zc (Conformance)
/std (Specify language standard version)
 };
 func(); // error C2064: term does not evaluate to a function taking 0
arguments
}
void f2() {
 auto a = [](auto arg) {
 decltype(arg)::Type t; // C2760 syntax error: unexpected token
'identifier', expected ';'
 };
}
void f3() {
 auto a = [](auto arg) {
 typename decltype(arg)::Type t;
 };
}
To set this compiler option in Visual Studio
See also
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
/Zc:noexceptTypes (C++17 noexcept
rules)
Article • 08/17/2021
The C++17 standard makes throw() an alias for noexcept , removes throw( type-list )
and throw(...) , and allows certain types to include noexcept . This change can cause a
number of source compatibility issues in code that conforms to C++14 or earlier. The
/Zc:noexceptTypes option specifies conformance to the C++17 standard.
/Zc:noexceptTypes- allows the C++14 and earlier behavior when code is compiled in
C++17 mode.
Syntax
/Zc:noexceptTypes [ - ]
Remarks
When the /Zc:noexceptTypes option is specified, the compiler conforms to the C++17
standard and treats throw() as an alias for noexcept, removes throw( type-list ) and
throw(...) , and allows certain types to include noexcept . The /Zc:noexceptTypes option
is only available when /std:c++17 or later is enabled. /Zc:noexceptTypes is enabled by
default to conform to the ISO C++17 and later standards. The /permissive- option
doesn't affect /Zc:noexceptTypes . Turn off this option by specifying /Zc:noexceptTypes￾to revert to the C++14 behavior of noexcept when /std:c++17 or later is specified.
Beginning in Visual Studio 2017 version 15.5, the C++ compiler diagnoses more
mismatched exception specifications in declarations in C++17 mode, or when you
specify the /permissive- option.
This sample shows how declarations with an exception specifier behave when the
/Zc:noexceptTypes option is set or disabled. To show the behavior when set, compile by
using cl /EHsc /W4 noexceptTypes.cpp . To show the behavior when disabled, compile by
using cl /EHsc /W4 /Zc:noexceptTypes- noexceptTypes.cpp .
C++
// noexceptTypes.cpp
// Compile by using: cl /EHsc /W4 noexceptTypes.cpp
// Compile by using: cl /EHsc /W4 /Zc:noexceptTypes- noexceptTypes.cpp
When compiled by using the default setting /Zc:noexceptTypes , the sample generates
the listed warnings. To update your code, use the following instead:
C++
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:noexceptTypes or
/Zc:noexceptTypes- and then choose OK.
void f() throw(); // equivalent to void f() noexcept;
void f() { } // warning C5043
void g() throw(...); // warning C5040
struct A
{
 virtual void f() throw();
};
struct B : A
{
 virtual void f() { } // error C2694
};
void f() noexcept;
void f() noexcept { }
void g() noexcept(false);
struct A
{
 virtual void f() noexcept;
};
struct B : A
{
 virtual void f() noexcept { }
};
To set this compiler option in the Visual Studio
development environment
See also
/Zc (Conformance)
noexcept
Exception specifications (throw)
/Zc:nrvo (Control optional NRVO)
Article • 11/15/2022
The /Zc:nrvo compiler option controls Standard C++ optional named return value
optimization (NRVO) copy or move elision behavior.
Syntax
/Zc:nrvo [ - ]
Remarks
In Visual Studio 2022 version 17.4 and later, you can explicitly enable optional copy or
move elision behavior by using the /Zc:nrvo compiler option. This option is off by
default, but is set automatically when you compile using the /O2 option, the
/permissive- option, or /std:c++20 or later. Under /Zc:nrvo , copy and move elision is
performed wherever possible. Optional copy or move elision can also be explicitly
disabled by using the /Zc:nrvo- option. These compiler options only control optional
copy or move elision. Mandatory copy or move elision (specified by the C++ Standard)
can't be disabled.
Mandatory copy and move elision
The C++ standard requires copy or move elision when the returned value is initialized as
part of the return statement. For example, it's required when a function returns an
ExampleType returned by using return ExampleType(); . The MSVC compiler always
performs copy and move elision for return statements when it's required, even under
/Zc:nrvo- .
Optional copy and move elision
When a return statement contains an expression of non-primitive type, its execution
copies the expression result into the return slot of the calling function. The compiler
invokes the copy or move constructor of the returned type. Then, as the function is
exited, destructors for function-local variables are called, which includes any variables
named in the expression.
The C++ standard allows (but doesn't require) the compiler to optionally construct the
returned object directly in the return slot of the calling function. This construction skips
(or elides) the copy or move constructor executed as part of the return statement.
Unlike most other optimizations, this transformation is allowed to have an observable
effect on the program's output. Namely, the copy or move constructor and associated
destructor are called one less time. The standard still requires that the named returned
variable has a defined copy or move constructor, even if the compiler elides the
constructor in all cases.
In versions before Visual Studio 2022 version 17.4, when optimizations are disabled
(such as under /Od or in functions marked #pragma optimize("", off) ) the compiler
only performs mandatory copy and move elision. Under /O2 , the older compilers
perform optional copy or move elision on return of a named variable in an optimized
function when all of these conditions are met: it has no loops or exception handling, it
doesn't return multiple symbols with overlapping lifetimes, the type's copy or move
constructor doesn't have default arguments.
Visual Studio 2022 version 17.4 increases the number of places where the compiler does
optional copy or move elisions under /Zc:nrvo , whether enabled explicitly, or
automatically by using the /O2 , /permissive- , or /std:c++20 or later options. Under
/Zc:nrvo , the compiler performs optional copy or move elision on return of a named
variable for any function when: it has no loops or exception handling (as before); it
returns the variable from a loop; it has exception handling; the returned type's copy or
move constructor has default arguments. Optional copy or move elisions are never done
when /Zc:nrvo- is applied, or when the function returns multiple symbols with
overlapping lifetimes, or for a throw of a named variable.
For more information and examples of mandatory and optional copy elision under
/Zc:nrvo , see Improving Copy and Move Elision in the C++ Team Blog.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:nrvo or /Zc:nrvo- . Choose OK or Apply to save
your changes.
See also
/Zc (Conformance)
/O2
/permissive-
/std (Specify language standard version)
/Zc:preprocessor (Enable preprocessor
conformance mode)
Article • 02/18/2022
This option enables a token-based preprocessor that conforms to C99 and C++11 and
later standards. For more information, see MSVC new preprocessor overview.
Syntax
/Zc:preprocessor [ - ]
Remarks
Use the /Zc:preprocessor compiler option to enable the conforming preprocessor. You
can use /Zc:preprocessor- option to explicitly specify the traditional (non-conforming)
preprocessor.
The /Zc:preprocessor option is available starting in Visual Studio 2019 version 16.5. An
earlier, incomplete version of the new preprocessor option is available in versions of
Visual Studio starting in Visual Studio 2017 version 15.8. For more information, see
/experimental:preprocessor.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Preprocessor property page.
3. Modify the Use Standard Conforming Preprocessor property and then choose OK.
See also
/Zc (Conformance)
/Zc:referenceBinding (Enforce reference
binding rules)
Article • 08/03/2021
When the /Zc:referenceBinding option is specified, the compiler doesn't allow a non￾const lvalue reference to bind to a temporary.
/Zc:referenceBinding[-]
If /Zc:referenceBinding is specified, the compiler follows section 8.5.3 of the C++11
standard: It doesn't allow expressions that bind a user-defined type temporary to a non￾const lvalue reference. By default, or if /Zc:referenceBinding- is specified, the compiler
allows such expressions as a Microsoft extension, but a level 4 warning is issued. For
code security, portability and conformance, we recommend you use
/Zc:referenceBinding.
The /Zc:referenceBinding option is off by default. The /permissive- compiler option
implicitly sets this option, but it can be overridden by using /Zc:referenceBinding-.
This sample shows the Microsoft extension that allows a temporary of a user-defined
type to be bound to a non-const lvalue reference.
C++
Syntax
Remarks
Example
// zcreferencebinding.cpp
struct S {
};
void f(S&) {
}
S g() {
 return S{};
}
int main() {
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:referenceBinding and then
choose OK.
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zc (Conformance)
 S& s = g(); // warning C4239 at /W4
 const S& cs = g(); // okay, bound to const ref
 f(g()); // Extension: error C2664 only if
/Zc:referenceBinding
}
To set this compiler option in the Visual Studio
development environment
See also
/Zc:rvalueCast (Enforce type conversion
rules)
Article • 08/03/2021
When the /Zc:rvalueCast option is specified, the compiler correctly identifies an rvalue
reference type as the result of a cast operation. Its behavior conforms to the C++11
standard. When the option is unspecified, the compiler behavior is the same as in Visual
Studio 2012.
Syntax
/Zc:rvalueCast
/Zc:rvalueCast￾Remarks
If /Zc:rvalueCast is specified, the compiler follows section 5.4 of the C++11 standard
and treats only cast expressions that result in non-reference types and cast expressions
that result in rvalue references to non-function types as rvalue types. By default, or if
/Zc:rvalueCast- is specified, the compiler is non-conforming, and treats all cast
expressions that result in rvalue references as rvalues. For conformance, and to eliminate
errors in the use of casts, we recommend that you use /Zc:rvalueCast .
By default, /Zc:rvalueCast is off ( /Zc:rvalueCast- ). The /permissive- compiler option
implicitly sets this option, but it can be overridden by using /Zc:rvalueCast- .
Use /Zc:rvalueCast if you pass a cast expression as an argument to a function that
takes an rvalue reference type. The default behavior causes compiler error C2664 when
the compiler incorrectly determines the type of the cast expression. This example shows
a compiler error in correct code when /Zc:rvalueCast isn't specified:
C++
// Test of /Zc:rvalueCast
// compile by using:
// cl /c /Zc:rvalueCast- make_thing.cpp
// cl /c /Zc:rvalueCast make_thing.cpp
#include <utility>
The default compiler behavior may not report error C2102 when appropriate. In this
example, the compiler doesn't report an error if the address of an rvalue created by an
identity cast is taken when /Zc:rvalueCast is unspecified:
C++
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
template <typename T>
struct Thing {
 // Construct a Thing by using two rvalue reference parameters
 Thing(T&& t1, T&& t2)
 : thing1(t1), thing2(t2) {}
 T& thing1;
 T& thing2;
};
// Create a Thing, using move semantics if possible
template <typename T>
Thing<T> make_thing(T&& t1, T&& t2)
{
 return (Thing<T>(std::forward<T>(t1), std::forward<T>(t2)));
}
struct Test1 {
 long a;
 long b;
 Thing<long> test() {
 // Use identity casts to create rvalues as arguments
 return make_thing(static_cast<long>(a), static_cast<long>(b));
 }
};
int main() {
 int a = 1;
 int *p = &a; // Okay, take address of lvalue
 // Identity cast creates rvalue from lvalue;
 p = &(int)a; // problem: should cause C2102: '&' requires l-value
}
To set this compiler option in the Visual Studio
development environment
2. Select the Configuration Properties > C/C++ > Language property page.
3. Set the Enforce type conversion rules property to /Zc:rvalueCast or
/Zc:rvalueCast- . Choose OK or Apply to save your changes.
See also
/Zc (Conformance)
/Zc:sizedDealloc (Enable Global Sized
Deallocation Functions)
Article • 08/03/2021
The /Zc:sizedDealloc compiler option tells the compiler to preferentially call global
operator delete or operator delete[] functions that have a second parameter of type
size_t when the size of the object is available. These functions may use the size_t
parameter to optimize deallocator performance.
Syntax
/Zc:sizedDealloc[-]
Remarks
In the C++11 standard, you may define static member functions operator delete and
operator delete[] that take a second, size_t parameter. Typically these are used in
combination with operator new functions to implement more efficient allocators and
deallocators for the object. However, C++11 did not define an equivalent set of
deallocation functions at global scope. In C++11, global deallocation functions that
have a second parameter of type size_t are considered placement delete functions.
They must be explicitly called by passing a size argument.
The C++14 standard changes the behavior of the compiler. When you define global
operator delete and operator delete[] that take a second parameter of type size_t ,
the compiler prefers to call these functions when member scope versions are not
invoked and the size of the object is available. The compiler passes the size argument
implicitly. The single argument versions are called when the compiler can't determine
the size of the object being deallocated. Otherwise, the usual rules for choosing the
version of the deallocation function to invoke still apply. Calls to the global functions
may be explicitly specified by prepending the scope resolution operator ( :: ) to the
deallocation function call.
By default, Visual C++ starting in Visual Studio 2015 implements this C++14 standard
behavior. You may explicitly specify this by setting the /Zc:sizedDealloc compiler option.
This represents a potentially breaking change. Use the /Zc:sizedDealloc- option to
preserve the old behavior, for example, when your code defines placement delete
operators that use a second parameter of type size_t . The default Visual Studio library
implementations of the global deallocation functions that have the second parameter of
type size_t invoke the single parameter versions. If your code supplies only single￾parameter global operator delete and operator delete[], the default library
implementations of the global sized deallocation functions invoke your global functions.
The /Zc:sizedDealloc compiler option is on by default. The /permissive- option does not
affect /Zc:sizedDealloc.
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. From the Configurations drop down menu, choose All Configurations.
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional Options property to include /Zc:sizedDealloc or
/Zc:sizedDealloc- and then choose OK.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zc (Conformance)
/Zc:static_assert (Strict static_assert
handling)
Article • 01/17/2025
The /Zc:static_assert compiler option tells the compiler to evaluate static_assert
calls with non-dependent test expressions when class or function templates are parsed.
Syntax
/Zc:static_assert
/Zc:static_assert￾Remarks
Starting with Visual Studio 17.10, /Zc:static_assert and /Zc:static_assert- have no
effect. Both options are ignored to avoid breaking builds that use them. static_assert
is now never evaluated when parsing class or function templates.
The /Zc:static_assert compiler option tells the compiler to evaluate a static_assert
in the body of a function template or in the body of a class template member function
when first parsed, if the test expression isn't dependent. If the non-dependent test
expression is false , the compiler emits an error immediately. When the test expression
is dependent, the static_assert isn't evaluated until the template is instantiated.
The /Zc:static_assert option is available starting in Visual Studio 2022 version 17.1. In
earlier versions of Visual Studio, or if /Zc:static_assert- is specified, Visual Studio
doesn't do dependent analysis if the static_assert is within the body of a function
template or within the body of a member function of a class template. Instead, it only
evaluates the static_assert when a template is instantiated.
The /permissive- option enables /Zc:static_assert , so it's on by default in projects
that use /std:c++20 or /std:c++latest . The /Zc:static_assert- option must come after
a /std:c++20 , /std:c++latest , or /permissive- option on the command line.
If the compiler is in the default C++14 mode and /permissive- or /Zc:static_assert is
specified, it uses /Zc:static_assert behavior. However, if it evaluates a static_assert
in a template body, it also reports off-by-default warning C5254, "language feature
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
'terse static assert' requires compiler flag ' /std:c++17 '", since this behavior isn't required
until C++17.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Add /Zc:static_assert or /Zc:static_assert- to the Additional options: pane.
/Zc (Conformance)
To set this compiler option in Visual Studio
See also
 Yes  No
/Zc:strictStrings (Disable string literal
type conversion)
Article • 08/03/2021
When specified, the compiler requires strict const -qualification conformance for
pointers initialized by using string literals.
/Zc:strictStrings [ - ]
If /Zc:strictStrings is specified, the compiler enforces the standard C++ const
qualifications for string literals, as type 'array of const char ' or 'array of const wchar_t ',
depending on the declaration. String literals are immutable, and an attempt to modify
the contents of one results in an access violation error at run time. You must declare a
string pointer as const to initialize it by using a string literal, or use an explicit
const_cast to initialize a non- const pointer. By default, or if /Zc:strictStrings- is
specified, the compiler does not enforce the standard C++ const qualifications for
string pointers initialized by using string literals.
The /Zc:strictStrings option is off by default. The /permissive- compiler option
implicitly sets this option, but it can be overridden by using /Zc:strictStrings- .
Use the /Zc:strictStrings option to prevent compilation of incorrect code. This
example shows how a simple declaration error leads to a crash at run time:
C++
When /Zc:strictStrings is enabled, the same code reports an error in the declaration
of str .
Syntax
Remarks
// strictStrings_off.cpp
// compile by using: cl /W4 strictStrings_off.cpp
int main() {
 wchar_t* str = L"hello";
 str[2] = L'a'; // run-time error: access violation
}
C++
If you use auto to declare a string pointer, the compiler creates the correct const
pointer type declaration for you. An attempt to modify the contents of a const pointer
is reported by the compiler as an error.
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:strictStrings and then
choose OK.
/Zc (Conformance)
// strictStrings_on.cpp
// compile by using: cl /Zc:strictStrings /W4 strictStrings_on.cpp
int main() {
 wchar_t* str = L"hello"; // error: Conversion from string literal
 // loses const qualifier
 str[2] = L'a';
}
７ Note
The C++ Standard Library in Visual Studio 2013 does not support the
/Zc:strictStrings compiler option in debug builds. If you see several C2665 errors
in your build output, this may be the cause.
To set this compiler option in the Visual Studio
development environment
See also
/Zc:templateScope (Check template
parameter shadowing)
Article • 11/15/2022
The /Zc:templateScope compiler option enables checks for Standard C++ behavior
around shadowing of template parameters.
/Zc:templateScope [ - ]
The C++ Standard doesn't allow the reuse of a template parameter's name (or
shadowing) for another declaration within the scope of the template. The
/Zc:templateScope compiler option enables an error check for such shadowing.
The /Zc:templateScope option is new in Visual Studio 2022 version 17.5 preview 1. The
option is off by default even when the code is compiled using the /permissive- option
(or an option that implies /permissive- , such as /std:c++20 or /std:c++latest ). To
enable the error check, you must explicitly add /Zc:templateScope to the compiler
command line. To explicitly disable the check, use the /Zc:templateScope- option.
Under /Zc:templateScope , this sample code produces an error:
C++
Syntax
Remarks
Example
template<typename T>
void f(T&& t) {
 int T = 13;
}
/* Output:
t.cpp(3): error C7527: 'T': a template parameter name cannot be reused
within its scope
*/
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:templateScope or /Zc:templateScope- . Choose OK
or Apply to save your changes.
See also
/Zc (Conformance)
/permissive-
/std (Specify language standard version)
/Zc:ternary (Enforce conditional
operator rules)
Article • 08/17/2021
Enable enforcement of C++ Standard rules for the types and const or volatile (cv)
qualification of the second and third operands in a conditional operator expression.
Syntax
/Zc:ternary [ - ]
Remarks
Starting in Visual Studio 2017, the compiler supports C++ standard conditional operator
( ?: ) behavior. It's also known as the ternary operator. The C++ Standard requires
ternary operands satisfy one of three conditions: The operands must be of the same
type and const or volatile qualification (cv-qualification), or only one operand must
be unambiguously convertible to the same type and cv-qualification as the other. Or,
one or both operands must be a throw expression. In versions before Visual Studio 2017
version 15.5, the compiler allowed conversions that are considered ambiguous by the
standard.
When the /Zc:ternary option is specified, the compiler conforms to the standard. It
rejects code that doesn't satisfy the rules for matched types and cv-qualification of the
second and third operands.
The /Zc:ternary option is off by default in Visual Studio 2017. Use /Zc:ternary to
enable conforming behavior, or /Zc:ternary- to explicitly specify the previous non￾conforming compiler behavior. The /permissive- option implicitly enables this option,
but it can be overridden by using /Zc:ternary- .
Examples
This sample shows how a class that provides both non-explicit initialization from a type,
and conversion to a type, can lead to ambiguous conversions. This code is accepted by
the compiler by default, but rejected when / Zc:ternary or /permissive- is specified.
C++
To fix this code, make an explicit cast to the preferred common type, or prevent one
direction of type conversion. You can keep the compiler from matching a type
conversion by making the conversion explicit.
An important exception to this common pattern is when the type of the operands is one
of the null-terminated string types, such as const char* , const char16_t* , and so on.
You can also reproduce the effect with array types and the pointer types they decay to.
The behavior when the actual second or third operand to ?: is a string literal of
corresponding type depends on the language standard used. C++17 has changed
semantics for this case from C++14. As a result, the compiler accepts the code in the
following example under the default /std:c++14 , but rejects it when you specify
/std:c++17 or later.
C++
// zcternary1.cpp
// Compile by using: cl /EHsc /W4 /nologo /Zc:ternary zcternary1.cpp
struct A
{
 long l;
 A(int i) : l{i} {} // explicit prevents conversion of int
 operator int() const { return static_cast<int>(l); }
};
int main()
{
 A a(42);
 // Accepted when /Zc:ternary (or /permissive-) is not used
 auto x = true ? 7 : a; // old behavior prefers A(7) over (int)a
 auto y = true ? A(7) : a; // always accepted
 auto z = true ? 7 : (int)a; // always accepted
 return x + y + z;
}
// zcternary2.cpp
// Compile by using: cl /EHsc /W4 /nologo /Zc:ternary /std:c++17
zcternary2.cpp
struct MyString
{
 const char * p;
 MyString(const char* s = "") noexcept : p{s} {} // from char*
 operator const char*() const noexcept { return p; } // to char*
};
int main()
{
 MyString s;
To fix this code, cast one of the operands explicitly.
Under /Zc:ternary , the compiler rejects conditional operators where one of the
arguments is of type void , and the other isn't a throw expression. A common use of this
pattern is in ASSERT-like macros:
C++
The typical solution is to replace the non-void argument with void() .
This sample shows code that generates an error under both /Zc:ternary and
/Zc:ternary- :
C++
This code previously gave this error:
Output
 auto x = true ? "A" : s; // MyString: permissive prefers MyString("A")
over (const char*)s
}
// zcternary3.cpp
// Compile by using: cl /EHsc /W4 /nologo /Zc:ternary /c zcternary3.cpp
void myassert(const char* text, const char* file, int line);
#define ASSERT(ex) (void)((ex) ? 0 : myassert(#ex, __FILE__, __LINE__))
// To fix, define it this way instead:
// #define ASSERT(ex) (void)((ex) ? void() : myassert(#ex, __FILE__,
__LINE__))
int main()
{
 ASSERT(false); // C3447
}
// zcternary4.cpp
// Compile by using:
// cl /EHsc /W4 /nologo /Zc:ternary zcternary4.cpp
// cl /EHsc /W4 /nologo /Zc:ternary zcternary4.cpp
int main() {
 auto p1 = [](int a, int b) { return a > b; };
 auto p2 = [](int a, int b) { return a > b; };
 auto p3 = true ? p1 : p2; // C2593 under /Zc:ternary, was C2446
}
With /Zc:ternary , the reason for failure becomes clearer. Any of several
implementation-defined calling conventions could be used to generate each lambda.
However, the compiler has no preference rule to disambiguate the possible lambda
signatures. The new output looks like this:
Output
A common source of problems found by /Zc:ternary comes from conditional operators
used in template meta-programming. Some of the result types change under this
switch. The following example demonstrates two cases where /Zc:ternary changes a
conditional expression's result type in a non-meta-programming context:
C++
error C2446: ':': no conversion from 'foo::
<lambda_f6cd18702c42f6cd636bfee362b37033>' to 'foo::
<lambda_717fca3fc65510deea10bc47e2b06be4>'
note: No user-defined-conversion operator available that can perform this
conversion, or the operator cannot be called
error C2593: 'operator ?' is ambiguous
note: could be 'built-in C++ operator?(bool (__cdecl *)(int,int), bool
(__cdecl *)(int,int))'
note: or 'built-in C++ operator?(bool (__stdcall *)(int,int), bool
(__stdcall *)(int,int))'
note: or 'built-in C++ operator?(bool (__fastcall *)(int,int), bool
(__fastcall *)(int,int))'
note: or 'built-in C++ operator?(bool (__vectorcall *)(int,int), bool
(__vectorcall *)(int,int))'
note: while trying to match the argument list '(foo::
<lambda_717fca3fc65510deea10bc47e2b06be4>, foo::
<lambda_f6cd18702c42f6cd636bfee362b37033>)'
// zcternary5.cpp
// Compile by using: cl /EHsc /W4 /nologo /Zc:ternary zcternary5.cpp
int main(int argc, char**) {
 char a = 'A';
 const char b = 'B';
 decltype(auto) x = true ? a : b; // char without, const char& with
/Zc:ternary
 const char(&z)[2] = argc > 3 ? "A" : "B"; // const char* without
/Zc:ternary
 return x > *z;
}
The typical fix is to apply a std::remove_reference trait on the result type, where needed
to preserve the old behavior.
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:ternary or /Zc:ternary￾and then choose OK.
See also
/Zc (Conformance)
/Zc:threadSafeInit (Thread-safe Local
Static Initialization)
Article • 08/03/2021
The /Zc:threadSafeInit compiler option tells the compiler to initialize static local
(function scope) variables in a thread-safe way, eliminating the need for manual
synchronization. Only initialization is thread-safe. Use and modification of static local
variables by multiple threads must still be manually synchronized. This option is
available starting in Visual Studio 2015. By default, Visual Studio enables this option.
Syntax
/Zc:threadSafeInit[-]
Remarks
In the C++11 standard, block scope variables with static or thread storage duration
must be zero-initialized before any other initialization takes place. Initialization occurs
when control first passes through the declaration of the variable. If an exception is
thrown during initialization, the variable is considered uninitialized, and initialization is
re-attempted the next time control passes through the declaration. If control enters the
declaration concurrently with initialization, the concurrent execution blocks while
initialization is completed. The behavior is undefined if control re-enters the declaration
recursively during initialization. By default, Visual Studio starting in Visual Studio 2015
implements this standard behavior. This behavior may be explicitly specified by setting
the /Zc:threadSafeInit compiler option.
The /Zc:threadSafeInit compiler option is on by default. The /permissive- option does
not affect /Zc:threadSafeInit.
Thread-safe initialization of static local variables relies on code implemented in the
Universal C run-time library (UCRT). To avoid taking a dependency on the UCRT, or to
preserve the non-thread-safe initialization behavior of versions of Visual Studio prior to
Visual Studio 2015, use the /Zc:threadSafeInit- option. If you know that thread-safety is
not required, use this option to generate slightly smaller, faster code around static local
declarations.
Thread-safe static local variables use thread-local storage (TLS) internally to provide
efficient execution when the static has already been initialized. The implementation of
this feature relies on Windows operating system support functions in Windows Vista
and later operating systems. Windows XP, Windows Server 2003, and older operating
systems do not have this support, so they do not get the efficiency advantage. These
operating systems also have a lower limit on the number of TLS sections that can be
loaded. Exceeding the TLS section limit can cause a crash. If this is a problem in your
code, especially in code that must run on older operating systems, use
/Zc:threadSafeInit- to disable the thread-safe initialization code.
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. From the Configurations drop down menu, choose All Configurations.
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional Options property to include /Zc:threadSafeInit or
/Zc:threadSafeInit- and then choose OK.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zc (Conformance)
/Zc:throwingNew (Assume operator new
throws)
Article • 08/03/2021
When the /Zc:throwingNew option is specified, the compiler optimizes calls to operator
new to skip checks for a null pointer return. This option tells the compiler to assume that
all linked implementations of operator new and custom allocators conform to the C++
standard and throw on allocation failure. By default in Visual Studio, the compiler
pessimistically generates null checks (/Zc:throwingNew-) for these calls, because users
can link with a non-throwing implementation of operator new or write custom allocator
routines that return null pointers.
Syntax
/Zc:throwingNew[-]
Remarks
Since ISO C++98, the standard has specified that the default operator new throws
std::bad_alloc when memory allocation fails. Versions of Visual C++ up to Visual
Studio 6.0 returned a null pointer on an allocation failure. Beginning in Visual Studio
2002, operator new conforms to the standard and throws on failure. To support code
that uses the older allocation style, Visual Studio provides a linkable implementation of
operator new in nothrownew.obj that returns a null pointer on failure. By default, the
compiler also generates defensive null checks to prevent these older-style allocators
from causing an immediate crash on failure. The /Zc:throwingNew option tells the
compiler to leave out these null checks, on the assumption that all linked memory
allocators conform to the standard. This does not apply to explicit non-throwing
operator new overloads, which are declared by using an additional parameter of type
std::nothrow_t and have an explicit noexcept specification.
Conceptually, to create an object on the free store, the compiler generates code to
allocate its memory and then to invoke its constructor to initialize the memory. Because
the MSVC compiler normally cannot tell if this code will be linked to a non-conforming,
non-throwing allocator, by default it also generates a null check before calling the
constructor. This prevents a null pointer dereference in the constructor call if a non￾throwing allocation fails. In most cases, these checks are unnecessary, because the
default operator new allocators throw instead of returning null pointers. The checks also
have unfortunate side effects. They bloat the code size, they flood the branch predictor,
and they inhibit other useful compiler optimizations such as devirtualization or const
propagation out of the initialized object. The checks exist only to support code that links
to nothrownew.obj or has custom non-conforming operator new implementations. If you
do not use non-conforming operator new , we recommend you use /Zc:throwingNew to
optimize your code.
The /Zc:throwingNew option is off by default, and is not affected by the /permissive￾option.
If you compile by using link-time code generation (LTCG), you do not need to specify
/Zc:throwingNew. When your code is compiled by using LTCG, the compiler can detect
if the default, conforming operator new implementation is used. If so, the compiler
leaves out the null checks automatically. The linker looks for the /ThrowingNew flag to
tell if the implementation of operator new is conforming. You can specify this flag to the
linker by including this directive in the source for your custom operator new
implementation:
C++
#pragma comment(linker, "/ThrowingNew")
For more information about conformance issues in Visual C++, see Nonstandard
Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. From the Configuration drop down menu, choose All Configurations.
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional Options property to include /Zc:throwingNew or
/Zc:throwingNew- and then choose OK.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zc (Conformance)
noexcept (C++)
Exception Specifications (throw) (C++)
terminate (exception)
/Zc:tlsGuards (Check TLS initialization)
Article • 12/12/2022
The /Zc:tlsGuards compiler option generates runtime checks for thread local storage
(TLS) initialization in DLLs.
Syntax
/Zc:tlsGuards [ - ]
Remarks
The /Zc:tlsGuards compiler option enables checks for initialization of thread-local
variables in DLLs. Previously, thread-local variables in DLLs weren't correctly initialized.
Other than on the thread that loaded the DLL, they weren't initialized before first use on
threads that existed before the DLL was loaded. The /Zc:tlsGuards option enables code
that corrects this defect. Thread-local variables in such a DLL get initialized immediately
before their first use on such threads.
The /Zc:tlsGuards option is new in Visual Studio 2019 version 16.5. This option is on by
default in all compiler modes. The new behavior of testing for initialization on uses of
thread-local variables may be disabled by using the /Zc:tlsGuards- compiler option. To
disable checks for specific thread-local variables, use the [[msvc::no_tls_guard]] attribute.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:tlsGuards . Choose OK or Apply to save your
changes.
See also
/Zc (Conformance)\
/Zc:trigraphs (Trigraphs Substitution)
Article • 08/03/2021
When /Zc:trigraphs is specified, the compiler replaces a trigraph character sequence
by using a corresponding punctuation character.
Syntax
/Zc:trigraphs [ - ]
Remarks
A trigraph consists of two consecutive question marks ( ?? ) followed by a unique third
character. The C language standard supports trigraphs for source files that use a
character set that doesn't contain convenient graphic representations for some
punctuation characters. For example, when trigraphs are enabled, the compiler replaces
the ??= trigraph by using the # character. Through C++14, trigraphs are supported as
in C. The C++17 standard removes trigraphs from the C++ language. In C++ code, the
/Zc:trigraphs compiler option enables substitution of trigraph sequences by the
corresponding punctuation character. /Zc:trigraphs- disables trigraph substitution.
The /Zc:trigraphs option is off by default, and the option isn't affected when the
/permissive- option is specified.
For a list of C/C++ trigraphs, and an example that shows how to use trigraphs, see
Trigraphs.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:trigraphs or
/Zc:trigraphs- and then choose OK.
See also
/Zc (Conformance)
Trigraphs
/Zc:twoPhase- (disable two-phase name
lookup)
Article • 09/28/2022
The /Zc:twoPhase- option, under /permissive- , tells the compiler to use the original,
non-conforming Microsoft C++ compiler behavior to parse and instantiate class
templates and function templates.
Syntax
/Zc:twoPhase￾Remarks
Visual Studio 2017 version 15.3 and later: Under /permissive-, the compiler uses two￾phase name lookup for template name resolution. If you also specify /Zc:twoPhase- , the
compiler reverts to its previous non-conforming class template and function template
name resolution and substitution behavior. When /permissive- isn't specified, the non￾conforming behavior is the default.
The Windows SDK header files in version 10.0.15063.0 (Creators Update or RS2) and
earlier don't work in conformance mode. /Zc:twoPhase- is required to compile code for
those SDK versions when you use /permissive- . Versions of the Windows SDK starting
with version 10.0.15254.0 (Fall Creators Update or RS3) work correctly in conformance
mode. They don't require the /Zc:twoPhase- option.
Use /Zc:twoPhase- if your code requires the old behavior to compile correctly. Strongly
consider updating your code to conform to the standard.
Compiler behavior under /Zc:twoPhase￾By default, or in Visual Studio 2017 version 15.3 and later when you specify both
/permissive- and /Zc:twoPhase- , the compiler uses this behavior:
It parses only the template declaration, the class head, and the base class list. The
template body is captured as a token stream. No function bodies, initializers,
default arguments, or noexcept arguments are parsed. The class template is
pseudo-instantiated on a tentative type to validate that the declarations in the
class template are correct. Consider this class template:
C++
template <typename T> class Derived : public Base<T> { ... }
The template declaration, template <typename T> , the class head class Derived ,
and the base-class list public Base<T> are parsed, but the template body is
captured as a token stream.
When it parses a function template, the compiler parses only the function
signature. The function body is never parsed. Instead, it's captured as a token
stream.
As a result, if the template body has syntax errors, but the template never gets
instantiated, the compiler doesn't diagnose the errors.
Another effect of this behavior is in overload resolution. Non-standard behavior occurs
because of the way the token stream is expanded at the site of instantiation. Symbols
that weren't visible at the template declaration may be visible at the point of
instantiation. That means they can participate in overload resolution. You may find
templates change behavior based on code that wasn't visible at template definition,
contrary to the standard.
For example, consider this code:
C++
// zctwophase.cpp
// To test options, compile by using
// cl /EHsc /nologo /W4 zctwophase.cpp
// cl /EHsc /nologo /W4 /permissive- zctwophase.cpp
// cl /EHsc /nologo /W4 /permissive- /Zc:twoPhase- zctwophase.cpp
#include <cstdio>
void func(long) { std::puts("Standard two-phase") ;}
template<typename T> void g(T x)
{
 func(0);
}
void func(int) { std::puts("Microsoft one-phase"); }
int main()
{
 g(6174);
}
Here's the output when you use the default mode, conformance mode, and
conformance mode with /Zc:twoPhase- compiler options:
Windows Command Prompt
C:\Temp>cl /EHsc /nologo /W4 zctwophase.cpp && zctwophase
zctwophase.cpp
Microsoft one-phase
C:\Temp>cl /EHsc /nologo /W4 /permissive- zctwophase.cpp && zctwophase
zctwophase.cpp
Standard two-phase
C:\Temp>cl /EHsc /nologo /W4 /permissive- /Zc:twoPhase- zctwophase.cpp &&
zctwophase
zctwophase.cpp
Microsoft one-phase
When compiled in conformance mode under /permissive- , this program prints
" Standard two-phase ", because the second overload of func isn't visible when the
compiler reaches the template. If you add /Zc:twoPhase- , the program prints " Microsoft
one-phase ". The output is the same as when you don't specify /permissive- .
Dependent names are names that depend on a template parameter. These names have
lookup behavior that is also different under /Zc:twoPhase- . In conformance mode,
dependent names aren't bound at the point of the template's definition. Instead, the
compiler looks them up when it instantiates the template. For function calls with a
dependent function name, the name gets bound to functions visible at the call site in
the template definition. Other overloads from argument-dependent lookup are added,
both at the point of the template definition, and at the point of template instantiation.
Two-phase lookup consists of two parts: The lookup for non-dependent names during
template definition, and the lookup for dependent names during template instantiation.
Under /Zc:twoPhase- , the compiler doesn't do argument-dependent lookup separately
from unqualified lookup. That is, it doesn't do two-phase lookup, so the results of
overload resolution may be different.
Here's another example:
C++
When compiled without /permissive- , this code prints:
Output
When compiled with /permissive- , but without /Zc:twoPhase- , this code prints:
Output
When compiled with both /permissive- and /Zc:twoPhase- , this code prints:
Output
// zctwophase1.cpp
// To test options, compile by using
// cl /EHsc /W4 zctwophase1.cpp
// cl /EHsc /W4 /permissive- zctwophase1.cpp
// cl /EHsc /W4 /permissive- /Zc:twoPhase- zctwophase1.cpp
#include <cstdio>
void func(long) { std::puts("func(long)"); }
template <typename T> void tfunc(T t) {
 func(t);
}
void func(int) { std::puts("func(int)"); }
namespace NS {
 struct S {};
 void func(S) { std::puts("NS::func(NS::S)"); }
}
int main() {
 tfunc(1729);
 NS::S s;
 tfunc(s);
}
func(int)
NS::func(NS::S)
func(long)
NS::func(NS::S)
func(int)
NS::func(NS::S)
In conformance mode under /permissive- , the call tfunc(1729) resolves to the void
func(long) overload. It doesn't resolve to the void func(int) overload, as under
/Zc:twoPhase- . The reason is, the unqualified func(int) is declared after the definition
of the template, and it isn't found through argument-dependent lookup. But void
func(S) does participate in argument-dependent lookup, so it's added to the overload
set for the call tfunc(s) , even though it's declared after the function template.
Older versions of the compiler don't require the keywords template and typename
everywhere the C++ Standard requires them. These keywords are needed in some
positions to disambiguate how compilers should parse a dependent name during the
first phase of lookup. For example:
T::Foo<a || b>(c);
A conforming compiler parses Foo as a variable in the scope of T , meaning this code is
a logical-or expression with T::foo < a as the left operand and b > (c) as the right
operand. If you mean to use Foo as a function template, you must indicate that it's a
template by adding the template keyword:
T::template Foo<a || b>(c);
In versions Visual Studio 2017 version 15.3 and later, when /permissive- and
/Zc:twoPhase- are specified, the compiler allows this code without the template
keyword. It interprets the code as a call to a function template with an argument of a ||
b , because it only parses templates in a limited fashion. The code above isn't parsed at
all in the first phase. During the second phase, there's enough context to tell that
T::Foo is a template rather than a variable, so the compiler doesn't enforce use of the
keyword.
This behavior can also be seen by eliminating the keyword typename before names in
function template bodies, initializers, default arguments, and noexcept arguments. For
example:
C++
Update your code for two-phase conformance
template<typename T>
typename T::TYPE func(typename T::TYPE*)
{
 /* typename */ T::TYPE i;
}
If you don't use the keyword typename in the function body, this code compiles under
/permissive- /Zc:twoPhase- , but not under /permissive- alone. The typename keyword
is required to indicate that the TYPE is dependent. Because the body isn't parsed under
/Zc:twoPhase- , the compiler does't require the keyword. In /permissive- conformance
mode, code without the typename keyword generates errors. To migrate your code to
conformance in Visual Studio 2017 version 15.3 and beyond, insert the typename
keyword where it's missing.
Similarly, consider this code sample:
C++
Under /permissive- /Zc:twoPhase- and in older compilers, the compiler only requires
the template keyword on line 2. In conformance mode, the compiler now also requires
the template keyword on line 4 to indicate that T::X<T> is a template. Look for code
that is missing this keyword, and supply it to make your code conform to the standard.
For more information about conformance issues, see C++ conformance improvements
in Visual Studio and Nonstandard behavior.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zc:twoPhase- and then
choose OK.
/Zc (Conformance)
template<typename T>
typename T::template X<T>::TYPE func(typename T::TYPE)
{
 typename T::/* template */ X<T>::TYPE i;
}
To set this compiler option in the Visual Studio
development environment
See also
/Zc:wchar_t (wchar_t Is Native Type)
Article • 08/03/2021
Parse wchar_t as a built-in type according to the C++ standard.
Syntax
/Zc:wchar_t[-]
Remarks
If /Zc:wchar_t is on, wchar_t is a keyword for a built-in integral type in code compiled as
C++. If /Zc:wchar_t- (with a minus sign) is specified, or in code compiled as C, wchar_t is
not a built-in type. Instead, wchar_t is defined as a typedef for unsigned short in the
canonical header stddef.h. (The Microsoft implementation defines it in another header
that is included by stddef.h and other standard headers.)
We do not recommend /Zc:wchar_t- because the C++ standard requires that wchar_t
be a built-in type. Using the typedef version can cause portability problems. If you
upgrade from earlier versions of Visual Studio and encounter compiler error C2664
because the code is trying to implicitly convert a wchar_t to unsigned short , we
recommend that you change the code to fix the error, instead of setting /Zc:wchar_t-.
The /Zc:wchar_t option is on by default in C++ compilations, and is ignored in C
compilations. The /permissive- option does not affect /Zc:wchar_t.
Microsoft implements wchar_t as a two-byte unsigned value. It maps to the Microsoft￾specific native type __wchar_t . For more information about wchar_t , see Data Type
Ranges and Fundamental Types.
If you write new code that has to interoperate with older code that still uses the typedef
version of wchar_t , you can provide overloads for both the unsigned short and
__wchar_t variations of wchar_t , so that your code can be linked with code compiled
with /Zc:wchar_t or code compiled without it. Otherwise, you would have to provide two
different builds of the library, one with and one without /Zc:wchar_t enabled. Even in
this case, we recommend that you build the older code by using the same compiler that
you use to compile the new code. Never mix binaries compiled with different compilers.
When /Zc:wchar_t is specified, _WCHAR_T_DEFINED and _NATIVE_WCHAR_T_DEFINED
symbols are defined. For more information, see Predefined Macros.
If your code uses the compiler COM global functions, because /Zc:wchar_t is now on by
default, we recommend that you change explicit references to comsupp.lib (either from
the comment pragma or on the command line) to either comsuppw.lib or
comsuppwd.lib. (If you must compile with /Zc:wchar_t-, use comsupp.lib.) If you include
the comdef.h header file, the correct library is specified for you. For information about
compiler COM support, see Compiler COM Support.
The wchar_t built-in type is not supported when you compile C code. For more
information about conformance issues with Visual C++, see Nonstandard Behavior.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Language page.
3. Modify the Treat wchar_t as Built-in Type property.
To set this compiler option programmatically
See TreatWChar_tAsBuiltInType.
See also
/Zc (Conformance)
/Zc:zeroSizeArrayNew (Call member
new/delete on arrays)
Article • 11/09/2022
The /Zc:zeroSizeArrayNew compiler option calls member new and delete for zero￾length arrays of objects.
Syntax
/Zc:zeroSizeArrayNew [ - ]
Remarks
The /Zc:zeroSizeArrayNew compiler option enables calls to member new and delete for
zero-length arrays of objects of class types with virtual destructors. This behavior
conforms to the standard. This compiler option is new in Visual Studio 2019 version 16.9
and is enabled by default in all compiler modes. Previously, in code compiled by
versions before Visual Studio 2019 version 16.9, the compiler invoked global new and
delete on zero-length arrays of objects of class types with virtual destructors.
The /Zc:zeroSizeArrayNew option may cause a breaking change in code that relied on
the previous non-conforming behavior. To restore the previous behavior, use the
/Zc:zeroSizeArrayNew- compiler option.
To set this compiler option in Visual Studio
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. In Additional options, add /Zc:zeroSizeArrayNew or /Zc:zeroSizeArrayNew- .
Choose OK or Apply to save your changes.
See also
/Zc (Conformance)\
/Zf (Faster PDB generation)
Article • 08/17/2021
Enable faster PDB generation in parallel builds by minimizing RPC calls to mspdbsrv.exe.
Syntax
/Zf
Remarks
The /Zf option enables compiler support for faster generation of PDB files when using
the /MP (Build with Multiple Processes) option, or when the build system (for example,
MSBuild or CMake) may run multiple cl.exe compiler processes at the same time. This
option causes the compiler front end to delay generation of type indexes for each type
record in the PDB file until the end of compilation, then requests them all in a single RPC
call to mspdbsrv.exe, instead of making an RPC request for each record. This can
substantially improve build throughput by reducing the RPC load on the mspdbsrv.exe
process in an environment where multiple cl.exe compiler processes run simultaneously.
Because the /Zf option only applies to PDB generation, it requires the /Zi or /ZI option.
The /Zf option is available beginning in Visual Studio 2017 version 15.1, where it is off
by default. Starting in Visual Studio 2017 version 15.7, this option is on by default when
the /Zi or /ZI option is enabled.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zf and then choose OK.
See also
Compiler Options Listed Alphabetically
/MP (Build with Multiple Processes)
/Zg (Generate Function Prototypes)
Article • 08/03/2021
Removed. Creates a function prototype for each function defined in the source file, but
does not compile the source file.
Syntax
/Zg
Remarks
This compiler option is no longer available. It was removed in Visual Studio 2015. This
page remains for users of older versions of Visual Studio.
The function prototype includes the function return type and an argument type list. The
argument type list is created from the types of the formal parameters of the function.
Any function prototypes already present in the source file are ignored.
The list of prototypes is written to standard output. You may find this list helpful to
verify that actual arguments and formal parameters of a function are compatible. You
can save the list by redirecting standard output to a file. Then you can use #include to
make the list of function prototypes a part of your source file. Doing so causes the
compiler to perform argument type checking.
If you use the /Zg option and your program contains formal parameters that have
struct, enum, or union type (or pointers to such types), the declaration of each struct,
enum, or union type must have a tag (name). In the following sample, the tag name is
MyStruct .
C
// Zg_compiler_option.c
// compile with: /Zg
typedef struct MyStruct { int i; } T2;
void f2(T2 * t) {}
The /Zg option was deprecated in Visual Studio 2005 and has been removed in Visual
Studio 2015. The MSVC compiler has removed support for older, C-style code. For a list
of deprecated compiler options, see Deprecated and Removed Compiler Options in
Compiler Options Listed by Category.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/ZH (Hash algorithm for calculation of
file checksum in debug info)
Article • 02/01/2022
Specifies which cryptographic hash algorithm to use to generate a checksum of each
source file.
Syntax
/ZH:MD5
/ZH:SHA1
/ZH:SHA_256
Arguments
/ZH:MD5
Use an MD5 hash for the checksum. This option is the default in Visual Studio 2019.
/ZH:SHA1
Use an SHA-1 hash for the checksum.
/ZH:SHA_256
Use an SHA-256 hash for the checksum. This option is the default in Visual Studio 2022
version 17.0 and later.
Remarks
PDB files store a checksum for each source file, compiled into the object code in the
associated executable. The checksum allows the debugger to verify that the source code
it loads matches the executable. The compiler and debugger support MD5, SHA-1, and
SHA-256 hash algorithms. By default, in Visual Studio 2019 the compiler uses an MD5
hash to generate the checksum. To specify this hash algorithm explicitly, use the
/ZH:MD5 option.
Because of a risk of collision problems in MD5 and SHA-1, Microsoft recommends you
use the /ZH:SHA_256 option. The SHA-256 hash might result in a small increase in
compile times. The /ZH:SHA_256 option is the default in Visual Studio 2022 version 17.0
and later.
When more than one /ZH option is specified, the last option is used.
The /ZH option is available in Visual Studio 2019 version 16.4 and later.
To set this compiler option in the Visual Studio
development environment
1. Open the Property Pages dialog box for the project. For details, see Set C++
compiler and build properties in Visual Studio.
2. Set the Configuration drop-down to All Configurations. Set the Platform drop￾down to All Platforms.
3. Select the Configuration Properties > C/C++ > Command Line property page.
4. Modify the Additional options property to add a /ZH:MD5 , /ZH:SHA1 , or
/ZH:SHA_256 option, and then choose OK.
See also
Compiler options
Source server
/Zl (Omit Default Library Name)
Article • 08/03/2021
Omits the default C runtime library name from the .obj file. By default, the compiler puts
the name of the library into the .obj file to direct the linker to the correct library.
For more information on the default library, see Use Run-Time Library.
You can use /Zl to compile .obj files you plan to put into a library. Although omitting the
library name saves only a small amount of space for a single .obj file, the total space
saved is significant in a library that contains many object modules.
This option is an advanced option. Setting this option removes certain C Runtime library
support that may be required by your application, resulting in link-time errors if your
application depends on this support. If you use this option you must provide the
required components in some other way.
Use /NODEFAULTLIB (Ignore Libraries). to direct the linker to ignore library references in
all .obj files.
For more information, see CRT Library Features.
When compiling with /Zl, _VC_NODEFAULTLIB is defined. For example:
C++
Syntax
/Zl
Remarks
// vc_nodefaultlib.cpp
// compile with: /Zl
void Test() {
 #ifdef _VC_NODEFAULTLIB
 int i;
 #endif
 int i; // C2086
}
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Advanced property page.
3. Modify the Omit Default Library Names property.
To set this compiler option programmatically
See OmitDefaultLibName.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zm (Specify precompiled header
memory allocation limit)
Article • 02/23/2022
Determines the amount of memory that the compiler allocates to construct precompiled
headers.
Syntax
/Zm factor
Arguments
factor
A scaling factor percentage that determines the amount of memory that the compiler
uses to construct precompiled headers.
The factor argument is a percentage of the default size of a compiler-defined work
buffer. The default value of factor is 100 (percent), but you can specify larger or smaller
amounts.
Remarks
In versions before Visual Studio 2015, the C++ compiler used several discrete heaps,
and each had a finite limit. Currently, the compiler dynamically grows the heaps as
necessary up to a total heap size limit, and allows the precompiled header to comprise
multiple address ranges. Now, the /Zm compiler option is rarely necessary.
If the compiler runs out of heap space and emits the C1060 error message when you
use the /Zm compiler option, you might have reserved too much memory. Consider
removing the /Zm option.
If the compiler emits the C1076 error message, an accompanying C3859 message
specifies the factor argument to use when you recompile by using the /Zm compiler
option. This message is only significant when a precompiled header uses #pragma
hdrstop . In other cases, it's a spurious error caused by Windows virtual memory pressure
issues, and the recommendation to use the /Zm option should be ignored. Instead,
consider reducing the number of parallel processes when using the /maxcpucount option
to MSBUILD.EXE together with the /MP option to CL.EXE. For more information, see
Precompiled Header (PCH) issues and recommendations .
The following table shows how the factor argument affects the memory allocation
limit. In the table, we assume the size of the default precompiled header buffer is 75 MB.
Value of factor Memory allocation limit
10 7.5 MB
100 75 MB
200 150 MB
1000 750 MB
2000 1500 MB
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the /Zm compiler option in the Additional Options box.
See AdditionalOptions.
MSVC compiler options
MSVC compiler command-line syntax
Other ways to set the memory allocation limit
To set the /Zm compiler option in the Visual Studio
development environment
To set the /Zm compiler option programmatically
See also
/Zo (Enhance Optimized Debugging)
Article • 06/01/2022
Generate enhanced debugging information for optimized code in non-debug builds.
Syntax
/Zo [ - ]
Remarks
The /Zo compiler option generates enhanced debugging information for optimized
code. Optimization may use registers for local variables, reorder code, vectorize loops,
and inline function calls. These optimizations can obscure the relationship between the
source code and the compiled object code. The /Zo option tells the compiler to
generate extra debugging information for local variables and inlined functions. It allows
you to see variables in the Autos, Locals, and Watch windows when you step through
optimized code in the Visual Studio debugger. It also enables stack traces to show
inlined functions in the WinDBG debugger. Debug builds that have disabled
optimizations (/Od) don't need the extra debugging information generated when /Zo is
specified. Use the /Zo option to debug Release configurations with optimization turned
on. For more information on optimization options, see /O options (Optimize Code).
The /Zo option is enabled by default when you specify debugging information with /Zi
or /Z7 . It's disabled by the /ZI compiler option. Specify /Zo- to explicitly disable this
compiler option.
The /Zo option is available starting in Visual Studio 2013 Update 3, and it replaces the
previously undocumented /d2Zi+ option.
To set the /Zo compiler option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Modify the Additional Options property to include /Zo and then choose OK.
To set this compiler option programmatically
See AdditionalOptions.
See also
/O Options (Optimize code)
/Z7, /Zi, /ZI (Debug information format)
Edit and Continue
/Zp (Struct Member Alignment)
Article • 07/06/2022
Controls how the members of a structure are packed into memory and specifies the
same packing for all structures in a module.
/Zp [ 1 | 2 | 4 | 8 | 16 ]
The /ZpN option tells the compiler where to store each structure member. The compiler
stores members after the first one on a boundary that's the smaller of either the size of
the member type, or an N-byte boundary.
The available packing values are described in the following table:
/Zp argument Effect
1 Packs structures on 1-byte boundaries. Same as /Zp .
2 Packs structures on 2-byte boundaries.
4 Packs structures on 4-byte boundaries.
8 Packs structures on 8-byte boundaries (default for x86, ARM, and ARM64).
16 Packs structures on 16-byte boundaries (default for x64 and ARM64EC).
Don't use this option unless you have specific alignment requirements.
You can also use the pack pragma to control structure packing. For more information
about alignment, see:
Syntax
Remarks
２ Warning
The C/C++ headers in the Windows SDK assume the platform's default alignment is
used. Don't change the setting from the default when you include the Windows
SDK headers, either by using /Zp on the command line or by using #pragma pack .
Otherwise, your application may cause memory corruption at runtime.
align
alignof Operator
__unaligned
/ALIGN (Section Alignment)
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Code Generation property page.
3. Modify the Struct Member Alignment property.
To set this compiler option programmatically
See StructMemberAlignment.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/Zs (Syntax Check Only)
Article • 08/03/2021
Tells the compiler to check only the syntax of the source files on the command line.
Syntax
/Zs
Remarks
When using this option, no output files are created, and error messages are written to
standard output.
The /Zs option provides a quick way to find and correct syntax errors before you
compile and link a source file.
To set this compiler option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > C/C++ > Command Line property page.
3. Enter the compiler option in the Additional Options box.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
/ZW (Windows Runtime Compilation)
Article • 06/26/2023
Compiles source code to support Microsoft C++ component extensions C++/CX for the
creation of Universal Windows Platform (UWP) apps.
When you use /ZW to compile, always specify /EHsc as well.
/ZW isn't compatible with /std:c++20 .
Syntax
C++
/ZW /EHsc
/ZW:nostdlib /EHsc
Arguments
nostdlib
Indicates that Platform.winmd , Windows.Foundation.winmd , and other default Windows
metadata ( .winmd ) files aren't automatically included in the compilation. Instead, you
must use the /FU (Name Forced #using File) compiler option to explicitly specify
Windows metadata files.
Remarks
When you specify the /ZW option, the compiler supports these features:
The required metadata files, namespaces, data types, and functions that your app
requires to execute in the Windows Runtime.
Automatic reference-counting of Windows Runtime objects, and automatic
discarding of an object when its reference count goes to zero.
Because the incremental linker doesn't support the Windows metadata included in .obj
files by using the /ZW option, the deprecated /Gm (Enable Minimal Rebuild) option is
incompatible with /ZW .
For more information, see Visual C++ Language Reference.
Requirements
See also
MSVC Compiler Options
MSVC Compiler Command-Line Syntax
Structured SARIF Diagnostics
Article • 11/13/2023
The MSVC compiler can be made to output diagnostics as SARIF (Static Analysis
Results Interchange Format). SARIF is a machine-readable JSON-based format.
There are two ways to make the MSVC compiler produce SARIF diagnostics:
Pass the /experimental:log switch on the command line. See the documentation
for /experimental:log for details.
Launch cl.exe programatically and set the SARIF_OUTPUT_PIPE environment
variable to retrieve SARIF blocks through a pipe.
Retrieving SARIF through a pipe
Tools that consume SARIF from the MSVC compiler while a compilation is in progress
use a pipe. See the documentation for CreatePipe for details about creating Windows
pipes.
To retrieve SARIF through a pipe, set the SARIF_OUTPUT_PIPE environment variable to be
the UTF-16-encoded integer representation of the HANDLE to the write end of the pipe,
then launch cl.exe . SARIF is sent along the pipe as follows:
When a new diagnostic is available, it is written to this pipe.
Diagnostics are written to the pipe one-at-a-time rather than as an entire SARIF
object.
Each diagnostic is represented by a JSON-RPC 2.0 message of type
Notification .
The JSON-RPC message is prefixed with a Content-Length header with the form
Content-Length: <N> followed by two newlines, where <N> is the length of the
following JSON-RPC message in bytes.
The JSON-RPC message and header are both encoded in UTF-8.
This JSON-RPC-with-header format is compatible with vs-streamjsonrpc .
The method name for the JSON-RPC call is OnSarifResult .
The call has a single parameter that is encoded by-name with the parameter
name result .
The value of the argument is a single result object as specified by the SARIF
Version 2.1 standard .
Example
Here's an example of a JSON-RPC SARIF result produced by cl.exe :
JSON
Content-Length: 334
{"jsonrpc":"2.0","method":"OnSarifResult","params":{"result":
{"ruleId":"C1034","level":"fatal","message":{"text":"iostream: no include
path set"},"locations":[{"physicalLocation":{"artifactLocation":
{"uri":"file:///C:/Users/sybrand/source/repos/cppcon-diag/cppcon￾diag/cppcon-diag.cpp"},"region":{"startLine":1,"startColumn":10}}}]}}}
{"jsonrpc":"2.0","method":"OnSarifResult","params":{"result":
{"ruleId":"C1034","level":"fatal","message":{"text":"iostream: no include
path set"},"locations":[{"physicalLocation":{"artifactLocation":
{"uri":"file:///C:/Users/sybrand/source/repos/cppcon-diag/cppcon￾diag/cppcon-diag.cpp"},"region":{"startLine":1,"startColumn":10}}}]}}}
SARIF result data
The compiler outputs SARIF that may include additional information to represent the
nested structure of some diagnostics. A diagnostic (represented by a result SARIF
object) may contain a "diagnostic tree" of additional information in its relatedLocations
field. This tree is encoded using a SARIF property bag as follows:
A location object's properties field may contain a nestingLevel property whose value
is the depth of this location in the diagnostic tree. If a location doesn't have a
nestingLevel specified, the depth is considered to be 0 and this location is a child of
the root diagnostic represented by the result object containing it. Otherwise, if the
value is greater than the depth of the location immediately preceding this location in
the relatedLocations field, this location is a child of that location. Otherwise, this
location is a sibling of the closest preceding location in the relatedLocations field with
the same depth.
Example
Consider the following code:
C++
struct dog {};
struct cat {};
void pet(dog);
void pet(cat);
When this code is compiled, the compiler produces the following result object
( physicalLocation properties have been removed for brevity):
JSON
struct lizard {};
int main() {
 pet(lizard{});
}
{
 "ruleId": "C2665",
 "level": "error",
 "message": {
 "text": "'pet': no overloaded function could convert all the
argument types"
 },
 "relatedLocations": [
 {
 "id": 0,
 "message": {
 "text": "could be 'void pet(cat)'"
 }
 },
 {
 "id": 1,
 "message": {
 "text": "'void pet(cat)': cannot convert argument 1 from
'lizard' to 'cat'"
 },
 "properties": {
 "nestingLevel": 1
 }
 },
 {
 "id": 2,
 "message": {
 "text": "No user-defined-conversion operator available that
can perform this conversion, or the operator cannot be called"
 },
 "properties": {
 "nestingLevel": 2
 }
 },
 {
 "id": 3,
 "message": {
 "text": "or 'void pet(dog)'"
 }
 },
 {
 "id": 4,
The logical diagnostics tree produced from the messages in this result object is:
'pet': no overloaded function could convert all the argument types
could be 'void pet(cat)'
'void pet(cat)': cannot convert argument 1 from 'lizard' to 'cat
No user-defined-conversion operator available that can perform this
conversion, or the operator cannot be called
or 'void pet(dog)'
'void pet(dog)': cannot convert argument 1 from 'lizard' to 'dog'
No user-defined-conversion operator available that can perform this
conversion, or the operator cannot be called
while trying to match the argument list '(lizard)'
/experimental:log (Enable structured SARIF diagnostics)
 "message": {
 "text": "'void pet(dog)': cannot convert argument 1 from
'lizard' to 'dog'"
 },
 "properties": {
 "nestingLevel": 1
 }
 },
 {
 "id": 5,
 "message": {
 "text": "No user-defined-conversion operator available that
can perform this conversion, or the operator cannot be called"
 },
 "properties": {
 "nestingLevel": 2
 }
 },
 {
 "id": 6,
 "message": {
 "text": "while trying to match the argument list '(lizard)'"
 }
 }
 ]
}
See also
Unicode support in the compiler and
linker
Article • 08/03/2021
Most Microsoft C/C++ (MSVC) build tools support Unicode inputs and outputs.
Filenames
Filenames specified on the command line or in compiler directives (such as #include )
may contain Unicode characters.
Source code files
Unicode characters are supported in identifiers, macros, string and character literals, and
in comments. Universal character names are also supported.
Unicode can be input into a source code file in the following encodings:
UTF-16 little endian with or without byte order mark (BOM)
UTF-16 big endian with or without BOM
UTF-8 with BOM
In the Visual Studio IDE, you can save files in several encoding formats, including
Unicode ones. Save them in the Save File As dialog by using the dropdown on the Save
button. Select Save with Encoding in the dropdown. Then, in the Advanced Save
Options dialog, select an encoding from the dropdown list. Choose OK to save the file.
Output
During compilation, the compiler outputs diagnostics to the console in UTF-16. The
characters that can be displayed at your console depend on the console window
properties. Compiler output redirected to a file is in the current ANSI console codepage.
Linker response files and .DEF files
Response files and .DEF files can be either UTF-16 or UTF-8 with a BOM, or ANSI.
.asm and .cod dumps
.asm and .cod dumps are in ANSI by default for compatibility with MASM. Use /FAu to
output UTF-8.
If you specify /FAs , the intermingled source gets printed directly. It may look garbled,
for example, when the source code is UTF-8 and you didn't specify /FAsu .
See also
Use the MSVC toolset from the command line
Linking
Article • 01/10/2024
In a C++ project, the linking step is performed after the compiler compiles the source
code into object files (*.obj). The linker ( link.exe ) combines the object files into a single
executable file.
Linker options can be set inside or outside of Visual Studio. Within Visual Studio, you
access linker options by right-clicking on a project node in Solution Explorer and
choosing Properties to display the property pages. Choose Linker in the left pane to
expand the node and see all the options.
Linker command-line syntax
When you run the linker outside of Visual Studio, you can specify input in one or more
ways:
On the command line
Using command files
In environment variables
The linker first processes options specified in the LINK environment variable, followed
by options in the order they're specified on the command line and in command files. If
an option is repeated with different arguments, the last one processed takes
precedence.
Options apply to the entire build; no options can be applied to specific input files.
To run link.exe , use the following command syntax:
Windows Command Prompt
link arguments
The arguments include options and filenames and can be specified in any order. Options
are processed first, then files. Use one or more spaces or tabs to separate arguments.
７ Note
You can start this tool only from the Visual Studio command prompt. You can't start
it from a system command prompt or from File Explorer.
Command line
On the command line, an option consists of an option specifier, either a dash ( - ) or a
forward slash ( / ), followed by the name of the option. Option names can't be
abbreviated. Some options take an argument, specified after a colon ( : ). No spaces or
tabs are allowed within an option specification, except within a quoted string in the
/COMMENT option. Specify numeric arguments in decimal or C-language notation. Option
names and their keyword or filename arguments aren't case sensitive, but identifiers as
arguments are case sensitive.
To pass a file to the linker, specify the filename on the command line after the link.exe
command. You can specify an absolute or relative path with the filename, and you can
use wildcards in the filename. If you omit the dot ( . ) and filename extension, the linker
assumes an extension of .obj to find the file. The linker doesn't use filename extensions
or the lack of them to make assumptions about the contents of files. It determines the
type of file by examining it, and processes it accordingly.
The linker returns zero for success (no errors). Otherwise, it returns the error number
that stopped the link. For example, if the linker generates LNK1104 , the linker returns
1104. Accordingly, the lowest error number returned on an error by the linker is 1000. A
return value of 128 represents a configuration problem with either the operating system
or a .config file; the loader didn't load either link.exe or c2.dll .
Linker command files
You can pass command-line arguments to link.exe in the form of a command file. To
specify a command file to the linker, use the following syntax:
link @commandfile
The commandfile is the name of a text file. No space or tab is allowed between the at
sign (@) and the filename. There's no default extension; you must specify the full
filename, including any extension. Wildcards can't be used. You can specify an absolute
or relative path with the filename. The linker doesn't use an environment variable to
search for the file.
In the command file, arguments are separated by spaces or tabs (as on the command
line) and by newline characters.
You can specify all or part of the command line in a command file. You can use more
than one command file in a link.exe command. The linker accepts the command-file
input as if it was specified in that location on the command line. Command files can't be
nested. The linker echoes the contents of command files, unless /NOLOGO is specified.
Example
The following command builds a DLL. It passes the names of object files and libraries in
separate command files and uses a third command file for specification of the /EXPORTS
option:
Windows Command Prompt
link /dll @objlist.txt @liblist.txt @exports.txt
LINK environment variables
The linker recognizes the following environment variables:
LINK and _LINK_ , if defined. The linker prepends the options and arguments
defined in the LINK environment variable and appends the options and arguments
defined in the _LINK_ environment variable to the command line arguments
before processing.
LIB , if defined. The linker uses the LIB path when it searches for an object, library,
or other file specified on the command line or by the /BASE option. It also uses the
LIB path to find a .pdb file named in an object. The LIB variable can contain one
or more path specifications, separated by semicolons. One path must point to the
\lib subdirectory of your Visual C++ installation.
PATH , if the tool needs to run CVTRES and can't find the file in the same directory
as link.exe itself. ( link.exe requires CVTRES to link a .res file.) PATH must point
to the \bin subdirectory of your Visual C++ installation.
TMP , to specify a directory when linking OMF or .res files.
See also
C/C++ Building Reference
MSVC Linker Options
Module-Definition (.def) Files
Linker Support for Delay-Loaded DLLs
Linker options
Article • 06/03/2024
LINK.exe links Common Object File Format (COFF) object files and libraries to create an
executable (EXE) file or a dynamic-link library (DLL).
The following table lists options for LINK.exe. For more information about LINK, see:
Compiler-controlled LINK options
LINK input files
LINK output
Reserved words
On the command line, linker options aren't case-sensitive; for example, /base and
/BASE mean the same thing. For details on how to specify each option on the command
line or in Visual Studio, see the documentation for that option.
You can use the comment pragma to specify some linker options.
Option Purpose
@ Specifies a response file.
/ALIGN Specifies the alignment of each section.
/ALLOWBIND Specifies that a DLL can't be bound.
/ALLOWISOLATION Specifies behavior for manifest lookup.
/APPCONTAINER Specifies whether the app must run within an appcontainer
process environment.
/ARM64XFUNCTIONPADMINX64 Specifies the minimum number of bytes of padding between
x64 functions in ARM64X images.
/ASSEMBLYDEBUG Adds the DebuggableAttribute to a managed image.
/ASSEMBLYLINKRESOURCE Creates a link to a managed resource.
/ASSEMBLYMODULE Specifies that a Microsoft intermediate language (MSIL)
module should be imported into the assembly.
Linker options listed alphabetically
ﾉ Expand table
17.8
Option Purpose
/ASSEMBLYRESOURCE Embeds a managed resource file in an assembly.
/BASE Sets a base address for the program.
/CETCOMPAT Marks the binary as CET Shadow Stack compatible.
/CGTHREADS Sets number of cl.exe threads to use for optimization and
code generation when link-time code generation is specified.
/CLRIMAGETYPE Sets the type (IJW, pure, or safe) of a CLR image.
/CLRSUPPORTLASTERROR Preserves the last error code of functions that are called
through the P/Invoke mechanism.
/CLRTHREADATTRIBUTE Specifies the threading attribute to apply to the entry point of
your CLR program.
/CLRUNMANAGEDCODECHECK Specifies whether the linker applies the
SuppressUnmanagedCodeSecurity attribute to linker-generated
P/Invoke stubs that call from managed code into native DLLs.
/DEBUG Creates debugging information.
/DEBUGTYPE Specifies which data to include in debugging information.
/DEF Passes a module-definition (.def) file to the linker.
/DEFAULTLIB Searches the specified library when external references are
resolved.
/DELAY Controls the delayed loading of DLLs.
/DELAYLOAD Causes the delayed loading of the specified DLL.
/DELAYSIGN Partially signs an assembly.
/DEPENDENTLOADFLAG Sets default flags on dependent DLL loads.
/DLL Builds a DLL.
/DRIVER Creates a kernel mode driver.
/DYNAMICBASE Specifies whether to generate an executable image that's
rebased at load time by using the address space layout
randomization (ASLR) feature.
/ENTRY Sets the starting address.
/ERRORREPORT Deprecated. Error reporting is controlled by Windows Error
Reporting (WER) settings.
Option Purpose
/EXPORT Exports a function.
/FILEALIGN Aligns sections within the output file on multiples of a
specified value.
/FIXED Creates a program that can be loaded only at its preferred
base address.
/FORCE Forces a link to complete even with unresolved symbols or
symbols defined more than once.
/FUNCTIONPADMIN Creates an image that can be hot patched.
/GENPROFILE,
/FASTGENPROFILE
Both of these options specify generation of a .pgd file by the
linker to support profile-guided optimization (PGO).
/GENPROFILE and /FASTGENPROFILE use different default
parameters.
/GUARD Enables Control Flow Guard protection.
/HEAP Sets the size of the heap, in bytes.
/HIGHENTROPYVA Specifies support for high-entropy 64-bit address space layout
randomization (ASLR).
/IDLOUT Specifies the name of the .idl file and other MIDL output
files.
/IGNORE Suppresses output of specified linker warnings.
/IGNOREIDL Prevents the processing of attribute information into an .idl
file.
/ILK Overrides the default incremental database file name.
/IMPLIB Overrides the default import library name.
/INCLUDE Forces symbol references.
/INCREMENTAL Controls incremental linking.
/INFERASANLIBS Uses inferred sanitizer libraries.
/INTEGRITYCHECK Specifies that the module requires a signature check at load
time.
/KERNEL Create a kernel mode binary.
/KEYCONTAINER Specifies a key container to sign an assembly.
/KEYFILE Specifies a key or key pair to sign an assembly.
Option Purpose
/LARGEADDRESSAWARE Tells the compiler that the application supports addresses
larger than 2 gigabytes
/LIBPATH Specifies a path to search before the environmental library
path.
/LINKREPRO Specifies a path to generate link repro artifacts in.
LINKREPROFULLPATHRSP Generates a response file containing the absolute paths to all
the files that the linker took as input.
/LINKREPROTARGET Generates a link repro only when producing the specified
target.
/LTCG Specifies link-time code generation.
/MACHINE Specifies the target platform.
/MANIFEST Creates a side-by-side manifest file and optionally embeds it
in the binary.
/MANIFESTDEPENDENCY Specifies a <dependentAssembly> section in the manifest file.
/MANIFESTFILE Changes the default name of the manifest file.
/MANIFESTINPUT Specifies a manifest input file for the linker to process and
embed in the binary. You can use this option multiple times to
specify more than one manifest input file.
/MANIFESTUAC Specifies whether User Account Control (UAC) information is
embedded in the program manifest.
/MAP Creates a mapfile.
/MAPINFO Includes the specified information in the mapfile.
/MERGE Combines sections.
/MIDL Specifies MIDL command-line options.
/NATVIS Adds debugger visualizers from a Natvis file to the program
database (PDB).
/NOASSEMBLY Suppresses the creation of a .NET Framework assembly.
/NODEFAULTLIB Ignores all (or the specified) default libraries when external
references are resolved.
/NOENTRY Creates a resource-only DLL.
16.1
Option Purpose
/NOFUNCTIONPADSECTION Disables function padding for functions in the specified
section.
/NOLOGO Suppresses the startup banner.
/NXCOMPAT Marks an executable as verified to be compatible with the
Windows Data Execution Prevention feature.
/OPT Controls LINK optimizations.
/ORDER Places COMDATs into the image in a predetermined order.
/OUT Specifies the output file name.
/PDB Creates a PDB file.
/PDBALTPATH Uses an alternate location to save a PDB file.
/PDBSTRIPPED Creates a PDB file that has no private symbols.
/PGD Specifies a .pgd file for profile-guided optimizations.
/POGOSAFEMODE Obsolete Creates a thread-safe PGO instrumented build.
/PROFILE Produces an output file that can be used with the Performance
Tools profiler.
/RELEASE Sets the Checksum in the .exe header.
/SAFESEH Specifies that the image will contain a table of safe exception
handlers.
/SECTION Overrides the attributes of a section.
/SOURCELINK Specifies a SourceLink file to add to the PDB.
/STACK Sets the size of the stack in bytes.
/STUB Attaches an MS-DOS stub program to a Win32 program.
/SUBSYSTEM Tells the operating system how to run the .exe file.
/SWAPRUN Tells the operating system to copy the linker output to a swap
file before it's run.
/TIME Output linker pass timing information.
/TLBID Specifies the resource ID of the linker-generated type library.
/TLBOUT Specifies the name of the .tlb file and other MIDL output
files.
17.8
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
Option Purpose
/TSAWARE Creates an application that is designed specifically to run
under Terminal Server.
/USEPROFILE Uses profile-guided optimization training data to create an
optimized image.
/VERBOSE Prints linker progress messages.
/VERSION Assigns a version number.
/WHOLEARCHIVE Includes every object file from specified static libraries.
/WINMD Enables generation of a Windows Runtime Metadata file.
/WINMDFILE Specifies the file name for the Windows Runtime Metadata
(winmd) output file that's generated by the /WINMD linker
option.
/WINMDKEYFILE Specifies a key or key pair to sign a Windows Runtime
Metadata file.
/WINMDKEYCONTAINER Specifies a key container to sign a Windows Metadata file.
/WINMDDELAYSIGN Partially signs a Windows Runtime Metadata ( .winmd ) file by
placing the public key in the winmd file.
/WX Treats linker warnings as errors.
 This option is available starting in Visual Studio 2019 version 16.1.
 This option is available starting in Visual Studio 2022 version 17.8.
C/C++ building reference
MSVC linker reference
16.1
17.8
See also
 Yes  No
Compiler-Controlled LINK Options
Article • 08/03/2021
The CL compiler automatically calls LINK unless you specify the /c option. CL provides
some control over the linker through command-line options and arguments. The
following table summarizes the features in CL that affect linking.
CL specification CL action that affects LINK
Any file name extension other than .c,
.cxx, .cpp, or .def
Passes a file name as input to LINK
filename.def Passes /DEF:filename.def
/Fnumber Passes /STACK:number
/Fdfilename Passes /PDB:filename
/Fefilename Passes /OUT:filename
/Fmfilename Passes /MAP:filename
/Gy Creates packaged functions (COMDATs); enables
function-level linking
/LD Passes /DLL
/LDd Passes /DLL
/link Passes remainder of command line to LINK
/MD or /MT Places a default library name in the .obj file
/MDd or /MTd Places a default library name in the .obj file. Defines
the symbol _DEBUG
/nologo Passes /NOLOGO
/Zd Passes /DEBUG
/Zi or /Z7 Passes /DEBUG
/Zl Omits default library name from .obj file
For more information, see MSVC Compiler Options.
See also
MSVC linker reference
MSVC Linker Options
LINK input files
Article • 09/08/2022
You provide the linker with files that contain objects, import and standard libraries,
resources, module definitions, and command input. LINK doesn't use file extensions to
make assumptions about the contents of a file. Instead, LINK examines each input file to
determine what kind of file it is.
Object files on the command line are processed in the order they appear on the
command line. Libraries are searched in command line order as well, with the following
caveat: Symbols that are unresolved when bringing in an object file from a library are
searched for in that library first, and then the following libraries from the command line
and /DEFAULTLIB (Specify default library) directives, and then to any libraries at the
beginning of the command line.
７ Note
LINK no longer accepts a semicolon (or any other character) as the start of a
comment in response files and order files. Semicolons are recognized only as the
start of comments in module-definition files ( .def ).
LINK uses the following types of input files:
.obj files
.netmodule files
.lib files
.exp files
.def files
.pdb files
.res files
.exe files
.txt files
.ilk files
See also
MSVC linker reference
MSVC linker options
.Obj Files as Linker Input
Article • 08/03/2021
The linker tool (LINK.EXE) accepts .obj files that are in Common Object File Format
(COFF).
Remarks
Microsoft provides a complete description of the common object file format. For more
information, see PE Format.
Unicode support
Starting with Visual Studio 2005, the Microsoft MSVC compiler supports Unicode
characters in identifiers as defined by the ISO/IEC C and C++ standards. Previous
versions of the compiler supported only ASCII characters in identifiers. To support
Unicode in the names of functions, classes, and statics, the compiler and linker use the
Unicode UTF-8 encoding for COFF symbols in .obj files. The UTF-8 encoding is upwardly
compatible with the ASCII encoding used by earlier versions of Visual Studio.
For more information about the compiler and linker, see Unicode Support in the
Compiler and Linker. For more information about the Unicode standard, see the
Unicode organization.
See also
LINK Input Files
MSVC Linker Options
Support for Unicode
Unicode Support in the Compiler and Linker
Unicode standard
PE Format
.netmodule files as linker input
Article • 02/24/2023
link.exe accepts MSIL .obj and .netmodule files as input. The output file produced by
the linker is an assembly or a .netmodule file with no run-time dependency on any of
the .obj or .netmodule files that were input to the linker.
Remarks
.netmodule files are created by the MSVC compiler with /LN (Create MSIL module) or by
the linker with /NOASSEMBLY (Create a MSIL Module). .obj files are always created in a
C++ compilation. For other Visual Studio compilers, use the /target:module compiler
option.
The linker must be passed the .obj file from the C++ compilation that created the
.netmodule . Passing in a .netmodule is no longer supported because the /clr:pure and
/clr:safe compiler options are deprecated in Visual Studio 2015 and unsupported in
Visual Studio 2017 and later.
For information on how to invoke the linker from the command line, see Linker
command-line syntax and Use the MSVC toolset from the command line.
Passing a .netmodule or .dll file to the linker that was compiled by the MSVC compiler
with /clr can result in a linker error. For more information, see Choosing the format of
.netmodule input files.
The linker accepts both native .obj files and MSIL .obj files compiled with /clr. You can
pass mixed .obj files in the same build. The resulting output file's default verifiability is
the same as the lowest input module's verifiability.
You can change an application that's composed of two or more assemblies to be
contained in one assembly. Recompile the assemblies' sources, and then link the .obj
files or .netmodule files to produce a single assembly.
Specify an entry point using /ENTRY (Entry-point symbol) when creating an executable
image.
When linking with an MSIL .obj or .netmodule file, use /LTCG (Link-time code
generation), otherwise when the linker encounters the MSIL .obj or .netmodule , it will
restart the link with /LTCG. You'll see an informational message that the link is restarting.
You can ignore this message, but to improve linker performance, explicitly specify /LTCG.
MSIL .obj or .netmodule files can also be passed to cl.exe.
Input MSIL .obj or .netmodule files can't have embedded resources. Embed resources
in an output module or assembly file by using the /ASSEMBLYRESOURCE (Embed a
managed resource) linker option. Or, use the /resource compiler option in other Visual
Studio compilers.
In C++ code, the catch block of a corresponding try will be invoked for a non- System
exception. However, by default, the CLR wraps non- System exceptions with
RuntimeWrappedException. When an assembly is created from C++ and non-C++
modules, and you want a catch block in C++ code to be invoked from its
corresponding try clause when the try block throws a non- System exception, you
must add the
[assembly:System::Runtime::CompilerServices::RuntimeCompatibility(WrapNonExceptionT
hrows=false)] attribute to the source code for the non-C++ modules.
C++
By changing the Boolean value of the WrapNonExceptionThrows attribute, you modify the
ability of the C++ code to catch a non- System exception.
C#
Examples
// MSIL_linking.cpp
// compile with: /c /clr
value struct V {};
ref struct MCPP {
 static void Test() {
 try {
 throw (gcnew V);
 }
 catch (V ^) {
 System::Console::WriteLine("caught non System exception in C++
source code file");
 }
 }
};
/*
int main() {
 MCPP::Test();
}
*/
Output
LINK Input Files
MSVC Linker Options
// MSIL_linking_2.cs
// compile with: /target:module /addmodule:MSIL_linking.obj
// post-build command: link /LTCG MSIL_linking.obj MSIL_linking_2.netmodule
/entry:MLinkTest.Main /out:MSIL_linking_2.exe /subsystem:console
using System.Runtime.CompilerServices;
// enable non System exceptions
[assembly:RuntimeCompatibility(WrapNonExceptionThrows=false)]
class MLinkTest {
 public static void Main() {
 try {
 MCPP.Test();
 }
 catch (RuntimeWrappedException) {
 System.Console.WriteLine("caught a wrapped exception in C#");
 }
 }
}
caught non System exception in C++ source code file
See also
Choosing the Format of .netmodule
Input Files
Article • 08/03/2021
An MSIL .obj file (compiled with /clr) can also be used as a .netmodule file. .obj files
contain metadata and native symbols. .netmodules only contain metadata.
You can pass an MSIL .obj file to any other Visual Studio compiler via the /addmodule
compiler option (but be aware that the .obj file becomes part of the resulting assembly
and must be shipped with the assembly). For example, Visual C# and Visual Basic have
the /addmodule compiler option.
７ Note
In most cases, you will need to pass to the linker the .obj file from the compilation
that created the .net module. Passing a .dll or .netmodule MSIL module file to the
linker may result in LNK1107.
.obj files, along with their associated .h files, which you reference via #include in source,
allow C++ applications to consume the native types in the module, whereas in a
.netmodule file, only the managed types can be consumed by a C++ application. If you
attempt to pass a .obj file to #using, information about native types will not be available;
#include the .obj file's .h file instead.
Other Visual Studio compilers can only consume managed types from a module.
Use the following to determine whether you need to use a .netmodule or a .obj file as
module input to the MSVC linker:
If you are building with a Visual Studio compiler other than Visual C++, produce a
.netmodule and use the .netmodule as input to the linker.
If you are using the MSVC compiler to produce modules and if the module(s) will
be used to build something other than a library, use the .obj files produced by the
compiler as module input to the linker; do not use the .netmodule file as input.
If your modules will be used to build a native (not a managed) library, use .obj files
as module input to the linker and generate a .lib library file.
If your modules will be used to build a managed library, and if all module input to
the linker will be verifiable (produced with /clr:safe), use .obj files as module input
to the linker and generate a .dll (assembly) or .netmodule (module) library file.
If your modules will be used to build a managed library, and if one or more
modules input to the linker will be produced with just /clr, use .obj files as module
input to the linker and generate a .dll (assembly). If you want to expose managed
types from the library and if you also want C++ applications to consume the native
types in the library, your library will consist of the .obj files for the libraries
component modules (you will also want to ship the .h files for each module, so
they can be referenced with #include from source code).
See also
.netmodule Files as Linker Input
.lib files as linker input
Article • 09/22/2022
LINK accepts COFF standard libraries and COFF import libraries, both of which usually
have the extension .lib . Standard libraries contain objects and are created by the LIB
tool. Import libraries contain information about exports in other programs and are
created either by LINK when it builds a program that contains exports or by the LIB tool.
For information on using LIB to create standard or import libraries, see LIB Reference.
For details on using LINK to create an import library, see the /DLL option.
A library is specified to LINK as either a file name argument or a default library. LINK
resolves external references by searching first in libraries specified on the command line,
then in default libraries specified with the /DEFAULTLIB option, and then in default
libraries named in .obj files. If a path is specified with the library name, LINK looks for
the library in that directory. If no path is specified, LINK looks first in the directory that
LINK is running from, and then in any directories specified in the LIB environment
variable.
To add .lib files as linker input in the
development environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Choose the Configuration Properties > Linker > Input property page.
3. Modify the Additional Dependencies property to add the .lib files.
4. Choose OK or Apply to save your changes.
To programmatically add .lib files as linker
input
See AdditionalDependencies.
Example
The following sample shows how to build and use a .lib file.
First, build the .lib file:
C++
And then, compile this sample by using the .lib file you just created:
C++
Output
LINK input files
MSVC linker options
// lib_link_input_1.cpp
// compile by using: cl /LD lib_link_input_1.cpp
__declspec(dllexport) int Test() {
 return 213;
}
// lib_link_input_2.cpp
// compile by using: cl /EHsc lib_link_input_1.lib lib_link_input_2.cpp
__declspec(dllimport) int Test();
#include <iostream>
int main() {
 std::cout << Test() << std::endl;
}
213
See also
.Exp Files as Linker Input
Article • 08/03/2021
Export (.exp) files contain information about exported functions and data items. When
LIB creates an import library, it also creates an .exp file. You use the .exp file when you
link a program that both exports to and imports from another program, either directly
or indirectly. If you link with an .exp file, LINK does not produce an import library,
because it assumes that LIB already created one. For details about .exp files and import
libraries, see Working with Import Libraries and Export Files.
See also
LINK Input Files
MSVC Linker Options
.Def Files as Linker Input
Article • 08/03/2021
See Module-definition (.def) files for more information. Use the /DEF option to specify
the .def file name.
See also
LINK Input Files
MSVC Linker Options
.Pdb Files as Linker Input
Article • 08/03/2021
Object (.obj) files compiled using the /Zi option contain the name of a program
database (PDB). You do not specify the object's PDB file name to the linker; LINK uses
the embedded name to find the PDB if it is needed. This also applies to debuggable
objects contained in a library; the PDB for a debuggable library must be available to the
linker along with the library.
LINK also uses a PDB to hold debugging information for the .exe file or the .dll file. The
program's PDB is both an output file and an input file, because LINK updates the PDB
when it rebuilds the program.
See also
LINK Input Files
MSVC Linker Options
.Res Files as Linker Input
Article • 08/03/2021
You can specify a .res file when linking a program. The .res file is created by the resource
compiler (RC). LINK automatically converts .res files to COFF. The CVTRES.exe tool must
be in the same directory as LINK.exe or in a directory specified in the PATH environment
variable.
See also
LINK Input Files
MSVC Linker Options
.Exe Files as Linker Input
Article • 08/03/2021
The MS-DOS Stub File Name (/STUB) option specifies the name of an .exe file that runs
with MS-DOS. LINK examines the specified file to be sure that it is a valid MS-DOS
program.
See also
LINK Input Files
MSVC Linker Options
.Txt Files as Linker Input
Article • 08/03/2021
LINK expects various text files as additional input. The command-file specifier (@) and
the Base Address (/BASE), /DEF, and /ORDER options all specify text files. These files can
have any extension, not just .txt.
See also
LINK Input Files
MSVC Linker Options
.ilk files as linker input
Article • 09/08/2022
The linker creates and uses a .ilk database file for incremental link information.
Remarks
When linking incrementally, LINK updates the .ilk status file that it created during the
first incremental link. This file has the same base name as the target EXE or DLL file, and
it has the extension .ilk . During subsequent incremental links, LINK updates the .ilk
file. If the .ilk file is missing, LINK performs a full link and creates a new .ilk file. If the
.ilk file is unusable, LINK performs a non-incremental link. For more information about
incremental linking, see the /INCREMENTAL (Link incrementally) linker option. For
information about how to specify the name and location of the file, see /ILK (Name
incremental database file).
See also
LINK input files
MSVC linker options
LINK Output
Article • 08/03/2021
Link output includes .exe files, DLLs, mapfiles, and messages.
Output Files
The default output file from LINK is an .exe file. If the /DLL option is specified, LINK
builds a .dll file. You can control the output file name with the Output File Name (/OUT)
option.
In incremental mode, LINK creates an .ilk file to hold status information for later
incremental builds of the program. For details about .ilk files, see .ilk Files. For more
information about incremental linking, see the Link Incrementally (/INCREMENTAL)
option.
When LINK creates a program that contains exports (usually a DLL), it also builds a .lib
file, unless an .exp file was used in the build. You can control the import library file name
with the /IMPLIB option.
If the Generate Mapfile (/MAP) option is specified, LINK creates a mapfile.
If the Generate Debug Info (/DEBUG) option is specified, LINK creates a PDB to contain
debugging information for the program.
Other Output
When you type link without any other command-line input, LINK displays a usage
statement that summarizes its options.
LINK displays a copyright and version message and echoes command-file input, unless
the Suppress Startup Banner (/NOLOGO) option is used.
You can use the Print Progress Messages (/VERBOSE) option to display additional details
about the build.
LINK issues error and warning messages in the form LNKnnnn. This error prefix and
range of numbers are also used by LIB, DUMPBIN, and EDITBIN.
See also
MSVC linker reference
MSVC Linker Options
Reserved words
Article • 08/03/2021
The following words are reserved by the linker. These names can be used as arguments
in module-definition statements only if the name is enclosed in double quotation marks
("").
APPLOADER
BASE
CODE
CONFORMING
DATA
DESCRIPTION
DEV386
DISCARDABLE
DYNAMIC
EXECUTE-ONLY
EXECUTEONLY
EXECUTEREAD
EXETYPE
EXPORTS
FIXED
FUNCTIONS
HEAPSIZE
IMPORTS
IMPURE
INCLUDE
INITINSTANCE
IOPL
LIBRARY
LOADONCALL
LONGNAMES
MOVABLE
MOVEABLE
MULTIPLE
1
1
2
1
2
2
1
1
2
1
1
NAME
NEWFILES
NODATA
NOIOPL
NONAME
NONCONFORMING
NONDISCARDABLE
NONE
NONSHARED
NOTWINDOWCOMPAT
OBJECTS
OLD
PRELOAD
PRIVATE
PROTMODE
PURE
READONLY
READWRITE
REALMODE
RESIDENT
RESIDENTNAME
SECTIONS
SEGMENTS
SHARED
SINGLE
STACKSIZE
STUB
VERSION
WINDOWAPI
WINDOWCOMPAT
WINDOWS
 The linker emits a warning ("ignored") when it encounters this term. However, the
word is still reserved.
 The linker ignores this word but emits no warning.
2
1
1
1
1
1
2
1
1
1
1
2
See also
MSVC linker reference
MSVC Linker Options
@ (Specify a linker response file)
Article • 05/18/2022
Specifies a linker response file.
Syntax
@ response_file
Arguments
response_file
A text file that contains linker commands.
Remarks
For more information, see @ (Specify a compiler response file).
To set this linker option in the Visual Studio development
environment
This linker option isn't available from the Visual Studio development environment.
To set this linker option programmatically
This linker option can't be changed programmatically.
See also
MSVC linker reference
MSVC linker options
/ALIGN (Section alignment)
Article • 05/18/2022
Specify the alignment of each section within the executable image.
Syntax
/ALIGN [ : number ]
Arguments
number
The alignment value in bytes.
Remarks
The /ALIGN linker option specifies the alignment of each section within the linear
address space of the program. The number argument is in bytes and must be a power of
two. The default is 4K (4096). The linker issues a warning if the alignment produces an
invalid image.
Unless you're writing an application such as a device driver, you shouldn't need to
modify the alignment.
It's possible to modify the alignment of a particular section with the align parameter to
the /SECTION option.
The alignment value that you specify can't be smaller than the largest section alignment.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Choose the Configuration Properties > Linker > Command Line property page.
3. Enter the option in the Additional Options box. Choose OK or Apply to apply the
change.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/ALLOWBIND (Prevent DLL binding)
Article • 05/18/2022
Set a flag to disallow DLL binding.
Syntax
/ALLOWBIND [ :NO ]
Remarks
The /ALLOWBIND:NO linker option sets a bit in a DLL's header that indicates to Bind.exe
that the image can't be bound. You may not want a DLL to be bound if it's been digitally
signed (binding invalidates the signature).
You can edit an existing DLL for /ALLOWBIND functionality with the /ALLOWBIND option
of the EDITBIN utility.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter /ALLOWBIND:NO into Additional Options. Choose OK or Apply to apply the
change.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
BindImage function
BindImageEx function
/ALLOWISOLATION (Manifest lookup)
Article • 05/18/2022
Specifies behavior for manifest lookup.
Syntax
/ALLOWISOLATION [ :NO ]
Remarks
The /ALLOWISOLATION:NO linker option indicates DLLs are loaded as if there was no
manifest and causes the linker to set the IMAGE_DLLCHARACTERISTICS_NO_ISOLATION bit in
the optional header's DllCharacteristics field.
/ALLOWISOLATION causes the operating system to do manifest lookups and loads.
/ALLOWISOLATION is the default.
When isolation is disabled for an executable, the Windows loader won't attempt to find
an application manifest for the newly created process. The new process won't have a
default activation context, even if there's a manifest inside the executable or placed in
the same directory as the executable with name <executable-name>.exe.manifest .
For more information, see Manifest files reference.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Manifest File property page.
3. Modify the Allow Isolation property.
See also
MSVC linker reference
MSVC linker options
/APPCONTAINER (Microsoft Store app)
Article • 05/18/2022
Specifies whether the linker creates an executable image that must run in an
AppContainer environment.
Syntax
/APPCONTAINER [ :NO ]
Remarks
The /APPCONTAINER linker option modifies an executable to indicate whether the app
must run in the AppContainer process-isolation environment. Specify /APPCONTAINER for
an app that must run in the AppContainer environment—for example, a Universal
Windows Platform (UWP) or Windows Phone 8.x app. The option is set automatically in
Visual Studio when you create a Universal Windows app from a template. For a desktop
app, specify /APPCONTAINER:NO or just omit the option. By default, /APPCONTAINER is off.
The /APPCONTAINER option was introduced in Windows 8.
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In Additional Options, enter /APPCONTAINER or /APPCONTAINER:NO .
See also
MSVC linker reference
MSVC linker options
/ARM64XFUNCTIONPADMINX64
(Minimum x64 function padding)
Article • 01/10/2024
Specifies the minimum number of bytes of padding between x64 functions in ARM64X
images.
Syntax
/ARM64XFUNCTIONPADMINX64:[number]
Arguments
number
The minimum number of bytes of padding between x64 functions.
Remarks
This switch ensures that there is at least as much padding between X64 functions in an
ARM64X image as specified. There may be more padding to meet architecture
alignment requirements.
This flag is available in Visual Studio 17.8 and later.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Modify the Additional Options property to include
/ARM64XFUNCTIONPADMINX64: number , where number is the minimum number
of bytes of padding to put between x64 functions, and then choose OK.
To set this linker option programmatically
See AdditionalOptions.
See also
/FUNCTIONPADMIN (Create hotpatchable image)
/NOFUNCTIONPADSECTION
MSVC Linker Options
MSVC linker reference
/ASSEMBLYDEBUG (Add
DebuggableAttribute)
Article • 05/18/2022
Specify whether to emit the DebuggableAttribute attribute with debug information
tracking and to disable JIT optimizations.
Syntax
/ASSEMBLYDEBUG [ :DISABLE ]
Remarks
The /ASSEMBLYDEBUG linker option emits the DebuggableAttribute attribute with debug
information tracking and disables JIT optimizations. This option is the same as specifying
the following attribute in source:
C++
[assembly:Debuggable(true, true)]; // same as /ASSEMBLYDEBUG
/ASSEMBLYDEBUG:DISABLE emits the DebuggableAttribute attribute but disables the
tracking of debug information and enables JIT optimizations. This option is the same as
specifying the following attribute in source:
C++
[assembly:Debuggable(false, false)]; // same as /ASSEMBLYDEBUG:DISABLE
By default, the linker doesn't emit the DebuggableAttribute attribute.
DebuggableAttribute can also be added to an assembly directly in source code. For
example:
C++
[assembly:Debuggable(true, true)]; // same as /ASSEMBLYDEBUG
You must explicitly specify that a managed image is debuggable. The /Zi option alone is
insufficient.
Other linker options that affect assembly generation are:
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/DELAYSIGN
/KEYCONTAINER
/KEYFILE
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Debug property page.
3. Modify the Debuggable Assembly property.
To set this linker option programmatically
See AssemblyDebug.
See also
MSVC linker reference
MSVC linker options
/ASSEMBLYLINKRESOURCE (Link to .NET
Framework resource)
Article • 05/18/2022
Create a link to a .NET Framework resource in the output file.
Syntax
/ASSEMBLYLINKRESOURCE: filename
Arguments
filename The .NET Framework resource file to link from the assembly.
Remarks
The /ASSEMBLYLINKRESOURCE linker option creates a link to a .NET Framework resource in
the output file. The resource file isn't placed in the output file. Use the
/ASSEMBLYRESOURCE option to embed a resource file in the output file.
Linked resources are public in the assembly when created with the linker.
/ASSEMBLYLINKRESOURCE requires the /clr compiler option. The /LN or /NOASSEMBLY
options aren't allowed with /ASSEMBLYLINKRESOURCE .
If filename is a .NET Framework resource file that's created, for example, by Resgen.exe
or in the development environment, it can be accessed with members in the
System.Resources namespace. For more information, see
System.Resources.ResourceManager. For all other resources, use the
GetManifestResource* methods in the System.Reflection.Assembly class to access the
resource at run time.
filename can have any file format. For example, you may want to make a native DLL
part of the assembly. Then it can be installed into the Global Assembly Cache and
accessed from managed code in the assembly.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/DELAYSIGN
/KEYCONTAINER
/KEYFILE
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option in Additional Options. Choose OK or Apply to apply the change.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/ASSEMBLYMODULE (Add an MSIL module
to the assembly)
Article • 05/18/2022
Syntax
/ASSEMBLYMODULE: filename
Arguments
filename
The module you want to include in this assembly.
Remarks
The /ASSEMBLYMODULE linker option allows you to add a module reference to an
assembly. Type information in the module won't be available to the assembly program
that added the module reference. However, type information in the module will be
available to any program that references the assembly.
Use #using to both add a module reference to an assembly and make the module's type
information available to the assembly program.
For example, consider the following scenario:
1. Create a module with /LN.
2. Use /ASSEMBLYMODULE in a different project to include the module in the current
compilation, which creates an assembly. This project won't reference the module
with #using .
3. Any project that references this assembly can now also use types from the module.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYRESOURCE
/DELAYSIGN
/NOASSEMBLY
/KEYFILE
/KEYCONTAINER
The MSVC linker accepts .netmodule files as input and the output file produced by the
linker will be an assembly or .netmodule file with no run-time dependence on any of the
.netmodule files that were input to the linker. For more information, see .netmodule files
as linker input.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Input property page.
3. Modify the Add Module to Assembly property.
To set this linker option programmatically
See AddModuleNamesToAssembly.
See also
MSVC linker reference
MSVC linker options
/ASSEMBLYRESOURCE (Embed a managed
resource)
Article • 05/18/2022
Embeds a managed resource in an assembly.
Syntax
/ASSEMBLYRESOURCE: filename [ , [ name ][ ,PRIVATE ]]
Arguments
filename
The managed resource you want to embed in this assembly.
name
Optional. The logical name for the resource; the name used to load the resource. The
default is the name of the file.
Optionally, you can use PRIVATE to specify if the file should be private in the assembly
manifest. By default, name is public in the assembly.
Remarks
Use the /ASSEMBLYRESOURCE linker option to embed a resource in an assembly.
Resources are public in the assembly when created with the linker. The linker doesn't
allow you to rename the resource in the assembly.
If filename is a .NET Framework resource ( .resources ) file created, for example, by the
Resource file generator (Resgen.exe) or in the development environment, it can be
accessed with members in the System.Resources namespace. For more information, see
System.Resources.ResourceManager. For all other resources, use the
GetManifestResource* methods in the System.Reflection.Assembly class to access the
resource at run time.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/DELAYSIGN
/KEYFILE
/KEYCONTAINER
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Input property page.
3. Modify the Embed Managed Resource File property.
To set this linker option programmatically
1. See EmbedManagedResourceFile.
See also
MSVC linker reference
MSVC linker options
/BASE (Base address)
Article • 05/18/2022
Specifies the base address for a program.
Syntax
/BASE: { address [ , size ] | @ filename , key }
Remarks
７ Note
For security reasons, Microsoft recommends you use the /DYNAMICBASE option
instead of specifying base addresses for your executables. /DYNAMICBASE generates
an executable image that can be randomly rebased at load time by using the
address space layout randomization (ASLR) feature of Windows. The /DYNAMICBASE
option is on by default.
The /BASE linker option sets a base address for the program. It overrides the default
location for an EXE or DLL file. The default base address for an EXE file is 0x400000 for
32-bit images or 0x140000000 for 64-bit images. For a DLL, the default base address is
0x10000000 for 32-bit images or 0x180000000 for 64-bit images. On operating systems
that don't support address space layout randomization (ASLR), or when the
/DYNAMICBASE:NO option was set, the operating system first attempts to load a program
at its specified or default base address. If insufficient space is available there, the system
relocates the program. To prevent relocation, use the /FIXED option.
The linker issues an error if address isn't a multiple of 64K. You can optionally specify
the size of the program. The linker issues a warning if the program can't fit in the size
you specified.
On the command line, another way to specify the base address is by using a base
address response file. A base address response file is a text file that contains the base
addresses and optional sizes of all the DLLs your program uses, and a unique text key
for each base address. To specify a base address by using a response file, use an at sign
( @ ) followed by the name of the response file, filename , followed by a comma, then the
key value for the base address to use in the file. The linker looks for filename in either
the specified path, or if no path is specified, in the directories specified in the LIB
environment variable. Each line in filename represents one DLL and has the following
syntax:
key address [ size ] ; comment
The key is a string of alphanumeric characters and isn't case sensitive. It's usually the
name of a DLL, but that's not required. The key is followed by a base address in C￾language, hexadecimal, or decimal notation and an optional maximum size . All three
arguments are separated by spaces or tabs. The linker issues a warning if the specified
size is less than the virtual address space required by the program. A comment is
specified by a semicolon ( ; ) and can be on the same or a separate line. The linker
ignores all text from the semicolon to the end of the line. This example shows part of
such a file:
txt
main 0x00010000 0x08000000 ; for PROJECT.exe
one 0x28000000 0x00100000 ; for DLLONE.DLL
two 0x28100000 0x00300000 ; for DLLTWO.DLL
If the file that contains these lines is called DLLS.txt, the following example command
applies this information:
Windows Command Prompt
link dlltwo.obj /dll /base:@dlls.txt,two
Another way to set the base address is by using the BASE argument in a NAME or
LIBRARY statement. The /BASE and /DLL options together are equivalent to the LIBRARY
statement.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Base Address property.
To set this linker option programmatically
See BaseAddress.
See also
MSVC linker reference
MSVC linker options
/CETCOMPAT (CET Shadow Stack
compatible)
Article • 09/22/2022
Specifies whether the linker marks an executable image as compatible with Control-flow
Enforcement Technology (CET) Shadow Stack.
Syntax
/CETCOMPAT
/CETCOMPAT:NO
Arguments
NO
Specifies that the executable shouldn't be marked compatible with CET Shadow Stack.
Remarks
Control-flow Enforcement Technology (CET) Shadow Stack is a computer processor
feature. It provides capabilities to defend against return-oriented programming (ROP)
based malware attacks. For more information, see A Technical Look at Intel's Control￾flow Enforcement Technology .
The /CETCOMPAT linker option tells the linker to mark the binary as CET Shadow Stack￾compatible. /CETCOMPAT:NO marks the binary as not compatible with CET Shadow Stack.
If both options are specified on the command line, the last one specified is used. This
switch is currently only applicable to x86 and x64 architectures.
The /CETCOMPAT option is available beginning in Visual Studio 2019.
To set the /CETCOMPAT linker option in Visual Studio
Starting in Visual Studio 2019 version 16.7:
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Select the CET Shadow Stack Compatible property.
4. In the dropdown control, choose Yes (/CETCOMPAT) to mark the binary as CET
Shadow Stack compatible, or No (/CETCOMPAT:NO) to mark it as non-compatible.
In previous versions of Visual Studio 2019:
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In the Additional Options edit control, add /CETCOMPAT to mark the binary as CET
Shadow Stack compatible, or /CETCOMPAT:NO to explicitly mark it as non￾compatible.
To set this linker option programmatically
This option doesn't have a programmatic equivalent.
See also
Linker options
/CGTHREADS (Compiler Threads)
Article • 08/03/2021
Sets the number of cl.exe threads to use for optimization and code generation when
link-time code generation is specified.
Syntax
/CGTHREADS:[1-8]
Arguments
number
The maximum number of threads for cl.exe to use, in the range 1 to 8.
Remarks
The /CGTHREADS option specifies the maximum number of threads cl.exe uses in
parallel for the optimization and code-generation phases of compilation when link-time
code generation (/LTCG) is specified. By default, cl.exe uses four threads, as if
/CGTHREADS:4 were specified. If more processor cores are available, a larger number
value can improve build times.
Multiple levels of parallelism can be specified for a build. The msbuild.exe switch
/maxcpucount specifies the number of MSBuild processes that can be run in parallel.
The /MP (Build with Multiple Processes) compiler flag specifies the number of cl.exe
processes that simultaneously compile the source files. The /cgthreads compiler option
specifies the number of threads used by each cl.exe process. Because the processor can
only run as many threads at the same time as there are processor cores, it's not useful to
specify larger values for all of these options at the same time, and it can be
counterproductive. For more information about how to build projects in parallel, see
Building Multiple Projects in Parallel.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Modify the Additional Options property to include /CGTHREADS: number , where
number is a value from 1 to 8, and then choose OK.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC Linker Options
MSVC linker reference
/CLRIMAGETYPE (Specify Type of CLR
Image)
Article • 08/03/2021
Set the CLR image type in the linked image.
Syntax
/CLRIMAGETYPE:{IJW|PURE|SAFE|SAFE32BITPREFERRED}
Remarks
The linker accepts native objects and also MSIL objects that are compiled by using /clr.
The /clr:pure and /clr:safe compiler options were deprecated in Visual Studio 2015 and
are unsupported in Visual Studio 2017 and later. When mixed objects in the same build
are passed, the verifiability of the resulting output file is, by default, equal to the lowest
level of verifiability of the input modules. For example, if you pass a native image and a
mixed mode image (compiled by using /clr), the resulting image will be a mixed mode
image.
You can use /CLRIMAGETYPE to specify a lower level of verifiability, if that is what you
need.
For information about how to determine the CLR image type of a file, see /CLRHEADER.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the CLR Image Type property.
To set this linker option programmatically
1. See CLRImageType.
See also
MSVC linker reference
MSVC Linker Options
/CLRSUPPORTLASTERROR (Preserve Last
Error Code for PInvoke Calls)
Article • 09/22/2022
/CLRSUPPORTLASTERROR , which is on by default, preserves the last error code of functions
called through the P/Invoke mechanism, which allows you to call native functions in
DLLS, from code compiled with /clr .
Syntax
/CLRSUPPORTLASTERROR
/CLRSUPPORTLASTERROR:NO
/CLRSUPPORTLASTERROR:SYSTEMDLL
Remarks
Preserving the last error code implies a decrease in performance. If you don't want to
incur the performance cost of preserving the last error code, link by using
/CLRSUPPORTLASTERROR:NO .
You can minimize the performance penalty by linking with
/CLRSUPPORTLASTERROR:SYSTEMDLL , which only preserves the last error code for functions
in system DLLs.
７ Note
Preserving the last error isn't supported for unmanaged functions that are
consumed by CLR code in the same module.
For more information, see /clr (Common Language Runtime Compilation).
To set this linker option in the Visual Studio development
environment
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Preserve Last Error Code for PInvoke Calls property. Choose OK or
Apply to save your changes.
See AdditionalOptions.
The following sample defines a native DLL with one exported function that modifies last
error.
C++
The following sample consumes the DLL, demonstrating how to use
/CLRSUPPORTLASTERROR .
C++
To set this linker option programmatically
Examples
// CLRSUPPORTLASTERROR_dll.cpp
// compile with: /LD
#include <windows.h>
#include <math.h>
#pragma unmanaged
__declspec(dllexport) double MySqrt(__int64 n) {
 SetLastError(DWORD(-1));
 return sqrt(double(n));
}
// CLRSUPPORTLASTERROR_client.cpp
// compile with: /clr CLRSUPPORTLASTERROR_dll.lib /link
/clrsupportlasterror:systemdll
// processor: x86
#include <windows.h>
#include <wininet.h>
#include <stdio.h>
#include <math.h>
#pragma comment(lib, "wininet.lib")
double MySqrt(__int64 n);
#pragma managed
int main() {
 double d = 0.0;
 __int64 n = 65;
 HANDLE hGroup = NULL;
Output
MSVC linker reference
MSVC linker options
 GROUPID groupID;
 DWORD dwSet = 127, dwGet = 37;
 SetLastError(dwSet);
 d = MySqrt(n);
 dwGet = GetLastError();
 if (dwGet == DWORD(-1))
 printf_s("GetLastError for application call succeeded (%d).\n",
 dwGet);
 else
 printf_s("GetLastError for application call failed (%d).\n",
 dwGet);
 hGroup = FindFirstUrlCacheGroup(0, CACHEGROUP_SEARCH_ALL,
 0, 0, &groupID, 0);
 dwGet = GetLastError();
 if (dwGet == 183)
 printf_s("GetLastError for system call succeeded (%d).\n",
 dwGet);
 else
 printf_s("GetLastError for system call failed (%d).\n",
 dwGet);
}
GetLastError for application call failed (127).
GetLastError for system call succeeded (183).
See also
/CLRTHREADATTRIBUTE (Set CLR
Thread Attribute)
Article • 08/03/2021
Explicitly specify the threading attribute for the entry point of your CLR program.
Syntax
/CLRTHREADATTRIBUTE:{STA|MTA|NONE}
Parameters
MTA
Applies the MTAThreadAttribute attribute to the entry point of your program.
NONE
Same as not specifying /CLRTHREADATTRIBUTE. Lets the Common Language Runtime
(CLR) set the default threading attribute.
STA
Applies the STAThreadAttribute attribute to the entry point of your program.
Remarks
Setting the thread attribute is only valid when building an .exe, as it affects the entry
point of the main thread.
If you use the default entry point (main or wmain, for example) specify the threading
model either by using /CLRTHREADATTRIBUTE or by placing the threading attribute
(STAThreadAttribute or MTAThreadAttribute) on the default entry function.
If you use a non-default entry point, specify the threading model either by using
/CLRTHREADATTRIBUTE or by placing the threading attribute on the non-default entry
function, and then specify the non-default entry point with /ENTRY.
If the threading model specified in source code does not agree with the threading
model specified with /CLRTHREADATTRIBUTE, the linker will ignore
/CLRTHREADATTRIBUTE and apply the threading model specified in source code.
It will be necessary for you to use single-threading, for example, if your CLR program
hosts a COM object that uses single-threading. If your CLR program uses multi￾threading, it cannot host a COM object that uses single-threading.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the CLR Thread Attribute property.
To set this linker option programmatically
1. See CLRThreadAttribute.
See also
MSVC linker reference
MSVC Linker Options
/CLRUNMANAGEDCODECHECK (Remove
SuppressUnmanagedCodeSecurityAttrib
ute)
Article • 03/02/2023
/CLRUNMANAGEDCODECHECK specifies that the linker doesn't apply
SuppressUnmanagedCodeSecurityAttribute to linker-generated PInvoke calls from
managed code into native DLLs.
Syntax
/CLRUNMANAGEDCODECHECK
/CLRUNMANAGEDCODECHECK:NO
Remarks
By default, the linker applies the SuppressUnmanagedCodeSecurityAttribute attribute to
linker-generated PInvoke calls. When /CLRUNMANAGEDCODECHECK is in effect,
SuppressUnmanagedCodeSecurityAttribute is removed. To explicitly apply the
SuppressUnmanagedCodeSecurityAttribute attribute to linker-generated PInvoke calls,
you can use /CLRUNMANAGEDCODECHECK:NO .
The linker only adds the attribute to objects that are compiled using /clr or /clr:pure .
However, the /clr:pure compiler option is deprecated in Visual Studio 2015 and
unsupported in Visual Studio 2017 and later.
A PInvoke call is generated by the linker when the linker can't find a managed symbol to
satisfy a reference from a managed caller but can find a native symbol to satisfy that
reference. For more information about PInvoke , see Calling Native Functions from
Managed Code.
If you use AllowPartiallyTrustedCallersAttribute in your code, you should explicitly set
/CLRUNMANAGEDCODECHECK to remove the SuppressUnmanagedCodeSecurity attribute. It's a
potential security vulnerability if an image contains both the
SuppressUnmanagedCodeSecurity and AllowPartiallyTrustedCallers attributes.
For more information about the implications of using
SuppressUnmanagedCodeSecurityAttribute , see Secure Coding Guidelines for Unmanaged
Code.
To set this linker option in the Visual Studio development
environment
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the CLR Unmanaged Code Check property.
To set this linker option programmatically
1. See CLRUnmanagedCodeCheck.
See also
MSVC linker reference
MSVC linker options
/DEBUG (Generate debug info)
Article • 10/27/2023
The /DEBUG linker option creates a debugging information file for the executable.
Syntax
/DEBUG [ : { FASTLINK | FULL | NONE }]
Remarks
The /DEBUG option puts the debugging information from linked object and library files
into a program database (PDB) file. It updates the PDB during subsequent builds of the
program.
An executable (an EXE or DLL file) created for debugging contains the name and path of
the corresponding PDB. The debugger reads the embedded name and uses the PDB
when you debug the program. The linker uses the base name of the program and the
extension .pdb to name the program database, and embeds the path where it was
created. To override this default, set the /PDB option and specify a different file name.
The /DEBUG:FASTLINK option is available in Visual Studio 2017 and later. This option
generates a limited PDB that indexes into the debug information in the object files and
libraries used to build the executable instead of making a full copy. You can only use this
limited PDB to debug from the computer where the binary and its libraries were built. If
you deploy the binary elsewhere, you may debug it remotely from the build computer,
but not directly on the test computer. Despite its name, /DEBUG:FASTLINK is generally
slower than /DEBUG:FULL , so this option is not recommended.
A /DEBUG:FASTLINK PDB can be converted to a full PDB that you can deploy to a test
machine for local debugging. In Visual Studio, use the Property Pages dialog as
described below to create a full PDB for the project or solution. In a developer
command prompt, you can use the mspdbcmf.exe tool to create a full PDB.
The /DEBUG:FULL option moves all private symbol information from individual
compilation products (object files and libraries) into a single PDB, and can be the most
time-consuming part of the link. However, the full PDB can be used to debug the
executable when no other build products are available, such as when the executable is
deployed.
The /DEBUG:NONE option doesn't generate a PDB.
Specifying /DEBUG with no extra arguments is equivalent to specifying /DEBUG:FULL .
The compiler's /Z7 (C7 Compatible) option causes the compiler to leave the debugging
information in the object (OBJ) files. You can also use the /Zi (Program Database)
compiler option to store the debugging information in a PDB for the OBJ file. The linker
looks for the object's PDB first in the absolute path written in the OBJ file, and then in
the directory that contains the OBJ file. You can't specify an object's PDB file name or
location to the linker.
/INCREMENTAL is implied when /DEBUG is specified.
/DEBUG changes the defaults for the /OPT option from REF to NOREF and from ICF to
NOICF , so if you want the original defaults, you must explicitly specify /OPT:REF or
/OPT:ICF after the /DEBUG option.
It isn't possible to create an EXE or DLL that contains debug information. Debug
information is always placed in an OBJ or PDB file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Linker > Debugging property page.
3. Modify the Generate Debug Info property to enable or disable PDB generation.
This property enables /DEBUG:FASTLINK by default in Visual Studio 2017 and later.
4. Modify the Generate Full Program Database File property to enable /DEBUG:FULL
for full PDB generation for every incremental build.
To set this linker option programmatically
1. See GenerateDebugInformation.
See also
MSVC linker reference
MSVC linker options
/DEBUGTYPE (Debug Info Options)
Article • 08/03/2021
The /DEBUGTYPE option specifies the types of debugging information generated by the
/DEBUG option.
/DEBUGTYPE:[CV | PDATA | FIXUP]
Arguments
CV
Tells the linker to emit debug information for symbols, line numbers, and other object
compilation information in the PDB file. By default, this option is enabled when /DEBUG
is specified and /DEBUGTYPE is not specified.
PDATA
Tells the linker to add .pdata and .xdata entries to the debug stream information in the
PDB file. By default, this option is enabled when both the /DEBUG and /DRIVER options
are specified. If /DEBUGTYPE:PDATA is specified by itself, the linker automatically
includes debugging symbols in the PDB file. If /DEBUGTYPE:PDATA,FIXUP is specified,
the linker does not include debugging symbols in the PDB file.
FIXUP
Tells the linker to add relocation table entries to the debug stream information in the
PDB file. By default, this option is enabled when both the /DEBUG and /PROFILE options
are specified. If /DEBUGTYPE:FIXUP or /DEBUGTYPE:FIXUP,PDATA is specified, the linker
does not include debugging symbols in the PDB file.
Arguments to /DEBUGTYPE may be combined in any order by separating them with a
comma. The /DEBUGTYPE option and its arguments are not case sensitive.
Remarks
Use the /DEBUGTYPE option to specify inclusion of relocation table data or .pdata and
.xdata header information in the debugging stream. This causes the linker to include
information about user-mode code that is visible in a kernel debugger when breaking in
kernel-mode code. To make debugging symbols available when FIXUP is specified,
include the CV argument.
To debug code in user mode, which is typical for applications, the /DEBUGTYPE option
isn't needed. By default, the compiler switches that specify debugging output (/Z7, /Zi,
/ZI) emit all the information needed by the Visual Studio debugger. Use
/DEBUGTYPE:PDATA or /DEBUGTYPE:CV,PDATA,FIXUP to debug code that combines
user-mode and kernel-mode components, such as a configuration app for a device
driver. For more information about kernel mode debuggers, see Debugging Tools for
Windows (WinDbg, KD, CDB, NTSD)
See also
/DEBUG (Generate Debug Info)
/DRIVER (Windows NT Kernel Mode Driver)
/PROFILE (Performance Tools Profiler)
Debugging Tools for Windows (WinDbg, KD, CDB, NTSD)
/DEF (Specify module-definition file)
Article • 09/22/2022
Specifies a module-definition file to the linker.
Syntax
/DEF: filename
Arguments
filename
The name of a module-definition file ( .def ) to be passed to the linker.
Remarks
The /DEF linker option passes a module-definition file ( .def ) to the linker. Only one
.def file can be specified to LINK. For details about .def files, see Module-definition
files.
To specify a .def file from within the development environment, add it to the project
along with your other source files and then specify the file in the project's Property
Pages dialog.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Input property page.
3. Modify the Module Definition File property. Choose OK or Apply to save your
changes.
To set this linker option programmatically
See ModuleDefinitionFile.
See also
MSVC linker reference
MSVC Linker Options
/DEFAULTLIB (Specify Default Library)
Article • 08/03/2021
Specify a default library to search to resolve external references.
Syntax
/DEFAULTLIB:library
Arguments
library
The name of a library to search when resolving external references.
Remarks
The /DEFAULTLIB option adds one library to the list of libraries that LINK searches when
resolving references. A library specified with /DEFAULTLIB is searched after libraries
specified explicitly on the command line and before default libraries named in .obj files.
When used without arguments, the /NODEFAULTLIB (Ignore All Default Libraries) option
overrides all /DEFAULTLIB:library options. The /NODEFAULTLIB:library option overrides
/DEFAULTLIB:library when the same library name is specified in both.
To set this linker option in the Visual Studio development
environment
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In Additional Options, enter a /DEFAULTLIB:library option for each library to
search. Choose OK to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/DELAY (Delay load import settings)
Article • 09/22/2022
Linker options to control delayed loading of DLLs at runtime.
Syntax
/DELAY:UNLOAD
/DELAY:NOBIND
Remarks
The /DELAY option controls delayed loading of DLLs:
The /DELAY:UNLOAD qualifier tells the delay-load helper function to support explicit
unloading of the DLL. The Import Address Table (IAT) is reset to its original form,
invalidating IAT pointers and causing them to be overwritten.
If you don't select /DELAY:UNLOAD , any call to __FUnloadDelayLoadedDLL will fail.
The /DELAY:NOBIND qualifier tells the linker not to include a bindable IAT in the final
image. The default is to create the bindable IAT for delay-loaded DLLs. The
resulting image can't be statically bound. (Images with bindable IATs may be
statically bound before execution.) For more information, see /BIND.
If the DLL is bound, the helper function attempts to use the bound information
instead of calling GetProcAddress on each of the referenced imports. If either the
timestamp or the preferred address doesn't match the ones in the loaded DLL, the
helper function assumes the bound IAT is out of date. It continues as if the bound
IAT doesn't exist.
/DELAY:NOBIND causes your program image to be larger, but can speed load time
of the DLL. If you never intend to bind the DLL, /DELAY:NOBIND prevents the bound
IAT from being generated.
To specify DLLs to delay load, use the /DELAYLOAD option.
To set this linker option in the Visual Studio development
environment
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Unload delay loaded DLL property or the Unbind delay loaded DLL
property. Choose OK or Apply to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/DELAYLOAD (Delay Load Import)
Article • 08/03/2021
/DELAYLOAD:dllname
Parameters
dllname
The name of a DLL that you want to delay load.
Remarks
The /DELAYLOAD option causes the DLL that's specified by dllname to be loaded only
on the first call by the program to a function in that DLL. For more information, see
Linker Support for Delay-Loaded DLLs. You can use this option as many times as
necessary to specify as many DLLs as you choose. You must use Delayimp.lib when you
link your program, or you can implement your own delay-load helper function.
The /DELAY option specifies binding and loading options for each delay-loaded DLL.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. In the Linker folder, select the Input property page.
3. Modify the Delay Loaded DLLs property.
To set this linker option programmatically
See DelayLoadDLLs.
See also
MSVC linker reference
MSVC Linker Options
/DELAYSIGN (Partially Sign an
Assembly)
Article • 08/03/2021
/DELAYSIGN[:NO]
Arguments
NO
Specifies that the assembly should not be partially signed.
Remarks
Use /DELAYSIGN if you only want to place the public key in the assembly. The default is
/DELAYSIGN:NO.
The /DELAYSIGN option has no effect unless used with /KEYFILE or /KEYCONTAINER.
When you request a fully signed assembly, the compiler hashes the file that contains the
manifest (assembly metadata) and signs that hash with the private key. The resulting
digital signature is stored in the file that contains the manifest. When an assembly is
delay signed, the linker does not compute and store the signature, but reserves space in
the file so the signature can be added later.
For example, using /DELAYSIGN allows a tester to put the assembly in the global cache.
After testing, you can fully sign the assembly by placing the private key in the assembly.
See Strong Name Assemblies (Assembly Signing) (C++/CLI) and Delay Signing an
Assembly for more information on signing an assembly.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Click the Linker folder.
3. Click the Command Line property page.
4. Type the option into the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/DEPENDENTLOADFLAG (Set default
dependent load flags)
Article • 10/06/2021
Sets the default load flags used when the operating system resolves the statically linked
imports of a module.
Syntax
/DEPENDENTLOADFLAG[:load_flags]
Arguments
load_flags
An optional integer value that specifies the load flags to apply when resolving statically
linked import dependencies of the module. The default value is 0. For a list of supported
flag values, see the LOAD_LIBRARY_SEARCH_* entries in LoadLibraryEx.
Remarks
When the operating system resolves the statically linked imports of a module, it uses the
default search order. Use the /DEPENDENTLOADFLAG option to specify a load_flags
value that changes the search path used to resolve these imports. On supported
operating systems, it changes the static import resolution search order, similar to what
LoadLibraryEx does when using LOAD_LIBRARY_SEARCH parameters. For information on
the search order set by load_flags, see Search order using LOAD_LIBRARY_SEARCH flags.
This flag can be used to make one DLL planting attack vector more difficult. For
example, consider an app that has statically linked a DLL:
An attacker could plant a DLL with the same name earlier in the import resolution
search path, such as the application directory. Protected directories are more
difficult - but not impossible - for an attacker to change.
If the DLL is missing from the application, %windows%\system32, and %windows%
directories, import resolution falls through to the current directory. An attacker
could plant a DLL there.
In both cases, if you specify the link option /DEPENDENTLOADFLAG:0x800 (the value of the
flag LOAD_LIBRARY_SEARCH_SYSTEM32 ), then the module search path is limited to the
%windows%\system32 directory. It offers some protection from planting attacks on the
other directories. For more information, see Dynamic-Link Library Security.
To see the value set by the /DEPENDENTLOADFLAG option in any DLL, use the
DUMPBIN command with the /LOADCONFIG option.
The /DEPENDENTLOADFLAG option is new in Visual Studio 2017. It applies only to apps
running on Windows 10 RS1 and later Windows versions. This option is ignored by other
operating systems that run the app.
To set the DEPENDENTLOADFLAG linker option in the
Visual Studio development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option in Additional Options.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
Link an executable to a DLL implicitly
Determine which linking method to use
LoadLibraryEx
Dynamic-Link Library Search Order
Dynamic-Link Library Security
/DLL (Build a DLL)
Article • 08/03/2021
/DLL
Remarks
The /DLL option builds a DLL as the main output file. A DLL usually contains exports that
can be used by another program. There are three methods for specifying exports, listed
in recommended order of use:
1. __declspec(dllexport) in the source code
2. An EXPORTS statement in a .def file
3. An /EXPORT specification in a LINK command
A program can use more than one method.
Another way to build a DLL is with the LIBRARY module-definition statement. The /BASE
and /DLL options together are equivalent to the LIBRARY statement.
Do not specify this option within the development environment; this option is for use
only on the command line. This option is set when you create a DLL project with an
Application Wizard.
Note that if you create your import library in a preliminary step, before creating your .dll,
you must pass the same set of object files when building the .dll, as you passed when
building the import library.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Click the Configuration Properties folder.
3. Click the General property page.
4. Modify the Configuration Type property.
To set this linker option programmatically
See ConfigurationType.
See also
MSVC linker reference
MSVC Linker Options
/DRIVER (Windows NT Kernel Mode
Driver)
Article • 08/03/2021
/DRIVER[:UPONLY |:WDM]
Remarks
Use the /DRIVER linker option to build a Windows NT kernel mode driver.
/DRIVER:UPONLY causes the linker to add the IMAGE_FILE_UP_SYSTEM_ONLY bit to the
characteristics in the output header to specify that it is a uniprocessor (UP) driver. The
operating system will refuse to load a UP driver on a multiprocessor (MP) system.
/DRIVER:WDM causes the linker to set the
IMAGE_DLLCHARACTERISTICS_WDM_DRIVER bit in the optional header's
DllCharacteristics field.
If /DRIVER is not specified, these bits are not set by the linker.
If /DRIVER is specified:
/FIXED:NO is in effect. For more information, see /FIXED (Fixed Base Address).
The extension of the output file is set to .sys. Use /OUT to change the default
filename and extension. For more information, see /OUT (Output File Name).
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Click the Linker folder.
3. Click the System property page.
4. Modify the Driver property.
To set this linker option programmatically
See VCLinkerTool.driver Property.
See also
MSVC linker reference
MSVC Linker Options
/DYNAMICBASE (Use address space layout
randomization)
Article • 05/06/2022
Specifies whether to generate an executable image that can be randomly rebased at
load time by using the address space layout randomization (ASLR) feature of Windows.
ASLR was first available in Windows Vista.
Syntax
/DYNAMICBASE [ :NO ]
Remarks
The /DYNAMICBASE option modifies the header of an executable image, a .dll or .exe file,
to indicate whether the application should be randomly rebased at load time, and
enables virtual address allocation randomization, which affects the virtual memory
location of heaps, stacks, and other operating system allocations. The /DYNAMICBASE
option applies to both 32-bit and 64-bit images. ASLR is supported on Windows Vista
and later operating systems. The option is ignored by earlier operating systems.
By default, /DYNAMICBASE is enabled. To disable this option, use /DYNAMICBASE:NO . The
/DYNAMICBASE option is required for the /HIGHENTROPYVA option to have an effect.
Because ASLR can't be disabled on ARM, ARM64, or ARM64EC architectures,
/DYNAMICBASE:NO isn't supported for these targets.
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Randomized Base Address property.
To set this linker option programmatically
See RandomizedBaseAddress.
See also
MSVC linker reference
MSVC linker options
/HIGHENTROPYVA
Windows ISV Software Security Defenses
/ENTRY (Entry-Point Symbol)
Article • 08/03/2021
function
A function that specifies a user-defined starting address for an .exe file or DLL.
The /ENTRY option specifies an entry point function as the starting address for an .exe
file or DLL.
The function must be defined to use the __stdcall calling convention. The parameters
and return value depend on if the program is a console application, a windows
application or a DLL. It is recommended that you let the linker set the entry point so that
the C run-time library is initialized correctly, and C++ constructors for static objects are
executed.
By default, the starting address is a function name from the C run-time library. The linker
selects it according to the attributes of the program, as shown in the following table.
Function name Default for
mainCRTStartup (or
wmainCRTStartup)
An application that uses /SUBSYSTEM:CONSOLE; calls main (or
wmain )
WinMainCRTStartup (or
wWinMainCRTStartup)
An application that uses /SUBSYSTEM:WINDOWS; calls WinMain (or
wWinMain ), which must be defined to use __stdcall
_DllMainCRTStartup A DLL; calls DllMain if it exists, which must be defined to use
__stdcall
If the /DLL or /SUBSYSTEM option is not specified, the linker selects a subsystem and
entry point depending on whether main or WinMain is defined.
/ENTRY:function
Arguments
Remarks
The functions main , WinMain , and DllMain are the three forms of the user-defined entry
point.
When creating a managed image, the function specified to /ENTRY must have a
signature of (LPVOID var1, DWORD var2, LPVOID var3).
For information on how to define your own DllMain entry point, see DLLs and Visual
C++ run-time library behavior .
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Entry Point property.
To set this linker option programmatically
See EntryPointSymbol.
See also
MSVC linker reference
MSVC Linker Options
/ERRORREPORT (Report Internal Linker
Errors)
Article • 08/03/2021
The /ERRORREPORT option is deprecated. Starting in Windows Vista, error reporting is
controlled by Windows Error Reporting (WER) settings.
Syntax
/ERRORREPORT: [ none | prompt | queue | send ]
Remarks
The /ERRORREPORT arguments are overridden by the Windows Error Reporting service
settings. The linker automatically sends reports of internal errors to Microsoft, if
reporting is enabled by Windows Error Reporting. No report is sent if disabled by
Windows Error Reporting.
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Error Reporting property.
To set this compiler option programmatically
See ErrorReporting.
See also
MSVC linker reference
MSVC linker options
/EXPORT (Exports a Function)
Article • 08/03/2021
Exports a function by name or ordinal, or data, from your program.
Syntax
/EXPORT:entryname[,@ordinal[,NONAME]][,DATA]
Remarks
The /EXPORT option specifies a function or data item to export from your program so
that other programs can call the function or use the data. Exports are usually defined in
a DLL.
The entryname is the name of the function or data item as it is to be used by the calling
program. ordinal specifies an index into the exports table in the range 1 through 65,535;
if you do not specify ordinal, LINK assigns one. The NONAME keyword exports the
function only as an ordinal, without an entryname.
The DATA keyword specifies that the exported item is a data item. The data item in the
client program must be declared using extern __declspec(dllimport).
There are four methods for exporting a definition, listed in recommended order of use:
1. __declspec(dllexport) in the source code
2. An EXPORTS statement in a .def file
3. An /EXPORT specification in a LINK command
4. A comment directive in the source code, of the form #pragma comment(linker,
"/export: definition ") .
All these methods can be used in the same program. When LINK builds a program that
contains exports, it also creates an import library, unless an .exp file is used in the build.
LINK uses decorated forms of identifiers. The compiler decorates an identifier when it
creates the .obj file. If entryname is specified to the linker in its undecorated form (as it
appears in the source code), LINK attempts to match the name. If it cannot find a unique
match, LINK issues an error message. Use the DUMPBIN tool to get the decorated name
form of an identifier when you need to specify it to the linker.
７ Note
Do not specify the decorated form of C identifiers that are declared __cdecl or
__stdcall .
If you need to export an undecorated function name, and have different exports
depending on the build configuration (for example, in 32-bit or 64-bit builds), you can
use different DEF files for each configuration. (Preprocessor conditional directives are
not allowed in DEF files.) As an alternative, you can use a #pragma comment directive
before a function declaration as shown here, where PlainFuncName is the undecorated
name, and _PlainFuncName@4 is the decorated name of the function:
C++
#pragma comment(linker, "/export:PlainFuncName=_PlainFuncName@4")
BOOL CALLBACK PlainFuncName( Things * lpParams)
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option into the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/FILEALIGN (Align sections in files)
Article • 08/03/2021
The /FILEALIGN linker option lets you specify the alignment of sections written to your
output file as a multiple of an specified size.
Syntax
/FILEALIGN:size
Parameters
size
The section alignment size in bytes, which must be a power of two.
Remarks
The /FILEALIGN option causes the linker to align each section in the output file on a
boundary that is a multiple of the size value. By default, the linker does not use a fixed
alignment size.
The /FILEALIGN option can be used to make disk utilization more efficient, or to make
page loads from disk faster. A smaller section size may be useful for apps that run on
smaller devices, or to keep downloads smaller. Section alignment on disk does not affect
alignment in memory.
Use DUMPBIN to see information about sections in your output file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option name /FILEALIGN: and the size in the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/FIXED (Fixed Base Address)
Article • 08/03/2021
/FIXED[:NO]
Remarks
Tells the operating system to load the program only at its preferred base address. If the
preferred base address is unavailable, the operating system does not load the file. For
more information, see /BASE (Base Address).
/FIXED:NO is the default setting for a DLL, and /FIXED is the default setting for any other
project type.
When /FIXED is specified, LINK does not generate a relocation section in the program.
At run time, if the operating system is unable to load the program at the specified
address, it issues an error message and does not load the program.
Specify /FIXED:NO to generate a relocation section in the program.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option name and setting in the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/FORCE (Force file output)
Article • 09/22/2022
Tells the linker to create an executable even if symbols are undefined or multiply
defined.
Syntax
/FORCE [ :MULTIPLE | :UNRESOLVED ]
Remarks
The /FORCE linker option tells the linker to create an executable image (EXE file or DLL)
even if a symbol is referenced but not defined or is defined more than once.
） Important
The /FORCE option can create an executable that crashes or misbehaves at runtime
if it references an undefined symbol or, when a multiply defined symbol has
different definitions, if it invokes an unexpected definition in context.
The /FORCE option can take an optional argument:
Use /FORCE:MULTIPLE to create an output file whether or not LINK finds more than
one definition for a symbol.
Use /FORCE:UNRESOLVED to create an output file whether or not LINK finds an
undefined symbol. /FORCE:UNRESOLVED is ignored if the entry point symbol is
unresolved.
/FORCE with no arguments implies both /FORCE:MULTIPLE and /FORCE:UNRESOLVED .
The linker won't link incrementally when the /FORCE option is specified.
If a module is compiled with /clr , the linker ignores the /FORCE option.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Force File Output property. Choose OK or Apply to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/FUNCTIONPADMIN (Create hotpatchable
image)
Article • 09/22/2022
Tells the linker to prepare an executable image for hot patching.
Syntax
/FUNCTIONPADMIN [ : size ]
Arguments
size
The amount of padding to add to the beginning of each function in bytes. On x86 the
default is 5 bytes of padding and on x64 the default is 6 bytes. On other targets a value
must be provided.
Remarks
In order for the linker to produce a hotpatchable image, the .obj files must be
compiled by using the /hotpatch (Create hotpatchable image) compiler option.
When you compile and link an image with a single invocation of cl.exe, /hotpatch
implies /FUNCTIONPADMIN .
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Create Hot Patchable Image property. Choose OK or Apply to save
your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/GENPROFILE , /FASTGENPROFILE (Generate
Profiling Instrumented Build)
Article • 08/03/2021
Specifies generation of a .pgd file by the linker to support profile-guided optimization
(PGO). /GENPROFILE and /FASTGENPROFILE use different default parameters. Use
/GENPROFILE to favor precision over speed and memory usage during profiling. Use
/FASTGENPROFILE to favor smaller memory usage and speed over precision.
/GENPROFILE [ : profile-argument [ , profile-argument ...]]
/FASTGENPROFILE [ : profile-argument [ , profile-argument ...]]\
profile-argument
 { COUNTER32 | COUNTER64 }
 { EXACT | NOEXACT }
MEMMAX= value
MEMMIN= value
 { PATH | NOPATH }
 { TRACKEH | NOTRACKEH }
PGD= filename
Any of the profile-argument arguments may be specified to /GENPROFILE or
/FASTGENPROFILE . Arguments listed here separated by a pipe character ( | ) are mutually
exclusive. Use a comma character ( , ) to separate arguments. Don't put spaces between
arguments, commas, or after the colon ( : ).
COUNTER32 | COUNTER64
Use COUNTER32 to specify the use of 32-bit probe counters, and COUNTER64 to specify 64-
bit probe counters. When you specify /GENPROFILE , the default is COUNTER64 . When you
specify /FASTGENPROFILE , the default is COUNTER32 .
EXACT | NOEXACT
Use EXACT to specify thread-safe interlocked increments for probes. NOEXACT specifies
Syntax
Arguments
unprotected increment operations for probes. The default is NOEXACT .
MEMMAX=value, MEMMIN=value
Use MEMMAX and MEMMIN to specify the maximum and minimum reservation sizes for
training data in memory. The value is the amount of memory to reserve in bytes. By
default, these values are determined by an internal heuristic.
PATH | NOPATH
Use PATH to specify a separate set of PGO counters for each unique path to a function.
Use NOPATH to specify only one set of counters for each function. When you specify
/GENPROFILE , the default is PATH . When you specify /FASTGENPROFILE , the default is
NOPATH .
TRACKEH | NOTRACKEH
Specifies whether to use extra counters to keep an accurate count when exceptions are
thrown during training. Use TRACKEH to specify extra counters for an exact count. Use
NOTRACKEH to specify single counters for code that doesn't use exception handling or
that doesn't run into exceptions in your training scenarios. When you specify
/GENPROFILE , the default is TRACKEH . When you specify /FASTGENPROFILE , the default is
NOTRACKEH .
PGD=filename
Specifies a base file name for the .pgd file. By default, the linker uses the base
executable image file name with a .pgd extension.
Remarks
The /GENPROFILE and /FASTGENPROFILE options tell the linker to generate the profiling
instrumentation file needed to support application training for profile-guided
optimization (PGO). These options are new in Visual Studio 2015. Prefer these options to
the deprecated /LTCG:PGINSTRUMENT , /PGD , and /POGOSAFEMODE options, and to the
PogoSafeMode , VCPROFILE_ALLOC_SCALE , and VCPROFILE_PATH environment variables. The
profiling information generated by application training is used as input for targeted
whole-program optimizations during builds. You can also set other options to control
various profiling features for performance during app training and builds. The default
options specified by /GENPROFILE give the most accurate results, especially for large,
complex multi-threaded apps. The /FASTGENPROFILE option uses different defaults for a
lower memory footprint and faster performance during training, at the expense of
accuracy.
Profiling information is captured when you run the instrumented app after you build by
using /GENPROFILE of /FASTGENPROFILE . This information is captured when you specify
the /USEPROFILE linker option to do the profiling step and then used to guide the
optimized build step. For more information on how to train your app and details on the
collected data, see Profile-guided optimizations.
Always specify /LTCG when you specify /GENPROFILE or /FASTGENPROFILE .
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the /GENPROFILE or /FASTGENPROFILE options and arguments into the
Additional Options box. Choose OK to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/LTCG (Link-time code generation)
/GUARD (Enable Guard Checks)
Article • 09/22/2022
Tells the linker whether to support Control Flow Guard checks in the executable image.
Syntax
/GUARD:CF
/GUARD:NO
Remarks
The /GUARD:CF linker option modifies the header of a DLL or EXE file to indicate support
for Control Flow Guard (CFG) runtime checks. The linker also adds the required control
flow target address data to the header. By default, /GUARD:CF is disabled. It can be
explicitly disabled by using /GUARD:NO . To be effective, /GUARD:CF also requires the
/DYNAMICBASE (Use address space layout randomization) linker option, which is on by
default.
When source code is compiled by using the /guard:cf compiler option, the compiler
analyzes the control flow by examining all indirect calls for possible target addresses.
The compiler inserts code to verify the target address of an indirect call instruction is in
the list of known target addresses at runtime. Operating systems that support CFG stop
a program that fails a CFG runtime check. This check makes it more difficult for an
attacker to execute malicious code by using data corruption to change a call target.
The /GUARD:CF option must be specified to both the compiler and linker to create CFG￾enabled executable images. Code compiled but not linked by using /GUARD:CF incurs
the cost of runtime checks, but doesn't enable CFG protection. When the /guard:cf
option is specified to the cl command to compile and link in one step, the compiler
passes the flag to the linker. When the Control Flow Guard property is set in Visual
Studio, the /GUARD:CF option is passed to both the compiler and linker. When object
files or libraries have been compiled separately, the option must be explicitly specified in
the link command.
To set this linker option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In Additional Options, enter /GUARD:CF . Choose OK or Apply to save your
changes.
To set this linker option programmatically
See AdditionalOptions.
See also
/guard (Enable Control Flow Guard)
MSVC linker reference
MSVC linker options
/HEAP (Set Heap Size)
Article • 08/03/2021
/HEAP:reserve[,commit]
Remarks
The /HEAP option sets the size of the heap in bytes. This option is only for use when
building an .exe file.
The reserve argument specifies the total heap allocation in virtual memory. The default
heap size is 1 MB. The linker rounds up the specified value to the nearest 4 bytes.
The optional commit argument specifies the amount of physical memory to allocate at a
time. Committed virtual memory causes space to be reserved in the paging file. A higher
commit value saves time when the application needs more heap space, but increases the
memory requirements and possibly the startup time.
Specify the reserve and commit values in decimal or C-language notation.
This functionality is also available via a module definition file with HEAPSIZE.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify the Heap Commit Size property.
To set this linker option programmatically
See HeapReserveSize and HeapCommitSize.
See also
MSVC linker reference
MSVC Linker Options
/HIGHENTROPYVA (Support 64-Bit
ASLR)
Article • 08/03/2021
Specifies whether the executable image supports high-entropy 64-bit address space
layout randomization (ASLR).
Syntax
/HIGHENTROPYVA [ :NO ]
Remarks
/HIGHENTROPYVA modifies the header of an executable image file (for example, a .dll or
.exe file), to indicate whether ASLR can use the entire 64-bit address space. To have an
effect, set the option on both the executable and all modules that it depends on. Then
an operating system that supports 64-bit ASLR can rebase the executable image's
segments at load time by using 64-bit randomized virtual addresses. This large address
space makes it more difficult for an attacker to guess the location of a particular
memory region.
By default, /HIGHENTROPYVA is enabled for 64-bit executable images. This option requires
/LARGEADDRESSAWARE, which is also enabled by default for 64-bit images.
/HIGHENTROPYVA isn't applicable to 32-bit executable images, where the linker ignores
the option. To explicitly disable this option, use /HIGHENTROPYVA:NO .
For /HIGHENTROPYVA to have an effect at load time, /DYNAMICBASE must also be
enabled. /DYNAMICBASE is enabled by default, and is required to enable ASLR in Windows
Vista and later operating systems. Earlier versions of Windows ignore this flag.
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In Additional Options, enter /HIGHENTROPYVA or /HIGHENTROPYVA:NO .
See also
MSVC linker reference
MSVC linker options
/DYNAMICBASE
/LARGEADDRESSAWARE
Windows ISV Software Security Defenses
/IDLOUT (Name MIDL Output Files)
Article • 08/03/2021
/IDLOUT:[path\]filename
Parameters
path
An absolute or relative path specification. By specifying a path, you affect only the
location of an .idl file; all other files are placed in the project directory.
filename
Specifies the name of the .idl file created by the MIDL compiler. No file extension is
assumed; specify filename.idl if you want an .idl extension.
Remarks
The /IDLOUT option specifies the name and extension of the .idl file.
The MIDL compiler is called by the MSVC linker when linking projects that have the
module attribute.
/IDLOUT also specifies the file names of the other output files associated with the MIDL
compiler:
filename.tlb
filename_p.c
filename_i.c
filename.h
filename is the parameter that you pass to /IDLOUT. If /TLBOUT is specified, the .tlb file
will get its name from /TLBOUT filename.
If you specify neither /IDLOUT nor /TLBOUT, the linker will create vc70.tlb, vc70.idl,
vc70_p.c, vc70_i.c, and vc70.h.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Embedded IDL property page.
3. Modify the Merge IDL Base File Name property.
To set this linker option programmatically
See MergedIDLBaseFileName.
See also
MSVC linker reference
MSVC Linker Options
/IGNOREIDL (Don't Process Attributes into MIDL)
/MIDL (Specify MIDL Command Line Options)
Building an Attributed Program
/IGNORE (Ignore Specific Warnings)
Article • 08/03/2021
warning
The number of the linker warning to suppress, in the range 4000 to 4999.
By default, LINK reports all warnings. Specify /IGNORE: warning to tell the linker to
suppress a specific warning number. To ignore multiple warnings, separate the warning
numbers with commas.
The linker does not allow some warnings to be ignored. This table lists the warnings that
are not suppressed by /IGNORE:
Linker
Warning
Message
LNK4017 keyword statement not supported for the target platform; ignored
LNK4044 unrecognized option ' option '; ignored
LNK4062 ' option ' not compatible with ' architecture ' target machine; option ignored
LNK4075 ignoring " option1 " due to " option2 " specification
LNK4086 entrypoint ' function ' is not __stdcall with ' number ' bytes of arguments; image may
not run
LNK4088 image being generated due to /FORCE option; image may not run
LNK4105 no argument specified with option ' option '; ignoring switch
LNK4203 error reading program database ' filename '; linking object as if no debug info
LNK4204 ' filename ' is missing debugging information for referencing module; linking object
as if no debug info
/IGNORE:warning[,warning]
Parameters
Remarks
Linker
Warning
Message
LNK4205 ' filename ' is missing current debugging information for referencing module; linking
object as if no debug info
LNK4206 precompiled type information not found; ' filename ' not linked or overwritten;
linking object as if no debug info
LNK4207 ' filename ' compiled /Yc /Yu /Z7; cannot create PDB; recompile with /Zi; linking
object as if no debug info
LNK4208 incompatible PDB format in ' filename '; delete and rebuild; linking object as if no
debug info
LNK4209 debugging information corrupt; recompile module; linking object as if no debug
info
LNK4224 option is no longer supported; ignored
LNK4228 ' option ' invalid for a DLL; ignored
LNK4229 invalid directive / directive found; ignored
In general, linker warnings that can't be ignored represent build failures, command line
errors or configuration errors that you should fix.
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Modify the Additional Options property.
See AdditionalOptions.
To set this linker option in the Visual Studio development
environment
To set this linker option programmatically
/IGNOREIDL (Don't Process Attributes
into MIDL)
Article • 11/11/2021
/IGNOREIDL
Remarks
The /IGNOREIDL option specifies that any IDL attributes in source code should not be
processed into an .idl file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Embedded IDL property page.
3. Modify the Ignore Embedded IDL property.
To set this linker option programmatically
See IgnoreEmbeddedIDL.
See also
MSVC linker reference
MSVC Linker Options
/IDLOUT (Name MIDL Output Files)
/TLBOUT (Name .TLB File)
/MIDL (Specify MIDL Command Line Options)
Building an Attributed Program
/ILK (Name incremental database file)
Article • 09/08/2022
The /ILK linker option tells the linker where to put the .ilk database file for
incremental link information (/INCREMENTAL).
Syntax
/ILK: [ pathname ]
Arguments
pathname
The destination directory and filename for the generated .ilk file. If the /ILK option
isn't specified when /INCREMENTAL is used, the filename is created by appending .ilk to
the target base filename.
Remarks
The /ILK linker option tells the linker the path and filename to use for the .ilk
incremental database file when you specify /INCREMENTAL.
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Incremental Link Database File property. The default value is
$(IntDir)$(TargetName).ilk .
To set this compiler option programmatically
See AdditionalOptions.
See also
/INCREMENTAL
MSVC linker reference
MSVC linker options
/IMPLIB (Name Import Library)
Article • 08/03/2021
/IMPLIB:filename
Parameters
filename
A user-specified name for the import library. It replaces the default name.
Remarks
The /IMPLIB option overrides the default name for the import library that LINK creates
when it builds a program that contains exports. The default name is formed from the
base name of the main output file and the extension .lib. A program contains exports if
one or more of the following are specified:
The __declspec(dllexport) keyword in the source code
EXPORTS statement in a .def file
An /EXPORT specification in a LINK command
LINK ignores /IMPLIB when an import library is not being created. If no exports are
specified, LINK does not create an import library. If an export file is used in the build,
LINK assumes that an import library already exists and does not create one. For
information on import libraries and export files, see LIB Reference.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Import Library property.
To set this linker option programmatically
See ImportLibrary.
See also
MSVC linker reference
MSVC Linker Options
/INCLUDE (Force Symbol References)
Article • 08/03/2021
/INCLUDE:symbol
Parameters
symbol
Specifies a symbol to be added to the symbol table.
Remarks
The /INCLUDE option tells the linker to add a specified symbol to the symbol table.
To specify multiple symbols, type a comma (,), a semicolon (;), or a space between the
symbol names. On the command line, specify /INCLUDE: symbol once for each symbol.
The linker resolves symbol by adding the object that contains the symbol definition to
the program. This feature is useful for including a library object that otherwise would
not be linked to the program.
Specifying a symbol with this option overrides the removal of that symbol by /OPT:REF.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Input property page.
3. Modify the Force Symbol References property.
To set this linker option programmatically
See ForceSymbolReferences.
See also
MSVC linker reference
MSVC Linker Options
/INCREMENTAL (Link incrementally)
Article • 09/08/2022
Specifies whether to link incrementally or always perform a full link.
Syntax
/INCREMENTAL [ :NO ]
Remarks
The /INCREMENTAL linker option controls how the linker handles incremental linking.
By default, the linker runs in incremental mode. To override a default incremental link,
specify /INCREMENTAL:NO .
An incrementally linked program is functionally equivalent to a program that is non￾incrementally linked. However, because it's prepared for subsequent incremental links,
an incrementally linked executable, static library, or dynamic-link library file:
Is larger than a non-incrementally linked program because of padding of code and
data. Padding enables the linker to increase the size of functions and data without
recreating the file.
May contain jump thunks to handle relocation of functions to new addresses.
７ Note
To ensure that your final release build does not contain padding or thunks,
link your program non-incrementally.
To link incrementally regardless of the default, specify /INCREMENTAL . When this option is
selected, the linker issues a warning if it can't link incrementally, and then links the
program non-incrementally. Certain options and situations override /INCREMENTAL .
Most programs can be linked incrementally. However, some changes are too great, and
some options are incompatible with incremental linking. LINK performs a full link if any
of the following options are specified:
Link Incrementally isn't selected ( /INCREMENTAL:NO )
/OPT:REF is selected
/OPT:ICF is selected
/OPT:LBR is selected
/ORDER is selected
/INCREMENTAL is implied when /DEBUG is specified.
Additionally, LINK performs a full link if any of the following situations occur:
The incremental status ( .ilk ) file is missing. (LINK creates a new .ilk file in
preparation for subsequent incremental linking.)
There's no write permission for the .ilk file. (LINK ignores the .ilk file and links
non-incrementally.)
The .exe or .dll output file is missing.
The timestamp of the .ilk , .exe , or .dll is changed.
A LINK option is changed. Most LINK options, when changed between builds,
cause a full link.
An object ( .obj ) file is added or omitted.
An incremental link creates or updates an incremental link database .ilk file. You can
specify the name and location of this file by using the /ILK (Name incremental database
file) linker option. For more information about the .ilk file, see .ilk files as linker input.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Enable Incremental Linking property.
To set this linker option programmatically
1. See LinkIncremental.
See also
MSVC linker reference
MSVC linker options
.ilk files as linker input
/INFERASANLIBS (Use inferred sanitizer
libs)
Article • 08/03/2021
Use the /INFERASANLIBS linker option to enable or disable linking to the default
AddressSanitizer libraries. As of Visual Studio 2019 16.9, the only supported sanitizer is
AddressSanitizer.
Syntax
/INFERASANLIBS [ :NO ]
Remarks
The /INFERASANLIBS linker option enables the default AddressSanitizer libraries. This
option is enabled by default.
The /INFERASANLIBS and /INFERASANLIBS:NO linker options offer support for advanced
users. For more information, see AddressSanitizer build and language reference.
The /INFERASANLIBS option is available beginning in Visual Studio 2019 version 16.9.
To set the /INFERASANLIBS linker option in the Visual
Studio development environment
1. Open your project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Modify the Additional Options property. To enable default libraries, enter
/INFERASANLIBS in the edit box. To disable default libraries, enter
/INFERASANLIBS:NO instead.
4. Choose OK or Apply to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/fsanitize (Enable sanitizers)
AddressSanitizer overview
AddressSanitizer known issues
AddressSanitizer build and language reference
/INTEGRITYCHECK (Require signature
check)
Article • 08/30/2023
Specifies that the digital signature of the binary image must be checked at load time.
/INTEGRITYCHECK
Remarks
By default, /INTEGRITYCHECK is off.
The /INTEGRITYCHECK linker option sets a flag,
IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY , in the PE header of the DLL file or
executable file. This flag tells the memory manager to check for a digital signature in
order to load the image in Windows. This option must be set for both 32-bit and 64-bit
DLLs that certain Windows features load. It's recommended for all device drivers on
Windows Vista, Windows Server 2008, and all later versions of Windows and Windows
Server. Versions of Windows prior to Windows Vista ignore this flag. For more
information, see Forced Integrity Signing of Portable Executable (PE) files .
Signing /INTEGRITYCHECK files
Microsoft has new signing guidance for DLL and executable files linked by using
/INTEGRITYCHECK . The guidance used to recommend a cross-signed certificate from the
cross-signing program. However, the cross-signing program is now deprecated. You
must now sign your /INTEGRITYCHECK files by using the Microsoft Azure Code Signing
program instead.
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. To create a digitally signed image, include /INTEGRITYCHECK in the Additional
Options command line. A digitally signed image must pass a verification check
before it's loaded. This feature is disabled by default.
4. Choose OK to save your changes.
See also
MSVC linker reference
MSVC linker options
Forced integrity signing of portable executable (PE) files
Kernel-mode code signing requirements
AppInit DLLs and Secure Boot
/KERNEL (Create kernel mode binary)
Article • 08/29/2023
Create a binary that is suitable for running in kernel mode.
Syntax
/KERNEL
Remarks
Causes the linker to emit a warning if any object file or library linked in the binary wasn't
compiled with /kernel.
Code that can run in kernel mode must be compiled with the /kernel option. If you link
a binary that contains code that wasn't compiled with /kernel , the binary might not run
correctly in kernel mode.
Code for kernel mode is compiled with a simplified set of C++ language features that
are specific to code that runs in kernel mode. The compiler produces warnings for C++
language features that are potentially disruptive but can't be disabled. For more
information about compiling code in kernel mode, see /kernel (Create kernel mode
binary).
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In Additional Options, enter /KERNELMODE .
See also
MSVC linker reference
MSVC linker options
Compiler options: /kernel
/KEYCONTAINER (Specify a Key
Container to Sign an Assembly)
Article • 03/03/2022
/KEYCONTAINER:name
Arguments
name
Container that contains the key. Place the string in double quotation marks (" ") if it
contains a space.
Remarks
The linker creates a signed assembly by inserting a public key into the assembly
manifest and signing the final assembly with the private key. To generate a key file, type
sn -k filename at the command line. sn -i installs the key pair into a container.
If you compile with /LN, the name of the key file is held in the module and incorporated
into the assembly that is created when you compile an assembly that includes an explicit
reference to the module, via #using, or when linking with /ASSEMBLYMODULE.
You can also pass your encryption information to the compiler with /KEYFILE. Use
/DELAYSIGN if you want a partially signed assembly. For more information on signing an
assembly, see Strong Name Assemblies (Assembly Signing) (C++/CLI).
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option into the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/KEYFILE (Specify Key or Key Pair to Sign
an Assembly)
Article • 08/03/2021
/KEYFILE:filename
Arguments
filename
File that contains the key. Place the string in double quotation marks (" ") if it contains a
space.
Remarks
The linker inserts the public key into the assembly manifest and then signs the final
assembly with the private key. To generate a key file, type sn -k filename at the
command line. A signed assembly is said to have a strong name.
If you compile with /LN, the name of the key file is held in the module and incorporated
into the assembly that is created when you compile an assembly that includes an explicit
reference to the module, via #using, or when linking with /ASSEMBLYMODULE.
You can also pass your encryption information to the linker with /KEYCONTAINER. Use
/DELAYSIGN if you want a partially signed assembly. For more information on signing an
assembly, see Strong Name Assemblies (Assembly Signing) (C++/CLI) and Creating and
Using Strong-Named Assemblies.
In case both /KEYFILE and /KEYCONTAINER are specified (either by command-line
option or by custom attribute), the linker will first try the key container. If that succeeds,
then the assembly is signed with the information in the key container. If the linker
doesn't find the key container, it will try the file specified with /KEYFILE. If that succeeds,
the assembly is signed with the information in the key file and the key information will
be installed in the key container (similar to sn -i) so that on the next compilation, the key
container will be valid.
A key file might contain only the public key.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/NOASSEMBLY
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option into the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/LARGEADDRESSAWARE (Handle Large
Addresses)
Article • 03/02/2024
/LARGEADDRESSAWARE[:NO]
Remarks
The /LARGEADDRESSAWARE option tells the linker that the application can handle
addresses larger than 2 gigabytes. In the 64-bit compilers, this option is enabled by
default. In the 32-bit compilers, /LARGEADDRESSAWARE:NO is enabled if /LARGEADDRESSAWARE
is not otherwise specified on the linker line.
If an application was linked with /LARGEADDRESSAWARE , DUMPBIN /HEADERS will display
information to that effect.
Linking 64-bit applications with /LARGEADDRESSAWARE:NO is not recommended because it
restricts the available address space, which can result in runtime failures if the app
exhausts memory. It may also prevent x64 apps from running on ARM64 systems
because the emulation runtime will try to reserve 4GB of virtual address space. If the app
was linked with /LARGEADRESSAWARE:NO , the app won't launch because it can't allocate
that much address space.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify the Enable Large Addresses property.
To set this linker option programmatically
See LargeAddressAware.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
MSVC linker reference
MSVC Linker Options
See also
 Yes  No
/LIBPATH (Additional Libpath)
Article • 08/03/2021
/LIBPATH:dir
Parameters
dir
Specifies a path that the linker will search before it searches the path specified in the LIB
environment option.
Remarks
Use the /LIBPATH option to override the environment library path. The linker will first
search in the path specified by this option, and then search in the path specified in the
LIB environment variable. You can specify only one directory for each /LIBPATH option
you enter. If you want to specify more than one directory, you must specify multiple
/LIBPATH options. The linker will then search the specified directories in order.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Additional Library Directories property.
To set this linker option programmatically
See AdditionalLibraryDirectories.
See also
MSVC linker reference
MSVC Linker Options
/LINKREPRO (Link repro directory name)
Article • 08/03/2021
Tells the linker or library tool to generate a link repro in a specified directory.
Syntax
/LINKREPRO:directory-name
Arguments
/LINKREPRO:directory-name
The user-specified directory to store the link repro in. Directory names that include
spaces must be enclosed in double quotes.
Remarks
The /LINKREPRO option is used to create a link repro. It's a set of build artifacts that
allow Microsoft to reproduce a problem that occurs at link time, or during library
operations. It's useful for problems such as a backend crash involving Link-Time Code
Generation (LTCG), an LNK1000 linker error, or a linker crash. The tool produces a link
repro when you specify the /LINKREPRO linker option, or when you set the link_repro
environment variable in your command-line build environment. For more information,
see the Link repros section of How to report a problem with the Microsoft C++ toolset.
Both the /LINKREPRO linker option and the link_repro environment variable require
you to specify an output directory for the link repro. On the command line or in the IDE,
specify the directory by using a /LINKREPRO:directory-name option. The directory-name
you specify may be an absolute or relative path, but the directory must exist. The
command-line option overrides any directory value set in the link_repro environment
variable.
For information on how to limit link repro generation to a specific target file name, see
the /LINKREPROTARGET option. This option can be used to specify a specific target to
generate a link repro for. It's useful in complex builds that invoke the linker or library
tool more than once.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the /LINKREPRO:directory-name option in the Additional Options box. The
directory-name value you specify must exist. Choose OK to apply the change.
Once you've generated the link repro, open this property page again to remove the
/LINKREPRO option from your builds.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/LINKREPROTARGET
/LINKREPROFULLPATHRSP (Generate file
containing absolute paths of linked
files)
Article • 06/13/2024
Generates a response file (.RSP) containing the absolute paths of all the files the linker
took as input.
This flag was introduced in Visual Studio 2022 version 17.11.
Syntax
/LINKREPROFULLPATHRSP:filename
Remarks
Rather than generating a full link repro like /LINKREPRO which copies all the files to a
directory and creating a response file with relative paths to that directory, this option
writes the names of the files used during linking to the specified file.
For example, given:
a directory c:\temp\test that contains the files test.cpp , f1.cpp , f2.cpp
the linker command line: link f1.obj f2.obj test.obj /out:test.exe
/LINKREPROFULLPATHRSP:test.rsp The linker produces test.rsp containing the
following lines to reflect the fully qualified paths of the input files:
Windows Command Prompt
"c:\temp\test\f1.obj"
"c:\temp\test\f2.obj"
"c:\temp\test\test.obj"
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter /LINKREPROFULLPATHRSP:file.rsp into Additional Options. Choose OK or
Apply to apply the change.
See VCLinkerTool.AdditionalOptions
MSVC linker reference
MSVC linker options
To set this linker option programmatically
See also
 Yes  No
/LINKREPROTARGET (Link repro file
name)
Article • 08/03/2021
Tells the linker or library tool to generate a link repro only when the target has the
specified file name.
Syntax
/LINKREPROTARGET:file-name
Arguments
/LINKREPROTARGET:file-name
The target file name to filter on. A link repro is only generated when the named file is
the output target. File names that include spaces must be enclosed in double quotes.
The file name should include the base name and the extension, but not the path.
Remarks
The /LINKREPROTARGET option is used to specify a target file name to generate a link
repro for. A link repro is a set of build artifacts that allow Microsoft to reproduce a
problem that occurs at link time, or during library operations. The linker or library tool
produces a link repro when you specify the /LINKREPRO option, or when you set the
link_repro environment variable in your command-line build environment.
The /LINKREPROTARGET option is useful in complex builds that invoke the linker or
library tool more than once. It lets you specify a specific target for the link repro, such as
problem.dll. It lets you generate the link repro only when the tool produces a specific
file.
For more information about how and when to create a link repro, see the Link repros
section of How to report a problem with the Microsoft C++ toolset.
The /LINKREPRO and /OUT options must be set for the /LINKREPROTARGET option to
have any effect.
/LINKREPROTARGET is available starting in Visual Studio 2019 version 16.1.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the /LINKREPROTARGET:file-name option in the Additional Options box.
Choose OK to apply the change.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/LINKREPRO
/LTCG (Link-time code generation)
Article • 09/22/2022
Use /LTCG to perform whole-program optimization, or to create profile-guided
optimization (PGO) instrumentation, perform training, and create profile-guided
optimized builds.
Syntax
/LTCG [ : { INCREMENTAL | NOSTATUS | STATUS | OFF }]
These options are deprecated starting in Visual Studio 2015:
/LTCG: { PGINSTRUMENT | PGOPTIMIZE | PGUPDATE }
Arguments
INCREMENTAL
(Optional) Specifies that the linker only applies whole program optimization or link-time
code generation (LTCG) to files affected by an edit, instead of the entire project. By
default, this flag isn't set when /LTCG is specified, and the entire project is linked by
using whole program optimization.
NOSTATUS | STATUS
(Optional) Specifies whether the linker displays a progress indicator that shows what
percentage of the link is complete. By default, this status information isn't displayed.
OFF
(Optional) Disables link-time code generation. The linker treats all modules compiled
with /GL as if they're compiled without that option, and any MSIL modules cause the
link to fail.
PGINSTRUMENT
(Optional) This option is deprecated starting in Visual Studio 2015. Instead, use /LTCG
and /GENPROFILE or /FASTGENPROFILE to generate an instrumented build for profile￾guided optimization. The data that is collected from instrumented runs is used to create
an optimized image. For more information, see Profile-Guided Optimizations. The short
form of this option is /LTCG:PGI .
PGOPTIMIZE
(Optional) This option is deprecated starting in Visual Studio 2015. Instead, use /LTCG
and /USEPROFILE to build an optimized image. For more information, see Profile￾Guided Optimizations. The short form of this option is /LTCG:PGO .
PGUPDATE
(Optional) This option is deprecated starting in Visual Studio 2015. Instead, use /LTCG
and /USEPROFILE to rebuild an optimized image. For more information, see Profile￾Guided Optimizations. The short form of this option is /LTCG:PGU .
Remarks
The /LTCG option tells the linker to call the compiler and perform whole-program
optimization. You can also do profile guided optimization. For more information, see
Profile-Guided Optimizations.
With the following exceptions, you can't add linker options to the PGO combination of
/LTCG and /USEPROFILE that weren't specified in the previous PGO initialization
combination of /LTCG and /GENPROFILE options:
/BASE
/FIXED
/LTCG
/MAP
/MAPINFO
/NOLOGO
/OUT
/PGD
/PDB
/PDBSTRIPPED
/STUB
/VERBOSE
Any linker options that are specified together with the /LTCG and /GENPROFILE options
to initialize PGO don't have to be specified when you build by using /LTCG and
/USEPROFILE ; they're implied.
The rest of this article discusses the link-time code generation done by /LTCG .
/LTCG is implied with /GL.
The linker invokes link-time code generation if it's passed a module that was compiled
by using /GL or an MSIL module (see .netmodule Files as Linker Input). If you don't
explicitly specify /LTCG when you pass /GL or MSIL modules to the linker, the linker
eventually detects this situation and restarts the link by using /LTCG . Explicitly specify
/LTCG when you pass /GL and MSIL modules to the linker for the fastest possible build
performance.
For even faster performance, use /LTCG:INCREMENTAL . This option tells the linker to
reoptimize only the files affected by a source file change, instead of the entire project.
This option can significantly reduce the link time required. This option isn't the same
option as incremental linking. If you remove the /LTCG:INCREMENTAL option, also remove
any /LTCGOUT option to improve build times and disk utilization.
/LTCG isn't valid for use with /INCREMENTAL.
When /LTCG is used to link modules compiled by using /Og, /O1, /O2, or /Ox, the
following optimizations are performed:
Cross-module inlining
Interprocedural register allocation (64-bit operating systems only)
Custom calling convention (x86 only)
Small TLS displacement (x86 only)
Stack double alignment (x86 only)
Improved memory disambiguation (better interference information for global
variables and input parameters)
７ Note
The linker determines which optimizations were used to compile each function and
applies the same optimizations at link time.
Using /LTCG and /O2 causes double-alignment optimization.
If /LTCG and /O1 are specified, double alignment isn't performed. If most of the
functions in an application are compiled for speed, with a few functions compiled for
size (for example, by using the optimize pragma), the compiler double-aligns the
functions that are optimized for size if they call functions that require double alignment.
If the compiler can identify all of the call sites of a function, the compiler ignores explicit
calling-convention modifiers, and tries to optimize the function's calling convention:
pass parameters in registers
reorder parameters for alignment
remove unused parameters
If a function is called through a function pointer, or if a function is called from outside a
module that is compiled by using /GL , the compiler doesn't attempt to optimize the
function's calling convention.
７ Note
If you use /LTCG and redefine mainCRTStartup , your application can have
unpredictable behavior that relates to user code that executes before global
objects are initialized. There are three ways to address this issue: do not redefine
mainCRTStartup , do not compile the file that contains mainCRTStartup by using
/LTCG , or initialize global variables and objects statically.
/LTCG and MSIL Modules
Modules that are compiled by using /GL and /clr can be used as input to the linker when
/LTCG is specified.
/LTCG can accept native object files, and mixed native/managed object files
(compiled by using /clr ). The /clr:pure and /clr:safe compiler options are
deprecated in Visual Studio 2015 and unsupported in Visual Studio 2017 and later.
/LTCG:PGI doesn't accept native modules compiled by using /GL and /clr
To set this compiler option in the Visual Studio
development environment
The Whole Program Optimization property sets several compiler and linker options,
including /LTCG . We recommend you use this property to change the settings for an
entire build configuration. To set Whole Program Optimization for your project:
1. Open the project Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > General property page.
3. Modify the Whole Program Optimization property. Choose OK or Apply to save
your changes.
You can also apply /LTCG to specific builds by choosing Build > Profile Guided
Optimization on the menu bar, or by choosing one of the Profile Guided Optimization
options on the shortcut menu for the project.
To enable Link Time Code Generation separately or set a specific Link Time Code
Generation option:
1. Open the project Property Pages dialog box.
2. Select the Configuration Properties > Linker > Optimization property page.
3. Modify the Link Time Code Generation property to one of the following options:
Default
Use Fast Link Time Code Generation (LTCG:incremental)
Use Link Time Code Generation (LTCG)
Profile Guided Optimization - Instrument (LTCG:PGInstrument)
Profile Guided Optimization - Optimization (LTCG:PGOptimize)
Profile Guided Optimization - Update (LTCG:PGUpdate)
4. Choose OK or Apply to save your changes.
To specify whether the linker displays a progress indicator for Link Time Code
Generation:
1. Open the project Property Pages dialog box.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Link Status property. Choose OK or Apply to save your changes.
To set this compiler option programmatically
See LinkTimeCodeGeneration.
See also
MSVC linker reference
MSVC linker options
/LTCGOUT (Name LTCG incremental
object file)
Article • 09/02/2022
The /LTCGOUT linker option tells the linker where to put the intermediate .iobj object
file for incremental link-time code generation ( /LTCG:INCREMENTAL ).
Syntax
/LTCGOUT: [ pathname ]
Arguments
pathname
The optional destination directory and filename for the generated .iobj file. If the
/LTCGOUT option isn't specified when /LTCG:INCREMENTAL is used, the filename is created
by appending .iobj to the target base filename. If the /LTCGOUT option is specified with
an empty pathname when /LTCG:INCREMENTAL isn't used, no .iobj file is generated.
Remarks
The /LTCGOUT linker option tells the linker the path and filename to use for the
intermediate .iobj object file when you specify /LTCG:INCREMENTAL. If you remove the
/LTCG:INCREMENTAL option from your project, you should also remove any /LTCGOUT
option.
To set this compiler option in the Visual Studio
development environment
1. Open the project Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Optimization property page.
3. Modify the Link Time Code Generation Object File property. The option isn't set if
this property is empty.
To set this compiler option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/MACHINE (Specify Target Platform)
Article • 03/28/2022
/MACHINE: { ARM | ARM64 | ARM64EC | EBC | X64 | X86 }
Remarks
The /MACHINE option specifies the target platform for the program.
Usually, you don't have to specify the /MACHINE option. LINK infers the machine type
from the .obj files. However, in some circumstances, LINK cannot determine the
machine type and issues a linker tools error LNK1113. If such an error occurs, specify
/MACHINE .
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Target Machine property.
To set this linker option programmatically
1. See TargetMachine.
See also
MSVC linker reference
MSVC Linker Options
/MANIFEST (Create side-by-side assembly
manifest)
Article • 09/22/2022
Specifies whether the linker should create a side-by-side manifest file.
Syntax
/MANIFEST [ : { EMBED [ ,ID= resource_id ]| NO }]
Remarks
The /MANIFEST linker option tells the linker to create a side-by-side manifest file. For
more information about manifest files, see Manifest files reference.
The default is /MANIFEST .
The /MANIFEST:EMBED option specifies that the linker should embed the manifest file in
the image as a resource of type RT_MANIFEST . The optional ID parameter sets the
resource ID to use for the manifest. Use a resource_id value of 1 for an executable file.
Use a value of 2 for a DLL to enable it to specify private dependencies. If the ID
parameter isn't specified, the default value is 2 if the /DLL option is set; otherwise, the
default value is 1.
Beginning with Visual Studio 2008, manifest files for executables contain a section that
specifies User Account Control (UAC) information. If you specify /MANIFEST but don't
specify either /MANIFESTUAC or /DLL, a default UAC fragment that has the UAC level set
to asInvoker is inserted into the manifest. For more information about UAC levels, see
/MANIFESTUAC (Embeds UAC information in manifest).
To change the default behavior for UAC, set one of these options:
Specify the /MANIFESTUAC option and set the UAC level to the desired value.
Or, specify the /MANIFESTUAC:NO option if you don't want to generate a UAC
fragment in the manifest.
If you don't specify /MANIFEST but do specify /MANIFESTDEPENDENCY attributes, a
manifest file is created. A manifest file isn't created if you specify /MANIFEST:NO .
If you specify /MANIFEST , the name of the manifest file is the same as the full name of
your output file, but with .manifest appended to the file name. For example, if your
output file name is MyFile.exe , the manifest file name is MyFile.exe.manifest . If you
specify /MANIFESTFILE: name , the name of the manifest is what you specify in name .
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Manifest File property page.
3. Modify the Generate Manifest property. Choose OK or Apply to save your
changes.
To set this linker option programmatically
1. See GenerateManifest.
See also
Manifest files reference
/MANIFESTDEPENDENCY (Specify manifest dependencies)
/MANIFESTFILE (Name manifest file)
/MANIFESTUAC (Embeds UAC information in manifest)
MSVC linker reference
MSVC linker options
/MANIFESTDEPENDENCY (Specify
Manifest Dependencies)
Article • 08/03/2021
/MANIFESTDEPENDENCY lets you specify attributes that will be placed in the
<dependency> section of the manifest file.
See /MANIFEST (Create Side-by-Side Assembly Manifest) for information on how to
create a manifest file.
For more information on the <dependency> section of the manifest file, see Publisher
Configuration Files.
/MANIFESTDEPENDENCY information can be passed to the linker in one of two ways:
Directly on the command line (or in a response file) with /MANIFESTDEPENDENCY.
Via the comment pragma.
The following example shows a /MANIFESTDEPENDENCY comment passed via pragma,
C++
which results in the following entry in the manifest file:
XML
/MANIFESTDEPENDENCY:manifest_dependency
Remarks
#pragma comment(linker, "\"/manifestdependency:type='Win32'
name='Test.Research.SampleAssembly' version='6.0.0.0'
processorArchitecture='X86' publicKeyToken='0000000000000000'
language='*'\"")
<dependency>
 <dependentAssembly>
 <assemblyIdentity type='Win32' name='Test.Research.SampleAssembly'
version='6.0.0.0' processorArchitecture='X86'
publicKeyToken='0000000000000000' language='*' />
The same /MANIFESTDEPENDENCY comments can be passed at the command line as
follows:
Windows Command Prompt
The linker will collect /MANIFESTDEPENDENCY comments, eliminate duplicate entries,
and then add the resulting XML string to the manifest file. If the linker finds conflicting
entries, the manifest file will become corrupt and the application will fail to launch (an
entry may be added to the event log, indicating the source of the failure).
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Manifest File property page.
3. Modify the Additional Manifest Dependencies property.
1. See AdditionalManifestDependencies.
MSVC linker reference
MSVC Linker Options
 </dependentAssembly>
</dependency>
"/manifestdependency:type='Win32' name='Test.Research.SampleAssembly'
version='6.0.0.0' processorArchitecture='X86'
publicKeyToken='0000000000000000' language='*'\"
To set this linker option in the Visual Studio development
environment
To set this linker option programmatically
See also
/MANIFESTFILE (Name Manifest File)
Article • 08/03/2021
/MANIFESTFILE:filename
Remarks
/MANIFESTFILE lets you change the default name of the manifest file. The default name
of the manifest file is the file name with .manifest appended.
/MANIFESTFILE will have no effect if you do not also link with /MANIFEST.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Manifest File property page.
3. Modify the Manifest File property.
To set this linker option programmatically
1. See ManifestFile.
See also
MSVC linker reference
MSVC Linker Options
/MANIFESTINPUT (Specify Manifest
Input)
Article • 09/22/2022
Specifies a manifest input file to include in the manifest that's embedded in the image.
Syntax
/MANIFESTINPUT: filename
Parameters
filename
The manifest file to include in the embedded manifest.
Remarks
The /MANIFESTINPUT option specifies the path of an input file to use to create the
embedded manifest in an executable image. If you have multiple manifest input files,
use the switch multiple times: once for each input file. The manifest input files are
merged to create the embedded manifest. This option requires the /MANIFEST:EMBED
option.
This option can't be set directly in Visual Studio. Instead, use the Additional Manifest
Files property of the project to specify additional manifest files to include. For more
information, see Manifest Tool Property Pages.
See also
MSVC linker reference
MSVC Linker Options
/MANIFESTUAC (Embeds UAC
information in manifest)
Article • 08/03/2021
Specifies whether User Account Control (UAC) information is embedded in the program
manifest.
Syntax
/MANIFESTUAC
/MANIFESTUAC:NO
/MANIFESTUAC: level
/MANIFESTUAC: uiAccess
/MANIFESTUAC: fragment
Parameters
NO
The linker doesn't embed UAC information in the program manifest.
level
level= followed by one of 'asInvoker' , 'highestAvailable' , or
'requireAdministrator' . Defaults to 'asInvoker' . For more information, see the
Remarks section.
uiAccess
uiAccess='true' if you want the application to bypass user interface protection levels
and drive input to higher-permission windows on the desktop; otherwise,
uiAccess='false' . Defaults to uiAccess='false' . Set this argument to uiAccess='true'
only for user interface accessibility applications.
fragment
A string that contains the level and uiAccess values. May optionally be enclosed in
double quotes. For more information, see the Remarks section.
Remarks
If you specify multiple /MANIFESTUAC options on the command-line, the last one entered
takes precedence.
The choices for /MANIFESTUAC: level are as follows:
level='asInvoker' : The application runs at the same permission level as the
process that started it. You can elevate the application to a higher permission level
by selecting Run as Administrator.
level='highestAvailable' : The application runs at the highest permission level
that it can. If the user who starts the application is a member of the Administrators
group, this option is the same as level='requireAdministrator' . If the highest
available permission level is higher than the level of the opening process, the
system prompts for credentials.
level='requireAdministrator' : The application runs using administrator
permissions. The user who starts the application must be a member of the
Administrators group. If the opening process isn't running with administrative
permissions, the system prompts for credentials.
You can specify both the level and uiAccess values in one step by using the
/MANIFESTUAC: fragment option. The fragment must be in the following form:
/MANIFESTUAC: [ " ] level= { 'asInvoker' | 'highestAvailable' |
'requireAdministrator' } uiAccess= { 'true' | 'false' } [ " ]
For example:
/MANIFESTUAC:"level='highestAvailable' uiAccess='true'"
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Manifest File property page.
3. Modify the Enable User Account Control (UAC), UAC Execution Level, and UAC
Bypass UI Protection properties.
To set this linker option programmatically
1. See EnableUAC, UACExecutionLevel, and UACUIAccess.
See also
MSVC linker reference
MSVC Linker Options
/MAP (Generate Mapfile)
Article • 08/03/2021
/MAP[:filename]
Arguments
filename
A user-specified name for the mapfile. It replaces the default name.
Remarks
The /MAP option tells the linker to create a mapfile.
By default, the linker names the mapfile with the base name of the program and the
extension .map. The optional filename allows you to override the default name for a
mapfile.
A mapfile is a text file that contains the following information about the program being
linked:
The module name, which is the base name of the file
The timestamp from the program file header (not from the file system)
A list of groups in the program, with each group's start address (as section:offset),
length, group name, and class
A list of public symbols, with each address (as section:offset), symbol name, flat
address, and .obj file where the symbol is defined
The entry point (as section:offset)
The /MAPINFO option specifies additional information to be included in the mapfile.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Debug property page.
3. Modify the Generate Map File property.
To set this linker option programmatically
1. See GenerateMapFile and MapFileName.
See also
MSVC linker reference
MSVC Linker Options
/MAPINFO (Include Information in
Mapfile)
Article • 08/03/2021
/MAPINFO:EXPORTS
Remarks
The /MAPINFO option tells the linker to include the specified information in a mapfile,
which is created if you specify the /MAP option. EXPORTS tells the linker to include
exported functions.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Debug property page.
3. Modify of the Map Exports properties:
To set this linker option programmatically
See MapExports.
See also
MSVC linker reference
MSVC Linker Options
/MERGE (Combine Sections)
Article • 08/03/2021
/MERGE:from=to
Remarks
The /MERGE option combines the first section (from) with the second section (to),
naming the resulting section to. For example, /merge:.rdata=.text .
If the second section does not exist, LINK renames the section from as to.
The /MERGE option is useful for creating VxDs and overriding the compiler-generated
section names.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Merge Sections property.
To set this linker option programmatically
1. See MergeSections.
See also
MSVC linker reference
MSVC Linker Options
/MIDL (Specify MIDL Command Line
Options)
Article • 08/03/2021
Specifies a response file for MIDL command line options
Syntax
/MIDL:@file
Arguments
file
The name of the file that contains MIDL command line options.
Remarks
All options for the conversion of an IDL file to a TLB file must be given in file; MIDL
command-line options cannot be specified on the linker's command line. If /MIDL is not
specified, the MIDL compiler will be invoked with only the IDL file name and no other
options.
The file should contain one MIDL command-line option per line.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Embedded IDL property page.
3. Modify the MIDL Commands property.
To set this linker option programmatically
See MidlCommandFile.
See also
MSVC linker reference
MSVC Linker Options
/IDLOUT (Name MIDL Output Files)
/IGNOREIDL (Don't Process Attributes into MIDL)
/TLBOUT (Name .TLB File)
Building an Attributed Program
/NATVIS (Add Natvis to PDB)
Article • 09/22/2022
Specifies a debugger visualization file (a Natvis file) to embed in the PDB file generated
by the linker.
Syntax
/NATVIS: filename
Parameters
filename
The pathname for a Natvis file to add to the PDB file. It embeds the debugger
visualizations in the Natvis file into the PDB.
Remarks
The /NATVIS linker option embeds the debugger visualizations defined in the Natvis file
filename into the PDB file generated by LINK. A Natvis file has a .natvis extension.
Embedding the information allows the debugger to display the visualizations
independently of the Natvis file. You can use multiple /NATVIS options to embed more
than one Natvis file in the generated PDB file. For more information on how to create
and use Natvis files, see Create custom views of native objects in the Visual Studio
debugger.
LINK ignores /NATVIS when a PDB file isn't created by using a /DEBUG option.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Add the /NATVIS option to the Additional Options text box. Choose OK or Apply
to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/NOASSEMBLY (Create a MSIL Module)
Article • 08/03/2021
/NOASSEMBLY
Remarks
The /NOASSEMBLY option tells the linker to create an image for the current output file
without a .NET Framework assembly. An MSIL output file without an assembly manifest
is called a module.
By default, an assembly is created. You can also use the /LN (Create MSIL Module)
compiler option to create a module.
Other linker options that affect assembly generation are:
/ASSEMBLYDEBUG
/ASSEMBLYLINKRESOURCE
/ASSEMBLYMODULE
/ASSEMBLYRESOURCE
/DELAYSIGN
/KEYFILE
/KEYCONTAINER
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Turn Off Assembly Generation property.
To set this linker option programmatically
See TurnOffAssemblyGeneration.
See also
MSVC linker reference
MSVC Linker Options
/NODEFAULTLIB (Ignore Libraries)
Article • 09/22/2022
The /NODEFAULTLIB linker option tells the linker to remove one or more default libraries
from the list of libraries it searches when it resolves external references.
Syntax
/NODEFAULTLIB [ : library ]
Arguments
library
An optional library name that you want the linker to ignore when it resolves external
references.
Remarks
To create an .obj file that contains no references to default libraries, use /Zl (Omit
default library name).
By default, /NODEFAULTLIB removes all default libraries from the list of libraries it
searches when resolving external references. The optional library parameter lets you
remove a specified library from the list of libraries it searches when resolving external
references. Specify one /NODEFAULTLIB option for each library you want to exclude.
The linker resolves references to external definitions by searching first in libraries that
you explicitly specify, then in default libraries specified by the /DEFAULTLIB option, and
then in default libraries named in .obj files.
/NODEFAULTLIB: library overrides /DEFAULTLIB: library when the same library name
is specified in both.
If you use /NODEFAULTLIB to build your program without the C run-time library, you may
also have to use the /ENTRY option to specify the entry-point function in your program.
For more information, see CRT library features.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Input property page.
3. Modify the Ignore All Default Libraries property. Or, specify a semicolon￾separated list of the libraries you want to ignore in the Ignore Specific Default
Libraries property. The Linker > Command Line property page shows the effect of
the changes you make to these properties.
4. Choose OK or Apply to save your changes.
To set this linker option programmatically
See IgnoreDefaultLibraryNames and IgnoreAllDefaultLibraries.
See also
MSVC linker reference
MSVC linker options
/NOENTRY (No Entry Point)
Article • 08/03/2021
/NOENTRY
Remarks
The /NOENTRY option is required for creating a resource-only DLL that contains no
executable code. For more information, see Creating a Resource-Only DLL.
Use this option to prevent LINK from linking a reference to _main into the DLL.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the No Entry Point property.
To set this linker option programmatically
1. See ResourceOnlyDLL.
See also
Creating a Resource-Only DLL
MSVC linker reference
MSVC Linker Options
/NOFUNCTIONPADSECTION (Disable
function padding)
Article • 01/10/2024
Disables function padding for functions in the specified section.
Syntax
/NOFUNCTIONPADSECTION:[name]
Arguments
name
The name of the section to disable x64 function padding in.
Remarks
You can instruct the linker to put a specified minimum number of bytes between
functions with /FUNCTIONPADMIN (Create hotpatchable image) and
/ARM64XFUNCTIONPADMINX64. This flag disables adding that padding for the
specified sections.
To exclude multiple sections, specify the switch multiple times.
This flag is available starting with in Visual Studio 17.8 and later.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Modify the Additional Options property to include
/NOFUNCTIONPADSECTION: name , where name is the name of the section to
disable x64 function padding in, and then choose OK.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC Linker Options
MSVC linker reference
/NOLOGO (Suppress Startup Banner)
(Linker)
Article • 08/03/2021
/NOLOGO
Remarks
The /NOLOGO option prevents display of the copyright message and version number.
This option also suppresses echoing of command files. For details, see LINK Command
Files.
By default, this information is sent by the linker to the Output window. On the command
line, it is sent to standard output and can be redirected to a file.
To set this linker option in the Visual Studio development
environment
1. This option should only be used from the command line.
To set this linker option programmatically
1. This linker option cannot be changed programmatically.
See also
MSVC linker reference
MSVC Linker Options
/NXCOMPAT (Compatible with Data
Execution Prevention)
Article • 09/22/2022
Indicates that an executable is compatible with the Windows Data Execution Prevention
feature.
Syntax
/NXCOMPAT [ :NO ]
Remarks
By default, /NXCOMPAT is on.
/NXCOMPAT:NO can be used to explicitly specify an executable as incompatible with Data
Execution Prevention.
For more information about Data Execution Prevention, see these articles:
Data Execution Prevention
Data Execution Prevention (Windows Embedded)
To set this linker option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Choose the Configuration Properties > Linker > Advanced property page.
3. Modify the Data Execution Prevention (DEP) property. Choose OK or Apply to
apply the change.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/OPT (Optimizations)
Article • 02/17/2022
Controls the optimizations that LINK performs during a build.
Syntax
/OPT:{REF | NOREF}
/OPT:{ICF[=iterations] | NOICF}
/OPT:{LBR | NOLBR}
Arguments
REF | NOREF
/OPT:REF eliminates functions and data that are never referenced; /OPT:NOREF keeps
functions and data that are never referenced.
When /OPT:REF is enabled, LINK removes unreferenced packaged functions and data,
known as COMDATs. This optimization is known as transitive COMDAT elimination. The
/OPT:REF option also disables incremental linking.
Inlined functions and member functions defined inside a class declaration are always
COMDATs. All of the functions in an object file are made into COMDATs if it is compiled
by using the /Gy option. To place const data in COMDATs, you must declare it by using
__declspec(selectany) . For information about how to specify data for removal or
folding, see selectany.
By default, /OPT:REF is enabled by the linker unless /OPT:NOREF or /DEBUG is specified.
To override this default and keep unreferenced COMDATs in the program, specify
/OPT:NOREF. You can use the /INCLUDE option to override the removal of a specific
symbol.
If /DEBUG is specified, the default for /OPT is NOREF, and all functions are preserved in
the image. To override this default and optimize a debug build, specify /OPT:REF. This
can reduce the size of your executable, and can be a useful optimization even in debug
builds. We recommend that you also specify /OPT:NOICF to preserve identical functions
in debug builds. This makes it easier to read stack traces and set breakpoints in
functions that would otherwise be folded together.
ICF[=iterations] | NOICF
Use ICF[=iterations] to perform identical COMDAT folding. Redundant COMDATs can be
removed from the linker output. The optional iterations parameter specifies the number
of times to traverse the symbols for duplicates. The default number of iterations is 1.
Additional iterations may locate more duplicates that are uncovered through folding in
the previous iteration.
By default, /OPT:ICF is enabled by the linker unless /OPT:NOICF or /DEBUG is specified.
To override this default and prevent COMDATs from being folded in the program,
specify /OPT:NOICF.
In a debug build, you must explicitly specify /OPT:ICF to enable COMDAT folding.
However, because /OPT:ICF can merge identical data or functions, it can change the
function names that appear in stack traces. It can also make it impossible to set
breakpoints in certain functions or to examine some data in the debugger, and can take
you into unexpected functions when you single-step through your code. The behavior of
the code is identical, but the debugger presentation can be very confusing. Therefore,
we do not recommend that you use /OPT:ICF in debug builds unless the advantages of
smaller code outweigh these disadvantages.
７ Note
Because /OPT:ICF can cause the same address to be assigned to different functions
or read-only data members (that is, const variables when compiled by using /Gy),
it can break a program that depends on unique addresses for functions or read￾only data members. For more information, see /Gy (Enable Function-Level
Linking).
LBR | NOLBR
The /OPT:LBR and /OPT:NOLBR options apply only to ARM binaries. Because certain
ARM processor branch instructions have a limited range, if the linker detects a jump to
an out-of-range address, it replaces the branch instruction's destination address with
the address of a code "island" that contains a branch instruction that targets the actual
destination. You can use /OPT:LBR to optimize the detection of long branch instructions
and the placement of intermediate code islands to minimize overall code size.
/OPT:NOLBR instructs the linker to generate code islands for long branch instructions as
they are encountered, without optimization.
By default, the /OPT:LBR option is set when incremental linking is not enabled. If you
want a non-incremental link but not long branch optimizations, specify /OPT:NOLBR.
The /OPT:LBR option disables incremental linking.
Remarks
When used at the command line, the linker defaults to /OPT:REF,ICF,LBR. If /DEBUG is
specified, the default is /OPT:NOREF,NOICF,NOLBR.
The /OPT optimizations generally decrease the image size and increase the program
speed. These improvements can be substantial in larger programs, which is why they are
enabled by default for retail builds.
Linker optimization does take extra time up front, but the optimized code also saves
time when the linker has fewer relocations to fix up and creates a smaller final image,
and it saves even more time when it has less debug information to process and write
into the PDB. When optimization is enabled, it can result in a faster link time overall, as
the small additional cost in analysis may be more than offset by the time savings in
linker passes over smaller binaries.
The /OPT arguments may be specified together, separated by commas. For example,
instead of /OPT:REF /OPT:NOICF, you can specify /OPT:REF,NOICF.
You can use the /VERBOSE linker option to see the functions that are removed by
/OPT:REF and the functions that are folded by /OPT:ICF.
The /OPT arguments are often set for projects created by using the New Project dialog
in the Visual Studio IDE, and usually have different values for debug and release
configurations. If no value is set for these linker options in your project, then you may
get the project defaults, which can be different from the default values used by the
linker at the command line.
To set the OPT:ICF or OPT:REF linker option in the Visual
Studio development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Optimization property page.
3. Modify one of these properties:
Enable COMDAT Folding
References
To set the OPT:LBR linker option in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option in Additional Options:
/opt:lbr or /opt:nolbr
To set this linker option programmatically
See EnableCOMDATFolding and OptimizeReferences properties.
See also
MSVC linker reference
MSVC Linker Options
/ORDER (Put Functions in Order)
Article • 08/03/2021
Specify the link order for separately packaged (COMDAT) functions.
Syntax
/ORDER:@filename
Parameters
filename
A text file that specifies the link order for COMDAT functions.
Remarks
The /ORDER compiler option allows you to optimize your program's paging behavior by
grouping a function together with the functions it calls. You can also group frequently
called functions together. These techniques, known as swap tuning or paging
optimization, increase the probability that a called function is in memory when it is
needed and does not have to be paged from disk.
When you compile your source code into an object file, you can tell the compiler to put
each function into its own section, called a COMDAT, by using the /Gy (Enable function￾level linking) compiler option. The /ORDER linker option tells the linker to place
COMDATs into the executable image in the order you specify.
To specify the COMDAT order, create a response file, a text file that lists each COMDAT
by name, one per line, in the order you want them to be placed by the linker. Pass the
name of this file as the filename parameter of the /ORDER option. For C++ functions,
the name of a COMDAT is the decorated form of the function name. Use the
undecorated name for C functions, main , and for C++ functions declared as extern "C" .
Function names and decorated names are case sensitive. For more information on
decorated names, see Decorated Names.
To find the decorated names of your COMDATs, use the DUMPBIN tool's /SYMBOLS
option on the object file. The linker automatically prepends an underscore (_) to function
names in the response file unless the name starts with a question mark (?) or at sign (@).
For example, if a source file, example.cpp, contains functions int cpp_func(int) , extern
"C" int c_func(int) and int main(void) , the command DUMPBIN /SYMBOLS example.obj
lists these decorated names:
Output
...
088 00000000 SECT1A notype () External | ?cpp_func@@YAHH@Z (int
__cdecl cpp_func(int))
089 00000000 SECT22 notype () External | _c_func
08A 00000000 SECT24 notype () External | _main
...
In this case, specify the names as ?cpp_func@@YAHH@Z , c_func , and main in your response
file.
If more than one /ORDER option appears in the linker options, the last one specified
takes effect.
The /ORDER option disables incremental linking. You may see linker warning LNK4075
when you specify this option if incremental linking is enabled, or if you have specified
the /ZI (Incremental PDB) compiler option. To silence this warning, you can use the
/INCREMENTAL:NO linker option to turn off incremental linking, and use the /Zi
(Generate PDB) compiler option to generate a PDB without incremental linking.
７ Note
LINK cannot order static functions because static function names are not public
symbol names. When /ORDER is specified, linker warning LNK4037 is generated for
each symbol in the order response file that is either static or not found.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Optimization property page.
3. Modify the Function Order property to contain the name of your response file.
To set this linker option programmatically
See FunctionOrder.
See also
MSVC linker reference
MSVC Linker Options
/OUT (Output File Name)
Article • 08/03/2021
/OUT:filename
Arguments
filename
A user-specified name for the output file. It replaces the default name.
Remarks
The /OUT option overrides the default name and location of the program that the linker
creates.
By default, the linker forms the file name using the base name of the first .obj file
specified and the appropriate extension (.exe or .dll).
This option the default base name for a .mapfile or import library. For details, see
Generate Mapfile (/MAP) and /IMPLIB.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Output File property.
To set this linker option programmatically
See OutputFile.
See also
MSVC linker reference
MSVC Linker Options
/PDB (Use Program Database)
Article • 08/03/2021
/PDB:filename
Arguments
filename
A user-specified name for the program database (PDB) that the linker creates. It replaces
the default name.
Remarks
By default, when /DEBUG is specified, the linker creates a program database (PDB) which
holds debugging information. The default file name for the PDB has the base name of
the program and the extension .pdb.
Use /PDB:filename to specify the name of the PDB file. If /DEBUG is not specified, the
/PDB option is ignored.
A PDB file can be up to 2GB.
For more information, see .pdb Files as Linker Input.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Debug property page.
3. Modify the Generate Program Database File property.
To set this linker option programmatically
See ProgramDatabaseFile.
See also
MSVC linker reference
MSVC Linker Options
/PDBALTPATH (Use Alternate PDB Path)
Article • 08/03/2021
/PDBALTPATH:pdb_file_name
Arguments
pdb_file_name
The path and file name for the .pdb file.
Remarks
Use this option to provide an alternate location for the Program Database (.pdb) file in a
compiled binary file. Normally, the linker records the location of the .pdb file in the
binaries that it produces. You can use this option to provide a different path and file
name for the .pdb file. The information provided with /PDBALTPATH does not change
the location or name of the actual .pdb file; it changes the information that the linker
writes in the binary file. This enables you to provide a path that is independent of the file
structure of the build computer. Two common uses for this option are to provide a
network path or a file that has no path information.
The value of pdb_file_name can be an arbitrary string, an environment variable, or
%_PDB%. The linker will expand an environment variable, such as %SystemRoot%, to its
value. The linker defines the environment variables %_PDB% and %_EXT%. %_PDB%
expands to the file name of the actual .pdb file without any path information and
%_EXT% is the extension of the generated executable.
See also
DUMPBIN Options
/PDBPATH
/PDBSTRIPPED (Strip Private Symbols)
Article • 08/03/2021
/PDBSTRIPPED:pdb_file_name
Arguments
pdb_file_name
A user-specified name for the stripped program database (PDB) that the linker creates.
Remarks
The /PDBSTRIPPED option creates a second program database (PDB) file when you build
your program image with any of the compiler or linker options that generate a PDB file
(/DEBUG, /Z7, /Zd, or /Zi). This second PDB file omits symbols that you would not want
to ship to your customers. The second PDB file will only contain:
Public symbols
The list of object files and the portions of the executable to which they contribute
Frame pointer optimization (FPO) debug records used to traverse the stack
The stripped PDB file will not contain:
Type information
Line number information
Per-object file CodeView symbols such as those for functions, locals, and static
data
The full PDB file will still be generated when you use /PDBSTRIPPED.
If you do not create a PDB file, /PDBSTRIPPED is ignored.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Debug property page.
3. Modify the Strip Private Symbols property.
To set this linker option programmatically
See StripPrivateSymbols.
See also
MSVC linker reference
MSVC Linker Options
/PGD (Specify Database for Profile￾Guided Optimizations)
Article • 08/03/2021
The /PGD option is deprecated. Starting in Visual Studio 2015, prefer the /GENPROFILE
or /FASTGENPROFILE linker options instead. This option is used to specify the name of
the .pgd file used by the profile-guided optimization process.
Syntax
/PGD:filename
Argument
filename
Specifies the name of the .pgd file that is used to hold information about the running
program.
Remarks
When using the deprecated /LTCG:PGINSTRUMENT option, use /PGD to specify a
nondefault name or location for the .pgd file. If you do not specify /PGD, the .pgd file
base name is the same as the output file (.exe or .dll) base name and is created in the
same directory from which the link was invoked.
When using the deprecated /LTCG:PGOPTIMIZE option, use the /PGD option to specify
the name of the .pgd file to use to create the optimized image. The filename argument
should match the filename specified to /LTCG:PGINSTRUMENT.
For more information, see Profile-Guided Optimizations.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Optimization property page.
3. Modify the Profile Guided Database property. Choose OK to save your changes.
To set this linker option programmatically
1. See ProfileGuidedDatabase.
See also
MSVC linker reference
MSVC Linker Options
/POGOSAFEMODE (Run PGO in thread
safe mode)
Article • 08/03/2021
The /POGOSAFEMODE option is deprecated starting in Visual Studio 2015. Use the
/GENPROFILE:EXACT and /GENPROFILE:NOEXACT options instead. The
/POGOSAFEMODE linker option specifies that the instrumented build is created to use
thread-safe mode for profile data capture during profile-guided optimization (PGO)
training runs.
Syntax
/POGOSAFEMODE
Remarks
Profile-guided optimization (PGO) has two possible modes during the profiling phase:
fast mode and safe mode. When profiling is in fast mode, it uses an increment instruction
to increase data counters. The increment instruction is faster but is not thread-safe.
When profiling is in safe mode, it uses the interlocked-increment instruction to increase
data counters. This instruction has the same functionality as the increment instruction
has, and is thread-safe, but it is slower.
The /POGOSAFEMODE option sets the instrumented build to use safe mode. This
option can only be used when the deprecated /LTCG:PGINSTRUMENT is specified,
during the PGO instrumentation linker phase.
By default, PGO profiling operates in fast mode. /POGOSAFEMODE is only required if
you want to use safe mode.
To run PGO profiling in safe mode, you must use either /GENPROFILE:EXACT
(preferred), or use the environment variable PogoSafeMode or the linker switch
/POGOSAFEMODE, depending on the system. If you are performing the profiling on an
x64 computer, you must use the linker switch. If you are performing the profiling on an
x86 computer, you may use the linker switch or define the environment variable to any
value before you start the PGO instrumentation process.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Optimization property page.
3. In the Link Time Code Generation property, choose Profile Guided Optimization -
Instrument (/LTCG:PGInstrument).
4. Select the Configuration Properties > Linker > Command Line property page.
5. Enter the /POGOSAFEMODE option into the Additional Options box. Choose OK
to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
/GENPROFILE and /FASTGENPROFILE
/LTCG
Profile-Guided Optimizations
Environment Variables for Profile-Guided Optimizations
/PROFILE (Performance Tools Profiler)
Article • 10/14/2021
Produces an output file that can be used with the Performance Tools profiler.
Syntax
/PROFILE
Remarks
/PROFILE implies the following linker options:
/DEBUG:FULL
/DEBUGTYPE:cv,fixup
/OPT:REF
/OPT:NOICF
/INCREMENTAL:NO
/FIXED:NO
/PROFILE is used to support the Performance Tools for Visual Studio Profiler utility
VSInstr.exe.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Profile property.
To set this linker option programmatically
1. See Profile.
To set this linker option in a Visual Studio CMake project
Because a CMake project doesn't have the usual Property Pages support, the linker
option can be set by modifying the CMakeLists.txt file.
1. Open the CMakeLists.txt file in the project root directory.
2. Add the code below. For more information, see the CMake set_target_properties
documentation.
txt
SET_TARGET_PROPERTIES(${PROJECT_NAME} PROPERTIES LINK_FLAGS "/PROFILE")
3. Rebuild your solution.
See Also
MSVC linker reference
MSVC linker options
/RELEASE (Set the Checksum)
Article • 08/03/2021
/RELEASE
Remarks
The /RELEASE option sets the Checksum in the header of an .exe file.
The operating system requires the Checksum for device drivers. Set the Checksum for
release versions of your device drivers to ensure compatibility with future operating
systems.
The /RELEASE option is set by default when the /SUBSYSTEM:NATIVE option is specified.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Click the Linker folder.
3. Click the Advanced property page.
4. Modify the Set Checksum property.
To set this linker option programmatically
See SetChecksum.
See also
MSVC linker reference
MSVC Linker Options
/SAFESEH (Image has Safe Exception
Handlers)
Article • 09/22/2022
When /SAFESEH is specified, the linker only produces an image if it can also produce a
table of the image's safe exception handlers. This table specifies to the operating system
which exception handlers are valid for the image.
Syntax
/SAFESEH
/SAFESEH:NO
Remarks
/SAFESEH is only valid when linking for x86 targets. /SAFESEH isn't supported for
platforms that already have the exception handlers noted. For example, on x64 and
ARM, all exception handlers are noted in the PDATA. ML64.exe has support for adding
annotations that emit SEH information (XDATA and PDATA) into the image, allowing you
to unwind through ml64 functions. For more information, see MASM for x64 (ml64.exe).
If /SAFESEH isn't specified, the linker will produce an image with a table of safe
exceptions handlers if all code segments are compatible with the safe exception
handling feature. If any code segments weren't compatible with the safe exception
handling feature, the resulting image won't contain a table of safe exception handlers. If
/SUBSYSTEM specifies WINDOWSCE or one of the EFI_* options, the linker won't attempt
to produce an image with a table of safe exceptions handlers, as neither of those
subsystems can make use of the information.
If /SAFESEH:NO is specified, the linker won't produce an image with a table of safe
exceptions handlers even if all code segments are compatible with the safe exception
handling feature.
The most common reason the linker can't produce an image is because one or more of
the input files to the linker was incompatible with the safe exception handlers feature. A
common reason why code is incompatible with safe exception handlers is because it was
created with a compiler from a previous version of Visual C++.
You can also register a function as a structured exception handler by using .SAFESEH.
It isn't possible to mark an existing binary as having safe exception handlers (or no
exception handlers); information on safe exception handling must be added at build
time.
The linker's ability to build a table of safe exception handlers depends on the
application using the C runtime library. If you link with /NODEFAULTLIB and you want a
table of safe exception handlers, you need to supply a load config struct (such as can be
found in the loadcfg.c CRT source file) that contains all the entries defined for Visual
C++. For example:
C
#include <windows.h>
extern DWORD_PTR __security_cookie; /* /GS security cookie */
/*
* The following two names are automatically created by the linker for any
* image that has the safe exception table present.
*/
extern PVOID __safe_se_handler_table[]; /* base of safe handler entry table
*/
extern BYTE __safe_se_handler_count; /* absolute symbol whose address is
 the count of table entries */
typedef struct {
 DWORD Size;
 DWORD TimeDateStamp;
 WORD MajorVersion;
 WORD MinorVersion;
 DWORD GlobalFlagsClear;
 DWORD GlobalFlagsSet;
 DWORD CriticalSectionDefaultTimeout;
 DWORD DeCommitFreeBlockThreshold;
 DWORD DeCommitTotalFreeThreshold;
 DWORD LockPrefixTable; // VA
 DWORD MaximumAllocationSize;
 DWORD VirtualMemoryThreshold;
 DWORD ProcessHeapFlags;
 DWORD ProcessAffinityMask;
 WORD CSDVersion;
 WORD Reserved1;
 DWORD EditList; // VA
 DWORD_PTR *SecurityCookie;
 PVOID *SEHandlerTable;
 DWORD SEHandlerCount;
} IMAGE_LOAD_CONFIG_DIRECTORY32_2;
const IMAGE_LOAD_CONFIG_DIRECTORY32_2 _load_config_used = {
 sizeof(IMAGE_LOAD_CONFIG_DIRECTORY32_2),
 0,
 0,
 0,
1. Open the Property Pages dialog box for the project. For more information, see Set
compiler and build properties.
2. Select the Configuration Properties > Linker > Advanced property page.
3. Modify the Image Has Safe Exception Handlers property. Choose OK or Apply to
save your changes.
See AdditionalOptions.
MSVC linker reference
MSVC linker options
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 0,
 &__security_cookie,
 __safe_se_handler_table,
 (DWORD)(DWORD_PTR) &__safe_se_handler_count
};
To set this linker option in the Visual Studio development
environment
To set this linker option programmatically
See also
/SECTION (Specify Section Attributes)
Article • 09/22/2022
/SECTION: name , [[ ! ]{ D | E | K | P | R | S | W }][ ,ALIGN= number ]
Remarks
The /SECTION option changes the attributes of a section, overriding the attributes set
when the .obj file for the section was compiled.
A section in a portable executable (PE) file is a named contiguous block of memory that
contains either code or data. Some sections contain code or data that your program
declared and uses directly. Other data sections are created for you by the linker and
library manager (LIB) and contain information vital to the operating system. For more
information, see PE Format.
Specify a colon ( : ) and a section name name . The name is case sensitive.
Don't use the following names, as they conflict with standard names. For example,
.sdata is used on RISC platforms:
.arch
.bss
.data
.edata
.idata
.pdata
.rdata
.reloc
.rsrc
.sbss
.sdata
.srdata
.text
.xdata
Specify one or more attributes for the section. The attribute characters, listed below,
aren't case sensitive. You must specify all attributes that you want the section to have.
An omitted attribute character causes that attribute bit to be turned off. If you don't
specify R , W , or E , the existing read, write, or executable status remains unchanged.
To negate an attribute, precede its character with an exclamation point ( ! ). The
meanings of the attribute characters are shown in this table:
Character Attribute Meaning
E Execute The section is executable
R Read Allows read operations on data
W Write Allows write operations on data
S Shared Shares the section among all processes that load the image
D Discardable Marks the section as discardable
K Cacheable Marks the section as not cacheable
P Pageable Marks the section as not pageable
K and P are unusual in that the section flags that correspond to them are used in the
negative sense. If you specify one of them on the .text section by using the
/SECTION:.text,K option, there's no difference in the section flags when you run
DUMPBIN with the /HEADERS option; the section was already implicitly cached. To
remove the default, specify /SECTION:.text,!K instead. DUMPBIN reveals section
characteristics, including "Not Cached."
A section in the PE file that doesn't have E , R , or W set is probably invalid.
The ALIGN= number argument lets you specify an alignment value for a particular section.
The number argument is in bytes and must be a power of two. For more information, see
/ALIGN.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. Choose the Configuration Properties > Linker > General property page.
3. Modify the Specify Section Attributes property. Choose OK or Apply to save your
changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/SOURCELINK (Include Source Link file
in PDB)
Article • 08/03/2021
Specifies a Source Link configuration file to include in the PDB file generated by the
linker.
Syntax
/SOURCELINK: filename
Arguments
filename
Specifies a JSON-formatted configuration file that contains a simple mapping of local
file paths to URLs for source files to display in the debugger. For more information on
the format of this file, see Source Link JSON Schema .
Remarks
Source Link is a language- and source-control agnostic system for providing source
debugging for binaries. Source Link is supported for native C++ binaries starting in
Visual Studio 2017 version 15.8. For an overview of Source Link, see Source Link . For
information on how to use Source Link in your projects, and how to generate the
SourceLink file as part of your project, see Using Source Link .
To set the /SOURCELINK linker option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In the Additional options box, add /SOURCELINK: filename and then choose OK or
Apply to save your changes.
To set this linker option programmatically
This option doesn't have a programmatic equivalent.
See also
MSVC linker reference
MSVC Linker Options
/STACK (Stack allocations)
Article • 02/23/2022
/STACK: reserve [ , commit ]
Remarks
The /STACK linker option sets the size of the stack in bytes. Use this option only when
you build an .exe file. The /STACK option is ignored when applied to .dll files.
The reserve value specifies the total stack allocation in virtual memory. For ARM64, x86,
and x64 machines, the default stack size is 1 MB.
The commit value is subject to interpretation by the operating system. In WindowsRT, it
specifies the amount of physical memory to allocate at a time. Committed virtual
memory causes space to be reserved in the paging file. A higher commit value saves
time when the application needs more stack space, but increases the memory
requirements and possibly the startup time. For ARM64, x86, and x64 machines, the
default commit value is 4 KB.
Specify the reserve and commit values in decimal or C-language hexadecimal notation
(use a 0x prefix).
Another way to set the size of the stack is with the STACKSIZE statement in a module￾definition ( .def ) file. STACKSIZE overrides the Stack Allocations ( /STACK ) option if both
are specified. You can change the stack size after the .exe file is built by using the
EDITBIN tool.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify one of the following properties:
Stack Commit Size
Stack Reserve Size
To set this linker option programmatically
1. See StackCommitSize and StackReserveSize properties.
See also
MSVC linker reference
MSVC linker options
/STUB (MS-DOS Stub File Name)
Article • 08/03/2021
/STUB:filename
Arguments
filename
An MS-DOS application.
Remarks
The /STUB option attaches an MS-DOS stub program to a Win32 program.
A stub program is invoked if the file is executed in MS-DOS. It usually displays an
appropriate message; however, any valid MS-DOS application can be a stub program.
Specify a filename for the stub program after a colon (:) on the command line. The linker
checks filename and issues an error message if the file is not an executable. The
program must be an .exe file; a .com file is invalid for a stub program.
If this option is not used, the linker attaches a default stub program that issues the
following message:
This program cannot be run in MS-DOS mode.
When building a virtual device driver, filename allows the user to specify a file name that
contains an IMAGE_DOS_HEADER structure (defined in WINNT.H) to be used in the VXD,
rather than the default header.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Enter the option into the Additional Options box.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC Linker Options
/SUBSYSTEM (Specify Subsystem)
Article • 09/22/2022
Specify the Windows subsystem targeted by the executable.
/SUBSYSTEM: { BOOT_APPLICATION | CONSOLE | EFI_APPLICATION |
  EFI_BOOT_SERVICE_DRIVER | EFI_ROM | EFI_RUNTIME_DRIVER | NATIVE |
  POSIX | WINDOWS }
  [ , major [ . minor ]]
BOOT_APPLICATION
An application that runs in the Windows boot environment. For more information about
boot applications, see About BCD.
CONSOLE
Win32 character-mode application. The operating system provides a console for console
applications. If main or wmain is defined for native code, int main(array<String ^> ^) is
defined for managed code, or you build the application completely by using /clr:safe ,
CONSOLE is the default.
EFI_APPLICATION
EFI_BOOT_SERVICE_DRIVER
EFI_ROM
EFI_RUNTIME_DRIVER
The Extensible Firmware Interface subsystems. For more information, see the UEFI
specification . For examples, see the Intel UEFI Driver and Application Tool
Resources . The minimum version and default version is 1.0.
NATIVE
Kernel mode drivers for Windows NT. This option is normally reserved for Windows
system components. If /DRIVER:WDM is specified, NATIVE is the default.
POSIX
Application that runs with the POSIX subsystem in Windows NT.
Syntax
Arguments
WINDOWS
The application doesn't require a console, probably because it creates its own windows
for interaction with the user. If WinMain or wWinMain is defined for native code, or
WinMain(HINSTANCE *, HINSTANCE *, char *, int) or wWinMain(HINSTANCE *, HINSTANCE
*, wchar_t *, int) is defined for managed code, WINDOWS is the default.
major and minor
(Optional) Specify the minimum required version of the subsystem. The arguments are
decimal numbers in the range 0 through 65,535. There are no upper bounds for version
numbers.
The /SUBSYSTEM option specifies the environment for the executable.
The choice of subsystem affects the entry point symbol (or entry point function) that the
linker will select.
The optional minimum and default major and minor version numbers for the
subsystems are as follows:
Subsystem Minimum Default
BOOT_APPLICATION 1.0 1.0
CONSOLE 5.01 (x86) 5.02 (x64)
6.02 (ARM)
6.00 (x86, x64) 6.02
(ARM)
WINDOWS 5.01 (x86) 5.02 (x64)
6.02 (ARM)
6.00 (x86, x64) 6.02
(ARM)
NATIVE (with /DRIVER:WDM ) 1.00 (x86) 1.10 (x64,
ARM)
1.00 (x86) 1.10 (x64,
ARM)
NATIVE (without /DRIVER:WDM ) 4.00 (x86) 5.02 (x64)
6.02 (ARM)
4.00 (x86) 5.02 (x64)
6.02 (ARM)
POSIX 1.0 19.90
EFI_APPLICATION , EFI_BOOT_SERVICE_DRIVER ,
EFI_ROM , EFI_RUNTIME_DRIVER
1.0 1.0
Remarks
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify the SubSystem property.
To set this linker option programmatically
See SubSystem.
See also
MSVC linker reference
MSVC linker options
/SWAPRUN (Load Linker Output to
Swap File)
Article • 08/03/2021
/SWAPRUN:{NET|CD}
Remarks
The /SWAPRUN option tells the operating system to first copy the linker output to a
swap file, and then run the image from there. This is a Windows NT 4.0 (and later)
feature.
If NET is specified, the operating system will first copy the binary image from the
network to a swap file and load it from there. This option is useful for running
applications over the network. When CD is specified, the operating system will copy the
image on a removable disk to a page file and then load it.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify one of the following properties:
Swap Run From CD
Swap Run From Network
To set this linker option programmatically
1. See SwapRunFromCD and SwapRunFromNet properties.
See also
MSVC linker reference
MSVC Linker Options
/TLBID (Specify Resource ID for TypeLib)
Article • 08/03/2021
/TLBID:id
Arguments
id
A user-specified value for a linker-created type library. It overrides the default resource
ID of 1.
Remarks
When compiling a program that uses attributes, the linker will create a type library. The
linker will assign a resource ID of 1 to the type library.
If this resource ID conflicts with one of your existing resources, you can specify another
ID with /TLBID. The range of values that you can pass to id is 1 to 65535.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Embedded IDL property page.
3. Modify the TypeLib Resource ID property.
To set this linker option programmatically
1. See TypeLibraryResourceID.
See also
MSVC linker reference
MSVC Linker Options
/TLBOUT (Name .TLB File)
Article • 08/03/2021
/TLBOUT:[path\]filename
Arguments
path
An absolute or relative path specification for where the .tlb file should be created.
filename
Specifies the name of the .tlb file created by the MIDL compiler. No file extension is
assumed; specify filename.tlb if you want a .tlb extension.
Remarks
The /TLBOUT option specifies the name and extension of the .tlb file.
The MIDL compiler is called by the MSVC linker when linking projects that have the
module attribute.
If /TLBOUT is not specified, the .tlb file will get its name from /IDLOUT filename. If
/IDLOUT is not specified, the .tlb file will be called vc70.tlb.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Embedded IDL property page.
3. Modify the Type Library property.
To set this linker option programmatically
1. See TypeLibraryFile.
See also
MSVC linker reference
MSVC Linker Options
/IGNOREIDL (Don't Process Attributes into MIDL)
/MIDL (Specify MIDL Command Line Options)
Building an Attributed Program
/TSAWARE (Create Terminal Server aware
application)
Article • 03/03/2022
/TSAWARE [ :NO ]
Remarks
The /TSAWARE option sets a flag in the IMAGE_OPTIONAL_HEADER DllCharacteristics field
in the program image's optional header. When this flag is set, Terminal Server won't
make certain changes to the application.
When an application isn't Terminal Server aware (also known as a legacy application),
Terminal Server makes certain modifications to the legacy application to make it work
properly in a multiuser environment. For example, Terminal Server creates a virtual
Windows folder, such that each user gets a Windows folder instead of getting the system's
Windows directory. This virtual folder gives users access to their own INI files. In addition,
Terminal Server makes some adjustments to the registry for a legacy application. These
modifications slow the loading of the legacy application on Terminal Server.
If an application is Terminal Server aware, it must not rely on INI files or write to the
HKEY_CURRENT_USER registry during setup.
If you use /TSAWARE and your application still uses INI files, the files will be shared by all
users of the system. If that's acceptable, you can still link your application with /TSAWARE ;
otherwise you need to use /TSAWARE:NO .
The /TSAWARE option is enabled by default for Windows and console applications. For
more information, see /SUBSYSTEM and /VERSION.
/TSAWARE isn't valid for drivers or DLLs.
If an application was linked with /TSAWARE , DUMPBIN /HEADERS will display information
to that effect.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Modify the Terminal Server property.
To set this linker option programmatically
See TerminalServerAware.
See also
MSVC linker reference
MSVC Linker Options
Storing User-Specific Information
Legacy Applications in a Terminal Services Environment
/USEPROFILE (Run PGO in thread safe
mode)
Article • 08/03/2021
This linker option together with /LTCG (Link-time code generation tells the linker to
build by using profile-guided optimization (PGO) training data.
Syntax
/USEPROFILE[:{AGGRESSIVE|PGD=filename}]
Arguments
AGGRESSIVE
This optional argument specifies that aggressive speed optimizations should be used
during optimized code generation.
PGD=filename
Specifies a base file name for the .pgd file. By default, the linker uses the base
executable file name with a .pgd extension.
Remarks
The /USEPROFILE linker option is used together with /LTCG to generate or update an
optimized build based on PGO training data. It is the equivalent of the deprecated
/LTCG:PGUPDATE and /LTCG:PGOPTIMIZE options.
The optional AGGRESSIVE argument disables size-related heuristics to attempt to
optimize for speed. This may result in optimizations that substantially increase the size
of your executable, and may not increase the resulting speed. You should profile and
compare the results of using and not using AGGRESSIVE. This argument must be
specified explicitly; it is not enabled by default.
The PGD argument specifies an optional name for the training data .pgd file to use, the
same as in /GENPROFILE or /FASTGENPROFILE. It is the equivalent of the deprecated
/PGD switch. By default, or if no filename is specified, a .pgd file that has the same base
name as the executable is used.
The /USEPROFILE linker option is new in Visual Studio 2015.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Optimization property page.
3. In the Link Time Code Generation property, choose Use Link Time Code
Generation (/LTCG).
4. Select the Configuration Properties > Linker > Command Line property page.
5. Enter the /USEPROFILE option and optional arguments into the Additional
Options box. Choose OK to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
/GENPROFILE and /FASTGENPROFILE
/LTCG
Profile-Guided Optimizations
Environment Variables for Profile-Guided Optimizations
/VERBOSE (Print progress messages)
Article • 08/03/2021
Outputs progress messages during the link process.
/VERBOSE [ : { CLR | ICF | INCR | LIB | REF | SAFESEH | UNUSEDDELAYLOAD | UNUSEDLIBS }]
The linker sends information about the progress of the linking session to the Output
window. On the command line, the information is sent to standard output, and can be
redirected to a file.
Option Description
/VERBOSE Displays details about the linking process.
/VERBOSE:CLR Displays information about linker activity specific to objects and
metadata compiled by using /clr.
/VERBOSE:ICF Displays information about linker activity that results from the use of
/OPT:ICF.
/VERBOSE:INCR Displays information about the incremental link process.
/VERBOSE:LIB Displays progress messages that indicate just the libraries searched.
The displayed information includes the library search process. It lists
each library and object name (with full path), the symbol being
resolved from the library, and a list of objects that reference the
symbol.
/VERBOSE:REF Displays information about linker activity that results from the use of
/OPT:REF.
/VERBOSE:SAFESEH Displays information about modules that are incompatible with safe
structured exception handling when /SAFESEH isn't specified.
/VERBOSE:UNUSEDDELAYLOAD Displays information about any delay loaded DLLs that have no
symbols used when the image is created.
/VERBOSE:UNUSEDLIBS Displays information about any library files that are unused when the
image is created.
Syntax
Remarks
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Add the option to the Additional Options box.
To set this linker option programmatically
See ShowProgress.
See also
MSVC linker reference
MSVC Linker Options
/VERSION (Version information)
Article • 03/03/2022
/VERSION: major [ .minor ]
Arguments
major and minor
The version number you want in the header of the EXE or DLL file.
Remarks
The /VERSION option tells the linker to put a version number in the header of the EXE or
DLL file. Use DUMPBIN /HEADERS to see the image version field of the OPTIONAL HEADER
VALUES to see the effect of /VERSION .
The major and minor arguments are decimal numbers in the range 0 through 65,535.
The default is version 0.0 .
The information specified with /VERSION doesn't affect the version information that
appears for an application when you view its properties in File Explorer. That version
information comes from a resource file that's used to build the application. For more
information, see Version Information Editor.
Another way to insert a version number is with the VERSION module-definition
statement.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > General property page.
3. Modify the Version property.
To set this linker option programmatically
See Version.
See also
MSVC linker reference
MSVC linker options
/WHOLEARCHIVE (Include All Library
Object Files)
Article • 08/03/2021
Force the linker to include all object files in the static library in the linked executable.
Syntax
/WHOLEARCHIVE
/WHOLEARCHIVE:library
Arguments
library
An optional pathname to a static library. The linker includes every object file from this
library.
Remarks
The /WHOLEARCHIVE option forces the linker to include every object file from either a
specified static library, or if no library is specified, from all static libraries specified to the
LINK command. To specify the /WHOLEARCHIVE option for multiple libraries, you can
use more than one /WHOLEARCHIVE switch on the linker command line. By default, the
linker includes object files in the linked output only if they export symbols referenced by
other object files in the executable. The /WHOLEARCHIVE option makes the linker treat
all object files archived in a static library as if they were specified individually on the
linker command line.
The /WHOLEARCHIVE option can be used to re-export all the symbols from a static
library. This allows you to make sure that all of your library code, resources, and
metadata are included when you create a component from more than one static library.
If you see warning LNK4264 when you create a static library that contains Windows
Runtime components for export, use the /WHOLEARCHIVE option when linking that
library into another component or app.
The /WHOLEARCHIVE option was introduced in Visual Studio 2015 Update 2.
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. Add the /WHOLEARCHIVE option to the Additional Options text box.
See also
MSVC linker reference
MSVC Linker Options
/WINMD (Generate Windows Metadata)
Article • 08/03/2021
Enables generation of a Windows Runtime Metadata (.winmd) file.
/WINMD[:{NO|ONLY}]
Arguments
/WINMD
The default setting for Universal Windows Platform apps. The linker generates both the
binary executable file and the .winmd metadata file.
/WINMD:NO
The linker generates only the binary executable file, but not a .winmd file.
/WINMD:ONLY
The linker generates only the .winmd file, but not the binary executable file.
Remarks
The /WINMD linker option is used for UWP apps and Windows runtime components to
control the creation of a Windows Runtime metadata (.winmd) file. A .winmd file is a
kind of DLL that contains metadata for Windows runtime types and, in the case of
runtime components, the implementations of those types. The metadata follows the
ECMA-335 standard.
By default, the output file name has the form binaryname.winmd. To specify a different
file name, use the /WINMDFILE option.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Windows Metadata property page.
3. In the Generate Windows Metadata drop-down list box, select the option you
want.
See also
Walkthrough: Creating a Simple Windows Runtime component and calling it from
JavaScript
Introduction to Microsoft Interface Definition Language 3.0
/WINMDFILE (Specify winmd File)
/WINMDKEYFILE (Specify winmd Key File)
/WINMDKEYCONTAINER (Specify Key Container)
/WINMDDELAYSIGN (Partially Sign a winmd)
MSVC linker reference
MSVC Linker Options
/WINMDFILE (Specify winmd File)
Article • 08/03/2021
Specifies the file name for the Windows Runtime Metadata (.winmd) output file that is
generated by the /WINMD linker option.
/WINMDFILE:filename
Remarks
Use the value that is specified in filename to override the default .winmd file name
( binaryname .winmd). Notice that you do not append ".winmd" to filename . If multiple
values are listed on the /WINMDFILE command line, the last one takes precedence.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Windows Metadata property page.
3. In the Windows Metadata File box, enter the file location.
See also
/WINMD (Generate Windows Metadata)
MSVC linker reference
MSVC Linker Options
/WINMDKEYFILE (Specify winmd Key
File)
Article • 08/03/2021
Specifies a key or a key pair to sign a Windows Runtime Metadata (.winmd) file.
/WINMDKEYFILE:filename
Remarks
Resembles the /KEYFILE linker option that is applied to a .winmd file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Windows Metadata property page.
3. In the Windows Metadata Key File box, enter the file location.
See also
MSVC linker reference
MSVC Linker Options
/WINMDKEYCONTAINER (Specify Key
Container)
Article • 08/03/2021
Specifies a key container to sign a Windows Metadata (.winmd) file.
/WINMDKEYCONTAINER:name
Remarks
Resembles the /KEYCONTAINER linker option that is applied to a (.winmd) file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Windows Metadata property page.
3. In the Windows Metadata Key Container box, enter the location.
See also
MSVC linker reference
MSVC Linker Options
/WINMDDELAYSIGN (Partially Sign a
winmd)
Article • 08/03/2021
Enables partial signing of a Windows Runtime Metadata (.winmd) file by putting the
public key in the file.
/WINMDDELAYSIGN[:NO]
Remarks
Resembles the /DELAYSIGN linker option that is applied to the .winmd file. Use
/WINMDDELAYSIGN if you want to put only the public key in the .winmd file. By default,
the linker acts as if /WINMDDELAYSIGN:NO were specified; that is, it does not sign the
winmd file.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Windows Metadata property page.
3. In the Windows Metadata Delay Sign drop-down list box, select the option you
want.
See also
MSVC linker reference
MSVC Linker Options
/WX (Treat linker warnings as errors)
Article • 02/06/2023
Specifies whether to treat linker warnings as errors.
Syntax
/WX [ :NO ]
/WX [ : nnnn [ , nnnn ...]]
Remarks
The /WX linker option causes no output file to be generated if the linker generates a
warning.
This option is similar to /WX for the compiler. For more information, see /w, /W0, /W1,
/W2, /W3, /W4, /w1, /w2, /w3, /w4, /Wall, /wd, /we, /wo, /Wv, /WX (Warning Level).
However, specifying /WX for the compilation doesn't imply that /WX will also be in effect
for the link phase; you must explicitly specify /WX for each tool.
In Visual Studio 2022 and later versions, you can specify /WX with one or more comma￾separated nnnn arguments, where nnnn is a number between 4000 and 4999. The linker
treats the corresponding LNKnnnn warnings as errors.
By default, /WX isn't in effect. To treat linker warnings as errors, specify a /WX option.
/WX:NO is the same as not specifying /WX , and overrides any previous /WX linker option.
To set this linker option in the Visual Studio development
environment
1. Open the project's Property Pages dialog box. For more information, see Set
compiler and build properties.
2. To set or unset all warnings as errors, select the Configuration Properties > Linker
> General property page.
3. Modify the Treat Linker Warnings as Errors property.
4. To set specific warnings as errors, select the Configuration Properties > Linker >
Command Line property page.
5. In the Additional Options edit control, add /WX:warnings , where warnings is a
comma-separated list of linker warning numbers.
6. Choose OK or Apply to save your changes.
To set this linker option programmatically
See AdditionalOptions.
See also
MSVC linker reference
MSVC linker options
/WX compiler option
Decorated names
Article • 06/15/2022
Functions, data, and objects in C and C++ programs are represented internally by their
decorated names. A decorated name is an encoded string created by the compiler
during compilation of an object, data, or function definition. It records calling
conventions, types, function parameters and other information together with the name.
This name decoration, also known as name mangling, helps the linker find the correct
functions and objects when linking an executable.
The decorated naming conventions have changed in various versions of Visual Studio,
and can also be different on different target architectures. To link correctly with source
files created by using Visual Studio, C and C++ DLLs and libraries should be compiled by
using the same compiler toolset, flags, and target architecture.
７ Note
Libraries built by Visual Studio 2015 or later can be consumed by applications built
with later versions of Visual Studio through Visual Studio 2022. For more
information, see C++ binary compatibility between Visual Studio versions.
Using decorated names
Normally, you don't have to know the decorated name to write code that compiles and
links successfully. Decorated names are an implementation detail internal to the
compiler and linker. The tools can usually handle the name in its undecorated form.
However, a decorated name is sometimes required when you specify a function name to
the linker and other tools. For example, to match overloaded C++ functions, members
of namespaces, class constructors, destructors and special member functions, you must
specify the decorated name. For details about the option flags and other situations that
require decorated names, see the documentation for the tools and options that you're
using.
If you change the function name, class, calling convention, return type, or any
parameter, the decorated name also changes. In this case, you must get the new
decorated name and use it everywhere the decorated name is specified.
Name decoration is also important when linking to code written in other programming
languages or using other compilers. Different compilers use different name decoration
conventions. When your executable links to code written in another language, special
care must be taken to match the exported and imported names and calling conventions.
Assembly language code must use the MSVC decorated names and calling conventions
to link to source code written using MSVC.
A decorated name for a C++ function contains the following information:
The function name.
The class that the function is a member of, if it's a member function. The
decoration may include the class that encloses the class that contains the function,
and so on.
The namespace the function belongs to, if it's part of a namespace.
The types of the function parameters.
The calling convention.
The return type of the function.
An optional target-specific element. In ARM64EC objects, a $$h tag is inserted into
the name.
The function and class names are encoded in the decorated name. The rest of the
decorated name is a code that has internal meaning only for the compiler and the linker.
The following are examples of undecorated and decorated C++ names.
Undecorated name Decorated name
int a(char){int i=3;return i;}; ?a@@YAHD@Z
void __stdcall b::c(float){}; ?c@b@@AAGXM@Z
The form of decoration for a C function depends on the calling convention used in its
declaration, as shown in the following table. It's also the decoration format that's used
when C++ code is declared to have extern "C" linkage. The default calling convention
is __cdecl . In a 64-bit environment, C or extern "C" functions are only decorated when
using the __vectorcall calling convention.
Format of a C++ decorated name
Format of a C decorated name
Calling
convention
Decoration Calling
convention
Decoration
__cdecl Leading underscore ( _ )
__stdcall Leading underscore ( _ ) and a trailing at sign ( @ ) followed by the number of bytes
in the parameter list in decimal
__fastcall Leading and trailing at signs ( @ ) followed by a decimal number representing the
number of bytes in the parameter list
__vectorcall Two trailing at signs ( @@ ) followed by a decimal number of bytes in the parameter
list
For ARM64EC functions with C linkage (whether compiled as C or by using extern "C" ),
a # is prepended to the decorated name.
You can get the decorated form of a symbol name after you compile the source file that
contains the data, object, or function definition or prototype. To examine decorated
names in your program, you can use one of the following methods:
1. Generate a listing by compiling the source file that contains the data, object, or
function definition or prototype with the /FA (Listing file type) compiler option set
to assembly with source code ( /FAs ).
For example, enter cl /c /FAs example.cpp at a developer command prompt to
generate a listing file, example.asm .
2. In the resulting listing file, find the line that starts with PUBLIC and ends a
semicolon ( ; ) followed by the undecorated data or function name. The symbol
between PUBLIC and the semicolon is the decorated name.
1. To see the exported symbols in an OBJ or LIB file, enter dumpbin /exports <obj-or￾lib-file> at a developer command prompt.
2. To find the decorated form of a symbol, look for the undecorated name in
parentheses. The decorated name is on the same line, before the undecorated
View decorated names
To use a listing to view decorated names
To use DUMPBIN to view decorated names
name.
Viewing undecorated names
You can use undname.exe to convert a decorated name to its undecorated form. This
example shows how it works:
Windows Command Prompt
C:\>undname ?func1@a@@AAEXH@Z
Microsoft (R) C++ Name Undecorator
Copyright (C) Microsoft Corporation. All rights reserved.
Undecoration of :- "?func1@a@@AAEXH@Z"
is :- "private: void __thiscall a::func1(int)"
See also
Additional MSVC build tools
Using extern to specify linkage
Module-Definition (.Def) Files
Article • 08/03/2021
Module-definition (.def) files provide the linker with information about exports,
attributes, and other information about the program to be linked. A .def file is most
useful when building a DLL. Because there are MSVC Linker Options that can be used
instead of module-definition statements, .def files are generally not necessary. You can
also use __declspec(dllexport) as a way to specify exported functions.
You can invoke a .def file during the linker phase with the /DEF (Specify Module￾Definition File) linker option.
If you are building an .exe file that has no exports, using a .def file will make your output
file larger and slower loading.
For an example, see Exporting from a DLL Using DEF Files.
See the following sections for more information:
Rules for Module-Definition Statements
EXPORTS
HEAPSIZE
LIBRARY
NAME
SECTIONS
STACKSIZE
STUB
VERSION
Reserved words
See also
C/C++ Building Reference
MSVC Linker Options
Rules for Module-Definition Statements
Article • 08/03/2021
The following syntax rules apply to all statements in a .def file. Other rules that apply to
specific statements are described with each statement.
Statements, attribute keywords, and user-specified identifiers are case sensitive.
Long file names containing spaces or semicolons (;) must be enclosed in quotation
marks (").
Use one or more spaces, tabs, or newline characters to separate a statement
keyword from its arguments and to separate statements from each other. A colon
(:) or equal sign (=) that designates an argument is surrounded by zero or more
spaces, tabs, or newline characters.
A NAME or LIBRARY statement, if used, must precede all other statements.
The SECTIONS and EXPORTS statements can appear more than once in the .def
file. Each statement can take multiple specifications, which must be separated by
one or more spaces, tabs, or newline characters. The statement keyword must
appear once before the first specification and can be repeated before each
additional specification.
Many statements have an equivalent LINK command-line option. See the
description of the corresponding LINK option for additional details.
Comments in the .def file are designated by a semicolon (;) at the beginning of
each comment line. A comment cannot share a line with a statement, but it can
appear between specifications in a multiline statement. (SECTIONS and EXPORTS
are multiline statements.)
Numeric arguments are specified in base 10 or hexadecimal.
If a string argument matches a reserved word, it must be enclosed in double
quotation marks (").
See also
Module-Definition (.Def) Files
EXPORTS
Article • 08/03/2021
Introduces a section of one or more export definitions that specify the exported names
or ordinals of functions or data. Each definition must be on a separate line.
DEF
EXPORTS
 definition
Remarks
The first definition can be on the same line as the EXPORTS keyword or on a subsequent
line. The .DEF file can contain one or more EXPORTS statements.
The syntax for an export definition is:
entryname[=internal_name|other_module.exported_name] [@ordinal [NONAME] ] [
[PRIVATE] | [DATA] ]
entryname is the function or variable name that you want to export. This is required. If
the name that you export differs from the name in the DLL, specify the export's name in
the DLL by using internal_name. For example, if your DLL exports a function func1 and
you want callers to use it as func2 , you would specify:
DEF
EXPORTS
 func2=func1
If the name that you export is from some other module, specify the export's name in the
DLL by using other_module.exported_name. For example, if your DLL exports a function
other_module.func1 and you want callers to use it as func2 , you would specify:
DEF
EXPORTS
 func2=other_module.func1
If the name that you export is from another module that exports by ordinal, specify the
export's ordinal in the DLL by using other_module.#ordinal. For example, if your DLL
exports a function from the other module where it is ordinal 42, and you want callers to
use it as func2 , you would specify:
DEF
EXPORTS
 func2=other_module.#42
Because the MSVC compiler uses name decoration for C++ functions, you must either
use the decorated name internal_name or define the exported functions by using extern
"C" in the source code. The compiler also decorates C functions that use the __stdcall
calling convention with an underscore (_) prefix and a suffix composed of the at sign (@)
followed by the number of bytes (in decimal) in the argument list.
To find the decorated names produced by the compiler, use the DUMPBIN tool or the
linker /MAP option. The decorated names are compiler-specific. If you export the
decorated names in the .DEF file, executables that link to the DLL must also be built by
using the same version of the compiler. This ensures that the decorated names in the
caller match the exported names in the .DEF file.
You can use @ordinal to specify that a number, and not the function name, goes into
the DLL's export table. Many Windows DLLs export ordinals to support legacy code. It
was common to use ordinals in 16-bit Windows code, because it can help minimize the
size of a DLL. We don't recommend exporting functions by ordinal unless your DLL's
clients need it for legacy support. Because the .LIB file will contain the mapping between
the ordinal and the function, you can use the function name as you normally would in
projects that use the DLL.
By using the optional NONAME keyword, you can export by ordinal only and reduce the
size of the export table in the resulting DLL. However, if you want to use GetProcAddress
on the DLL, you must know the ordinal because the name will not be valid.
The optional keyword PRIVATE prevents entryname from being included in the import
library generated by LINK. It does not affect the export in the image also generated by
LINK.
The optional keyword DATA specifies that an export is data, not code. This example
shows how you could export a data variable named exported_global :
DEF
EXPORTS
 exported_global DATA
There are four ways to export a definition, listed in recommended order:
1. The __declspec(dllexport) keyword in the source code
2. An EXPORTS statement in a .DEF file
3. An /EXPORT specification in a LINK command
4. A comment directive in the source code, of the form #pragma comment(linker,
"/export: definition ") . The following example shows a #pragma comment
directive before a function declaration, where PlainFuncName is the undecorated
name, and _PlainFuncName@4 is the decorated name of the function:
C++
#pragma comment(linker, "/export:PlainFuncName=_PlainFuncName@4")
BOOL CALLBACK PlainFuncName( Things * lpParams)
The #pragma directive is useful if you need to export an undecorated function name,
and have different exports depending on the build configuration (for example, in 32-bit
or 64-bit builds).
All four methods can be used in the same program. When LINK builds a program that
contains exports, it also creates an import library, unless an .EXP file is used in the build.
Here's an example of an EXPORTS section:
DEF
EXPORTS
 DllCanUnloadNow @1 PRIVATE
 DllWindowName = WindowName DATA
 DllGetClassObject @4 NONAME PRIVATE
 DllRegisterServer @7
 DllUnregisterServer
When you export a variable from a DLL by using a .DEF file, you do not have to specify
__declspec(dllexport) on the variable. However, in any file that uses the DLL, you must
still use __declspec(dllimport) on the declaration of data.
See also
Rules for Module-Definition Statements
LIBRARY
Article • 08/03/2021
Tells LINK to create a DLL. At the same time, LINK creates an import library, unless an
.exp file is used in the build.
LIBRARY [library][BASE=address]
Remarks
The library argument specifies the name of the DLL. You can also use the /OUT linker
option to specify the DLL's output name.
The BASE=address argument sets the base address that the operating system uses to
load the DLL. This argument overrides the default DLL location of 0x10000000. See the
description of the /BASE option for details about base addresses.
Remember to use the /DLL linker option when you build a DLL.
See also
Rules for Module-Definition Statements
HEAPSIZE
Article • 08/03/2021
Exposes the same functionality as the /HEAP linker option.
/HEAP:reserve[,commit]
See also
Rules for Module-Definition Statements
NAME (C/C++)
Article • 08/03/2021
Specifies a name for the main output file.
NAME [application][BASE=address]
Remarks
An equivalent way to specify an output file name is with the /OUT linker option, and an
equivalent way to set the base address is with the /BASE linker option. If both are
specified, /OUT overrides NAME.
If you build a DLL, NAME will only affect the DLL name.
See also
Rules for Module-Definition Statements
SECTIONS (C/C++)
Article • 08/03/2021
Introduces a section of one or more definitions that are access specifiers on sections
in your project's output file.
Each definition must be on a separate line. The SECTIONS keyword can be on the same
line as the first definition or on a preceding line. The .def file can contain one or more
SECTIONS statements.
This SECTIONS statement sets attributes for one or more sections in the image file, and
can be used to override the default attributes for each type of section.
The format for definitions is:
.section_name specifier
where .section_name is the name of a section in your program image and specifier is
one or more of the following access modifiers:
Modifier Description
EXECUTE The section is executable
READ Allows read operations on data
SHARED Shares the section among all processes that load the image
WRITE Allows write operations on data
Separate specifier names with a space. For example:
SECTIONS
definitions
Remarks
SECTIONS
.rdata READ WRITE
SECTIONS marks the beginning of a list of section definitions . Each definition must be
on a separate line. The SECTIONS keyword can be on the same line as the first
definition or on a preceding line. The .def file can contain one or more SECTIONS
statements. The SEGMENTS keyword is supported as a synonym for SECTIONS .
Older versions of Visual C++ supported:
section [CLASS 'classname'] specifier
The CLASS keyword is supported for compatibility, but is ignored.
An equivalent way to specify section attributes is with the /SECTION option.
See also
Rules for Module-Definition Statements
STACKSIZE
Article • 08/03/2021
Sets the size of the stack in bytes.
STACKSIZE reserve[,commit]
Remarks
An equivalent way to set the stack is with the Stack Allocations (/STACK) option. See the
documentation on that option for details about the reserve and commit arguments.
This option has no effect on DLLs.
See also
Rules for Module-Definition Statements
STUB
Article • 08/03/2021
When used in a module definition file that builds a virtual device driver (VxD), allows you
to specify a file name that contains an IMAGE_DOS_HEADER structure (defined in
WINNT.H) to be used in the virtual device driver (VxD), rather than the default header.
STUB:filename
Remarks
An equivalent way to specify filename is with the /STUB linker option.
STUB is valid in a module definition file only when building a VxD.
See also
Rules for Module-Definition Statements
VERSION (C/C++)
Article • 08/03/2021
Tells LINK to put a number in the header of the .exe file or DLL.
VERSION major[.minor]
Remarks
The major and minor arguments are decimal numbers in the range 0 through 65,535.
The default is version 0.0.
An equivalent way to specify a version number is with the Version Information
(/VERSION) option.
See also
Rules for Module-Definition Statements
Linker support for delay-loaded DLLs
Article • 08/03/2021
The MSVC linker supports the delayed loading of DLLs. This feature relieves you of the
need to use the Windows SDK functions LoadLibrary and GetProcAddress to implement
DLL delayed loading.
Without delayed load, the only way to load a DLL at run time is by using LoadLibrary
and GetProcAddress ; the operating system loads the DLL when the executable or DLL
using it gets loaded.
With delayed load, when you implicitly link a DLL, the linker provides options to delay
the DLL load until the program calls a function in that DLL.
An application can delay load a DLL using the /DELAYLOAD (Delay load import) linker
option with a helper function. (A default helper function implementation is provided by
Microsoft.) The helper function loads the DLL on demand at runtime by calling
LoadLibrary and GetProcAddress for you.
Consider delay loading a DLL if:
Your program might not call a function in the DLL.
A function in the DLL might not get called until late in your program's execution.
The delayed loading of a DLL can be specified during the build of either an EXE or DLL
project. A DLL project that delays the loading of one or more DLLs itself shouldn't call a
delay-loaded entry point in DllMain .
Specify DLLs to delay load
You can specify which DLLs to delay load by using the /delayload: dllname linker option.
If you don't plan to use your own version of a helper function, you must also link your
program with delayimp.lib (for desktop applications) or dloadhelper.lib (for UWP
apps).
Here's a simple example of delay loading a DLL:
C++
// cl t.cpp user32.lib delayimp.lib /link /DELAYLOAD:user32.dll
#include <windows.h>
// uncomment these lines to remove .libs from command line
Build the DEBUG version of the project. Step through the code using the debugger and
you'll notice that user32.dll is loaded only when you make the call to MessageBox .
The /delay:unload linker option allows your code to explicitly unload a DLL that was
delay loaded. By default, the delay-loaded imports remain in the import address table
(IAT). However, if you use /delay:unload on the linker command line, the helper
function supports the explicit unloading of the DLL by a __FUnloadDelayLoadedDLL2 call,
and resets the IAT to its original form. The now-invalid pointers get overwritten. The IAT
is a field in the ImgDelayDescr structure that contains the address of a copy of the
original IAT, if one exists.
This example shows how to explicitly unload a DLL, MyDll.dll , which contains a function
fnMyDll :
C
// #pragma comment(lib, "delayimp")
// #pragma comment(lib, "user32")
int main() {
 // user32.dll will load at this point
 MessageBox(NULL, "Hello", "Hello", MB_OK);
}
Explicitly unload a delay-loaded DLL
Example of unloading a delay-loaded DLL
// link with /link /DELAYLOAD:MyDLL.dll /DELAY:UNLOAD
#include <windows.h>
#include <delayimp.h>
#include "MyDll.h"
#include <stdio.h>
#pragma comment(lib, "delayimp")
#pragma comment(lib, "MyDll")
int main()
{
 BOOL TestReturn;
 // MyDLL.DLL will load at this point
 fnMyDll();
 //MyDLL.dll will unload at this point
 TestReturn = __FUnloadDelayLoadedDLL2("MyDll.dll");
 if (TestReturn)
 printf_s("\nDLL was unloaded");
Important notes on unloading a delay-loaded DLL:
You can find the implementation of the __FUnloadDelayLoadedDLL2 function in the
file delayhlp.cpp , in the MSVC include directory. For more information, see
Understand the delay load helper function.
The name parameter of the __FUnloadDelayLoadedDLL2 function must exactly match
(including case) what the import library contains. (That string is also in the import
table in the image.) You can view the contents of the import library by using
DUMPBIN /DEPENDENTS. If you prefer a case-insensitive string match, you can
update __FUnloadDelayLoadedDLL2 to use one of the case-insensitive CRT string
functions, or a Windows API call.
The default linker behavior is to create a bindable import address table (IAT) for the
delay-loaded DLL. If the DLL is bound, the helper function attempts to use the bound
information instead of calling GetProcAddress on each of the referenced imports. If
either the timestamp or the preferred address doesn't match the one in the loaded DLL,
the helper function assumes the bound import address table is out of date. It proceeds
as if the IAT doesn't exist.
If you never intend to bind the delay-loaded imports of a DLL, specify /delay:nobind on
the linker command line. The linker won't generate the bound import address table,
which saves space in the image file.
The __HrLoadAllImportsForDll function, which is defined in delayhlp.cpp , tells the linker
to load all imports from a DLL that was specified with the /delayload linker option.
When you load all imports at once, you can centralize error handling in one place. You
can avoid structured exception handling around all the actual calls to the imports. It also
avoids a situation where your application fails part way through a process: For example,
if the helper code fails to load an import, after successfully loading others.
Calling __HrLoadAllImportsForDll doesn't change the behavior of hooks and error
handling. For more information, see Error handling and notification.
 else
 printf_s("\nDLL was not unloaded");
}
Bind delay-loaded imports
Load all imports for a delay-loaded DLL
__HrLoadAllImportsForDll makes a case-sensitive comparison to the name stored inside
the DLL itself.
Here's an example that uses __HrLoadAllImportsForDll in a function called
TryDelayLoadAllImports to attempt to load a named DLL. It uses a function,
CheckDelayException , to determine exception behavior.
C
You can use the result of TryDelayLoadAllImports to control whether you call the import
functions or not.
int CheckDelayException(int exception_value)
{
 if (exception_value == VcppException(ERROR_SEVERITY_ERROR,
ERROR_MOD_NOT_FOUND) ||
 exception_value == VcppException(ERROR_SEVERITY_ERROR,
ERROR_PROC_NOT_FOUND))
 {
 // This example just executes the handler.
 return EXCEPTION_EXECUTE_HANDLER;
 }
 // Don't attempt to handle other errors
 return EXCEPTION_CONTINUE_SEARCH;
}
bool TryDelayLoadAllImports(LPCSTR szDll)
{
 __try
 {
 HRESULT hr = __HrLoadAllImportsForDll(szDll);
 if (FAILED(hr))
 {
 // printf_s("Failed to delay load functions from %s\n", szDll);
 return false;
 }
 }
 __except (CheckDelayException(GetExceptionCode()))
 {
 // printf_s("Delay load exception for %s\n", szDll);
 return false;
 }
 // printf_s("Delay load completed for %s\n", szDll);
 return true;
}
Error handling and notification
If your program uses delay-loaded DLLs, it must handle errors robustly. Failures that
occur while the program is running will result in unhandled exceptions. For more
information on DLL delay load error handling and notification, see Error handling and
notification.
Dump delay-loaded imports
Delay-loaded imports can be dumped by using DUMPBIN /IMPORTS. These imports
show up with slightly different information than standard imports. They're segregated
into their own section of the /imports list, and are explicitly labeled as delay-loaded
imports. If there's unload information present in the image, that is noted. If there's bind
information present, the time and date stamp of the target DLL is noted along with the
bound addresses of the imports.
Constraints on delay-load DLLs
There are several constraints on the delay loading of DLL imports.
Imports of data can't be supported. A workaround is to explicitly handle the data
import yourself by using LoadLibrary (or by using GetModuleHandle after you
know the delay-load helper has loaded the DLL) and GetProcAddress .
Delay loading Kernel32.dll isn't supported. This DLL must be loaded for the
delay-load helper routines to work.
Binding of forwarded entry points isn't supported.
A process may have different behavior if a DLL is delay-loaded, instead of loaded
on start-up. It can be seen if there are per-process initializations that occur in the
entry point of the delay-loaded DLL. Other cases include static TLS (thread local
storage), declared using __declspec(thread), which isn't handled when the DLL is
loaded via LoadLibrary . Dynamic TLS, using TlsAlloc, TlsFree, TlsGetValue, and
TlsSetValue, is still available for use in either static or delay-loaded DLLs.
Reinitialize static global function pointers to imported functions after the first call
of each function. That's required because the first use of a function pointer points
to the thunk, not the loaded function.
There's currently no way to delay the loading of only specific procedures from a
DLL while using the normal import mechanism.
Custom calling conventions (such as using condition codes on x86 architectures)
aren't supported. Also, the floating-point registers aren't saved on any platform.
Take care if your custom helper routine or hook routines use floating-point types:
The routines must save and restore the complete floating-point state on machines
that use register calling conventions with floating-point parameters. Be careful
about delay-loading the CRT DLL, particularly if you call CRT functions that take
floating-point parameters on a numeric data processor (NDP) stack in the help
function.
Understand the delay load helper function
The helper function for linker-supported delayed loading is what actually loads the DLL
at runtime. You can modify the helper function to customize its behavior. Instead of
using the supplied helper function in delayimp.lib , write your own function and link it
to your program. One helper function serves all delay loaded DLLs. For more
information, see Understand the delay load helper function and Develop your own
helper function.
See also
Create C/C++ DLLs in Visual Studio
MSVC linker reference
Error handling and notification
Article • 08/03/2021
If your program uses delay-loaded DLLs, it must handle errors robustly, since failures
that occur while the program is running will result in unhandled exceptions. Failure
handling is composed of two portions: Recovery through a hook, and reporting via an
exception.
For more information on DLL delay load error handling and notification, see Understand
the helper function.
For more information on hook functions, see Structure and constant definitions.
Recovery through a hook
Your code may need to recover on a failure, or to provide an alternate library or routine.
You can provide a hook to the helper function that can supply the alternative code, or
remedy the situation. The hook routine needs to return a suitable value, so that
processing can continue (an HINSTANCE or FARPROC ). Or, it can return 0 to indicate that
an exception should be thrown. It could also throw its own exception or longjmp out of
the hook. There are notification hooks and failure hooks. The same routine may be used
for both.
Notification hooks
The delay load notification hooks are called just before the following actions are taken
in the helper routine:
The stored handle to the library is checked to see if it has already been loaded.
LoadLibrary is called to attempt the load of the DLL.
GetProcAddress is called to attempt to get the address of the procedure.
Return to the delay import load thunk.
The notification hook is enabled:
By supplying a new definition of the pointer __pfnDliNotifyHook2 that's initialized
to point to your own function that receives the notifications.
-or-
By setting the pointer __pfnDliNotifyHook2 to your hook function before any calls
to the DLL that the program is delay loading.
If the notification is dliStartProcessing , the hook function can return:
NULL
The default helper handles the loading of the DLL. It's useful to call just for
informational purposes.
a function pointer
Bypass the default delay-load handling. It lets you supply your own load handler.
If the notification is dliNotePreLoadLibrary , the hook function can return:
0, if it just wants informational notifications.
The HMODULE for the loaded DLL, if it loaded the DLL itself.
If the notification is dliNotePreGetProcAddress , the hook function can return:
0, if it just wants informational notifications.
The imported function's address, if the hook function gets the address itself.
If the notification is dliNoteEndProcessing , the hook function's return value is ignored.
If this pointer is initialized (nonzero), the delay load helper invokes the function at
certain notification points throughout its execution. The function pointer has the
following definition:
C
// The "notify hook" gets called for every call to the
// delay load helper. This allows a user to hook every call and
// skip the delay load helper entirely.
//
// dliNotify == {
// dliStartProcessing |
// dliNotePreLoadLibrary |
// dliNotePreGetProc |
// dliNoteEndProcessing}
// on this call.
//
ExternC
PfnDliHook __pfnDliNotifyHook2;
// This is the failure hook, dliNotify = {dliFailLoadLib|dliFailGetProc}
ExternC
PfnDliHook __pfnDliFailureHook2;
The notifications pass in a DelayLoadInfo structure to the hook function along with the
notification value. This data is identical to the data used by the delay load helper
routine. The notification value will be one of the values defined in Structure and
constant definitions.
Failure hooks
The failure hook is enabled in the same manner as the notification hook. The hook
routine needs to return a suitable value so that processing can continue (an HINSTANCE
or FARPROC ), or 0 to indicate that an exception should be thrown.
The pointer variable that refers to the user-defined function is:
C
// This is the failure hook, dliNotify = {dliFailLoadLib|dliFailGetProc}
ExternC
PfnDliHook __pfnDliFailureHook2;
The DelayLoadInfo structure contains all the pertinent data necessary for detailed
reporting of the error, including the value from GetLastError .
If the notification is dliFailLoadLib , the hook function can return:
0, if it can't handle the failure.
An HMODULE , if the failure hook fixed the problem and loaded the library itself.
If the notification is dliFailGetProc , the hook function can return:
0, if it can't handle the failure.
A valid proc address (import function address), if the failure hook succeeded in
getting the address itself.
Report by using an exception
If all that's required to handle the error is to abort the procedure, no hook is necessary,
as long as the user code can handle the exception.
Delay load exception codes
Structured exception codes can be raised when failures occur during a delayed load. The
exception values are specified by using a VcppException macro:
C
//
// Exception information
//
#define FACILITY_VISUALCPP ((LONG)0x6d)
#define VcppException(sev,err) ((sev) | (FACILITY_VISUALCPP<<16) | err)
For a LoadLibrary failure, the standard VcppException(ERROR_SEVERITY_ERROR,
ERROR_MOD_NOT_FOUND) is thrown. For a GetProcAddress failure, the error thrown is
VcppException(ERROR_SEVERITY_ERROR, ERROR_PROC_NOT_FOUND) . The exception passes a
pointer to a DelayLoadInfo structure. It's in the LPDWORD value retrieved by
GetExceptionInformation from the EXCEPTION_RECORD structure, in the
ExceptionInformation[0] field.
If the incorrect bits are set in the grAttrs field, the exception ERROR_INVALID_PARAMETER
is thrown. This exception is, for all intents and purposes, fatal.
For more information, see Structure and constant definitions.
See also
Linker support for delay-loaded DLLs
Understand the delay load helper
function
Article • 08/03/2021
The helper function for linker-supported delayed loading is what actually loads the DLL
at runtime. You can modify the helper function to customize its behavior. Instead of
using the supplied helper function in delayimp.lib , write your own function and link it
to your program. One helper function serves all delay loaded DLLs.
You can provide your own version of the helper function if you want to do specific
processing based on the names of the DLL or imports.
The helper function takes these actions:
Checks the stored handle to the library to see if it has already been loaded
Calls LoadLibrary to attempt to load the DLL
Calls GetProcAddress to attempt getting the address of the procedure
Returns to the delay import load thunk to call the now-loaded entry point
The helper function can call back to a notification hook in your program after each of
the following actions:
When the helper function starts up
Just before LoadLibrary is called in the helper function
Just before GetProcAddress is called in the helper function
If the call to LoadLibrary in the helper function fails
If the call to GetProcAddress in the helper function fails
After the helper function is done processing
Each of these hook points can return a value that alters normal processing of the helper
routine in some manner, except the return to the delay import load thunk.
The default helper code can be found in delayhlp.cpp and delayimp.h in the MSVC
include directory. It's compiled into delayimp.lib in the MSVC lib directory for your
target architecture. You'll need to include this library in your compilations unless you
write your own helper function.
Delay load helper calling conventions,
parameters, and return type
The prototype for the delay load helper routine is:
C
FARPROC WINAPI __delayLoadHelper2(
 PCImgDelayDescr pidd,
 FARPROC * ppfnIATEntry
);
Parameters
pidd
A const pointer to a ImgDelayDescr that contains the offsets of various import-related
data, a timestamp for binding information, and a set of attributes that provide further
information about the descriptor content. Currently there's only one attribute,
dlattrRva , which indicates that the addresses in the descriptor are relative virtual
addresses. For more information, see the declarations in delayimp.h .
The pointers in the delay descriptor ( ImgDelayDescr in delayimp.h ) use relative virtual
addresses (RVAs) to work as expected in both 32-bit and 64-bit programs. To use them,
convert these RVAs back to pointers by using the function PFromRva , found in
delayhlp.cpp . You can use this function on each of the fields in the descriptor to convert
them back to either 32-bit or 64-bit pointers. The default delay load helper function is a
good template to use as an example.
For the definition of the PCImgDelayDescr structure, see Structure and constant
definitions.
ppfnIATEntry
A pointer to a slot in the delay load import address table (IAT). It's the slot that's
updated with the address of the imported function. The helper routine needs to store
the same value that it returns into this location.
Expected return values
If the helper function is successful, it returns the address of the imported function.
If the function fails, it raises a structured exception and returns 0. Three types of
exceptions can be raised:
Invalid parameter, which happens if the attributes in pidd aren't specified
correctly. Treat this as an unrecoverable error.
LoadLibrary failed on the specified DLL.
Failure of GetProcAddress .
It's your responsibility to handle these exceptions. For more information, see Error
handling and notification.
The calling convention for the helper function is __stdcall . The type of the return value
isn't relevant, so FARPROC is used. This function has C linkage, which means it needs to
be wrapped by extern "C" when declared in C++ code. The ExternC macro takes care
of this wrapper for you.
To use your helper routine as a notification hook, your code must specify the
appropriate function pointer to return. The thunk code the linker generates then takes
that return value as the real target of the import and jumps directly to it. If you don't
want to use your helper routine as a notification hook, store the return value of the
helper function in ppfnIATEntry , the passed-in function pointer location.
The following code shows how to implement a basic hook function.
C
Remarks
Sample hook function
FARPROC WINAPI delayHook(unsigned dliNotify, PDelayLoadInfo pdli)
{
 switch (dliNotify) {
 case dliStartProcessing :
 // If you want to return control to the helper, return 0.
 // Otherwise, return a pointer to a FARPROC helper function
 // that will be used instead, thereby bypassing the rest
 // of the helper.
 break;
 case dliNotePreLoadLibrary :
 // If you want to return control to the helper, return 0.
 // Otherwise, return your own HMODULE to be used by the
 // helper instead of having it call LoadLibrary itself.
 break;
 case dliNotePreGetProcAddress :
 // If you want to return control to the helper, return 0.
 // If you choose you may supply your own FARPROC function
 // address and bypass the helper's call to GetProcAddress.
 break;
 case dliFailLoadLib :
 // LoadLibrary failed.
 // If you don't want to handle this failure yourself, return 0.
 // In this case the helper will raise an exception
 // (ERROR_MOD_NOT_FOUND) and exit.
 // If you want to handle the failure by loading an alternate
 // DLL (for example), then return the HMODULE for
 // the alternate DLL. The helper will continue execution with
 // this alternate DLL and attempt to find the
 // requested entrypoint via GetProcAddress.
 break;
 case dliFailGetProc :
 // GetProcAddress failed.
 // If you don't want to handle this failure yourself, return 0.
 // In this case the helper will raise an exception
 // (ERROR_PROC_NOT_FOUND) and exit.
 // If you choose, you may handle the failure by returning
 // an alternate FARPROC function address.
 break;
 case dliNoteEndProcessing :
 // This notification is called after all processing is done.
 // There is no opportunity for modifying the helper's behavior
 // at this point except by longjmp()/throw()/RaiseException.
 // No return value is processed.
 break;
 default :
 return NULL;
 }
 return NULL;
The default delay load helper routine uses several structures to communicate with the
hook functions and during any exceptions. These structures are defined in delayimp.h .
Here are the macros, typedefs, notification and failure values, information structures,
and the pointer-to-hook-function type passed to the hooks:
C
}
/*
and then at global scope somewhere:
ExternC const PfnDliHook __pfnDliNotifyHook2 = delayHook;
ExternC const PfnDliHook __pfnDliFailureHook2 = delayHook;
*/
Delay load structure and constant definitions
#define _DELAY_IMP_VER 2
#if defined(__cplusplus)
#define ExternC extern "C"
#else
#define ExternC extern
#endif
typedef IMAGE_THUNK_DATA * PImgThunkData;
typedef const IMAGE_THUNK_DATA * PCImgThunkData;
typedef DWORD RVA;
typedef struct ImgDelayDescr {
 DWORD grAttrs; // attributes
 RVA rvaDLLName; // RVA to dll name
 RVA rvaHmod; // RVA of module handle
 RVA rvaIAT; // RVA of the IAT
 RVA rvaINT; // RVA of the INT
 RVA rvaBoundIAT; // RVA of the optional bound IAT
 RVA rvaUnloadIAT; // RVA of optional copy of original IAT
 DWORD dwTimeStamp; // 0 if not bound,
 // O.W. date/time stamp of DLL bound to
(Old BIND)
 } ImgDelayDescr, * PImgDelayDescr;
typedef const ImgDelayDescr * PCImgDelayDescr;
enum DLAttr { // Delay Load Attributes
 dlattrRva = 0x1, // RVAs are used instead of pointers
 // Having this set indicates a VC7.0
 // and above delay load descriptor.
 };
//
// Delay load import hook notifications
//
enum {
 dliStartProcessing, // used to bypass or note helper only
 dliNoteStartProcessing = dliStartProcessing,
 dliNotePreLoadLibrary, // called just before LoadLibrary, can
 // override w/ new HMODULE return val
 dliNotePreGetProcAddress, // called just before GetProcAddress,
can
 // override w/ new FARPROC return value
 dliFailLoadLib, // failed to load library, fix it by
 // returning a valid HMODULE
 dliFailGetProc, // failed to get proc address, fix it by
 // returning a valid FARPROC
 dliNoteEndProcessing, // called after all processing is done,
no
 // bypass possible at this point except
 // by longjmp()/throw()/RaiseException.
 };
typedef struct DelayLoadProc {
 BOOL fImportByName;
 union {
 LPCSTR szProcName;
 DWORD dwOrdinal;
 };
 } DelayLoadProc;
typedef struct DelayLoadInfo {
 DWORD cb; // size of structure
 PCImgDelayDescr pidd; // raw form of data (everything is
there)
 FARPROC * ppfn; // points to address of function to load
 LPCSTR szDll; // name of dll
 DelayLoadProc dlp; // name or ordinal of procedure
 HMODULE hmodCur; // the hInstance of the library we have
loaded
 FARPROC pfnCur; // the actual function that will be
called
 DWORD dwLastError;// error received (if an error
notification)
 } DelayLoadInfo, * PDelayLoadInfo;
typedef FARPROC (WINAPI *PfnDliHook)(
 unsigned dliNotify,
 PDelayLoadInfo pdli
 );
Calculate necessary values for delay loading
The delay load helper routine needs to calculate two critical pieces of information. To
help, there are two inline functions in delayhlp.cpp to calculate this information.
The first, IndexFromPImgThunkData , calculates the index of the current import into
the three different tables (import address table (IAT), bound import address table
(BIAT), and unbound import address table (UIAT)).
The second, CountOfImports , counts the number of imports in a valid IAT.
C
When a delay-loaded DLL gets loaded, the default delay-load helper checks to see if the
delay-load descriptors have a pointer and a copy of the original import address table
(IAT) in the pUnloadIAT field. If so, the helper saves a pointer in a list to the import delay
descriptor. This entry lets the helper function find the DLL by name, to support
unloading that DLL explicitly.
Here are the associated structures and functions for explicitly unloading a delay-loaded
DLL:
C++
// utility function for calculating the index of the current import
// for all the tables (INT, BIAT, UIAT, and IAT).
__inline unsigned
IndexFromPImgThunkData(PCImgThunkData pitdCur, PCImgThunkData pitdBase) {
 return pitdCur - pitdBase;
 }
// utility function for calculating the count of imports given the base
// of the IAT. NB: this only works on a valid IAT!
__inline unsigned
CountOfImports(PCImgThunkData pitdBase) {
 unsigned cRet = 0;
 PCImgThunkData pitd = pitdBase;
 while (pitd->u1.Function) {
 pitd++;
 cRet++;
 }
 return cRet;
 }
Support unload of a delay-loaded DLL
//
// Unload support from delayimp.h
//
// routine definition; takes a pointer to a name to unload
ExternC
BOOL WINAPI
__FUnloadDelayLoadedDLL2(LPCSTR szDll);
// structure definitions for the list of unload records
typedef struct UnloadInfo * PUnloadInfo;
typedef struct UnloadInfo {
 PUnloadInfo puiNext;
 PCImgDelayDescr pidd;
 } UnloadInfo;
// from delayhlp.cpp
// the default delay load helper places the unloadinfo records in the
// list headed by the following pointer.
ExternC
PUnloadInfo __puiHead;
The UnloadInfo structure is implemented using a C++ class that uses LocalAlloc and
LocalFree implementations as its operator new and operator delete , respectively.
These options are kept in a standard linked list that uses __puiHead as the head of the
list.
When you call __FUnloadDelayLoadedDLL , it attempts to find the name you provide in the
list of loaded DLLs. (An exact match is required.) If found, the copy of the IAT in
pUnloadIAT is copied over the top of the running IAT to restore the thunk pointers. Then,
the library is freed by using FreeLibrary , the matching UnloadInfo record is unlinked
from the list and deleted, and TRUE is returned.
The argument to the function __FUnloadDelayLoadedDLL2 is case-sensitive. For example,
you would specify:
C++
__FUnloadDelayLoadedDLL2("user32.dll");
and not:
C++
__FUnloadDelayLoadedDLL2("User32.DLL");
For an example of unloading a delay-loaded DLL, see Explicitly unload a delay-loaded
DLL.
Develop your own delay load helper function
You may want to provide your own version of the delay load helper routine. In your own
routine, you can do specific processing based on the names of the DLL or imports. There
are two ways to insert your own code: Code your own helper function, possibly based
on the supplied code. Or, hook the supplied helper to call your own function by using
the notification hooks.
Code your own helper
Creating your own helper routine is straightforward. You can use the existing code as a
guide for your new function. Your function must use the same calling conventions as the
existing helper. And, if it returns to the linker-generated thunks, it must return a proper
function pointer. Once you've created your code, you may either satisfy the call or get
out of the call, however you like.
Use the start processing notification hook
It's probably easiest to provide a new pointer to a user-supplied notification hook
function that takes the same values as the default helper for the dliStartProcessing
notification. At that point, the hook function can essentially become the new helper
function, because a successful return to the default helper bypasses all further
processing in the default helper.
See also
Linker support for delay-loaded DLLs
Additional MSVC Build Tools
Article • 08/03/2021
Visual Studio provides the following command-line utilities for viewing or manipulating
build output:
LIB.EXE is used to create and manage a library of Common Object File Format
(COFF) object files. It can also be used to create export files and import libraries to
reference exported definitions.
EDITBIN.EXE is used to modify COFF binary files.
DUMPBIN.EXE displays information (such as a symbol table) about COFF binary
files.
NMAKE reads and executes makefiles.
ERRLOOK, the Error Lookup utility, retrieves a system error message or module
error message based on the value entered.
XDCMake. A tool for processing source code files that contain documentation
comments marked up with XML tags.
BSCMAKE.EXE (provided for backward compatibility only) builds a browse
information file (.bsc) that contains information about the symbols (classes,
functions, data, macros, and types) in your program. You view this information in
browse windows within the development environment. (A .bsc file can also be built
in the development environment.)
The Windows SDK also has several build tools, including RC.EXE, which the C++
compiler invokes to compile native Windows resources such as dialogs, property pages,
bitmaps, string tables and so on.
See also
C/C++ Building Reference
Decorated Names
MSVC Compiler Options
MSVC Linker Options
NMAKE Reference
Article • 09/30/2021
The Microsoft Program Maintenance Utility (NMAKE.EXE) is a command-line tool
included with Visual Studio. It builds projects based on commands that are contained in
a description file, usually called a makefile.
NMAKE must run in a Developer Command Prompt window. A Developer Command
Prompt window has the environment variables set for the tools, libraries, and include file
paths required to build at the command line. For details on how to open a Developer
Command Prompt window, see Use the MSVC toolset from the command line.
What do you want to know more about?
Running NMAKE
Makefile contents and features
Sample Makefile
Description blocks
Commands in a Makefile
Macros and NMAKE
Inference rules
Dot directives
Makefile preprocessing
See also
Use the MSVC toolset from the command line
Additional MSVC Build Tools
Visual Studio Projects - C++
Debugging in Visual Studio
C/C++ Building Reference
Create a C++ makefile project
Article • 03/03/2022
A makefile is a text file that contains instructions for how to compile and link (or build) a
set of source code files. A program (often called a make program) reads the makefile
and invokes a compiler, linker, and possibly other programs to make an executable file.
The Microsoft program is called NMAKE.
If you have an existing makefile project, you have these choices if you want to edit,
build, and debug in the Visual Studio IDE:
Create a makefile project in Visual Studio that uses your existing makefile to
configure a .vcxproj file that Visual Studio will use for IntelliSense. (You won't have
all the IDE features that you get with a native MSBuild project.) See To create a
makefile project below.
Use the Create New Project from Existing Code Files wizard to create a native
MSBuild project from your source code. The original makefile won't be used
anymore. For more information, see How to: Create a C++ Project from Existing
Code.
Visual Studio 2017 and later: Use the Open Folder feature to edit and build a
makefile project as-is without any involvement of the MSBuild system. For more
information, see Open Folder projects for C++.
Visual Studio 2019 and later: Create a UNIX makefile project for Linux.
To create a makefile project with the makefile
project template
In Visual Studio 2017 and later, the Makefile project template is available when the C++
Desktop Development workload is installed.
Follow the wizard to specify the commands and environment used by your makefile. You
can then use this project to build your code in Visual Studio.
By default, the makefile project displays no files in Solution Explorer. The makefile
project specifies the build settings, which are reflected in the project's property page.
The output file that you specify in the project has no effect on the name that the build
script generates. It declares only an intention. Your makefile still controls the build
process and specifies the build targets.
To create a makefile project in Visual Studio
1. From the Visual Studio main menu, choose File > New > Project and type
"makefile" into the search box. If you see more than one project template, select
from the options depending on your target platform.
2. Windows only: In the Makefile project Debug Configuration Settings page,
provide the command, output, clean, and rebuild information for debug and retail
builds. Choose Next if you want to specify different settings for a Release
configuration.
3. Choose Finish to close the dialog and open the newly created project in Solution
Explorer.
You can view and edit the project's properties in its property page. For more information
about displaying the property page, see Set C++ compiler and build properties in Visual
Studio.
Makefile project wizard
After you create a makefile project, you can view and edit each of the following options
in the Nmake page of the project's property page.
Build command line: Specifies the command line to run when the user selects
Build from the Build menu. Displayed in the Build command line field on the
Nmake page of the project's property page.
Output: Specifies the name of the file that will contain the output for the
command line. By default, this option is based on the project name. Displayed in
the Output field on the Nmake page of the project's property page.
Clean commands: Specifies the command line to run when the user selects Clean
from the Build menu. Displayed in the Clean command line field on the Nmake
page of the project's property page.
Rebuild command line: Specifies the command line to run when the user selects
Rebuild from the Build menu. Displayed in the Rebuild all command line field on
the Nmake page of the project's property page.
How to: Enable IntelliSense for Makefile
Projects
IntelliSense fails in makefile projects when certain project settings or compiler options
are set up incorrectly. Follow these steps to configure makefile projects so that
IntelliSense works as expected:
1. Open the Property Pages dialog box. For more information, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > NMake property page.
3. Modify properties under IntelliSense as appropriate:
Set the Preprocessor Definitions property to define any preprocessor
symbols in your makefile project. For more information, see /D (Preprocessor
Definitions).
Set the Include Search Path property to specify the list of directories that the
compiler will search to resolve file references that are passed to preprocessor
directives in your makefile project. For more information, see /I (Additional
Include Directories).
For projects that are built using CL.EXE from a Command Window, set the
INCLUDE environment variable to specify directories that the compiler will
search to resolve file references that are passed to preprocessor directives in
your makefile project.
Set the Forced Includes property to specify which header files to process
when building your makefile project. For more information, see /FI (Name
Forced Include File).
Set the Assembly Search Path property to specify the list of directories that
the compiler will search to resolve references to .NET assemblies in your
project. For more information, see /AI (Specify Metadata Directories).
Set the Forced Using Assemblies property to specify which .NET assemblies
to process when building your makefile project. For more information, see
/FU (Name Forced #using File).
Set the Additional Options property to specify other compiler switches to be
used by IntelliSense when parsing C++ files.
4. Choose OK to close the property pages.
5. Use the Save All command to save the modified project settings.
The next time you open your makefile project in the Visual Studio development
environment, run the Clean Solution command and then the Build Solution command
on your makefile project. IntelliSense should work properly in the IDE.
See also
Using IntelliSense
NMAKE Reference
How to: Create a C++ project from existing code
Special characters in a makefile
Makefile contents and features
Running NMAKE
Article • 02/17/2022
NMAKE [option ...] [macros ...] [targets ...] [ @ command-file ...]
NMAKE builds only specified targets or, when none is specified, the first target in the
makefile. The first makefile target can be a pseudotarget that builds other targets.
NMAKE uses makefiles specified with /F , or if /F isn't specified, the Makefile file in the
current directory. If no makefile is specified, it uses inference rules to build command￾line targets.
The command-file text file (or response file) contains command-line input. Other input
can precede or follow @command-file. A path is permitted. In command-file, line breaks
are treated as spaces. Enclose macro definitions in quotation marks if they contain
spaces.
NMAKE options are described in the following table. Options are preceded by either a
slash ( / ) or a dash ( - ), and aren't case-sensitive. Use !CMDSWITCHES to change option
settings in a makefile or in Tools.ini .
Option Purpose
/A Forces build of all evaluated targets, even if not out-of-date compared to
dependents. Doesn't force builds of unrelated targets.
/B Forces build even if timestamps are equal. Recommended only for fast systems
(resolution of two seconds or less).
/C Suppresses default output, including nonfatal NMAKE errors or warnings,
timestamps, and NMAKE copyright message. Suppresses warnings issued by /K .
/D Displays timestamps of each evaluated target and dependent and a message
when a target doesn't exist. Useful with /P for debugging a makefile. Use
!CMDSWITCHES to set or clear /D for part of a makefile.
Syntax
Remarks
NMAKE options
Option Purpose
/E Causes environment variables to override makefile macro definitions.
/ERRORREPORT
[ NONE |
PROMPT |
QUEUE | SEND
]
Deprecated. Windows Error Reporting (WER) settings control reporting.
/F filename Specifies filename as a makefile. Spaces or tabs can precede filename. Specify /F
once for each makefile. To supply a makefile from standard input, specify a dash
( - ) for filename, and end keyboard input with either F6 or CTRL+Z.
/G Displays the makefiles included with the !INCLUDE directive. For more
information, see Makefile preprocessing directives.
/HELP , /? Displays a brief summary of NMAKE command-line syntax.
/I Ignores exit codes from all commands. To set or clear /I for part of a makefile,
use !CMDSWITCHES . To ignore exit codes for part of a makefile, use a dash ( - )
command modifier or .IGNORE. Overrides /K if both are specified.
/K Continues building unrelated dependencies, if a command returns an error. Also
issues a warning and returns an exit code of 1. By default, NMAKE halts if any
command returns a nonzero exit code. Warnings from /K are suppressed by /C ;
/I overrides /K if both are specified.
/N Displays but doesn't execute commands; preprocessing commands are executed.
Doesn't display commands in recursive NMAKE calls. Useful for debugging
makefiles and checking timestamps. To set or clear /N for part of a makefile, use
!CMDSWITCHES .
/NOLOGO Suppresses the NMAKE copyright message.
/P Displays information (macro definitions, inference rules, targets, .SUFFIXES list) to
standard output, and then runs the build. If no makefile or command-line target
exists, it displays information only. Use with /D to debug a makefile.
/Q Checks timestamps of targets; doesn't run the build. Returns a zero exit code if all
targets are up to date, and a nonzero exit code if any target is out of date.
Preprocessing commands are executed. Useful when running NMAKE from a
batch file.
/R Clears the .SUFFIXES list and ignores inference rules and macros that are defined
in the Tools.ini file or that are predefined.
/S Suppresses display of executed commands. To suppress display in part of a
makefile, use the @ command modifier or .SILENT. To set or clear /S for part of a
makefile, use !CMDSWITCHES .
Option Purpose
/T Updates timestamps of command-line targets (or first makefile target) and
executes preprocessing commands but doesn't run the build.
/U Must be used in conjunction with /N . Dumps inline NMAKE files so that the /N
output can be used as a batch file.
/X filename Sends NMAKE error output to filename instead of standard error. Spaces or tabs
can precede filename. To send error output to standard output, specify a dash ( - )
for filename. Doesn't affect output from commands to standard error.
/Y Disables batch-mode inference rules. When this option is selected, all batch￾mode inference rules are treated as regular inference rules.
NMAKE reads Tools.ini before it reads makefiles, unless /R is used. It looks for
Tools.ini first in the current directory, and then in the directory specified by the INIT
environment variable. The section for NMAKE settings in the initialization file begins
with [NMAKE] and can contain any makefile information. Specify a comment on a
separate line beginning with a number sign ( # ).
NMAKE returns the following exit codes:
Code Meaning
0 No error (possibly a warning)
1 Incomplete build (issued only when /K is used)
2 Program error, possibly caused by one of these issues:
- A syntax error in the makefile
- An error or exit code from a command
- An interruption by the user
4 System error — out of memory
255 Target isn't up to date (issued only when /Q is used)
Tools.ini and NMAKE
Exit Codes from NMAKE
See also
NMAKE Reference
NMAKE makefile contents and features
Article • 09/30/2021
A makefile contains:
Description blocks
Commands
Macros
Inference rules
Dot directives
Preprocessing directives
For a sample, see Sample makefile.
NMAKE supports other features, such as wildcards, long filenames, comments, and
escapes for special characters.
Wildcards and NMAKE
NMAKE expands filename wildcards ( * and ? ) in dependency lines. A wildcard specified
in a command is passed to the command; NMAKE doesn't expand it.
Long filenames in a makefile
Enclose long filenames in double quotation marks, as follows:
makefile
all : "VeryLongFileName.exe"
Comments in a makefile
Precede a comment with a number sign ( # ). NMAKE ignores text from the number sign
to the next newline character.
Examples:
makefile
# Comment on line by itself
OPTIONS = /MAP # Comment on macro definition line
all.exe : one.obj two.obj # Comment on dependency line
 link one.obj two.obj
# Comment in commands block
# copy *.obj \objects # Command turned into comment
 copy one.exe \release
.obj.exe: # Comment on inference rule line
 link $<
my.exe : my.obj ; link my.obj # Err: cannot comment this
# Error: # must be the first character
.obj.exe: ; link $< # Error: cannot comment this
To specify a literal number sign, precede it with a caret ( ^ ), as follows:
makefile
DEF = ^#define #Macro for a C preprocessing directive
Special characters in a makefile
To use an NMAKE special character as a literal character, place a caret ( ^ ) in front of it as
an escape. NMAKE ignores carets that precede other characters. The special characters
are:
: ; # ( ) $ ^ \ { } ! @ —
A caret ( ^ ) within a quoted string is treated as a literal caret character. A caret at the
end of a line inserts a literal newline character in a string or macro.
In macros, a backslash ( \ ) followed by a newline character is replaced by a space.
In commands, a percent symbol ( % ) is a file specifier. To represent % literally in a
command, specify a double percent sign ( %% ) in place of a single one. In other
situations, NMAKE interprets a single % literally, but it always interprets a double %% as a
single % . Therefore, to represent a literal %% , specify either three percent signs, %%% , or
four percent signs, %%%% .
To use the dollar sign ( $ ) as a literal character in a command, specify two dollar signs
( $$ ). This method can also be used in other situations where ^$ works.
See also
NMAKE Reference
Sample Makefile
Article • 09/30/2021
This topic contains a sample makefile.
makefile
Makefile contents and features
Sample
Code
# Sample makefile
!include <win32.mak>
all: simple.exe challeng.exe
.c.obj:
 $(cc) $(cdebug) $(cflags) $(cvars) $*.c
simple.exe: simple.obj
 $(link) $(ldebug) $(conflags) -out:simple.exe simple.obj $(conlibs)
lsapi32.lib
challeng.exe: challeng.obj md4c.obj
 $(link) $(ldebug) $(conflags) -out:challeng.exe $** $(conlibs) lsapi32.lib
See also
Description blocks
Article • 09/30/2021
Description blocks form the core of a makefile. They describe the targets, or files to
create, and their dependencies, the files needed to create the targets. A description block
may include commands, that describe how to create the targets from the dependencies.
A description block is a dependency line, optionally followed by a commands block:
makefile
targets... : dependents...
 commands...
Dependency lines
A dependency line specifies one or more targets, and zero or more dependents. If a
target doesn't exist, or has an earlier timestamp than a dependent, NMAKE executes the
commands in the command block. NMAKE also executes the command block if the
target is a pseudotarget. Here's an example dependency line:
makefile
hi_bye.exe : hello.obj goodbye.obj helper.lib
In this dependency line, hi_bye.exe is the target. Its dependencies are hello.obj ,
goodbye.obj , and helper.lib . The dependency line tells NMAKE to build the target
whenever hello.obj , goodbye.obj , or helper.lib has changed more recently than
hi_bye.exe .
A target must be at the start of the line. It can't be indented with any spaces or tabs. Use
a colon ( : ) to separate targets from dependents. Spaces or tabs are allowed between
targets, the colon separator ( : ), and dependents. To split the dependency line, use a
backslash ( \ ) after a target or dependent.
Before it executes command blocks, NMAKE scans all the dependencies and any
applicable inference rules to build a dependency tree. A dependency tree specifies the
steps required to fully update the target. NMAKE checks recursively whether a
dependent is itself a target in another dependency list. After it builds the dependency
tree, NMAKE checks time stamps. If any dependents in the tree are newer than the
target, NMAKE builds the target.
Targets
The targets section of a dependency line specifies one or more targets. A target can be
any valid filename, directory name, or pseudotarget. Separate multiple targets by using
one or more spaces or tabs. Targets aren't case-sensitive. Paths are permitted with
filenames. A target and its path can't exceed 256 characters. If the target preceding the
colon is a single character, use a separating space. Otherwise, NMAKE interprets the
letter-colon combination as a drive specifier.
Multiple targets
NMAKE evaluates multiple targets in a single dependency as if each were specified in a
separate description block.
For example, this rule:
makefile
bounce.exe leap.exe : jump.obj
 echo Building...
is evaluated as:
makefile
bounce.exe : jump.obj
 echo Building...
leap.exe : jump.obj
 echo Building...
Cumulative dependencies
Dependencies are cumulative in a description block, if a target is repeated.
For example, this set of rules,
makefile
bounce.exe : jump.obj
bounce.exe : up.obj
 echo Building bounce.exe...
is evaluated as:
makefile
bounce.exe : jump.obj up.obj
 echo Building bounce.exe...
When you have multiple targets in multiple dependency lines in a single description
block, NMAKE evaluates them as if each were specified in a separate description block.
However, only targets in the last dependency line use the commands block. NMAKE
attempts to use an inference rule for the other targets.
For example, this set of rules,
makefile
leap.exe bounce.exe : jump.obj
bounce.exe climb.exe : up.obj
 echo Building bounce.exe...
is evaluated as:
makefile
leap.exe : jump.obj
# invokes an inference rule
bounce.exe : jump.obj up.obj
 echo Building bounce.exe...
climb.exe : up.obj
 echo Building bounce.exe...
Targets in multiple description blocks
To update a target in more than one description block using different commands,
specify two consecutive colons (::) between targets and dependents.
makefile
target.lib :: one.asm two.asm three.asm
 ml one.asm two.asm three.asm
 lib target one.obj two.obj three.obj
target.lib :: four.c five.c
 cl /c four.c five.c
 lib target four.obj five.obj
Dependency side effects
You might specify a target with a colon (:) in two dependency lines in different locations.
If commands appear after only one of the lines, NMAKE interprets the dependencies as
if the lines were adjacent or combined. It doesn't invoke an inference rule for the
dependency that has no commands. Instead, NMAKE assumes the dependencies belong
to one description block, and executes the commands specified with the other
dependency. Consider this set of rules:
makefile
bounce.exe : jump.obj
 echo Building bounce.exe...
bounce.exe : up.obj
is evaluated as:
makefile
bounce.exe : jump.obj up.obj
 echo Building bounce.exe...
This effect doesn't occur if a double colon ( :: ) is used. For example, this set of rules:
makefile
bounce.exe :: jump.obj
 echo Building bounce.exe...
bounce.exe :: up.obj
is evaluated as:
makefile
bounce.exe : jump.obj
 echo Building bounce.exe...
bounce.exe : up.obj
# invokes an inference rule
Pseudotargets
A pseudotarget is a label used in place of a filename in a dependency line. It's
interpreted as a file that doesn't exist, and so is out-of-date. NMAKE assumes a
pseudotarget's timestamp is the same as the most recent of all its dependents. If it has
no dependents, the current time is assumed. If a pseudotarget is used as a target, its
commands are always executed. A pseudotarget used as a dependent must also appear
as a target in another dependency. However, that dependency doesn't need to have a
commands block.
Pseudotarget names follow the filename syntax rules for targets. However, if the name
doesn't have an extension, it can exceed the 8-character limit for filenames, and can be
up to 256 characters long.
Pseudotargets are useful when you want NMAKE to build more than one target
automatically. NMAKE only builds targets specified on the command line. Or, if no
command-line target is specified, it builds only the first target in the first dependency in
the makefile. You can tell NMAKE to build multiple targets without listing them
individually on the command line. Write a description block with a dependency
containing a pseudotarget, and list the targets you want to build as its dependents.
Then, place this description block first in the makefile, or specify the pseudotarget on
the NMAKE command line.
In this example, UPDATE is a pseudotarget.
makefile
UPDATE : *.*
!COPY $** c:\product\release
When UPDATE is evaluated, NMAKE copies all files in the current directory to the
specified drive and directory.
In the following makefile, the pseudotarget all builds both project1.exe and
project2.exe if either all or no target is specified on the command line. The
pseudotarget setenv changes the LIB environment variable before the .exe files are
updated:
makefile
all : setenv project1.exe project2.exe
project1.exe : project1.obj
 LINK project1;
project2.exe : project2.obj
 LINK project2;
setenv :
 set LIB=\project\lib
Dependents
In a dependency line, specify zero or more dependents after the colon ( : ) or double
colon ( :: ), using any valid filename or pseudotarget. Separate multiple dependents by
using one or more spaces or tabs. Dependents aren't case-sensitive. Paths are permitted
with filenames.
Inferred dependents
Along with dependents you explicitly list in the dependency line, NMAKE can assume an
inferred dependent. An inferred dependent is derived from an inference rule, and is
evaluated before explicit dependents. When an inferred dependent is out-of-date
compared to its target, NMAKE invokes the command block for the dependency. If an
inferred dependent doesn't exist, or is out-of-date compared to its own dependents,
NMAKE first updates the inferred dependent. For more information about inferred
dependents, see Inference rules.
Search paths for dependents
You can specify an optional search path for each dependent. Here's the syntax to specify
a set of directories to search:
{directory[;directory...]}dependent
Enclose directory names in braces ( { } ). Separate multiple directories with a semicolon
( ; ). No spaces or tabs are allowed. NMAKE looks for the dependent first in the current
directory, and then in the list of directories in the order specified. You can use a macro
to specify part or all of a search path. Only the specified dependent uses this search
path.
Directory search path example
This dependency line shows how to create a directory specification for a search:
makefile
reverse.exe : {\src\omega;e:\repo\backwards}retro.obj
The target reverse.exe has one dependent, retro.obj . The brace-enclosed list specifies
two directories. NMAKE searches for retro.obj in the current directory first. If it isn't
there, NMAKE searches the \src\omega directory, then the e:\repo\backwards directory.
See also
NMAKE Reference
Commands in a makefile
Article • 09/30/2021
A description block or inference rule specifies a block of commands to run if the
dependency is out-of-date. NMAKE displays each command before running it, unless
/S , .SILENT , !CMDSWITCHES , or @ is used. NMAKE looks for a matching inference rule if a
description block isn't followed by a commands block.
A commands block contains one or more commands, each on its own line. No blank line
can appear between the dependency or rule and the commands block. However, a line
containing only spaces or tabs can appear; this line is interpreted as a null command,
and no error occurs. Blank lines are permitted between command lines.
A command line begins with one or more spaces or tabs. A backslash ( \ ) followed by a
newline character is interpreted as a space in the command. Use a backslash at the end
of a line to continue a command onto the next line. NMAKE interprets the backslash
literally if any other character, including a space or tab, follows the backslash.
A command preceded by a semicolon ( ; ) can appear on a dependency line or inference
rule, whether a commands block follows or not:
makefile
You can specify one or more command modifiers preceding a command, optionally
separated by spaces or tabs. As with commands, modifiers must be indented.
Modifier Purpose
@ command Prevents display of the command. Display by commands is not suppressed. By
default, NMAKE echoes all executed commands. Use /S to suppress display for the
entire makefile; use .SILENT to suppress display for part of the makefile.
- [number]
command
Turns off error checking for command. By default, NMAKE halts when a command
returns a nonzero exit code. If -number is used, NMAKE stops if the exit code
exceeds number. Spaces or tabs can't appear between the dash and number. At
least one space or tab must appear between number and command. Use /I to turn
off error checking for the entire makefile; use .IGNORE to turn off error checking for
part of the makefile.
project.obj : project.c project.h ; cl /c project.c
Command modifiers
Modifier Purpose
!
command
Executes command for each dependent file if command uses $** (all dependent
files in the dependency) or $? (all dependent files in the dependency with a later
timestamp than the target).
Filename-parts syntax in commands represents components of the first dependent
filename (which may be an implied dependent). Filename components are the file's
drive, path, base name, and extension as specified, not as it exists on disk. Use %s to
represent the complete filename. Use %| [parts] F (a vertical bar character follows the
percent symbol) to represent parts of the filename, where parts can be zero or more of
the following letters, in any order.
Letter Description
No letter Complete name (same as %s )
d Drive
p Path
f File base name
e File extension
For example, if the filename is c:\prog.exe :
%s becomes c:\prog.exe
%|F becomes c:\prog.exe
%|dF becomes c
%|pF becomes c:\
%|fF becomes prog
%|eF becomes exe
Inline files in a makefile
Filename-parts syntax
What do you want to know more about?
See also
NMAKE Reference
Inline files in a makefile
Article • 09/30/2021
An inline file contains text you specify in the makefile. Its name can be used in
commands as input (for example, a LINK command file), or it can pass commands to the
operating system. The file is created on disk when a command that creates the file is
run.
Specify an inline file
Specify two angle brackets ( << ) in the command where filename is to appear. The angle
brackets can't be a macro expansion. The filename is optional:
makefile
<<filename
When the command is run, the angle brackets are replaced by filename, if specified, or
by a unique NMAKE-generated name. If specified, filename must follow angle brackets
without a space or tab. A path is permitted. No extension is required or assumed. If
filename is specified, the file is created in the current or specified directory, overwriting
any existing file by that name. Otherwise, it's created in the TMP directory (or the current
directory, if the TMP environment variable isn't defined). If a previous filename is reused,
NMAKE replaces the previous file.
Create inline file text
Inline files are temporary or permanent.
makefile
inline_text
.
.
.
<<[KEEP | NOKEEP]
Specify your inline_text on the first line after the command. Mark the end with double
angle brackets ( << ) at the beginning of a separate line, followed by an optional KEEP or
NOKEEP . The file contains all inline_text before the delimiting brackets. The inline_text can
have macro expansions and substitutions, but not directives or makefile comments.
Spaces, tabs, and newline characters are treated literally.
A temporary file exists for the duration of the session and can be reused by other
commands. Specify KEEP after the closing angle brackets to retain the file after the
NMAKE session; an unnamed file is preserved on disk with the generated filename.
Specify NOKEEP or nothing for a temporary file. KEEP and NOKEEP are not case sensitive.
Reuse inline files
To reuse an inline file, specify <<filename where the file is defined and first used, then
reuse filename without << later in the same or another command. The command to
create the inline file must run before all commands that use the file.
Multiple inline files
A command can create more than one inline file:
makefile
command << <<
inline_text
<<[KEEP | NOKEEP]
inline_text
. . .
inline_text
<<[KEEP | NOKEEP]
For each file, specify one or more lines of inline text followed by a closing line
containing the delimiter and optional KEEP or NOKEEP . Begin the second file's text on the
line following the delimiting line for the first file.
See also
Commands in a Makefile
Macros and NMAKE
Article • 08/03/2021
Macros replace a particular string in the makefile with another string. Using macros, you
can:
Create a makefile that can build different projects.
Specify options for commands.
Set environment variables.
You can define your own macros or use NMAKE's predefined macros.
What do you want to know more about?
Defining an NMAKE macro
Using an NMAKE macro
Special NMAKE macros
See also
NMAKE Reference
Define an NMAKE macro
Article • 09/30/2021
An NMAKE macro is defined by using this syntax:
makefile
macro_name=string
The macro_name is a case-sensitive combination of letters, digits, and underscores ( _ )
up to 1,024 characters long. The macro_name can contain an invoked macro. If
macro_name consists entirely of an invoked macro, the macro being invoked can't be
null or undefined.
The string can be any sequence of zero or more characters. A null string contains zero
characters or only spaces or tabs. The string can contain a macro invocation.
Special characters in macros
A number sign ( # ) after a definition specifies a comment. To specify a literal number
sign in a macro, use a caret ( ^ ) to escape it, as in ^# .
A dollar sign ( $ ) specifies a macro invocation. To specify a literal $ , use $$ .
To extend a definition to a new line, end the line with a backslash ( \ ). When the macro
is invoked, the backslash and following newline character is replaced with a space. To
specify a literal backslash at the end of the line, precede it with a caret ( ^ ) escape, or
follow it with a comment specifier ( # ).
To specify a literal newline character, end the line with a caret ( ^ ) escape, as in this
example:
makefile
CMDS = cls^
dir
Null and undefined macros
Both null and undefined macros expand to null strings, but a macro defined as a null
string is considered defined in preprocessing expressions. To define a macro as a null
string, specify no characters except spaces or tabs after the equal sign ( = ) in a command
line or command file, and enclose the null string or definition in double quotation marks
( " " ). To undefine a macro, use !UNDEF . For more information, see Makefile
preprocessing directives.
Where to define macros
Define macros in a command line, command file, makefile, or the Tools.ini file.
In a makefile or the Tools.ini file, each macro definition must appear on a separate line
and can't start with a space or tab. Spaces or tabs around the equal sign are ignored. All
string characters are literal, including surrounding quotation marks and embedded
spaces.
In a command line or command file, spaces and tabs delimit arguments and can't
surround the equal sign. If string has embedded spaces or tabs, enclose either the string
itself or the entire macro in double quotation marks ( " " ).
Precedence in macro definitions
If a macro has multiple definitions, NMAKE uses the highest-precedence definition. The
following list shows the order of precedence, from highest to lowest:
1. A macro defined on the command line
2. A macro defined in a makefile or include file
3. An inherited environment-variable macro
4. A macro defined in the Tools.ini file
5. A predefined macro, such as CC and AS
Use /E to cause macros inherited from environment variables to override makefile
macros with the same name. Use !UNDEF to override a command line.
See also
Macros and NMAKE
Use an NMAKE macro
Article • 02/25/2022
To use a macro, enclose its name in parentheses preceded by a dollar sign ( $ ) as
follows:
makefile
$(macro_name)
No spaces are allowed. The parentheses are optional if macro_name is a single
character. The definition string replaces $(macro_name) ; an undefined macro is replaced
by a null string.
Macro substitution
When macro_name is invoked, each occurrence of string1 in its definition string is
replaced by string2.
makefile
$(macro_name:string1=string2)
Macro substitution is case-sensitive and is literal; string1 and string2 can't invoke
macros. Substitution doesn't modify the original definition. You can replace text in any
predefined macro except $$@.
No spaces or tabs precede the colon ( : ); any spaces or tabs after the colon are
interpreted as literal. If string2 is null, all occurrences of string1 are deleted from the
macro's definition string.
Macro functions
NMAKE provides a set of functions that can be used to modify strings, lists of items and
file paths. These functions are available in NMAKE starting in Visual Studio 2022.
Function syntax
Functions use the following syntax:
makefile
$(function_name arg0,arg1,arg2...)
Arguments to a function can be any string and may include nested macro invocations.
Except in special cases, arguments can't be null.
Any extra whitespace between the function name and the argument list is ignored. If the
first argument requires leading whitespace, then use a macro that contains the needed
whitespace:
makefile
SINGLESPACE=$(subst ',,' ') # Use "subst" since a normal assignment trims
trailing whitespace.
$(subst $(SINGLESPACE)an,irec,red ant) # Evaluates to "redirect"
Commas within an argument list are always considered argument separators and can't
be escaped. If any argument requires a literal comma, use a macro that contains a
comma instead:
makefile
COMMA=,
INPUT=a, b
$(subst $(COMMA) , and ,$(INPUT)) # Evaluates to "a and b"
List syntax
Some functions support a whitespace-separated list of items. Extra whitespace is
ignored at the beginning of the list, the end of the list, or between each item. Lists
produced by a function use a single space between each item as a separator, and don't
have leading or trailing whitespace.
For example, the simplest list function is strip , which takes a single list argument and
produces a list with the exact same items (but with the whitespace cleaned as above):
makefile
$(strip a b c d ) # Evaluates to "a b c d"
Pattern syntax
Some functions support using a pattern. A pattern is a string that contains a single
wildcard that can match any number of characters. The first % in a pattern is the
wildcard, and any later % characters are treated as literals. A % anywhere before the
actual wildcard can be escaped by using \ (that is, \% is treated as a literal % ). Any \
that would escape the wildcard can be escaped with another \ (so \\% is treated as a
literal \ followed by the wildcard). To be considered a match, all of the input characters
must be matched by the pattern; partial matches aren't supported.
Patterns can be demonstrated using the filter function, which only keeps items that
match the pattern:
makefile
Function Purpose Supported
Text functions Purpose Supported
findstring,
findstringi
Checks if the input contains a string. VS 2022
17.0
lowercase Converts a string to lowercase. VS 2022
17.2
subst, substi Replaces all instances of one string with another. VS 2022
17.0
$(filter abc,abc) # Evaluates to "abc" - exactly matches
$(filter bc,abc) # Evaluates to "" - pattern "bc" only matches part of the
item "abc"
$(filter %ef,abcdef) # Evaluates to "abcdef" - wildcard matches "abcd"
$(filter a%f,abcdef) # Evaluates to "abcdef" - wildcard matches "bcde"
$(filter %abc,abc) # Evaluates to "abc" - wildcard doesn't need to match any
characters
$(filter a%c%d,abcd abc%d) # Evaluates to "abc%d" - only the first `%` is a
wildcard, the rest are literals
$(filter a\%b%d,a%bcd) # Evaluates to "a%bcd" - `%` before the wildcard must
be escaped with `\`
$(filter a\\%cd,a\bcd) # Evaluates to "a\bcd" - a `\` that would escape the
wildcard must be escaped with another `\`
$(filter a%c\\%d,abc\\%d) # Evaluates to "abc\\%d" - any `\` after the
wildcard isn't treated as an escape
$(filter \\a%f,\\abcdef) # Evaluates to "\\abcdef" - any `\\` that isn't
directly before the wildcard isn't treated as an escape
Functions by category
Function Purpose Supported
uppercase Converts a string to uppercase. VS 2022
17.2
List functions Purpose Supported
filter, filteri Keeps items in a list that match at least one pattern. VS 2022
17.0
filterout,
filterouti
Keeps items in a list that don't match any patterns. VS 2022
17.0
patsubst,
patsubsti
Transforms each item that matches a pattern, items that don't
match are left as-is.
VS 2022
17.1
strip Cleans the whitespace in and around a list of items. VS 2022
17.0
File path
functions
Purpose Supported
abspath Gets the absolute path for each item in a list. VS 2022
17.1
basename Gets the base name for each item in a list. VS 2022
17.1
Macros and NMAKE
See also
abspath NMAKE function
Article • 02/25/2022
Gets the absolute path for each item in a list.
Syntax
makefile
$(abspath input)
Parameters
input
The list of file paths to convert.
Return value
A list with each of the items from input converted to their absolute form.
Remarks
abspath supports extended-length paths, either by using the \\?\ prefix, or when long
paths are enabled. For more information about long paths, see Maximum Path Length
Limitation.
This macro function is available starting in Visual Studio 2022 version 17.1, in NMAKE
version 14.31 or later.
Example
makefile
$(abspath relative\path\file.c) # If run from "c:\temp", evaluates to
"c:\temp\relative\path\file.c"
$(abspath c:\temp\..\file1.cpp c:\\temp\/dir//) # Evaluates to "c:\file1.cpp
c:\temp\dir\". Follows path traversals and normalizes directory separators.
# abspath can be combined with filter to find which items exist within a
directory tree
TEMP_SOURCES=$(filteri c:\temp\\%,$(abspath $(SOURCES)))
See also
Macros and NMAKE
NMAKE functions by category
basename NMAKE function
Article • 02/25/2022
Gets the base name for each item in a list.
Syntax
makefile
$(basename input)
Parameters
input
The list of file paths to convert.
Return value
A list with each of the items from input converted to their base name (that is, with their
extensions removed).
Remarks
basename doesn't have any maximum path limitations.
The basename function is equivalent to using the R modifier in a filename macro.
This macro function is available starting in Visual Studio 2022 version 17.1, in NMAKE
version 14.31 or later.
Example
makefile
$(basename c:\temp\file.txt) # Evaluates to "c:\temp\file"
$(basename c:\temp\ c:\file) # Evaluates to "c:\temp\ c:\file" - Directories
and files without extensions are left as-is
$(basename c:\src\.gitignore) # Evaluates to "c:\src\" - Dot files are
considered to be extensions and so are removed
See also
Macros and NMAKE
NMAKE functions by category
filter , filteri NMAKE functions
Article • 11/22/2021
Evaluates to a list of items that matched at least one pattern.
Syntax
makefile
$(filter filters,input)
$(filteri filters,input)
Parameters
filters
A list of one or more patterns to filter by.
input
The list to be filtered.
Return value
A list of all of the items in input that match at least one pattern in filters .
Remarks
filteri is the case-insensitive version of filter .
This macro function is available starting in Visual Studio 2022, in NMAKE version 14.30
or later.
Example
makefile
$(filter He%,Hello Hey Hi) # Evaluates to "Hello Hey" - "Hi" doesn't match
the filter
$(filter %y %i,Hello Hey Hi) # Evaluates to "Hey Hi" - items are kept if
they match any filter, "Hello" is dropped as it doesn't match any
$(filter Not%Found,Hello Hey Hi) # Evaluates to "" - none of the items match
any filters
$(filter he%,Hello Hey Hi) # Evaluates to "" - filter is case-sensitive
$(filteri he%,Hello Hey Hi) # Evaluates to "Hello Hey" - filteri is case￾insensitive
# filteri is commonly used to filter a list of files by their extensions
CPP_SOURCES=$(filteri %.cpp %.cxx,$(SOURCES))
C_SOURCES=$(filteri %.c,$(SOURCES))
See also
Macros and NMAKE
NMAKE functions by category
filterout, filterouti
filterout , filterouti NMAKE functions
Article • 11/22/2021
Evaluates to a list of items that don't match any patterns.
Syntax
makefile
$(filterout filters,input)
$(filterouti filters,input)
Parameters
filters
A list of one or more patterns to filter by.
input
The list to be filtered.
Return value
A list of all of the items in input that don't match any patterns in filters .
Remarks
filterouti is the case-insensitive version of filterout .
This macro function is available starting in Visual Studio 2022, in NMAKE version 14.30
or later.
Example
makefile
$(filterout He%,Hello Hey Hi) # Evaluates to "Hi" - "Hello" and "Hey" match
the filter
$(filterout %y %i,Hello Hey Hi) # Evaluates to "Hello" - items are kept if
they don't match any filters, "Hey" and "Hi" each match one filter
$(filterout H%,Hello Hey Hi) # Evaluates to "" - each of the items matched
the filter
$(filterout he%,Hello Hey Hi) # Evaluates to "Hello Hey Hi" - filterout is
case-sensitive
$(filterouti he%,Hello Hey Hi) # Evaluates to "Hi" - filterouti is case￾insensitive
See also
Macros and NMAKE
NMAKE functions by category
filter, filteri
findstring , findstringi NMAKE
functions
Article • 11/22/2021
Evaluates to the searched-for string if it's found within another string.
Syntax
makefile
$(findstring searchFor,input)
$(findstringi searchFor,input)
Parameters
searchFor
The string to search for.
input
The string to search in.
Return value
If searchFor is found within input , then the function returns searchFor , otherwise it
returns null.
Remarks
findstringi is the case-insensitive version of findstring .
This macro function is available starting in Visual Studio 2022, in NMAKE version 14.30
or later.
Example
makefile
$(findstring Hello,Hello World!) # Evaluates to "Hello"
$(findstring Hey,Hello World!) # Evaluates to ""
$(findstring hello,Hello World!) # Evaluates to "" - findstring is case￾sensitive
$(findstringi hello,Hello World!) # Evaluates to "hello" - findstringi is
case-insensitive
See also
Macros and NMAKE
NMAKE functions by category
lowercase NMAKE function
Article • 02/25/2022
Evaluates to a string where all characters have been converted to their lowercase
equivalent.
Syntax
makefile
$(lowercase input)
Parameters
input
The string to convert.
Return value
Returns input , but all characters have been converted to their lowercase equivalent.
Remarks
This macro function is available starting in Visual Studio 2022 version 17.2, in NMAKE
version 14.32 or later.
Example
makefile
$(lowercase Hello World!) # Evaluates to "hello world!"
See also
Macros and NMAKE
NMAKE functions by category
patsubst , patsubsti NMAKE functions
Article • 02/25/2022
Evaluates to a list of items with each item that matches a pattern replaced by a
substitution, and items that don't match kept as-is.
Syntax
makefile
$(patsubst pattern,replacement,input)
$(patsubsti pattern,replacement,input)
Parameters
pattern
The pattern to search for.
replacement
The pattern to replace pattern with. If a wildcard is present in replacement , then it will
be replaced with the text that the wildcard in pattern matched.
input
The list of items to be replaced or kept.
Return value
Returns input , but each item that matches pattern is replaced by replacement . Items
that don't match pattern are kept as-is.
Remarks
patsubsti is the case-insensitive version of patsubst .
This macro function is available starting in Visual Studio 2022 version 17.1, in NMAKE
version 14.31 or later.
Example
makefile
$(patsubst He%,_%_,Hello Hey Hi) # Evaluates to "_llo_ _y_ Hi"
# "He" matches "Hello" and "Hey", and so "llo" and "y" are matched by the
wildcard
# and used to substitute the wildcard in the replacement. "Hi" is not
matched and so is kept as-is
$(patsubst Hi,Bye,Hello Hey Hi) # Evaluates to "Hello Hey Bye" - No wildcard
is required
$(patsubst %lo,Bye,Hello Hey Hi) # Evaluates to "Bye Hey Hi"
# A wildcard can be used in the pattern without a wildcard in the
replacement
$(patsubst he%,_%_,Hello Hey Hi) # Evaluates to "Hello Hey Hi" - patsubst is
case-sensitive, so no substitutions performed
$(patsubsti he%,_%_,Hello Hey Hi) # Evaluates to "_llo_ _y_ Hi" - patsubsti
is case-insensitive
# patsubsti is commonly used to change the file extensions of a list of
files
OBJ_FILES=$(patsubst %.c,%.obj,$(C_SOURCES)) $(patsubst
%.cpp,%.obj,$(patsubst %.cxx,%.obj,$(CPP_SOURCES)))
See also
Macros and NMAKE
NMAKE functions by category
strip NMAKE function
Article • 11/22/2021
Cleans up whitespace in and around a list of items.
Syntax
makefile
$(strip input)
Parameters
input
The list to be cleaned.
Return value
A list of the exact same items as input .
Remarks
NMAKE outputs a list that has a single space between each item and no leading or
trailing whitespace. strip doesn't change any item within a list, but it does ensure that
the returned list is in this canonical form. The canonical form can be useful for later
operations that operate on strings instead of lists.
This macro function is available starting in Visual Studio 2022, in NMAKE version 14.30
or later.
Example
makefile
$(strip a b c d ) # Evaluates to "a b c d"
# strip is useful to get a canonical form of a list, which can then be
transformed into a different format
SINGLESPACE=$(subst ',,' ') # Use "subst" since a normal assignment trims
trailing whitespace.
INCLUDE_PATH=$(subst $(SINGLESPACE),;,$(strip $(INCLUDES)))
See also
Macros and NMAKE
NMAKE functions by category
subst , substi NMAKE functions
Article • 11/22/2021
Evaluates to a string where all instances of one string have been replaced with another.
Syntax
makefile
$(subst oldString,newString,input)
$(substi oldString,newString,input)
Parameters
oldString
The string to replace.
newString
The string that replaces oldString . This argument can be null.
input
The string to search.
Return value
Returns input , but all instances of oldString are replaced by newString . If newString is
null, then all instances of oldString are removed.
Remarks
substi is the case-insensitive version of subst .
This macro function is available starting in Visual Studio 2022, in NMAKE version 14.30
or later.
Example
makefile
$(subst Hello,Hey,Hello World!) # Evaluates to "Hey World!"
$(subst ed,ing,red ring mended) # Evaluates to "ring ring mending"
$(subst Hello ,,Hello World!) # Evaluates to "World!"
$(subst hello,Hey,Hello World!) # Evaluates to "Hello World!" - subst is
case-sensitive, so no substitution performed
$(substi hello,Hey,Hello World!) # Evaluates to "Hey World!" - substi is
case-insensitive
See also
Macros and NMAKE
NMAKE functions by category
uppercase NMAKE function
Article • 02/25/2022
Evaluates to a string where all characters have been converted to their uppercase
equivalent.
Syntax
makefile
$(uppercase input)
Parameters
input
The string to convert.
Return value
Returns input , but all characters have been converted to their uppercase equivalent.
Remarks
This macro function is available starting in Visual Studio 2022 version 17.2, in NMAKE
version 14.32 or later.
Example
makefile
$(uppercase Hello World!) # Evaluates to "HELLO WORLD!"
See also
Macros and NMAKE
NMAKE functions by category
Special NMAKE macros
Article • 06/21/2022
NMAKE provides several special macros to represent various filenames and commands.
One use for some of these macros is in the predefined inference rules. Like all macros,
the macros provided by NMAKE are case sensitive.
Filename macros are predefined as filenames specified in the dependency (not full
filename specifications on disk). These macros don't need to be enclosed in parentheses
when invoked; specify only a $ as shown.
Macro Meaning
$@ Current target's full name (path, base name, extension), as currently specified.
$$@ Current target's full name (path, base name, extension), as currently specified. Valid only
as a dependent in a dependency.
$* Current target's path and base name minus file extension.
$** All dependents of the current target.
$? All dependents with a later timestamp than the current target.
$< Dependent file with a later timestamp than the current target. Valid only in commands in
inference rules.
To specify part of a predefined filename macro, append a macro modifier and enclose
the modified macro in parentheses.
Modifier Resulting filename part
D Drive plus directory
B Base name
F Base name plus extension
R Drive plus directory plus base name
Filename Macros
Recursion macros
Use recursion macros to call NMAKE recursively. Recursive sessions inherit command￾line and environment-variable macros and Tools.ini information. They don't inherit
makefile-defined inference rules or .SUFFIXES and .PRECIOUS specifications. There are
three ways to pass macros to a recursive NMAKE session:
Set an environment variable with a SET command before the recursive call.
Define a macro in the command for the recursive call.
Or, define a macro in Tools.ini .
Macro Definition
MAKE Command used originally to invoke NMAKE.
The $(MAKE) macro gives the full path to nmake.exe .
MAKEDIR Current directory when NMAKE was invoked.
MAKEFLAGS Options currently in effect. Use as /$(MAKEFLAGS) . The /F option isn't included.
Command macros are predefined for Microsoft products. Options macros represent
options to these products and are undefined by default. Both are used in predefined
inference rules and can be used in description blocks or user-defined inference rules.
Command macros can be redefined to represent part or all of a command line, including
options. Options macros generate a null string if left undefined.
Tool Command macro Defined as Options macro
Macro Assembler AS ml or ml64 AFLAGS
C Compiler CC cl CFLAGS
C++ Compiler CPP cl CPPFLAGS
C++ Compiler CXX cl CXXFLAGS
Resource Compiler RC rc RFLAGS
NMAKE inherits macro definitions for environment variables that exist before the start of
the session. If a variable was set in the operating-system environment, it is available as
an NMAKE macro. The inherited names are converted to uppercase. Inheritance occurs
Command macros and options macros
Environment-variable macros
before preprocessing. Use the /E option to cause macros inherited from environment
variables to override any macros with the same name in the makefile.
Environment-variable macros can be redefined in the session, and this changes the
corresponding environment variable. You can also change environment variables with
the SET command. Using the SET command to change an environment variable in a
session does not change the corresponding macro, however.
For example:
makefile
PATH=$(PATH);\nonesuch
all:
 echo %%PATH%%
In this example, changing PATH changes the corresponding environment variable PATH ;
it appends \nonesuch to your path.
If an environment variable is defined as a string that would be syntactically incorrect in a
makefile, no macro is created and no warning is generated. If a variable's value contains
a dollar sign ($), NMAKE interprets it as the beginning of a macro invocation. Using the
macro can cause unexpected behavior.
See also
Macros and NMAKE
Inference rules
Article • 09/30/2021
Inference rules in NMAKE supply commands to update targets and to infer dependents
for targets. Extensions in an inference rule match a single target and dependent that
have the same base name. Inference rules are user-defined or predefined; predefined
rules can be redefined.
If an out-of-date dependency has no commands, and if .SUFFIXES contains the
dependent's extension, NMAKE uses a rule whose extensions match the target and an
existing file in the current or specified directory. If more than one rule matches existing
files, the .SUFFIXES list determines which to use; list priority descends from left to right.
If a dependent file doesn't exist and isn't listed as a target in another description block,
an inference rule can create the missing dependent from another file that has the same
base name. If a description block's target has no dependents or commands, an inference
rule can update the target. Inference rules can build a command-line target even if no
description block exists. NMAKE may invoke a rule for an inferred dependent even if an
explicit dependent is specified.
Defining a rule
The from_ext represents the extension of a dependent file, and to_ext represents the
extension of a target file.
makefile
.from_ext.to_ext:
 commands
Extensions aren't case-sensitive. Macros can be invoked to represent from_ext and
to_ext; the macros are expanded during preprocessing. The period ( . ) that precedes
from_ext must appear at the beginning of the line. The colon ( : ) is preceded by zero or
more spaces or tabs. It can be followed only by spaces or tabs, a semicolon ( ; ) to
specify a command, a number sign ( # ) to specify a comment, or a newline character. No
other spaces are allowed. Commands are specified as in description blocks.
Search paths in rules
makefile
An inference rule applies to a dependency only if paths specified in the dependency
exactly match the inference-rule paths. Specify the dependent's directory in from_path
and the target's directory in to_path; no spaces are allowed. Specify only one path for
each extension. A path on one extension requires a path on the other. To specify the
current directory, use either a period ( . ) or empty braces ( { } ). Macros can represent
from_path and to_path; they are invoked during preprocessing.
makefile
makefile
{from_path}.from_ext{to_path}.to_ext:
 commands
Example of search paths
{dbi\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $(YUDBI) $<
{ilstore\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $<
{misc\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $(YUPDB) $<
{misc\}.c{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $<
{msf\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $<
{bsc\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $(YUPDB) $<
{mre\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $(YUPDB) $<
{namesrvr\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $(YUPDB) $<
{src\cvr\}.cpp{$(ODIR)}.obj::
 $(CC) $(CFLAGS) $<
Batch-mode rules
Batch-mode inference rules provide only one invocation of the inference rule when N
commands go through this inference rule. Without batch-mode inference rules, it would
require N commands to be invoked. N is the number of dependents that trigger the
inference rule.
The only syntactical difference from the standard inference rule is that a batch-mode
inference rule ends with a double colon ( :: ).
The batch-mode inference rules can speed up the build process. It's faster to supply files
to the compiler in batch mode, because the compiler driver is invoked only once. For
example, the C and C++ compiler runs faster when handling a set of files, because it can
remain memory resident during the entire process.
The following example shows how to use batch-mode inference rules:
makefile
{from_path}.from_ext{to_path}.to_ext::
 commands
７ Note
The tool being invoked must be able to handle multiple files. The batch-mode
inference rule must use $< as the macro to access dependent files.
#
# sample makefile to illustrate batch-mode inference rules
#
O = .
S = .
Objs = $O/foo1.obj $O/foo2.obj $O/foo2.obj $O/foo3.obj $O/foo4.obj
CFLAGS = -nologo
all : $(Objs)
!ifdef NOBatch
{$S}.cpp{$O}.obj:
!else
{$S}.cpp{$O}.obj::
!endif
 $(CC) $(CFLAGS) -Fd$O\ -c $<
$(Objs) :
#end of makefile
NMAKE produces the following output without batch-mode inference rules:
Windows Command Prompt
NMAKE produces the following result with the batch-mode inference rules:
Windows Command Prompt
Predefined inference rules use NMAKE-supplied command and options macros.
Rule Command Default action Batch rule Platform
.asm.exe $(AS) $(AFLAGS) $< ml $< no x86
.asm.obj $(AS) $(AFLAGS) /c $< ml /c $< yes x86
.asm.exe $(AS) $(AFLAGS) $< ml64 $< no x64
.asm.obj $(AS) $(AFLAGS) /c $< ml64 /c $< yes x64
.c.exe $(CC) $(CFLAGS) $< cl $< no all
E:\tmp> nmake -f test.mak -a NOBatch=1
Microsoft (R) Program Maintenance Utility Version 7.00.0000
Copyright (C) Microsoft Corp 1988-2001. All rights reserved.
 cl -nologo -Fd.\ -c .\foo1.cpp
foo1.cpp
 cl -nologo -Fd.\ -c .\foo2.cpp
foo2.cpp
 cl -nologo -Fd.\ -c .\foo3.cpp
foo3.cpp
 cl -nologo -Fd.\ -c .\foo4.cpp
foo4.cpp
E:\tmp> nmake -f test.mak -a
Microsoft (R) Program Maintenance Utility Version 7.00.0000
Copyright (C) Microsoft Corp 1988-2001. All rights reserved.
 cl -nologo -Fd.\ -c .\foo1.cpp .\foo2.cpp .\foo3.cpp .\foo4.cpp
foo1.cpp
foo2.cpp
foo3.cpp
foo4.cpp
Generating Code...
Predefined rules
Rule Command Default action Batch rule Platform
.c.obj $(CC) $(CFLAGS) /c $< cl /c $< yes all
.cc.exe $(CC) $(CFLAGS) $< cl $< no all
.cc.obj $(CC) $(CFLAGS) /c $< cl /c $< yes all
.cpp.exe $(CPP) $(CPPFLAGS) $< cl $< no all
.cpp.obj $(CPP) $(CPPFLAGS) /c $< cl /c $< yes all
.cxx.exe $(CXX) $(CXXFLAGS) $< cl $< no all
.cxx.obj $(CXX) $(CXXFLAGS) /c $< cl /c $< yes all
.rc.res $(RC) $(RFLAGS) /r $< rc /r $< no all
NMAKE assumes an inferred dependent for a target if an applicable inference rule exists.
A rule applies if:
to_ext matches the target's extension.
from_ext matches the extension of a file that has the target's base name and that
exists in the current or specified directory.
from_ext is in .SUFFIXES; no other from_ext in a matching rule has a higher
.SUFFIXES priority.
No explicit dependent has a higher .SUFFIXES priority.
Inferred dependents can cause unexpected side effects. If the target's description block
contains commands, NMAKE executes those commands instead of the commands in the
rule.
If an inference rule is defined more than once, NMAKE uses the highest-precedence
definition. The following list shows the order of precedence from highest to lowest:
1. An inference rule defined in a makefile; later definitions have precedence.
2. An inference rule defined in Tools.ini ; later definitions have precedence.
Inferred dependents and rules
Precedence in inference rules
3. A predefined inference rule.
See also
NMAKE reference
Dot directives
Article • 09/30/2021
Specify dot directives outside a description block, at the start of a line. Dot directives
begin with a period ( . ) and are followed by a colon ( : ). Spaces and tabs are allowed.
Dot directive names are case-sensitive and must be uppercase.
Directive Purpose
.IGNORE
:
Ignores nonzero exit codes returned by commands, from the place it is specified to
the end of the makefile. By default, NMAKE halts if a command returns a nonzero exit
code. To restore error checking, use !CMDSWITCHES . To ignore the exit code for a single
command, use the dash ( - ) modifier. To ignore exit codes for an entire file, use /I .
.PRECIOUS
: targets
Preserves targets on disk if the commands to update them are halted; has no effect if
a command handles an interrupt by deleting the file. Separate the target names with
one or more spaces or tabs. By default, NMAKE deletes a target if a build is
interrupted by CTRL+C or CTRL+BREAK. Each use of .PRECIOUS applies to the entire
makefile; multiple specifications are cumulative.
.SILENT Suppresses display of executed commands, from the place it is specified to the end
of the makefile. By default, NMAKE displays the commands it invokes. To restore
echoing, use !CMDSWITCHES . To suppress echoing of a single command, use the @
modifier. To suppress echoing for an entire file, use /S .
.SUFFIXES
: list
Lists extensions for inference-rule matching; predefined to include the following
extensions: .exe .obj .asm .c .cpp .cxx .bas .cbl .for .pas .res .rc .f .f90
To change the .SUFFIXES list order or to specify a new list, clear the list and specify a
new setting. To clear the list, specify no extensions after the colon:
makefile
To add additional suffixes to the end of the list, specify
makefile
where suffix_list is a list of the additional suffixes, separated by one or more spaces or
tabs. To see the current setting of .SUFFIXES , run NMAKE with /P .
.SUFFIXES :
.SUFFIXES : suffix_list
See also
NMAKE Reference
Makefile preprocessing
Article • 02/17/2022
You can control the NMAKE session by using preprocessing directives and expressions.
Preprocessing instructions can be placed in the makefile or in Tools.ini . Using
directives, you can conditionally process your makefile, display error messages, include
other makefiles, undefine a macro, and turn certain options on or off.
Makefile Preprocessing Directives
Preprocessing directives aren't case-sensitive. The initial exclamation point ( ! ) must
appear at the beginning of the line. Zero or more spaces or tabs can appear after the
exclamation point, for indentation.
!CMDSWITCHES { + option | - option } ...
Turns each listed option on or off. Spaces or tabs must appear before the + or -
operator. No spaces can appear between the operator and the option letters.
Letters aren't case-sensitive and are specified without a slash ( / ). To turn on some
options and turn off others, use separate specifications of !CMDSWITCHES .
Only /D , /I , /N , and /S can be used in a makefile. In Tools.ini , all options are
allowed except /F , /HELP , /NOLOGO , /X , and /? . Changes specified in a description
block don't take effect until the next description block. This directive updates
MAKEFLAGS ; changes are inherited during recursion if MAKEFLAGS is specified.
!ERROR text
Displays text in error U1050, then halts NMAKE, even if /K , /I , .IGNORE ,
!CMDSWITCHES , or the dash ( - ) command modifier is used. Spaces or tabs before
text are ignored.
!MESSAGE text
Displays text to standard output. Spaces or tabs before text are ignored.
!INCLUDE [ < ] filename [ > ]
Reads filename as a makefile, then continues with the current makefile. NMAKE
searches for filename first in the specified or current directory, then recursively
through directories of any parent makefiles, then, if filename is enclosed by angle
brackets ( < > ), in directories specified by the INCLUDE macro, which is initially set
to the INCLUDE environment variable. Useful to pass .SUFFIXES settings, .PRECIOUS ,
and inference rules to recursive makefiles.
!IF constant_expression
Processes statements between !IF and the next !ELSE or !ENDIF if
constant_expression evaluates to a nonzero value.
!IFDEF macro_name
Processes statements between !IFDEF and the next !ELSE or !ENDIF if
macro_name is defined. A null macro is considered to be defined.
!IFNDEF macro_name
Processes statements between !IFNDEF and the next !ELSE or !ENDIF if
macro_name isn't defined.
!ELSE [ IF constant_expression | IFDEF macro_name | IFNDEF macro_name ]
Processes statements between !ELSE and the next !ENDIF if the prior !IF , !IFDEF ,
or !IFNDEF statement evaluated to zero. The optional keywords give further
control of preprocessing.
!ELSEIF
Synonym for !ELSE IF .
!ELSEIFDEF
Synonym for !ELSE IFDEF .
!ELSEIFNDEF
Synonym for !ELSE IFNDEF .
!ENDIF
Marks the end of an !IF , !IFDEF , or !IFNDEF block. Any text after !ENDIF on the
same line is ignored.
!UNDEF macro_name
Undefines macro_name.
The !IF or !ELSE IF constant_expression consists of integer constants (in decimal or C￾language notation), string constants, or commands. Use parentheses to group
expressions. Expressions use C-style signed long integer arithmetic; numbers are in 32-
bit two's-complement form in the range -2147483648 to 2147483647.
Expressions can use operators that act on constant values, exit codes from commands,
strings, macros, and file-system paths.
Makefile preprocessing expressions can use operators that act on constant values, exit
codes from commands, strings, macros, and file-system paths. To evaluate the
expression, the preprocessor first expands macros, and then executes commands, and
then does the operations. It evaluates operations in order of explicit grouping in
parentheses, and then in order of operator precedence. The result is a constant value.
The DEFINED operator is a logical operator that acts on a macro name. The expression
DEFINED( macro_name ) is true if macro_name is defined, even if it doesn't have an
assigned value. DEFINED in combination with !IF or !ELSE IF is equivalent to !IFDEF or
!ELSE IFDEF . However, unlike these directives, DEFINED can be used in complex
expressions.
The EXIST operator is a logical operator that acts on a file-system path. EXIST( path )
is true if path exists. The result from EXIST can be used in binary expressions. If path
contains spaces, enclose it in double quotation marks.
To compare two strings, use the equality ( == ) operator or the inequality ( != ) operator.
Enclose strings in double quotation marks.
Integer constants can use the unary operators for numerical negation ( - ), one's
complement ( ~ ), and logical negation ( ! ).
Expressions can use the following operators. The operators of equal precedence are
grouped together, and the groups are listed in decreasing order of precedence. Unary
operators associate with the operand to the right. Binary operators of equal precedence
associate operands from left to right.
Operator Description
Expressions in makefile preprocessing
Makefile preprocessing operators
Operator Description
DEFINED( macro_name ) Produces a logical value for the current definition state of
macro_name.
EXIST( path ) Produces a logical value for the existence of a file at path.
! Unary logical NOT.
~ Unary one's complement.
- Unary negation.
* Multiplication.
/ Division.
% Modulus (remainder).
+ Addition.
- Subtraction.
<< Bitwise shift left.
>> Bitwise shift right.
<= Less than or equal.
>= Greater than or equal.
< Less than.
> Greater than.
== Equality.
!= Inequality.
& Bitwise AND.
^ Bitwise XOR.
| Bitwise OR.
Operator Description
&& Logical AND.
|| Logical OR.
To use a command's exit code during preprocessing, specify the command, with any
arguments, within brackets ( [ ] ). Any macros are expanded before the command is
executed. NMAKE replaces the command specification with the command's exit code,
which can be used in an expression to control preprocessing.
Makefile
NMAKE Reference
７ Note
The bitwise XOR operator ( ^ ) is the same as the escape character, and must be
escaped (as ^^ ) when it's used in an expression.
Executing a program in preprocessing
Example
!IF [my_command.exe arg1 arg2] != 0
!MESSAGE my_command.exe failed!
!ENDIF
See also
LIB Reference
Article • 08/03/2021
The Microsoft Library Manager (LIB.exe) creates and manages a library of Common
Object File Format (COFF) object files. LIB can also be used to create export files and
import libraries to reference exported definitions.
７ Note
You can start this tool only from the Visual Studio command prompt. You cannot
start it from a system command prompt or from File Explorer.
Overview of LIB
How to: Set LIB.EXE Options in the Visual Studio Development Environment
Running LIB
Managing a Library
Extracting a Library Member
Working with Import Libraries and Export Files
See also
Additional MSVC Build Tools
Overview of LIB
Article • 08/03/2021
LIB (lib.exe) creates standard libraries, import libraries, and export files you can use with
LINK when building a program. LIB runs from a command prompt.
You can use LIB in the following modes:
Building or modifying a COFF library
Extracting a member object to a file
Creating an export file and an import library
These modes are mutually exclusive; you can use LIB in only one mode at a time.
The following table lists the options for lib.exe, with a link to more information.
Option Description
/DEF Create an import library and an export file.
For more information, see Building an Import Library and Export File.
/ERRORREPORT Deprecated. For more information, see Running LIB.
/EXPORT Exports a function from your program.
For more information, see Building an Import Library and Export File.
/EXTRACT Create an object (.obj) file that contains a copy of a member of an existing
library.
For more information, see Extracting a Library Member.
/INCLUDE Adds a symbol to the symbol table.
For more information, see Building an Import Library and Export File.
/LIBPATH Overrides the environment library path.
For more information, see Managing a Library.
LIB options
Option Description
/LINKREPRO Creates artifacts needed to reproduce a lib.exe crash or internal error.
For more information, see Running LIB.
/LINKREPROTARGET Only generates the /LINKREPRO artifacts when lib.exe is used with a
specified file.
For more information, see Running LIB.
/LIST Displays information about the output library to standard output.
For more information, see Managing a Library.
/LTCG Causes the library to be built using link-time code generation.
For more information, see Running LIB.
/MACHINE Specifies the target platform for the program.
For more information, see Running LIB.
/NAME When building an import library, specifies the name of the DLL for which
the import library is being built.
For more information, see Managing a Library.
/NODEFAULTLIB Removes one or more default libraries from the list of libraries it searches
when resolving external references.
For more information, see Managing a Library.
/NOLOGO Suppresses display of the LIB copyright message and version number and
prevents echoing of command files.
For more information, see Running LIB.
/OUT Overrides the default output filename.
For more information, see Managing a Library.
/REMOVE Omits an object from the output library.
For more information, see Managing a Library.
/SUBSYSTEM Tells the operating system how to run a program created by linking to the
output library.
For more information, see Managing a Library.
Option Description
/VERBOSE Displays details about the progress of the session, including names of the
.obj files being added.
For more information, see Running LIB.
/WX Treat warnings as errors.
For more information, see Running LIB.
LIB Reference
LIB Input Files
LIB Output Files
Other LIB Output
Structure of a Library
See also
How to: Set LIB.EXE Options in the
Visual Studio Development Environment
Article • 08/03/2021
To set LIB.EXE options in the Visual Studio development
environment
1. Access the project's Property Page dialog box.
2. With a static library project active, select the Librarian node.
3. Select either the General or Input/Output property page.
4. Modify properties as needed.
See also
LIB Reference
LIB Input Files
Article • 08/03/2021
The input files expected by LIB depend on the mode in which it is being used, as shown
in the following table.
Mode Input
Default (building or modifying
a library)
COFF object (.obj) files, COFF libraries (.lib), 32-bit Object Model
Format (OMF) object (.obj) files
Extracting a member with
/EXTRACT
COFF library (.lib)
Building an export file and
import library with /DEF
Module-definition (.def) file, COFF object (.obj) files, COFF
libraries (.lib), 32-bit OMF object (.obj) files
Overview of LIB
７ Note
OMF libraries created by the 16-bit version of LIB cannot be used as input to the
32-bit version of LIB.
See also
LIB Output Files
Article • 08/03/2021
The output files produced by LIB depend on the mode in which it is being used, as
shown in the following table.
Mode Output
Default (building or modifying a library) COFF library (.lib)
Extracting a member with /EXTRACT Object (.obj) file
Building an export file and import library with /DEF Import library (.lib) and export (.exp) file
Overview of LIB
See also
Other LIB Output
Article • 08/03/2021
In the default mode, you can use the /LIST option to display information about the
resulting library. You can redirect this output to a file.
LIB displays a copyright and version message and echoes command files unless the
/NOLOGO option is used.
When you type lib with no other input, LIB displays a usage statement that summarizes
its options.
Error and warning messages issued by LIB have the form LNKnnnn. The LINK, DUMPBIN,
and EDITBIN tools also use this range of errors. Help is available by selecting the error in
the Output window and pressing F1.
See also
Overview of LIB
Structure of a Library
Article • 08/03/2021
A library contains COFF objects. Objects in a library contain functions and data that can
be referenced externally by other objects in a program. An object in a library is
sometimes referred to as a library member.
You can get additional information about the contents of a library by running the
DUMPBIN tool with the /LINKERMEMBER option. For more information about this
option, see DUMPBIN Reference.
See also
Overview of LIB
Running LIB
Article • 02/17/2022
Various command-line options can be used to control LIB.
LIB Command Line
To run LIB, type the command lib , followed by the options and file names for the task
you're using LIB for. LIB also accepts command-line input in command files, which are
described in the following section. LIB doesn't use an environment variable.
LIB Command Files
You can pass command-line arguments to LIB in a command file using the following
syntax:
LIB @command-file
The file command-file is a text file. No spaces or tabs are allowed between the at sign
(@) and the file name. The command-file name has no default extension. Specify the full
file name, including any extension. Wildcards can't be used. You may specify an absolute
or relative path with the file name.
In the command file, arguments can be separated by spaces or tabs, as they can on the
command line. Arguments can also be separated by newline characters. Use a semicolon
(;) to mark a comment. LIB ignores all text from the semicolon to the end of the line.
You can specify either all or part of the command line in a command file, and you may
use more than one command file in a LIB command. LIB accepts the command-file input
as if it's specified in that location on the command line. Command files can't be nested.
LIB echoes the contents of command files unless the /NOLOGO option is used.
Using LIB Options
An option consists of an option specifier, which is either a dash (-) or a forward slash (/),
followed by the name of the option. Option names can't be abbreviated. Some options
take an argument, specified after a colon (:). No spaces or tabs are allowed within an
option specification. Use one or more spaces or tabs to separate option specifications
on the command line. Option names and their keyword or file name arguments aren't
case-sensitive, but identifiers used as arguments are case-sensitive. LIB processes
options in the order specified on the command line and in command files. If an option is
repeated with different arguments, the last one to be processed takes precedence.
The following options apply to all modes of LIB:
/ERRORREPORT [NONE | PROMPT | QUEUE | SEND]
The /ERRORREPORT option is deprecated. Starting in Windows Vista, error reporting is
controlled by Windows Error Reporting (WER) settings.
/LINKREPRO:directory-path
/LINKREPROTARGET:filename
To help Microsoft diagnose lib.exe crashes and internal errors, you can use the
/LINKREPRO option. This option generates a link repro, a set of build artifacts that allow
Microsoft to reproduce a problem that occurs during library operations. The
/LINKREPROTARGET option can be used with the /LINKREPRO option. It only generates
link repro artifacts when lib.exe produces the specified file. For more information, see
How to report a problem with the Microsoft C++ toolset.
/LTCG
"LTCG" stands for link-time code generation. This feature requires cooperation between
the compiler (cl.exe), LIB, and the linker (LINK). Together they can optimize code beyond
what any component can do by itself.
The /LTCG option to LIB specifies that the inputs from cl.exe include object files
generated by using the /GL compiler option. If LIB encounters such inputs, and /LTCG
isn't specified, it restarts with /LTCG enabled after displaying an informational message.
In other words, it isn't necessary to set this option explicitly, but it speeds up build
performance. That's because LIB doesn't have to restart itself.
In the build process, the output from LIB is sent to LINK. LINK has its own separate
/LTCG option. It's used to perform various optimizations, including whole-program
optimization and profile-guided optimization (PGO) instrumentation. For more
information about the LINK option, see /LTCG.
/MACHINE
Specifies the target platform for the program. Usually, you don't need to specify
/MACHINE. LIB infers the machine type from the .obj files. However, in some
circumstances, LIB can't determine the machine type and issues an error message. If
such an error occurs, specify /MACHINE. In /EXTRACT mode, this option is for
verification only. Use lib /? at the command line to see available machine types.
/NOLOGO
Suppresses display of the LIB copyright message and version number and prevents
echoing of command files.
/VERBOSE
Displays details about the progress of the session, including names of the .obj files
being added. The information is sent to standard output and can be redirected to a file.
/WX[:NO]
Treat warnings as errors. For more information, see /WX (Treat Linker Warnings as
Errors).
Other options apply only to specific modes of LIB. These options are discussed in the
sections describing each mode.
See also
LIB Reference
Managing a Library
Article • 03/03/2022
The default mode for LIB is to build or modify a library of COFF objects. LIB runs in this
mode when you don't specify /EXTRACT (to copy an object to a file) or /DEF (to build an
import library).
To build a library from objects and/or libraries, use the following syntax:
LIB [ options... ] files...
This command creates a library from one or more input files, files . The files can be
COFF object files, 32-bit OMF object files, or existing COFF libraries. LIB creates one
library that contains all objects in the specified files. If an input file is a 32-bit OMF
object file, LIB converts it to COFF before building the library. LIB can't accept a 32-bit
OMF object that's in a library created by the 16-bit version of LIB. You must first use the
16-bit LIB to extract the object; then you can use the extracted object file as input to the
32-bit LIB.
By default, LIB names the output file using the base name of the first object or library file
and the extension .lib . The output file is put in the current directory. If a file already
exists with the same name, the output file replaces the existing file. To preserve an
existing library, use the /OUT option to specify a name for the output file.
The following options apply to building and modifying a library:
/LIBPATH: dir
Overrides the environment library path and sets it to dir . For details, see the
description of the LINK /LIBPATH option.
/LIST
Displays information about the output library to standard output. The output can be
redirected to a file. You can use /LIST to determine the contents of an existing library
without modifying it.
/NAME: filename
When building an import library, filename specifies the name of the DLL for which the
import library is being built.
/NODEFAULTLIB
Removes one or more default libraries from the list of libraries it searches when
resolving external references. For more information, see /NODEFAULTLIB.
/OUT: filename
Overrides the default output filename and replaces it with filename . By default, the
output library is created in the current directory, with the base name of the first library
or object file on the command line and the extension .lib .
/REMOVE: object
Omits the specified object from the output library. LIB creates an output library by
combining all objects (whether in object files or libraries), and then deleting any objects
specified with /REMOVE .
/SUBSYSTEM: { CONSOLE | EFI_APPLICATION | EFI_BOOT_SERVICE_DRIVER | EFI_ROM |
EFI_RUNTIME_DRIVER | NATIVE | POSIX | WINDOWS | WINDOWSCE }[,#[.##]]
Tells the operating system how to run a program created by linking to the output library.
For more information, see the description of the LINK /SUBSYSTEM option.
LIB options specified on the command line aren't case sensitive.
You can use LIB to perform the following library-management tasks:
To add objects to a library, specify the file name for the existing library and the
filenames for the new objects.
To combine libraries, specify the library file names. You can add objects and
combine libraries with a single LIB command.
To replace a library member with a new object, specify the library containing the
member object to be replaced and the file name for the new object (or the library
that contains it). When an object that has the same name exists in more than one
input file, LIB puts the last object specified in the LIB command into the output
library. When you replace a library member, be sure to specify the new object or
library after the library that contains the old object.
To delete a member from a library, use the /REMOVE option. LIB processes any
specifications of /REMOVE after combining all input objects, regardless of
command-line order.
７ Note
You can't both delete a member and extract it to a file in the same step. You must
first extract the member object using /EXTRACT , then run LIB again using /REMOVE .
This behavior differs from that of the 16-bit LIB (for OMF libraries) provided in
other Microsoft products.
See also
LIB Reference
Extracting a Library Member
Article • 08/03/2021
You can use LIB to create an object (.obj) file that contains a copy of a member of an
existing library. To extract a copy of a member, use the following syntax:
LIB library /EXTRACT:member /OUT:objectfile
This command creates an .obj file called objectfile that contains a copy of a member of a
library. The member name is case sensitive. You can extract only one member in a single
command. The /OUT option is required; there is no default output name. If a file called
objectfile already exists in the specified directory (or the current directory, if no directory
is specified with objectfile), the extracted objectfile replaces the existing file.
See also
LIB Reference
Working with Import Libraries and
Export Files
Article • 08/03/2021
You can use LIB with the /DEF option to create an import library and an export file. LINK
uses the export file to build a program that contains exports (usually a dynamic-link
library (DLL)), and it uses the import library to resolve references to those exports in
other programs.
Note that if you create your import library in a preliminary step, before creating your .dll,
you must pass the same set of object files when building the .dll, as you passed when
building the import library.
In most situations, you do not need to use LIB to create your import library. When you
link a program (either an executable file or a DLL) that contains exports, LINK
automatically creates an import library that describes the exports. Later, when you link a
program that references those exports, you specify the import library.
However, when a DLL exports to a program that it also imports from, whether directly or
indirectly, you must use LIB to create one of the import libraries. When LIB creates an
import library, it also creates an export file. You must use the export file when linking
one of the DLLs.
See also
LIB Reference
Building an Import Library and Export
File
Article • 08/03/2021
To build an import library and export file, use the following syntax:
LIB /DEF[:deffile] [options] [objfiles] [libraries]
When /DEF is specified, LIB creates the output files from export specifications that are
passed in the LIB command. There are three methods for specifying exports, listed in
recommended order of use:
1. A __declspec(dllexport) definition in one of the objfiles or libraries
2. A specification of /EXPORT:name on the LIB command line
3. A definition in an EXPORTS statement in a deffile
These are the same methods you use to specify exports when linking an exporting
program. A program can use more than one method. You can specify parts of the LIB
command (such as multiple objfiles or /EXPORT specifications) in a command file in the
LIB command, just as you can in a LINK command.
The following options apply to building an import library and export file:
/OUT: import
Overrides the default output file name for the import library being created. When /OUT
is not specified, the default name is the base name of the first object file or library in the
LIB command and the extension .lib. The export file is given the same base name as the
import library and the extension .exp.
/EXPORT: entryname[= internalname][,@ordinal[, NONAME]][, DATA]
Exports a function from your program to allow other programs to call the function. You
can also export data (using the DATA keyword). Exports are usually defined in a DLL.
The entryname is the name of the function or data item as it is to be used by the calling
program. Optionally, you can specify the internalname as the function known in the
defining program; by default, internalname is the same as entryname. The ordinal
specifies an index into the export table in the range 1 through 65,535; if you do not
specify ordinal, LIB assigns one. The NONAME keyword exports the function only as an
ordinal, without an entryname. The DATA keyword is used to export data-only objects.
/INCLUDE: symbol
Adds the specified symbol to the symbol table. This option is useful for forcing the use
of a library object that otherwise would not be included.
Note that if you create your import library in a preliminary step, before creating your .dll,
you must pass the same set of object files when building the .dll, as you passed when
building the import library.
See also
Working with Import Libraries and Export Files
Using an Import Library and Export File
Article • 08/03/2021
When a program (either an executable file or a DLL) exports to another program that it
also imports from, or if more than two programs both export to and import from each
other, the commands to link these programs must accommodate circular exports.
In a situation without circular exports, when linking a program that uses exports from
another program, you must specify the import library for the exporting program. The
import library for the exporting program is created when you link that exporting
program. Therefore, you must link the exporting program before the importing
program. For example, if TWO.dll imports from ONE.dll, you must first link ONE.dll and
get the import library ONE.lib. Then, you specify ONE.lib when linking TWO.dll. When
the linker creates TWO.dll, it also creates its import library, TWO.lib. Use TWO.lib when
linking programs that import from TWO.dll.
However, in a circular export situation, it is not possible to link all of the interdependent
programs using import libraries from the other programs. In the example discussed
earlier, if TWO.dll also exports to ONE.dll, the import library for TWO.dll won't exist yet
when ONE.dll is linked. When circular exports exist, you must use LIB to create an import
library and export file for one of the programs.
To begin, choose one of the programs on which to run LIB. In the LIB command, list all
objects and libraries for the program and specify /DEF. If the program uses a .def file or
/EXPORT specifications, specify these as well.
After you create the import library (.lib) and the export file (.exp) for the program, you
use the import library when linking the other program or programs. LINK creates an
import library for each exporting program it builds. For example, if you run LIB on the
objects and exports for ONE.dll, you create ONE.lib and ONE.exp. You can now use
ONE.lib when linking TWO.dll; this step also creates the import library TWO.lib.
Finally, link the program you began with. In the LINK command, specify the objects and
libraries for the program, the .exp file that LIB created for the program, and the import
library or libraries for the exports used by the program. To continue the example, the
LINK command for ONE.dll contains ONE.exp and TWO.lib, as well as the objects and
libraries that go into ONE.dll. Do not specify the .def file or /EXPORT specifications in the
LINK command; these are not needed, because the export definitions are contained in
the .exp file. When you link using an .exp file, LINK does not create an import library,
because it assumes that one was created when the .exp file was created.
See also
Working with Import Libraries and Export Files
EDITBIN Reference
Article • 08/03/2021
The Microsoft COFF Binary File Editor (EDITBIN.EXE) modifies Common Object File
Format (COFF) binary files. You can use EDITBIN to modify object files, executable files,
and dynamic-link libraries (DLL).
７ Note
You can start this tool only from the Visual Studio command prompt. You cannot
start it from a system command prompt or from File Explorer.
EDITBIN is not available for use on files produced with the /GL compiler option. Any
modifications to binary files produced with /GL will have to be achieved by recompiling
and linking.
EDITBIN command line
EDITBIN options
See also
Additional MSVC Build Tools
EDITBIN Command Line
Article • 08/03/2021
To run EDITBIN, use the following syntax:
EDITBIN [options] files...
Specify one or more files for the objects or images to be changed, and one or more
options for changing the files.
When you type the command editbin without any other command-line input, EDITBIN
displays a usage statement that summarizes its options.
See also
Additional MSVC Build Tools
EDITBIN Reference
EDITBIN Options
Article • 08/03/2021
You can use EDITBIN to modify object files, executable files, and dynamic-link libraries
(DLLs). Options specify the changes that EDITBIN makes.
An option consists of an option specifier, which is either a dash ( - ) or a forward slash
( / ), followed by the name of the option. Option names can't be abbreviated. Some
options take arguments that are specified after a colon ( : ). No spaces or tabs are
allowed within an option specification. Use one or more spaces or tabs to separate
option specifications on the command line. Option names and their keyword arguments
or file name arguments aren't case-sensitive. For example, -bind and /BIND mean the
same thing.
EDITBIN has the following options:
Option Purpose
/ALLOWBIND Specifies whether a DLL can be bound.
/ALLOWISOLATION Specifies DLL or executable file manifest lookup behavior.
/APPCONTAINER Specifies whether the app must run within an AppContainer—for
example, a UWP app.
/BIND Sets the addresses for the entry points in the specified objects to
speed load time.
/DYNAMICBASE Specifies whether the DLL or executable image can be randomly
rebased at load-time by using address space layout randomization
(ASLR).
/ERRORREPORT Deprecated. Error reporting is controlled by Windows Error Reporting
(WER) settings.
/HEAP Sets the size of the executable image's heap in bytes.
/HIGHENTROPYVA Specifies whether the DLL or executable image supports high entropy
(64-bit) address space layout randomization (ASLR).
/INTEGRITYCHECK Specifies whether to check the digital signature at load time.
/LARGEADDRESSAWARE Specifies whether the object supports addresses that are larger than
two gigabytes.
/NOLOGO Suppresses the EDITBIN startup banner.
Option Purpose
/NXCOMPAT Specifies whether the executable image is compatible with Windows
Data Execution Prevention.
/REBASE Sets the base addresses for the specified objects.
/RELEASE Sets the checksum in the header.
/SECTION Overrides the attributes of a section.
/STACK Sets the size of the executable image's stack in bytes.
/SUBSYSTEM Specifies the execution environment.
/SWAPRUN Specifies that the executable image is copied to the swap file, and then
run from there.
/TSAWARE Specifies that the app is designed to run in a multi-user environment.
/VERSION Sets the version number in the header.
Additional MSVC build tools
EDITBIN Reference
See also
/ALLOWISOLATION
Article • 11/07/2022
Specifies behavior for manifest lookup.
Syntax
/ALLOWISOLATION[:NO]
Remarks
/ALLOWISOLATION causes the operating system to do manifest lookups and loads.
/ALLOWISOLATION is the default.
/ALLOWISOLATION:NO indicates that executables are loaded as if there were no
manifest, and causes EDITBIN Reference to set the
IMAGE_DLLCHARACTERISTICS_NO_ISOLATION bit in the optional header's DllCharacteristics
field.
When isolation is disabled for an executable, the Windows loader doesn't try to find an
application manifest for the newly created process. The new process doesn't have a
default activation context, even if there is a manifest in the executable itself or if there is
a manifest that has the name executable-name.exe.manifest.
See also
EDITBIN Options
/ALLOWISOLATION (Manifest Lookup)
Manifest Files Reference
/ALLOWBIND
Article • 11/07/2022
Specifies whether a DLL can be bound.
/ALLOWBIND[:NO]
Remarks
The /ALLOWBIND option sets a bit in a DLL's header that indicates to Bind.exe that the
image is allowed to be bound. Binding can allow an image to load faster when the
loader doesn't have to rebase and perform address fixup for each referenced DLL. You
may not want a DLL to be bound if it has been digitally signed—binding invalidates the
signature. Binding has no effect if address space layout randomization (ASLR) is enabled
for the image by using /DYNAMICBASE on versions of Windows that support ASLR.
Use /ALLOWBIND:NO to prevent Bind.exe from binding the DLL.
For more information, see the /ALLOWBIND linker option.
See also
EDITBIN Options
/APPCONTAINER
Article • 11/07/2022
Marks an executable that must run in an app container—for example, a Microsoft Store
or Universal Windows app.
/APPCONTAINER[:NO]
Remarks
An executable that has the /APPCONTAINER option set can only be run in an app
container, which is the process-isolation environment introduced in Windows 8. For
Microsoft Store and Universal Windows apps, this option must be set.
See also
EDITBIN Options
What's a Universal Windows App?
/BIND
Article • 08/03/2021
/BIND[:PATH=path]
Remarks
This option sets the addresses of the entry points in the import address table for an
executable file or DLL. Use this option to reduce load time of a program.
Specify the program's executable file and DLLs in the files argument on the EDITBIN
command line. The optional path argument to /BIND specifies the location of the DLLs
used by the specified files. Separate multiple directories with a semicolon (;). If path is
not specified, EDITBIN searches the directories specified in the PATH environment
variable. If path is specified, EDITBIN ignores the PATH variable.
By default, the program loader sets the addresses of entry points when it loads a
program. The amount of time this process takes varies, depending on the number of
DLLs and the number of entry points referenced in the program. If a program has been
modified with /BIND, and if the base addresses for the executable file and its DLLs do
not conflict with DLLs that are already loaded, the operating system does not need to
set these addresses. In a situation where the files are incorrectly based, the operating
system relocates the program's DLLs and recalculates the entry-point addresses, which
adds to the program's load time.
See also
EDITBIN Options
/DYNAMICBASE
Article • 05/06/2022
Specifies whether to generate an executable image that can be randomly rebased at
load time by using the address space layout randomization (ASLR) feature of Windows
that was first available in Windows Vista.
Syntax
/DYNAMICBASE [ :NO ]
Remarks
The /DYNAMICBASE option modifies the header of an executable image, a .dll or .exe file,
to indicate whether the application should be randomly rebased at load time, and
enables virtual address allocation randomization, which affects the virtual memory
location of heaps, stacks, and other operating system allocations. The /DYNAMICBASE
option applies to both 32-bit and 64-bit images. ASLR is supported on Windows Vista
and later operating systems. The option is ignored by earlier operating systems.
By default, /DYNAMICBASE is enabled. To disable this option, use /DYNAMICBASE:NO . The
/DYNAMICBASE option is required for the /HIGHENTROPYVA option to have an effect.
Because ASLR can't be disabled on ARM, ARM64, or ARM64EC architectures,
/DYNAMICBASE:NO isn't supported for these targets.
See also
EDITBIN Options
Windows ISV Software Security Defenses
/ERRORREPORT (editbin.exe)
Article • 08/03/2021
７ Note
The /ERRORREPORT option is deprecated. Starting in Windows Vista, error
reporting is controlled by Windows Error Reporting (WER) settings.
Syntax
/ERRORREPORT [ NONE | PROMPT | QUEUE | SEND ]
Remarks
The /ERRORREPORT arguments are overridden by the Windows Error Reporting service
settings. EDITBIN automatically sends reports of internal errors to Microsoft, if reporting
is enabled by Windows Error Reporting. No report is sent if disabled by Windows Error
Reporting.
See also
EDITBIN Options
/HEAP
Article • 08/03/2021
Sets the size of the heap in bytes. This option only applies to executable files.
Syntax
/HEAP: reserve [ , commit ]
Remarks
The reserve argument specifies the total initial heap allocation in virtual memory. The
/HEAP linker or EDITBIN option rounds up the specified value to the nearest multiple of
4 bytes. By default, the heap size is 1 MB.
The optional commit argument is subject to interpretation by the operating system. On a
Windows operating system, it specifies the initial amount of physical memory to
allocate. It also specifies how much more memory to allocate when the heap is
expanded. Committed virtual memory causes space to be reserved in the paging file. A
higher commit value allows the system to allocate memory less often when the app
needs more heap space but increases the memory requirements and possibly the app
startup duration. The commit value must be less than or equal to the reserve value. The
default value is 4 KB.
Specify the reserve and commit values in decimal, C-language hexadecimal, or octal
notation. For example, a value of 1 MB can be specified as 1048576 in decimal, or as
0x100000 in hexadecimal, or as 04000000 in octal. The default values are equivalent to
the option /HEAP:1048576,4096 .
Example
This example link command creates an executable main.exe that has heap reserve of 2
MB. The initial heap and later heap expansions come in blocks of 64 KB:
link /heap:0x200000,0x10000 main.obj
To set this linker option in Visual Studio
1. Open the project Property Pages dialog box. For more information, see Set C++
compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > System property page.
3. Set the Heap Reserve Size and Heap Commit Size properties, then choose OK or
Apply to save your changes.
See also
EDITBIN options
MSVC linker options
/HIGHENTROPYVA
Article • 08/03/2021
Specifies whether the executable image supports high-entropy 64-bit address space
layout randomization (ASLR).
Syntax
/HIGHENTROPYVA [ :NO ]
Remarks
This option modifies the header of an executable image file (for example, a .dll or .exe
file), to indicate support for 64-bit address ASLR. To have an effect, set the option on
both the executable and all modules that it depends on. Then operating systems that
support 64-bit ASLR can rebase the executable image's segments at load time by using
randomized 64-bit virtual addresses. This large address space makes it more difficult for
an attacker to guess the location of a particular memory region.
By default, the linker enables /HIGHENTROPYVA for 64-bit executable images. This option
requires both /DYNAMICBASE and /LARGEADDRESSAWARE, which are also enabled by
default for 64-bit images. /HIGHENTROPYVA isn't applicable to 32-bit executable images,
where the option is ignored. To explicitly disable this option, use /HIGHENTROPYVA:NO .
See also
EDITBIN Options
/DYNAMICBASE
/LARGEADDRESSAWARE
Windows ISV Software Security Defenses
/INTEGRITYCHECK
Article • 08/03/2021
Specifies that the digital signature of the binary image must be checked at load time.
/INTEGRITYCHECK[:NO]
Remarks
In the header of the DLL file or executable file, this option sets a flag that requires a
digital signature check by the memory manager to load the image in Windows. Versions
of Windows prior to Windows Vista ignore this flag. This option must be set for 64-bit
DLLs that implement kernel-mode code, and is recommended for all device drivers. For
more information, see Kernel-Mode Code Signing Requirements.
See also
EDITBIN Options
/LARGEADDRESSAWARE
Article • 08/03/2021
/LARGEADDRESSAWARE
Remarks
This option edits the image to indicate that the application can handle addresses larger
than 2 gigabytes.
See also
EDITBIN Options
/NOLOGO (EDITBIN)
Article • 08/03/2021
/NOLOGO
Remarks
This option suppresses display of the EDITBIN copyright message and version number.
See also
EDITBIN Options
/NXCOMPAT
Article • 08/03/2021
/NXCOMPAT[:NO]
Remarks
Indicates that an executable was tested to be compatible with the Windows Data
Execution Prevention feature.
For more information, see /NXCOMPAT (Compatible with Data Execution Prevention).
See also
EDITBIN Options
/REBASE
Article • 08/03/2021
This option sets the base addresses for the specified files. EDITBIN assigns new base
addresses in a contiguous address space according to the size of each file rounded up
to the nearest 64 KB. For details about base addresses, see the Base Address (/BASE)
linker option.
Specify the program's executable files and DLLs in the files argument on the EDITBIN
command line in the order in which they are to be based. You can optionally specify one
or more modifiers, each separated by a comma (,):
Modifier Action
BASE=address Provides a beginning address for reassigning base addresses to the files. Specify
address in decimal or C-language notation. If BASE is not specified, the default
starting base address is 0x400000. If DOWN is used, BASE must be specified, and
address sets the end of the range of base addresses.
BASEFILE Creates a file named COFFBASE.TXT, which is a text file in the format expected by
LINK's /BASE option.
DOWN Tells EDITBIN to reassign base addresses downward from an ending address. The
files are reassigned in the order specified, with the first file located in the highest
possible address below the end of the address range. BASE must be used with
DOWN to ensure sufficient address space for basing the files. To determine the
address space needed by the specified files, run EDITBIN with /REBASE on the
files and add 64 KB to the displayed total size.
EDITBIN Options
/REBASE[:modifiers]
Remarks
See also
/RELEASE
Article • 08/03/2021
/RELEASE
Remarks
This option sets the checksum in the header of an executable file.
The operating system requires the checksum for device drivers. It is recommended that
you set the checksum for release versions of your device drivers to ensure compatibility
with future operating systems.
See also
EDITBIN Options
/SECTION (EDITBIN)
Article • 08/03/2021
This option changes the attributes of a section, overriding the attributes that were set
when the object file for the section was compiled or linked.
After the colon ( : ), specify the name of the section. To change the section name, follow
name with an equal sign (=) and a newname for the section.
To set or change the section's attributes , specify a comma (,) followed by one or more
attributes characters. To negate an attribute, precede its character with an exclamation
point (!). The following characters specify memory attributes:
Attribute Setting
c code
d discardable
e executable
i initialized data
k cached virtual memory
m link remove
o link info
p paged virtual memory
r read
s shared
u uninitialized data
w write
/SECTION:name[=newname][,attributes][alignment]
Remarks
To control alignment, specify the character A followed by one of the following characters
to set the size of alignment in bytes, as follows:
Character Alignment size in bytes
1 1
2 2
4 4
8 8
p 16
t 32
s 64
x no alignment
Specify the attributes and alignment characters as a string with no white space. The
characters are not case sensitive.
EDITBIN Options
See also
/STACK
Article • 08/03/2021
/STACK:reserve[,commit]
Remarks
This option sets the size of the stack in bytes and takes arguments in decimal or C￾language notation. The /STACK option applies only to an executable file.
The reserve argument specifies the total stack allocation in virtual memory. EDITBIN
rounds up the specified value to the nearest 4 bytes.
The optional commit argument is subject to interpretation by the operating system. In
Windows NT, Windows 95, and Windows 98, commit specifies the amount of physical
memory to allocate at a time. Committed virtual memory causes space to be reserved in
the paging file. A higher commit value saves time when the application needs more stack
space but increases the memory requirements and possibly startup time.
See also
EDITBIN Options
/SUBSYSTEM
Article • 08/03/2021
Specifies the execution environment that's required by the executable image.
/SUBSYSTEM:{BOOT_APPLICATION|CONSOLE|EFI_APPLICATION|
 EFI_BOOT_SERVICE_DRIVER|EFI_ROM|EFI_RUNTIME_DRIVER|
 NATIVE|POSIX|WINDOWS|WINDOWSCE}[,major[.minor]]
Remarks
This option edits the image to indicate which subsystem the operating system must
invoke for execution.
You can specify any of the following subsystems:
BOOT_APPLICATION
An application that runs in the Windows boot environment. For more information about
boot applications, see About the BCD WMI Provider.
CONSOLE
A Windows character-mode application. The operating system provides a console for
console applications.
EFI_APPLICATION
EFI_BOOT_SERVICE_DRIVER
EFI_ROM
EFI_RUNTIME_DRIVER
Extensible Firmware Interface (EFI) Image
The EFI subsystem options describe executable images that run in the Extensible
Firmware Interface environment. This environment is typically provided with the
hardware and executes before the operating system is loaded. The major differences
between EFI image types are the memory location that the image is loaded into and the
action that's taken when the call to the image returns. An EFI_APPLICATION image is
unloaded when control returns. An EFI_BOOT_SERVICE_DRIVER or EFI_RUNTIME_DRIVER
is unloaded only if control returns with an error code. An EFI_ROM image is executed
from ROM. For more information, see the specifications on the Unified EFI Forum
website.
NATIVE
Code that runs without a subsystem environment—for example, kernel mode device
drivers and native system processes. This option is usually reserved for Windows system
features.
POSIX
An app that runs in the POSIX subsystem in Windows.
WINDOWS
An app that runs in the Windows graphical environment. This includes both desktop
apps and Universal Windows Platform (UWP) apps.
WINDOWSCE
The WINDOWSCE subsystem indicates that the app is intended to run on a device that
has a version of the Windows CE kernel. Versions of the kernel include PocketPC,
Windows Mobile, Windows Phone 7, Windows CE V1.0-6.0R3, and Windows Embedded
Compact 7.
The optional major and minor values specify the minimum required version of the
specified subsystem:
The whole number part of the version number—the portion to the left of the
decimal point—is represented by major .
The fractional part of the version number—the portion to the right of the decimal
point—is represented by minor .
The values of major and minor must be from 0 through 65,535.
The choice of subsystem affects the default starting address for the program. For more
information, see /ENTRY (Entry-Point Symbol), the linker /ENTRY:function option.
For more information, including the minimum and default values for the major and
minor version numbers for each subsystem, see the /SUBSYSTEM linker option.
See also
EDITBIN Options
/SWAPRUN
Article • 08/03/2021
/SWAPRUN:{[!]NET|[!]CD}
Remarks
This option edits the image to tell the operating system to copy the image to a swap file
and run it from there. Use this option for images that reside on networks or removable
media.
You can add or remove the NET or CD qualifiers:
NET indicates that the image resides on a network.
CD indicates that the image resides on a CD-ROM or similar removable medium.
Use !NET and !CD to reverse the effects of NET and CD.
See also
EDITBIN Options
/TSAWARE
Article • 08/03/2021
/TSAWARE[:NO]
Remarks
The /TSAWARE option to the EDITBIN utility allows you to modify a program image the
same way as if you had used the /TSAWARE linker option.
See also
EDITBIN Options
/VERSION
Article • 08/03/2021
/VERSION:left[,right]
Remarks
This option places a version number into the header of the image.
The whole number part of the version number, the portion to the left of the decimal
point, is represented by left . The fractional part of the version number, the portion to
the right of the decimal point, is represented by right .
See also
EDITBIN Options
DUMPBIN Reference
Article • 08/10/2021
The Microsoft COFF Binary File Dumper (DUMPBIN.EXE) displays information about
Common Object File Format (COFF) binary files. You can use DUMPBIN to examine COFF
object files, standard libraries of COFF objects, executable files, and dynamic-link
libraries (DLLs).
７ Note
We recommend you run DUMPBIN from the Visual Studio command prompt. You
can't start it from a system command prompt unless you set the environment
correctly. For more information, see Use the Microsoft C++ toolset from the
command line.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
DUMPBIN command line
DUMPBIN options
See also
Additional MSVC Build Tools
DUMPBIN Command Line
Article • 08/03/2021
To run DUMPBIN, use the following syntax:
DUMPBIN [options] files...
Specify one or more binary files, along with any options required to control the
information. DUMPBIN displays the information to standard output. You can either
redirect it to a file or use the /OUT option to specify a file name for the output.
When you run DUMPBIN on a file without specifying an option, DUMPBIN displays the
/SUMMARY output.
When you type the command dumpbin without any other command-line input,
DUMPBIN displays a usage statement that summarizes its options.
See also
Additional MSVC Build Tools
DUMPBIN Reference
DUMPBIN options
Article • 08/03/2021
An option consists of an option specifier, which is either a dash ( - ) or a forward slash
( / ), followed by the name of the option. Option names can't be abbreviated. Some
options take arguments, specified after a colon ( : ). No spaces or tabs are allowed
within an option specification. Use one or more spaces or tabs to separate option
specifications on the command line. Option names and their keyword or file name
arguments aren't case-sensitive. Most options apply to all binary files, but a few apply
only to certain types of files. By default, DUMPBIN sends information to standard
output. Use the /OUT option to send output to a file.
Options list
DUMPBIN has the following options:
/ALL
/ARCHIVEMEMBERS
/CLRHEADER
/DEPENDENTS
/DIRECTIVES
/DISASM[:{BYTES|NOBYTES}]
/ERRORREPORT:{NONE|PROMPT|QUEUE|SEND} (Deprecated)
/EXPORTS
/FPO
/HEADERS
/IMPORTS[:filename]
/LINENUMBERS
/LINKERMEMBER[:{1|2}]
/LOADCONFIG
/NOPDB
/OUT:filename
/PDATA
/PDBPATH[:VERBOSE]
/RANGEE:vaMin[,vaMax]
/RAWDATA[:{NONE|1|2|4|8}[,#]]
/RELOCATIONS
/SECTION:name
/SUMMARY
/SYMBOLS
/TLS
To list the options supported by DUMPBIN on the command line, use the /? option.
See also
Additional MSVC build tools
DUMPBIN command line
DUMPBIN reference
/ALL
Article • 08/03/2021
/ALL
Remarks
This option displays all available information except code disassembly. Use /DISASM to
display disassembly. You can use /RAWDATA:NONE with /ALL to omit the raw binary
details of the file.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/ARCHIVEMEMBERS
Article • 08/03/2021
/ARCHIVEMEMBERS
Remarks
This option displays minimal information about member objects in a library.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/CLRHEADER
Article • 08/03/2021
Display CLR-specific information.
Syntax
/CLRHEADER file
Arguments
file
An image file built with /clr.
Remarks
/CLRHEADER displays information about the .NET headers used in any managed
program. The output shows the location and size, in bytes, of the .NET header and
sections in the header.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
When /CLRHEADER is used on a file that was compiled with /clr, there will be a clr
Header: section in the dumpbin output. The value of flags indicates which /clr option
was used:
0 -- /clr (image may contain native code).
You can also programmatically check if an image was built for the common language
runtime. For more information, see How to: Determine if an Image is Native or CLR.
The /clr:pure and /clr:safe compiler options are deprecated in Visual Studio 2015 and
unsupported in Visual Studio 2017 and later. Code that must be "pure" or "safe" should
be ported to C#.
See also
DUMPBIN Options
/DEPENDENTS
Article • 08/03/2021
Dumps the names of the DLLs from which the image imports functions. You can use the
list to determine which DLLs to redistribute with your app, or find the name of a missing
dependency.
/DEPENDENTS
This option applies to all the executable files specified on the command line. It doesn't
take any arguments.
The /DEPENDENTS option adds the names of the DLLs from which the image imports
functions to the output. This option does not dump the names of the imported
functions. To see the names of the imported functions, use the /IMPORTS option.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
This example shows the DUMPBIN output of the /DEPENDENTS option on the client
executable built in Walkthrough: Create and use your own Dynamic Link Library:
Windows Command Prompt
Syntax
Remarks
Example
C:\Users\username\Source\Repos\MathClient\Debug>dumpbin /DEPENDENTS
MathClient.exe
Microsoft (R) COFF/PE Dumper Version 14.16.27032.1
Copyright (C) Microsoft Corporation. All rights reserved.
Dump of file MathClient1322.exe
File Type: EXECUTABLE IMAGE
 Image has the following dependencies:
DUMPBIN Options
 MathLibrary.dll
 MSVCP140D.dll
 VCRUNTIME140D.dll
 ucrtbased.dll
 KERNEL32.dll
 Summary
 1000 .00cfg
 1000 .data
 2000 .idata
 1000 .msvcjmc
 3000 .rdata
 1000 .reloc
 1000 .rsrc
 8000 .text
 10000 .textbss
See also
/DIRECTIVES
Article • 01/05/2022
/DIRECTIVES
Remarks
This option dumps the compiler-generated .drectve section of an image.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/DISASM
Article • 08/03/2021
Print the disassembly of code sections in the DUMPBIN output.
Syntax
/DISASM{:[BYTES|NOBYTES]}
Arguments
BYTES
Includes the instruction bytes together with the interpreted opcodes and arguments in
the disassembly output. This is the default option.
NOBYTES
Does not include the instruction bytes in the disassembly output.
Remarks
The /DISASM option displays disassembly of code sections in the file. It uses debug
symbols if they are present in the file.
/DISASM should only be used on native, not managed, images. The equivalent tool for
managed code is ILDASM.
Only the /HEADERS DUMPBIN option is available for use on files produced by the /GL
(Whole program optimization) compiler option.
See also
DUMPBIN Options
/ERRORREPORT (dumpbin.exe)
Article • 08/03/2021
７ Note
The /ERRORREPORT option is deprecated. Starting in Windows Vista, error
reporting is controlled by Windows Error Reporting (WER) settings.
Syntax
/ERRORREPORT[NONE | PROMPT | QUEUE | SEND ]
Remarks
The /ERRORREPORT arguments are overridden by the Windows Error Reporting service
settings. DUMPBIN automatically sends reports of internal errors to Microsoft, if
reporting is enabled by Windows Error Reporting. No report is sent if disabled by
Windows Error Reporting.
See also
DUMPBIN Options
/EXPORTS
Article • 08/03/2021
/EXPORTS
Remarks
This option displays all definitions exported from an executable file or DLL.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/FPO
Article • 08/03/2021
/FPO
Remarks
This option displays frame pointer optimization (FPO) records.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/HEADERS
Article • 08/03/2021
/HEADERS
Remarks
This option displays the file header and the header for each section. When used with a
library, it displays the header for each member object.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/IMPORTS (DUMPBIN)
Article • 08/03/2021
/IMPORTS[:file]
This option displays the list of DLLs (both statically linked and delay loaded) that are
imported to an executable file or DLL and all the individual imports from each of these
DLLs.
The optional file specification allows you to specify that the imports for only that DLL
will be displayed. For example:
dumpbin /IMPORTS:msvcrt.dll
Remarks
The output displayed by this option is similar to the /EXPORTS output.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/LINENUMBERS
Article • 08/03/2021
/LINENUMBERS
Remarks
This option displays COFF line numbers. Line numbers exist in an object file if it was
compiled with Program Database (/Zi), C7 Compatible (/Z7), or Line Numbers Only (/Zd).
An executable file or DLL contains COFF line numbers if it was linked with Generate
Debug Info (/DEBUG).
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/LINKERMEMBER
Article • 08/03/2021
/LINKERMEMBER[:{1|2}]
Remarks
This option displays public symbols defined in a library. Specify the 1 argument to
display symbols in object order, along with their offsets. Specify the 2 argument to
display offsets and index numbers of objects, and then list the symbols in alphabetical
order, along with the object index for each. To get both outputs, specify
/LINKERMEMBER without the number argument.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/LOADCONFIG
Article • 08/03/2021
/LOADCONFIG
Remarks
This option dumps the IMAGE_LOAD_CONFIG_DIRECTORY structure, an optional
structure that is used by the Windows NT loader and defined in WINNT.H.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/NOPDB
Article • 08/03/2021
Tells DUMPBIN not to load and search program database (PDB) files for symbol
information.
Syntax
/NOPDB
Remarks
By default, DUMPBIN attempts to load PDB files for its target executables. DUMPBIN
uses this information to match addresses to symbol names. The process can be time￾consuming if the PDB files are large, or must be loaded from a remote server. The
/NOPDB option tells DUMPBIN to skip this step. It only prints the addresses and symbol
information available in the executable.
To set the /NOPDB linker option in Visual Studio
1. Open the Property Pages dialog box for the project. For more information, see Set
C++ compiler and build properties in Visual Studio.
2. Select the Configuration Properties > Linker > Command Line property page.
3. In the Additional options box, add the /NOPDB option. Choose OK or Apply to
save your changes.
To set this linker option programmatically
This option doesn't have a programmatic equivalent.
See also
DUMPBIN command line
DUMPBIN options
DUMPBIN reference
/OUT (DUMPBIN)
Article • 08/03/2021
/OUT:filename
Remarks
This option specifies a filename for the output. By default, DUMPBIN displays the
information to standard output.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/PDATA
Article • 08/03/2021
/PDATA
Remarks
RISC processors only.
This option dumps the exception tables (.pdata) from an image or object.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/PDBPATH
Article • 03/12/2024
/PDBPATH[:VERBOSE] filename
Parameters
filename
The name of the .dll or .exe file for which you want to find the matching .pdb file.
:VERBOSE
(Optional) Reports all directories where an attempt was made to locate the .pdb file.
Remarks
/PDBPATH searches your computer along the same paths that the debugger searches for
a .pdb file and reports which, if any, .pdb files correspond to the file specified in
filename.
When using the Visual Studio debugger, you may experience a problem because the
debugger is using a .pdb file for a different version of the file you're debugging.
/PDBPATH will search for .pdb files along the following paths:
Check the location where the executable resides.
Check the location of the PDB written into the executable. This is usually the
location at the time the image was linked.
Check along the search path configured in the Visual Studio IDE.
Check along the paths in the _NT_SYMBOL_PATH and _NT_ALT_SYMBOL_PATH
environment variables.
Check in the Windows directory.
See also
DUMPBIN Options
/PDBALTPATH (Use Alternate PDB Path)
Feedback
Was this page helpful?
Provide product feedback | Get help at Microsoft Q&A
 Yes  No
/RANGE
Article • 08/03/2021
Modifies the output of dumpbin when used with other dumpbin options, such as
/RAWDATA or /DISASM.
Syntax
/RANGE:vaMin[,vaMax]
Parameters
vaMin
The virtual address at which you want the dumpbin operation to begin.
vaMax
(Optional) The virtual address at which you want the dumpbin operation to end. If not
specified, dumpbin will go to the end of the file.
Remarks
To see the virtual addresses for an image, use the map file for the image (RVA + Base),
the /DISASM or /HEADERS option of dumpbin, or the disassembly window in the Visual
Studio debugger.
Example
In this example, /range is used to modify the display of the /disasm option. In this
example, the starting value is expressed as a decimal number and the ending value is
specified as a hex number.
dumpbin /disasm /range:4219334,0x004061CD t.exe
See also
DUMPBIN Options
/RAWDATA
Article • 08/03/2021
This option displays the raw contents of each section in the file. The arguments control
the format of the display, as shown below:
Argument Result
1 The default. Contents are displayed in hexadecimal bytes, and also as ASCII
characters if they have a printed representation.
2 Contents are displayed as hexadecimal 2-byte values.
4 Contents are displayed as hexadecimal 4-byte values.
8 Contents are displayed as hexadecimal 8-byte values.
NONE Raw data is suppressed. This argument is useful to control the output of /ALL.
Number Displayed lines are set to a width that holds number values per line.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
DUMPBIN Options
/RAWDATA[:{1|2|4|8|NONE[,number]]
Remarks
See also
/RELOCATIONS
Article • 08/03/2021
/RELOCATIONS
Remarks
This option displays any relocations in the object or image.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/SECTION (DUMPBIN)
Article • 08/03/2021
/SECTION:section
Remarks
This option restricts the output to information on the specified section. Use the
/HEADERS option to get a list of sections in the file.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/SUMMARY
Article • 08/03/2021
/SUMMARY
Remarks
This option displays minimal information about sections, including total size. This option
is the default if no other option is specified.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/SYMBOLS
Article • 08/03/2021
/SYMBOLS
This option displays the COFF symbol table. Symbol tables exist in all object files. A COFF
symbol table appears in an image file only if it is linked with /DEBUG.
The following is a description of the output for /SYMBOLS. Additional information on
the meaning of /SYMBOLS output can be found by looking in winnt.h (IMAGE_SYMBOL
and IMAGE_AUX_SYMBOL), or COFF documentation.
Given the following sample dump:
Dump of file main.obj
File Type: COFF OBJECT
COFF SYMBOL TABLE
000 00000000 DEBUG notype Filename | .file
 main.cpp
002 000B1FDB ABS notype Static | @comp.id
003 00000000 SECT1 notype Static | .drectve
 Section length 26, #relocs 0, #linenums 0, checksum 722C964F
005 00000000 SECT2 notype Static | .text
 Section length 23, #relocs 1, #linenums 0, checksum 459FF65F,
selection 1 (pick no duplicates)
007 00000000 SECT2 notype () External | _main
008 00000000 UNDEF notype () External | ?MyDump@@YAXXZ (void
__cdecl MyDump(void))
String Table Size = 0x10 bytes
 Summary
 26 .drectve
 23 .text
Remarks
The following description, for lines that begin with a symbol number, describes columns
that have information relevant to users:
The first three-digit number is the symbol index/number.
If the third column contains SECTx, the symbol is defined in that section of the
object file. But if UNDEF appears, it is not defined in that object and must be
resolved elsewhere.
The fifth column (Static, External) tells whether the symbol is visible only within that
object, or whether it is public (visible externally). A Static symbol, _sym, wouldn't be
linked to a Public symbol _sym; these would be two different instances of functions
named _sym.
The last column in a numbered line is the symbol name, both decorated and
undecorated.
Only the /HEADERS DUMPBIN option is available for use on files produced with the /GL
compiler option.
See also
DUMPBIN Options
/TLS
Article • 08/03/2021
Displays the IMAGE_TLS_DIRECTORY structure from an executable.
Remarks
/TLS displays the fields of the TLS structure as well as the addresses of the TLS callback
functions.
If a program does not use thread local storage, its image will not contain a TLS structure.
See thread for more information.
IMAGE_TLS_DIRECTORY is defined in winnt.h.
See also
DUMPBIN Options
ERRLOOK Reference
Article • 08/03/2021
The ERRLOOK utility, which is available from the Tools menu as Error Lookup, retrieves a
system error message or module error message based on the value entered. ERRLOOK
retrieves the error message text automatically if you drag and drop a hexadecimal or
decimal value from the Visual Studio debugger into the Value edit control. You can also
enter a value either by typing it in the Value edit control or by pasting it from the
Clipboard and clicking Look Up.
The accelerator keys for Copy (CTRL+C), Cut (CTRL+X), and Paste (CTRL+V) work for
both the Value and Error Message edit controls if you first highlight the text.
In This Section
Value Edit Control
Describes the Value Edit control in ERRLOOK.
Error Message Edit Control
Describes the Error Message Edit control in ERRLOOK.
Modules Button
Describes the Modules button in ERRLOOK.
Look Up Button
Describes the Look Up button in ERRLOOK.
Related Sections
Additional MSVC Build Tools
Provides links to topics discussing the C/C++ build tools provided in Visual C++.
Value Edit Control
Article • 08/03/2021
To use the control, enter a value, paste it from the Clipboard, or drag and drop it from
the debugger into this edit control. Enter the value in hexadecimal or decimal form and
then click Look Up. Hexadecimal values should be preceded by 0x; valid characters are
0-9, A-F, and a-f. Decimal values can be preceded by the minus sign (-); valid characters
are 0-9.
See also
ERRLOOK Reference
Error Message Edit Control
Article • 08/03/2021
The Error Message box contains the text of the system error message or module error
message based on the value entered.
See also
Value Edit Control
Modules Button
Article • 08/03/2021
Click the Modules button to bring up the Additional Modules for Error Searching
dialog. Enter the name of the desired EXE or DLL in the edit box and click Add to include
the modules in your error message search. Remove a module from the list by
highlighting it and clicking the Remove button.
See also
Value Edit Control
Look Up Button
Article • 08/03/2021
Click Look Up to retrieve the error message that corresponds to the system or module
value entered. Values can be entered in hexadecimal or decimal form (including negative
decimal values). Modules listed in the Additional Modules for Error Searching dialog
are also searched.
See also
Value Edit Control
XDCMake Reference
Article • 12/03/2021
The xdcmake.exe program compiles XDC files into an XML file. An XDC file is created by
the MSVC compiler for each source code file when source code is compiled with /doc
and when the source code file contains documentation comments marked up with XML
tags.
To use xdcmake.exe in the Visual Studio
development environment
1. Open the project's Property Pages dialog box. For details, see Set C++ compiler
and build properties in Visual Studio.
2. Select the Configuration Properties > XML Document Comments property page.
3. Enter options in the property page.
７ Note
xdcmake.exe options at the command line differ from the options when
xdcmake.exe is used in the development environment (property pages). For
information on using xdcmake.exe in the development environment, see XML
Document Generator Tool Property Pages.
Syntax
xdcmake input_filename options
Parameters
input_filename
The file name of the XDC files used as input to xdcmake.exe. Specify one or more XDC
files or use *.xdc to use all XDC files in the current directory.
options
You can supply zero or more of the following options:
Option Description Option Description
/? , /help Display help for xdcmake.exe.
/assembly:filename Lets you specify the value of the <assembly> tag in the XML file. By default,
the value of the <assembly> tag is the same as the filename of the XML file.
/nologo Suppress copyright message.
/out:filename Lets you specify the name of the XML file. By default, the name of the XML
file is the filename of the first XDC file processed by xdcmake.exe.
Visual Studio invokes xdcmake.exe automatically when building a project. You can also
invoke xdcmake.exe at the command line.
For more information on adding documentation comments to source code files, see
Recommended tags for documentation comments.
XML documentation
Remarks
See also
BSCMAKE Reference
Article • 08/03/2021
２ Warning
Although BSCMAKE is still installed with Visual Studio, it is no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
The Microsoft Browse Information Maintenance Utility (BSCMAKE.EXE) builds a browse
information file (.bsc) from .sbr files created during compilation. Certain third-party tools
use .bsc files for code analysis.
When you build your program, you can create a browse information file for your
program automatically, using BSCMAKE to build the file. You do not need to know how
to run BSCMAKE if you create your browse information file in the Visual Studio
development environment. However, you may want to read this topic to understand the
choices available.
If you build your program outside of the development environment, you can still create
a custom .bsc that you can examine in the environment. Run BSCMAKE on the .sbr files
that you created during compilation.
７ Note
You can start this tool only from the Visual Studio Developer command prompt.
You cannot start it from a system command prompt or from File Explorer.
This section includes the following topics:
Building Browse Information Files: Overview
Building a .bsc file
BSCMAKE command line
BSCMAKE command file
BSCMAKE options
BSCMAKE exit codes
See also
Additional MSVC Build Tools
Building Browse Information Files:
Overview
Article • 03/02/2022
２ Warning
Although BSCMAKE is still installed with Visual Studio, it's no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
To create browse information for symbol browsing, the compiler creates an .sbr file for
each source file in your project, then BSCMAKE.EXE concatenates the .sbr files into one
.bsc file.
Generating .sbr and .bsc files takes time, so Visual Studio turns off these functions by
default. If you want to browse current information, you must turn on the browse options
and build your project again.
Use /FR or /Fr to tell the compiler to create .sbr files. To create .bsc files, you can call
BSCMAKE from the command line. Using BSCMAKE from the command line gives you
more precise control over the manipulation of browse information files. For more
information, see BSCMAKE reference.
 Tip
You can turn on .sbr file generation but leave .bsc file generation turned off. This
provides fast builds but also enables you to create a fresh .bsc file quickly by
turning on .bsc file generation and building the project.
You can reduce the time, memory, and disk space required to build a .bsc file by
reducing the size of the .bsc file.
See General Property Page (Project) for information on how to build a browser file in the
development environment.
To create a smaller .bsc file
1. Use BSCMAKE command-line options to exclude information from the browse
information file.
2. Omit local symbols in one or more .sbr files when compiling or assembling.
3. If an object file doesn't contain information needed for your current stage of
debugging, omit its .sbr file from the BSCMAKE command when you rebuild the
browse information file.
To combine the browse information from several projects
into one browser file ( .bsc )
1. Either don't build the .bsc file at the project level or use the /n switch to prevent
the .sbr files from being truncated.
2. After all the projects are built, run BSCMAKE with all of the .sbr files as input.
Wildcards are accepted. For instance, if you had project directories C:\X , C:\Y , and
C:\Z with .sbr files in them and you wanted to combine them all into one .bsc
file, then use BSCMAKE C:\X\*.sbr C:\Y\*.sbr C:\Z\*.sbr /o
c:\whatever_directory\combined.bsc to build the combined .bsc file.
See also
Additional MSVC build tools
BSCMAKE reference
Building a .Bsc File
Article • 08/03/2021
BSCMAKE can build a new browse information file from newly created .sbr files. It can
also maintain an existing .bsc file using .sbr files for object files that have changed since
the last build.
How to create an .sbr file
How BSCMAKE builds a .bsc file
See also
BSCMAKE Reference
Creating an .Sbr File
Article • 08/03/2021
２ Warning
Although BSCMAKE is still installed with Visual Studio, it is no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
The input files for BSCMAKE are .sbr files. The compiler creates an .sbr file for each
object file (.obj) it compiles. When you build or update your browse information file, all
.sbr files for your project must be available on disk.
To create an .sbr file with all possible information, specify /FR.
To create an .sbr file that doesn't contain local symbols, specify /Fr. If the .sbr files
contain local symbols, you can still omit them from the .bsc file by using BSCMAKE's /El
option.
You can create an .sbr file without performing a full compile. For example, you can
specify the /Zs option to the compiler to perform a syntax check and still generate an
.sbr file if you specify /FR or /Fr.
The build process can be more efficient if the .sbr files are first packed to remove
unreferenced definitions. The compiler automatically packs .sbr files.
See also
Building a .Bsc File
How BSCMAKE Builds a .Bsc File
Article • 08/03/2021
BSCMAKE builds or rebuilds a .bsc file in the most efficient way it can. To avoid potential
problems, it is important to understand the build process.
When BSCMAKE builds a browse information file, it truncates the .sbr files to zero
length. During a subsequent build of the same file, a zero-length (or empty) .sbr file tells
BSCMAKE that the .sbr file has no new contribution to make. It lets BSCMAKE know that
an update of that part of the file is not required and an incremental build will be
sufficient. During every build (unless the /n option is specified), BSCMAKE first attempts
to update the file incrementally by using only those .sbr files that have changed.
BSCMAKE looks for a .bsc file that has the name specified with the /o option. If /o is not
specified, BSCMAKE looks for a file that has the base name of the first .sbr file and a .bsc
extension. If the file exists, BSCMAKE performs an incremental build of the browse
information file using only the contributing .sbr files. If the file does not exist, BSCMAKE
performs a full build using all .sbr files. The rules for builds are as follows:
For a full build to succeed, all specified .sbr files must exist and must not be
truncated. If an .sbr file is truncated, you must rebuild it (by recompiling or
assembling) before running BSCMAKE.
For an incremental build to succeed, the .bsc file must exist. All contributing .sbr
files, even empty files, must exist and must be specified on the BSCMAKE
command line. If you omit an .sbr file from the command line, BSCMAKE removes
its contribution from the file.
See also
Building a .Bsc File
BSCMAKE Command Line
Article • 08/03/2021
２ Warning
Although BSCMAKE is still installed with Visual Studio, it is no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
To run BSCMAKE, use the following command line syntax:
BSCMAKE [options] sbrfiles
Options can appear only in the options field on the command line.
The sbrfiles field specifies one or more .sbr files created by a compiler or assembler.
Separate the names of .sbr files with spaces or tabs. You must specify the extension;
there is no default. You can specify a path with the filename, and you can use operating￾system wildcards (* and ?).
During an incremental build, you can specify new .sbr files that were not part of the
original build. If you want all contributions to remain in the browse information file, you
must specify all .sbr files (including truncated files) that were originally used to create
the .bsc file. If you omit an .sbr file, that file's contribution to the browse information file
is removed.
Do not specify a truncated .sbr file for a full build. A full build requires contributions
from all specified .sbr files. Before you perform a full build, recompile the project and
create a new .sbr file for each empty file.
The following command runs BSCMAKE to build a file called MAIN.bsc from three .sbr
files:
BSCMAKE main.sbr file1.sbr file2.sbr
For related information, see BSCMAKE Command File and BSCMAKE Options.
See also
BSCMAKE Reference
BSCMAKE Command File (Response File)
Article • 08/03/2021
２ Warning
Although BSCMAKE is still installed with Visual Studio, it is no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
You can provide part or all of the command-line input in a command file. Specify the
command file using the following syntax:
BSCMAKE @filename
Only one command file is allowed. You can specify a path with filename. Precede
filename with an at sign (@). BSCMAKE does not assume an extension. You can specify
additional sbrfiles on the command line after filename. The command file is a text file
that contains the input to BSCMAKE in the same order as you would specify it on the
command line. Separate the command-line arguments with one or more spaces, tabs, or
newline characters.
The following command calls BSCMAKE using a command file:
BSCMAKE @prog1.txt
The following is a sample command file:
/n /v /o main.bsc /El
/S (
toolbox.h
verdate.h c:\src\inc\screen.h
)
file1.sbr file2.sbr file3.sbr file4.sbr
See also
BSCMAKE Reference
BSCMAKE options
Article • 03/22/2022
２ Warning
Although BSCMAKE is still installed with Visual Studio, it's no longer used by the
IDE. Since Visual Studio 2008, browse and symbol information is stored
automatically in a SQL Server .sdf file in the solution folder.
This section describes the options available for controlling BSCMAKE. Several options
control the content of the browse information file by excluding or including certain
information. The exclusion options can allow BSCMAKE to run faster and may result in a
smaller .bsc file. Option names are case-sensitive (except for /HELP and /NOLOGO ).
Only /NOLOGO and /o are available from within the Visual Studio development
environment. For more information, see Set C++ compiler and build properties in Visual
Studio.
Options
/Ei ( filename ... )
Excludes the contents of one or more specified filename include files from the browse
information file. To specify multiple files, separate the names with a space and enclose
the list in parentheses. Parentheses aren't necessary if you specify only one filename .
Use /Ei along with the /Es option to exclude files not excluded by /Es .
/El
Excludes local symbols. The default is to include local symbols. For more information
about local symbols, see Creating an .sbr File.
/Em
Excludes symbols in the body of macros. Use /Em to include only the names of macros
in the browse information file. The default is to include both the macro names and the
result of the macro expansions.
/Er ( symbol ... )
Excludes one or more of the specified symbol symbols from the browse information file.
To specify multiple symbol names, separate the names with a space and enclose the list
in parentheses. Parentheses are unnecessary if you specify only one symbol .
/Es
Excludes every include file specified with an absolute path, or found in an absolute path
specified in the INCLUDE environment variable. (Usually, these files are the system
include files, which contain much information you may not need in your browse
information file.) This option doesn't exclude files specified without a path, or with
relative paths, or files found in a relative path in INCLUDE. You can use the /Ei option
along with /Es to exclude files that /Es doesn't exclude. If you want to exclude only
some of the files, use /Ei instead of /Es , and list the files you want to exclude.
/errorreport: [ none | prompt | queue | send ]
This option is deprecated. In Windows Vista and later, error reporting is controlled by
Windows Error Reporting (WER) settings.
/HELP
Displays a summary of the BSCMAKE command-line syntax.
/Iu
Includes unreferenced symbols. By default, BSCMAKE doesn't record any symbols that
are defined but not referenced. If an .sbr file has been packed, this option has no effect
for that input file because the compiler has already removed the unreferenced symbols.
/n
Forces a non-incremental build. Use /n to force a full build of the browse information
file whether a .bsc file exists or not, and to prevent .sbr files from being truncated. For
more information, see How BSCMAKE builds a .bsc file.
/NOLOGO
Suppresses the BSCMAKE copyright message.
/o filename
The filename option parameter specifies a name for the browse information file. By
default, BSCMAKE gives the browse information file the base name of the first .sbr file
and a .bsc extension.
/S ( filename ... )
Tells BSCMAKE to process each specified filename include file the first time it's
encountered and to exclude it otherwise. Use this option to save processing time when
a file (such as a header, or .h , file for a .c or .cpp source file) is included in several
source files but is unchanged by preprocessing directives each time. Use this option if a
file is changed in ways unimportant for the browse information file you're creating. To
specify multiple files, separate the names with a space, and enclose the list in
parentheses. Parentheses aren't necessary if you specify only one filename . If you want
to exclude the file every time it's included, use the /Ei or /Es option.
/v
Provides verbose output, which includes the name of each .sbr file being processed
and information about the complete BSCMAKE run.
/?
Displays a brief summary of BSCMAKE command-line syntax.
Example
The following command line tells BSCMAKE to do a full build of main.bsc from three
.sbr files. It also tells BSCMAKE to exclude duplicate instances of toolbox.h :
Windows Command Prompt
BSCMAKE /n /S toolbox.h /o main.bsc file1.sbr file2.sbr file3.sbr
See also
BSCMAKE reference
BSCMAKE Exit Codes
Article • 08/03/2021
BSCMAKE returns an exit code (also called a return code or error code) to the operating
system or the calling program.
Code Meaning
0 No error
1 Command-line error
4 Fatal error during build
BSCMAKE Reference
See also
C/C++ Compiler and build tools errors
and warnings
Article • 08/03/2021
The articles in this section of the documentation explain diagnostic error and warning
messages that are generated by the Microsoft C/C++ compiler and build tools.
） Important
The Visual Studio compilers and build tools can report many kinds of errors and
warnings. After an error or warning is found, the build tools may make assumptions
about code intent and attempt to continue, so that more issues can be reported at
the same time. If the tools make the wrong assumption, later errors or warnings
may not apply to your project. When you correct issues in your project, always start
with the first error or warning that's reported, and rebuild often. One fix may make
many subsequent errors go away.
To get help on a particular diagnostic message in Visual Studio, select it in the Output
window and press the F1 key. Visual Studio opens the documentation page for that
error, if one exists. You can also use the search tool at the top of the page to find articles
about specific errors or warnings. Or, browse the list of errors and warnings by tool and
type in the table of contents on this page.
７ Note
Not every Visual Studio error or warning is documented. In many cases, the
diagnostic message provides all of the information that's available. If you landed on
this page when you used F1 and you think the error or warning message needs
additional explanation, let us know. You can use the feedback buttons on this page
to raise a documentation issue on GitHub . If you think the error or warning is
wrong, or you've found another problem with the toolset, report a product issue on
the Developer Community site. You can also send feedback and enter bugs
within the IDE. In Visual Studio, go to the menu bar and choose Help > Send
Feedback > Report a Problem, or submit a suggestion by using Help > Send
Feedback > Send a Suggestion.
You may find additional assistance for errors and warnings in Microsoft Learn Q&A
forums. Or, search for the error or warning number on the Visual Studio C++ Developer
Community site. You can also search Stack Overflow to find solutions.
For links to additional help and community resources, see Visual C++ Help and
Community.
In this section
BSCMAKE errors and warnings (BKxxxx)
Errors and warnings generated by the Microsoft Browse Information Maintenance Utility
(BSCMAKE.EXE).
Command-line errors and warnings
Errors and warnings generated by the build tools for command-line options issues.
Compiler fatal errors C999 - C1999
Errors that halt the C++ compiler (CL.EXE).
Compiler errors C2001 - C3999
Errors detected by the C++ compiler (CL.EXE).
Compiler warnings C4000 - C5999
Warnings for issues detected by the C++ compiler (CL.EXE).
Compiler warnings by compiler version
A list of the warnings introduced by each compiler version.
C Runtime errors (Rxxxx)
Errors generated at runtime by the C Runtime Library (CRT).
CVTRES errors and warnings (CVTxxxx)
Errors and warnings generated by the Microsoft Resource File To COFF Object
Conversion Utility (CVTRES.EXE).
Expression evaluator errors (CXXxxxx)
Errors generated by the debugger and diagnostics tools.
Linker tools errors and warnings (LNKxxxx)
Errors and warnings generated by the linker and related tools (LINK.EXE, LIB.EXE,
DUMPBIN.EXE, EDITBIN.EXE).
Math errors (Mxxxx)
Errors generated by the runtime floating-point math library.
NMAKE errors and warnings (Uxxxx)
Errors and warnings generated by the Microsoft makefile tool (NMAKE.EXE).
Profile-Guided Optimization errors and warnings (PGxxxx)
Errors and warnings generated by the Profile-Guided Optimization (PGO) tools.
Project build errors and warnings (PRJxxxx)
Errors and warnings generated by the native C++ Project build system in Visual Studio.
Resource compiler errors and warnings (RCxxxx, RWxxxx)
Errors and warnings generated by the Resource Compiler (RC.EXE).
Vectorizer and parallelizer messages
Diagnostic messages generated by the vectorizer and parallelizer optimization compiler
options.
Related sections
Compiler warnings that are off by default
See also
C/C++ Building Reference
Debugging in Visual Studio
XML documentation (Visual C++)
Article • 12/03/2021
In Visual C++, you can add comments to your source code that are processed to an
XML documentation file. This file can then be the input to a process that creates
documentation for the classes in your code.
In a Visual C++ code file, XML documentation comments must be located directly
before a method or type definition. The comments can be used to populate the
IntelliSense QuickInfo data tip in the following scenarios:
1. When the code is compiled as a Windows Runtime component with a WINMD file
2. When the source code is included in the current project
3. In a library whose type declarations and implementations are located in the same
header file
For details on creating an XML file with documentation comments, see the following
articles.
For information about See
The compiler options to use /doc
Tags you can use to provide commonly used functionality
in documentation
Recommended tags for
documentation comments
The ID strings that the compiler produces to identify the
constructs in your code
Processing the XML File
How to delimit documentation tags Delimiters for Visual C++
documentation tags
Generating an XML file from one or more XDC files. XDCMake reference
Links to information about XML as it relates to Visual
Studio feature areas
XML in Visual Studio
７ Note
In the current release, code comments aren't processed on templates or anything
containing a template type (for example, a function taking a parameter as a
template). Adding such comments will result in undefined behavior.
If you need to put XML special characters in the text of a documentation comment, you
must use XML entities or a CDATA section.
See also
Component extensions for runtime platforms
Recommended tags for documentation
comments
Article • 12/03/2021
The MSVC compiler processes documentation comments in your code to create an XDC
file for each compiled source file. Then, xdcmake.exe processes the XDC files to create
an XML documentation file. Processing the XML file to create documentation is a detail
that needs to be implemented at your site.
Tags are processed on constructs such as types and type members.
Tags must immediately precede types or members.
７ Note
Documentation comments can't be applied to a namespace or on out of line
definitions for properties and events; documentation comments must be on the in￾class declarations.
The compiler will process any tag that is valid XML. The following tags provide
commonly used functionality in user documentation:
<c>
<code>
<example>
<exception>1
<include>1
<list>
<para>
<param>1
<paramref>1
<permission>1
<remarks>
<returns>
<see>1
<seealso>1
<summary>
<value>
1. Compiler verifies syntax.
In the current release, the MSVC compiler doesn't support <paramref> , a tag that's
supported by other Visual Studio compilers. Visual C++ may support <paramref> in a
future release.
See also
XML documentation
<c> documentation tag
Article • 11/23/2021
The <c> tag indicates that text within a description should be marked as code. Use
<code> to indicate multiple lines as code.
C++
text
The text you want to indicate as code.
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <c>text</c>
Parameters
Remarks
Example
// xml_c_tag.cpp
// compile with: /doc /LD
// post-build command: xdcmake xml_c_tag.xdc
/// Text for class MyClass.
class MyClass {
public:
 int m_i;
 MyClass() : m_i(0) {}
 /// <summary><c>MyMethod</c> is a method in the <c>MyClass</c> class.
 /// </summary>
 int MyMethod(MyClass * a) {
 return a -> m_i;
 }
};
See also
XML documentation
<code> documentation tag
Article • 12/03/2021
The <code> tag gives you a way to indicate one or more lines as code.
Syntax
C++
/// <code>content</code>
/// <code>
/// content
/// content
/// </code>
Parameters
content
The text you want marked as code.
Remarks
Use <c> to indicate a portion of text should be marked as code.
Compile with /doc to process documentation comments to a file.
Example
For an example of how to use the <code> tag, see <example>.
See also
XML documentation
<example> documentation tag
Article • 12/03/2021
The <example> tag lets you specify an example of how to use a method or other library
member. Commonly, use of this tag would also involve the <code> tag.
C++
description
A description of the code sample.
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <example>description</example>
Parameters
Remarks
Example
// xml_example_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_example_tag.dll
/// Text for class MyClass.
public ref class MyClass {
public:
 /// <summary>
 /// GetZero method
 /// </summary>
 /// <example> This sample shows how to call the GetZero method.
 /// <code>
 /// int main()
 /// {
 /// return GetZero();
 /// }
 /// </code>
 /// </example>
XML documentation
 static int GetZero() {
 return 0;
 }
};
See also
<exception> documentation tag
Article • 11/23/2021
The <exception> tag lets you specify which exceptions can be thrown. This tag is applied
to a method definition.
Syntax
C++
/// <exception cref="member">description</exception>
Parameters
member
A reference to an exception that's available from the current compilation environment.
Using name lookup rules, the compiler checks that the given exception exists, and
translates member to the canonical element name in the output XML. The compiler issues
a warning if it doesn't find member .
Enclose the name in single or double quotation marks.
For more information on how to create a cref reference to a generic type, see <see>.
description
A description.
Remarks
Compile with /doc to process documentation comments to a file.
The MSVC compiler attempts to resolve cref references in one pass through the
documentation comments. If using the C++ lookup rules, when a symbol isn't found by
the compiler the reference is marked as unresolved. For more information, see
<seealso>.
Example
C++
XML documentation
// xml_exception_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_exception_tag.dll
using namespace System;
/// Text for class EClass.
public ref class EClass : public Exception {
 // class definition ...
};
/// <exception cref="System.Exception">Thrown when... .</exception>
public ref class TestClass {
 void Test() {
 try {
 }
 catch(EClass^) {
 }
 }
};
See also
<include> documentation tag
Article • 12/03/2021
The <include> tag lets you refer to comments in another file that describe the types and
members in your source code. This tag is an alternative to placing documentation
comments directly in your source code file. For example, you can use <include> to
insert standard "boilerplate" comments that are used throughout your team or
company.
Syntax
C++
/// <include file='filename' path='tag-path[@name="ID"' />
Parameters
filename
The name of the file containing the documentation. The file name can be qualified with
a path. Enclose the name in single or double quotation marks. The compiler issues a
warning if it doesn't find filename .
tag-path
A valid XPath expression that selects the wanted node-set contained in the file.
name
The name specifier in the tag that precedes the comments; name will have an ID .
ID
The ID for the tag that precedes the comments. Enclose the ID in single or double
quotation marks.
Remarks
The <include> tag uses the XML XPath syntax. Refer to XPath documentation for ways
to customize using <include> .
Compile with /doc to process documentation comments to a file.
This example uses multiple files. The first file, which uses <include> , contains the
following documentation comments:
C++
The second file, xml_include_tag.doc , contains the following documentation comments:
XML
XML
Example
// xml_include_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_include_tag.dll
/// <include file='xml_include_tag.doc'
path='MyDocs/MyMembers[@name="test"]/*' />
public ref class Test {
 void TestMethod() {
 }
};
/// <include file='xml_include_tag.doc'
path='MyDocs/MyMembers[@name="test2"]/*' />
public ref class Test2 {
 void Test() {
 }
};
<MyDocs>
<MyMembers name="test">
<summary>
The summary for this type.
</summary>
</MyMembers>
<MyMembers name="test2">
<summary>
The summary for this other type.
</summary>
</MyMembers>
</MyDocs>
Program Output
XML documentation
<?xml version="1.0"?>
<doc>
 <assembly>
 <name>t2</name>
 </assembly>
 <members>
 <member name="T:Test">
 <summary>
The summary for this type.
</summary>
 </member>
 <member name="T:Test2">
 <summary>
The summary for this other type.
</summary>
 </member>
 </members>
</doc>
See also
<list> and <listheader>
documentation tags
Article • 12/03/2021
The <listheader> block is used to define the heading row of either a table or definition
list. When defining a table, you only need to supply an entry for term in the heading.
XML
term
A term to define, which will be defined in description .
description
Either an item in a bullet or numbered list or the definition of a term .
Each item in the list is specified with an <item> block. When creating a definition list,
you'll need to specify both term and description . However, for a table, bulleted list, or
numbered list, you only need to supply an entry for description .
A list or table can have as many <item> blocks as needed.
Compile with /doc to process documentation comments to a file.
Syntax
<list type="bullet" | "number" | "table">
 <listheader>
 <term>term</term>
 <description>description</description>
 </listheader>
 <item>
 <term>term</term>
 <description>description</description>
 </item>
</list>
Parameters
Remarks
Example
C++
// xml_list_tag.cpp
// compile with: /doc /LD
// post-build command: xdcmake xml_list_tag.dll
/// <remarks>Here is an example of a bulleted list:
/// <list type="bullet">
/// <item>
/// <description>Item 1.</description>
/// </item>
/// <item>
/// <description>Item 2.</description>
/// </item>
/// </list>
/// </remarks>
class MyClass {};
See also
XML documentation
<para> documentation tag
Article • 12/03/2021
The <para> tag is for use inside a tag, such as <summary>, <remarks>, or <returns>,
and lets you add structure to the text.
Syntax
C++
/// <para>content</para>
Parameters
content
The text of the paragraph.
Remarks
Compile with /doc to process documentation comments to a file.
Example
See <summary> for an example of using <para> .
See also
XML documentation
<param> documentation tag
Article • 12/03/2021
The <param> tag should be used in the comment for a method declaration to describe
one of the parameters for the method.
C++
param-name
The name of a method parameter. Enclose the name in single or double quotation
marks. The compiler issues a warning if it doesn't find param-name .
description
A description for the parameter.
The text for the <param> tag will be displayed in IntelliSense, the Object Browser, and in
the Code Comment Web Report.
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <param name='param-name'>description</param>
Parameters
Remarks
Example
// xml_param_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_param_tag.dll
/// Text for class MyClass.
public ref class MyClass {
 /// <param name="Int1">Used to indicate status.</param>
 void MyMethod(int Int1) {
 }
};
See also
XML documentation
<paramref> documentation tag
Article • 12/03/2021
The <paramref> tag gives you a way to indicate that a word is a parameter. The XML file
can be processed to format this parameter in some distinct way.
C++
ref-name
The name of the parameter to refer to. Enclose the name in single or double quotation
marks. The compiler issues a warning if it doesn't find ref-name .
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <paramref name="ref-name"/>
Parameters
Remarks
Example
// xml_paramref_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_paramref_tag.dll
/// Text for class MyClass.
public ref class MyClass {
 /// <summary>MyMethod is a method in the MyClass class.
 /// The <paramref name="Int1"/> parameter takes a number.
 /// </summary>
 void MyMethod(int Int1) {}
};
See also
XML documentation
<permission> documentation tag
Article • 12/03/2021
The <permission> tag lets you document the access of a member. PermissionSet lets
you specify access to a member.
Syntax
C++
/// <permission cref="member">description</permission>
Parameters
member
A reference to a member or field that is available to be called from the current
compilation environment. The compiler checks that the given code element exists and
translates member to the canonical element name in the output XML. Enclose the name
in single or double quotation marks.
The compiler issues a warning if it doesn't find member .
For information on how to create a cref reference to a generic type, see <see>.
description
A description of the access to the member.
Remarks
Compile with /doc to process documentation comments to a file.
The MSVC compiler will attempt to resolve cref references in one pass through the
documentation comments. If the compiler doesn't find a symbol when using the C++
lookup rules, the reference will be marked as unresolved. For more information, see
<seealso>.
Example
C++
XML documentation
// xml_permission_tag.cpp
// compile with: /clr /doc /LD
// post-build command: xdcmake xml_permission_tag.dll
using namespace System;
/// Text for class TestClass.
public ref class TestClass {
 /// <permission cref="System::Security::PermissionSet">Everyone can
access this method.</permission>
 void Test() {}
};
See also
<remarks> documentation tag
Article • 12/03/2021
The <remarks> tag is used to add information about a type, supplementing the
information specified with <summary>. This information is displayed in the Object
Browser and in the Code Comment Web Report.
Syntax
C++
/// <remarks>description</remarks>
Parameters
description
A description of the member.
Remarks
Compile with /doc to process documentation comments to a file.
Example
C++
// xml_remarks_tag.cpp
// compile with: /LD /clr /doc
// post-build command: xdcmake xml_remarks_tag.dll
using namespace System;
/// <summary>
/// You may have some primary information about this class.
/// </summary>
/// <remarks>
/// You may have some additional information about this class.
/// </remarks>
public ref class MyClass {};
See also
XML documentation
<returns> documentation tag
Article • 12/03/2021
The <returns> tag should be used in the comment for a method declaration to describe
the return value.
C++
description
A description of the return value.
Compile with /doc to process documentation comments to a file.
C++
XML documentation
Syntax
/// <returns>description</returns>
Parameters
Remarks
Example
// xml_returns_tag.cpp
// compile with: /LD /clr /doc
// post-build command: xdcmake xml_returns_tag.dll
/// Text for class MyClass.
public ref class MyClass {
public:
 /// <returns>Returns zero.</returns>
 int GetZero() { return 0; }
};
See also
<see> documentation tag
Article • 12/03/2021
The <see> tag lets you specify a link from within text. Use <seealso> to indicate text
that you might want to appear in a See also section.
Syntax
C++
/// <see cref="member"/>
Parameters
member
A reference to a member or field that is available to be called from the current
compilation environment. Enclose the name in single or double quotation marks.
The compiler checks that the given code element exists and resolves member to the
element name in the output XML. The compiler issues a warning if it doesn't find
member .
Remarks
Compile with /doc to process documentation comments to a file.
For an example of using <see> , see <summary>.
The MSVC compiler will attempt to resolve cref references in one pass through the
documentation comments. If the compiler doesn't find a symbol when it's using the
C++ lookup rules, it marks the reference as unresolved. For more information, see
<seealso>.
Example
The following sample shows how you can make cref reference to a generic type so the
compiler will resolve the reference.
C++
// xml_see_cref_example.cpp
// compile with: /LD /clr /doc
// the following cref shows how to specify the reference, such that,
// the compiler will resolve the reference
/// <see cref="C{T}">
/// </see>
ref class A {};
// the following cref shows another way to specify the reference,
// such that, the compiler will resolve the reference
/// <see cref="C < T >"/>
// the following cref shows how to hard-code the reference
/// <see cref="T:C`1">
/// </see>
ref class B {};
/// <see cref="A">
/// </see>
/// <typeparam name="T"></typeparam>
generic<class T>
ref class C {};
See also
XML documentation
<seealso> documentation tag
Article • 12/03/2021
The <seealso> tag lets you specify the text that you might want to appear in a See Also
section. Use <see> to specify a link from within text.
Syntax
C++
/// <seealso cref="member"/>
Parameters
member
A reference to a member or field that is available to be called from the current
compilation environment. Enclose the name in single or double quotation marks.
The compiler checks that the given code element exists and resolves member to the
element name in the output XML. The compiler issues a warning if it doesn't find
member .
For information on how to create a cref reference to a generic type, see <see>.
Remarks
Compile with /doc to process documentation comments to a file.
See <summary> for an example of using <seealso> .
The MSVC compiler attempts to resolve cref references in one pass through the
documentation comments. If the compiler doesn't find a symbol when using the C++
lookup rules, it marks the reference as unresolved.
Example
In the following sample, an unresolved symbol is referenced in a cref . The XML
comment for the cref to A::Test is well formed: <seealso cref="M:A.Test" /> .
However, the cref to B::Test becomes <seealso cref="!:B::Test" /> .
C++
XML documentation
// xml_seealso_tag.cpp
// compile with: /LD /clr /doc
// post-build command: xdcmake xml_seealso_tag.dll
/// Text for class A.
public ref struct A {
 /// <summary><seealso cref="A::Test"/>
 /// <seealso cref="B::Test"/>
 /// </summary>
 void MyMethod(int Int1) {}
 /// text
 void Test() {}
};
/// Text for class B.
public ref struct B {
 void Test() {}
};
See also
<summary>
Article • 12/03/2021
The <summary> tag should be used to describe a type or a type member. Use <remarks>
to add supplemental information to a type description.
C++
description
A summary of the object.
The text for the <summary> tag is the only source of information about the type in
IntelliSense, and is also displayed in the Object Browser and in the Code Comment Web
Report.
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <summary>description</summary>
Parameters
Remarks
Example
// xml_summary_tag.cpp
// compile with: /LD /clr /doc
// post-build command: xdcmake xml_summary_tag.dll
/// Text for class MyClass.
public ref class MyClass {
public:
 /// <summary>MyMethod is a method in the MyClass class.
 /// <para>Here's how you could make a second paragraph in a description.
<see cref="System::Console::WriteLine"/> for information about output
statements.</para>
 /// <seealso cref="MyClass::MyMethod2"/>
 /// </summary>
XML documentation
 void MyMethod(int Int1) {}
 /// text
 void MyMethod2() {}
};
See also
<value> documentation tag
Article • 12/03/2021
The <value> tag lets you describe a property and property accessor methods. When you
add a property with a code wizard in the Visual Studio integrated development
environment, it will add a <summary> tag for the new property. You need to manually
add a <value> tag to describe the value that the property represents.
C++
property-description
A description for the property.
Compile with /doc to process documentation comments to a file.
C++
Syntax
/// <value>property-description</value>
Parameters
Remarks
Example
// xml_value_tag.cpp
// compile with: /LD /clr /doc
// post-build command: xdcmake xml_value_tag.dll
using namespace System;
/// Text for class Employee.
public ref class Employee {
private:
 String ^ name;
 /// <value>Name accesses the value of the name data member</value>
public:
 property String ^ Name {
 String ^ get() {
 return name;
 }
 void set(String ^ i) {
 name = i;
 }
 }
};
See also
XML documentation
XML documentation file processing
Article • 12/03/2021
The compiler generates an ID string for each construct in your code that is tagged to
generate documentation. For more information, see Recommended tags documentation
comments. The ID string uniquely identifies the construct. Programs that process the
XML file can use the ID string to identify the corresponding .NET Framework metadata
or reflection item to which the documentation applies.
The XML file isn't a hierarchical representation of your code, it's a flat list with a
generated ID for each element.
The compiler observes the following rules when it generates the ID strings:
No white space is placed in the string.
The first part of the ID string identifies the kind of member being identified, with a
single character followed by a colon. The following member types are used:
Character Description
N Namespace
You can't add documentation comments to a namespace, cref references to a
namespace are possible.
T Type: class, interface, struct, enum, delegate
D Typedef
F Field
P Property (including indexers or other indexed properties)
M Method (including such special methods as constructors, operators, and so
forth)
E Event
! Error string
The rest of the string provides information about the error. The MSVC compiler
generates error information for links that can't be resolved.
The second part of the string is the fully qualified name of the item, starting at the
root of the namespace. The name of the item, its enclosing type or types, and
namespace are separated by periods. If the name of the item itself has periods,
they're replaced by the hash-sign ('#'). It's assumed that no item has a hash-sign
directly in its name. For example, the fully qualified name of the String
constructor would be System.String.#ctor .
For properties and methods, if there are arguments to the method, the argument
list enclosed in parentheses follows. If there are no arguments, no parentheses are
present. The arguments are separated by commas. Each argument is encoded the
same way it's encoded in a .NET Framework signature:
Base types. Regular types ( ELEMENT_TYPE_CLASS or ELEMENT_TYPE_VALUETYPE ) are
represented as the fully qualified name of the type.
Intrinsic types (for example, ELEMENT_TYPE_I4 , ELEMENT_TYPE_OBJECT ,
ELEMENT_TYPE_STRING , ELEMENT_TYPE_TYPEDBYREF , and ELEMENT_TYPE_VOID ) are
represented as the fully qualified name of the corresponding full type, for
example, System.Int32 or System.TypedReference .
ELEMENT_TYPE_PTR is represented as a ' * ' following the modified type.
ELEMENT_TYPE_BYREF is represented as a ' @ ' following the modified type.
ELEMENT_TYPE_PINNED is represented as a ' ^ ' following the modified type. The
MSVC compiler never generates this element.
ELEMENT_TYPE_CMOD_REQ is represented as a ' | ' and the fully qualified name of
the modifier class, following the modified type. The MSVC compiler never
generates this element.
ELEMENT_TYPE_CMOD_OPT is represented as a ' ! ' and the fully qualified name of
the modifier class, following the modified type.
ELEMENT_TYPE_SZARRAY is represented as " [] " following the element type of the
array.
ELEMENT_TYPE_GENERICARRAY is represented as " [?] " following the element type
of the array. The MSVC compiler never generates this element.
ELEMENT_TYPE_ARRAY is represented as [ lower bound: size , lower bound: size ]
where the number of commas is the rank - 1, and the lower bound and size of
each dimension, if known, are represented in decimal. If a lower bound or size
isn't specified, it's omitted. If the lower bound and size are omitted for a
particular dimension, the ' : ' is omitted as well. For example, a 2-dimensional
array with 1 as the lower bound and unspecified sizes is represented as [1:,1:] .
ELEMENT_TYPE_FNPTR is represented as "=FUNC: type (signature)", where type is
the return type, and signature is the arguments of the method. If there are no
arguments, the parentheses are omitted. The MSVC compiler never generates
this element.
The following signature components aren't represented because they're never
used for differentiating overloaded methods:
Calling convention
Return type
ELEMENT_TYPE_SENTINEL
For conversion operators only, the return value of the method is encoded as a ' ~ '
followed by the return type, as previously encoded.
For generic types, the name of the type will be followed by a back tick and then a
number that indicates the number of generic type parameters. For example,
XML
The example shows a type that's defined as public class MyClass<T, U> .
For methods that take generic types as parameters, the generic type parameters
are specified as numbers prefaced with back ticks (for example `0, `1). Each number
represents a zero-based array position for the type's generic parameters.
The following examples show how the ID strings for a class and its members would be
generated.
C++
<member name="T:MyClass`2">
Example
// xml_id_strings.cpp
// compile with: /clr /doc /LD
///
namespace N {
// "N:N"
 /// <see cref="System" />
 // <see cref="N:System"/>
 ref class X {
 // "T:N.X"
 protected:
 ///
 !X(){}
 // "M:N.X.Finalize", destructor's representation in metadata
 public:
 ///
 X() {}
 // "M:N.X.#ctor"
 ///
 static X() {}
 // "M:N.X.#cctor"
 ///
 X(int i) {}
 // "M:N.X.#ctor(System.Int32)"
 ///
 ~X() {}
 // "M:N.X.Dispose", Dispose function representation in metadata
 ///
 System::String^ q;
 // "F:N.X.q"
 ///
 double PI;
 // "F:N.X.PI"
 ///
 int f() { return 1; }
 // "M:N.X.f"
 ///
 int bb(System::String ^ s, int % y, void * z) { return 1; }
 // "M:N.X.bb(System.String,System.Int32@,System.Void*)"
 ///
 int gg(array<short> ^ array1, array< int, 2 >^ IntArray) { return 0; }
 // "M:N.X.gg(System.Int16[], System.Int32[0:,0:])"
 ///
 static X^ operator+(X^ x, X^ xx) { return x; }
 // "M:N.X.op_Addition(N.X,N.X)"
 ///
 property int prop;
 // "M:N.X.prop"
 ///
 property int prop2 {
 // "P:N.X.prop2"
XML documentation
 ///
 int get() { return 0; }
 // M:N.X.get_prop2
 ///
 void set(int i) {}
 // M:N.X.set_prop2(System.Int32)
 }
 ///
 delegate void D(int i);
 // "T:N.X.D"
 ///
 event D ^ d;
 // "E:N.X.d"
 ///
 ref class Nested {};
 // "T:N.X.Nested"
 ///
 static explicit operator System::Int32 (X x) { return 1; }
 //
"M:N.X.op_Explicit(N.X!System.Runtime.CompilerServices.IsByValue)~System.Int
32"
 };
}
See also
Delimiters for Visual C++
documentation tags
Article • 12/03/2021
The use of documentation tags requires delimiters, which indicate to the compiler where
a documentation comment begins and ends.
You can use the following kinds of delimiters with the XML documentation tags:
Delimiter Description
/// This is the form that's shown in documentation examples and used by the Visual
Studio C++ project templates.
/** */ These are multiline delimiters.
There are some formatting rules when using the /** */ delimiters:
For the line that contains the /** delimiter, if the rest of the line is whitespace, the
line isn't processed for comments. If the first character is whitespace, that
whitespace character is ignored and the rest of the line is processed. Otherwise,
the entire text of the line after the /** delimiter is processed as part of the
comment.
For the line that contains the */ delimiter, if there's only whitespace up to the */
delimiter, that line is ignored. Otherwise, the text on the line up to the */ delimiter
is processed as part of the comment, subject to the pattern-matching rules
described in the following bullet.
For the lines after the one that begins with the /** delimiter, the compiler looks
for a common pattern at the beginning of each line that consists of optional white
space and an asterisk ( * ), followed by more optional whitespace. If the compiler
finds a common set of characters at the beginning of each line, it will ignore that
pattern for all lines after the /** delimiter, up to and possibly including the line
that contains the */ delimiter.
The only part of the following comment that will be processed is the line that
begins with <summary> . The following two tag formats will produce the same
comments:
Examples
C++
/**
<summary>text</summary>
*/
/** <summary>text</summary> */
The compiler applies a pattern of " * " to ignore at the beginning of the second
and third lines.
C++
/**
 * <summary>
 * text </summary>*/
The compiler finds no pattern in this comment because there's no asterisk on the
second line. All text on the second and third lines, up until the */ , will be
processed as part of the comment.
C++
/**
 * <summary>
 text </summary>*/
The compiler finds no pattern in this comment for two reasons. First, there's no line
that begins with a consistent number of spaces before the asterisk. Second, the
fifth line begins with a tab, which doesn't match spaces. All text from the second
line until the */ will be processed as part of the comment.
C++
/**
 * <summary>
 * text
 * text2
 * </summary>
*/
See also
XML documentation


